From r@turner @ending from @uckl@nd@@c@nz  Sat Sep  1 01:01:51 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sat, 1 Sep 2018 11:01:51 +1200
Subject: [R] [FORGED]  Main label on Cullen and Frey
In-Reply-To: <2040384799.899784.1535715740012@mail2.virginmedia.com>
References: <2040384799.899784.1535715740012@mail2.virginmedia.com>
Message-ID: <83759f46-9307-4f79-2b96-2b83335ed221@auckland.ac.nz>


On 08/31/2018 11:42 PM, Nick Wray via R-help wrote:

> Hello   Does anyone know how to modify the main label when you plot a
> Cullen & Frey (sounds like an Oxford gentleman's outfitters -
> statistically significant waistcoats a speciality) diagram from the
> "descdist" function?  I've tried setting a variable to the
> descdist(data) but it just returns the summary statistics.

I know nothing about descdist() nor the package fitdistrplus whence it 
comes.  However I *do* know how to look at the code of R functions.
See fortune(250).

The short answer to your question is 'No.'  The main title is hard-wired in.

The long answer is:  It's easy to change:

* edit the function descdist()
* add the argument main="Cullen and Frey graph"
* change the call to plot() (about half way through the code) so
   that it says 'main=main' (rather than 'main="Cullen and Frey graph"')
* call descdist() with the syntax (something like)

     gorp <- descdist(x,discrete=TRUE,main="A Load of Dingoes' Kidneys")

And away you go.

Note: The editing process, however you go at it, will create a version 
of descdist() in your global environment.  This will over-ride (mask)
the package version.  However it will be ephemeral unless you choose to 
save your global environment when you quit from R.

You may wish to extract the code from the source package, edit that code 
in situ, and re-install the package from source.  This way you will get 
your modified version of descdist() every time you load the package.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @ending from @uckl@nd@@c@nz  Sat Sep  1 01:04:28 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sat, 1 Sep 2018 11:04:28 +1200
Subject: [R] [FORGED]  Main label on Cullen and Frey
In-Reply-To: <2040384799.899784.1535715740012@mail2.virginmedia.com>
References: <2040384799.899784.1535715740012@mail2.virginmedia.com>
Message-ID: <5f8160b5-7efa-da30-d157-0258a7550149@auckland.ac.nz>


On 08/31/2018 11:42 PM, Nick Wray via R-help wrote:

> ...  Does anyone know how to modify the main label when you plot a
> Cullen & Frey (sounds like an Oxford gentleman's outfitters -
> statistically significant waistcoats a speciality) diagram from the
> "descdist" function?

Fortune nomination.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jwd @ending from @urewe@t@net  Sat Sep  1 02:40:09 2018
From: jwd @ending from @urewe@t@net (John)
Date: Fri, 31 Aug 2018 17:40:09 -0700
Subject: [R] [FORGED]  Main label on Cullen and Frey
In-Reply-To: <5f8160b5-7efa-da30-d157-0258a7550149@auckland.ac.nz>
References: <2040384799.899784.1535715740012@mail2.virginmedia.com>
 <5f8160b5-7efa-da30-d157-0258a7550149@auckland.ac.nz>
Message-ID: <20180831174009.6a5f93b2@Draco.localdomain>

On Sat, 1 Sep 2018 11:04:28 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 08/31/2018 11:42 PM, Nick Wray via R-help wrote:
> 
> > ...  Does anyone know how to modify the main label when you plot a
> > Cullen & Frey (sounds like an Oxford gentleman's outfitters -
> > statistically significant waistcoats a speciality) diagram from the
> > "descdist" function?  
> 
> Fortune nomination.
> 
> cheers,
> 
> Rolf Turner
> 

Seconded.

JWDougherty


From wdunl@p @ending from tibco@com  Sat Sep  1 03:12:25 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 31 Aug 2018 18:12:25 -0700
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPQaxLM9FzNabJ=AJPGacVbWUnRBR3HpPRgweN=2oqVitU6pyQ@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
 <CAPQaxLN4Ji3rn9EF_2mKT1Z2-UY5Tx4M+3GNY4J-Ou-hMte_bg@mail.gmail.com>
 <CAPMtxSisrfmnMM79yT_XdvJXYdHUs6nyxw-_-CJ6rPZUpVhLpA@mail.gmail.com>
 <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>
 <CAF8bMcbCFbVbdgDbqbisyKZ+fYnBmW8ybSQD4mMym8Rgaa_9qg@mail.gmail.com>
 <CAPQaxLM9FzNabJ=AJPGacVbWUnRBR3HpPRgweN=2oqVitU6pyQ@mail.gmail.com>
Message-ID: <CAF8bMcZYLq8hUBNTdeiL=5_-Mvn5xwj+WkasdjOBEuk4eo8pSg@mail.gmail.com>

It looks like it is not a UTF-16 text file, although it could be UTF-16
with a different byte order.
Look at it with a text editor or Excel or 'od' or 'file' (the latter are
Unix utilities) or ask the person
you got it from to see what the file contains.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Aug 31, 2018 at 6:01 PM, Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Thank you Mr. Dunlap for the suggestion. How would this modified read.csv
> file read? This is my attempt at what you suggested, which is obviously
> errored.
>
> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=
> TRUE,fileEncoding="UTF-16")
> Warning messages:
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   invalid input found on input connection 'GBM_clinical_drug.csv'
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   incomplete final line found by readTableHeader on 'GBM_clinical_drug.csv'
> >  the_data<-read.csv(file="GBM_clinical_drug.csv",header=
> TRUE,sep=",",fileEncoding="UTF-16")
> Warning messages:
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   invalid input found on input connection 'GBM_clinical_drug.csv'
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   incomplete final line found by readTableHeader on 'GBM_clinical_drug.csv'
>
> Many thanks,
>
> Spencer Brackett
> >
>
>
> On Fri, Aug 31, 2018 at 11:12 AM William Dunlap <wdunlap at tibco.com> wrote:
>
>> Try adding fileEncoding="UTF-16" to your read.csv() call.  Many Windows
>> programs write UTF-16 files by default.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Thu, Aug 30, 2018 at 6:05 PM, Spencer Brackett <
>> spbrackett20 at saintjosephhs.com> wrote:
>>
>>> My apologies... the following is what I received from the correction
>>>
>>>  the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep=",")
>>> Warning messages:
>>> 1: In read.table(file = file, header = header, sep = sep, quote =
>>> quote,  :
>>>   line 3 appears to contain embedded nulls
>>> 2: In read.table(file = file, header = header, sep = sep, quote =
>>> quote,  :
>>>   line 4 appears to contain embedded nulls
>>> 3: In read.table(file = file, header = header, sep = sep, quote =
>>> quote,  :
>>>   line 5 appears to contain embedded nulls
>>> 4: In scan(file = file, what = what, sep = sep, quote = quote, dec =
>>> dec,  :
>>>   embedded nul(s) found in input
>>> >
>>>
>>>
>>> On Thu, Aug 30, 2018 at 8:57 PM Patrick Barry <pdbarry at alaska.edu>
>>> wrote:
>>>
>>> > You still haven't fixed the first thing both Sarah and I pointed out.
>>> You
>>> > are lacking an = between sep and ","
>>> >
>>> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>>> >
>>> > should be
>>> >
>>> > the_data <- read.csv(file = "GBM_clinical_drug.csv", header = TRUE,
>>> *sep
>>> > = ","*)
>>> >
>>> > as Sarah pointed out, you should use spaces to help make these errors
>>> more
>>> > obvious.
>>> >
>>> > On Thu, Aug 30, 2018 at 4:53 PM, Spencer Brackett <
>>> > spbrackett20 at saintjosephhs.com> wrote:
>>> >
>>> >> Hello again,
>>> >>
>>> >> My apologies for the delayed response... computer troubles. In
>>> reference
>>> >> to
>>> >> Ms. Goslee's and Mr. Barry's query, the following is the error code
>>> >> received after I inputted my R command
>>> >>
>>> >>  the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>>> >> Error: unexpected string constant in
>>> >> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",""
>>> >>
>>> >> Given this, should I proceed with implementing the path<getwd()
>>> ,since I
>>> >> am, as he suggested trying to set the variable *path* to my working
>>> >> directory with path<-"."
>>> >>
>>> >> Mr. Mittal also recommended importing with r studio, which I shall
>>> try in
>>> >> the meantime.
>>> >>
>>> >> Many thanks,
>>> >>
>>> >> Spencer Brackett
>>> >>
>>> >>
>>> >> On Wed, Aug 29, 2018 at 10:14 PM Amit Mittal <
>>> prof.amit.mittal at gmail.com>
>>> >> wrote:
>>> >>
>>> >> > Use r studio and import from the menu. Read_csv has changed
>>> >> >
>>> >> > Also you can see any format problems
>>> >> >
>>> >> > On Thu, 30 Aug 2018 3:36 am Spencer Brackett, <
>>> >> > spbrackett20 at saintjosephhs.com> wrote:
>>> >> >
>>> >> >> Good evening R users,
>>> >> >>
>>> >> >>   I am attempting to carry out DNA methylation analysis on two
>>> separate
>>> >> >> CSV
>>> >> >> files (LGG and GBM), which I have downloaded onto my R console. To
>>> set
>>> >> the
>>> >> >> path<-"." to be indicative of one or both of the csv files, I
>>> utilized
>>> >> the
>>> >> >> following functions and received the errors shown. How do I set the
>>> >> "." so
>>> >> >> that I can begin analysis on my files?
>>> >> >>
>>> >> >> > the_data <-read.csv(file="LGG_clinical_
>>> drug.csv",header=T,sep",")
>>> >> >> Error: unexpected string constant in "the_data
>>> >> >> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
>>> >> >> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
>>> >> >> Error: unexpected string constant in
>>> >> >> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>>> >> >>
>>> >> >> This is the preliminary portion of the analysis I am trying to run,
>>> >> which
>>> >> >> I
>>> >> >> am referring to:
>>> >> >>
>>> >> >> 1 library(TCGAbiolinks)
>>> >> >> 2
>>> >> >> 3 # Download the DNA methylation data: HumanMethylation450 LGG and
>>> GBM.
>>> >> >> 4 path <? "."
>>> >> >> 5
>>> >> >> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"
>>> HumanMethylation450",
>>> >> >> level = 3)
>>> >> >> 7 TCGAdownload(query.met, path = path )
>>> >> >> 8 met <? TCGAprepare(query = query.met,dir = path,
>>> >> >> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>> >> >> 10                    summarizedExperiment = TRUE,
>>> >> >> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>> >> >> 12
>>> >> >> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and
>>> GBM.
>>> >> >> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>> >> >> "IlluminaHiSeq_
>>> >> >> RNASeqV2",level = 3)
>>> >> >> 15
>>> >> >> 16 TCGAdownload(query.exp,path = path, type =
>>> "rsem.genes.normalized_
>>> >> >> results")
>>> >> >> 17
>>> >> >> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>> >> >> 19                    summarizedExperiment = TRUE,
>>> >> >> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>> >> >> 21                    type = "rsem.genes.normalized_results",
>>> >> >> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>> >> >>
>>> >> >> Many thanks,
>>> >> >>
>>> >> >> Spencer Brackett
>>> >> >>
>>> >> >>         [[alternative HTML version deleted]]
>>> >> >>
>>> >> >> ______________________________________________
>>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> >> PLEASE do read the posting guide
>>> >> >> http://www.R-project.org/posting-guide.html
>>> >> >> and provide commented, minimal, self-contained, reproducible code.
>>> >> >>
>>> >> >
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]


From @@@h@@w@ng2017 @ending from y@ndex@com  Sat Sep  1 01:58:57 2018
From: @@@h@@w@ng2017 @ending from y@ndex@com (Jiayue Wang)
Date: Sat, 1 Sep 2018 07:58:57 +0800
Subject: [R] Specifying Java runtime path
Message-ID: <e73cc047-58e1-6edb-0e8a-ea23c0c82b09@yandex.com>

My Java interpreter etc. are not in the "standard" paths (I use Oracle 
JDK, which was installed in /opt) so I keep getting error messages when 
I tried to install packages that depend on rJava. How should Java 
runtime specs be specified?

Thanks

Sasha


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Sep  1 18:29:04 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 01 Sep 2018 09:29:04 -0700
Subject: [R] Specifying Java runtime path
In-Reply-To: <e73cc047-58e1-6edb-0e8a-ea23c0c82b09@yandex.com>
References: <e73cc047-58e1-6edb-0e8a-ea23c0c82b09@yandex.com>
Message-ID: <D291050E-CAD0-43B2-94CD-6E6D9C9FBF82@dcn.davis.ca.us>

Wouldn't that be the usual way... by exporting environment variables? You can cobble together the right settings using Sys.setenv(), but this kind of thing is best handled in your user-level OS configuration (~/.profile?) and this is not the right place to learn about how to muck with your OS.

On August 31, 2018 4:58:57 PM PDT, Jiayue Wang <sasha.wang2017 at yandex.com> wrote:
>My Java interpreter etc. are not in the "standard" paths (I use Oracle 
>JDK, which was installed in /opt) so I keep getting error messages when
>
>I tried to install packages that depend on rJava. How should Java 
>runtime specs be specified?
>
>Thanks
>
>Sasha
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From t@vib@r @ending from gm@il@com  Sat Sep  1 22:32:26 2018
From: t@vib@r @ending from gm@il@com (Micha Silver)
Date: Sat, 1 Sep 2018 23:32:26 +0300
Subject: [R] partialPlot within a function
Message-ID: <4e61af90-99d0-f252-213f-358330d6af3e@gmail.com>

I am running randomForest regressions in a loop, passing a different 
data.frame each time, and trying to plot importance and partial 
dependency plots for all variables in the data.frame. The commands all 
run OK when typed at the prompt, but when I wrap them into a function, 
the partialPlot function fails with:
 ?Error in eval(x.var) : object 'impvar' not found

It seems that the x.var parameter is getting the variable name 
(impvar[i] in this case) rather than the value of the variable.
What am I missing here?


The easiest way to see this is using the example right from the 
partialPlot help page, but wrapped into a function:

##--------------------------
library(randomForest)
## Looping over variables ranked by importance:
do_pdp <- function(dta) {
 ??????? dta <- na.omit(dta)
 ??????? set.seed(131)
 ??????? ozone.rf <- randomForest(Ozone ~ ., dta, importance=TRUE)
 ??????? imp <- importance(ozone.rf)
 ??????? impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
 ??????? op <- par(mfrow=c(2, 3))
 ??????? for (i in seq_along(impvar)) {
 ???????????? partialPlot(ozone.rf, dta, impvar[i], xlab=impvar[i],
 ???????????????????? main=paste("Partial Dependence on", impvar[i]),
 ???????????????????? ylim=c(30, 70))
 ??????? }
 ??????? par(op)
}
data(airquality)
do_pdp(airquality)
##--------------------------

Fails with the above message above for me. Running the commands 
directly, without the "do_pdp" function works fine, of course.


sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Linux Mint 19

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3
LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so

locale:
 ?[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
 ?[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=en_US.UTF-8
 ?[5] LC_MONETARY=en_US.UTF-8??? LC_MESSAGES=en_US.UTF-8
 ?[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
 ?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods base

other attached packages:
[1] randomForest_4.6-14

loaded via a namespace (and not attached):
[1] compiler_3.5.1 tools_3.5.1

Thanks

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From t@vib@r @ending from gm@il@com  Sun Sep  2 08:38:08 2018
From: t@vib@r @ending from gm@il@com (Micha Silver)
Date: Sun, 2 Sep 2018 09:38:08 +0300
Subject: [R] partialPlot within a function
In-Reply-To: <DM6PR01MB4107BCCDB66DE1D72259C678FC0D0@DM6PR01MB4107.prod.exchangelabs.com>
References: <4e61af90-99d0-f252-213f-358330d6af3e@gmail.com>
 <DM6PR01MB4107A7B5B54A9CA54D67C5E8FC0D0@DM6PR01MB4107.prod.exchangelabs.com>
 <634035f9-025c-28c4-803a-00371ef0a656@gmail.com>
 <DM6PR01MB4107BCCDB66DE1D72259C678FC0D0@DM6PR01MB4107.prod.exchangelabs.com>
Message-ID: <5504d5a5-d9a6-6d22-f58b-369820489be2@gmail.com>



On 09/02/2018 09:28 AM, Amit Mittal wrote:
>> partialPlot(ozone.rf, dta, impvar[i],
>
> Is there a close bracket here. Have you tried naming each of the 
> parameters, like data = ozone.rf etc. Dry if I am rushing this . But 
> it looks a basic syntax problem
>

It's just copy-paste from the help example. I don't think there's a 
syntax problem.
And If I just take the same commands *out* of the function, it works fine.
:-(

> ????????????
> Amit Mittal
> PhD in Finance and Accounting (tbd)
> IIM Lucknow
> http://ssrn.com/author=2665511
> *Top 10%, downloaded author since July 2017
> ????????????
> Sent from my Outlook for Android
> https://aka.ms/ghei36
>
> ------------------------------------------------------------------------
> *From:* Micha Silver <tsvibar at gmail.com>
> *Sent:* Sunday, September 2, 2018 11:54:44 AM
> *To:* Amit Mittal
> *Cc:* R-help
> *Subject:* Re: [R] partialPlot within a function
>
>
> On 09/02/2018 09:17 AM, Amit Mittal wrote:
>> Could be just the assignment of a new xlab
>>
>> `xlab=impvar[i],`
>>
>
> The error message refers to the x.var, not the axis label.
> Besides, the x axis label has a default value. x.var does not)
> ??
> Thanks
>
>> Try xlab[i]=impvar[i]
>> Or initialising it xlab <-0
>>
>> ????????????
>> Amit Mittal
>> PhD in Finance and Accounting (tbd)
>> IIM Lucknow
>> http://ssrn.com/author=2665511
>> *Top 10%, downloaded author since July 2017
>> ????????????
>> Sent from my Outlook for Android
>> https://aka.ms/ghei36
>>
>> ------------------------------------------------------------------------
>> *From:* R-help <r-help-bounces at r-project.org> on behalf of Micha 
>> Silver <tsvibar at gmail.com>
>> *Sent:* Sunday, September 2, 2018 2:02:26 AM
>> *To:* R-help at r-project.org
>> *Subject:* [R] partialPlot within a function
>> I am running randomForest regressions in a loop, passing a different
>> data.frame each time, and trying to plot importance and partial
>> dependency plots for all variables in the data.frame. The commands all
>> run OK when typed at the prompt, but when I wrap them into a function,
>> the partialPlot function fails with:
>> ??Error in eval(x.var) : object 'impvar' not found
>>
>> It seems that the x.var parameter is getting the variable name
>> (impvar[i] in this case) rather than the value of the variable.
>> What am I missing here?
>>
>>
>> The easiest way to see this is using the example right from the
>> partialPlot help page, but wrapped into a function:
>>
>> ##--------------------------
>> library(randomForest)
>> ## Looping over variables ranked by importance:
>> do_pdp <- function(dta) {
>> ???????? dta <- na.omit(dta)
>> ???????? set.seed(131)
>> ???????? ozone.rf <- randomForest(Ozone ~ ., dta, importance=TRUE)
>> ???????? imp <- importance(ozone.rf)
>> ???????? impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
>> ???????? op <- par(mfrow=c(2, 3))
>> ???????? for (i in seq_along(impvar)) {
>> ????????????? partialPlot(ozone.rf, dta, impvar[i], xlab=impvar[i],
>> ????????????????????? main=paste("Partial Dependence on", impvar[i]),
>> ????????????????????? ylim=c(30, 70))
>> ???????? }
>> ???????? par(op)
>> }
>> data(airquality)
>> do_pdp(airquality)
>> ##--------------------------
>>
>> Fails with the above message above for me. Running the commands
>> directly, without the "do_pdp" function works fine, of course.
>>
>>
>> sessionInfo()
>> R version 3.5.1 (2018-07-02)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Linux Mint 19
>>
>> Matrix products: default
>> BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3
>> LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so
>>
>> locale:
>> ??[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
>> ??[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=en_US.UTF-8
>> ??[5] LC_MONETARY=en_US.UTF-8??? LC_MESSAGES=en_US.UTF-8
>> ??[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
>> ??[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats???? graphics? grDevices utils???? datasets methods base
>>
>> other attached packages:
>> [1] randomForest_4.6-14
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.5.1 tools_3.5.1
>>
>> Thanks
>>
>> -- 
>> Micha Silver
>> Ben Gurion Univ.
>> Sde Boker, Remote Sensing Lab
>> cell: +972-523-665918
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html 
>> <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
> -- 
> Micha Silver
> Ben Gurion Univ.
> Sde Boker, Remote Sensing Lab
> cell: +972-523-665918

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From @k@h@y_e4 @ending from hotm@il@com  Sun Sep  2 09:57:44 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Sun, 2 Sep 2018 07:57:44 +0000
Subject: [R] RHEl Vs UBUNTU for R
Message-ID: <SL2P216MB0091E5F57C803D6D5D4638BFC80D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I am using AWS LINUX ec2 instances for running my R code.

I am in  a conundrum whether to use RHEL or Ubuntu.

Does R run faster on Red Hat as compared to Ubuntu?

What other advantages does running R have on Red Hat over Ubuntu?

Very many thanks for your time and effort...
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Sep  2 10:20:53 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 02 Sep 2018 01:20:53 -0700
Subject: [R] RHEl Vs UBUNTU for R
In-Reply-To: <SL2P216MB0091E5F57C803D6D5D4638BFC80D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091E5F57C803D6D5D4638BFC80D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <3A079AB4-B74C-44B7-B858-2A47106ED307@dcn.davis.ca.us>

R runs equally well on both of those distributions of the Linux kernel. The choice of which to use would be determined by your personal preferences or by those of the people you have available to help you manage the system configuration. This is not an OS support area, nor a chat room for debating personal preferences, so please don't pursue this discussion here.

On September 2, 2018 12:57:44 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>              I am using AWS LINUX ec2 instances for running my R code.
>
>I am in  a conundrum whether to use RHEL or Ubuntu.
>
>Does R run faster on Red Hat as compared to Ubuntu?
>
>What other advantages does running R have on Red Hat over Ubuntu?
>
>Very many thanks for your time and effort...
>Yours sincerely,
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @@@h@@w@ng2017 @ending from y@ndex@com  Sun Sep  2 09:54:27 2018
From: @@@h@@w@ng2017 @ending from y@ndex@com (Jiayue Wang)
Date: Sun, 2 Sep 2018 15:54:27 +0800
Subject: [R] Specifying Java runtime path
In-Reply-To: <D291050E-CAD0-43B2-94CD-6E6D9C9FBF82@dcn.davis.ca.us>
References: <e73cc047-58e1-6edb-0e8a-ea23c0c82b09@yandex.com>
 <D291050E-CAD0-43B2-94CD-6E6D9C9FBF82@dcn.davis.ca.us>
Message-ID: <5081a6a6-7153-edfc-bd7c-40a27d7ce1fb@yandex.com>

Thanks Jeff, for the patience to answer my newbie question, now I know 
which way to look.

Sasha

On 09/02/2018 12:29 AM, Jeff Newmiller wrote:
> Wouldn't that be the usual way... by exporting environment variables? You can cobble together the right settings using Sys.setenv(), but this kind of thing is best handled in your user-level OS configuration (~/.profile?) and this is not the right place to learn about how to muck with your OS.
> 
> On August 31, 2018 4:58:57 PM PDT, Jiayue Wang <sasha.wang2017 at yandex.com> wrote:
>> My Java interpreter etc. are not in the "standard" paths (I use Oracle
>> JDK, which was installed in /opt) so I keep getting error messages when
>>
>> I tried to install packages that depend on rJava. How should Java
>> runtime specs be specified?
>>
>> Thanks
>>
>> Sasha
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From t@vib@r @ending from gm@il@com  Sun Sep  2 14:56:51 2018
From: t@vib@r @ending from gm@il@com (Micha Silver)
Date: Sun, 2 Sep 2018 15:56:51 +0300
Subject: [R] partialPlot within a function [Solved]
In-Reply-To: <4e61af90-99d0-f252-213f-358330d6af3e@gmail.com>
References: <4e61af90-99d0-f252-213f-358330d6af3e@gmail.com>
Message-ID: <9dd43e80-f06b-9061-4e9d-f1f8753d69d8@gmail.com>

I found a few old posts on StackOverflow that brought up the same 
problem with partialPlot. Apparently the function refers to the global 
env when looking for x.var, and if it's running within a function, there 
is no global value for that parameter.

The work around was simple: put the partialPlot function into a do.call()

 ??????? for (i in seq_along(impvar)) {
 ??? ??? ??? ?? pP_params <- list(x = ozone.rf,? pred.data = dta,
 ??? ??? ??? ??? ??? ??? ??? ??? x.var = impvar[i], xlab = impvar[i],
 ???????????????????? ??? ??? main=paste("Partial Dependence on", 
impvar[i]),
 ???????????????????? ??? ??? ylim=c(30, 70))
 ???????????? do.call("partialPlot", pP_params)
 ??????? }

Regards,

On 09/01/2018 11:32 PM, Micha Silver wrote:
> I am running randomForest regressions in a loop, passing a different 
> data.frame each time, and trying to plot importance and partial 
> dependency plots for all variables in the data.frame. The commands all 
> run OK when typed at the prompt, but when I wrap them into a function, 
> the partialPlot function fails with:
> ?Error in eval(x.var) : object 'impvar' not found
>
> It seems that the x.var parameter is getting the variable name 
> (impvar[i] in this case) rather than the value of the variable.
> What am I missing here?
>
>
> The easiest way to see this is using the example right from the 
> partialPlot help page, but wrapped into a function:
>
> ##--------------------------
> library(randomForest)
> ## Looping over variables ranked by importance:
> do_pdp <- function(dta) {
> ??????? dta <- na.omit(dta)
> ??????? set.seed(131)
> ??????? ozone.rf <- randomForest(Ozone ~ ., dta, importance=TRUE)
> ??????? imp <- importance(ozone.rf)
> ??????? impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
> ??????? op <- par(mfrow=c(2, 3))
> ??????? for (i in seq_along(impvar)) {
> ???????????? partialPlot(ozone.rf, dta, impvar[i], xlab=impvar[i],
> ???????????????????? main=paste("Partial Dependence on", impvar[i]),
> ???????????????????? ylim=c(30, 70))
> ??????? }
> ??????? par(op)
> }
> data(airquality)
> do_pdp(airquality)
> ##--------------------------
>
> Fails with the above message above for me. Running the commands 
> directly, without the "do_pdp" function works fine, of course.
>
>
> sessionInfo()
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Linux Mint 19
>
> Matrix products: default
> BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3
> LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so
>
> locale:
> ?[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=en_US.UTF-8
> ?[5] LC_MONETARY=en_US.UTF-8??? LC_MESSAGES=en_US.UTF-8
> ?[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
> ?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats???? graphics? grDevices utils???? datasets? methods base
>
> other attached packages:
> [1] randomForest_4.6-14
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.1 tools_3.5.1
>
> Thanks
>

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From t@@ingh @ending from ucl@@c@uk  Mon Sep  3 10:47:53 2018
From: t@@ingh @ending from ucl@@c@uk (Singh, Tanya)
Date: Mon, 3 Sep 2018 08:47:53 +0000
Subject: [R] pheatmap query
Message-ID: <AM4PR01MB1860BEBDAECEDF6B6BF03DE1BD0C0@AM4PR01MB1860.eurprd01.prod.exchangelabs.com>

Hi



I am plotting a pheatmap using following line in a R code

pheatmap(counts_filtered_df,scale="row",cluster_col=FALSE,cluster_row=TRUE,border_color=NA,show_rownames = T)



I want to extract the row names in the same order as shown in pheatmap and the z scores for them.



So basically a numeric matrix instead of a figure. Can someone help me how this can be done



Thanks



Tanya


	[[alternative HTML version deleted]]


From p@ulbern@l07 @ending from gm@il@com  Mon Sep  3 16:30:22 2018
From: p@ulbern@l07 @ending from gm@il@com (Paul Bernal)
Date: Mon, 3 Sep 2018 09:30:22 -0500
Subject: [R] Error when using complete function for imputed data
Message-ID: <CAMOcQfN82EGX1SPQY7iet2LsMT25iKXJBFLMvLg80k3cC6t0ug@mail.gmail.com>

Dear friends,

It seems to me that there is something wrong with the complete function. I
am using R version 3.5.0 and mice package for data imputation.

I am working on a Windows 8.1 Enterprise machine with 64-bit Operating
System.

So here is my code:

Imputed_Data <- mice(dataFrame[2:5])
CompleteData <- complete(Imputed_Data)
Error in UseMethod("complete_") :
  no applicable method for 'complete_' applied to an object of class "mids"

I used the complete function before when imputing data with the mice
function, but now it is not working.

Any help will be greatly appreciated. Below is the dput() of my dataset:

> dput(dataFrame)
structure(list(TransitDate = structure(c(496990800, 499669200,
502261200, 504939600, 507618000, 510037200, 512715600, 515307600,
517986000, 520578000, 523256400, 525934800, 528526800, 531205200,
533797200, 536475600, 539154000, 541573200, 544251600, 546843600,
549522000, 552114000, 554792400, 557470800, 560062800, 562741200,
565333200, 568011600, 570690000, 573195600, 575874000, 578466000,
581144400, 583736400, 586414800, 589093200, 591685200, 594363600,
596955600, 599634000, 602312400, 604731600, 607410000, 610002000,
612680400, 615272400, 617950800, 620629200, 623221200, 625899600,
628491600, 631170000, 633848400, 636267600, 638946000, 641538000,
644216400, 646808400, 649486800, 652165200, 654757200, 657435600,
660027600, 662706000, 665384400, 667803600, 670482000, 673074000,
675752400, 678344400, 681022800, 683701200, 686293200, 688971600,
691563600, 694242000, 696920400, 699426000, 702104400, 704696400,
707371200, 709963200, 712641600, 715320000, 717912000, 720590400,
723182400, 725860800, 728539200, 730958400, 733636800, 736232400,
738910800, 741502800, 744181200, 746859600, 749451600, 752130000,
754722000, 757400400, 760078800, 762498000, 765176400, 767768400,
770446800, 773038800, 775717200, 778395600, 780987600, 783666000,
786258000, 788936400, 791614800, 794034000, 796712400, 799304400,
801982800, 804574800, 807253200, 809931600, 812523600, 815202000,
817794000, 820472400, 823150800, 825656400, 828334800, 830926800,
833605200, 836197200, 838875600, 841554000, 844146000, 846824400,
849416400, 852094800, 854773200, 857192400, 859870800, 862462800,
865141200, 867733200, 870411600, 873090000, 875682000, 878360400,
880952400, 883630800, 886309200, 888728400, 891406800, 893998800,
896677200, 899269200, 901947600, 904626000, 907218000, 909896400,
912488400, 915166800, 917845200, 920264400, 922942800, 925534800,
928213200, 930805200, 933483600, 936162000, 938754000, 941432400,
944024400, 946702800, 949381200, 951886800, 954565200, 957157200,
959835600, 962427600, 965106000, 967784400, 970376400, 973054800,
975646800, 978325200, 981003600, 983422800, 986101200, 988693200,
991371600, 993963600, 996642000, 999320400, 1001912400, 1004590800,
1007182800, 1009861200, 1012539600, 1014958800, 1017637200, 1020229200,
1022907600, 1025499600, 1028178000, 1030856400, 1033448400, 1036126800,
1038718800, 1041397200, 1044075600, 1046494800, 1049173200, 1051765200,
1054443600, 1057035600, 1059714000, 1062392400, 1064984400, 1067662800,
1070254800, 1072933200, 1075611600, 1078117200, 1080795600, 1083387600,
1086066000, 1088658000, 1091336400, 1094014800, 1096606800, 1099285200,
1101877200, 1104555600, 1107234000, 1109653200, 1112331600, 1114923600,
1117602000, 1120194000, 1122872400, 1125550800, 1128142800, 1130821200,
1133413200, 1136091600, 1138770000, 1141189200, 1143867600, 1146459600,
1149138000, 1151730000, 1154408400, 1157086800, 1159678800, 1162357200,
1164949200, 1167627600, 1170306000, 1172725200, 1175403600, 1177995600,
1180674000, 1183266000, 1185944400, 1188622800, 1191214800, 1193893200,
1196485200, 1199163600, 1201842000, 1204347600, 1207026000, 1209618000,
1212296400, 1214888400, 1217566800, 1220245200, 1222837200, 1225515600,
1228107600, 1230786000, 1233464400, 1235883600, 1238562000, 1241154000,
1243832400, 1246424400, 1249102800, 1251781200, 1254373200, 1257051600,
1259643600, 1262322000, 1265000400, 1267419600, 1270098000, 1272690000,
1275368400, 1277960400, 1280638800, 1283317200, 1285909200, 1288587600,
1291179600, 1293858000, 1296536400, 1298955600, 1301634000, 1304226000,
1306904400, 1309496400, 1312174800, 1314853200, 1317445200, 1320123600,
1322715600, 1325394000, 1328072400, 1330578000, 1333256400, 1335848400,
1338526800, 1341118800, 1343797200, 1346475600, 1349067600, 1351746000,
1354338000, 1357016400, 1359694800, 1362114000, 1364792400, 1367384400,
1370062800, 1372654800, 1375333200, 1378011600, 1380603600, 1383282000,
1385874000, 1388552400, 1391230800, 1393650000, 1396328400, 1398920400,
1401598800, 1404190800, 1406869200, 1409547600, 1412139600, 1414818000,
1417410000, 1420088400, 1422766800, 1425186000, 1427864400, 1430456400,
1433134800, 1435726800, 1438405200, 1441083600, 1443675600, 1446354000,
1448946000, 1451624400, 1454302800, 1456808400, 1459486800, 1462078800,
1464757200, 1467349200, 1470027600, 1472706000, 1475298000, 1477976400,
1480568400, 1483246800, 1485925200, 1488344400, 1491022800, 1493614800,
1496293200, 1501563600, 1504242000), class = c("POSIXct", "POSIXt"
), tzone = ""), Transits = c(14L, 14L, 13L, 10L, 11L, 14L, 14L,
14L, 16L, 6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L, 8L,
10L, 9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L,
7L, 7L, 8L, 4L, 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L, 5L,
10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L, 5L, 6L, 7L, 6L, 9L, 8L,
10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L, 14L, 15L,
14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L, 9L, 12L, 8L,
12L, 10L, 11L, 10L, 9L, 10L, 11L, 8L, 10L, 12L, 10L, 11L, 14L,
9L, 15L, 15L, 14L, 14L, 14L, 15L, 16L, 15L, 18L, 21L, 18L, 17L,
21L, 18L, 19L, 19L, 18L, 21L, 22L, 25L, 23L, 28L, 25L, 25L, 25L,
21L, 28L, 21L, 22L, 23L, 20L, 24L, 22L, 26L, 24L, 24L, 28L, 31L,
34L, 36L, 33L, 29L, 34L, 33L, 33L, 31L, 33L, 29L, 32L, 26L, 24L,
30L, 27L, 31L, 23L, 23L, 21L, 21L, 18L, 21L, 19L, 19L, 16L, 14L,
22L, 24L, 28L, 26L, 29L, 23L, 28L, 21L, 17L, 17L, 14L, 12L, 14L,
10L, 12L, 13L, 14L, 15L, 21L, 10L, 15L, 12L, 15L, 16L, 17L, 14L,
14L, 12L, 7L, 8L, 8L, 11L, 9L, 12L, 11L, 6L, 8L, 11L, 7L, 8L,
14L, 9L, 11L, 8L, 8L, 6L, 3L, 4L, 4L, 5L, 4L, 3L, 3L, 5L, 8L,
6L, 8L, 6L, 7L, 14L, 14L, 15L, 13L, 16L, 18L, 20L, 21L, 18L,
19L, 24L, 27L, 26L, 18L, 28L, 21L, 22L, 25L, 29L, 26L, 22L, 22L,
14L, 18L, 18L, 13L, 15L, 16L, 19L, 9L, 14L, 11L, 9L, 14L, 16L,
11L, 13L, 11L, 16L, 16L, 20L, 17L, 19L, 18L, 24L, 19L, 19L, 15L,
21L, 21L, 24L, 28L, 14L, 20L, 15L, 24L, 18L, 24L, 24L, 25L, 21L,
24L, 27L, 28L, 27L, 26L, 29L, 25L, 24L, 25L, 28L, 23L, 30L, 23L,
29L, 26L, 31L, 33L, 40L, 36L, 39L, 36L, 34L, 32L, 32L, 30L, 27L,
32L, 30L, 31L, 26L, 31L, 29L, 26L, 28L, 24L, 22L, 11L, 15L, 17L,
12L, 13L, 14L, 9L, 12L, 11L, 17L, 9L, 8L, 7L, 11L, 8L, 15L, 8L,
10L, 13L, 12L, 13L, 12L, 12L, 19L, 21L, 18L, 20L, 21L, 20L, 22L,
19L, 21L, 20L, 21L, 18L, 18L, 19L, 13L, 16L, 12L, 6L, 7L, 5L,
6L, 6L, 7L, 7L, 5L, 4L, 6L, 4L, 1L, 2L, 7L, 12L), CargoTons = c(154973L,
129636L, 136884L, 86348L, 109907L, 154506L, 144083L, 152794L,
124861L, 60330L, 65221L, 61718L, 53997L, 83536L, 63218L, 98222L,
54719L, 98470L, 18263L, 104255L, 62869L, 62523L, 75344L, 81476L,
92818L, 87457L, 85231L, 77897L, 57699L, 96989L, 109361L, 59799L,
91116L, 82241L, 74251L, 124361L, 68751L, 61719L, 68017L, 37760L,
32513L, 56359L, 51333L, 80859L, 75852L, 65760L, 96043L, 38820L,
63202L, 102647L, 49104L, 53482L, 121305L, 71795L, 76704L, 146097L,
73047L, 68557L, 110642L, 77616L, 97767L, 52059L, 58658L, 66350L,
69303L, 76013L, 91909L, 108445L, 94454L, 101249L, 112131L, 56290L,
118342L, 70618L, 64783L, 112839L, 120506L, 94243L, 130768L, 133643L,
146321L, 140736L, 147234L, 158953L, 189888L, 93819L, 130021L,
130124L, 55088L, 114783L, 95184L, 82205L, 80321L, 65422L, 98933L,
93713L, 98417L, 97210L, 88464L, 94659L, 92873L, 79784L, 96655L,
122266L, 100779L, 120569L, 133029L, 92889L, 160886L, 132364L,
130435L, 139653L, 152143L, 160824L, 165842L, 175679L, 210872L,
211941L, 207820L, 179857L, 212733L, 203135L, 218368L, 198343L,
195677L, 210066L, 243311L, 261965L, 240683L, 245242L, 218004L,
247640L, 209872L, 223668L, 290521L, 185161L, 210341L, 261739L,
205431L, 284114L, 251466L, 302961L, 292981L, 279329L, 309197L,
341092L, 385209L, 366958L, 330515L, 286950L, 295590L, 350901L,
341678L, 284666L, 283148L, 279108L, 284896L, 238802L, 198786L,
273465L, 256694L, 360520L, 320201L, 296881L, 264202L, 280142L,
219105L, 278606L, 254420L, 260339L, 216457L, 198077L, 249436L,
302860L, 360184L, 317105L, 391413L, 265210L, 354714L, 306031L,
266124L, 215799L, 232630L, 156590L, 203111L, 157075L, 160140L,
177874L, 219162L, 159610L, 286483L, 144631L, 216456L, 157305L,
237780L, 191617L, 223211L, 180330L, 187074L, 126043L, 62462L,
93633L, 56417L, 115036L, 74365L, 98785L, 116172L, 43421L, 73769L,
128795L, 58910L, 74282L, 115312L, 102303L, 106109L, 76940L, 82683L,
49149L, 22517L, 20731L, 24684L, 52558L, 40057L, 28981L, 46062L,
43213L, 107755L, 53404L, 56390L, 41541L, 41183L, 80161L, 110960L,
130891L, 130395L, 183351L, 242803L, 225383L, 190962L, 169432L,
186260L, 206997L, 196097L, 202942L, 175063L, 240869L, 213226L,
237754L, 208280L, 231596L, 207033L, 213294L, 250265L, 129334L,
173986L, 145188L, 98384L, 163739L, 138180L, 136521L, 86836L,
97452L, 71988L, 79293L, 124134L, 116343L, 91030L, 98457L, 77906L,
130599L, 132381L, 162992L, 142756L, 150105L, 150339L, 161097L,
112633L, 145691L, 100771L, 147805L, 123418L, 138375L, 185776L,
108842L, 145245L, 108517L, 154079L, 118999L, 184855L, 157646L,
187000L, 126190L, 181693L, 180395L, 170781L, 200521L, 140371L,
185517L, 160662L, 149601L, 164220L, 162613L, 120102L, 189868L,
131791L, 187465L, 205760L, 249684L, 219829L, 201173L, 230138L,
261196L, 258797L, 286470L, 216719L, 219241L, 221386L, 191207L,
212000L, 220639L, 237053L, 172805L, 199395L, 154402L, 152970L,
120174L, 188452L, 122797L, 88608L, 101692L, 114182L, 96193L,
111524L, 93344L, 87006L, 104160L, 88455L, 77399L, 69451L, 73572L,
54280L, 93056L, 71274L, 124714L, 65822L, 54215L, 73492L, 73178L,
104991L, 68259L, 88045L, 84797L, 47925L, 88662L, 88082L, 140498L,
116875L, 145168L, 107149L, 144324L, 119079L, 171258L, 97017L,
86082L, 110873L, 50194L, 114805L, 62368L, 32524L, 39318L, 30558L,
42822L, 45154L, 35025L, 20565L, 58236L, 35809L, 47644L, 30747L,
NA, NA, 35449L, 48808L), RcnstPCUMS = c(229914L, 214547L, 215890L,
158695L, 173125L, 222533L, 212490L, 222125L, 266913L, 94268L,
112967L, 95480L, 87654L, 108996L, 97973L, 139247L, 93817L, 133197L,
40020L, 169749L, 102590L, 112121L, 140241L, 122989L, 144592L,
144979L, 123748L, 123249L, 70081L, 155218L, 168096L, 104743L,
163384L, 142648L, 129188L, 183170L, 99299L, 99873L, 111648L,
55890L, 59183L, 95568L, 72550L, 104562L, 100478L, 92665L, 130625L,
54786L, 105900L, 135833L, 70932L, 73247L, 149632L, 94317L, 87926L,
181989L, 92778L, 107097L, 153246L, 105175L, 126393L, 81976L,
95518L, 109019L, 95370L, 140492L, 125795L, 157978L, 138424L,
138160L, 180320L, 78757L, 135860L, 85921L, 114847L, 151965L,
152561L, 132841L, 204839L, 209567L, 224436L, 210209L, 227143L,
245968L, 264969L, 158648L, 222251L, 194335L, 111618L, 189643L,
137438L, 124953L, 163155L, 107633L, 164525L, 135102L, 152072L,
126636L, 121008L, 137824L, 149673L, 106832L, 134953L, 162195L,
135259L, 151180L, 188069L, 121234L, 199609L, 206011L, 186772L,
185596L, 189869L, 189930L, 209268L, 191993L, 238722L, 281076L,
236211L, 227651L, 277805L, 248063L, 258661L, 261644L, 248401L,
292764L, 313626L, 353877L, 318685L, 385547L, 346224L, 347058L,
353098L, 290663L, 398291L, 305578L, 314469L, 325343L, 281866L,
355524L, 323626L, 393901L, 360773L, 362326L, 415317L, 464535L,
511488L, 540671L, 491824L, 426657L, 500855L, 494717L, 495668L,
455605L, 484598L, 437629L, 476437L, 383114L, 357059L, 449471L,
409024L, 479044L, 360007L, 360455L, 333982L, 342971L, 273450L,
337258L, 308626L, 302838L, 265044L, 221514L, 341869L, 371003L,
450406L, 414775L, 469590L, 360334L, 451528L, 337465L, 283627L,
278748L, 242639L, 202808L, 237041L, 174856L, 206948L, 219398L,
247023L, 253697L, 351625L, 179661L, 255214L, 205368L, 258669L,
270376L, 284729L, 231441L, 240220L, 197141L, 110459L, 124586L,
115785L, 208191L, 139493L, 195068L, 184665L, 99351L, 123562L,
186571L, 117504L, 128846L, 217616L, 128850L, 158105L, 112762L,
118091L, 91510L, 41670L, 65418L, 57038L, 74113L, 63359L, 48717L,
59326L, 79181L, 133076L, 93478L, 121455L, 100396L, 113939L, 224357L,
209899L, 237803L, 196839L, 254633L, 278283L, 302996L, 315330L,
272767L, 277027L, 357066L, 398089L, 400740L, 275789L, 429226L,
326028L, 332848L, 388062L, 434889L, 397012L, 332171L, 338845L,
209076L, 270632L, 261217L, 191663L, 222970L, 237384L, 276674L,
138649L, 203588L, 178863L, 135641L, 217348L, 239162L, 168607L,
196393L, 173731L, 256877L, 250192L, 303120L, 256045L, 278352L,
266185L, 350521L, 282258L, 281162L, 226240L, 312103L, 312547L,
369650L, 420464L, 214503L, 305474L, 232981L, 382171L, 291030L,
370213L, 368859L, 395471L, 331912L, 389084L, 433543L, 446459L,
434882L, 427397L, 482135L, 424532L, 402021L, 413143L, 460258L,
399300L, 513805L, 383895L, 485673L, 426859L, 515510L, 532852L,
640559L, 591249L, 612067L, 577562L, 546291L, 524853L, 515396L,
485261L, 442432L, 520541L, 485585L, 505058L, 424639L, 527199L,
468619L, 427842L, 457937L, 414473L, 368965L, 165326L, 228879L,
261042L, 184066L, 199600L, 213524L, 140264L, 175064L, 152734L,
252011L, 139741L, 124736L, 106170L, 165564L, 127610L, 237950L,
122876L, 151239L, 191794L, 173043L, 187453L, 171653L, 171397L,
275756L, 308794L, 264032L, 285570L, 322867L, 281804L, 311683L,
271705L, 310707L, 286221L, 302599L, 270895L, 258684L, 277845L,
191935L, 236936L, 180781L, 101623L, 112534L, 81747L, 98125L,
102205L, 111226L, 110349L, 89677L, 69492L, 97820L, 69730L, 15018L,
40889L, 97624L, 166204L), TotalToll = c(420742L, 392621L, 395078L,
290411L, 316818L, 407235L, 388856L, 406488L, 482774L, 172510L,
206729L, 174728L, 160406L, 199462L, 179290L, 254822L, 171685L,
243750L, 73236L, 310640L, 187739L, 205181L, 249438L, 225069L,
264603L, 265311L, 226458L, 225545L, 128248L, 284048L, 296023L,
184934L, 298992L, 261045L, 236414L, 335201L, 181717L, 182767L,
204315L, 102278L, 108304L, 174889L, 132766L, 191348L, 183874L,
169576L, 239043L, 100258L, 212859L, 273024L, 142573L, 147226L,
300760L, 189577L, 176731L, 365797L, 186483L, 215264L, 308024L,
211401L, 254049L, 164771L, 191991L, 219128L, 191693L, 282388L,
252847L, 317535L, 278232L, 277701L, 356022L, 158301L, 273078L,
172701L, 230842L, 305449L, 306647L, 267010L, 406202L, 421229L,
451116L, 422520L, 456557L, 494395L, 582202L, 350612L, 491174L,
429480L, 239858L, 419111L, 303737L, 276146L, 360572L, 237868L,
358627L, 298575L, 336079L, 279865L, 267427L, 304591L, 323566L,
236098L, 298246L, 358450L, 298922L, 334107L, 415632L, 267927L,
441136L, 455284L, 412766L, 410167L, 419610L, 419745L, 462482L,
424305L, 527576L, 621178L, 522026L, 503109L, 613949L, 548219L,
571641L, 578233L, 548966L, 647008L, 693113L, 782068L, 704294L,
845344L, 765155L, 766998L, 774306L, 642365L, 880223L, 730331L,
751581L, 770694L, 660018L, 849702L, 773466L, 941423L, 862247L,
865959L, 992608L, 1103240L, 1222456L, 1389524L, 1263988L, 1096508L,
1278566L, 1271423L, 1273867L, 1158103L, 1239499L, 1124707L, 1218525L,
984603L, 909630L, 1155140L, 1043122L, 1231143L, 925218L, 926369L,
850265L, 881435L, 702766L, 866753L, 793169L, 778294L, 681163L,
569291L, 871709L, 953478L, 1150022L, 1065972L, 1206846L, 926058L,
1129778L, 867285L, 728921L, 716382L, 623582L, 521217L, 609195L,
449380L, 531856L, 563853L, 634849L, 643607L, 888831L, 461729L,
655900L, 527796L, 664779L, 687175L, 731754L, 586409L, 617365L,
506652L, 276310L, 320186L, 289618L, 535051L, 389544L, 544553L,
515428L, 277302L, 336755L, 512700L, 318225L, 359684L, 607673L,
379065L, 465104L, 331810L, 347203L, 268918L, 122643L, 192034L,
159071L, 217928L, 186080L, 134668L, 173724L, 232564L, 390599L,
265947L, 348773L, 294627L, 334562L, 649731L, 607805L, 698507L,
578572L, 1059450L, 1187844L, 1246619L, 1296120L, 1140384L, 1187214L,
1432452L, 1606332L, 1728174L, 1203594L, 1822716L, 1389276L, 1728426L,
1926935L, 2125297L, 1943820L, 1623321L, 1590148L, 1049286L, 1398754L,
1320550L, 994945L, 1164583L, 1205841L, 1559682L, 769662L, 1091567L,
1000642L, 718794L, 1175818L, 1254971L, 900558L, 1033592L, 927072L,
1245348L, 1240380L, 1820813L, 1567994L, 1789477L, 1700773L, 2204080L,
1745881L, 1842826L, 1476216L, 1967969L, 1939304L, 2335284L, 2676920L,
1580544L, 2277360L, 1694016L, 2721614L, 2107008L, 2630707L, 2530555L,
2872656L, 2395440L, 2704234L, 3035837L, 3147379L, 3076661L, 2903544L,
3398155L, 2964859L, 2837506L, 2883096L, 3264696L, 2779186L, 3980670L,
2923166L, 3739659L, 3317358L, 3978904L, 4112544L, 4828331L, 4423260L,
4650546L, 4321198L, 4147356L, 3959882L, 3891892L, 3623148L, 3365086L,
3917517L, 3708696L, 3876444L, 3234706L, 3968716L, 3558025L, 3313506L,
3522721L, 3104372L, 2772710L, 1329618L, 1857286L, 2126974L, 1509160L,
1616068L, 1679704L, 1164638L, 1390846L, 1199265L, 1868727L, 1091024L,
1023810L, 837614L, 1367468L, 1056694L, 1886631L, 951129L, 1153342L,
1491752L, 1305802L, 1461332L, 1286770L, 1310026L, 1997167L, 2234964L,
1924902L, 2080596L, 2331026L, 2046594L, 2302530L, 1958478L, 2262478L,
2115387L, 2220923L, 1959669L, 1849238L, 2089172L, 1381704L, 1553856L,
1251361L, 704230L, 776554L, 592426L, 704066L, 772042L, 754649L,
797425L, 624502L, 517122L, 683626L, 507750L, 99592L, 217680L,
671070L, 1150758L)), class = "data.frame", row.names = c(NA,
383L))

	[[alternative HTML version deleted]]


From z@@v@z @ending from gm@il@com  Mon Sep  3 15:21:48 2018
From: z@@v@z @ending from gm@il@com (Pedro Vaz)
Date: Mon, 3 Sep 2018 14:21:48 +0100
Subject: [R] Account for a factor variability in a logistic GLMM in lme4
Message-ID: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>

We did a field study in which we tried to understand which factors
significantly explain the probability of a group of animals (5 species in
total) crossing through 30 wildlife road-crossing structures. The response
variable is binomial (yes=crossed; no = did not cross) and was recorded by
animal species. We did about 30 visits to each crossing structure (our
random factor) in which we recorded the binomial response by each animal
species and the values of a few predictors.

So, I have this (simplified for better understanding) mixed effects model:
library (lme4)

Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|structure.id),
  data = Mydata, family = binomial)

stream is a factor with 2 levels; width.m is continuous; grass.per is a
percentage

This is the model in which I assessed crossings by all species combined
(i.e., cross. 01 = 1 when an animal of any species crossed, cross.01 = 0
when no animal crossed). However, we did one model per species and those
species-specific models highlight that different species exhibit different
relationships between crossings and explanatory variables.

My problem: This means that my model above suffers from an additional
source of variation related to the species level without accounting for it.
However I cannot recalibrate the above model adding the species level as
random factor because, in my binomial response, the zero means no species
crossed (all zeros would have "NA" or, say, "none" for species) and so that
additional source of variation is only present when the response was 1.
Just to confirm this, I did add species as a random factor:

(1 | structure.id) + (1 | species)

As expected, the message is "Error: Response is constant"

How can I account for the species variability in my model in lme4?

A few more details:
A few more details:
- I had 5 mammal species crossing through the 30 road-crossing structures.
In 134 occasions (i.e., 134 of my records on individual
crossing-structures), no animal crossed (so, @Dimitris Rizopoulos, no, I
didn't have the species of the animals which did not cross. A "no cross"
was a "zero" for that visit to the crossing-structure). In 498 occasions,
at least one animal of a given species crossed the structure (these were my
"ones" in my logistic response)
- A side comment: This is to respond to a reviewer in a paper of mine,
i.e., I did and presented species-specific and "all combined species"
models in the draft reviewed but now the reviewer is asking me to control
for the species variability in the "combined species model". He asked me to
include a random factor but I realized that is not possible since all my
zeros would have "none" for the species that crossed. So, is it possible to
control for the species variability in my model in lme4 in another way? I
know in nlme including a fitting of variance structures it's not that
difficult...
- Every time an animal crossed, the binary response was "one" and I
recorded the animal species as well. Thus, I have variability between
species in the "ones" but not in my "zeros" of my logistic model.

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Sep  3 16:46:53 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 3 Sep 2018 07:46:53 -0700
Subject: [R] Account for a factor variability in a logistic GLMM in lme4
In-Reply-To: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>
References: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>
Message-ID: <CAGxFJbTwkYC11NKc+3=ZCkihGerjVa5L9G2Dv+GybnXRNbfeLA@mail.gmail.com>

You should post this on the r-sig-mixed-models list, not here.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 3, 2018 at 7:43 AM Pedro Vaz <zasvaz at gmail.com> wrote:

> We did a field study in which we tried to understand which factors
> significantly explain the probability of a group of animals (5 species in
> total) crossing through 30 wildlife road-crossing structures. The response
> variable is binomial (yes=crossed; no = did not cross) and was recorded by
> animal species. We did about 30 visits to each crossing structure (our
> random factor) in which we recorded the binomial response by each animal
> species and the values of a few predictors.
>
> So, I have this (simplified for better understanding) mixed effects model:
> library (lme4)
>
> Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|
> structure.id),
>   data = Mydata, family = binomial)
>
> stream is a factor with 2 levels; width.m is continuous; grass.per is a
> percentage
>
> This is the model in which I assessed crossings by all species combined
> (i.e., cross. 01 = 1 when an animal of any species crossed, cross.01 = 0
> when no animal crossed). However, we did one model per species and those
> species-specific models highlight that different species exhibit different
> relationships between crossings and explanatory variables.
>
> My problem: This means that my model above suffers from an additional
> source of variation related to the species level without accounting for it.
> However I cannot recalibrate the above model adding the species level as
> random factor because, in my binomial response, the zero means no species
> crossed (all zeros would have "NA" or, say, "none" for species) and so that
> additional source of variation is only present when the response was 1.
> Just to confirm this, I did add species as a random factor:
>
> (1 | structure.id) + (1 | species)
>
> As expected, the message is "Error: Response is constant"
>
> How can I account for the species variability in my model in lme4?
>
> A few more details:
> A few more details:
> - I had 5 mammal species crossing through the 30 road-crossing structures.
> In 134 occasions (i.e., 134 of my records on individual
> crossing-structures), no animal crossed (so, @Dimitris Rizopoulos, no, I
> didn't have the species of the animals which did not cross. A "no cross"
> was a "zero" for that visit to the crossing-structure). In 498 occasions,
> at least one animal of a given species crossed the structure (these were my
> "ones" in my logistic response)
> - A side comment: This is to respond to a reviewer in a paper of mine,
> i.e., I did and presented species-specific and "all combined species"
> models in the draft reviewed but now the reviewer is asking me to control
> for the species variability in the "combined species model". He asked me to
> include a random factor but I realized that is not possible since all my
> zeros would have "none" for the species that crossed. So, is it possible to
> control for the species variability in my model in lme4 in another way? I
> know in nlme including a fitting of variance structures it's not that
> difficult...
> - Every time an animal crossed, the binary response was "one" and I
> recorded the animal species as well. Thus, I have variability between
> species in the "ones" but not in my "zeros" of my logistic model.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Mon Sep  3 16:57:26 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 3 Sep 2018 14:57:26 +0000
Subject: [R] Error when using complete function for imputed data
In-Reply-To: <CAMOcQfN82EGX1SPQY7iet2LsMT25iKXJBFLMvLg80k3cC6t0ug@mail.gmail.com>
References: <CAMOcQfN82EGX1SPQY7iet2LsMT25iKXJBFLMvLg80k3cC6t0ug@mail.gmail.com>
Message-ID: <ed740a07a1ea446d9f503563895d5fa9@SRVEXCHCM1302.precheza.cz>

Hi

AFAIK it was probably answered several days ago that mice conflicts with some other loaded package.

I did not get any error.

After importing your data
str(dataFrame)
'data.frame':   383 obs. of  5 variables:
 $ TransitDate: POSIXct, format: "1985-10-01 06:00:00" "1985-11-01 06:00:00" ...
 $ Transits   : int  14 14 13 10 11 14 14 14 16 6 ...
 $ CargoTons  : int  154973 129636 136884 86348 109907 154506 144083 152794 124861 60330 ...
 $ RcnstPCUMS : int  229914 214547 215890 158695 173125 222533 212490 222125 266913 94268 ...
 $ TotalToll  : int  420742 392621 395078 290411 316818 407235 388856 406488

> colSums(apply(dataFrame,2, is.na))
TransitDate    Transits   CargoTons  RcnstPCUMS   TotalToll
          0           0           2           0           0
> library(mice)
> Imputed_Data <- mice(dataFrame[2:5])
> CompleteData <- complete(Imputed_Data)
> colSums(apply(CompleteData,2, is.na))
  Transits  CargoTons RcnstPCUMS  TotalToll
         0          0          0          0
>

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
> Sent: Monday, September 3, 2018 4:30 PM
> To: r-help at r-project.org
> Subject: [R] Error when using complete function for imputed data
>
> Dear friends,
>
> It seems to me that there is something wrong with the complete function. I
> am using R version 3.5.0 and mice package for data imputation.
>
> I am working on a Windows 8.1 Enterprise machine with 64-bit Operating
> System.
>
> So here is my code:
>
> Imputed_Data <- mice(dataFrame[2:5])
> CompleteData <- complete(Imputed_Data)
> Error in UseMethod("complete_") :
>   no applicable method for 'complete_' applied to an object of class "mids"
>
> I used the complete function before when imputing data with the mice
> function, but now it is not working.
>
> Any help will be greatly appreciated. Below is the dput() of my dataset:
>
> > dput(dataFrame)
> structure(list(TransitDate = structure(c(496990800, 499669200,
> 502261200, 504939600, 507618000, 510037200, 512715600, 515307600,
> 517986000, 520578000, 523256400, 525934800, 528526800, 531205200,
> 533797200, 536475600, 539154000, 541573200, 544251600, 546843600,
> 549522000, 552114000, 554792400, 557470800, 560062800, 562741200,
> 565333200, 568011600, 570690000, 573195600, 575874000, 578466000,
> 581144400, 583736400, 586414800, 589093200, 591685200, 594363600,
> 596955600, 599634000, 602312400, 604731600, 607410000, 610002000,
> 612680400, 615272400, 617950800, 620629200, 623221200, 625899600,
> 628491600, 631170000, 633848400, 636267600, 638946000, 641538000,
> 644216400, 646808400, 649486800, 652165200, 654757200, 657435600,
> 660027600, 662706000, 665384400, 667803600, 670482000, 673074000,
> 675752400, 678344400, 681022800, 683701200, 686293200, 688971600,
> 691563600, 694242000, 696920400, 699426000, 702104400, 704696400,
> 707371200, 709963200, 712641600, 715320000, 717912000, 720590400,
> 723182400, 725860800, 728539200, 730958400, 733636800, 736232400,
> 738910800, 741502800, 744181200, 746859600, 749451600, 752130000,
> 754722000, 757400400, 760078800, 762498000, 765176400, 767768400,
> 770446800, 773038800, 775717200, 778395600, 780987600, 783666000,
> 786258000, 788936400, 791614800, 794034000, 796712400, 799304400,
> 801982800, 804574800, 807253200, 809931600, 812523600, 815202000,
> 817794000, 820472400, 823150800, 825656400, 828334800, 830926800,
> 833605200, 836197200, 838875600, 841554000, 844146000, 846824400,
> 849416400, 852094800, 854773200, 857192400, 859870800, 862462800,
> 865141200, 867733200, 870411600, 873090000, 875682000, 878360400,
> 880952400, 883630800, 886309200, 888728400, 891406800, 893998800,
> 896677200, 899269200, 901947600, 904626000, 907218000, 909896400,
> 912488400, 915166800, 917845200, 920264400, 922942800, 925534800,
> 928213200, 930805200, 933483600, 936162000, 938754000, 941432400,
> 944024400, 946702800, 949381200, 951886800, 954565200, 957157200,
> 959835600, 962427600, 965106000, 967784400, 970376400, 973054800,
> 975646800, 978325200, 981003600, 983422800, 986101200, 988693200,
> 991371600, 993963600, 996642000, 999320400, 1001912400, 1004590800,
> 1007182800, 1009861200, 1012539600, 1014958800, 1017637200,
> 1020229200,
> 1022907600, 1025499600, 1028178000, 1030856400, 1033448400,
> 1036126800,
> 1038718800, 1041397200, 1044075600, 1046494800, 1049173200,
> 1051765200,
> 1054443600, 1057035600, 1059714000, 1062392400, 1064984400,
> 1067662800,
> 1070254800, 1072933200, 1075611600, 1078117200, 1080795600,
> 1083387600,
> 1086066000, 1088658000, 1091336400, 1094014800, 1096606800,
> 1099285200,
> 1101877200, 1104555600, 1107234000, 1109653200, 1112331600,
> 1114923600,
> 1117602000, 1120194000, 1122872400, 1125550800, 1128142800,
> 1130821200,
> 1133413200, 1136091600, 1138770000, 1141189200, 1143867600,
> 1146459600,
> 1149138000, 1151730000, 1154408400, 1157086800, 1159678800,
> 1162357200,
> 1164949200, 1167627600, 1170306000, 1172725200, 1175403600,
> 1177995600,
> 1180674000, 1183266000, 1185944400, 1188622800, 1191214800,
> 1193893200,
> 1196485200, 1199163600, 1201842000, 1204347600, 1207026000,
> 1209618000,
> 1212296400, 1214888400, 1217566800, 1220245200, 1222837200,
> 1225515600,
> 1228107600, 1230786000, 1233464400, 1235883600, 1238562000,
> 1241154000,
> 1243832400, 1246424400, 1249102800, 1251781200, 1254373200,
> 1257051600,
> 1259643600, 1262322000, 1265000400, 1267419600, 1270098000,
> 1272690000,
> 1275368400, 1277960400, 1280638800, 1283317200, 1285909200,
> 1288587600,
> 1291179600, 1293858000, 1296536400, 1298955600, 1301634000,
> 1304226000,
> 1306904400, 1309496400, 1312174800, 1314853200, 1317445200,
> 1320123600,
> 1322715600, 1325394000, 1328072400, 1330578000, 1333256400,
> 1335848400,
> 1338526800, 1341118800, 1343797200, 1346475600, 1349067600,
> 1351746000,
> 1354338000, 1357016400, 1359694800, 1362114000, 1364792400,
> 1367384400,
> 1370062800, 1372654800, 1375333200, 1378011600, 1380603600,
> 1383282000,
> 1385874000, 1388552400, 1391230800, 1393650000, 1396328400,
> 1398920400,
> 1401598800, 1404190800, 1406869200, 1409547600, 1412139600,
> 1414818000,
> 1417410000, 1420088400, 1422766800, 1425186000, 1427864400,
> 1430456400,
> 1433134800, 1435726800, 1438405200, 1441083600, 1443675600,
> 1446354000,
> 1448946000, 1451624400, 1454302800, 1456808400, 1459486800,
> 1462078800,
> 1464757200, 1467349200, 1470027600, 1472706000, 1475298000,
> 1477976400,
> 1480568400, 1483246800, 1485925200, 1488344400, 1491022800,
> 1493614800,
> 1496293200, 1501563600, 1504242000), class = c("POSIXct", "POSIXt"
> ), tzone = ""), Transits = c(14L, 14L, 13L, 10L, 11L, 14L, 14L,
> 14L, 16L, 6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L, 8L,
> 10L, 9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L,
> 7L, 7L, 8L, 4L, 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L, 5L,
> 10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L, 5L, 6L, 7L, 6L, 9L, 8L,
> 10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L, 14L, 15L,
> 14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L, 9L, 12L, 8L,
> 12L, 10L, 11L, 10L, 9L, 10L, 11L, 8L, 10L, 12L, 10L, 11L, 14L,
> 9L, 15L, 15L, 14L, 14L, 14L, 15L, 16L, 15L, 18L, 21L, 18L, 17L,
> 21L, 18L, 19L, 19L, 18L, 21L, 22L, 25L, 23L, 28L, 25L, 25L, 25L,
> 21L, 28L, 21L, 22L, 23L, 20L, 24L, 22L, 26L, 24L, 24L, 28L, 31L,
> 34L, 36L, 33L, 29L, 34L, 33L, 33L, 31L, 33L, 29L, 32L, 26L, 24L,
> 30L, 27L, 31L, 23L, 23L, 21L, 21L, 18L, 21L, 19L, 19L, 16L, 14L,
> 22L, 24L, 28L, 26L, 29L, 23L, 28L, 21L, 17L, 17L, 14L, 12L, 14L,
> 10L, 12L, 13L, 14L, 15L, 21L, 10L, 15L, 12L, 15L, 16L, 17L, 14L,
> 14L, 12L, 7L, 8L, 8L, 11L, 9L, 12L, 11L, 6L, 8L, 11L, 7L, 8L,
> 14L, 9L, 11L, 8L, 8L, 6L, 3L, 4L, 4L, 5L, 4L, 3L, 3L, 5L, 8L,
> 6L, 8L, 6L, 7L, 14L, 14L, 15L, 13L, 16L, 18L, 20L, 21L, 18L,
> 19L, 24L, 27L, 26L, 18L, 28L, 21L, 22L, 25L, 29L, 26L, 22L, 22L,
> 14L, 18L, 18L, 13L, 15L, 16L, 19L, 9L, 14L, 11L, 9L, 14L, 16L,
> 11L, 13L, 11L, 16L, 16L, 20L, 17L, 19L, 18L, 24L, 19L, 19L, 15L,
> 21L, 21L, 24L, 28L, 14L, 20L, 15L, 24L, 18L, 24L, 24L, 25L, 21L,
> 24L, 27L, 28L, 27L, 26L, 29L, 25L, 24L, 25L, 28L, 23L, 30L, 23L,
> 29L, 26L, 31L, 33L, 40L, 36L, 39L, 36L, 34L, 32L, 32L, 30L, 27L,
> 32L, 30L, 31L, 26L, 31L, 29L, 26L, 28L, 24L, 22L, 11L, 15L, 17L,
> 12L, 13L, 14L, 9L, 12L, 11L, 17L, 9L, 8L, 7L, 11L, 8L, 15L, 8L,
> 10L, 13L, 12L, 13L, 12L, 12L, 19L, 21L, 18L, 20L, 21L, 20L, 22L,
> 19L, 21L, 20L, 21L, 18L, 18L, 19L, 13L, 16L, 12L, 6L, 7L, 5L,
> 6L, 6L, 7L, 7L, 5L, 4L, 6L, 4L, 1L, 2L, 7L, 12L), CargoTons = c(154973L,
> 129636L, 136884L, 86348L, 109907L, 154506L, 144083L, 152794L,
> 124861L, 60330L, 65221L, 61718L, 53997L, 83536L, 63218L, 98222L,
> 54719L, 98470L, 18263L, 104255L, 62869L, 62523L, 75344L, 81476L,
> 92818L, 87457L, 85231L, 77897L, 57699L, 96989L, 109361L, 59799L,
> 91116L, 82241L, 74251L, 124361L, 68751L, 61719L, 68017L, 37760L,
> 32513L, 56359L, 51333L, 80859L, 75852L, 65760L, 96043L, 38820L,
> 63202L, 102647L, 49104L, 53482L, 121305L, 71795L, 76704L, 146097L,
> 73047L, 68557L, 110642L, 77616L, 97767L, 52059L, 58658L, 66350L,
> 69303L, 76013L, 91909L, 108445L, 94454L, 101249L, 112131L, 56290L,
> 118342L, 70618L, 64783L, 112839L, 120506L, 94243L, 130768L, 133643L,
> 146321L, 140736L, 147234L, 158953L, 189888L, 93819L, 130021L,
> 130124L, 55088L, 114783L, 95184L, 82205L, 80321L, 65422L, 98933L,
> 93713L, 98417L, 97210L, 88464L, 94659L, 92873L, 79784L, 96655L,
> 122266L, 100779L, 120569L, 133029L, 92889L, 160886L, 132364L,
> 130435L, 139653L, 152143L, 160824L, 165842L, 175679L, 210872L,
> 211941L, 207820L, 179857L, 212733L, 203135L, 218368L, 198343L,
> 195677L, 210066L, 243311L, 261965L, 240683L, 245242L, 218004L,
> 247640L, 209872L, 223668L, 290521L, 185161L, 210341L, 261739L,
> 205431L, 284114L, 251466L, 302961L, 292981L, 279329L, 309197L,
> 341092L, 385209L, 366958L, 330515L, 286950L, 295590L, 350901L,
> 341678L, 284666L, 283148L, 279108L, 284896L, 238802L, 198786L,
> 273465L, 256694L, 360520L, 320201L, 296881L, 264202L, 280142L,
> 219105L, 278606L, 254420L, 260339L, 216457L, 198077L, 249436L,
> 302860L, 360184L, 317105L, 391413L, 265210L, 354714L, 306031L,
> 266124L, 215799L, 232630L, 156590L, 203111L, 157075L, 160140L,
> 177874L, 219162L, 159610L, 286483L, 144631L, 216456L, 157305L,
> 237780L, 191617L, 223211L, 180330L, 187074L, 126043L, 62462L,
> 93633L, 56417L, 115036L, 74365L, 98785L, 116172L, 43421L, 73769L,
> 128795L, 58910L, 74282L, 115312L, 102303L, 106109L, 76940L, 82683L,
> 49149L, 22517L, 20731L, 24684L, 52558L, 40057L, 28981L, 46062L,
> 43213L, 107755L, 53404L, 56390L, 41541L, 41183L, 80161L, 110960L,
> 130891L, 130395L, 183351L, 242803L, 225383L, 190962L, 169432L,
> 186260L, 206997L, 196097L, 202942L, 175063L, 240869L, 213226L,
> 237754L, 208280L, 231596L, 207033L, 213294L, 250265L, 129334L,
> 173986L, 145188L, 98384L, 163739L, 138180L, 136521L, 86836L,
> 97452L, 71988L, 79293L, 124134L, 116343L, 91030L, 98457L, 77906L,
> 130599L, 132381L, 162992L, 142756L, 150105L, 150339L, 161097L,
> 112633L, 145691L, 100771L, 147805L, 123418L, 138375L, 185776L,
> 108842L, 145245L, 108517L, 154079L, 118999L, 184855L, 157646L,
> 187000L, 126190L, 181693L, 180395L, 170781L, 200521L, 140371L,
> 185517L, 160662L, 149601L, 164220L, 162613L, 120102L, 189868L,
> 131791L, 187465L, 205760L, 249684L, 219829L, 201173L, 230138L,
> 261196L, 258797L, 286470L, 216719L, 219241L, 221386L, 191207L,
> 212000L, 220639L, 237053L, 172805L, 199395L, 154402L, 152970L,
> 120174L, 188452L, 122797L, 88608L, 101692L, 114182L, 96193L,
> 111524L, 93344L, 87006L, 104160L, 88455L, 77399L, 69451L, 73572L,
> 54280L, 93056L, 71274L, 124714L, 65822L, 54215L, 73492L, 73178L,
> 104991L, 68259L, 88045L, 84797L, 47925L, 88662L, 88082L, 140498L,
> 116875L, 145168L, 107149L, 144324L, 119079L, 171258L, 97017L,
> 86082L, 110873L, 50194L, 114805L, 62368L, 32524L, 39318L, 30558L,
> 42822L, 45154L, 35025L, 20565L, 58236L, 35809L, 47644L, 30747L,
> NA, NA, 35449L, 48808L), RcnstPCUMS = c(229914L, 214547L, 215890L,
> 158695L, 173125L, 222533L, 212490L, 222125L, 266913L, 94268L,
> 112967L, 95480L, 87654L, 108996L, 97973L, 139247L, 93817L, 133197L,
> 40020L, 169749L, 102590L, 112121L, 140241L, 122989L, 144592L,
> 144979L, 123748L, 123249L, 70081L, 155218L, 168096L, 104743L,
> 163384L, 142648L, 129188L, 183170L, 99299L, 99873L, 111648L,
> 55890L, 59183L, 95568L, 72550L, 104562L, 100478L, 92665L, 130625L,
> 54786L, 105900L, 135833L, 70932L, 73247L, 149632L, 94317L, 87926L,
> 181989L, 92778L, 107097L, 153246L, 105175L, 126393L, 81976L,
> 95518L, 109019L, 95370L, 140492L, 125795L, 157978L, 138424L,
> 138160L, 180320L, 78757L, 135860L, 85921L, 114847L, 151965L,
> 152561L, 132841L, 204839L, 209567L, 224436L, 210209L, 227143L,
> 245968L, 264969L, 158648L, 222251L, 194335L, 111618L, 189643L,
> 137438L, 124953L, 163155L, 107633L, 164525L, 135102L, 152072L,
> 126636L, 121008L, 137824L, 149673L, 106832L, 134953L, 162195L,
> 135259L, 151180L, 188069L, 121234L, 199609L, 206011L, 186772L,
> 185596L, 189869L, 189930L, 209268L, 191993L, 238722L, 281076L,
> 236211L, 227651L, 277805L, 248063L, 258661L, 261644L, 248401L,
> 292764L, 313626L, 353877L, 318685L, 385547L, 346224L, 347058L,
> 353098L, 290663L, 398291L, 305578L, 314469L, 325343L, 281866L,
> 355524L, 323626L, 393901L, 360773L, 362326L, 415317L, 464535L,
> 511488L, 540671L, 491824L, 426657L, 500855L, 494717L, 495668L,
> 455605L, 484598L, 437629L, 476437L, 383114L, 357059L, 449471L,
> 409024L, 479044L, 360007L, 360455L, 333982L, 342971L, 273450L,
> 337258L, 308626L, 302838L, 265044L, 221514L, 341869L, 371003L,
> 450406L, 414775L, 469590L, 360334L, 451528L, 337465L, 283627L,
> 278748L, 242639L, 202808L, 237041L, 174856L, 206948L, 219398L,
> 247023L, 253697L, 351625L, 179661L, 255214L, 205368L, 258669L,
> 270376L, 284729L, 231441L, 240220L, 197141L, 110459L, 124586L,
> 115785L, 208191L, 139493L, 195068L, 184665L, 99351L, 123562L,
> 186571L, 117504L, 128846L, 217616L, 128850L, 158105L, 112762L,
> 118091L, 91510L, 41670L, 65418L, 57038L, 74113L, 63359L, 48717L,
> 59326L, 79181L, 133076L, 93478L, 121455L, 100396L, 113939L, 224357L,
> 209899L, 237803L, 196839L, 254633L, 278283L, 302996L, 315330L,
> 272767L, 277027L, 357066L, 398089L, 400740L, 275789L, 429226L,
> 326028L, 332848L, 388062L, 434889L, 397012L, 332171L, 338845L,
> 209076L, 270632L, 261217L, 191663L, 222970L, 237384L, 276674L,
> 138649L, 203588L, 178863L, 135641L, 217348L, 239162L, 168607L,
> 196393L, 173731L, 256877L, 250192L, 303120L, 256045L, 278352L,
> 266185L, 350521L, 282258L, 281162L, 226240L, 312103L, 312547L,
> 369650L, 420464L, 214503L, 305474L, 232981L, 382171L, 291030L,
> 370213L, 368859L, 395471L, 331912L, 389084L, 433543L, 446459L,
> 434882L, 427397L, 482135L, 424532L, 402021L, 413143L, 460258L,
> 399300L, 513805L, 383895L, 485673L, 426859L, 515510L, 532852L,
> 640559L, 591249L, 612067L, 577562L, 546291L, 524853L, 515396L,
> 485261L, 442432L, 520541L, 485585L, 505058L, 424639L, 527199L,
> 468619L, 427842L, 457937L, 414473L, 368965L, 165326L, 228879L,
> 261042L, 184066L, 199600L, 213524L, 140264L, 175064L, 152734L,
> 252011L, 139741L, 124736L, 106170L, 165564L, 127610L, 237950L,
> 122876L, 151239L, 191794L, 173043L, 187453L, 171653L, 171397L,
> 275756L, 308794L, 264032L, 285570L, 322867L, 281804L, 311683L,
> 271705L, 310707L, 286221L, 302599L, 270895L, 258684L, 277845L,
> 191935L, 236936L, 180781L, 101623L, 112534L, 81747L, 98125L,
> 102205L, 111226L, 110349L, 89677L, 69492L, 97820L, 69730L, 15018L,
> 40889L, 97624L, 166204L), TotalToll = c(420742L, 392621L, 395078L,
> 290411L, 316818L, 407235L, 388856L, 406488L, 482774L, 172510L,
> 206729L, 174728L, 160406L, 199462L, 179290L, 254822L, 171685L,
> 243750L, 73236L, 310640L, 187739L, 205181L, 249438L, 225069L,
> 264603L, 265311L, 226458L, 225545L, 128248L, 284048L, 296023L,
> 184934L, 298992L, 261045L, 236414L, 335201L, 181717L, 182767L,
> 204315L, 102278L, 108304L, 174889L, 132766L, 191348L, 183874L,
> 169576L, 239043L, 100258L, 212859L, 273024L, 142573L, 147226L,
> 300760L, 189577L, 176731L, 365797L, 186483L, 215264L, 308024L,
> 211401L, 254049L, 164771L, 191991L, 219128L, 191693L, 282388L,
> 252847L, 317535L, 278232L, 277701L, 356022L, 158301L, 273078L,
> 172701L, 230842L, 305449L, 306647L, 267010L, 406202L, 421229L,
> 451116L, 422520L, 456557L, 494395L, 582202L, 350612L, 491174L,
> 429480L, 239858L, 419111L, 303737L, 276146L, 360572L, 237868L,
> 358627L, 298575L, 336079L, 279865L, 267427L, 304591L, 323566L,
> 236098L, 298246L, 358450L, 298922L, 334107L, 415632L, 267927L,
> 441136L, 455284L, 412766L, 410167L, 419610L, 419745L, 462482L,
> 424305L, 527576L, 621178L, 522026L, 503109L, 613949L, 548219L,
> 571641L, 578233L, 548966L, 647008L, 693113L, 782068L, 704294L,
> 845344L, 765155L, 766998L, 774306L, 642365L, 880223L, 730331L,
> 751581L, 770694L, 660018L, 849702L, 773466L, 941423L, 862247L,
> 865959L, 992608L, 1103240L, 1222456L, 1389524L, 1263988L, 1096508L,
> 1278566L, 1271423L, 1273867L, 1158103L, 1239499L, 1124707L, 1218525L,
> 984603L, 909630L, 1155140L, 1043122L, 1231143L, 925218L, 926369L,
> 850265L, 881435L, 702766L, 866753L, 793169L, 778294L, 681163L,
> 569291L, 871709L, 953478L, 1150022L, 1065972L, 1206846L, 926058L,
> 1129778L, 867285L, 728921L, 716382L, 623582L, 521217L, 609195L,
> 449380L, 531856L, 563853L, 634849L, 643607L, 888831L, 461729L,
> 655900L, 527796L, 664779L, 687175L, 731754L, 586409L, 617365L,
> 506652L, 276310L, 320186L, 289618L, 535051L, 389544L, 544553L,
> 515428L, 277302L, 336755L, 512700L, 318225L, 359684L, 607673L,
> 379065L, 465104L, 331810L, 347203L, 268918L, 122643L, 192034L,
> 159071L, 217928L, 186080L, 134668L, 173724L, 232564L, 390599L,
> 265947L, 348773L, 294627L, 334562L, 649731L, 607805L, 698507L,
> 578572L, 1059450L, 1187844L, 1246619L, 1296120L, 1140384L, 1187214L,
> 1432452L, 1606332L, 1728174L, 1203594L, 1822716L, 1389276L, 1728426L,
> 1926935L, 2125297L, 1943820L, 1623321L, 1590148L, 1049286L, 1398754L,
> 1320550L, 994945L, 1164583L, 1205841L, 1559682L, 769662L, 1091567L,
> 1000642L, 718794L, 1175818L, 1254971L, 900558L, 1033592L, 927072L,
> 1245348L, 1240380L, 1820813L, 1567994L, 1789477L, 1700773L, 2204080L,
> 1745881L, 1842826L, 1476216L, 1967969L, 1939304L, 2335284L, 2676920L,
> 1580544L, 2277360L, 1694016L, 2721614L, 2107008L, 2630707L, 2530555L,
> 2872656L, 2395440L, 2704234L, 3035837L, 3147379L, 3076661L, 2903544L,
> 3398155L, 2964859L, 2837506L, 2883096L, 3264696L, 2779186L, 3980670L,
> 2923166L, 3739659L, 3317358L, 3978904L, 4112544L, 4828331L, 4423260L,
> 4650546L, 4321198L, 4147356L, 3959882L, 3891892L, 3623148L, 3365086L,
> 3917517L, 3708696L, 3876444L, 3234706L, 3968716L, 3558025L, 3313506L,
> 3522721L, 3104372L, 2772710L, 1329618L, 1857286L, 2126974L, 1509160L,
> 1616068L, 1679704L, 1164638L, 1390846L, 1199265L, 1868727L, 1091024L,
> 1023810L, 837614L, 1367468L, 1056694L, 1886631L, 951129L, 1153342L,
> 1491752L, 1305802L, 1461332L, 1286770L, 1310026L, 1997167L, 2234964L,
> 1924902L, 2080596L, 2331026L, 2046594L, 2302530L, 1958478L, 2262478L,
> 2115387L, 2220923L, 1959669L, 1849238L, 2089172L, 1381704L, 1553856L,
> 1251361L, 704230L, 776554L, 592426L, 704066L, 772042L, 754649L,
> 797425L, 624502L, 517122L, 683626L, 507750L, 99592L, 217680L,
> 671070L, 1150758L)), class = "data.frame", row.names = c(NA,
> 383L))
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From jtelleri@@rproject @ending from gm@il@com  Mon Sep  3 17:17:54 2018
From: jtelleri@@rproject @ending from gm@il@com (Juan Telleria Ruiz de Aguirre)
Date: Mon, 3 Sep 2018 17:17:54 +0200
Subject: [R] ANOVA Permutation Test
Message-ID: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>

Dear R users,

I have the following Question related to Package lmPerm:

This package uses a modified version of aov() function, which uses
Permutation Tests instead of Normal Theory Tests for fitting an Analysis of
Variance (ANOVA) Model.

However, when I run the following code for a simple linear model:

library(lmPerm)

e$t_Downtime_per_Intervention_Successful %>%
  aovp(
    formula = `Downtime per Intervention[h]` ~ `Working Hours`,
    data = .
  ) %>%
  summary()

I obtain different p-values for each run!

With a regular ANOVA Test, I obtain instead a constant F-statistic, but I
do not fulfill the required Normality Assumptions.

So my questions are:

Would it still be possible use the regular aov() by generating permutations
in advance (Obtaining therefore a Normal Distribution thanks to the Central
Limit Theorem)? And applying the aov() function afterwards? Does it have
sense?


Or maybe this issue could be due to unbalanced classes? I also tried to
weight observations based on proportions, but the function failed.


Any alternative solution for performing a One-Way ANOVA Test over
Non-Normal Data?


Thank you.

Juan

	[[alternative HTML version deleted]]


From li@t@ @ending from dewey@myzen@co@uk  Mon Sep  3 17:58:46 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 3 Sep 2018 16:58:46 +0100
Subject: [R] ANOVA Permutation Test
In-Reply-To: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
References: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
Message-ID: <6d0b7771-a0fa-6b21-e248-0e28d59356a5@dewey.myzen.co.uk>

Dear Juan

I do not use the package but if it does permutation tests it presumably 
uses random numbers and since you are not setting the seed you would get 
different values for each run.

Michael

On 03/09/2018 16:17, Juan Telleria Ruiz de Aguirre wrote:
> Dear R users,
> 
> I have the following Question related to Package lmPerm:
> 
> This package uses a modified version of aov() function, which uses
> Permutation Tests instead of Normal Theory Tests for fitting an Analysis of
> Variance (ANOVA) Model.
> 
> However, when I run the following code for a simple linear model:
> 
> library(lmPerm)
> 
> e$t_Downtime_per_Intervention_Successful %>%
>    aovp(
>      formula = `Downtime per Intervention[h]` ~ `Working Hours`,
>      data = .
>    ) %>%
>    summary()
> 
> I obtain different p-values for each run!
> 
> With a regular ANOVA Test, I obtain instead a constant F-statistic, but I
> do not fulfill the required Normality Assumptions.
> 
> So my questions are:
> 
> Would it still be possible use the regular aov() by generating permutations
> in advance (Obtaining therefore a Normal Distribution thanks to the Central
> Limit Theorem)? And applying the aov() function afterwards? Does it have
> sense?
> 
> 
> Or maybe this issue could be due to unbalanced classes? I also tried to
> weight observations based on proportions, but the function failed.
> 
> 
> Any alternative solution for performing a One-Way ANOVA Test over
> Non-Normal Data?
> 
> 
> Thank you.
> 
> Juan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From meyner@@m @ending from pg@com  Mon Sep  3 18:06:51 2018
From: meyner@@m @ending from pg@com (Meyners, Michael)
Date: Mon, 3 Sep 2018 16:06:51 +0000
Subject: [R] ANOVA Permutation Test
In-Reply-To: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
References: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
Message-ID: <BL0PR01MB4132BBC31D231756636D7B539A0C0@BL0PR01MB4132.prod.exchangelabs.com>

Juan, 

Your question might be borderline for this list, as it ultimately rather seems a stats question coming in R disguise.

Anyway, the short answer is that you *expect* to get a different p value from a permutation test unless you are able to do all possible permutation and therefore use the so-called systematic reference set. That is rarely the case, and only for relatively small problems. 
The permutation test uses a random subset of all possible permutations. Given this randomness, you'll get a different p value. In order to get reproducible results, you may specify a seed (?set.seed), yet that is only reproducible with this environment. Someone else with a different software and/or code might come out with a different p. The higher the number of permutations used, the smaller the variation around the p values, however. For most applications, 1000 seem good enough to me, but sometimes I go higher (in particular if the p value is borderline and I really need a strict above/below alpha decision).

The permutations do not create an implicit normal distribution, but rather a null distribution that can (likely is depending on non-normality of your data) not normal. So your respective proposal does not appeal.

I don't think you need an alternative - the permutation test is just fine, and recognizing the randomness in the execution does not render the (relatively small) variability in p values a major issue.

You may want to have a look at the text book by Edgington & Onghena for details on permutation tests, and there are plenty of papers out there addressing them in various contexts, which will help to understand *why* you observe what you observe here. 

HTH, Michael



> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Juan Telleria Ruiz
> de Aguirre
> Sent: Montag, 3. September 2018 17:18
> To: R help Mailing list <r-help at r-project.org>
> Subject: [R] ANOVA Permutation Test
> 
> Dear R users,
> 
> I have the following Question related to Package lmPerm:
> 
> This package uses a modified version of aov() function, which uses
> Permutation Tests instead of Normal Theory Tests for fitting an Analysis of
> Variance (ANOVA) Model.
> 
> However, when I run the following code for a simple linear model:
> 
> library(lmPerm)
> 
> e$t_Downtime_per_Intervention_Successful %>%
>   aovp(
>     formula = `Downtime per Intervention[h]` ~ `Working Hours`,
>     data = .
>   ) %>%
>   summary()
> 
> I obtain different p-values for each run!
> 
> With a regular ANOVA Test, I obtain instead a constant F-statistic, but I do not
> fulfill the required Normality Assumptions.
> 
> So my questions are:
> 
> Would it still be possible use the regular aov() by generating permutations in
> advance (Obtaining therefore a Normal Distribution thanks to the Central
> Limit Theorem)? And applying the aov() function afterwards? Does it have
> sense?
> 
> 
> Or maybe this issue could be due to unbalanced classes? I also tried to weight
> observations based on proportions, but the function failed.
> 
> 
> Any alternative solution for performing a One-Way ANOVA Test over Non-
> Normal Data?
> 
> 
> Thank you.
> 
> Juan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S@Elli@on @ending from LGCGroup@com  Mon Sep  3 18:20:14 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Mon, 3 Sep 2018 16:20:14 +0000
Subject: [R] ANOVA Permutation Test
In-Reply-To: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
References: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
Message-ID: <9e13f11c85144361984a29db539e83b8@GBDCVPEXC04.corp.lgc-group.com>

> This package uses a modified version of aov() function, which uses
> Permutation Tests 
> 
> I obtain different p-values for each run!

Could that be because you are defaulting to perm="Prob"?

I am not familiar with the package, but the manual is informative.
You may have missed something when reading it.

" ...The Exact method will be used by default when the number of observations is less than or equal to
maxExact, otherwise Prob will be used.
Prob:  Iterations terminate when the estimated standard error of the estimated proportion p is less
than p*Ca"

I would assume that probabilistic permutation is random and will change from run to run.
You could use set.seed() to stop that, but it's actually quite useful to see how much the results change.
If you want complete permutation, you'd need to force Exact (unless that does not mean what it sounds like for this package).
It looks like that requires you to set maxExact to at least your number of observations. But given that permutation  grows combinatorially,  that could take a _long_ time for a run; the Example in the help page does not complete in a useful time when maxExact is set to exceed the number of data points.

So I'd probably run it using Prob and simply note the range of results for a handful of runs to give you an indication of how far to trust the answers.

> Would it still be possible use the regular aov() by generating permutations
> in advance (Obtaining therefore a Normal Distribution thanks to the Central
> Limit Theorem)? And applying the aov() function afterwards? Does it have
> sense?
As a chemist, I'd guess No. And you'd be even more limited in number of permutations.

> Or maybe this issue could be due to unbalanced classes? I also tried to
> weight observations based on proportions, but the function failed.
No, it's nothing to do with balance, if the results change run to run with no change in the model. I'd guess that may exacerbate the permutaiton variability somewhat but it won't _cause_ it.

> Any alternative solution for performing a One-Way ANOVA Test over
> Non-Normal Data?
Yes; the traditional nonparametric test for one-way data (balanced) is the kruskal-wallis test - see ?kruskal.test.
Classical ANOVA on ranks can also be defended as a general 'nonparametric' approach, though I gather it can also be criticised. 



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Sep  3 19:45:07 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Mon, 3 Sep 2018 10:45:07 -0700 (PDT)
Subject: [R] Display time of PDF plots
Message-ID: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>

   This may be an inappropriate forum for this question. If so, please point
me in a better direction.

   A current project includes scatter plots with thousands of points. Saved
as PDF files they display slowly using a pdf viewer or when included in the
PDF output of a LaTeX document.

   Is there a process by which these plots can be 'thinned' so they show the
same overall patterns but with fewer points so they display more quickly?

   Rasterizing them to .jpg files using 'convert' allows them to load
immediately, but the bit-mapped resolution is, of course, much lower than
the vector PDF format.

Rich


From jtelleri@@rproject @ending from gm@il@com  Mon Sep  3 19:47:07 2018
From: jtelleri@@rproject @ending from gm@il@com (Juan Telleria Ruiz de Aguirre)
Date: Mon, 3 Sep 2018 19:47:07 +0200
Subject: [R] ANOVA Permutation Test
In-Reply-To: <9e13f11c85144361984a29db539e83b8@GBDCVPEXC04.corp.lgc-group.com>
References: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
 <9e13f11c85144361984a29db539e83b8@GBDCVPEXC04.corp.lgc-group.com>
Message-ID: <CAJXDcw3ZzMnCP1V4dt6qzz+8tYk9-Bz=hmWWmuhV8G9FEF7zAg@mail.gmail.com>

Thank you all for your **very good** answers:

Using aovp(..., perm="Exact") seems to be the way to go for small datasets,
and also I should definitely try ?kruskal.test.


Juan

	[[alternative HTML version deleted]]


From p@ulbern@l07 @ending from gm@il@com  Mon Sep  3 20:18:21 2018
From: p@ulbern@l07 @ending from gm@il@com (Paul Bernal)
Date: Mon, 3 Sep 2018 13:18:21 -0500
Subject: [R] Error when using complete function for imputed data
In-Reply-To: <ed740a07a1ea446d9f503563895d5fa9@SRVEXCHCM1302.precheza.cz>
References: <CAMOcQfN82EGX1SPQY7iet2LsMT25iKXJBFLMvLg80k3cC6t0ug@mail.gmail.com>
 <ed740a07a1ea446d9f503563895d5fa9@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMOcQfNsFCduSQwwRDk+yzgr_f+8zt9ZdjEvhRdU5Z9hhBG+Tw@mail.gmail.com>

Thank you for the feedback Petr, I was able to run the code without any
problems.

Best regads,

Paul

El lun., 3 sept. 2018 a las 9:57, PIKAL Petr (<petr.pikal at precheza.cz>)
escribi?:

> Hi
>
> AFAIK it was probably answered several days ago that mice conflicts with
> some other loaded package.
>
> I did not get any error.
>
> After importing your data
> str(dataFrame)
> 'data.frame':   383 obs. of  5 variables:
>  $ TransitDate: POSIXct, format: "1985-10-01 06:00:00" "1985-11-01
> 06:00:00" ...
>  $ Transits   : int  14 14 13 10 11 14 14 14 16 6 ...
>  $ CargoTons  : int  154973 129636 136884 86348 109907 154506 144083
> 152794 124861 60330 ...
>  $ RcnstPCUMS : int  229914 214547 215890 158695 173125 222533 212490
> 222125 266913 94268 ...
>  $ TotalToll  : int  420742 392621 395078 290411 316818 407235 388856
> 406488
>
> > colSums(apply(dataFrame,2, is.na))
> TransitDate    Transits   CargoTons  RcnstPCUMS   TotalToll
>           0           0           2           0           0
> > library(mice)
> > Imputed_Data <- mice(dataFrame[2:5])
> > CompleteData <- complete(Imputed_Data)
> > colSums(apply(CompleteData,2, is.na))
>   Transits  CargoTons RcnstPCUMS  TotalToll
>          0          0          0          0
> >
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
> > Sent: Monday, September 3, 2018 4:30 PM
> > To: r-help at r-project.org
> > Subject: [R] Error when using complete function for imputed data
> >
> > Dear friends,
> >
> > It seems to me that there is something wrong with the complete function.
> I
> > am using R version 3.5.0 and mice package for data imputation.
> >
> > I am working on a Windows 8.1 Enterprise machine with 64-bit Operating
> > System.
> >
> > So here is my code:
> >
> > Imputed_Data <- mice(dataFrame[2:5])
> > CompleteData <- complete(Imputed_Data)
> > Error in UseMethod("complete_") :
> >   no applicable method for 'complete_' applied to an object of class
> "mids"
> >
> > I used the complete function before when imputing data with the mice
> > function, but now it is not working.
> >
> > Any help will be greatly appreciated. Below is the dput() of my dataset:
> >
> > > dput(dataFrame)
> > structure(list(TransitDate = structure(c(496990800, 499669200,
> > 502261200, 504939600, 507618000, 510037200, 512715600, 515307600,
> > 517986000, 520578000, 523256400, 525934800, 528526800, 531205200,
> > 533797200, 536475600, 539154000, 541573200, 544251600, 546843600,
> > 549522000, 552114000, 554792400, 557470800, 560062800, 562741200,
> > 565333200, 568011600, 570690000, 573195600, 575874000, 578466000,
> > 581144400, 583736400, 586414800, 589093200, 591685200, 594363600,
> > 596955600, 599634000, 602312400, 604731600, 607410000, 610002000,
> > 612680400, 615272400, 617950800, 620629200, 623221200, 625899600,
> > 628491600, 631170000, 633848400, 636267600, 638946000, 641538000,
> > 644216400, 646808400, 649486800, 652165200, 654757200, 657435600,
> > 660027600, 662706000, 665384400, 667803600, 670482000, 673074000,
> > 675752400, 678344400, 681022800, 683701200, 686293200, 688971600,
> > 691563600, 694242000, 696920400, 699426000, 702104400, 704696400,
> > 707371200, 709963200, 712641600, 715320000, 717912000, 720590400,
> > 723182400, 725860800, 728539200, 730958400, 733636800, 736232400,
> > 738910800, 741502800, 744181200, 746859600, 749451600, 752130000,
> > 754722000, 757400400, 760078800, 762498000, 765176400, 767768400,
> > 770446800, 773038800, 775717200, 778395600, 780987600, 783666000,
> > 786258000, 788936400, 791614800, 794034000, 796712400, 799304400,
> > 801982800, 804574800, 807253200, 809931600, 812523600, 815202000,
> > 817794000, 820472400, 823150800, 825656400, 828334800, 830926800,
> > 833605200, 836197200, 838875600, 841554000, 844146000, 846824400,
> > 849416400, 852094800, 854773200, 857192400, 859870800, 862462800,
> > 865141200, 867733200, 870411600, 873090000, 875682000, 878360400,
> > 880952400, 883630800, 886309200, 888728400, 891406800, 893998800,
> > 896677200, 899269200, 901947600, 904626000, 907218000, 909896400,
> > 912488400, 915166800, 917845200, 920264400, 922942800, 925534800,
> > 928213200, 930805200, 933483600, 936162000, 938754000, 941432400,
> > 944024400, 946702800, 949381200, 951886800, 954565200, 957157200,
> > 959835600, 962427600, 965106000, 967784400, 970376400, 973054800,
> > 975646800, 978325200, 981003600, 983422800, 986101200, 988693200,
> > 991371600, 993963600, 996642000, 999320400, 1001912400, 1004590800,
> > 1007182800, 1009861200, 1012539600, 1014958800, 1017637200,
> > 1020229200,
> > 1022907600, 1025499600, 1028178000, 1030856400, 1033448400,
> > 1036126800,
> > 1038718800, 1041397200, 1044075600, 1046494800, 1049173200,
> > 1051765200,
> > 1054443600, 1057035600, 1059714000, 1062392400, 1064984400,
> > 1067662800,
> > 1070254800, 1072933200, 1075611600, 1078117200, 1080795600,
> > 1083387600,
> > 1086066000, 1088658000, 1091336400, 1094014800, 1096606800,
> > 1099285200,
> > 1101877200, 1104555600, 1107234000, 1109653200, 1112331600,
> > 1114923600,
> > 1117602000, 1120194000, 1122872400, 1125550800, 1128142800,
> > 1130821200,
> > 1133413200, 1136091600, 1138770000, 1141189200, 1143867600,
> > 1146459600,
> > 1149138000, 1151730000, 1154408400, 1157086800, 1159678800,
> > 1162357200,
> > 1164949200, 1167627600, 1170306000, 1172725200, 1175403600,
> > 1177995600,
> > 1180674000, 1183266000, 1185944400, 1188622800, 1191214800,
> > 1193893200,
> > 1196485200, 1199163600, 1201842000, 1204347600, 1207026000,
> > 1209618000,
> > 1212296400, 1214888400, 1217566800, 1220245200, 1222837200,
> > 1225515600,
> > 1228107600, 1230786000, 1233464400, 1235883600, 1238562000,
> > 1241154000,
> > 1243832400, 1246424400, 1249102800, 1251781200, 1254373200,
> > 1257051600,
> > 1259643600, 1262322000, 1265000400, 1267419600, 1270098000,
> > 1272690000,
> > 1275368400, 1277960400, 1280638800, 1283317200, 1285909200,
> > 1288587600,
> > 1291179600, 1293858000, 1296536400, 1298955600, 1301634000,
> > 1304226000,
> > 1306904400, 1309496400, 1312174800, 1314853200, 1317445200,
> > 1320123600,
> > 1322715600, 1325394000, 1328072400, 1330578000, 1333256400,
> > 1335848400,
> > 1338526800, 1341118800, 1343797200, 1346475600, 1349067600,
> > 1351746000,
> > 1354338000, 1357016400, 1359694800, 1362114000, 1364792400,
> > 1367384400,
> > 1370062800, 1372654800, 1375333200, 1378011600, 1380603600,
> > 1383282000,
> > 1385874000, 1388552400, 1391230800, 1393650000, 1396328400,
> > 1398920400,
> > 1401598800, 1404190800, 1406869200, 1409547600, 1412139600,
> > 1414818000,
> > 1417410000, 1420088400, 1422766800, 1425186000, 1427864400,
> > 1430456400,
> > 1433134800, 1435726800, 1438405200, 1441083600, 1443675600,
> > 1446354000,
> > 1448946000, 1451624400, 1454302800, 1456808400, 1459486800,
> > 1462078800,
> > 1464757200, 1467349200, 1470027600, 1472706000, 1475298000,
> > 1477976400,
> > 1480568400, 1483246800, 1485925200, 1488344400, 1491022800,
> > 1493614800,
> > 1496293200, 1501563600, 1504242000), class = c("POSIXct", "POSIXt"
> > ), tzone = ""), Transits = c(14L, 14L, 13L, 10L, 11L, 14L, 14L,
> > 14L, 16L, 6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L, 8L,
> > 10L, 9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L,
> > 7L, 7L, 8L, 4L, 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L, 5L,
> > 10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L, 5L, 6L, 7L, 6L, 9L, 8L,
> > 10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L, 14L, 15L,
> > 14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L, 9L, 12L, 8L,
> > 12L, 10L, 11L, 10L, 9L, 10L, 11L, 8L, 10L, 12L, 10L, 11L, 14L,
> > 9L, 15L, 15L, 14L, 14L, 14L, 15L, 16L, 15L, 18L, 21L, 18L, 17L,
> > 21L, 18L, 19L, 19L, 18L, 21L, 22L, 25L, 23L, 28L, 25L, 25L, 25L,
> > 21L, 28L, 21L, 22L, 23L, 20L, 24L, 22L, 26L, 24L, 24L, 28L, 31L,
> > 34L, 36L, 33L, 29L, 34L, 33L, 33L, 31L, 33L, 29L, 32L, 26L, 24L,
> > 30L, 27L, 31L, 23L, 23L, 21L, 21L, 18L, 21L, 19L, 19L, 16L, 14L,
> > 22L, 24L, 28L, 26L, 29L, 23L, 28L, 21L, 17L, 17L, 14L, 12L, 14L,
> > 10L, 12L, 13L, 14L, 15L, 21L, 10L, 15L, 12L, 15L, 16L, 17L, 14L,
> > 14L, 12L, 7L, 8L, 8L, 11L, 9L, 12L, 11L, 6L, 8L, 11L, 7L, 8L,
> > 14L, 9L, 11L, 8L, 8L, 6L, 3L, 4L, 4L, 5L, 4L, 3L, 3L, 5L, 8L,
> > 6L, 8L, 6L, 7L, 14L, 14L, 15L, 13L, 16L, 18L, 20L, 21L, 18L,
> > 19L, 24L, 27L, 26L, 18L, 28L, 21L, 22L, 25L, 29L, 26L, 22L, 22L,
> > 14L, 18L, 18L, 13L, 15L, 16L, 19L, 9L, 14L, 11L, 9L, 14L, 16L,
> > 11L, 13L, 11L, 16L, 16L, 20L, 17L, 19L, 18L, 24L, 19L, 19L, 15L,
> > 21L, 21L, 24L, 28L, 14L, 20L, 15L, 24L, 18L, 24L, 24L, 25L, 21L,
> > 24L, 27L, 28L, 27L, 26L, 29L, 25L, 24L, 25L, 28L, 23L, 30L, 23L,
> > 29L, 26L, 31L, 33L, 40L, 36L, 39L, 36L, 34L, 32L, 32L, 30L, 27L,
> > 32L, 30L, 31L, 26L, 31L, 29L, 26L, 28L, 24L, 22L, 11L, 15L, 17L,
> > 12L, 13L, 14L, 9L, 12L, 11L, 17L, 9L, 8L, 7L, 11L, 8L, 15L, 8L,
> > 10L, 13L, 12L, 13L, 12L, 12L, 19L, 21L, 18L, 20L, 21L, 20L, 22L,
> > 19L, 21L, 20L, 21L, 18L, 18L, 19L, 13L, 16L, 12L, 6L, 7L, 5L,
> > 6L, 6L, 7L, 7L, 5L, 4L, 6L, 4L, 1L, 2L, 7L, 12L), CargoTons = c(154973L,
> > 129636L, 136884L, 86348L, 109907L, 154506L, 144083L, 152794L,
> > 124861L, 60330L, 65221L, 61718L, 53997L, 83536L, 63218L, 98222L,
> > 54719L, 98470L, 18263L, 104255L, 62869L, 62523L, 75344L, 81476L,
> > 92818L, 87457L, 85231L, 77897L, 57699L, 96989L, 109361L, 59799L,
> > 91116L, 82241L, 74251L, 124361L, 68751L, 61719L, 68017L, 37760L,
> > 32513L, 56359L, 51333L, 80859L, 75852L, 65760L, 96043L, 38820L,
> > 63202L, 102647L, 49104L, 53482L, 121305L, 71795L, 76704L, 146097L,
> > 73047L, 68557L, 110642L, 77616L, 97767L, 52059L, 58658L, 66350L,
> > 69303L, 76013L, 91909L, 108445L, 94454L, 101249L, 112131L, 56290L,
> > 118342L, 70618L, 64783L, 112839L, 120506L, 94243L, 130768L, 133643L,
> > 146321L, 140736L, 147234L, 158953L, 189888L, 93819L, 130021L,
> > 130124L, 55088L, 114783L, 95184L, 82205L, 80321L, 65422L, 98933L,
> > 93713L, 98417L, 97210L, 88464L, 94659L, 92873L, 79784L, 96655L,
> > 122266L, 100779L, 120569L, 133029L, 92889L, 160886L, 132364L,
> > 130435L, 139653L, 152143L, 160824L, 165842L, 175679L, 210872L,
> > 211941L, 207820L, 179857L, 212733L, 203135L, 218368L, 198343L,
> > 195677L, 210066L, 243311L, 261965L, 240683L, 245242L, 218004L,
> > 247640L, 209872L, 223668L, 290521L, 185161L, 210341L, 261739L,
> > 205431L, 284114L, 251466L, 302961L, 292981L, 279329L, 309197L,
> > 341092L, 385209L, 366958L, 330515L, 286950L, 295590L, 350901L,
> > 341678L, 284666L, 283148L, 279108L, 284896L, 238802L, 198786L,
> > 273465L, 256694L, 360520L, 320201L, 296881L, 264202L, 280142L,
> > 219105L, 278606L, 254420L, 260339L, 216457L, 198077L, 249436L,
> > 302860L, 360184L, 317105L, 391413L, 265210L, 354714L, 306031L,
> > 266124L, 215799L, 232630L, 156590L, 203111L, 157075L, 160140L,
> > 177874L, 219162L, 159610L, 286483L, 144631L, 216456L, 157305L,
> > 237780L, 191617L, 223211L, 180330L, 187074L, 126043L, 62462L,
> > 93633L, 56417L, 115036L, 74365L, 98785L, 116172L, 43421L, 73769L,
> > 128795L, 58910L, 74282L, 115312L, 102303L, 106109L, 76940L, 82683L,
> > 49149L, 22517L, 20731L, 24684L, 52558L, 40057L, 28981L, 46062L,
> > 43213L, 107755L, 53404L, 56390L, 41541L, 41183L, 80161L, 110960L,
> > 130891L, 130395L, 183351L, 242803L, 225383L, 190962L, 169432L,
> > 186260L, 206997L, 196097L, 202942L, 175063L, 240869L, 213226L,
> > 237754L, 208280L, 231596L, 207033L, 213294L, 250265L, 129334L,
> > 173986L, 145188L, 98384L, 163739L, 138180L, 136521L, 86836L,
> > 97452L, 71988L, 79293L, 124134L, 116343L, 91030L, 98457L, 77906L,
> > 130599L, 132381L, 162992L, 142756L, 150105L, 150339L, 161097L,
> > 112633L, 145691L, 100771L, 147805L, 123418L, 138375L, 185776L,
> > 108842L, 145245L, 108517L, 154079L, 118999L, 184855L, 157646L,
> > 187000L, 126190L, 181693L, 180395L, 170781L, 200521L, 140371L,
> > 185517L, 160662L, 149601L, 164220L, 162613L, 120102L, 189868L,
> > 131791L, 187465L, 205760L, 249684L, 219829L, 201173L, 230138L,
> > 261196L, 258797L, 286470L, 216719L, 219241L, 221386L, 191207L,
> > 212000L, 220639L, 237053L, 172805L, 199395L, 154402L, 152970L,
> > 120174L, 188452L, 122797L, 88608L, 101692L, 114182L, 96193L,
> > 111524L, 93344L, 87006L, 104160L, 88455L, 77399L, 69451L, 73572L,
> > 54280L, 93056L, 71274L, 124714L, 65822L, 54215L, 73492L, 73178L,
> > 104991L, 68259L, 88045L, 84797L, 47925L, 88662L, 88082L, 140498L,
> > 116875L, 145168L, 107149L, 144324L, 119079L, 171258L, 97017L,
> > 86082L, 110873L, 50194L, 114805L, 62368L, 32524L, 39318L, 30558L,
> > 42822L, 45154L, 35025L, 20565L, 58236L, 35809L, 47644L, 30747L,
> > NA, NA, 35449L, 48808L), RcnstPCUMS = c(229914L, 214547L, 215890L,
> > 158695L, 173125L, 222533L, 212490L, 222125L, 266913L, 94268L,
> > 112967L, 95480L, 87654L, 108996L, 97973L, 139247L, 93817L, 133197L,
> > 40020L, 169749L, 102590L, 112121L, 140241L, 122989L, 144592L,
> > 144979L, 123748L, 123249L, 70081L, 155218L, 168096L, 104743L,
> > 163384L, 142648L, 129188L, 183170L, 99299L, 99873L, 111648L,
> > 55890L, 59183L, 95568L, 72550L, 104562L, 100478L, 92665L, 130625L,
> > 54786L, 105900L, 135833L, 70932L, 73247L, 149632L, 94317L, 87926L,
> > 181989L, 92778L, 107097L, 153246L, 105175L, 126393L, 81976L,
> > 95518L, 109019L, 95370L, 140492L, 125795L, 157978L, 138424L,
> > 138160L, 180320L, 78757L, 135860L, 85921L, 114847L, 151965L,
> > 152561L, 132841L, 204839L, 209567L, 224436L, 210209L, 227143L,
> > 245968L, 264969L, 158648L, 222251L, 194335L, 111618L, 189643L,
> > 137438L, 124953L, 163155L, 107633L, 164525L, 135102L, 152072L,
> > 126636L, 121008L, 137824L, 149673L, 106832L, 134953L, 162195L,
> > 135259L, 151180L, 188069L, 121234L, 199609L, 206011L, 186772L,
> > 185596L, 189869L, 189930L, 209268L, 191993L, 238722L, 281076L,
> > 236211L, 227651L, 277805L, 248063L, 258661L, 261644L, 248401L,
> > 292764L, 313626L, 353877L, 318685L, 385547L, 346224L, 347058L,
> > 353098L, 290663L, 398291L, 305578L, 314469L, 325343L, 281866L,
> > 355524L, 323626L, 393901L, 360773L, 362326L, 415317L, 464535L,
> > 511488L, 540671L, 491824L, 426657L, 500855L, 494717L, 495668L,
> > 455605L, 484598L, 437629L, 476437L, 383114L, 357059L, 449471L,
> > 409024L, 479044L, 360007L, 360455L, 333982L, 342971L, 273450L,
> > 337258L, 308626L, 302838L, 265044L, 221514L, 341869L, 371003L,
> > 450406L, 414775L, 469590L, 360334L, 451528L, 337465L, 283627L,
> > 278748L, 242639L, 202808L, 237041L, 174856L, 206948L, 219398L,
> > 247023L, 253697L, 351625L, 179661L, 255214L, 205368L, 258669L,
> > 270376L, 284729L, 231441L, 240220L, 197141L, 110459L, 124586L,
> > 115785L, 208191L, 139493L, 195068L, 184665L, 99351L, 123562L,
> > 186571L, 117504L, 128846L, 217616L, 128850L, 158105L, 112762L,
> > 118091L, 91510L, 41670L, 65418L, 57038L, 74113L, 63359L, 48717L,
> > 59326L, 79181L, 133076L, 93478L, 121455L, 100396L, 113939L, 224357L,
> > 209899L, 237803L, 196839L, 254633L, 278283L, 302996L, 315330L,
> > 272767L, 277027L, 357066L, 398089L, 400740L, 275789L, 429226L,
> > 326028L, 332848L, 388062L, 434889L, 397012L, 332171L, 338845L,
> > 209076L, 270632L, 261217L, 191663L, 222970L, 237384L, 276674L,
> > 138649L, 203588L, 178863L, 135641L, 217348L, 239162L, 168607L,
> > 196393L, 173731L, 256877L, 250192L, 303120L, 256045L, 278352L,
> > 266185L, 350521L, 282258L, 281162L, 226240L, 312103L, 312547L,
> > 369650L, 420464L, 214503L, 305474L, 232981L, 382171L, 291030L,
> > 370213L, 368859L, 395471L, 331912L, 389084L, 433543L, 446459L,
> > 434882L, 427397L, 482135L, 424532L, 402021L, 413143L, 460258L,
> > 399300L, 513805L, 383895L, 485673L, 426859L, 515510L, 532852L,
> > 640559L, 591249L, 612067L, 577562L, 546291L, 524853L, 515396L,
> > 485261L, 442432L, 520541L, 485585L, 505058L, 424639L, 527199L,
> > 468619L, 427842L, 457937L, 414473L, 368965L, 165326L, 228879L,
> > 261042L, 184066L, 199600L, 213524L, 140264L, 175064L, 152734L,
> > 252011L, 139741L, 124736L, 106170L, 165564L, 127610L, 237950L,
> > 122876L, 151239L, 191794L, 173043L, 187453L, 171653L, 171397L,
> > 275756L, 308794L, 264032L, 285570L, 322867L, 281804L, 311683L,
> > 271705L, 310707L, 286221L, 302599L, 270895L, 258684L, 277845L,
> > 191935L, 236936L, 180781L, 101623L, 112534L, 81747L, 98125L,
> > 102205L, 111226L, 110349L, 89677L, 69492L, 97820L, 69730L, 15018L,
> > 40889L, 97624L, 166204L), TotalToll = c(420742L, 392621L, 395078L,
> > 290411L, 316818L, 407235L, 388856L, 406488L, 482774L, 172510L,
> > 206729L, 174728L, 160406L, 199462L, 179290L, 254822L, 171685L,
> > 243750L, 73236L, 310640L, 187739L, 205181L, 249438L, 225069L,
> > 264603L, 265311L, 226458L, 225545L, 128248L, 284048L, 296023L,
> > 184934L, 298992L, 261045L, 236414L, 335201L, 181717L, 182767L,
> > 204315L, 102278L, 108304L, 174889L, 132766L, 191348L, 183874L,
> > 169576L, 239043L, 100258L, 212859L, 273024L, 142573L, 147226L,
> > 300760L, 189577L, 176731L, 365797L, 186483L, 215264L, 308024L,
> > 211401L, 254049L, 164771L, 191991L, 219128L, 191693L, 282388L,
> > 252847L, 317535L, 278232L, 277701L, 356022L, 158301L, 273078L,
> > 172701L, 230842L, 305449L, 306647L, 267010L, 406202L, 421229L,
> > 451116L, 422520L, 456557L, 494395L, 582202L, 350612L, 491174L,
> > 429480L, 239858L, 419111L, 303737L, 276146L, 360572L, 237868L,
> > 358627L, 298575L, 336079L, 279865L, 267427L, 304591L, 323566L,
> > 236098L, 298246L, 358450L, 298922L, 334107L, 415632L, 267927L,
> > 441136L, 455284L, 412766L, 410167L, 419610L, 419745L, 462482L,
> > 424305L, 527576L, 621178L, 522026L, 503109L, 613949L, 548219L,
> > 571641L, 578233L, 548966L, 647008L, 693113L, 782068L, 704294L,
> > 845344L, 765155L, 766998L, 774306L, 642365L, 880223L, 730331L,
> > 751581L, 770694L, 660018L, 849702L, 773466L, 941423L, 862247L,
> > 865959L, 992608L, 1103240L, 1222456L, 1389524L, 1263988L, 1096508L,
> > 1278566L, 1271423L, 1273867L, 1158103L, 1239499L, 1124707L, 1218525L,
> > 984603L, 909630L, 1155140L, 1043122L, 1231143L, 925218L, 926369L,
> > 850265L, 881435L, 702766L, 866753L, 793169L, 778294L, 681163L,
> > 569291L, 871709L, 953478L, 1150022L, 1065972L, 1206846L, 926058L,
> > 1129778L, 867285L, 728921L, 716382L, 623582L, 521217L, 609195L,
> > 449380L, 531856L, 563853L, 634849L, 643607L, 888831L, 461729L,
> > 655900L, 527796L, 664779L, 687175L, 731754L, 586409L, 617365L,
> > 506652L, 276310L, 320186L, 289618L, 535051L, 389544L, 544553L,
> > 515428L, 277302L, 336755L, 512700L, 318225L, 359684L, 607673L,
> > 379065L, 465104L, 331810L, 347203L, 268918L, 122643L, 192034L,
> > 159071L, 217928L, 186080L, 134668L, 173724L, 232564L, 390599L,
> > 265947L, 348773L, 294627L, 334562L, 649731L, 607805L, 698507L,
> > 578572L, 1059450L, 1187844L, 1246619L, 1296120L, 1140384L, 1187214L,
> > 1432452L, 1606332L, 1728174L, 1203594L, 1822716L, 1389276L, 1728426L,
> > 1926935L, 2125297L, 1943820L, 1623321L, 1590148L, 1049286L, 1398754L,
> > 1320550L, 994945L, 1164583L, 1205841L, 1559682L, 769662L, 1091567L,
> > 1000642L, 718794L, 1175818L, 1254971L, 900558L, 1033592L, 927072L,
> > 1245348L, 1240380L, 1820813L, 1567994L, 1789477L, 1700773L, 2204080L,
> > 1745881L, 1842826L, 1476216L, 1967969L, 1939304L, 2335284L, 2676920L,
> > 1580544L, 2277360L, 1694016L, 2721614L, 2107008L, 2630707L, 2530555L,
> > 2872656L, 2395440L, 2704234L, 3035837L, 3147379L, 3076661L, 2903544L,
> > 3398155L, 2964859L, 2837506L, 2883096L, 3264696L, 2779186L, 3980670L,
> > 2923166L, 3739659L, 3317358L, 3978904L, 4112544L, 4828331L, 4423260L,
> > 4650546L, 4321198L, 4147356L, 3959882L, 3891892L, 3623148L, 3365086L,
> > 3917517L, 3708696L, 3876444L, 3234706L, 3968716L, 3558025L, 3313506L,
> > 3522721L, 3104372L, 2772710L, 1329618L, 1857286L, 2126974L, 1509160L,
> > 1616068L, 1679704L, 1164638L, 1390846L, 1199265L, 1868727L, 1091024L,
> > 1023810L, 837614L, 1367468L, 1056694L, 1886631L, 951129L, 1153342L,
> > 1491752L, 1305802L, 1461332L, 1286770L, 1310026L, 1997167L, 2234964L,
> > 1924902L, 2080596L, 2331026L, 2046594L, 2302530L, 1958478L, 2262478L,
> > 2115387L, 2220923L, 1959669L, 1849238L, 2089172L, 1381704L, 1553856L,
> > 1251361L, 704230L, 776554L, 592426L, 704066L, 772042L, 754649L,
> > 797425L, 624502L, 517122L, 683626L, 507750L, 99592L, 217680L,
> > 671070L, 1150758L)), class = "data.frame", row.names = c(NA,
> > 383L))
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Sep  3 20:20:54 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 3 Sep 2018 11:20:54 -0700
Subject: [R] Display time of PDF plots
In-Reply-To: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>

1. Plot a random sample of the points (e.g. of rows of matrix/dataframe
containing "x" and "y" columns

2. See the hexbin package

3. Check out the graphics taskview on cran:
https://cran.r-project.org/web/views/Graphics.html
(though it may be somewhat dated by now)

4. Internet search:  e.g. on "display scatterplots with thousands of
points"
typical hit:
https://stackoverflow.com/questions/7714677/scatterplot-with-too-many-points

5. Search/Post on stats.stackexchange.com instead.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 3, 2018 at 10:45 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>    This may be an inappropriate forum for this question. If so, please
> point
> me in a better direction.
>
>    A current project includes scatter plots with thousands of points. Saved
> as PDF files they display slowly using a pdf viewer or when included in the
> PDF output of a LaTeX document.
>
>    Is there a process by which these plots can be 'thinned' so they show
> the
> same overall patterns but with fewer points so they display more quickly?
>
>    Rasterizing them to .jpg files using 'convert' allows them to load
> immediately, but the bit-mapped resolution is, of course, much lower than
> the vector PDF format.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Sep  3 20:31:02 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Mon, 3 Sep 2018 11:31:02 -0700 (PDT)
Subject: [R] Display time of PDF plots
In-Reply-To: <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809031129550.20440@salmo.appl-ecosys.com>

On Mon, 3 Sep 2018, Bert Gunter wrote:

> 1. Plot a random sample of the points (e.g. of rows of matrix/dataframe
> containing "x" and "y" columns
>
> 2. See the hexbin package
>
> 3. Check out the graphics taskview on cran:
> https://cran.r-project.org/web/views/Graphics.html
> (though it may be somewhat dated by now)
>
> 4. Internet search:  e.g. on "display scatterplots with thousands of
> points"
> typical hit:
> https://stackoverflow.com/questions/7714677/scatterplot-with-too-many-points
>
> 5. Search/Post on stats.stackexchange.com instead.

Bert,

   I did a web search without finding useful information. Probably not the
best search terms.

   Will implement your suggestions.

Thanks,

Rich


From dc@rl@on @ending from t@mu@edu  Mon Sep  3 20:36:42 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Mon, 3 Sep 2018 18:36:42 +0000
Subject: [R] Display time of PDF plots
In-Reply-To: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
Message-ID: <2da8f15c0c824e0b846c82fd6e3049aa@tamu.edu>

If the plot is being displayed on a monitor, it is being bitmapped to the resolution of the display device regardless of how you save it. Most computer monitors are about 100dpi.

If the problem is that the points are overprinting, Bert's suggestion to use hexbin() is the way to go.

If the points are not substantially overprinting, you could just save the plot in raster format using an lzh compressed tif() or png() to the maximum likely resolution of the display device (take zooming into account by going up to 600dpi or 1200dpi, for example). Don't use jpg since it is lossy and you will get halos when you zoom in. 

You can always preserve a vector version for publication. If you have Adobe Acrobat (not Reader), you can Save As Other | Image | tiff (or png) and set the resolution before exporting.

----------------------------
David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Monday, September 3, 2018 12:45 PM
To: r-help at r-project.org
Subject: [R] Display time of PDF plots

   This may be an inappropriate forum for this question. If so, please point
me in a better direction.

   A current project includes scatter plots with thousands of points. Saved
as PDF files they display slowly using a pdf viewer or when included in the
PDF output of a LaTeX document.

   Is there a process by which these plots can be 'thinned' so they show the
same overall patterns but with fewer points so they display more quickly?

   Rasterizing them to .jpg files using 'convert' allows them to load
immediately, but the bit-mapped resolution is, of course, much lower than
the vector PDF format.

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Sep  3 21:10:27 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Mon, 3 Sep 2018 12:10:27 -0700 (PDT)
Subject: [R] Display time of PDF plots
In-Reply-To: <2da8f15c0c824e0b846c82fd6e3049aa@tamu.edu>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <2da8f15c0c824e0b846c82fd6e3049aa@tamu.edu>
Message-ID: <alpine.LNX.2.20.1809031207100.20440@salmo.appl-ecosys.com>

On Mon, 3 Sep 2018, David L Carlson wrote:

> If the plot is being displayed on a monitor, it is being bitmapped to the
> resolution of the display device regardless of how you save it. Most
> computer monitors are about 100dpi.

David,

   I'm looking at the report on the monitor. I suspect that most readers
will, too. But, some will print it.

> If the problem is that the points are overprinting, Bert's suggestion to
> use hexbin() is the way to go.

   Most look like overprints, but at the top there are discrete print
characters.

> If the points are not substantially overprinting, you could just save the
> plot in raster format using an lzh compressed tif() or png() to the
> maximum likely resolution of the display device (take zooming into account
> by going up to 600dpi or 1200dpi, for example). Don't use jpg since it is
> lossy and you will get halos when you zoom in.

   I used convert to produce .png images but, of course, bit-maps of plots
and text are less sharp than are vector images.

> You can always preserve a vector version for publication. If you have
> Adobe Acrobat (not Reader), you can Save As Other | Image | tiff (or png)
> and set the resolution before exporting.

   'convert', the ImageMagick tool, does this, too.

Thanks,

Rich


From p@ul @ending from @t@t@@uckl@nd@@c@nz  Mon Sep  3 21:32:49 2018
From: p@ul @ending from @t@t@@uckl@nd@@c@nz (Paul Murrell)
Date: Tue, 4 Sep 2018 07:32:49 +1200
Subject: [R] [FORGED] Re:  Display time of PDF plots
In-Reply-To: <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>
Message-ID: <2e6dbc25-c4e2-7722-bbee-1236574c05a6@stat.auckland.ac.nz>

Hi

Another option is to just rasterize the points (but leave the rest of 
the plot vector).  See ...

https://www.stat.auckland.ac.nz/~paul/Reports/rasterize/rasterize.html

Paul

On 04/09/18 06:20, Bert Gunter wrote:
> 1. Plot a random sample of the points (e.g. of rows of matrix/dataframe
> containing "x" and "y" columns
> 
> 2. See the hexbin package
> 
> 3. Check out the graphics taskview on cran:
> https://cran.r-project.org/web/views/Graphics.html
> (though it may be somewhat dated by now)
> 
> 4. Internet search:  e.g. on "display scatterplots with thousands of
> points"
> typical hit:
> https://stackoverflow.com/questions/7714677/scatterplot-with-too-many-points
> 
> 5. Search/Post on stats.stackexchange.com instead.
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Sep 3, 2018 at 10:45 AM Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
> 
>>     This may be an inappropriate forum for this question. If so, please
>> point
>> me in a better direction.
>>
>>     A current project includes scatter plots with thousands of points. Saved
>> as PDF files they display slowly using a pdf viewer or when included in the
>> PDF output of a LaTeX document.
>>
>>     Is there a process by which these plots can be 'thinned' so they show
>> the
>> same overall patterns but with fewer points so they display more quickly?
>>
>>     Rasterizing them to .jpg files using 'convert' allows them to load
>> immediately, but the bit-mapped resolution is, of course, much lower than
>> the vector PDF format.
>>
>> Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Sep  3 23:17:52 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Mon, 3 Sep 2018 14:17:52 -0700 (PDT)
Subject: [R] [FORGED] Re:  Display time of PDF plots
In-Reply-To: <2e6dbc25-c4e2-7722-bbee-1236574c05a6@stat.auckland.ac.nz>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>
 <2e6dbc25-c4e2-7722-bbee-1236574c05a6@stat.auckland.ac.nz>
Message-ID: <alpine.LNX.2.20.1809031417210.20440@salmo.appl-ecosys.com>

On Tue, 4 Sep 2018, Paul Murrell wrote:

> Another option is to just rasterize the points (but leave the rest of the
> plot vector). See ...
> https://www.stat.auckland.ac.nz/~paul/Reports/rasterize/rasterize.html

Paul,

   Thanks very much for the suggestion and URL.

Regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Sep  3 23:19:12 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Mon, 3 Sep 2018 14:19:12 -0700 (PDT)
Subject: [R] Display time of PDF plots
In-Reply-To: <0F789916-5437-4A84-8CC0-2CA9216CE45F@som.umaryland.edu>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <0F789916-5437-4A84-8CC0-2CA9216CE45F@som.umaryland.edu>
Message-ID: <alpine.LNX.2.20.1809031418130.20440@salmo.appl-ecosys.com>

On Mon, 3 Sep 2018, Sorkin, John wrote:

> Might it help to take a random subset of the data and plot the sub set? If
> the relation is linear you could include a regression line obtained from
> the entire data set

John,

   I'll definitely explore this option. Thanks for the idea.

Regards,

Rich


From drjimlemon @ending from gm@il@com  Tue Sep  4 00:36:22 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 4 Sep 2018 08:36:22 +1000
Subject: [R] Account for a factor variability in a logistic GLMM in lme4
In-Reply-To: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>
References: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>
Message-ID: <CA+8X3fXUk2=zNkKxLojEj9pHrFfQjDMVNNohnq=irLSN236WXw@mail.gmail.com>

Hi Pedro,
I have encountered similar situations in a number of areas. Great care
is taken to record significant events of low probability, but not the
non-occurrence of those events. Sometimes this is due to a problem
with the definition of non-occurrence. To use your example, how close
does an animal have to approach the crossing to be counted as not
crossing? Perhaps it was just a failure to record the species of
animals that didn't cross. In that case you have a problem, because
the probability of crossing within species cannot be estimated from
the data you describe.

Jim
On Tue, Sep 4, 2018 at 12:43 AM Pedro Vaz <zasvaz at gmail.com> wrote:
>
> We did a field study in which we tried to understand which factors
> significantly explain the probability of a group of animals (5 species in
> total) crossing through 30 wildlife road-crossing structures. The response
> variable is binomial (yes=crossed; no = did not cross) and was recorded by
> animal species. We did about 30 visits to each crossing structure (our
> random factor) in which we recorded the binomial response by each animal
> species and the values of a few predictors.
>
> So, I have this (simplified for better understanding) mixed effects model:
> library (lme4)
>
> Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|structure.id),
>   data = Mydata, family = binomial)
>
> stream is a factor with 2 levels; width.m is continuous; grass.per is a
> percentage
>
> This is the model in which I assessed crossings by all species combined
> (i.e., cross. 01 = 1 when an animal of any species crossed, cross.01 = 0
> when no animal crossed). However, we did one model per species and those
> species-specific models highlight that different species exhibit different
> relationships between crossings and explanatory variables.
>
> My problem: This means that my model above suffers from an additional
> source of variation related to the species level without accounting for it.
> However I cannot recalibrate the above model adding the species level as
> random factor because, in my binomial response, the zero means no species
> crossed (all zeros would have "NA" or, say, "none" for species) and so that
> additional source of variation is only present when the response was 1.
> Just to confirm this, I did add species as a random factor:
>
> (1 | structure.id) + (1 | species)
>
> As expected, the message is "Error: Response is constant"
>
> How can I account for the species variability in my model in lme4?
>
> A few more details:
> A few more details:
> - I had 5 mammal species crossing through the 30 road-crossing structures.
> In 134 occasions (i.e., 134 of my records on individual
> crossing-structures), no animal crossed (so, @Dimitris Rizopoulos, no, I
> didn't have the species of the animals which did not cross. A "no cross"
> was a "zero" for that visit to the crossing-structure). In 498 occasions,
> at least one animal of a given species crossed the structure (these were my
> "ones" in my logistic response)
> - A side comment: This is to respond to a reviewer in a paper of mine,
> i.e., I did and presented species-specific and "all combined species"
> models in the draft reviewed but now the reviewer is asking me to control
> for the species variability in the "combined species model". He asked me to
> include a random factor but I realized that is not possible since all my
> zeros would have "none" for the species that crossed. So, is it possible to
> control for the species variability in my model in lme4 in another way? I
> know in nlme including a fitting of variance structures it's not that
> difficult...
> - Every time an animal crossed, the binary response was "one" and I
> recorded the animal species as well. Thus, I have variability between
> species in the "ones" but not in my "zeros" of my logistic model.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon @ending from gm@il@com  Tue Sep  4 03:09:52 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 4 Sep 2018 11:09:52 +1000
Subject: [R] pheatmap query
In-Reply-To: <AM4PR01MB1860BEBDAECEDF6B6BF03DE1BD0C0@AM4PR01MB1860.eurprd01.prod.exchangelabs.com>
References: <AM4PR01MB1860BEBDAECEDF6B6BF03DE1BD0C0@AM4PR01MB1860.eurprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fXEiqn2PoVDLF0hORXqtf=RhRqaAFP6rx33ZinkbLgv5A@mail.gmail.com>

Hi Tanya,
Have you looked at the return value of pheatmap?

ret<-pheatmap(counts_filtered_df,scale="row",cluster_col=FALSE,
 cluster_row=TRUE,border_color=NA,show_rownames = TRUE)
str(ret)
names(ret$tree_row)
names(ret$tree_col)

Look at what is in "ret" to see if your numeric matrix is hidden there.

Jim
On Mon, Sep 3, 2018 at 7:25 PM Singh, Tanya <t.singh at ucl.ac.uk> wrote:
>
> Hi
>
>
>
> I am plotting a pheatmap using following line in a R code
>
> pheatmap(counts_filtered_df,scale="row",cluster_col=FALSE,cluster_row=TRUE,border_color=NA,show_rownames = T)
>
>
>
> I want to extract the row names in the same order as shown in pheatmap and the z scores for them.
>
>
>
> So basically a numeric matrix instead of a figure. Can someone help me how this can be done
>
>
>
> Thanks
>
>
>
> Tanya
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@echler @ending from @t@t@m@th@ethz@ch  Tue Sep  4 11:28:12 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 4 Sep 2018 11:28:12 +0200
Subject: [R] Account for a factor variability in a logistic GLMM in lme4
In-Reply-To: <CA+8X3fXUk2=zNkKxLojEj9pHrFfQjDMVNNohnq=irLSN236WXw@mail.gmail.com>
References: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>
 <CA+8X3fXUk2=zNkKxLojEj9pHrFfQjDMVNNohnq=irLSN236WXw@mail.gmail.com>
Message-ID: <23438.20524.387844.394620@stat.math.ethz.ch>

>>>>> Jim Lemon 
>>>>>     on Tue, 4 Sep 2018 08:36:22 +1000 writes:

    > Hi Pedro,
    > I have encountered similar situations in a number of areas. Great care
    > is taken to record significant events of low probability, but not the
    > non-occurrence of those events. Sometimes this is due to a problem
    > with the definition of non-occurrence. To use your example, how close
    > does an animal have to approach the crossing to be counted as not
    > crossing? Perhaps it was just a failure to record the species of
    > animals that didn't cross. In that case you have a problem, because
    > the probability of crossing within species cannot be estimated from
    > the data you describe.

    > Jim

Indeed!

For those among us too young to remember:

The 1986 Space shuttle Challenger catastrophe was co-caused by
that mistake:  Only considering the '1's and not considering the
'0's in the data (visualised and shown to the decision making experts).

See, e.g.,
  https://priceonomics.com/the-space-shuttle-challenger-explosion-and-the-o/

  (couldn't easily find a more academic / reliable source which
   *does* include the graphics)

Martin Maechler
ETH Zurich

    > On Tue, Sep 4, 2018 at 12:43 AM Pedro Vaz <zasvaz at gmail.com> wrote:
    >> 
    >> We did a field study in which we tried to understand which factors
    >> significantly explain the probability of a group of animals (5 species in
    >> total) crossing through 30 wildlife road-crossing structures. The response
    >> variable is binomial (yes=crossed; no = did not cross) and was recorded by
    >> animal species. We did about 30 visits to each crossing structure (our
    >> random factor) in which we recorded the binomial response by each animal
    >> species and the values of a few predictors.
    >> 
    >> So, I have this (simplified for better understanding) mixed effects model:
    >> library (lme4)
    >> 
    >> Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|structure.id),
    >> data = Mydata, family = binomial)
    >> 
    >> stream is a factor with 2 levels; width.m is continuous; grass.per is a
    >> percentage
    >> 
    >> This is the model in which I assessed crossings by all species combined
    >> (i.e., cross. 01 = 1 when an animal of any species crossed, cross.01 = 0
    >> when no animal crossed). However, we did one model per species and those
    >> species-specific models highlight that different species exhibit different
    >> relationships between crossings and explanatory variables.
    >> 
    >> My problem: This means that my model above suffers from an additional
    >> source of variation related to the species level without accounting for it.
    >> However I cannot recalibrate the above model adding the species level as
    >> random factor because, in my binomial response, the zero means no species
    >> crossed (all zeros would have "NA" or, say, "none" for species) and so that
    >> additional source of variation is only present when the response was 1.
    >> Just to confirm this, I did add species as a random factor:
    >> 
    >> (1 | structure.id) + (1 | species)
    >> 
    >> As expected, the message is "Error: Response is constant"
    >> 
    >> How can I account for the species variability in my model in lme4?
    >> 
    >> A few more details:
    >> A few more details:
    >> - I had 5 mammal species crossing through the 30 road-crossing structures.
    >> In 134 occasions (i.e., 134 of my records on individual
    >> crossing-structures), no animal crossed (so, @Dimitris Rizopoulos, no, I
    >> didn't have the species of the animals which did not cross. A "no cross"
    >> was a "zero" for that visit to the crossing-structure). In 498 occasions,
    >> at least one animal of a given species crossed the structure (these were my
    >> "ones" in my logistic response)
    >> - A side comment: This is to respond to a reviewer in a paper of mine,
    >> i.e., I did and presented species-specific and "all combined species"
    >> models in the draft reviewed but now the reviewer is asking me to control
    >> for the species variability in the "combined species model". He asked me to
    >> include a random factor but I realized that is not possible since all my
    >> zeros would have "none" for the species that crossed. So, is it possible to
    >> control for the species variability in my model in lme4 in another way? I
    >> know in nlme including a fitting of variance structures it's not that
    >> difficult...
    >> - Every time an animal crossed, the binary response was "one" and I
    >> recorded the animal species as well. Thus, I have variability between
    >> species in the "ones" but not in my "zeros" of my logistic model.
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From nell@redu @ending from hotm@il@fr  Tue Sep  4 18:32:56 2018
From: nell@redu @ending from hotm@il@fr (Nelly Reduan)
Date: Tue, 4 Sep 2018 16:32:56 +0000
Subject: [R] Round down numeric values with decimals
Message-ID: <DM5PR05MB279324049A2520E959CB8B1B99030@DM5PR05MB2793.namprd05.prod.outlook.com>

Hello,



How can I round down numeric values with decimals? For example,



> signif(3.896037e+09, digits = 1)

[1] 4e+09



The expected result is 3e+09 (and not 4e+09).



> signif(8.68542378e-10, digits = 1)

[1] 9e-10



The expected result is 8e-10 (and not 9e-10).



Thank you very much for your time.

Have a nice day

Nell


	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Tue Sep  4 18:41:03 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Tue, 4 Sep 2018 09:41:03 -0700 (PDT)
Subject: [R] Display time of PDF plots
In-Reply-To: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809040934080.8839@salmo.appl-ecosys.com>

On Mon, 3 Sep 2018, Rich Shepard wrote:

> Is there a process by which these plots can be 'thinned' so they show the
> same overall patterns but with fewer points so they display more quickly?

Bert/Paul/David/John:

   Thanks very much for the suggestions. I think an appropriate way to
illustrate the patterns is to plot the median and maximum for each month
(for all sites). That's the important information and plotting each daily
point over 13 years obscures that information.

   The dataframe is structured this way:

str(rainfall)
'data.frame':	113569 obs. of  6 variables:
  $ name    : chr  "Headworks Portland Water" "Headworks Portland Water" "Headworks Portland Water" "Headworks Portland Water" ...
  $ easting : num  2370575 2370575 2370575 2370575 2370575 ...
  $ northing: num  199338 199338 199338 199338 199338 ...
  $ elev    : num  228 228 228 228 228 228 228 228 228 228 ...
  $ sampdate: Date, format: "2005-01-01" "2005-01-02" ...
  $ prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...

   There are probably multiple ways of extracting the monthly median and
maximum 'prcp' and I don't know how to identify the appropriate one. Is
there a task view for this type of data manipulation? I've not before done
anything like this and would appreciate a pointer to where I start to learn.

Regards,

Rich


From z@@v@z @ending from gm@il@com  Tue Sep  4 18:39:51 2018
From: z@@v@z @ending from gm@il@com (Pedro Vaz)
Date: Tue, 4 Sep 2018 17:39:51 +0100
Subject: [R] leave-one-out cross validation in mixed effects logistic model
 (lme4)
Message-ID: <CAKW-RG_2b9MzYUg-zCpxTRd4xoiOPZW-bHXf4098j_Rzg3J+TA@mail.gmail.com>

 Hello,

So, I have this (simplified for better understanding) binomial mixed
effects model [library (lme4)]

Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|
structure.id),
  data = Mydata, family = binomial)

stream is a factor with 2 levels; width.m is continuous; grass.per is a
percentage

Now, a reviewer is asking me to apply "a cross-validation procedure (i.e. a
leave-one-out design coupled with predictive metrics as e.g. AUC) on this
model"

Does anyone have R-code to do this cross validation in my logistic mixed
effects model? In the reviewer words: "the model should be evaluated also
as for their predictive performance, not only for assumptions violation and
for goodness-of-fit" (which I presented already in the reviewed paper draft)

Many thanks in advance,
pedro

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Sep  4 20:08:07 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 4 Sep 2018 11:08:07 -0700
Subject: [R] Round down numeric values with decimals
In-Reply-To: <DM5PR05MB279324049A2520E959CB8B1B99030@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB279324049A2520E959CB8B1B99030@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <CAGxFJbQFkRuiWHZAnmmuSdn_Tr9uSYPsBGM5jP+HbUtLhWGx4g@mail.gmail.com>

This is *not* "rounding down."

But this should do it I think:
## (see ?floor)

x <- 3.896e09
k <- floor(log10(x))

> floor(x*10^(-k))*10^k
[1] 3e+09

There may be even slicker ways, but this is as slick as I can muster...

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 4, 2018 at 9:33 AM Nelly Reduan <nell.redu at hotmail.fr> wrote:

> Hello,
>
>
>
> How can I round down numeric values with decimals? For example,
>
>
>
> > signif(3.896037e+09, digits = 1)
>
> [1] 4e+09
>
>
>
> The expected result is 3e+09 (and not 4e+09).
>
>
>
> > signif(8.68542378e-10, digits = 1)
>
> [1] 9e-10
>
>
>
> The expected result is 8e-10 (and not 9e-10).
>
>
>
> Thank you very much for your time.
>
> Have a nice day
>
> Nell
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Sep  4 20:13:51 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 4 Sep 2018 11:13:51 -0700
Subject: [R] 
 leave-one-out cross validation in mixed effects logistic model
 (lme4)
In-Reply-To: <CAKW-RG_2b9MzYUg-zCpxTRd4xoiOPZW-bHXf4098j_Rzg3J+TA@mail.gmail.com>
References: <CAKW-RG_2b9MzYUg-zCpxTRd4xoiOPZW-bHXf4098j_Rzg3J+TA@mail.gmail.com>
Message-ID: <CAGxFJbT3j12+MVY=-R-5+eCtEMX7iu8najYneWRGrmYb8-9Vxw@mail.gmail.com>

Please post on the r-sig-mixed-models list, where you are more likely to
find the requisite expertise.

However, FWIW, I think the reviewer's request is complete nonsense (na?ve
cross validation requires iid sampling). But the mixed models experts are
the authorities on such judgments (and may tell you that my opinion is
complete nonsense!).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 4, 2018 at 10:16 AM Pedro Vaz <zasvaz at gmail.com> wrote:

>  Hello,
>
> So, I have this (simplified for better understanding) binomial mixed
> effects model [library (lme4)]
>
> Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|
> structure.id),
>   data = Mydata, family = binomial)
>
> stream is a factor with 2 levels; width.m is continuous; grass.per is a
> percentage
>
> Now, a reviewer is asking me to apply "a cross-validation procedure (i.e. a
> leave-one-out design coupled with predictive metrics as e.g. AUC) on this
> model"
>
> Does anyone have R-code to do this cross validation in my logistic mixed
> effects model? In the reviewer words: "the model should be evaluated also
> as for their predictive performance, not only for assumptions violation and
> for goodness-of-fit" (which I presented already in the reviewed paper
> draft)
>
> Many thanks in advance,
> pedro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From giftedlife2014 @ending from gm@il@com  Tue Sep  4 21:34:36 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Tue, 4 Sep 2018 20:34:36 +0100
Subject: [R] Equal Standard Error bar
Message-ID: <CAC8ss30AWzFAGoeg8xaNFRwXHRMs-9+NnRJcOtch1daViA_ubw@mail.gmail.com>

Dear List,

I have a dataset of high variability. I conducted epoch analysis and
attempted to plot the standard error bar alongside.

I am, however, surprised that the error bars are of equal length. I do not
think that the variability in the data is captured, except there is a kind
of averaging that smooths out the differences in daily variations. Should
that be the case, I don't know how and as such need your assistance to
explain what is going on.

The plot is attached. 71 events are represented in the plot.

The code I use to generate the plot is:
oodf<-data.frame(A,B)
library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(145000,162000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/day",main="Superposed
Epoch of all the Events")
dispersion(-5:10,oomean,oose).

The sample data is:
-5 64833
-4 95864
-3 82322
-2 95591
-1 69378
0 74281
1 103261
2 92473
3 84344
4 127415
5 123826
6 100029
7 76205
8 105162
9 119533
10 106490
-5 82322
-4 95591
-3 69378
-2 74281
-1 103261
0 92473
1 84344
2 127415
3 123826
4 100029
5 76205
6 105162
7 119533
8 106490
9 114771
10 55593
-5 85694
-4 65205
-3 80995
-2 51723
-1 62310
0 53401
1 65677
2 76094
3 64035
4 68290
5 73306
6 82176
7 75566
8 89762
9 88063
10 94395
-5 80651
-4 81291
-3 63702
-2 70297
-1 64117
0 71219
1 57354
2 62111
3 42252
4 35454
5 33469
6 38899
7 64981
8 85694
9 79452
10 85216
-5 71219
-4 57354
-3 62111
-2 42252
-1 35454
0 33469
1 38899
2 64981
3 85694
4 79452
5 85216
6 81721
7 91231
8 107074
9 108103
10 75768


You kind help will be greatly appreciated.

Many thanks

Ogbos

-------------- next part --------------
A non-text attachment was scrubbed...
Name: A8.png
Type: image/png
Size: 10229 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180904/a9a19f5a/attachment.png>

From dc@rl@on @ending from t@mu@edu  Tue Sep  4 22:58:04 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Tue, 4 Sep 2018 20:58:04 +0000
Subject: [R] Equal Standard Error bar
In-Reply-To: <CAC8ss30AWzFAGoeg8xaNFRwXHRMs-9+NnRJcOtch1daViA_ubw@mail.gmail.com>
References: <CAC8ss30AWzFAGoeg8xaNFRwXHRMs-9+NnRJcOtch1daViA_ubw@mail.gmail.com>
Message-ID: <044a56c442cf4573870f5fe24bfabfab@tamu.edu>

Thank you for the reproducible data, but it is not the data used in the plot you attached and does not plot anything with the code you included. The ylim= argument must be modified:

plot(-5:10, oomean, type="b", ylim=c(40000, 120000),
  xlab="days (epoch is the day of Fd)", ylab="strikes/day",
  main="Superposed Epoch of all the Events")
dispersion(-5:10, oomean, oose, arrow.cap=.01)

On the plot of these data it is clear that the error bars are different sizes:

range(oose)
[1] 1728.234 6890.916

What was the range of oose values for the data in the plot you included with your message?

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Ogbos Okike
Sent: Tuesday, September 4, 2018 2:35 PM
To: r-help <r-help at r-project.org>
Subject: [R] Equal Standard Error bar

Dear List,

I have a dataset of high variability. I conducted epoch analysis and attempted to plot the standard error bar alongside.

I am, however, surprised that the error bars are of equal length. I do not think that the variability in the data is captured, except there is a kind of averaging that smooths out the differences in daily variations. Should that be the case, I don't know how and as such need your assistance to explain what is going on.

The plot is attached. 71 events are represented in the plot.

The code I use to generate the plot is:
oodf<-data.frame(A,B)
library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(145000,162000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/day",main="Superposed
Epoch of all the Events")
dispersion(-5:10,oomean,oose).

The sample data is:
-5 64833
-4 95864
-3 82322
-2 95591
-1 69378
0 74281
1 103261
2 92473
3 84344
4 127415
5 123826
6 100029
7 76205
8 105162
9 119533
10 106490
-5 82322
-4 95591
-3 69378
-2 74281
-1 103261
0 92473
1 84344
2 127415
3 123826
4 100029
5 76205
6 105162
7 119533
8 106490
9 114771
10 55593
-5 85694
-4 65205
-3 80995
-2 51723
-1 62310
0 53401
1 65677
2 76094
3 64035
4 68290
5 73306
6 82176
7 75566
8 89762
9 88063
10 94395
-5 80651
-4 81291
-3 63702
-2 70297
-1 64117
0 71219
1 57354
2 62111
3 42252
4 35454
5 33469
6 38899
7 64981
8 85694
9 79452
10 85216
-5 71219
-4 57354
-3 62111
-2 42252
-1 35454
0 33469
1 38899
2 64981
3 85694
4 79452
5 85216
6 81721
7 91231
8 107074
9 108103
10 75768


You kind help will be greatly appreciated.

Many thanks

Ogbos

-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot.png
Type: image/png
Size: 7334 bytes
Desc: plot.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180904/8f32584f/attachment.png>

From bgunter@4567 @ending from gm@il@com  Wed Sep  5 00:12:20 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 4 Sep 2018 15:12:20 -0700
Subject: [R] Round down numeric values with decimals
In-Reply-To: <CAGxFJbQFkRuiWHZAnmmuSdn_Tr9uSYPsBGM5jP+HbUtLhWGx4g@mail.gmail.com>
References: <DM5PR05MB279324049A2520E959CB8B1B99030@DM5PR05MB2793.namprd05.prod.outlook.com>
 <CAGxFJbQFkRuiWHZAnmmuSdn_Tr9uSYPsBGM5jP+HbUtLhWGx4g@mail.gmail.com>
Message-ID: <CAGxFJbQ0P+BgMFYbD_NnxtOyMzBDPA-+i=f6V9S=tnfTJ645Ew@mail.gmail.com>

Note also that if you wish to include 0 and negative numbers, and your
intent is to truncate to 1 digit towards 0, then you must of course check
for 0 separately and modify what I suggested for x != 0 to:

k <- floor(log10(abs(x)))
ifelse(x <0, ceiling(x*10^(-k)), floor(x*10^(-k))) *10^k

Note that this is all vectorized, so, e.g. ,

> x<- c(-101.8, 101.8)
> k <- floor(log10(abs(x)))
> ifelse(x <0, ceiling(x*10^(-k)), floor(x*10^(-k))) *10^k
[1] -100  100

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 4, 2018 at 11:08 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> This is *not* "rounding down."
>
> But this should do it I think:
> ## (see ?floor)
>
> x <- 3.896e09
> k <- floor(log10(x))
>
> > floor(x*10^(-k))*10^k
> [1] 3e+09
>
> There may be even slicker ways, but this is as slick as I can muster...
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Sep 4, 2018 at 9:33 AM Nelly Reduan <nell.redu at hotmail.fr> wrote:
>
>> Hello,
>>
>>
>>
>> How can I round down numeric values with decimals? For example,
>>
>>
>>
>> > signif(3.896037e+09, digits = 1)
>>
>> [1] 4e+09
>>
>>
>>
>> The expected result is 3e+09 (and not 4e+09).
>>
>>
>>
>> > signif(8.68542378e-10, digits = 1)
>>
>> [1] 9e-10
>>
>>
>>
>> The expected result is 8e-10 (and not 9e-10).
>>
>>
>>
>> Thank you very much for your time.
>>
>> Have a nice day
>>
>> Nell
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From giftedlife2014 @ending from gm@il@com  Wed Sep  5 04:06:25 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 5 Sep 2018 03:06:25 +0100
Subject: [R] Equal Standard Error bar
In-Reply-To: <044a56c442cf4573870f5fe24bfabfab@tamu.edu>
References: <CAC8ss30AWzFAGoeg8xaNFRwXHRMs-9+NnRJcOtch1daViA_ubw@mail.gmail.com>
 <044a56c442cf4573870f5fe24bfabfab@tamu.edu>
Message-ID: <CAC8ss33wBpVc4jketJuhjkkRhL2_9W0YKnFX+vQRLeNaeVELwA@mail.gmail.com>

Hi David,

You are right. Thanks for your time.

The problem is certainly with the data. Plotting part of it gives different
results, usually quite different from the output when the total data is
used. In fact, just as you mentioned, it will look as if it is not the same
code that is used to plot it.

The range is  33469-281856.

Instead of taking time to explain how I fiddled with the range before
getting the plot I attached, let me just attach the whole data. I really
had issues with the range when plotting the whole data (see attached
please).

Many thanks again.

Ogbos



On Tue, Sep 4, 2018 at 9:58 PM David L Carlson <dcarlson at tamu.edu> wrote:

> Thank you for the reproducible data, but it is not the data used in the
> plot you attached and does not plot anything with the code you included.
> The ylim= argument must be modified:
>
> plot(-5:10, oomean, type="b", ylim=c(40000, 120000),
>   xlab="days (epoch is the day of Fd)", ylab="strikes/day",
>   main="Superposed Epoch of all the Events")
> dispersion(-5:10, oomean, oose, arrow.cap=.01)
>
> On the plot of these data it is clear that the error bars are different
> sizes:
>
> range(oose)
> [1] 1728.234 6890.916
>
> What was the range of oose values for the data in the plot you included
> with your message?
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ogbos Okike
> Sent: Tuesday, September 4, 2018 2:35 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] Equal Standard Error bar
>
> Dear List,
>
> I have a dataset of high variability. I conducted epoch analysis and
> attempted to plot the standard error bar alongside.
>
> I am, however, surprised that the error bars are of equal length. I do not
> think that the variability in the data is captured, except there is a kind
> of averaging that smooths out the differences in daily variations. Should
> that be the case, I don't know how and as such need your assistance to
> explain what is going on.
>
> The plot is attached. 71 events are represented in the plot.
>
> The code I use to generate the plot is:
> oodf<-data.frame(A,B)
> library(plotrix)
> std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> oomean<-as.vector(by(oodf$B,oodf$A,mean))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(145000,162000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/day",main="Superposed
> Epoch of all the Events")
> dispersion(-5:10,oomean,oose).
>
> The sample data is:
> -5 64833
> -4 95864
> -3 82322
> -2 95591
> -1 69378
> 0 74281
> 1 103261
> 2 92473
> 3 84344
> 4 127415
> 5 123826
> 6 100029
> 7 76205
> 8 105162
> 9 119533
> 10 106490
> -5 82322
> -4 95591
> -3 69378
> -2 74281
> -1 103261
> 0 92473
> 1 84344
> 2 127415
> 3 123826
> 4 100029
> 5 76205
> 6 105162
> 7 119533
> 8 106490
> 9 114771
> 10 55593
> -5 85694
> -4 65205
> -3 80995
> -2 51723
> -1 62310
> 0 53401
> 1 65677
> 2 76094
> 3 64035
> 4 68290
> 5 73306
> 6 82176
> 7 75566
> 8 89762
> 9 88063
> 10 94395
> -5 80651
> -4 81291
> -3 63702
> -2 70297
> -1 64117
> 0 71219
> 1 57354
> 2 62111
> 3 42252
> 4 35454
> 5 33469
> 6 38899
> 7 64981
> 8 85694
> 9 79452
> 10 85216
> -5 71219
> -4 57354
> -3 62111
> -2 42252
> -1 35454
> 0 33469
> 1 38899
> 2 64981
> 3 85694
> 4 79452
> 5 85216
> 6 81721
> 7 91231
> 8 107074
> 9 108103
> 10 75768
>
>
> You kind help will be greatly appreciated.
>
> Many thanks
>
> Ogbos
>

From @rchhbpn@tejenn @ending from utex@@@edu  Wed Sep  5 01:30:57 2018
From: @rchhbpn@tejenn @ending from utex@@@edu (Nathan D Jennings)
Date: Tue, 4 Sep 2018 18:30:57 -0500
Subject: [R] Help with r script
Message-ID: <663d1062-1801-40db-98a3-699b8c8e6ea4@Spark>

?To the R Project:

I am using R Studio and I need help sum product exponents with R Script. ?Every time I type at the very start in the R Script window like 25* 30 nothing happens. ?Where can I go to find the complete commands for basic functions in the r script window?


Sincerely,


Nathan Jennings

	[[alternative HTML version deleted]]


From philipsm m@ili@g off cp@@el1@stormweb@@et  Wed Sep  5 04:08:59 2018
From: philipsm m@ili@g off cp@@el1@stormweb@@et (philipsm m@ili@g off cp@@el1@stormweb@@et)
Date: Tue, 04 Sep 2018 22:08:59 -0400
Subject: [R] Multi-word column names in a data frame
Message-ID: <20180904220859.Horde._UUjvliZZ6zi537vypqQ-93@webmail.philipsmith.ca>

I am having trouble working with column names in a data frame. My  
column names are multi-word text strings and I like it that way. I  
want to loop through the columns, plotting graphs for each one, and I  
want to use the column names in the chart labels and in the file names  
when I save the charts. Here is a simple reproducible example that  
does not work.

library(dplyr)
`RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
`Number of vegetables` <- c(14,23,45)
`Number of people` <- c(20,30,40)
MyData <- data.frame(RefDate,`Number of vegetables`,`Number of  
people`,check.names=FALSE)
MyVars <- c("Number of vegetables","Number of people")
for (A in MyVars) {
   g2 <- ggplot(MyData,aes(RefDate,eval(parse(text=A)))) + geom_line() +
     labs(title = paste(A," adjusted",sep=""))
   g2
   ggsave(paste(A,".jpg",sep=""),g2,height=5,width=8,dpi=300)
}

Philip


From drjimlemon @ending from gm@il@com  Wed Sep  5 06:22:44 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 5 Sep 2018 14:22:44 +1000
Subject: [R] Multi-word column names in a data frame
In-Reply-To: <20180904220859.Horde._UUjvliZZ6zi537vypqQ-93@webmail.philipsmith.ca>
References: <20180904220859.Horde._UUjvliZZ6zi537vypqQ-93@webmail.philipsmith.ca>
Message-ID: <CA+8X3fXe6=QZB=a2OJM6xGiHoLpjQYDSVxOd96jwt7L07GJKLg@mail.gmail.com>

Hi Philip,
This may work:

library(dplyr)
`RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
`Number of vegetables` <- c(14,23,45)
`Number of people` <- c(20,30,40)
MyData <- data.frame(RefDate,`Number_of_vegetables`,
 `Number_of_people`,check.names=FALSE)
MyVars <- c("Number of vegetables","Number of people")
My_Vars <- c("Number_of_vegetables","Number_of_people")
nnames<-length(MyVars)
for (i in 1:nnames) {
   g2 <- ggplot(MyData,aes(RefDate,eval(parse(text=My_Vars[i])))) +
geom_line() +
     labs(title = paste(MyVars[i]," adjusted",sep=""))
   g2
   ggsave(paste(A,".jpg",sep=""),g2,height=5,width=8,dpi=300)
}

Jim
On Wed, Sep 5, 2018 at 1:22 PM <philipsm at cpanel1.stormweb.net> wrote:
>
> I am having trouble working with column names in a data frame. My
> column names are multi-word text strings and I like it that way. I
> want to loop through the columns, plotting graphs for each one, and I
> want to use the column names in the chart labels and in the file names
> when I save the charts. Here is a simple reproducible example that
> does not work.
>
> library(dplyr)
> `RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
> `Number of vegetables` <- c(14,23,45)
> `Number of people` <- c(20,30,40)
> MyData <- data.frame(RefDate,`Number of vegetables`,`Number of
> people`,check.names=FALSE)
> MyVars <- c("Number of vegetables","Number of people")
> for (A in MyVars) {
>    g2 <- ggplot(MyData,aes(RefDate,eval(parse(text=A)))) + geom_line() +
>      labs(title = paste(A," adjusted",sep=""))
>    g2
>    ggsave(paste(A,".jpg",sep=""),g2,height=5,width=8,dpi=300)
> }
>
> Philip
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Sep  5 06:55:01 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 4 Sep 2018 21:55:01 -0700 (PDT)
Subject: [R] Multi-word column names in a data frame
In-Reply-To: <20180904220859.Horde._UUjvliZZ6zi537vypqQ-93@webmail.philipsmith.ca>
References: <20180904220859.Horde._UUjvliZZ6zi537vypqQ-93@webmail.philipsmith.ca>
Message-ID: <alpine.BSF.2.00.1809042150090.27516@pedal.dcn.davis.ca.us>

a) missing ggplot2 library
b) cannot word wrap in the middle of a string in R without introducing 
newlines
c) aes is not recommended for working with string variables as names... 
use aes_string
d) Because aes_string will parse the string, you need to add the backticks
e) paste0() is a shorter version of paste( sep="" )

##############################
library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(ggplot2)
`RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
`Number of vegetables` <- c(14,23,45)
`Number of people` <- c(20,30,40)
MyData <- data.frame( RefDate
                     , `Number of vegetables`
                     , `Number of people`
                     , check.names = FALSE
                     )
MyVars <- c( "Number of vegetables", "Number of people" )
for ( A in MyVars ) {
   g2 <- ggplot( MyData
               , aes_string( x = RefDate
                           , y = paste0( "`", A, "`" )
                           )
               ) +
     geom_line() +
     labs( title = paste0( A, " adjusted" ) )
   g2
   ggsave( paste0( A, ".jpg" )
         , g2
         , height=5
         , width=8
         , dpi=300
         )
}

#' Created on 2018-09-05 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
###################################33

On Tue, 4 Sep 2018, philipsm at cpanel1.stormweb.net wrote:

> I am having trouble working with column names in a data frame. My column 
> names are multi-word text strings and I like it that way. I want to loop 
> through the columns, plotting graphs for each one, and I want to use the 
> column names in the chart labels and in the file names when I save the 
> charts. Here is a simple reproducible example that does not work.
>
> library(dplyr)
> `RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
> `Number of vegetables` <- c(14,23,45)
> `Number of people` <- c(20,30,40)
> MyData <- data.frame(RefDate,`Number of vegetables`,`Number of 
> people`,check.names=FALSE)
> MyVars <- c("Number of vegetables","Number of people")
> for (A in MyVars) {
> g2 <- ggplot(MyData,aes(RefDate,eval(parse(text=A)))) + geom_line() +
>   labs(title = paste(A," adjusted",sep=""))
> g2
> ggsave(paste(A,".jpg",sep=""),g2,height=5,width=8,dpi=300)
> }
>
> Philip
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Sep  5 07:36:15 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 4 Sep 2018 22:36:15 -0700 (PDT)
Subject: [R] Help with r script
In-Reply-To: <663d1062-1801-40db-98a3-699b8c8e6ea4@Spark>
References: <663d1062-1801-40db-98a3-699b8c8e6ea4@Spark>
Message-ID: <alpine.BSF.2.00.1809042155180.27516@pedal.dcn.davis.ca.us>

On Tue, 4 Sep 2018, Nathan D Jennings wrote:

> ?To the R Project:

This is the R-help mailing list, populated by various people who use R 
including the occasional R-core developer.

> I am using R Studio and I need help sum product exponents with R Script.

a) This is the R-help mailing list, not the RStudio-help mailing list. 
RStudio is only one of numerous user interfaces that can be used to 
interact with R. This mailing list is about the language, not the user 
interface. They do have a forum [1].

> ?Every time I type at the very start in the R Script window like 25* 30 
> nothing happens.

b) I think the window you are describing as the "R Script" window is 
actually a text editor window. All interaction with R occurs in the R 
Console, and the text editor window is a place to keep organized in a file 
the commands you write that seem to do what you want when executed in the 
Console. Usually you will need a number of commands executed in sequence 
to accomplish whatever analysis goal you have, so a text file is a good 
place to keep those commands organized. You can position the cursor on an 
R command in the editor and hold down the control key and press Enter, and 
RStudio will type it into the console window for you. Once you are 
confident those commands work you can use the source() function to have R 
execute the entire file of commands at once. You would look for the 
response/result/output in the Console and/or the Plot windows depending 
which commands you used.

> ?Where can I go to find the complete commands for basic functions in the 
> r script window?

c) I don't think that there is any comprehensive list of commands you can 
give to R. There are many introductory R books, and there is an 
Introduction to R document provided with R [2]. You might find the 
cheatsheets listed under the Help/Cheatsheets menu in RStudio helpful to 
give you some clues. If you want a thorough discussion of the structure of 
the R language you can refer to the R Language Definition [3], but that is 
really rather dense going if you are just starting out... an introductory 
book or the r-intro document would probably be most useful to you at this 
point.

Finally, per the Posting Guide mentioned below this mailing list is not 
appropriate for students doing homework... from your email address I think 
you should have local resources who can boost you up the learning curve 
much more efficiently than we can through a plain text mailing list (or 
even the RStudio forum). In this mailing list, you need to understand 
enough R to be able to post R code that illustrates what isn't working for 
you, along with a clear specification of what you wanted to get.

[1] https://community.rstudio.com/
[2] https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf
[3] https://cran.r-project.org/manuals.html

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From ruipb@rr@d@@ @ending from @@po@pt  Wed Sep  5 09:17:28 2018
From: ruipb@rr@d@@ @ending from @@po@pt (ruipbarradas)
Date: Wed, 05 Sep 2018 08:17:28 +0100
Subject: [R] Help with r script
Message-ID: <mojlpj5t8w4cnbi7h7byle6q.1536131848861@email.android.com>

Hello,
25*30 <Ctrl><Enter>
This is the most basic possible, please google an intro text and run its examples.
Hope this helps,
Rui Barradas?


Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: Nathan D Jennings <archhbpnatejenn at utexas.edu> Data: 05/09/2018  00:30  (GMT+00:00) Para: r-help at r-project.org Assunto: [R] Help with r script 
?To the R Project:

I am using R Studio and I need help sum product exponents with R Script. ?Every time I type at the very start in the R Script window like 25* 30 nothing happens. ?Where can I go to find the complete commands for basic functions in the r script window?


Sincerely,


Nathan Jennings

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From celine_jou@nin @ending from y@hoo@fr  Wed Sep  5 15:34:11 2018
From: celine_jou@nin @ending from y@hoo@fr (Jouanin Celine)
Date: Wed, 5 Sep 2018 13:34:11 +0000 (UTC)
Subject: [R] Convention de stage
References: <1220985191.3018295.1536154451818.ref@mail.yahoo.com>
Message-ID: <1220985191.3018295.1536154451818@mail.yahoo.com>

Bonjour,
Suite ? votre appel la semaine derni?re, je reviens vers vous concernant ma convention de stage et mon entr?e ? Open le 10 septembre.
Avez vous eu des retours pour la signature de celle ci ? Je peux passer demain ou vendredi la chercher afin de la transmettre ? mon organisme de formation.Je vous remercie pour votre retour.

Bien cordialement,C?line Jouanin


	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Wed Sep  5 21:26:36 2018
From: ruipb@rr@d@@ @ending from @@po@pt (ruipbarradas)
Date: Wed, 05 Sep 2018 20:26:36 +0100
Subject: [R] Convention de stage
Message-ID: <8s8wu3j6nvtg49ae711bvp3x.1536175596895@email.android.com>

Bonjour,
Vous ?tes en erreur, cette liste est la liste R-Help pour aider ceux qui ont des doutes sur le langage de programmation R, un langage pour statistique, analyse de donn?s et graphiques scientifiques.
Cordialement,
Rui Barradas


Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: Jouanin Celine via R-help <r-help at r-project.org> Data: 05/09/2018  14:34  (GMT+00:00) Para: emmanuel.jouan at open-groupe.com, "R." <r-help at r-project.org> Assunto: [R] Convention de stage 
Bonjour,
Suite ? votre appel la semaine derni?re, je reviens vers vous concernant ma convention de stage et mon entr?e ? Open le 10 septembre.
Avez vous eu des retours pour la signature de celle ci ? Je peux passer demain ou vendredi la chercher afin de la transmettre ? mon organisme de formation.Je vous remercie pour votre retour.

Bien cordialement,C?line Jouanin


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Wed Sep  5 22:05:02 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Wed, 5 Sep 2018 20:05:02 +0000
Subject: [R] Display time of PDF plots
In-Reply-To: <alpine.LNX.2.20.1809040934080.8839@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1809040934080.8839@salmo.appl-ecosys.com>
Message-ID: <1AAA6D75-B182-48AE-ACE3-F263EDED2DD4@llnl.gov>

(this is somewhat a change of subject from the original question)

Rich, there functions such as aggregate() in base R. There are also many options in CRAN packages.

But I tend to have difficulty getting them to do exactly what I want, and usually end up rolling my own.

The idea is to split the data into groups by station and month, then calculate summary stats for each group, then recombine into a new data frame.

## untested with your data, but this kind of approach works well for me
## note that this code assumes easting, northing, and elevation are in fact unique within each group
## if they are not, you will get an ERROR

## add a 'month' variable
raindf <- rainfall
raindf$mon <- format(raindf$sampdate,'%Y-%m')
  
  mysum <- function(df) {
    data.frame( name=unique(df$name),
               easting=unique(df$easting),
               northing=unique(df$northing),
               elev=unique(df$elev),
               mon=unique(df$mon),
               pr.med=median(df$prcp),
               pr.max=max(df$prcp) )
  }

tmpdf <- split(raindf, paste(raindf$name, raindf$mon) )

## at this point, you can check your summary stats function with, for example,
mysum(tmpdf[[1]])
mysum(tmpdf[[2]])

## when satisfied with mysum(), do this
tmpsum <- lapply(tmpdf, mysum)

## recombine
rain.by.mon <- do.call(rbind, tmpsum)

## might still want to create a numeric month to facilitate plotting
## or maybe assign each month to the first of the month, or the 15th, or end or whatever makes sense
rain.by.mon$mondt <- as.Date(paste0(rain.by.mon$mon,'-1'))




--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/4/18, 9:41 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

    On Mon, 3 Sep 2018, Rich Shepard wrote:
    
    > Is there a process by which these plots can be 'thinned' so they show the
    > same overall patterns but with fewer points so they display more quickly?
    
    Bert/Paul/David/John:
    
       Thanks very much for the suggestions. I think an appropriate way to
    illustrate the patterns is to plot the median and maximum for each month
    (for all sites). That's the important information and plotting each daily
    point over 13 years obscures that information.
    
       The dataframe is structured this way:
    
    str(rainfall)
    'data.frame':	113569 obs. of  6 variables:
      $ name    : chr  "Headworks Portland Water" "Headworks Portland Water" "Headworks Portland Water" "Headworks Portland Water" ...
      $ easting : num  2370575 2370575 2370575 2370575 2370575 ...
      $ northing: num  199338 199338 199338 199338 199338 ...
      $ elev    : num  228 228 228 228 228 228 228 228 228 228 ...
      $ sampdate: Date, format: "2005-01-01" "2005-01-02" ...
      $ prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
    
       There are probably multiple ways of extracting the monthly median and
    maximum 'prcp' and I don't know how to identify the appropriate one. Is
    there a task view for this type of data manipulation? I've not before done
    anything like this and would appreciate a pointer to where I start to learn.
    
    Regards,
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep  5 22:17:54 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 5 Sep 2018 13:17:54 -0700 (PDT)
Subject: [R] Casting Date to char
Message-ID: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>

   I've read the help for as.Date: "Date Conversion Functions to and from
Character" but the method as.character(x ...) isn't working for me:

> str(dp)
'data.frame':	113569 obs. of  2 variables:
  $ rainfall.sampdate: Date, format: "2005-01-01" "2005-01-02" ...
  $ rainfall.prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
> dp$sampdate <- as.Character(dp$sampdate)
Error in `$<-.data.frame`(`*tmp*`, sampdata, value = character(0)) :
   replacement has 0 rows, data has 113569

   I don't understand the error message and want to learn what I've done
incorrectly.

Regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep  5 22:32:56 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 5 Sep 2018 13:32:56 -0700 (PDT)
Subject: [R] Casting Date to char
In-Reply-To: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809051332020.20257@salmo.appl-ecosys.com>

On Wed, 5 Sep 2018, Rich Shepard wrote:

>> dp$sampdate <- as.Character(dp$sampdate)

   This from a failed attempt: as.Character not found. The reported error was
generated by using as.character.

Rich


From murdoch@dunc@n @ending from gm@il@com  Wed Sep  5 22:30:26 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 5 Sep 2018 16:30:26 -0400
Subject: [R] Casting Date to char
In-Reply-To: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
Message-ID: <f88669eb-80c1-68ba-9bf5-26df3f23f2a0@gmail.com>

On 05/09/2018 4:17 PM, Rich Shepard wrote:
>     I've read the help for as.Date: "Date Conversion Functions to and from
> Character" but the method as.character(x ...) isn't working for me:
> 
>> str(dp)
> 'data.frame':	113569 obs. of  2 variables:
>    $ rainfall.sampdate: Date, format: "2005-01-01" "2005-01-02" ...
>    $ rainfall.prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
>> dp$sampdate <- as.Character(dp$sampdate)
> Error in `$<-.data.frame`(`*tmp*`, sampdata, value = character(0)) :
>     replacement has 0 rows, data has 113569

This might just be a typo in your message, but as.character() is the 
function you want, not as.Character().

The other typo or error above is that you are trying to convert 
dp$sampdate, but the dataframe has no column with that name according to 
the lines above.

Duncan Murdoch

> 
>     I don't understand the error message and want to learn what I've done
> incorrectly.
> 
> Regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep  5 22:42:35 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 5 Sep 2018 13:42:35 -0700 (PDT)
Subject: [R] Casting Date to char
In-Reply-To: <f88669eb-80c1-68ba-9bf5-26df3f23f2a0@gmail.com>
References: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
 <f88669eb-80c1-68ba-9bf5-26df3f23f2a0@gmail.com>
Message-ID: <alpine.LNX.2.20.1809051341520.20257@salmo.appl-ecosys.com>

On Wed, 5 Sep 2018, Duncan Murdoch wrote:

> This might just be a typo in your message, but as.character() is the function 
> you want, not as.Character().

Duncan,

   Yes, it is a typo.

> The other typo or error above is that you are trying to convert
> dp$sampdate, but the dataframe has no column with that name according to
> the lines above.

   I now see this.

Many thanks,

Rich


From btupper @ending from bigelow@org  Wed Sep  5 22:51:50 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Wed, 5 Sep 2018 16:51:50 -0400
Subject: [R] Casting Date to char
In-Reply-To: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
Message-ID: <B1606BF8-A7ED-4771-8A4D-DF35355530FA@bigelow.org>

Hi,

Perhaps you wanted to convert dp$rainfall.sampdate and not dp$sampdate like this...

dp$sampdate <- as.character(dp$rainfall.sampdate)

... or even better, take charge of the conversion with format() ...

dp$sampdate <- format(dp$rainfall.sampdate, format = '%Y-%m-%d')

Cheers,
Ben

> On Sep 5, 2018, at 4:17 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I've read the help for as.Date: "Date Conversion Functions to and from
> Character" but the method as.character(x ...) isn't working for me:
> 
>> str(dp)
> 'data.frame':	113569 obs. of  2 variables:
> $ rainfall.sampdate: Date, format: "2005-01-01" "2005-01-02" ...
> $ rainfall.prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
>> dp$sampdate <- as.Character(dp$sampdate)
> Error in `$<-.data.frame`(`*tmp*`, sampdata, value = character(0)) :
>  replacement has 0 rows, data has 113569
> 
>  I don't understand the error message and want to learn what I've done
> incorrectly.
> 
> Regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep  5 22:54:50 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 5 Sep 2018 13:54:50 -0700 (PDT)
Subject: [R] Casting Date to char
In-Reply-To: <B1606BF8-A7ED-4771-8A4D-DF35355530FA@bigelow.org>
References: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
 <B1606BF8-A7ED-4771-8A4D-DF35355530FA@bigelow.org>
Message-ID: <alpine.LNX.2.20.1809051353360.20257@salmo.appl-ecosys.com>

On Wed, 5 Sep 2018, Ben Tupper wrote:

> Perhaps you wanted to convert dp$rainfall.sampdate and not dp$sampdate like this...
>
> dp$sampdate <- as.character(dp$rainfall.sampdate)
>
> ... or even better, take charge of the conversion with format() ...
>
> dp$sampdate <- format(dp$rainfall.sampdate, format = '%Y-%m-%d')

Ben,

   Yep. That's what I want and didn't know how to do. The first conversion I
missed seeing and the second reflects my infamiliarity with format().

Many thanks,

Rich


From d@vid@mi @ending from micro@oft@com  Thu Sep  6 00:08:21 2018
From: d@vid@mi @ending from micro@oft@com (David Smith (CDA))
Date: Wed, 5 Sep 2018 22:08:21 +0000
Subject: [R] Revolutions blog: August 2018 roundup
Message-ID: <DM5PR2101MB10488ACF9F11FB6D7B40294AC8020@DM5PR2101MB1048.namprd21.prod.outlook.com>

Since 2008, Microsoft staff and guests have written about R at the Revolutions
blog (http://blog.revolutionanalytics.com) and every month I post a summary of
articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of August:

A guide to installing R and RStudio with packages and multithreaded BLAS on
various platforms:
http://blog.revolutionanalytics.com/2018/08/installation-guide.html

Some tips for Excel users migrating to R for data analysis:
http://blog.revolutionanalytics.com/2018/08/how-to-use-r-with-excel.html 

Videos of presentations from the New York R Conference:
http://blog.revolutionanalytics.com/2018/08/videos-from-nyc-r-conference.html

The Chartmaker Directory compares and provides examples of data visualizations
for dozens of tools, including R:
http://blog.revolutionanalytics.com/2018/08/chartmaker-directory.html

Siraj Raval's video overview of Azure machine learning services:
http://blog.revolutionanalytics.com/2018/08/aml-video.html

A simple script based on the gganimate package illustrates the luminance
illusion: http://blog.revolutionanalytics.com/2018/08/luminance-illusion.html

Roundup of AI, Machine Learning and Data Science news from August 2018:
http://blog.revolutionanalytics.com/2018/08/ai-roundup-august-2018.html

A package to make R play text as speech:
http://blog.revolutionanalytics.com/2018/08/make-r-speak.html

Microsoft R Open 3.5.1 is now available:
http://blog.revolutionanalytics.com/2018/08/mro-351-now-available.html

R ranks #14 in the June 2018 Redmonk Language Rankings:
http://blog.revolutionanalytics.com/2018/08/redmonk-language-rankings-june-2018.html

R drops one place to #7 in the 2018 IEEE Language Rankings:
http://blog.revolutionanalytics.com/2018/08/ieee-language-rankings-2018.html

A video tutorial on running R and Python in SQL Server from a Jupyter Notebook:
http://blog.revolutionanalytics.com/2018/08/r-python-in-sql-server.html

The cover story for Significance Magazine celebrates 25 years of the R project:
http://blog.revolutionanalytics.com/2018/08/r-generation.html

And some general interest stories (not necessarily related to R):

* The Curiosity Show, the 80's Australian science program for kids:
  http://blog.revolutionanalytics.com/2018/08/because-its-friday-the-curiosity-show.html

* A visualization of the prime factors of the first million integers shows
  surprising structure:
  http://blog.revolutionanalytics.com/2018/08/one-million-integers.html

* Brexit as the Titanic disaster:
  http://blog.revolutionanalytics.com/2018/08/because-its-friday-a-titanic-brexit.html

* An experimental underwater data center gets a fishcam:
  http://blog.revolutionanalytics.com/2018/08/because-its-friday-a-turbine-under-the-sea.html

* A parody commercial for Australia tourism focuses on the "dangers":
  http://blog.revolutionanalytics.com/2018/08/undangerous-australia.html

As always, thanks for the comments and please keep sending suggestions to me at
davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From miluji@b @ending from gm@il@com  Thu Sep  6 00:30:09 2018
From: miluji@b @ending from gm@il@com (Miluji Sb)
Date: Thu, 6 Sep 2018 00:30:09 +0200
Subject: [R] Marginal effects with plm
Message-ID: <CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>

Dear all,

I am running the following panel regression;

plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt, data =
df, index=c("region","year"))

where 'df' is a pdata.frame. I would like to obtain marginal effects of 'y'
for the variable 'x1'. I have tried the packages 'prediction' and 'margins'
without luck.

Is it possible to obtain marginal effects with 'plm'? Any help will be
highly appreciated. Thank you.

Error in UseMethod("predict") :
  no applicable method for 'predict' applied to an object of class
"c('plm', 'panelmodel')"

Sincerely,

Milu

	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Thu Sep  6 01:12:30 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Wed, 5 Sep 2018 23:12:30 +0000
Subject: [R] Marginal effects with plm
In-Reply-To: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
References: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>

Dear Milu,

Depending upon what you mean by "marginal effects," you might try the effects package. For example, for your model, try 

	(Ef.hd <- Effect(c("heat", "debt_dummy"), plm1))
	plot(Ef.hd)

A couple of comments about the model: I'd prefer to specify the formula as log(y) ~ poly(x1, 2) + heat*debt + tt or log(y) ~ poly(x1, 2, raw=TRUE) + heat*debt + tt (assuming that debt_dummy is a precoded dummy regressor for a factor debt).

I hope this helps,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Miluji
> Sb
> Sent: Wednesday, September 5, 2018 6:30 PM
> To: r-help mailing list <r-help at r-project.org>
> Subject: [R] Marginal effects with plm
> 
> Dear all,
> 
> I am running the following panel regression;
> 
> plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt, data
> = df, index=c("region","year"))
> 
> where 'df' is a pdata.frame. I would like to obtain marginal effects of
> 'y'	
> for the variable 'x1'. I have tried the packages 'prediction' and
> 'margins'
> without luck.
> 
> Is it possible to obtain marginal effects with 'plm'? Any help will be
> highly appreciated. Thank you.
> 
> Error in UseMethod("predict") :
>   no applicable method for 'predict' applied to an object of class
> "c('plm', 'panelmodel')"
> 
> Sincerely,
> 
> Milu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Thu Sep  6 04:28:31 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 5 Sep 2018 19:28:31 -0700
Subject: [R] A small thing that amused my small mind
In-Reply-To: <CAGxFJbQ0P+BgMFYbD_NnxtOyMzBDPA-+i=f6V9S=tnfTJ645Ew@mail.gmail.com>
References: <DM5PR05MB279324049A2520E959CB8B1B99030@DM5PR05MB2793.namprd05.prod.outlook.com>
 <CAGxFJbQFkRuiWHZAnmmuSdn_Tr9uSYPsBGM5jP+HbUtLhWGx4g@mail.gmail.com>
 <CAGxFJbQ0P+BgMFYbD_NnxtOyMzBDPA-+i=f6V9S=tnfTJ645Ew@mail.gmail.com>
Message-ID: <CAGxFJbS7p9=nD+TB2TB3JvQ7p-XphakVH8qvw95g2F_URY+kTQ@mail.gmail.com>

A few days ago, someone asked how to truncate arbitrary numerics to 1
digit towards 0. e.g. -189 should become -100 and 254 should become
200; and all values in magniude < 1 should become 0.

I proposed a somewhat clumsy solution using floor() and ceiling(), but
in fooling with it a bit more, I realized that a better way to do it
is to use R's trunc() function. It is simpler and works for all cases
AFAICS. Here's a litte function to do it -- maybe someone else might
find it amusing/instructive:

poof <- function(x){
   ## truncating to 0
## x is a numeric vector
k <- 10^trunc(log10(abs(x)))
ifelse(k, trunc(x/k)*k, k)
}

## test it
> x <- c(0,-.036578, .4876, -189, 254)
> poof(x)
[1]    0    0    0 -100  200

Cheers,
Bert


From Scott@W@ichler @ending from pnnl@gov  Thu Sep  6 07:00:52 2018
From: Scott@W@ichler @ending from pnnl@gov (Waichler, Scott R)
Date: Thu, 6 Sep 2018 05:00:52 +0000
Subject: [R] seq() problem with chron
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881BB21182@EX10MBOX03.pnnl.gov>

Hi, 

I encountered the problem below where the last value in the chron vector created with seq() should have a time of 15:30, but instead has 15:15.  What causes this and how can I make sure that the last value in the chron vector is the same as the "to" value in seq()?

library(chron)
dt1 <- chron("02/20/13", "00:00:00")
dt2 <- chron("07/03/18", "15:30:00")
dt <- seq(from=dt1, to=dt2, by=1/(24*4))
dt[length(dt)]
#[1] (07/03/18 15:15:00)

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
scott.waichler at pnnl.gov


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Sep  6 09:04:10 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 6 Sep 2018 00:04:10 -0700 (PDT)
Subject: [R] Multi-word column names in a data frame
In-Reply-To: <20180905195744.Horde.PwCsZ1Pu2AdI-VDJpD-CJ9-@webmail.philipsmith.ca>
References: <20180905195744.Horde.PwCsZ1Pu2AdI-VDJpD-CJ9-@webmail.philipsmith.ca>
Message-ID: <alpine.BSF.2.00.1809052338150.85393@pedal.dcn.davis.ca.us>

You forgot to reply-all ... I don't do private consulting, so please keep 
the conversation on the mailing list.

Here are some ideas for extending your example. However, whether you WANT 
to or not, you really need to learn to manipulate your data BEFORE you 
give it to ggplot.

#########################################
library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(tidyr)
library(ggplot2)
library(rlang)
`RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
`Number of vegetables` <- c(14,23,45)
`Number of people` <- c(20,30,40)
MyData <- data.frame( RefDate
                     , `Number of vegetables`
                     , `Number of people`
                     , check.names=FALSE
                     )
MyVars <- c("Number of vegetables","Number of people")

# simple approach... notice "RefDate" is a string

for (A in MyVars) {
  g2 <- ggplot( MyData
              , aes_string( x = "RefDate"
                          , y = paste0( "`", A, "`")
                          )
              ) +
    geom_line() +
    labs( title = paste( A, "adjusted" ) )
    print( g2 )
  # ggsave( paste0( A,".jpg" )
  #       ,g2
  #       ,height=5
  #       ,width=8
  #       ,dpi=300
  #       )
}


# Using function FQPC here - works, but an inferior use of ggplot
# because ggplot does not build legends with wide data

FQPC <- function(x) {100*x/lag(x,1)-100} # % change
for (A in MyVars) {
  g2 <- ggplot( MyData
              , aes( x = RefDate
                   , y = FQPC( !!sym( A ) )
                   )
              ) +
    geom_line() +
    labs(title = paste( A,"adjusted" ) )
  print( g2 )
  # ggsave( paste0( A,".jpg" )
  #         ,g2
  #         ,height=5
  #         ,width=8
  #         ,dpi=300
  # )
}
#> Warning: Removed 1 rows containing missing values (geom_path).
#'
#> Warning: Removed 1 rows containing missing values (geom_path).

# superior approach is to do the computations first

for ( A in MyVars ) {
   DF <- MyData[ , c( "RefDate", A ) ]
   DF[[ 2 ]] <- FQPC( DF[[ 2 ]] )
   g2 <- ( ggplot( DF, aes( x = RefDate, y = !!sym( A ) ) )
         + geom_line()
         + labs( title = paste( A,"adjusted" ) )
         )
   print( g2 )
}
#> Warning: Removed 1 rows containing missing values (geom_path).
#'
#> Warning: Removed 1 rows containing missing values (geom_path).

# Another way to do the computations first
resultDF <- data_frame( variable = MyVars
                       , data = lapply( MyVars
                                      , function( A ) {
                                           DF <- setNames( MyData[ , c( "RefDate", A ) ]
                                                         , c( "RefDate", "value" )
                                                         )
                                           DF[[ 2 ]] <- FQPC( DF[[ 2 ]] )
                                           DF
                                        }
                                      )
                       )
for ( i in seq.int( nrow( resultDF ) ) ) {
   A <- resultDF$variable[ i ]
   g2 <- ( ggplot( resultDF$data[[ i ]], aes( x = RefDate, y = value ) )
         + geom_line()
         + ylab( A )
         + labs( title = paste( A, "adjusted" ) )
         )
   print( g2 )
}
#> Warning: Removed 1 rows containing missing values (geom_path).

#'     #> Warning: Removed 1 rows containing missing values (geom_path).

# or put them together in order determined by MyVars:

resultDF %>%
mutate( variable = factor( variable, levels = MyVars ) ) %>%
unnest %>% # flattens separate data frames in data column into one long 
data frame
ggplot( aes( x = RefDate, y = value ) ) +
   geom_line() +
   facet_grid( variable ~ ., scales = "free_y" )
#> Warning: Removed 1 rows containing missing values (geom_path).

#' Created on 2018-09-05 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
#####################################33

On Wed, 5 Sep 2018, philipsm at cpanel1.stormweb.net wrote:

> Thanks again for your help. Your suggested solution using aes_string(), which 
> I was not familiar with, worked perfectly when I plotted the column 
> variables. However, I also want to plot transformations of those variables 
> and the aes_string() approach does not work in that case. I implement the 
> transformations with a function and the function is expecting a numeric 
> rather than a string.
>
> For example, when I use the function:
>
> library(dplyr)
> library(ggplot2)
> `RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
> `Number of vegetables` <- c(14,23,45)
> `Number of people` <- c(20,30,40)
> MyData <- data.frame(RefDate
>                    ,`Number of vegetables`
>                    ,`Number of people`
>                    ,check.names=FALSE
>                    )
> MyVars <- c("Number of vegetables","Number of people")
>
> # No function here - it works
>
> for (A in MyVars) {
> g2 <- ggplot(MyData
>              ,aes_string( x = RefDate
>                         , y = paste0( "`", A, "`")
>                         )
>              ) +
>   geom_line() +
>   labs(title = paste( A,"adjusted" ) )
> g2
> ggsave( paste0( A,".jpg" )
>       ,g2
>       ,height=5
>       ,width=8
>       ,dpi=300
>       )
> }
>
> # Using function FQPC here - it does not work
>
> FQPC <- function(x) {100*x/lag(x,1)-100} # % change
> for (A in MyVars) {
> g2 <- ggplot(MyData
>              ,aes_string( x = RefDate
>                           , y = FQPC(paste0( "`", A, "`"))
>              )
> ) +
>   geom_line() +
>   labs(title = paste( A,"adjusted" ) )
> g2
> ggsave( paste0( A,".jpg" )
>         ,g2
>         ,height=5
>         ,width=8
>         ,dpi=300
> )
> }
>
>
> # I get the error: "Error in 100*x : non-numeric argument to binary 
> operator".
>
> I need some way to convert the string representation of the variable, 'A', 
> back to a column name representation and, presumably, use aes() instead of 
> aes_string(). Any further thoughts about this?
>
> Philip
>
>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From djnordlund @ending from gm@il@com  Thu Sep  6 09:07:02 2018
From: djnordlund @ending from gm@il@com (Daniel Nordlund)
Date: Thu, 6 Sep 2018 00:07:02 -0700
Subject: [R] seq() problem with chron
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB8881BB21182@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB8881BB21182@EX10MBOX03.pnnl.gov>
Message-ID: <c10972e0-c6a0-ceb9-f830-3d4c8fe45327@gmail.com>

On 9/5/2018 10:00 PM, Waichler, Scott R wrote:
> Hi,
> 
> I encountered the problem below where the last value in the chron vector created with seq() should have a time of 15:30, but instead has 15:15.  What causes this and how can I make sure that the last value in the chron vector is the same as the "to" value in seq()?
> 
> library(chron)
> dt1 <- chron("02/20/13", "00:00:00")
> dt2 <- chron("07/03/18", "15:30:00")
> dt <- seq(from=dt1, to=dt2, by=1/(24*4))
> dt[length(dt)]
> #[1] (07/03/18 15:15:00)
> 
> Thanks,
> Scott Waichler
> Pacific Northwest National Laboratory
> scott.waichler at pnnl.gov
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

This is not a chron problem, it is a floating-point arithmetic problem 
(basically, FAQ 7.31).  You are adding incrementing by 1/96, which can't 
be represent exactly in binary representation.  So, when you expected 
that you should get a time of 15:30, it is slightly larger and the 
sequence is stopped at 15:15.

You could change dt2 to be chron("07/03/18", "15:31:00").  Or or you 
could use POSIX datetimes with something like the following, where the 
increment 900 is the number of seconds in 15 minutes.

dt1 <- strptime("02/20/13 00:00:00", "%m/%d/%y %H:%M:%S")
dt2 <- strptime("07/03/18 15:30:00", "%m/%d/%y %H:%M:%S")
dt <- seq(from=dt1, to=dt2, by=900)
dt[length(dt)]

There might also be some useful functions in the lubridate package.


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Sep  6 09:54:25 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 6 Sep 2018 00:54:25 -0700 (PDT)
Subject: [R] seq() problem with chron
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB8881BB21182@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB8881BB21182@EX10MBOX03.pnnl.gov>
Message-ID: <alpine.BSF.2.00.1809060008540.85393@pedal.dcn.davis.ca.us>

See FAQ 7.31... chron uses floating point representation, and there is 
some error accumulating. I also think there may be at least one bug in 
chron::seq.dates(), but I think POSIXct is significantly better than chron 
anywway so I don't intend to debug chron.

#############################
# with chron, avoiding repeated addition of fractional days
library(chron)
dt1 <- chron("02/20/13", "00:00:00")
dt2 <- chron("07/03/18", "15:30:00")
n <- round( 24*4*as.numeric( dt2 - dt1 ) )
length(dt)
#> [1] 1
dt <- dt1 + seq( 0, n ) / 24 / 4
dt[length(dt)]
#> [1] (07/03/18 15:30:00)
# with POSIXct
Sys.setenv( TZ = "GMT" )
DT1 <- as.POSIXct( "02/20/2013 00:00:00", format = "%m/%d/%Y %H:%M:%S" )
DT2 <- as.POSIXct( "07/03/2018 15:30:00", format = "%m/%d/%Y %H:%M:%S" )
# POSIXct is represented as seconds, so no fractions are used
DT <- seq( DT1, DT2, by = as.difftime( 15, units="mins" ) )
DT[length(DT)]
#> [1] "2018-07-03 15:30:00 GMT"

#' Created on 2018-09-06 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
#############################


On Thu, 6 Sep 2018, Waichler, Scott R wrote:

> Hi,
>
> I encountered the problem below where the last value in the chron vector created with seq() should have a time of 15:30, but instead has 15:15.  What causes this and how can I make sure that the last value in the chron vector is the same as the "to" value in seq()?
>
> library(chron)
> dt1 <- chron("02/20/13", "00:00:00")
> dt2 <- chron("07/03/18", "15:30:00")
> dt <- seq(from=dt1, to=dt2, by=1/(24*4))
> dt[length(dt)]
> #[1] (07/03/18 15:15:00)
>
> Thanks,
> Scott Waichler
> Pacific Northwest National Laboratory
> scott.waichler at pnnl.gov
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From miluji@b @ending from gm@il@com  Thu Sep  6 11:37:10 2018
From: miluji@b @ending from gm@il@com (Miluji Sb)
Date: Thu, 6 Sep 2018 11:37:10 +0200
Subject: [R] Marginal effects with plm
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>
References: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAMLwc7OGY2cfy0ruwPNwCD-QnAJ0ePqf+6H0UBjAF4PeR3NcuQ@mail.gmail.com>

Dear John,

Thank you very much for the solution and the suggestion. I have tried the
following;

plm1 <- plm(formula = log(gva_ind) ~  poly(x1, 2, raw=TRUE) +
heat*debt_dummy + tt, data = df, index=c("region","year"))

Ef.hd <- Effect(c("heat", "debt_dummy"), plm1)

But get the following error;  - Error in UseMethod("droplevels") : no
applicable method for 'droplevels' applied to an object of class "NULL"

Is this something to do with the way the plm object? Thanks again!

Sincerely,

Milu

On Thu, Sep 6, 2018 at 1:12 AM Fox, John <jfox at mcmaster.ca> wrote:

> Dear Milu,
>
> Depending upon what you mean by "marginal effects," you might try the
> effects package. For example, for your model, try
>
>         (Ef.hd <- Effect(c("heat", "debt_dummy"), plm1))
>         plot(Ef.hd)
>
> A couple of comments about the model: I'd prefer to specify the formula as
> log(y) ~ poly(x1, 2) + heat*debt + tt or log(y) ~ poly(x1, 2, raw=TRUE) +
> heat*debt + tt (assuming that debt_dummy is a precoded dummy regressor for
> a factor debt).
>
> I hope this helps,
>  John
>
> --------------------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Miluji
> > Sb
> > Sent: Wednesday, September 5, 2018 6:30 PM
> > To: r-help mailing list <r-help at r-project.org>
> > Subject: [R] Marginal effects with plm
> >
> > Dear all,
> >
> > I am running the following panel regression;
> >
> > plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt, data
> > = df, index=c("region","year"))
> >
> > where 'df' is a pdata.frame. I would like to obtain marginal effects of
> > 'y'
> > for the variable 'x1'. I have tried the packages 'prediction' and
> > 'margins'
> > without luck.
> >
> > Is it possible to obtain marginal effects with 'plm'? Any help will be
> > highly appreciated. Thank you.
> >
> > Error in UseMethod("predict") :
> >   no applicable method for 'predict' applied to an object of class
> > "c('plm', 'panelmodel')"
> >
> > Sincerely,
> >
> > Milu
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@@@k@@h @ending from gm@il@com  Thu Sep  6 12:43:05 2018
From: @@@@k@@h @ending from gm@il@com (Aakash Kumar)
Date: Thu, 6 Sep 2018 16:13:05 +0530
Subject: [R] Query on read.xls function in gdata
In-Reply-To: <CAEd2DY+3ShFOqeVaxMCwZnkvW5zTdqQJMsjA6ywBVpbMqdO7Cg@mail.gmail.com>
References: <CAEd2DYJkz1n7ozF9qOqNen01dfo7+MUhpLj3RfU8WUN8+pAHmA@mail.gmail.com>
 <CAEd2DYL6BLMC8jMr-Pst6Q-PXH0r2LApoL2adJxmhNfE84sw6g@mail.gmail.com>
 <CAEd2DYKb0QmkxLUF0_LGnu46Gjbpz+2aKUj7JvhFCzFcV_Hdsw@mail.gmail.com>
 <CAEd2DYLT+AHmpO0+uESQ4ygVMPeJySrxh20xvxw=9TH1PB0wfA@mail.gmail.com>
 <CAEd2DYKO7HoTtMLP_t=RGBC4B9AjKrfThHBZXRajnrC=OPw2dA@mail.gmail.com>
 <CAEd2DY+cundHG_EhfFWx9qvRRdFNEdA6z-vSd0=2P5X1gwVizw@mail.gmail.com>
 <CAEd2DY+3ShFOqeVaxMCwZnkvW5zTdqQJMsjA6ywBVpbMqdO7Cg@mail.gmail.com>
Message-ID: <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>

Hi Team,

I am trying to read in .xls files in R using read.xls function present in
gdata package. I have installed the required perl dependencies as well.
Yet, I am facing the following error.

"*Error in xls2sep : Intermediate file is missing*"

Could someone please help me out understanding the cause and if possible, a
fix for the same?

Thanks in advance!

Regards,
Aakash

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Thu Sep  6 13:30:26 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 6 Sep 2018 11:30:26 +0000
Subject: [R] Query on read.xls function in gdata
In-Reply-To: <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>
References: <CAEd2DYJkz1n7ozF9qOqNen01dfo7+MUhpLj3RfU8WUN8+pAHmA@mail.gmail.com>
 <CAEd2DYL6BLMC8jMr-Pst6Q-PXH0r2LApoL2adJxmhNfE84sw6g@mail.gmail.com>
 <CAEd2DYKb0QmkxLUF0_LGnu46Gjbpz+2aKUj7JvhFCzFcV_Hdsw@mail.gmail.com>
 <CAEd2DYLT+AHmpO0+uESQ4ygVMPeJySrxh20xvxw=9TH1PB0wfA@mail.gmail.com>
 <CAEd2DYKO7HoTtMLP_t=RGBC4B9AjKrfThHBZXRajnrC=OPw2dA@mail.gmail.com>
 <CAEd2DY+cundHG_EhfFWx9qvRRdFNEdA6z-vSd0=2P5X1gwVizw@mail.gmail.com>
 <CAEd2DY+3ShFOqeVaxMCwZnkvW5zTdqQJMsjA6ywBVpbMqdO7Cg@mail.gmail.com>
 <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>
Message-ID: <1a746e7561a24a12ab986159a88273ed@SRVEXCHCM1302.precheza.cz>

Hi

If you do not need to stick with gdata you could try package readxl, it does not need any further packages.

https://cran.r-project.org/web/packages/readxl/readxl.pdf

It results in tibble data but change to data.frame is easy.

Cheers
Petr
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Aakash Kumar
> Sent: Thursday, September 6, 2018 12:43 PM
> To: r-help at r-project.org
> Subject: [R] Query on read.xls function in gdata
>
> Hi Team,
>
> I am trying to read in .xls files in R using read.xls function present in gdata
> package. I have installed the required perl dependencies as well.
> Yet, I am facing the following error.
>
> "*Error in xls2sep : Intermediate file is missing*"
>
> Could someone please help me out understanding the cause and if possible, a
> fix for the same?
>
> Thanks in advance!
>
> Regards,
> Aakash
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From jfox @ending from mcm@@ter@c@  Thu Sep  6 14:16:01 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Thu, 6 Sep 2018 12:16:01 +0000
Subject: [R] Marginal effects with plm
In-Reply-To: <CAMLwc7OGY2cfy0ruwPNwCD-QnAJ0ePqf+6H0UBjAF4PeR3NcuQ@mail.gmail.com>
References: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>
 <CAMLwc7OGY2cfy0ruwPNwCD-QnAJ0ePqf+6H0UBjAF4PeR3NcuQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368A7D2B@FHSDB2D11-2.csu.mcmaster.ca>

Dear Milu,

Effect() doesn't have a specific plm method so the default method is invoked. Before responding to your initial question. I tried Effect() with an example from ?plm and it worked.

Without a reproducible example that produces the error that you encountered, there's no way to answer your question.

Best,
 John

> -----Original Message-----
> From: Miluji Sb [mailto:milujisb at gmail.com]
> Sent: Thursday, September 6, 2018 5:37 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Marginal effects with plm
> 
> Dear John,
> 
> Thank you very much for the solution and the suggestion. I have tried the
> following;
> 
> plm1 <- plm(formula = log(gva_ind) ~  poly(x1, 2, raw=TRUE) +
> heat*debt_dummy + tt, data = df, index=c("region","year"))
> 
> Ef.hd <- Effect(c("heat", "debt_dummy"), plm1)
> 
> 
> But get the following error;  - Error in UseMethod("droplevels") : no applicable
> method for 'droplevels' applied to an object of class "NULL"
> 
> Is this something to do with the way the plm object? Thanks again!
> 
> Sincerely,
> 
> Milu
> 
> On Thu, Sep 6, 2018 at 1:12 AM Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Milu,
> 
> 	Depending upon what you mean by "marginal effects," you might try
> the effects package. For example, for your model, try
> 
> 	        (Ef.hd <- Effect(c("heat", "debt_dummy"), plm1))
> 	        plot(Ef.hd)
> 
> 	A couple of comments about the model: I'd prefer to specify the
> formula as log(y) ~ poly(x1, 2) + heat*debt + tt or log(y) ~ poly(x1, 2,
> raw=TRUE) + heat*debt + tt (assuming that debt_dummy is a precoded
> dummy regressor for a factor debt).
> 
> 	I hope this helps,
> 	 John
> 
> 	--------------------------------------
> 	John Fox, Professor Emeritus
> 	McMaster University
> 	Hamilton, Ontario, Canada
> 	Web: socialsciences.mcmaster.ca/jfox/
> <http://socialsciences.mcmaster.ca/jfox/>
> 
> 
> 
> 	> -----Original Message-----
> 	> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org> ] On Behalf Of Miluji
> 	> Sb
> 	> Sent: Wednesday, September 5, 2018 6:30 PM
> 	> To: r-help mailing list <r-help at r-project.org <mailto:r-help at r-
> project.org> >
> 	> Subject: [R] Marginal effects with plm
> 	>
> 	> Dear all,
> 	>
> 	> I am running the following panel regression;
> 	>
> 	> plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt,
> data
> 	> = df, index=c("region","year"))
> 	>
> 	> where 'df' is a pdata.frame. I would like to obtain marginal effects of
> 	> 'y'
> 	> for the variable 'x1'. I have tried the packages 'prediction' and
> 	> 'margins'
> 	> without luck.
> 	>
> 	> Is it possible to obtain marginal effects with 'plm'? Any help will be
> 	> highly appreciated. Thank you.
> 	>
> 	> Error in UseMethod("predict") :
> 	>   no applicable method for 'predict' applied to an object of class
> 	> "c('plm', 'panelmodel')"
> 	>
> 	> Sincerely,
> 	>
> 	> Milu
> 	>
> 	>       [[alternative HTML version deleted]]
> 	>
> 	> ______________________________________________
> 	> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list --
> To UNSUBSCRIBE and more, see
> 	> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> PLEASE do read the posting guide http://www.R-project.org/posting-
> 	> guide.html
> 	> and provide commented, minimal, self-contained, reproducible
> code.
> 


From miluji@b @ending from gm@il@com  Thu Sep  6 14:51:48 2018
From: miluji@b @ending from gm@il@com (Miluji Sb)
Date: Thu, 6 Sep 2018 14:51:48 +0200
Subject: [R] Marginal effects with plm
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8368A7D2B@FHSDB2D11-2.csu.mcmaster.ca>
References: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>
 <CAMLwc7OGY2cfy0ruwPNwCD-QnAJ0ePqf+6H0UBjAF4PeR3NcuQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7D2B@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAMLwc7N9HL7z53vFUxvPweKHnJ9oVMf0sFVF2Wqtfz3T=rx=mQ@mail.gmail.com>

Dear John,

Apologies for not providing reproducible example. I just tried with a plm
example but ran into the same issue;

library(plm)
data("Produc", package = "plm")
zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc,
index = c("state","year"))

Ef.hd <- Effect(c("pc", "emp", "unemp"), zz)

Error in UseMethod("droplevels") :
  no applicable method for 'droplevels' applied to an object of class "NULL"

What am I doing wrong? Thanks again.

Sincerely,

Milu

	[[alternative HTML version deleted]]


From i@t@z@hn @ending from gm@il@com  Thu Sep  6 15:03:47 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Thu, 6 Sep 2018 09:03:47 -0400
Subject: [R] Marginal effects with plm
In-Reply-To: <CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
References: <CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
Message-ID: <CA+vqiLGH5Ybr43mnVkEzt4cn6HworjLy=rf6ZkhYCmiJV9VDMQ@mail.gmail.com>

You might be interested in the "prediction" and "margins" packages.

--Ista

On Wed, Sep 5, 2018 at 6:30 PM Miluji Sb <milujisb at gmail.com> wrote:
>
> Dear all,
>
> I am running the following panel regression;
>
> plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt, data =
> df, index=c("region","year"))
>
> where 'df' is a pdata.frame. I would like to obtain marginal effects of 'y'
> for the variable 'x1'. I have tried the packages 'prediction' and 'margins'
> without luck.
>
> Is it possible to obtain marginal effects with 'plm'? Any help will be
> highly appreciated. Thank you.
>
> Error in UseMethod("predict") :
>   no applicable method for 'predict' applied to an object of class
> "c('plm', 'panelmodel')"
>
> Sincerely,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Sep  6 15:14:52 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 06 Sep 2018 06:14:52 -0700
Subject: [R] Query on read.xls function in gdata
In-Reply-To: <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>
References: <CAEd2DYJkz1n7ozF9qOqNen01dfo7+MUhpLj3RfU8WUN8+pAHmA@mail.gmail.com>
 <CAEd2DYL6BLMC8jMr-Pst6Q-PXH0r2LApoL2adJxmhNfE84sw6g@mail.gmail.com>
 <CAEd2DYKb0QmkxLUF0_LGnu46Gjbpz+2aKUj7JvhFCzFcV_Hdsw@mail.gmail.com>
 <CAEd2DYLT+AHmpO0+uESQ4ygVMPeJySrxh20xvxw=9TH1PB0wfA@mail.gmail.com>
 <CAEd2DYKO7HoTtMLP_t=RGBC4B9AjKrfThHBZXRajnrC=OPw2dA@mail.gmail.com>
 <CAEd2DY+cundHG_EhfFWx9qvRRdFNEdA6z-vSd0=2P5X1gwVizw@mail.gmail.com>
 <CAEd2DY+3ShFOqeVaxMCwZnkvW5zTdqQJMsjA6ywBVpbMqdO7Cg@mail.gmail.com>
 <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>
Message-ID: <30116570-C704-4E8E-BD2B-897FE79370D2@dcn.davis.ca.us>

Without a reproducible example that is highly unlikely to happen.

However, you might just want to try the openxlsx or readxl packages instead.

On September 6, 2018 3:43:05 AM PDT, Aakash Kumar <ssaakash at gmail.com> wrote:
>Hi Team,
>
>I am trying to read in .xls files in R using read.xls function present
>in
>gdata package. I have installed the required perl dependencies as well.
>Yet, I am facing the following error.
>
>"*Error in xls2sep : Intermediate file is missing*"
>
>Could someone please help me out understanding the cause and if
>possible, a
>fix for the same?
>
>Thanks in advance!
>
>Regards,
>Aakash
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From miluji@b @ending from gm@il@com  Thu Sep  6 15:12:51 2018
From: miluji@b @ending from gm@il@com (Miluji Sb)
Date: Thu, 6 Sep 2018 15:12:51 +0200
Subject: [R] Marginal effects with plm
In-Reply-To: <CA+vqiLGH5Ybr43mnVkEzt4cn6HworjLy=rf6ZkhYCmiJV9VDMQ@mail.gmail.com>
References: <CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
 <CA+vqiLGH5Ybr43mnVkEzt4cn6HworjLy=rf6ZkhYCmiJV9VDMQ@mail.gmail.com>
Message-ID: <CAMLwc7MbzuJ9dtbjrh+ud8CX_hGPm6zLyGUb6QGFH1Ukan4t=w@mail.gmail.com>

Dear Ista,

Thanks for your reply. I tried both "prediction" and "margins" but neither
of them seem to work  with plm.

Sincerely,

Milu

On Thu, Sep 6, 2018 at 3:04 PM Ista Zahn <istazahn at gmail.com> wrote:

> You might be interested in the "prediction" and "margins" packages.
>
> --Ista
>
> On Wed, Sep 5, 2018 at 6:30 PM Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Dear all,
> >
> > I am running the following panel regression;
> >
> > plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt, data
> =
> > df, index=c("region","year"))
> >
> > where 'df' is a pdata.frame. I would like to obtain marginal effects of
> 'y'
> > for the variable 'x1'. I have tried the packages 'prediction' and
> 'margins'
> > without luck.
> >
> > Is it possible to obtain marginal effects with 'plm'? Any help will be
> > highly appreciated. Thank you.
> >
> > Error in UseMethod("predict") :
> >   no applicable method for 'predict' applied to an object of class
> > "c('plm', 'panelmodel')"
> >
> > Sincerely,
> >
> > Milu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Thu Sep  6 15:24:14 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 6 Sep 2018 13:24:14 +0000
Subject: [R] Query on read.xls function in gdata
In-Reply-To: <CAEd2DYJHBR9h_jGhurWUECMxntRrWepfa28Gfir=vn6R+kuf_A@mail.gmail.com>
References: <CAEd2DYJkz1n7ozF9qOqNen01dfo7+MUhpLj3RfU8WUN8+pAHmA@mail.gmail.com>
 <CAEd2DYL6BLMC8jMr-Pst6Q-PXH0r2LApoL2adJxmhNfE84sw6g@mail.gmail.com>
 <CAEd2DYKb0QmkxLUF0_LGnu46Gjbpz+2aKUj7JvhFCzFcV_Hdsw@mail.gmail.com>
 <CAEd2DYLT+AHmpO0+uESQ4ygVMPeJySrxh20xvxw=9TH1PB0wfA@mail.gmail.com>
 <CAEd2DYKO7HoTtMLP_t=RGBC4B9AjKrfThHBZXRajnrC=OPw2dA@mail.gmail.com>
 <CAEd2DY+cundHG_EhfFWx9qvRRdFNEdA6z-vSd0=2P5X1gwVizw@mail.gmail.com>
 <CAEd2DY+3ShFOqeVaxMCwZnkvW5zTdqQJMsjA6ywBVpbMqdO7Cg@mail.gmail.com>
 <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>
 <1a746e7561a24a12ab986159a88273ed@SRVEXCHCM1302.precheza.cz>
 <CAEd2DYJHBR9h_jGhurWUECMxntRrWepfa28Gfir=vn6R+kuf_A@mail.gmail.com>
Message-ID: <6e7e9ef233524d33afec1689ba8ce106@SRVEXCHCM1302.precheza.cz>

Hi

You need to help yourself. My guess is that you did not tell to read_excel function where is your excel file.

When the file is in working directory it works seamlessly.

> library(readxl)
> read_excel("ebc.xlsx")
# A tibble: 8 x 16
  material   Rok osoby    `8oh` `8ohg` `5ohm`  otyr `3tyr`   mda   hhe   hne
  <chr>    <dbl> <chr>    <dbl>  <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>
1 tio2     2012. vyroba     25.    35.    25.   38.    42.   40.   40.   40.
2 tio2     2013. vyroba     38.    46.    35.   45.    48.   45.   55.   45.
3 tio2     2012. kontrola   10.    12.    12.   28.    14.   20.   15.   15.
4 tio2     2013. kontrola   17.    15.    17.   18.    20.   20.   15.   20.
5 fe2o3    2013. vyroba     28.    32.    25.   28.    29.   32.   30.   32.
6 fe2o3    2013. kontrola   17.    15.    17.   18.    20.   20.   17.   19.
7 kompozit 2016. vyroba     28.    37.    28.   32.    32.   25.   25.   25.
8 kompozit 2016. kontrola   20.    20.    20.   22.    22.   18.   20.   20.
# ... with 5 more variables: `8iso` <dbl>, ltb4 <dbl>, ltc4 <dbl>, ltd4 <dbl>,
#   lte4 <dbl>
>

You should either to disclose to read function where is your excel file or change working directory or copy excel file to your working directory, whatever is easiest and most convenient to you.

Cheers
Petr


From: Aakash Kumar <ssaakash at gmail.com>
Sent: Thursday, September 6, 2018 2:48 PM
To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
Subject: RE: [R] Query on read.xls function in gdata

Thanks for the suggestion, Petr.

I did try using read_xls and read_excel functions, but I got an error :

"Error in read_fun : Failed to open .xls file"

The file can be manually opened though.

It would be very helpful if you could help me out with this.

Thanks.

Regards,
Aakash


On 06-Sep-2018 17:00, "PIKAL Petr" <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

If you do not need to stick with gdata you could try package readxl, it does not need any further packages.

https://cran.r-project.org/web/packages/readxl/readxl.pdf

It results in tibble data but change to data.frame is easy.

Cheers
Petr
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Aakash Kumar
> Sent: Thursday, September 6, 2018 12:43 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Query on read.xls function in gdata
>
> Hi Team,
>
> I am trying to read in .xls files in R using read.xls function present in gdata
> package. I have installed the required perl dependencies as well.
> Yet, I am facing the following error.
>
> "*Error in xls2sep : Intermediate file is missing*"
>
> Could someone please help me out understanding the cause and if possible, a
> fix for the same?
>
> Thanks in advance!
>
> Regards,
> Aakash
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Thu Sep  6 16:03:07 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Thu, 6 Sep 2018 14:03:07 +0000
Subject: [R] Marginal effects with plm
In-Reply-To: <CAMLwc7N9HL7z53vFUxvPweKHnJ9oVMf0sFVF2Wqtfz3T=rx=mQ@mail.gmail.com>
References: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>
 <CAMLwc7OGY2cfy0ruwPNwCD-QnAJ0ePqf+6H0UBjAF4PeR3NcuQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7D2B@FHSDB2D11-2.csu.mcmaster.ca>
 <CAMLwc7N9HL7z53vFUxvPweKHnJ9oVMf0sFVF2Wqtfz3T=rx=mQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368A7EA5@FHSDB2D11-2.csu.mcmaster.ca>

Dear Milu,

I get the same error as you with this example -- I tried a different plm model -- which of course is why a reproducible example is a good idea.

Here's where the error is:

----------- snip -----------

> Ef.hd <- Effect(c("pc", "emp", "unemp"), zz)
Error in UseMethod("droplevels") : 
  no applicable method for 'droplevels' applied to an object of class "NULL"
> traceback()
10: droplevels(index)
9: model.frame.pFormula(formula = log(gsp) ~ log(pcap) + log(pc) + 
       log(emp) + unemp, data = Produc, drop.unused.levels = TRUE)
8: stats::model.frame(formula = log(gsp) ~ log(pcap) + log(pc) + 
       log(emp) + unemp, data = Produc, drop.unused.levels = TRUE)
7: eval(mf, parent.frame())
6: eval(mf, parent.frame())
5: glm(formula = log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, 
       data = Produc, control = list(epsilon = 1, maxit = 1, trace = FALSE))
4: eval(cl)
3: eval(cl)
2: Effect.default(c("pc", "emp", "unemp"), zz)
1: Effect(c("pc", "emp", "unemp"), zz)

----------- snip -----------

So the error is in model.frame.pFormula(), which is from the plm package. It would probably require substantial effort to get this to work.

Best,
 John


> -----Original Message-----
> From: Miluji Sb [mailto:milujisb at gmail.com]
> Sent: Thursday, September 6, 2018 8:52 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Marginal effects with plm
> 
> Dear John,
> 
> Apologies for not providing reproducible example. I just tried with a
> plm example but ran into the same issue;
> 
> library(plm)
> data("Produc", package = "plm")
> zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data =
> Produc, index = c("state","year"))
> 
> Ef.hd <- Effect(c("pc", "emp", "unemp"), zz)
> 
> Error in UseMethod("droplevels") :
>   no applicable method for 'droplevels' applied to an object of class
> "NULL"
> 
> What am I doing wrong? Thanks again.
> 
> Sincerely,
> 
> Milu

From @k@h@y_e4 @ending from hotm@il@com  Fri Sep  7 10:26:22 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Fri, 7 Sep 2018 08:26:22 +0000
Subject: [R] histogram in GNU R....
Message-ID: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I am running R on Linux AWS ec2 instance.
When I try to create a histogram in it, I am running into problems:

> xht <- c(1,2,3,4,5,6,7,8,9,10)
>  hist(xht)
>

when I type hist(xht), it goes to the next prompt. More importantly, there is no error message. So, the most probable conclusion is that the command gets executed. But there is no pop up screen with a histogram, and nothing else...

whats going on?

How can I circumvent the help of histogram(which is not available in GNU R)? summary(xht) would help, but not much. Any other function that can give information, in LINUX R, that a histogram gives, in LINUX CLI?

Very many thanks for your time and effort...
Yours sincerely,
AKSHAYM KULKARNI

	[[alternative HTML version deleted]]


From krylov@r00t @ending from gm@il@com  Fri Sep  7 10:56:07 2018
From: krylov@r00t @ending from gm@il@com (Ivan Krylov)
Date: Fri, 7 Sep 2018 11:56:07 +0300
Subject: [R] histogram in GNU R....
In-Reply-To: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <20180907115607.46c7857b@Tarkus>

On Fri, 7 Sep 2018 08:26:22 +0000
akshay kulkarni <akshay_e4 at hotmail.com> wrote:

> when I type hist(xht), it goes to the next prompt. More importantly,
> there is no error message. So, the most probable conclusion is that
> the command gets executed

Yes, hist() returns its value invisibly (try typing "? invisible" in
the R prompt without the quotes), which means that you don't see it, but
you can assign it to a variable and then view as usual:

> xht <- c(1,2,3,4,5,6,7,8,9,10)
> hxt <- hist(xht)
> hxt

You can also use the following trick:

> (hist(xht))

to see the invisible returned value without assigning it to a temporary
variable.

> But there is no pop up screen with a histogram, and nothing else...

As to why you cannot see a plot, it depends a lot on your setup. For
example, how exactly do you connect to the R instance running at AWS?
If you use plain SSH from your own Linux machine, try `ssh -X` to allow
the remote server to connect to the X graphics system on your machine
and display windows (alas, it gets very slow). What does `dev.cur()`
show after you run `hist(xht)`? On my machine, when I start R with no
available X connection, it automatically switches to the
non-interactive `pdf` graphics device; all plots get redirected to the
`Rplots.pdf` file in the current directory. Perhaps you can download
that file from the EC2 instance and view it locally?

-- 
Best regards,
Ivan


From pd@lgd @ending from gm@il@com  Fri Sep  7 11:08:03 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Fri, 7 Sep 2018 11:08:03 +0200
Subject: [R] histogram in GNU R....
In-Reply-To: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <C627B316-B767-42A1-B936-B5D64F35EEFD@gmail.com>

You are most likely plotting to a non-screen device. Check dev.list() after the hist(), and then the documentation for that device. It's probably pdf, and after quitting R, you should find that a file Rplots.pdf has been created.

-pd

> On 7 Sep 2018, at 10:26 , akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> 
> dear members,
>                             I am running R on Linux AWS ec2 instance.
> When I try to create a histogram in it, I am running into problems:
> 
>> xht <- c(1,2,3,4,5,6,7,8,9,10)
>> hist(xht)
>> 
> 
> when I type hist(xht), it goes to the next prompt. More importantly, there is no error message. So, the most probable conclusion is that the command gets executed. But there is no pop up screen with a histogram, and nothing else...
> 
> whats going on?
> 
> How can I circumvent the help of histogram(which is not available in GNU R)? summary(xht) would help, but not much. Any other function that can give information, in LINUX R, that a histogram gives, in LINUX CLI?
> 
> Very many thanks for your time and effort...
> Yours sincerely,
> AKSHAYM KULKARNI
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From deep@m@hm@ii@c @ending from gm@il@com  Fri Sep  7 12:08:20 2018
From: deep@m@hm@ii@c @ending from gm@il@com (Deepa)
Date: Fri, 7 Sep 2018 15:38:20 +0530
Subject: [R] Efficient way of loading files in R
Message-ID: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>

Hello,

I am using a bioconductor package in R.
The command that I use reads the contents of a file downloaded from a
database and creates an expression object.

The syntax works perfectly fine when the input size is of 10 MB. Whereas,
when the file size is around 40MB the object isn't created.

Is there an efficient way of loading a large input file to create the
expression object?

This is my code,


library(gcrma)
library(limma)
library(biomaRt)
library(GEOquery)
library(Biobase)
require(GEOquery)
require(Biobase)
gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB

##gseEset2 doesn't load and isn't created

Many thanks

	[[alternative HTML version deleted]]


From deep@m@hm@ii@c @ending from gm@il@com  Fri Sep  7 12:10:30 2018
From: deep@m@hm@ii@c @ending from gm@il@com (Deepa)
Date: Fri, 7 Sep 2018 15:40:30 +0530
Subject: [R] Efficient way of loading files in R
In-Reply-To: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
Message-ID: <CAGchuN5Hq0Zf4SvqaSudFXqED_ESoFWMpqDnouD53h7rB1bV9Q@mail.gmail.com>

The following is the system configuration:
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                4
On-line CPU(s) list:   0-3
Thread(s) per core:    2
Core(s) per socket:    2
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 142
Model name:            Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz
Stepping:              9
CPU MHz:               2844.008
CPU max MHz:           3500.0000
CPU min MHz:           400.0000
BogoMIPS:              5808.00
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              4096K
NUMA node0 CPU(s):     0-3


On Fri, Sep 7, 2018 at 3:38 PM Deepa <deepamahm.iisc at gmail.com> wrote:

> Hello,
>
> I am using a bioconductor package in R.
> The command that I use reads the contents of a file downloaded from a
> database and creates an expression object.
>
> The syntax works perfectly fine when the input size is of 10 MB. Whereas,
> when the file size is around 40MB the object isn't created.
>
> Is there an efficient way of loading a large input file to create the
> expression object?
>
> This is my code,
>
>
> library(gcrma)
> library(limma)
> library(biomaRt)
> library(GEOquery)
> library(Biobase)
> require(GEOquery)
> require(Biobase)
> gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
> gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
>
> ##gseEset2 doesn't load and isn't created
>
> Many thanks
>
>
>

	[[alternative HTML version deleted]]


From prof@@mit@mitt@l @ending from gm@il@com  Fri Sep  7 12:11:58 2018
From: prof@@mit@mitt@l @ending from gm@il@com (Amit Mittal)
Date: Fri, 7 Sep 2018 15:41:58 +0530
Subject: [R] Efficient way of loading files in R
In-Reply-To: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
Message-ID: <CAP8zaQCaC49nMfgGJqWMYDjLL+gg8weM4h5V-87bnr+KQoBafQ@mail.gmail.com>

getgeo() seems to be a custom routine. Import the file in reader and
confirm that's a CSV file from Excel. If this is a non standard input,
custom subroutine is creating new constraints. Usually R has no problem
till workspace is 1 gb

On Fri 7 Sep, 2018, 15:38 Deepa, <deepamahm.iisc at gmail.com> wrote:

> Hello,
>
> I am using a bioconductor package in R.
> The command that I use reads the contents of a file downloaded from a
> database and creates an expression object.
>
> The syntax works perfectly fine when the input size is of 10 MB. Whereas,
> when the file size is around 40MB the object isn't created.
>
> Is there an efficient way of loading a large input file to create the
> expression object?
>
> This is my code,
>
>
> library(gcrma)
> library(limma)
> library(biomaRt)
> library(GEOquery)
> library(Biobase)
> require(GEOquery)
> require(Biobase)
> gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
> gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
>
> ##gseEset2 doesn't load and isn't created
>
> Many thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 

______________________________

Amit Mittal
Pursuing Ph.D. in Finance and Accounting
Indian Institute of Management, Lucknow
Visit my SSRN author page:
http://ssrn.com/author=2665511
* Top 10% Downloaded Author on SSRN
Mob: +91 7525023664

This message has been sent from a mobile device. I may contact you again.

_________________

	[[alternative HTML version deleted]]


From mtmorg@n@bioc @ending from gm@il@com  Fri Sep  7 12:14:58 2018
From: mtmorg@n@bioc @ending from gm@il@com (Martin Morgan)
Date: Fri, 7 Sep 2018 06:14:58 -0400
Subject: [R] Efficient way of loading files in R
In-Reply-To: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
Message-ID: <0b51bc32-4a72-7907-fcb3-8701bf5b4da1@gmail.com>

Ask on the Bioconductor support site https://support.bioconductor.org

Provide (on the support site) the output of the R commands

   library(GEOquery)
   sessionInfo()

Also include (copy and paste) the output of the command that fails. I have

 > gseEset2 <- getGEO('GSE76896')[[1]]
Found 1 file(s)
GSE76896_series_matrix.txt.gz
trying URL 
'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE76nnn/GSE76896/matrix/GSE76896_series_matrix.txt.gz'
Content type 'application/x-gzip' length 40561936 bytes (38.7 MB)
==================================================
downloaded 38.7 MB

Parsed with column specification:
cols(
   .default = col_double(),
   ID_REF = col_character()
)
See spec(...) for full column specifications.
|=================================================================| 100% 
   84 MB
File stored at:
/tmp/Rtmpe4NWji/GPL570.soft
|=================================================================| 100% 
   75 MB
 > sessionInfo()
R version 3.5.1 Patched (2018-08-22 r75177)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.5 LTS

Matrix products: default
BLAS: /home/mtmorgan/bin/R-3-5-branch/lib/libRblas.so
LAPACK: /home/mtmorgan/bin/R-3-5-branch/lib/libRlapack.so

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] bindrcpp_0.2.2      GEOquery_2.49.1     Biobase_2.41.2
[4] BiocGenerics_0.27.1 BiocManager_1.30.2

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.18     tidyr_0.8.1      crayon_1.3.4     dplyr_0.7.6
  [5] assertthat_0.2.0 R6_2.2.2         magrittr_1.5     pillar_1.3.0
  [9] stringi_1.2.4    rlang_0.2.2      curl_3.2         limma_3.37.4
[13] xml2_1.2.0       tools_3.5.1      readr_1.1.1      glue_1.3.0
[17] purrr_0.2.5      hms_0.4.2        compiler_3.5.1   pkgconfig_2.0.2
[21] tidyselect_0.2.4 bindr_0.1.1      tibble_1.4.2

On 09/07/2018 06:08 AM, Deepa wrote:
> Hello,
> 
> I am using a bioconductor package in R.
> The command that I use reads the contents of a file downloaded from a
> database and creates an expression object.
> 
> The syntax works perfectly fine when the input size is of 10 MB. Whereas,
> when the file size is around 40MB the object isn't created.
> 
> Is there an efficient way of loading a large input file to create the
> expression object?
> 
> This is my code,
> 
> 
> library(gcrma)
> library(limma)
> library(biomaRt)
> library(GEOquery)
> library(Biobase)
> require(GEOquery)
> require(Biobase)
> gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
> gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
> 
> ##gseEset2 doesn't load and isn't created
> 
> Many thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deep@m@hm@ii@c @ending from gm@il@com  Fri Sep  7 12:35:24 2018
From: deep@m@hm@ii@c @ending from gm@il@com (Deepa)
Date: Fri, 7 Sep 2018 16:05:24 +0530
Subject: [R] Efficient way of loading files in R
In-Reply-To: <0b51bc32-4a72-7907-fcb3-8701bf5b4da1@gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
 <0b51bc32-4a72-7907-fcb3-8701bf5b4da1@gmail.com>
Message-ID: <CAGchuN4hOFCW0S4so7hCjwM1kBTxAWbygWp2jgJgMKjFRZ4pnA@mail.gmail.com>

I already posted a similar issue on bioconductor.
https://support.bioconductor.org/p/112607/#112634
Couldn't find a solution.


On Fri, Sep 7, 2018 at 3:45 PM Martin Morgan <mtmorgan.bioc at gmail.com>
wrote:

> Ask on the Bioconductor support site https://support.bioconductor.org
>
> Provide (on the support site) the output of the R commands
>
>    library(GEOquery)
>    sessionInfo()
>
> Also include (copy and paste) the output of the command that fails. I have
>
>  > gseEset2 <- getGEO('GSE76896')[[1]]
> Found 1 file(s)
> GSE76896_series_matrix.txt.gz
> trying URL
> '
> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE76nnn/GSE76896/matrix/GSE76896_series_matrix.txt.gz
> '
> Content type 'application/x-gzip' length 40561936 bytes (38.7 MB)
> ==================================================
> downloaded 38.7 MB
>
> Parsed with column specification:
> cols(
>    .default = col_double(),
>    ID_REF = col_character()
> )
> See spec(...) for full column specifications.
> |=================================================================| 100%
>    84 MB
> File stored at:
> /tmp/Rtmpe4NWji/GPL570.soft
> |=================================================================| 100%
>    75 MB
>  > sessionInfo()
> R version 3.5.1 Patched (2018-08-22 r75177)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.5 LTS
>
> Matrix products: default
> BLAS: /home/mtmorgan/bin/R-3-5-branch/lib/libRblas.so
> LAPACK: /home/mtmorgan/bin/R-3-5-branch/lib/libRlapack.so
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] parallel  stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> other attached packages:
> [1] bindrcpp_0.2.2      GEOquery_2.49.1     Biobase_2.41.2
> [4] BiocGenerics_0.27.1 BiocManager_1.30.2
>
> loaded via a namespace (and not attached):
>   [1] Rcpp_0.12.18     tidyr_0.8.1      crayon_1.3.4     dplyr_0.7.6
>   [5] assertthat_0.2.0 R6_2.2.2         magrittr_1.5     pillar_1.3.0
>   [9] stringi_1.2.4    rlang_0.2.2      curl_3.2         limma_3.37.4
> [13] xml2_1.2.0       tools_3.5.1      readr_1.1.1      glue_1.3.0
> [17] purrr_0.2.5      hms_0.4.2        compiler_3.5.1   pkgconfig_2.0.2
> [21] tidyselect_0.2.4 bindr_0.1.1      tibble_1.4.2
>
> On 09/07/2018 06:08 AM, Deepa wrote:
> > Hello,
> >
> > I am using a bioconductor package in R.
> > The command that I use reads the contents of a file downloaded from a
> > database and creates an expression object.
> >
> > The syntax works perfectly fine when the input size is of 10 MB. Whereas,
> > when the file size is around 40MB the object isn't created.
> >
> > Is there an efficient way of loading a large input file to create the
> > expression object?
> >
> > This is my code,
> >
> >
> > library(gcrma)
> > library(limma)
> > library(biomaRt)
> > library(GEOquery)
> > library(Biobase)
> > require(GEOquery)
> > require(Biobase)
> > gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
> > gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
> >
> > ##gseEset2 doesn't load and isn't created
> >
> > Many thanks
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From deep@m@hm@ii@c @ending from gm@il@com  Fri Sep  7 12:38:08 2018
From: deep@m@hm@ii@c @ending from gm@il@com (Deepa)
Date: Fri, 7 Sep 2018 16:08:08 +0530
Subject: [R] Efficient way of loading files in R
In-Reply-To: <CAGchuN4hOFCW0S4so7hCjwM1kBTxAWbygWp2jgJgMKjFRZ4pnA@mail.gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
 <0b51bc32-4a72-7907-fcb3-8701bf5b4da1@gmail.com>
 <CAGchuN4hOFCW0S4so7hCjwM1kBTxAWbygWp2jgJgMKjFRZ4pnA@mail.gmail.com>
Message-ID: <CAGchuN62A_OeOzhd65Wo6gP_ZQiZ-RXb91ocjQwXzQVA3ZFtHA@mail.gmail.com>

I am also providing the output that I obtain for your kind reference,

gseEset2 <- getGEO('GSE76896', destdir = "data/")[[1]]
Found 1 file(s)
GSE76896_series_matrix.txt.gz
Using locally cached version: /data//GSE76896_series_matrix.txt.gz
Parsed with column specification:
cols(
  .default = col_double(),
  ID_REF = col_character()
)
See spec(...) for full column specifications.
Using locally cached version of GPL570 found here:
/data//GPL570.soft

After this I don't see any output. I had to forcefully stop the execution.

On Fri, Sep 7, 2018 at 4:05 PM Deepa <deepamahm.iisc at gmail.com> wrote:

> I already posted a similar issue on bioconductor.
> https://support.bioconductor.org/p/112607/#112634
> Couldn't find a solution.
>
>
> On Fri, Sep 7, 2018 at 3:45 PM Martin Morgan <mtmorgan.bioc at gmail.com>
> wrote:
>
>> Ask on the Bioconductor support site https://support.bioconductor.org
>>
>> Provide (on the support site) the output of the R commands
>>
>>    library(GEOquery)
>>    sessionInfo()
>>
>> Also include (copy and paste) the output of the command that fails. I have
>>
>>  > gseEset2 <- getGEO('GSE76896')[[1]]
>> Found 1 file(s)
>> GSE76896_series_matrix.txt.gz
>> trying URL
>> '
>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE76nnn/GSE76896/matrix/GSE76896_series_matrix.txt.gz
>> '
>> Content type 'application/x-gzip' length 40561936 bytes (38.7 MB)
>> ==================================================
>> downloaded 38.7 MB
>>
>> Parsed with column specification:
>> cols(
>>    .default = col_double(),
>>    ID_REF = col_character()
>> )
>> See spec(...) for full column specifications.
>> |=================================================================| 100%
>>    84 MB
>> File stored at:
>> /tmp/Rtmpe4NWji/GPL570.soft
>> |=================================================================| 100%
>>    75 MB
>>  > sessionInfo()
>> R version 3.5.1 Patched (2018-08-22 r75177)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 16.04.5 LTS
>>
>> Matrix products: default
>> BLAS: /home/mtmorgan/bin/R-3-5-branch/lib/libRblas.so
>> LAPACK: /home/mtmorgan/bin/R-3-5-branch/lib/libRlapack.so
>>
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] parallel  stats     graphics  grDevices utils     datasets  methods
>> [8] base
>>
>> other attached packages:
>> [1] bindrcpp_0.2.2      GEOquery_2.49.1     Biobase_2.41.2
>> [4] BiocGenerics_0.27.1 BiocManager_1.30.2
>>
>> loaded via a namespace (and not attached):
>>   [1] Rcpp_0.12.18     tidyr_0.8.1      crayon_1.3.4     dplyr_0.7.6
>>   [5] assertthat_0.2.0 R6_2.2.2         magrittr_1.5     pillar_1.3.0
>>   [9] stringi_1.2.4    rlang_0.2.2      curl_3.2         limma_3.37.4
>> [13] xml2_1.2.0       tools_3.5.1      readr_1.1.1      glue_1.3.0
>> [17] purrr_0.2.5      hms_0.4.2        compiler_3.5.1   pkgconfig_2.0.2
>> [21] tidyselect_0.2.4 bindr_0.1.1      tibble_1.4.2
>>
>> On 09/07/2018 06:08 AM, Deepa wrote:
>> > Hello,
>> >
>> > I am using a bioconductor package in R.
>> > The command that I use reads the contents of a file downloaded from a
>> > database and creates an expression object.
>> >
>> > The syntax works perfectly fine when the input size is of 10 MB.
>> Whereas,
>> > when the file size is around 40MB the object isn't created.
>> >
>> > Is there an efficient way of loading a large input file to create the
>> > expression object?
>> >
>> > This is my code,
>> >
>> >
>> > library(gcrma)
>> > library(limma)
>> > library(biomaRt)
>> > library(GEOquery)
>> > library(Biobase)
>> > require(GEOquery)
>> > require(Biobase)
>> > gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
>> > gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
>> >
>> > ##gseEset2 doesn't load and isn't created
>> >
>> > Many thanks
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>

	[[alternative HTML version deleted]]


From deep@m@hm@ii@c @ending from gm@il@com  Fri Sep  7 12:49:48 2018
From: deep@m@hm@ii@c @ending from gm@il@com (Deepa)
Date: Fri, 7 Sep 2018 16:19:48 +0530
Subject: [R] Efficient way of loading files in R
In-Reply-To: <CAGchuN62A_OeOzhd65Wo6gP_ZQiZ-RXb91ocjQwXzQVA3ZFtHA@mail.gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
 <0b51bc32-4a72-7907-fcb3-8701bf5b4da1@gmail.com>
 <CAGchuN4hOFCW0S4so7hCjwM1kBTxAWbygWp2jgJgMKjFRZ4pnA@mail.gmail.com>
 <CAGchuN62A_OeOzhd65Wo6gP_ZQiZ-RXb91ocjQwXzQVA3ZFtHA@mail.gmail.com>
Message-ID: <CAGchuN5noOvYohRj=EsXdvg44si8VrsE3Ds8UtH0Tcc36MhyWw@mail.gmail.com>

Martin,

I forgot to mention.

The same command works fine when I try,gseEset2 <- getGEO('GSE76896') ,
without saving the file to a destination folder .




Output:

Found 1 file(s)
GSE76896_series_matrix.txt.gz
trying URL '
https://ftp.ncbi.nlm.nih.gov/geo/series/GSE76nnn/GSE76896/matrix/GSE76896_series_matrix.txt.gz
'
Content type 'application/x-gzip' length 40561936 bytes (38.7 MB)
==================================================
downloaded 38.7 MB

Parsed with column specification:
cols(
  .default = col_double(),
  ID_REF = col_character()
)
See spec(...) for full column specifications.
|=================================================================| 100%
 84 MB
File stored at:
/tmp/RtmprygqGb/GPL570.soft
|=================================================================| 100%
 80 MB
|=================================================================| 100%
 75 MB

The problem occurs when I fetch the file from destination folder using
gseEset2 <- getGEO('GSE76896', destdir = "/data/")[[1]]

Found 1 file(s)
GSE76896_series_matrix.txt.gz
Using locally cached version: /data//GSE76896_series_matrix.txt.gz
Parsed with column specification:
cols(
  .default = col_double(),
  ID_REF = col_character()
)
See spec(...) for full column specifications.
|=================================================================| 100%
 84 MB
Using locally cached version of GPL570 found here:
/data//GPL570.soft
^C


On Fri, Sep 7, 2018 at 4:08 PM Deepa <deepamahm.iisc at gmail.com> wrote:

> I am also providing the output that I obtain for your kind reference,
>
> gseEset2 <- getGEO('GSE76896', destdir = "data/")[[1]]
> Found 1 file(s)
> GSE76896_series_matrix.txt.gz
> Using locally cached version: /data//GSE76896_series_matrix.txt.gz
> Parsed with column specification:
> cols(
>   .default = col_double(),
>   ID_REF = col_character()
> )
> See spec(...) for full column specifications.
> Using locally cached version of GPL570 found here:
> /data//GPL570.soft
>
> After this I don't see any output. I had to forcefully stop the execution.
>
> On Fri, Sep 7, 2018 at 4:05 PM Deepa <deepamahm.iisc at gmail.com> wrote:
>
>> I already posted a similar issue on bioconductor.
>> https://support.bioconductor.org/p/112607/#112634
>> Couldn't find a solution.
>>
>>
>> On Fri, Sep 7, 2018 at 3:45 PM Martin Morgan <mtmorgan.bioc at gmail.com>
>> wrote:
>>
>>> Ask on the Bioconductor support site https://support.bioconductor.org
>>>
>>> Provide (on the support site) the output of the R commands
>>>
>>>    library(GEOquery)
>>>    sessionInfo()
>>>
>>> Also include (copy and paste) the output of the command that fails. I
>>> have
>>>
>>>  > gseEset2 <- getGEO('GSE76896')[[1]]
>>> Found 1 file(s)
>>> GSE76896_series_matrix.txt.gz
>>> trying URL
>>> '
>>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE76nnn/GSE76896/matrix/GSE76896_series_matrix.txt.gz
>>> '
>>> Content type 'application/x-gzip' length 40561936 bytes (38.7 MB)
>>> ==================================================
>>> downloaded 38.7 MB
>>>
>>> Parsed with column specification:
>>> cols(
>>>    .default = col_double(),
>>>    ID_REF = col_character()
>>> )
>>> See spec(...) for full column specifications.
>>> |=================================================================| 100%
>>>    84 MB
>>> File stored at:
>>> /tmp/Rtmpe4NWji/GPL570.soft
>>> |=================================================================| 100%
>>>    75 MB
>>>  > sessionInfo()
>>> R version 3.5.1 Patched (2018-08-22 r75177)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 16.04.5 LTS
>>>
>>> Matrix products: default
>>> BLAS: /home/mtmorgan/bin/R-3-5-branch/lib/libRblas.so
>>> LAPACK: /home/mtmorgan/bin/R-3-5-branch/lib/libRlapack.so
>>>
>>> locale:
>>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] parallel  stats     graphics  grDevices utils     datasets  methods
>>> [8] base
>>>
>>> other attached packages:
>>> [1] bindrcpp_0.2.2      GEOquery_2.49.1     Biobase_2.41.2
>>> [4] BiocGenerics_0.27.1 BiocManager_1.30.2
>>>
>>> loaded via a namespace (and not attached):
>>>   [1] Rcpp_0.12.18     tidyr_0.8.1      crayon_1.3.4     dplyr_0.7.6
>>>   [5] assertthat_0.2.0 R6_2.2.2         magrittr_1.5     pillar_1.3.0
>>>   [9] stringi_1.2.4    rlang_0.2.2      curl_3.2         limma_3.37.4
>>> [13] xml2_1.2.0       tools_3.5.1      readr_1.1.1      glue_1.3.0
>>> [17] purrr_0.2.5      hms_0.4.2        compiler_3.5.1   pkgconfig_2.0.2
>>> [21] tidyselect_0.2.4 bindr_0.1.1      tibble_1.4.2
>>>
>>> On 09/07/2018 06:08 AM, Deepa wrote:
>>> > Hello,
>>> >
>>> > I am using a bioconductor package in R.
>>> > The command that I use reads the contents of a file downloaded from a
>>> > database and creates an expression object.
>>> >
>>> > The syntax works perfectly fine when the input size is of 10 MB.
>>> Whereas,
>>> > when the file size is around 40MB the object isn't created.
>>> >
>>> > Is there an efficient way of loading a large input file to create the
>>> > expression object?
>>> >
>>> > This is my code,
>>> >
>>> >
>>> > library(gcrma)
>>> > library(limma)
>>> > library(biomaRt)
>>> > library(GEOquery)
>>> > library(Biobase)
>>> > require(GEOquery)
>>> > require(Biobase)
>>> > gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
>>> > gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
>>> >
>>> > ##gseEset2 doesn't load and isn't created
>>> >
>>> > Many thanks
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Fri Sep  7 18:17:56 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 7 Sep 2018 16:17:56 +0000
Subject: [R] histogram in GNU R....
Message-ID: <09BA3BF7-FE7E-49E7-BA91-974E1BCD672B@llnl.gov>

In addition to the other suggestions, try typing

  x11()

before using hist().

That *should* start a graphics window. If it does not, then type

  capabilities()

and see if "X11" is TRUE.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/7/18, 1:26 AM, "R-help on behalf of akshay kulkarni" <r-help-bounces at r-project.org on behalf of akshay_e4 at hotmail.com> wrote:

    dear members,
                                 I am running R on Linux AWS ec2 instance.
    When I try to create a histogram in it, I am running into problems:
    
    > xht <- c(1,2,3,4,5,6,7,8,9,10)
    >  hist(xht)
    >
    
    when I type hist(xht), it goes to the next prompt. More importantly, there is no error message. So, the most probable conclusion is that the command gets executed. But there is no pop up screen with a histogram, and nothing else...
    
    whats going on?
    
    How can I circumvent the help of histogram(which is not available in GNU R)? summary(xht) would help, but not much. Any other function that can give information, in LINUX R, that a histogram gives, in LINUX CLI?
    
    Very many thanks for your time and effort...
    Yours sincerely,
    AKSHAYM KULKARNI
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From wdunl@p @ending from tibco@com  Fri Sep  7 19:30:31 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 7 Sep 2018 10:30:31 -0700
Subject: [R] histogram in GNU R....
In-Reply-To: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcYqj0hnC1HymcoNSYnJzAABe4Gh3c8huQ412bW7Stp6yw@mail.gmail.com>

You may have to install X11 stuff to your ec2 instance.  E.g., googling for
"ec2 X11 forwarding" showed things like the following:

Re: X11 forwarding to access AWS EC2 Linux instance
Posted by: wilderfield
<https://forums.aws.amazon.com/profile.jspa?userID=433982>
Posted on: Apr 5, 2018 11:31 AM
[image: in response to: LE M.]
<https://forums.aws.amazon.com/message.jspa?messageID=574740#574740> in
response to: LE M.
<https://forums.aws.amazon.com/message.jspa?messageID=574740#574740>
  [image: Click to reply to this thread]
<https://forums.aws.amazon.com/post!reply.jspa?messageID=841377> Reply
<https://forums.aws.amazon.com/post!reply.jspa?messageID=841377>
x11 <https://forums.aws.amazon.com/tags/x11>
sudo yum install xorg-x11-xauth

The above is all I needed to get X11 forwarding working over ssh

When ssh-ing to the instance, use the -X flag


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Sep 7, 2018 at 1:26 AM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                              I am running R on Linux AWS ec2 instance.
> When I try to create a histogram in it, I am running into problems:
>
> > xht <- c(1,2,3,4,5,6,7,8,9,10)
> >  hist(xht)
> >
>
> when I type hist(xht), it goes to the next prompt. More importantly, there
> is no error message. So, the most probable conclusion is that the command
> gets executed. But there is no pop up screen with a histogram, and nothing
> else...
>
> whats going on?
>
> How can I circumvent the help of histogram(which is not available in GNU
> R)? summary(xht) would help, but not much. Any other function that can give
> information, in LINUX R, that a histogram gives, in LINUX CLI?
>
> Very many thanks for your time and effort...
> Yours sincerely,
> AKSHAYM KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From peter@l@ngfelder @ending from gm@il@com  Fri Sep  7 20:07:57 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Fri, 7 Sep 2018 11:07:57 -0700
Subject: [R] histogram in GNU R....
In-Reply-To: <CAF8bMcYqj0hnC1HymcoNSYnJzAABe4Gh3c8huQ412bW7Stp6yw@mail.gmail.com>
References: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <CAF8bMcYqj0hnC1HymcoNSYnJzAABe4Gh3c8huQ412bW7Stp6yw@mail.gmail.com>
Message-ID: <CA+hbrhXb2ShM5vF+JvuUzGtoDYK-_a6kYa0aG9t6au6YGMJQGw@mail.gmail.com>

A simpler short term solution is to execute dev.off() and look for the plot
in file Rplots.pdf in the current directory. Depending on the OS of the
local computer, you should be able to point a file browser at the EC
instance and simply click the file to open in in a pdf viewer on the local
machine.

Peter

On Fri, Sep 7, 2018 at 10:31 AM William Dunlap via R-help <
r-help at r-project.org> wrote:

> You may have to install X11 stuff to your ec2 instance.  E.g., googling for
> "ec2 X11 forwarding" showed things like the following:
>
> Re: X11 forwarding to access AWS EC2 Linux instance
> Posted by: wilderfield
> <https://forums.aws.amazon.com/profile.jspa?userID=433982>
> Posted on: Apr 5, 2018 11:31 AM
> [image: in response to: LE M.]
> <https://forums.aws.amazon.com/message.jspa?messageID=574740#574740> in
> response to: LE M.
> <https://forums.aws.amazon.com/message.jspa?messageID=574740#574740>
>   [image: Click to reply to this thread]
> <https://forums.aws.amazon.com/post!reply.jspa?messageID=841377> Reply
> <https://forums.aws.amazon.com/post!reply.jspa?messageID=841377>
> x11 <https://forums.aws.amazon.com/tags/x11>
> sudo yum install xorg-x11-xauth
>
> The above is all I needed to get X11 forwarding working over ssh
>
> When ssh-ing to the instance, use the -X flag
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Sep 7, 2018 at 1:26 AM, akshay kulkarni <akshay_e4 at hotmail.com>
> wrote:
>
> > dear members,
> >                              I am running R on Linux AWS ec2 instance.
> > When I try to create a histogram in it, I am running into problems:
> >
> > > xht <- c(1,2,3,4,5,6,7,8,9,10)
> > >  hist(xht)
> > >
> >
> > when I type hist(xht), it goes to the next prompt. More importantly,
> there
> > is no error message. So, the most probable conclusion is that the command
> > gets executed. But there is no pop up screen with a histogram, and
> nothing
> > else...
> >
> > whats going on?
> >
> > How can I circumvent the help of histogram(which is not available in GNU
> > R)? summary(xht) would help, but not much. Any other function that can
> give
> > information, in LINUX R, that a histogram gives, in LINUX CLI?
> >
> > Very many thanks for your time and effort...
> > Yours sincerely,
> > AKSHAYM KULKARNI
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From D@vid@Joubert @ending from uott@w@@c@  Fri Sep  7 19:40:58 2018
From: D@vid@Joubert @ending from uott@w@@c@ (David Joubert)
Date: Fri, 7 Sep 2018 17:40:58 +0000
Subject: [R] Selecting random subset by ID
Message-ID: <YTOPR0101MB1531E8CDC94CA74A63B097D79A000@YTOPR0101MB1531.CANPRD01.PROD.OUTLOOK.COM>

Hello R users,

I am working with a large dataset, including roughly 50 000 sequential observations (variable "count") for 8000 individuals (variable "id"). The dataset is very unbalanced, meaning that some individuals have few observations and others have many. Because I plan on running Generalized Linear Models for panel data using pglm and the package has file size restrictions, I want to create 4 randomly selected subsets of 2500 individuals from the main dataset. What functions and code would I use to do this?

Thanks in advance,

David Joubert



	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Sep  7 21:00:07 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 7 Sep 2018 12:00:07 -0700
Subject: [R] Selecting random subset by ID
In-Reply-To: <YTOPR0101MB1531E8CDC94CA74A63B097D79A000@YTOPR0101MB1531.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1531E8CDC94CA74A63B097D79A000@YTOPR0101MB1531.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbR=pb71zL8D6Bz=hD7Ex7i4-sY==y5x7Eo_xXhhMhmbOQ@mail.gmail.com>

?sample

Should get you started

We expect you to first make an effort to learn about and write your
own code, rather than asking us to write it for you.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 7, 2018 at 11:38 AM David Joubert <David.Joubert at uottawa.ca> wrote:
>
> Hello R users,
>
> I am working with a large dataset, including roughly 50 000 sequential observations (variable "count") for 8000 individuals (variable "id"). The dataset is very unbalanced, meaning that some individuals have few observations and others have many. Because I plan on running Generalized Linear Models for panel data using pglm and the package has file size restrictions, I want to create 4 randomly selected subsets of 2500 individuals from the main dataset. What functions and code would I use to do this?
>
> Thanks in advance,
>
> David Joubert
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Sep  7 22:06:07 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 07 Sep 2018 13:06:07 -0700
Subject: [R] Selecting random subset by ID
In-Reply-To: <CAGxFJbR=pb71zL8D6Bz=hD7Ex7i4-sY==y5x7Eo_xXhhMhmbOQ@mail.gmail.com>
References: <YTOPR0101MB1531E8CDC94CA74A63B097D79A000@YTOPR0101MB1531.CANPRD01.PROD.OUTLOOK.COM>
 <CAGxFJbR=pb71zL8D6Bz=hD7Ex7i4-sY==y5x7Eo_xXhhMhmbOQ@mail.gmail.com>
Message-ID: <9CC23B91-1A1F-408F-8B7C-422CF2C1A10A@dcn.davis.ca.us>

IMO it is worth pointing out that you don't have to write code that solves your problem (else why have this list?) but this whole communication thing works best when you write code that creates a mock set of data that illustrates what you are starting from and some mock output.

The mock input can sometimes be the output of the dput function on a subset of your data, but in your case would probably be something more like

set.seed(42)
ids <- data.frame( id=1:8000, a1=rnorm(8000,0,1),n=sample(2:15,8000,replace=TRUE))
dta <- ids[rep(ids$id,ids$n),]
dta$a0 <- rnorm(nrow(dta),1,2)
dta$value <- with( dta, a0 + a1 )

where the exact way I approach making the data may not be exactly how your data is structured, but clarifying and avoiding that misunderstanding is exactly what you should try to address by learning how to do this when you ask your question.

You may find that reading the above helps you answer your own question, or you can confirm that this data set is close enough and show what code you tried starting with this data.

Oh, and by the way, sending your emails to this list formatted with html is a good way to corrupt your code examples because this list only forwards the plain text part of your email. Start with the plain text setting in your email program and avoid further miscommunication.

More on reproducible examples [1][2][3].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

On September 7, 2018 12:00:07 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>?sample
>
>Should get you started
>
>We expect you to first make an effort to learn about and write your
>own code, rather than asking us to write it for you.
>
>-- Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Fri, Sep 7, 2018 at 11:38 AM David Joubert
><David.Joubert at uottawa.ca> wrote:
>>
>> Hello R users,
>>
>> I am working with a large dataset, including roughly 50 000
>sequential observations (variable "count") for 8000 individuals
>(variable "id"). The dataset is very unbalanced, meaning that some
>individuals have few observations and others have many. Because I plan
>on running Generalized Linear Models for panel data using pglm and the
>package has file size restrictions, I want to create 4 randomly
>selected subsets of 2500 individuals from the main dataset. What
>functions and code would I use to do this?
>>
>> Thanks in advance,
>>
>> David Joubert
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep  7 23:19:18 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 7 Sep 2018 14:19:18 -0700 (PDT)
Subject: [R] Correctly applying aggregate.ts()
Message-ID: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>

   I've read ?aggregate and several blog posts on using aggregate() yet I
still haven't applied it correctly to my dataframe. The sample data are:

structure(list(sampdate = c("2005-01-01", "2005-01-02", "2005-01-03", 
"2005-01-04", "2005-01-05", "2005-01-06", "2005-01-07", "2005-01-08", 
"2005-01-09", "2005-01-10", "2005-01-11", "2005-01-12", "2005-01-13", 
"2005-01-14", "2005-01-15", "2005-01-16", "2005-01-17", "2005-01-18", 
"2005-01-19", "2005-01-20", "2005-01-21", "2005-01-22", "2005-01-23", 
"2005-01-24", "2005-01-25", "2005-01-26", "2005-01-27", "2005-01-28", 
"2005-01-29", "2005-01-30", "2005-01-31", "2005-02-01", "2005-02-02", 
"2005-02-03", "2005-02-04", "2005-02-05", "2005-02-06", "2005-02-07", 
"2005-02-08", "2005-02-09", "2005-02-10", "2005-02-11", "2005-02-12", 
"2005-02-13", "2005-02-14", "2005-02-15", "2005-02-16", "2005-02-17", 
"2005-02-18", "2005-02-19", "2005-02-20", "2005-02-21", "2005-02-22", 
"2005-02-23", "2005-02-24", "2005-02-25", "2005-02-26", "2005-02-27", 
"2005-02-28", "2005-03-01", "2005-03-02", "2005-03-03"), prcp = c(0.59, 
0.08, 0.1, 0, 0, 0.02, 0.05, 0.1, 0, 0.02, 0, 0.05, 0.2, 0, 0, 
0.5, 0.41, 0.84, 0.01, 0.1, 0.01, 0, 0, 0, 0, 0.21, 0.24, 0.13, 
1.12, 0.01, 0.09, 0, 0, 0, 0.35, 0.18, 0.65, 0.16, 0, 0, 0, 0, 
0.55, 0.21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.05, 
0.01, 0)), row.names = c(NA, 62L), class = "data.frame")

   What I need to learn how to do is to calculate monthly sum, median, and
maximum rainfall amounts from the full data set which has daily rainfall
amounts. My most current effort to calculate monthly sums uses this syntax:

monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)

(entered on a single line) which produces this result:

head(monthly.rain)
[1] NA

   The sample data has 62 of the 113K rows in the dataframe. A larger set can
be provided if needed.

   An explanation of what I've missed is needed.

Regards,

Rich


From bgunter@4567 @ending from gm@il@com  Sat Sep  8 00:25:53 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 7 Sep 2018 15:25:53 -0700
Subject: [R] Correctly applying aggregate.ts()
In-Reply-To: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTm=6dULSuKmofcmzy=CwmGn54OPROyQNBM4Nt2RkjBSA@mail.gmail.com>

Well, let's see:
"monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)"

1. x is a data frame, so why are you using the time series method?
Perhaps you need to study S3 method usage in R.

2. You have improperly subscripted the data frame: it should be dp[,
c('sampdate','prcp')] . Perhaps you need to read about how
subscripting in R. However, in this case, no subscripting is needed
(see 3.)

3. As you should be using the data frame method, and the month is
obtained as a substring of sampdate, you should use dp[,'prcp'] as
your data frame so that sum() is not applied to the sampdate column.

4. I assume the "\" indicates <Return> ?

Anyway, once you have corrected all that, here's the call:

> monthly.rain <- aggregate(dp[, 'prcp'],
+                           list(substr(dp$sampdate,1,7)),
+                           FUN = sum, na.rm = TRUE)
> ## yielding
> monthly.rain
  Group.1    x
1 2005-01 4.88
2 2005-02 2.27
3 2005-03 0.06

It's perhaps also worth noting that the formula method (for data
frames) is somewhat more convenient, especially with several grouping
factors in the list:

> monthly.rain <- aggregate(prcp ~ substr(sampdate,1,7), data = dp, FUN = sum, na.rm = TRUE)
> ##yielding
> monthly.rain
  substr(sampdate, 1, 7) prcp
1                2005-01 4.88
2                2005-02 2.27
3                2005-03 0.06

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Fri, Sep 7, 2018 at 2:19 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
>    I've read ?aggregate and several blog posts on using aggregate() yet I
> still haven't applied it correctly to my dataframe. The sample data are:
>
> structure(list(sampdate = c("2005-01-01", "2005-01-02", "2005-01-03",
> "2005-01-04", "2005-01-05", "2005-01-06", "2005-01-07", "2005-01-08",
> "2005-01-09", "2005-01-10", "2005-01-11", "2005-01-12", "2005-01-13",
> "2005-01-14", "2005-01-15", "2005-01-16", "2005-01-17", "2005-01-18",
> "2005-01-19", "2005-01-20", "2005-01-21", "2005-01-22", "2005-01-23",
> "2005-01-24", "2005-01-25", "2005-01-26", "2005-01-27", "2005-01-28",
> "2005-01-29", "2005-01-30", "2005-01-31", "2005-02-01", "2005-02-02",
> "2005-02-03", "2005-02-04", "2005-02-05", "2005-02-06", "2005-02-07",
> "2005-02-08", "2005-02-09", "2005-02-10", "2005-02-11", "2005-02-12",
> "2005-02-13", "2005-02-14", "2005-02-15", "2005-02-16", "2005-02-17",
> "2005-02-18", "2005-02-19", "2005-02-20", "2005-02-21", "2005-02-22",
> "2005-02-23", "2005-02-24", "2005-02-25", "2005-02-26", "2005-02-27",
> "2005-02-28", "2005-03-01", "2005-03-02", "2005-03-03"), prcp = c(0.59,
> 0.08, 0.1, 0, 0, 0.02, 0.05, 0.1, 0, 0.02, 0, 0.05, 0.2, 0, 0,
> 0.5, 0.41, 0.84, 0.01, 0.1, 0.01, 0, 0, 0, 0, 0.21, 0.24, 0.13,
> 1.12, 0.01, 0.09, 0, 0, 0, 0.35, 0.18, 0.65, 0.16, 0, 0, 0, 0,
> 0.55, 0.21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.05,
> 0.01, 0)), row.names = c(NA, 62L), class = "data.frame")
>
>    What I need to learn how to do is to calculate monthly sum, median, and
> maximum rainfall amounts from the full data set which has daily rainfall
> amounts. My most current effort to calculate monthly sums uses this syntax:
>
> monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
> substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)
>
> (entered on a single line) which produces this result:
>
> head(monthly.rain)
> [1] NA
>
>    The sample data has 62 of the 113K rows in the dataframe. A larger set can
> be provided if needed.
>
>    An explanation of what I've missed is needed.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Sat Sep  8 00:34:30 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 7 Sep 2018 15:34:30 -0700
Subject: [R] Correctly applying aggregate.ts()
In-Reply-To: <CAGxFJbTm=6dULSuKmofcmzy=CwmGn54OPROyQNBM4Nt2RkjBSA@mail.gmail.com>
References: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
 <CAGxFJbTm=6dULSuKmofcmzy=CwmGn54OPROyQNBM4Nt2RkjBSA@mail.gmail.com>
Message-ID: <CAGxFJbT42=CF=nvksVpf1PeJ=jJqkq7HOyhiJ6vkf=Q5aE90_Q@mail.gmail.com>

Clarification: When using the formula interface, no subscripting is needed.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 7, 2018 at 3:25 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Well, let's see:
> "monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
> substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)"
>
> 1. x is a data frame, so why are you using the time series method?
> Perhaps you need to study S3 method usage in R.
>
> 2. You have improperly subscripted the data frame: it should be dp[,
> c('sampdate','prcp')] . Perhaps you need to read about how
> subscripting in R. However, in this case, no subscripting is needed
> (see 3.)
>
> 3. As you should be using the data frame method, and the month is
> obtained as a substring of sampdate, you should use dp[,'prcp'] as
> your data frame so that sum() is not applied to the sampdate column.
>
> 4. I assume the "\" indicates <Return> ?
>
> Anyway, once you have corrected all that, here's the call:
>
> > monthly.rain <- aggregate(dp[, 'prcp'],
> +                           list(substr(dp$sampdate,1,7)),
> +                           FUN = sum, na.rm = TRUE)
> > ## yielding
> > monthly.rain
>   Group.1    x
> 1 2005-01 4.88
> 2 2005-02 2.27
> 3 2005-03 0.06
>
> It's perhaps also worth noting that the formula method (for data
> frames) is somewhat more convenient, especially with several grouping
> factors in the list:
>
> > monthly.rain <- aggregate(prcp ~ substr(sampdate,1,7), data = dp, FUN = sum, na.rm = TRUE)
> > ##yielding
> > monthly.rain
>   substr(sampdate, 1, 7) prcp
> 1                2005-01 4.88
> 2                2005-02 2.27
> 3                2005-03 0.06
>
> Cheers,
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> On Fri, Sep 7, 2018 at 2:19 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
> >
> >    I've read ?aggregate and several blog posts on using aggregate() yet I
> > still haven't applied it correctly to my dataframe. The sample data are:
> >
> > structure(list(sampdate = c("2005-01-01", "2005-01-02", "2005-01-03",
> > "2005-01-04", "2005-01-05", "2005-01-06", "2005-01-07", "2005-01-08",
> > "2005-01-09", "2005-01-10", "2005-01-11", "2005-01-12", "2005-01-13",
> > "2005-01-14", "2005-01-15", "2005-01-16", "2005-01-17", "2005-01-18",
> > "2005-01-19", "2005-01-20", "2005-01-21", "2005-01-22", "2005-01-23",
> > "2005-01-24", "2005-01-25", "2005-01-26", "2005-01-27", "2005-01-28",
> > "2005-01-29", "2005-01-30", "2005-01-31", "2005-02-01", "2005-02-02",
> > "2005-02-03", "2005-02-04", "2005-02-05", "2005-02-06", "2005-02-07",
> > "2005-02-08", "2005-02-09", "2005-02-10", "2005-02-11", "2005-02-12",
> > "2005-02-13", "2005-02-14", "2005-02-15", "2005-02-16", "2005-02-17",
> > "2005-02-18", "2005-02-19", "2005-02-20", "2005-02-21", "2005-02-22",
> > "2005-02-23", "2005-02-24", "2005-02-25", "2005-02-26", "2005-02-27",
> > "2005-02-28", "2005-03-01", "2005-03-02", "2005-03-03"), prcp = c(0.59,
> > 0.08, 0.1, 0, 0, 0.02, 0.05, 0.1, 0, 0.02, 0, 0.05, 0.2, 0, 0,
> > 0.5, 0.41, 0.84, 0.01, 0.1, 0.01, 0, 0, 0, 0, 0.21, 0.24, 0.13,
> > 1.12, 0.01, 0.09, 0, 0, 0, 0.35, 0.18, 0.65, 0.16, 0, 0, 0, 0,
> > 0.55, 0.21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.05,
> > 0.01, 0)), row.names = c(NA, 62L), class = "data.frame")
> >
> >    What I need to learn how to do is to calculate monthly sum, median, and
> > maximum rainfall amounts from the full data set which has daily rainfall
> > amounts. My most current effort to calculate monthly sums uses this syntax:
> >
> > monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
> > substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)
> >
> > (entered on a single line) which produces this result:
> >
> > head(monthly.rain)
> > [1] NA
> >
> >    The sample data has 62 of the 113K rows in the dataframe. A larger set can
> > be provided if needed.
> >
> >    An explanation of what I've missed is needed.
> >
> > Regards,
> >
> > Rich
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Sat Sep  8 00:39:36 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 7 Sep 2018 15:39:36 -0700 (PDT)
Subject: [R] Correctly applying aggregate.ts() [RESOLVED]
In-Reply-To: <CAGxFJbTm=6dULSuKmofcmzy=CwmGn54OPROyQNBM4Nt2RkjBSA@mail.gmail.com>
References: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
 <CAGxFJbTm=6dULSuKmofcmzy=CwmGn54OPROyQNBM4Nt2RkjBSA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809071532090.11940@salmo.appl-ecosys.com>

On Fri, 7 Sep 2018, Bert Gunter wrote:

> Well, let's see:
> "monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
> substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)"
>
> 1. x is a data frame, so why are you using the time series method?
> Perhaps you need to study S3 method usage in R.

Bert,

   I saw the four varieties of aggregate and thought the time series
appropriate for the data frame of sequential dates. As I wrote, I had
difficulties understanding which flavor to use.

> 2. You have improperly subscripted the data frame: it should be dp[,
> c('sampdate','prcp')] . Perhaps you need to read about how
> subscripting in R. However, in this case, no subscripting is needed
> (see 3.)

   Ah so. All the examples I saw used single column data frames.

> 3. As you should be using the data frame method, and the month is
> obtained as a substring of sampdate, you should use dp[,'prcp'] as
> your data frame so that sum() is not applied to the sampdate column.
>
> 4. I assume the "\" indicates <Return> ?

   Yes. Alpine broke the line so I added a newline to the first part.

> Anyway, once you have corrected all that, here's the call:
>
>> monthly.rain <- aggregate(dp[, 'prcp'],
> +                           list(substr(dp$sampdate,1,7)),
> +                           FUN = sum, na.rm = TRUE)

   Thanks for making the syntax so clear.

> It's perhaps also worth noting that the formula method (for data
> frames) is somewhat more convenient, especially with several grouping
> factors in the list:
>
>> monthly.rain <- aggregate(prcp ~ substr(sampdate,1,7), data = dp, FUN = sum, na.rm = TRUE)
>> ##yielding
>> monthly.rain
>  substr(sampdate, 1, 7) prcp
> 1                2005-01 4.88
> 2                2005-02 2.27
> 3                2005-03 0.06

   I looked at the formula method without appreciating how to apply it.

   Now I can work with the multiple of daily data sets I have and properly
condense them for presentation to readers of the report. And I'm much better
armed to understand how to apply aggregate() to various data sets.

Very much appreciated,

Rich
a


From @k@h@y_e4 @ending from hotm@il@com  Sat Sep  8 12:25:57 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Sat, 8 Sep 2018 10:25:57 +0000
Subject: [R] frequency distribution in figures....
Message-ID: <SL2P216MB009168C061B4FBC8D97AE478C8070@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I am facing difficulties in plotting histograms in R in Linux CLI.

Is there a function in R which produces a table of frequency distribution in figures rather than plot that distribution?

Something like this:

xht <- c(1,2,3,4,5,6,7,8,9,10)

required table:
                              bins:                   1-2     3-4    5-6     7-8     9-10
                              frequency:          2          2       2         2        2

Also is this possible:

xhth <- hist(xht)
summary(xhth)

very many thanks for your time and effort....
yours sincerely,
AKSHAYM KULKARNI


	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Sat Sep  8 12:43:42 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sat, 8 Sep 2018 06:43:42 -0400
Subject: [R] frequency distribution in figures....
In-Reply-To: <SL2P216MB009168C061B4FBC8D97AE478C8070@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009168C061B4FBC8D97AE478C8070@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <22f4b1ed-84f1-1cc4-5675-bcfc7d54d084@gmail.com>

On 08/09/2018 6:25 AM, akshay kulkarni wrote:
> dear members,
>                               I am facing difficulties in plotting histograms in R in Linux CLI.
> 
> Is there a function in R which produces a table of frequency distribution in figures rather than plot that distribution?
> 
> Something like this:
> 
> xht <- c(1,2,3,4,5,6,7,8,9,10)
> 
> required table:
>                                bins:                   1-2     3-4    5-6     7-8     9-10
>                                frequency:          2          2       2         2        2
> 
> Also is this possible:
> 
> xhth <- hist(xht)
> summary(xhth)
> 

You could use

table(cut(xht, breaks=2*(0:5)))

which produces


  (0,2]  (2,4]  (4,6]  (6,8] (8,10]
      2      2      2      2      2

for your dataset.

Duncan Murdoch


From drjimlemon @ending from gm@il@com  Sat Sep  8 12:45:57 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sat, 8 Sep 2018 20:45:57 +1000
Subject: [R] frequency distribution in figures....
In-Reply-To: <SL2P216MB009168C061B4FBC8D97AE478C8070@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009168C061B4FBC8D97AE478C8070@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fVLAsL96=U=uY7ijr1JQKTq27ysmtjkU1EHxpQdbvaB=w@mail.gmail.com>

Hi Akshay,
Try this:

table(cut(xht,breaks=seq(0,10,by=2)))

Jim

On Sat, Sep 8, 2018 at 8:26 PM akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>
> dear members,
>                              I am facing difficulties in plotting histograms in R in Linux CLI.
>
> Is there a function in R which produces a table of frequency distribution in figures rather than plot that distribution?
>
> Something like this:
>
> xht <- c(1,2,3,4,5,6,7,8,9,10)
>
> required table:
>                               bins:                   1-2     3-4    5-6     7-8     9-10
>                               frequency:          2          2       2         2        2
>
> Also is this possible:
>
> xhth <- hist(xht)
> summary(xhth)
>
> very many thanks for your time and effort....
> yours sincerely,
> AKSHAYM KULKARNI
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipb@rr@d@@ @ending from @@po@pt  Sat Sep  8 12:51:19 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Sat, 8 Sep 2018 11:51:19 +0100
Subject: [R] Correctly applying aggregate.ts()
In-Reply-To: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
Message-ID: <508c4296-5165-564d-4dcc-d1e880fc75f7@sapo.pt>

Hello,

Like Bert said, your data is a data.frame so there is no need to call 
aggregate.ts. Besides, R will call the right method so unless you want 
to change the standard behaviour, it would be enough to call aggregate 
and let the methods dispatch code to its job.

As for the problem, first an example of the formula interface, which I 
almost always prefer.


aggregate(prcp ~ substr(sampdate, 1, 7), data = dp, FUN = sum, na.rm = TRUE)
#  substr(sampdate, 1, 7) prcp
#1                2005-01 4.88
#2                2005-02 2.27
#3                2005-03 0.06


Now, you would have to change the name of the Month column, but it 
worked as expected, there was no NA issues.
And there is no need to subset the data.frame, R will find the columns 
where they are, by their names, as long as you pass the argument data = 
dp to aggregate.


If you want several statistics at the same time, it's a bit trickier, 
but with practice it becomes intuitive. (So to speak.)

Define a custom summary function. I haven't changed the default na.rm 
setting but it would make the rest of the code simpler to set na.rm = 
TRUE right now.

customSmry <- function(x, na.rm = FALSE){
   c(Sum = sum(x, na.rm = na.rm),
     Median = median(x, na.rm = na.rm),
     Max = max(x, na.rm = na.rm)
   )
}


#Now call aggregate:

agg <- aggregate(prcp ~ substr(sampdate, 1, 7), dp, FUN = customSmry, 
na.rm = TRUE)


But be VERY carefull, the result is not a df with 4 columns, it's a df 
with only two columns, the second being a matrix as you can see in the 
output of str.


str(agg)
#'data.frame':	3 obs. of  2 variables:
# $ substr(sampdate, 1, 7): chr  "2005-01" "2005-02" "2005-03"
# $ prcp                  : num [1:3, 1:3] 4.88 2.27 0.06 0.05 0 0.01 
1.12 0.65 0.05
# ..- attr(*, "dimnames")=List of 2
# .. ..$ : NULL
# .. ..$ : chr  "Sum" "Median" "Max"


So the final steps will be to cbind those two "columns" into a df.
"columns" is between quotes because I am not cbinding the first column, 
I'm cbinding the sub-df agg[1]. Like this the method of cbind that is 
called is cbind.data.frame and the result is a df.
Also, since df's are lists, the second column is an actual column but 
not a vector, an object of class matrix. This column is a list member, 
like all df columns and I will subset the df 'agg' as a list, agg[[2]].

As a bonus, the colnames of the matrix are immediately right, no prcp 
prefix. The first column's name comes from the function substr, and is 
not part of this story, just rename it when it's all done.


agg <- cbind(agg[1], agg[[2]])
str(agg)
#'data.frame':	3 obs. of  4 variables:
# $ substr(sampdate, 1, 7): chr  "2005-01" "2005-02" "2005-03"
# $ Sum                   : num  4.88 2.27 0.06
# $ Median                : num  0.05 0 0.01
# $ Max                   : num  1.12 0.65 0.05

names(agg)[1] <- "Month"
agg
#    Month  Sum Median  Max
#1 2005-01 4.88   0.05 1.12
#2 2005-02 2.27   0.00 0.65
#3 2005-03 0.06   0.01 0.05


Finally, try to get some practice with the formula interface, you will 
see that it pays in code simplicity and readability.


Hope this helps,

Rui Barradas

?s 22:19 de 07/09/2018, Rich Shepard escreveu:
>  ? I've read ?aggregate and several blog posts on using aggregate() yet I
> still haven't applied it correctly to my dataframe. The sample data are:
> 
> structure(list(sampdate = c("2005-01-01", "2005-01-02", "2005-01-03", 
> "2005-01-04", "2005-01-05", "2005-01-06", "2005-01-07", "2005-01-08", 
> "2005-01-09", "2005-01-10", "2005-01-11", "2005-01-12", "2005-01-13", 
> "2005-01-14", "2005-01-15", "2005-01-16", "2005-01-17", "2005-01-18", 
> "2005-01-19", "2005-01-20", "2005-01-21", "2005-01-22", "2005-01-23", 
> "2005-01-24", "2005-01-25", "2005-01-26", "2005-01-27", "2005-01-28", 
> "2005-01-29", "2005-01-30", "2005-01-31", "2005-02-01", "2005-02-02", 
> "2005-02-03", "2005-02-04", "2005-02-05", "2005-02-06", "2005-02-07", 
> "2005-02-08", "2005-02-09", "2005-02-10", "2005-02-11", "2005-02-12", 
> "2005-02-13", "2005-02-14", "2005-02-15", "2005-02-16", "2005-02-17", 
> "2005-02-18", "2005-02-19", "2005-02-20", "2005-02-21", "2005-02-22", 
> "2005-02-23", "2005-02-24", "2005-02-25", "2005-02-26", "2005-02-27", 
> "2005-02-28", "2005-03-01", "2005-03-02", "2005-03-03"), prcp = c(0.59, 
> 0.08, 0.1, 0, 0, 0.02, 0.05, 0.1, 0, 0.02, 0, 0.05, 0.2, 0, 0, 0.5, 
> 0.41, 0.84, 0.01, 0.1, 0.01, 0, 0, 0, 0, 0.21, 0.24, 0.13, 1.12, 0.01, 
> 0.09, 0, 0, 0, 0.35, 0.18, 0.65, 0.16, 0, 0, 0, 0, 0.55, 0.21, 0, 0, 0, 
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.05, 0.01, 0)), row.names = 
> c(NA, 62L), class = "data.frame")
> 
>  ? What I need to learn how to do is to calculate monthly sum, median, and
> maximum rainfall amounts from the full data set which has daily rainfall
> amounts. My most current effort to calculate monthly sums uses this syntax:
> 
> monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
> substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)
> 
> (entered on a single line) which produces this result:
> 
> head(monthly.rain)
> [1] NA
> 
>  ? The sample data has 62 of the 113K rows in the dataframe. A larger 
> set can
> be provided if needed.
> 
>  ? An explanation of what I've missed is needed.
> 
> Regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @hivipmp82 @ending from gm@il@com  Sat Sep  8 15:12:47 2018
From: @hivipmp82 @ending from gm@il@com (Shivi Bhatia)
Date: Sat, 8 Sep 2018 18:42:47 +0530
Subject: [R] argument "string" is missing, with no default
Message-ID: <CAB=p7Sr3CXuWJwcKXhXSy4pyB7ewqcQi7wb40EO+8_F3SLSTbw@mail.gmail.com>

Hi All,

I am trying to fetch data from a pdf file with the below code but getting
the error message:
Error in stri_split_regex(string, pattern, n = n, simplify = simplify,  :
  argument "string" is missing, with no default

library(readr)library(stringr)library(magrittr)library(dplyr)
table_data <- nvsr65_05[ [ 14 ] ] %>%
  str_split(pattern = "\n") %>%
  unlist() %>%
  str_subset(pattern = "^[^?].*(\\. ){5}") %>%
  str_c(collapse = "\n") %>%
  read_table(col_names = FALSE) %>%
  mutate(X2 = str_replace_all(X2, "(\\. )*", ""),
	 X5 = rep(c("Neonatal", "Postnatal"), each = 10)) %>%
  set_names(value = c("rank", "cause_of_death", "deaths", "percent", "group"))

Please advice. Thank you.

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Sat Sep  8 16:13:32 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sat, 8 Sep 2018 10:13:32 -0400
Subject: [R] argument "string" is missing, with no default
In-Reply-To: <CAB=p7Sr3CXuWJwcKXhXSy4pyB7ewqcQi7wb40EO+8_F3SLSTbw@mail.gmail.com>
References: <CAB=p7Sr3CXuWJwcKXhXSy4pyB7ewqcQi7wb40EO+8_F3SLSTbw@mail.gmail.com>
Message-ID: <0cc0f425-bd85-45e2-5a24-73ce9fc2cf71@gmail.com>

On 08/09/2018 9:12 AM, Shivi Bhatia wrote:
> Hi All,
> 
> I am trying to fetch data from a pdf file with the below code but getting
> the error message:
> Error in stri_split_regex(string, pattern, n = n, simplify = simplify,  :
>    argument "string" is missing, with no default
> 
> library(readr)library(stringr)library(magrittr)library(dplyr)
> table_data <- nvsr65_05[ [ 14 ] ] %>%
>    str_split(pattern = "\n") %>%
>    unlist() %>%
>    str_subset(pattern = "^[^?].*(\\. ){5}") %>%
>    str_c(collapse = "\n") %>%
>    read_table(col_names = FALSE) %>%
>    mutate(X2 = str_replace_all(X2, "(\\. )*", ""),
> 	 X5 = rep(c("Neonatal", "Postnatal"), each = 10)) %>%
>    set_names(value = c("rank", "cause_of_death", "deaths", "percent", "group"))
> 
> Please advice. Thank you.

Use traceback() to see which function called stri_split_regex.

Break up the long pipeline into smaller parts so you can see where the 
error is comming from.

Don't post in HTML.

Duncan Murdoch


From r@hep@rd @ending from @ppl-eco@y@@com  Sat Sep  8 16:43:27 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Sat, 8 Sep 2018 07:43:27 -0700 (PDT)
Subject: [R] Correctly applying aggregate.ts()
In-Reply-To: <508c4296-5165-564d-4dcc-d1e880fc75f7@sapo.pt>
References: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
 <508c4296-5165-564d-4dcc-d1e880fc75f7@sapo.pt>
Message-ID: <alpine.LNX.2.20.1809080739370.21814@salmo.appl-ecosys.com>

On Sat, 8 Sep 2018, Rui Barradas wrote:

> Like Bert said, your data is a data.frame so there is no need to call 
> aggregate.ts. Besides, R will call the right method so unless you want to 
> change the standard behaviour, it would be enough to call aggregate and let 
> the methods dispatch code to its job.

Rui,

   I have no excuse (and certainly no valid reason) for not calling aggregate
itself.

   <Exceptionlly well written tutorial deleted.>

> Hope this helps,

   Very much so. It has also strengthed my abilities to learn how to use
other functions new to me.

Best regards,

Rich


From @hi_peiji@n @ending from 163@com  Sat Sep  8 14:33:54 2018
From: @hi_peiji@n @ending from 163@com (shi_peijian)
Date: Sat, 8 Sep 2018 20:33:54 +0800 (CST)
Subject: [R] How can I know the Hausdorff dimensions of fractals in the
 'fractalcurve' function of package 'pracma'?
Message-ID: <153827cd.526d.165b92ca112.Coremail.shi_peijian@163.com>

Dear Dr. Hans W. Borchers,




I'm using your 'pracma' package. It is very useful. May I have a small question for the 'fractalcurve' function? How can I know the Hausdorff dimension for every option below?


c("hilbert", "sierpinski", "snowflake", "dragon", "triangle", "arrowhead", "flowsnake", "molecule")


For the "dragon" option, its Hausdorff dimension is log(4)/log(2) = 2. For the others, what are the Hausdorff dimensions?


I have found the list of some fractals by Hausforff dimensions. I don't know which in the above option corresponds to which in Wikepedia.


Thanks a lot!


Best wishes,


Peijian Shi







--


Peijian (Joe)  Shi, Ph.D.

Research interests: forest ecology; theoretical ecology; thermal biology

Bamboo Research Institute, Nanjing Forestry University, P.R. China

159 Longpan Road, Nanjing City, Jiangsu Province 210037

Office:  60817  Biotechnology Building
	[[alternative HTML version deleted]]


From ddi@@b01 @ending from gm@il@com  Mon Sep 10 00:49:45 2018
From: ddi@@b01 @ending from gm@il@com (David Disabato)
Date: Sun, 9 Sep 2018 18:49:45 -0400
Subject: [R] For loop with multiple iteration indexes
Message-ID: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>

Hi R-help,

I am trying to create a for loop with multiple iteration indexes. I don't
want to use two different for loops nested together because I don't need
the full matrix of the two indexes, just the diagonal elements (e.g., i[1]
& j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to specify
both i and j in a single for loop? Here is a simplified example of
pseudo-code where x and y are equally sized character vectors with column
names and dat is their dataframe (obviously this code doesn't run in R, but
hopefully you perceive my goal):

r <- list()
n <- 0
for (i in x; j in y) {
   n <- n + 1
   r[[n]] <- cor(x = dat[, i], y = dat[, j])
}
print(r)

I realize there are other solutions to this particular correlation example,
but my actual problem is much more complicated, so I am hoping for a
solution that generalizes across any code within the for loop.

-- 
David J. Disabato, M.A.
Clinical Psychology Doctoral Student
George Mason University
ddisabat at gmu.edu

Email is not a secure form of communication as information and
confidentiality cannot be guaranteed. Information provided in an email is
not intended to be a professional service. In the case of a crisis or
emergency situation, call 911.

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Mon Sep 10 07:16:00 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Mon, 10 Sep 2018 15:16:00 +1000
Subject: [R] For loop with multiple iteration indexes
In-Reply-To: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
References: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
Message-ID: <CA+8X3fXVJoCQG0HWguMUFc8BfMxisQ+o4=XB1qJgv3Ddw4es5g@mail.gmail.com>

Hi David,
If you mean that you have two data frames named x and y and want the
correlations between the columns that would be on the diagonal of a
correlation matrix:

r<-list()
for(i in 1:n) r[[i]]<-cor(x[,i],y[,i])

If I'm wrong, let me know.

Jim

On Mon, Sep 10, 2018 at 3:06 PM David Disabato <ddisab01 at gmail.com> wrote:
>
> Hi R-help,
>
> I am trying to create a for loop with multiple iteration indexes. I don't
> want to use two different for loops nested together because I don't need
> the full matrix of the two indexes, just the diagonal elements (e.g., i[1]
> & j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to specify
> both i and j in a single for loop? Here is a simplified example of
> pseudo-code where x and y are equally sized character vectors with column
> names and dat is their dataframe (obviously this code doesn't run in R, but
> hopefully you perceive my goal):
>
> r <- list()
> n <- 0
> for (i in x; j in y) {
>    n <- n + 1
>    r[[n]] <- cor(x = dat[, i], y = dat[, j])
> }
> print(r)
>
> I realize there are other solutions to this particular correlation example,
> but my actual problem is much more complicated, so I am hoping for a
> solution that generalizes across any code within the for loop.
>
> --
> David J. Disabato, M.A.
> Clinical Psychology Doctoral Student
> George Mason University
> ddisabat at gmu.edu
>
> Email is not a secure form of communication as information and
> confidentiality cannot be guaranteed. Information provided in an email is
> not intended to be a professional service. In the case of a crisis or
> emergency situation, call 911.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @lk@uffm @ending from f@@tm@il@fm  Mon Sep 10 08:34:36 2018
From: @lk@uffm @ending from f@@tm@il@fm (Albrecht Kauffmann)
Date: Mon, 10 Sep 2018 08:34:36 +0200
Subject: [R] For loop with multiple iteration indexes
In-Reply-To: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
References: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
Message-ID: <1536561276.175268.1502469920.41D712F8@webmail.messagingengine.com>

Hi,

this simple example is very similarly, and it works in R:

r <- list()
n <- 0
x <- c("a","b","c")#x,y: Data from a dataframe
y <- c("A","B","C")
for (k in 1:3) {
    n <- n+1
    r[[n]] <- paste0(x[k],y[k])#or any other function using x[k] and y[k] as arguments
}
print(r)

Is it this what you meant?

Best,
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mo, 10. Sep 2018, um 00:49, schrieb David Disabato:
> Hi R-help,
> 
> I am trying to create a for loop with multiple iteration indexes. I don't
> want to use two different for loops nested together because I don't need
> the full matrix of the two indexes, just the diagonal elements (e.g., i[1]
> & j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to specify
> both i and j in a single for loop? Here is a simplified example of
> pseudo-code where x and y are equally sized character vectors with column
> names and dat is their dataframe (obviously this code doesn't run in R, but
> hopefully you perceive my goal):
> 
> r <- list()
> n <- 0
> for (i in x; j in y) {
>    n <- n + 1
>    r[[n]] <- cor(x = dat[, i], y = dat[, j])
> }
> print(r)
> 
> I realize there are other solutions to this particular correlation example,
> but my actual problem is much more complicated, so I am hoping for a
> solution that generalizes across any code within the for loop.
> 
> -- 
> David J. Disabato, M.A.
> Clinical Psychology Doctoral Student
> George Mason University
> ddisabat at gmu.edu
> 
> Email is not a secure form of communication as information and
> confidentiality cannot be guaranteed. Information provided in an email is
> not intended to be a professional service. In the case of a crisis or
> emergency situation, call 911.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @pencer@gr@ve@ @ending from effectivedefen@e@org  Mon Sep 10 10:09:22 2018
From: @pencer@gr@ve@ @ending from effectivedefen@e@org (Spencer Graves)
Date: Mon, 10 Sep 2018 03:09:22 -0500
Subject: [R] real time monitoring of streaming audio with R?
Message-ID: <17ec99d3-d956-9195-a4fc-1b90a3101089@effectivedefense.org>

Hello, All:


 ????? Is it feasible to do real time monitoring of streaming audio with 
R, writing a compressed copy of what's read to 1-hour long MP3 files?


 ????? I'm a volunteer with a community radio station (kkfi.org).? My 
minimum requirements at the moment are to create MP3 files from what we 
broadcast.? I have a tuner hooked to the audio input of a computer.? I 
can listen to it in real time using the computer audio output jack, and 
I can record it manually using Audacity.? If I have MP3 versions of both 
what we send to the tower and what is actually broadcasted, I can read 
the two into R, compare them, identify substantive differences, write 
appropriate descriptions to files, send emails, etc.? I don't know how 
to sample the live stream.


 ?????? I know it can be done in Python, but I don't know how, and I'd 
prefer to use R.? I suspect it can be done with ffplay, part of ffmpeg, 
but again I don't know how.


 ????? Thanks,
 ????? Spencer Graves


From p_connolly @ending from @ling@hot@co@nz  Mon Sep 10 10:54:38 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Mon, 10 Sep 2018 20:54:38 +1200
Subject: [R] Why can't I make use of tcltk in this installation?
Message-ID: <20180910085438.GA5433@slingshot.co.nz>

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
 [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
 [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] utils     stats     grDevices graphics  methods   base     

other attached packages:
[1] lattice_0.20-35

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.17     dplyr_0.7.6      assertthat_0.2.0 grid_3.5.0      
 [5] R6_2.2.2         magrittr_1.5     pillar_1.2.3     rlang_0.2.1     
 [9] bindrcpp_0.2.2   tools_3.5.0      glue_1.2.0       purrr_0.2.5     
[13] compiler_3.5.0   pkgconfig_2.0.1  bindr_0.1.1      tidyselect_0.2.4
[17] tibble_1.4.2    
> capabilities()
       jpeg         png        tiff       tcltk         X11        aqua 
       TRUE        TRUE        TRUE       FALSE        TRUE       FALSE 
   http/ftp     sockets      libxml        fifo      cledit       iconv 
       TRUE        TRUE        TRUE        TRUE       FALSE        TRUE 
        NLS     profmem       cairo         ICU long.double     libcurl 
       TRUE       FALSE        TRUE        TRUE        TRUE        TRUE 
> 

If I try to load tcltk, no surprise...

> require(tcltk)
Loading required package: tcltk
Error: package or namespace load failed for ?tcltk?:
 .onLoad failed in loadNamespace() for 'tcltk', details:
  call: fun(libname, pkgname)
  error: Tcl/Tk support is not available on this system
Warning message:
S3 methods ?as.character.tclObj?, ?as.character.tclVar?, ?as.double.tclObj?, ?as.integer.tclObj?, ?as.logical.tclObj?, ?as.raw.tclObj?, ?print.tclObj?, ?[[.tclArray?, ?[[<-.tclArray?, ?$.tclArray?, ?$<-.tclArray?, ?names.tclArray?, ?names<-.tclArray?, ?length.tclArray?, ?length<-.tclArray?, ?tclObj.tclVar?, ?tclObj<-.tclVar?, ?tclvalue.default?, ?tclvalue.tclObj?, ?tclvalue.tclVar?, ?tclvalue<-.default?, ?tclvalue<-.tclVar?, ?close.tkProgressBar? were declared in NAMESPACE but not found 
> 

The question is:  What do I have to do to get Tcl/Tk support?
>From the bash prompt:
 > aptitude search tcltk
p   hfsutils-tcltk             - Tcl/Tk interfaces for reading and writing Macintosh volumes 
p   hfsutils-tcltk:i386        - Tcl/Tk interfaces for reading and writing Macintosh volumes 
p   libtcltk-ruby              - Tcl/Tk interface for Ruby           
p   libtcltk-ruby1.9.1         - Tcl/Tk interface for Ruby 1.9.1
p   libtcltk-ruby1.9.1:i386    - Tcl/Tk interface for Ruby 1.9.1
p   r-cran-tcltk2              - GNU R package for Tcl/Tk additions 
p   ruby2.0-tcltk              - Ruby/Tk for Ruby 2.0
p   ruby2.0-tcltk:i386         - Ruby/Tk for Ruby 2.0  

That's the same as what I get on another computer on which tcktl is
available, so it didn't surprise me when installing the r-cran-tcktl
package didn't help.

Where else should I be looking for a difference?

TIA


-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From @lk@uffm @ending from f@@tm@il@fm  Mon Sep 10 12:37:58 2018
From: @lk@uffm @ending from f@@tm@il@fm (Albrecht Kauffmann)
Date: Mon, 10 Sep 2018 12:37:58 +0200
Subject: [R] Why can't I make use of tcltk in this installation?
In-Reply-To: <20180910085438.GA5433@slingshot.co.nz>
References: <20180910085438.GA5433@slingshot.co.nz>
Message-ID: <1536575878.229467.1502681072.67196379@webmail.messagingengine.com>

Hi Patrick,

did you give the compiler path instructions to tclConfig.sh and tkConfig.sh , as

../R-3.5.1/configure  --with-tcl-config=/usr/lib64/tclConfig.sh --with-tk-config=/usr/lib64/tkConfig.sh

?

Best,
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mo, 10. Sep 2018, um 10:54, schrieb Patrick Connolly:
> > sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.5 LTS
> 
> Matrix products: default
> BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
> LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so
> 
> locale:
>  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
>  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
>  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
>  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       
> 
> attached base packages:
> [1] utils     stats     grDevices graphics  methods   base     
> 
> other attached packages:
> [1] lattice_0.20-35
> 
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.17     dplyr_0.7.6      assertthat_0.2.0 grid_3.5.0      
>  [5] R6_2.2.2         magrittr_1.5     pillar_1.2.3     rlang_0.2.1     
>  [9] bindrcpp_0.2.2   tools_3.5.0      glue_1.2.0       purrr_0.2.5     
> [13] compiler_3.5.0   pkgconfig_2.0.1  bindr_0.1.1      tidyselect_0.2.4
> [17] tibble_1.4.2    
> > capabilities()
>        jpeg         png        tiff       tcltk         X11        aqua 
>        TRUE        TRUE        TRUE       FALSE        TRUE       FALSE 
>    http/ftp     sockets      libxml        fifo      cledit       iconv 
>        TRUE        TRUE        TRUE        TRUE       FALSE        TRUE 
>         NLS     profmem       cairo         ICU long.double     libcurl 
>        TRUE       FALSE        TRUE        TRUE        TRUE        TRUE 
> > 
> 
> If I try to load tcltk, no surprise...
> 
> > require(tcltk)
> Loading required package: tcltk
> Error: package or namespace load failed for ?tcltk?:
>  .onLoad failed in loadNamespace() for 'tcltk', details:
>   call: fun(libname, pkgname)
>   error: Tcl/Tk support is not available on this system
> Warning message:
> S3 methods ?as.character.tclObj?, ?as.character.tclVar?, 
> ?as.double.tclObj?, ?as.integer.tclObj?, ?as.logical.tclObj?, 
> ?as.raw.tclObj?, ?print.tclObj?, ?[[.tclArray?, ?[[<-.tclArray?, 
> ?$.tclArray?, ?$<-.tclArray?, ?names.tclArray?, ?names<-.tclArray?, 
> ?length.tclArray?, ?length<-.tclArray?, ?tclObj.tclVar?, 
> ?tclObj<-.tclVar?, ?tclvalue.default?, ?tclvalue.tclObj?, 
> ?tclvalue.tclVar?, ?tclvalue<-.default?, ?tclvalue<-.tclVar?, 
> ?close.tkProgressBar? were declared in NAMESPACE but not found 
> > 
> 
> The question is:  What do I have to do to get Tcl/Tk support?
> From the bash prompt:
>  > aptitude search tcltk
> p   hfsutils-tcltk             - Tcl/Tk interfaces for reading and 
> writing Macintosh volumes 
> p   hfsutils-tcltk:i386        - Tcl/Tk interfaces for reading and 
> writing Macintosh volumes 
> p   libtcltk-ruby              - Tcl/Tk interface for Ruby           
> p   libtcltk-ruby1.9.1         - Tcl/Tk interface for Ruby 1.9.1
> p   libtcltk-ruby1.9.1:i386    - Tcl/Tk interface for Ruby 1.9.1
> p   r-cran-tcltk2              - GNU R package for Tcl/Tk additions 
> p   ruby2.0-tcltk              - Ruby/Tk for Ruby 2.0
> p   ruby2.0-tcltk:i386         - Ruby/Tk for Ruby 2.0  
> 
> That's the same as what I get on another computer on which tcktl is
> available, so it didn't surprise me when installing the r-cran-tcktl
> package didn't help.
> 
> Where else should I be looking for a difference?
> 
> TIA
> 
> 
> -- 
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
>    ___    Patrick Connolly   
>  {~._.~}                   Great minds discuss ideas    
>  _( Y )_  	         Average minds discuss events 
> (:_~*~_:)                  Small minds discuss people  
>  (_)-(_)  	                      ..... Eleanor Roosevelt
> 	  
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@lgd @ending from gm@il@com  Mon Sep 10 13:06:59 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Mon, 10 Sep 2018 13:06:59 +0200
Subject: [R] Why can't I make use of tcltk in this installation?
In-Reply-To: <1536575878.229467.1502681072.67196379@webmail.messagingengine.com>
References: <20180910085438.GA5433@slingshot.co.nz>
 <1536575878.229467.1502681072.67196379@webmail.messagingengine.com>
Message-ID: <BE7C6055-211C-4FD4-ACBC-95BA7B1DCCFC@gmail.com>

You may need to consult the R-sig-debian list, rather than R-help.

Offhand, I would expect that you need Tcl libraries, Tk libraries and the associated -devel or -dev packages. Notice that although they are designed to work together, Tcl and Tk are two separate entities, so searching for tcltk may not suffice.

-pd

> On 10 Sep 2018, at 12:37 , Albrecht Kauffmann <alkauffm at fastmail.fm> wrote:
> 
> Hi Patrick,
> 
> did you give the compiler path instructions to tclConfig.sh and tkConfig.sh , as
> 
> ../R-3.5.1/configure  --with-tcl-config=/usr/lib64/tclConfig.sh --with-tk-config=/usr/lib64/tkConfig.sh
> 
> ?
> 
> Best,
> Albrecht
> 
> -- 
>  Albrecht Kauffmann
>  alkauffm at fastmail.fm
> 
> Am Mo, 10. Sep 2018, um 10:54, schrieb Patrick Connolly:
>>> sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.5 LTS
>> 
>> Matrix products: default
>> BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
>> LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so
>> 
>> locale:
>> [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
>> [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
>> [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
>> [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       
>> 
>> attached base packages:
>> [1] utils     stats     grDevices graphics  methods   base     
>> 
>> other attached packages:
>> [1] lattice_0.20-35
>> 
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.12.17     dplyr_0.7.6      assertthat_0.2.0 grid_3.5.0      
>> [5] R6_2.2.2         magrittr_1.5     pillar_1.2.3     rlang_0.2.1     
>> [9] bindrcpp_0.2.2   tools_3.5.0      glue_1.2.0       purrr_0.2.5     
>> [13] compiler_3.5.0   pkgconfig_2.0.1  bindr_0.1.1      tidyselect_0.2.4
>> [17] tibble_1.4.2    
>>> capabilities()
>>       jpeg         png        tiff       tcltk         X11        aqua 
>>       TRUE        TRUE        TRUE       FALSE        TRUE       FALSE 
>>   http/ftp     sockets      libxml        fifo      cledit       iconv 
>>       TRUE        TRUE        TRUE        TRUE       FALSE        TRUE 
>>        NLS     profmem       cairo         ICU long.double     libcurl 
>>       TRUE       FALSE        TRUE        TRUE        TRUE        TRUE 
>>> 
>> 
>> If I try to load tcltk, no surprise...
>> 
>>> require(tcltk)
>> Loading required package: tcltk
>> Error: package or namespace load failed for ?tcltk?:
>> .onLoad failed in loadNamespace() for 'tcltk', details:
>>  call: fun(libname, pkgname)
>>  error: Tcl/Tk support is not available on this system
>> Warning message:
>> S3 methods ?as.character.tclObj?, ?as.character.tclVar?, 
>> ?as.double.tclObj?, ?as.integer.tclObj?, ?as.logical.tclObj?, 
>> ?as.raw.tclObj?, ?print.tclObj?, ?[[.tclArray?, ?[[<-.tclArray?, 
>> ?$.tclArray?, ?$<-.tclArray?, ?names.tclArray?, ?names<-.tclArray?, 
>> ?length.tclArray?, ?length<-.tclArray?, ?tclObj.tclVar?, 
>> ?tclObj<-.tclVar?, ?tclvalue.default?, ?tclvalue.tclObj?, 
>> ?tclvalue.tclVar?, ?tclvalue<-.default?, ?tclvalue<-.tclVar?, 
>> ?close.tkProgressBar? were declared in NAMESPACE but not found 
>>> 
>> 
>> The question is:  What do I have to do to get Tcl/Tk support?
>> From the bash prompt:
>>> aptitude search tcltk
>> p   hfsutils-tcltk             - Tcl/Tk interfaces for reading and 
>> writing Macintosh volumes 
>> p   hfsutils-tcltk:i386        - Tcl/Tk interfaces for reading and 
>> writing Macintosh volumes 
>> p   libtcltk-ruby              - Tcl/Tk interface for Ruby           
>> p   libtcltk-ruby1.9.1         - Tcl/Tk interface for Ruby 1.9.1
>> p   libtcltk-ruby1.9.1:i386    - Tcl/Tk interface for Ruby 1.9.1
>> p   r-cran-tcltk2              - GNU R package for Tcl/Tk additions 
>> p   ruby2.0-tcltk              - Ruby/Tk for Ruby 2.0
>> p   ruby2.0-tcltk:i386         - Ruby/Tk for Ruby 2.0  
>> 
>> That's the same as what I get on another computer on which tcktl is
>> available, so it didn't surprise me when installing the r-cran-tcktl
>> package didn't help.
>> 
>> Where else should I be looking for a difference?
>> 
>> TIA
>> 
>> 
>> -- 
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
>>   ___    Patrick Connolly   
>> {~._.~}                   Great minds discuss ideas    
>> _( Y )_  	         Average minds discuss events 
>> (:_~*~_:)                  Small minds discuss people  
>> (_)-(_)  	                      ..... Eleanor Roosevelt
>> 	  
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ccberry @ending from uc@d@edu  Mon Sep 10 17:29:50 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Mon, 10 Sep 2018 15:29:50 +0000
Subject: [R] For loop with multiple iteration indexes
In-Reply-To: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
References: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
Message-ID: <F226B06A-9457-47DF-A9F0-9B995D999475@ucsd.edu>

I have a sense of deja vu:

https://www.mail-archive.com/r-help at r-project.org/msg250494.html

There is some good advice there.

> On Sep 9, 2018, at 3:49 PM, David Disabato <ddisab01 at gmail.com> wrote:
> 
> Hi R-help,
> 
> I am trying to create a for loop with multiple iteration indexes. I don't
> want to use two different for loops nested together because I don't need
> the full matrix of the two indexes, just the diagonal elements (e.g., i[1]
> & j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to specify
> both i and j in a single for loop? Here is a simplified example of
> pseudo-code where x and y are equally sized character vectors with column
> names and dat is their dataframe (obviously this code doesn't run in R, but
> hopefully you perceive my goal):
> 
> r <- list()
> n <- 0
> for (i in x; j in y) {
>   n <- n + 1
>   r[[n]] <- cor(x = dat[, i], y = dat[, j])
> }
> print(r)
> 
> I realize there are other solutions to this particular correlation example,
> but my actual problem is much more complicated, so I am hoping for a
> solution that generalizes across any code within the for loop.

A more aRtful way (than a for loop) to approach this is with mapply:

	
i <- head(colnames(mtcars))
j <- tail(colnames(mtcars))

r <- mapply(function(i, j, dat) cor( x = dat[, i], y = dat[, j]),
       i=i , j=j , MoreArgs = list( dat = mtcars), 
       SIMPLIFY = FALSE, USE.NAMES = FALSE)


and if you want, maybe USE.NAMES = paste(i, j, sep="_")

Chuck


From k@kowit@ki @ending from icloud@com  Mon Sep 10 17:54:27 2018
From: k@kowit@ki @ending from icloud@com (Kevin Kowitski)
Date: Mon, 10 Sep 2018 15:54:27 +0000 (GMT)
Subject: [R] Packaged exe and Shiny
Message-ID: <d71e9b46-7a37-4e1c-b6ca-8142baaadbcd@me.com>

Hey Everyone,?

? I do not know if this topic has been covered, I'm sure it must have, but is there a good environment for packaging R code into a distributed exe. (which includes all of the required libraries, etc.)?? I have seen that Shiny is a good GUI / Web library for sharing R programs, but I have never used it.?

What is the groups input on this???

My goal is to create some basic tools (with interfaces) at work for analyzing .csv files and generating basic graphs and output csv files. These tools would be distributed to team members to have on their desktops.? ?I considered doing this in Java, but I am more well versed in R so it would be quicker for me to whip up the varying tools in R than re-learning Java.?

Thank you!

-Kevin

From drjimlemon @ending from gm@il@com  Tue Sep 11 00:17:02 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 11 Sep 2018 08:17:02 +1000
Subject: [R] Packaged exe and Shiny
In-Reply-To: <d71e9b46-7a37-4e1c-b6ca-8142baaadbcd@me.com>
References: <d71e9b46-7a37-4e1c-b6ca-8142baaadbcd@me.com>
Message-ID: <CA+8X3fUQYVu2zhrd6DDu-a3wP2OVuF0DUBcFvwd5iG-US0x=ZQ@mail.gmail.com>

Hi Kevin,
It might be just as easy to write R scripts that would do basic
analyses. Users could "source" these scripts in an R session or from
the command line. The scripts would be much more compact than the .exe
files that you describe.

Jim

On Tue, Sep 11, 2018 at 8:06 AM Kevin Kowitski via R-help
<r-help at r-project.org> wrote:
>
> Hey Everyone,
>
>   I do not know if this topic has been covered, I'm sure it must have, but is there a good environment for packaging R code into a distributed exe. (which includes all of the required libraries, etc.)?  I have seen that Shiny is a good GUI / Web library for sharing R programs, but I have never used it.
>
> What is the groups input on this?
>
> My goal is to create some basic tools (with interfaces) at work for analyzing .csv files and generating basic graphs and output csv files. These tools would be distributed to team members to have on their desktops.   I considered doing this in Java, but I am more well versed in R so it would be quicker for me to whip up the varying tools in R than re-learning Java.
>
> Thank you!
>
> -Kevin
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Sep 11 00:58:47 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 10 Sep 2018 15:58:47 -0700
Subject: [R] Packaged exe and Shiny
In-Reply-To: <CA+8X3fUQYVu2zhrd6DDu-a3wP2OVuF0DUBcFvwd5iG-US0x=ZQ@mail.gmail.com>
References: <d71e9b46-7a37-4e1c-b6ca-8142baaadbcd@me.com>
 <CA+8X3fUQYVu2zhrd6DDu-a3wP2OVuF0DUBcFvwd5iG-US0x=ZQ@mail.gmail.com>
Message-ID: <4C65246C-FDF7-4D4C-9F40-E510D50F9206@dcn.davis.ca.us>

IMO the best short answer is don't target making an install package or msi at all... the obstacles are quite significant. Aim for building most of your capabilities in packages and having people install them. You can setup an in-house package repo to simplify this and give them a startup script that configures their R environment.

There is also the option to use R-Portable [1] but this leads to massive deployment files that don't upgrade easily.

I also think that when the time crunch happens many people will go to the internet and copy-paste solutions that you would be unlikely to have anticipated. Closing off that scary console completely will keep you in the hot seat indefinitely, whereas giving them the option to go around your UI lets more resources be allocated later.

[1] https://www.r-bloggers.com/deploying-desktop-apps-with-r/amp/

On September 10, 2018 3:17:02 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Kevin,
>It might be just as easy to write R scripts that would do basic
>analyses. Users could "source" these scripts in an R session or from
>the command line. The scripts would be much more compact than the .exe
>files that you describe.
>
>Jim
>
>On Tue, Sep 11, 2018 at 8:06 AM Kevin Kowitski via R-help
><r-help at r-project.org> wrote:
>>
>> Hey Everyone,
>>
>>   I do not know if this topic has been covered, I'm sure it must
>have, but is there a good environment for packaging R code into a
>distributed exe. (which includes all of the required libraries, etc.)? 
>I have seen that Shiny is a good GUI / Web library for sharing R
>programs, but I have never used it.
>>
>> What is the groups input on this?
>>
>> My goal is to create some basic tools (with interfaces) at work for
>analyzing .csv files and generating basic graphs and output csv files.
>These tools would be distributed to team members to have on their
>desktops.   I considered doing this in Java, but I am more well versed
>in R so it would be quicker for me to whip up the varying tools in R
>than re-learning Java.
>>
>> Thank you!
>>
>> -Kevin
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From p_connolly @ending from @ling@hot@co@nz  Tue Sep 11 01:52:33 2018
From: p_connolly @ending from @ling@hot@co@nz (p_connolly)
Date: Tue, 11 Sep 2018 11:52:33 +1200
Subject: [R] Why can't I make use of tcltk in this installation?
In-Reply-To: <1536575878.229467.1502681072.67196379@webmail.messagingengine.com>
References: <20180910085438.GA5433@slingshot.co.nz>
 <1536575878.229467.1502681072.67196379@webmail.messagingengine.com>
Message-ID: <fcb88bfc7392f86af31accdbe6a28d4f@slingshot.co.nz>

Hello Albrecht.

I didn't specify those paths on the 3 machines that have tcltk 
available.  It appears that those files are not on the machine in 
question and that is the reason for my problem.  But if they are, 
./configure finds them itself.

I'm not at the machine that has the issue, but I assume that since I get 
this on a machine that does work:

> dpkg -S tkConfig.sh
tk8.6-dev:amd64: /usr/lib/x86_64-linux-gnu/tk8.6/tkConfig.sh
tk8.6-dev:amd64: /usr/lib/tk8.6/tkConfig.sh
tk-dev:amd64: /usr/lib/x86_64-linux-gnu/tkConfig.sh
tk-dev:amd64: /usr/lib/tkConfig.sh

I need to install those two packages (and the corresponding ones for 
tcl) and reinstall R.

Thanks for the pointer, and thank you pd for drawing my attention to the 
fact that Tcl and Tk need to be done separately.




On 2018-09-10 22:37, Albrecht Kauffmann wrote:
> Hi Patrick,
> 
> did you give the compiler path instructions to tclConfig.sh and 
> tkConfig.sh , as
> 
> ../R-3.5.1/configure  --with-tcl-config=/usr/lib64/tclConfig.sh
> --with-tk-config=/usr/lib64/tkConfig.sh
> 
> ?
> 
> Best,
> Albrecht
> 
> --
>   Albrecht Kauffmann
>   alkauffm at fastmail.fm
> 
> Am Mo, 10. Sep 2018, um 10:54, schrieb Patrick Connolly:
>> > sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.5 LTS
>> 
>> Matrix products: default
>> BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
>> LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so
>> 
>> locale:
>>  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
>>  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
>>  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] utils     stats     grDevices graphics  methods   base
>> 
>> other attached packages:
>> [1] lattice_0.20-35
>> 
>> loaded via a namespace (and not attached):
>>  [1] Rcpp_0.12.17     dplyr_0.7.6      assertthat_0.2.0 grid_3.5.0
>>  [5] R6_2.2.2         magrittr_1.5     pillar_1.2.3     rlang_0.2.1
>>  [9] bindrcpp_0.2.2   tools_3.5.0      glue_1.2.0       purrr_0.2.5
>> [13] compiler_3.5.0   pkgconfig_2.0.1  bindr_0.1.1      
>> tidyselect_0.2.4
>> [17] tibble_1.4.2
>> > capabilities()
>>        jpeg         png        tiff       tcltk         X11        
>> aqua
>>        TRUE        TRUE        TRUE       FALSE        TRUE       
>> FALSE
>>    http/ftp     sockets      libxml        fifo      cledit       
>> iconv
>>        TRUE        TRUE        TRUE        TRUE       FALSE        
>> TRUE
>>         NLS     profmem       cairo         ICU long.double     
>> libcurl
>>        TRUE       FALSE        TRUE        TRUE        TRUE        
>> TRUE
>> >
>> 
>> If I try to load tcltk, no surprise...
>> 
>> > require(tcltk)
>> Loading required package: tcltk
>> Error: package or namespace load failed for ?tcltk?:
>>  .onLoad failed in loadNamespace() for 'tcltk', details:
>>   call: fun(libname, pkgname)
>>   error: Tcl/Tk support is not available on this system
>> Warning message:
>> S3 methods ?as.character.tclObj?, ?as.character.tclVar?,
>> ?as.double.tclObj?, ?as.integer.tclObj?, ?as.logical.tclObj?,
>> ?as.raw.tclObj?, ?print.tclObj?, ?[[.tclArray?, ?[[<-.tclArray?,
>> ?$.tclArray?, ?$<-.tclArray?, ?names.tclArray?, ?names<-.tclArray?,
>> ?length.tclArray?, ?length<-.tclArray?, ?tclObj.tclVar?,
>> ?tclObj<-.tclVar?, ?tclvalue.default?, ?tclvalue.tclObj?,
>> ?tclvalue.tclVar?, ?tclvalue<-.default?, ?tclvalue<-.tclVar?,
>> ?close.tkProgressBar? were declared in NAMESPACE but not found
>> >
>> 
>> The question is:  What do I have to do to get Tcl/Tk support?
>> From the bash prompt:
>>  > aptitude search tcltk
>> p   hfsutils-tcltk             - Tcl/Tk interfaces for reading and
>> writing Macintosh volumes
>> p   hfsutils-tcltk:i386        - Tcl/Tk interfaces for reading and
>> writing Macintosh volumes
>> p   libtcltk-ruby              - Tcl/Tk interface for Ruby
>> p   libtcltk-ruby1.9.1         - Tcl/Tk interface for Ruby 1.9.1
>> p   libtcltk-ruby1.9.1:i386    - Tcl/Tk interface for Ruby 1.9.1
>> p   r-cran-tcltk2              - GNU R package for Tcl/Tk additions
>> p   ruby2.0-tcltk              - Ruby/Tk for Ruby 2.0
>> p   ruby2.0-tcltk:i386         - Ruby/Tk for Ruby 2.0
>> 
>> That's the same as what I get on another computer on which tcktl is
>> available, so it didn't surprise me when installing the r-cran-tcktl
>> package didn't help.
>> 
>> Where else should I be looking for a difference?
>> 
>> TIA
>> 
>> 
>> --
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>>    ___    Patrick Connolly
>>  {~._.~}                   Great minds discuss ideas
>>  _( Y )_  	         Average minds discuss events
>> (:_~*~_:)                  Small minds discuss people
>>  (_)-(_)  	                      ..... Eleanor Roosevelt
>> 
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ddi@@b01 @ending from gm@il@com  Tue Sep 11 03:32:57 2018
From: ddi@@b01 @ending from gm@il@com (David Disabato)
Date: Mon, 10 Sep 2018 21:32:57 -0400
Subject: [R] For loop with multiple iteration indexes
In-Reply-To: <F226B06A-9457-47DF-A9F0-9B995D999475@ucsd.edu>
References: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
 <F226B06A-9457-47DF-A9F0-9B995D999475@ucsd.edu>
Message-ID: <CACg0228eV_KsSyHpT6iBVhSyQ1hfFv2Nazj7a1JJrpMOfVQDLg@mail.gmail.com>

Thank you everyone. After thinking about each response, I realized a fairly
simple solution is available (obviously, other suggested approaches work as
well):

stopifnot(length(x) == length(y); stopifnot(length(x) > 0)
r <- list()
for (i in 1:length(x) ) {
   r[[i]] <- cor(x = dat[, x[i] ], y = dat[, y[i] ])
}
print(r)

On Mon, Sep 10, 2018 at 11:30 AM Berry, Charles <ccberry at ucsd.edu> wrote:

> I have a sense of deja vu:
>
> https://www.mail-archive.com/r-help at r-project.org/msg250494.html
>
> There is some good advice there.
>
> > On Sep 9, 2018, at 3:49 PM, David Disabato <ddisab01 at gmail.com> wrote:
> >
> > Hi R-help,
> >
> > I am trying to create a for loop with multiple iteration indexes. I don't
> > want to use two different for loops nested together because I don't need
> > the full matrix of the two indexes, just the diagonal elements (e.g.,
> i[1]
> > & j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to specify
> > both i and j in a single for loop? Here is a simplified example of
> > pseudo-code where x and y are equally sized character vectors with column
> > names and dat is their dataframe (obviously this code doesn't run in R,
> but
> > hopefully you perceive my goal):
> >
> > r <- list()
> > n <- 0
> > for (i in x; j in y) {
> >   n <- n + 1
> >   r[[n]] <- cor(x = dat[, i], y = dat[, j])
> > }
> > print(r)
> >
> > I realize there are other solutions to this particular correlation
> example,
> > but my actual problem is much more complicated, so I am hoping for a
> > solution that generalizes across any code within the for loop.
>
> A more aRtful way (than a for loop) to approach this is with mapply:
>
>
> i <- head(colnames(mtcars))
> j <- tail(colnames(mtcars))
>
> r <- mapply(function(i, j, dat) cor( x = dat[, i], y = dat[, j]),
>        i=i , j=j , MoreArgs = list( dat = mtcars),
>        SIMPLIFY = FALSE, USE.NAMES = FALSE)
>
>
> and if you want, maybe USE.NAMES = paste(i, j, sep="_")
>
> Chuck
>
>

-- 
David J. Disabato, M.A.
Clinical Psychology Doctoral Student
George Mason University
ddisabat at gmu.edu

Email is not a secure form of communication as information and
confidentiality cannot be guaranteed. Information provided in an email is
not intended to be a professional service. In the case of a crisis or
emergency situation, call 911.

	[[alternative HTML version deleted]]


From kri@ti@glover @ending from hotm@il@com  Tue Sep 11 08:52:06 2018
From: kri@ti@glover @ending from hotm@il@com (Kristi Glover)
Date: Tue, 11 Sep 2018 06:52:06 +0000
Subject: [R] loop for comparing two or more groups using bootstrapping
Message-ID: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>

Hi R users,

I was trying to test a null hypothesis of difference between two groups was 0. I have many years data, such as year1, year2,, year3, year4 and I was trying to compare between year1 and year2, year1 and year3, year2 and year3 and so on and have used following code with an example data.


I tried to make a loop but did not work to compare between many years, and also want to obtain the exact p value. Would you mind to help me to make a loop?

Thanks for your help.


KG


daT<-structure(list(year1 = c(0.417, 0.538, 0.69, 0.688, 0.688, 0.606,

0.667, 0.7, 0.545, 0.462, 0.711, 0.642, 0.744, 0.604, 0.612,

0.667, 0.533, 0.556, 0.444, 0.526, 0.323, 0.308, 0.195, 0.333,

0.323, 0.256, 0.345, 0.205, 0.286, 0.706, 0.7, 0.6, 0.571, 0.364,

0.429, 0.326, 0.571, 0.424, 0.341, 0.387, 0.341, 0.324, 0.696,

0.696, 0.583, 0.556, 0.645, 0.435, 0.471, 0.556), year2 = c(0.385,

0.552, 0.645, 0.516, 0.629, 0.595, 0.72, 0.638, 0.557, 0.588,

0.63, 0.744, 0.773, 0.571, 0.723, 0.769, 0.667, 0.667, 0.526,

0.476, 0.294, 0.323, 0.222, 0.556, 0.263, 0.37, 0.357, 0.25,

0.323, 0.778, 0.667, 0.636, 0.583, 0.432, 0.412, 0.333, 0.571,

0.39, 0.4, 0.452, 0.326, 0.471, 0.7, 0.75, 0.615, 0.462, 0.556,

0.4, 0.696, 0.465), year3 = c(0.435, 0.759, 0.759, 0.759, 0.714,

0.593, 0.651, 0.683, 0.513, 0.643, 0.652, 0.757, 0.791, 0.649,

0.78, 0.5, 0.5, 0.5, 0.533, 0.429, 0.333, 0.286, 0.231, 0.533,

0.303, 0.417, 0.333, 0.333, 0.357, 0.909, 1, 0.952, 0.8, 0.556,

0.529, 0.562, 0.762, 0.513, 0.733, 0.611, 0.733, 0.647, 0.909,

0.857, 0.8, 0.556, 0.588, 0.562, 0.857, 0.513), year4 = c(0.333,

0.533, 0.6, 0.483, 0.743, 0.5, 0.691, 0.619, 0.583, 0.385, 0.653,

0.762, 0.844, 0.64, 0.667, 0.571, 0.571, 0.615, 0.421, 0.5, 0.205,

0.308, 0.25, 0.6, 0.242, 0.308, 0.276, 0.235, 0.211, 0.9, 0.632,

0.72, 0.727, 0.356, 0.5, 0.368, 0.5, 0.41, 0.562, 0.514, 0.4,

0.409, 0.632, 0.72, 0.727, 0.4, 0.5, 0.421, 0.5, 0.462)), .Names = c("year1",

"year2", "year3", "year4"), row.names = c(NA, -50L), class = "data.frame")

head(daT)

# null hypothesis; difference is equal to zero

dif1.2<-daT$year2-daT$year1

k=10000

mysamples1.2=replicate(k, sample(dif1.2, replace=T))

mymeans1.2=apply(mysamples1.2, 2, mean)

quantile(mymeans1.2, c(0.025, 0.975))

hist(mysamples1.2)

mean(mymeans1.2)

#what is p value?


#similarly Now I want to compare between year 1 and year3,

dif1.3<-daT$year3-daT$year1

mysamples1.3=replicate(k, sample(dif1.3, replace=T))

mymeans1.3=apply(mysamples1.3, 2, mean)

quantile(mymeans1.3, c(0.025, 0.975))


	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Tue Sep 11 09:44:46 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 11 Sep 2018 17:44:46 +1000
Subject: [R] loop for comparing two or more groups using bootstrapping
In-Reply-To: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
References: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
Message-ID: <CA+8X3fX6f6zT3VGbprbaOFMspKFijOncD0jiwodQ=cXShcnX_g@mail.gmail.com>

Hi Kristy,
Try this:

colname.mat<-combn(paste0("year",1:4),2)
samplenames<-apply(colname.mat,2,paste,collapse="")
k<-10000
for(column in 1:ncol(colname.mat)) {
 assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,column]]),3,TRUE)))
}

Then use get(samplenames[1]) and so on to access the values.

Jim
On Tue, Sep 11, 2018 at 4:52 PM Kristi Glover <kristi.glover at hotmail.com> wrote:
>
> Hi R users,
>
> I was trying to test a null hypothesis of difference between two groups was 0. I have many years data, such as year1, year2,, year3, year4 and I was trying to compare between year1 and year2, year1 and year3, year2 and year3 and so on and have used following code with an example data.
>
>
> I tried to make a loop but did not work to compare between many years, and also want to obtain the exact p value. Would you mind to help me to make a loop?
>
> Thanks for your help.
>
>
> KG
>
>
> daT<-structure(list(year1 = c(0.417, 0.538, 0.69, 0.688, 0.688, 0.606,
>
> 0.667, 0.7, 0.545, 0.462, 0.711, 0.642, 0.744, 0.604, 0.612,
>
> 0.667, 0.533, 0.556, 0.444, 0.526, 0.323, 0.308, 0.195, 0.333,
>
> 0.323, 0.256, 0.345, 0.205, 0.286, 0.706, 0.7, 0.6, 0.571, 0.364,
>
> 0.429, 0.326, 0.571, 0.424, 0.341, 0.387, 0.341, 0.324, 0.696,
>
> 0.696, 0.583, 0.556, 0.645, 0.435, 0.471, 0.556), year2 = c(0.385,
>
> 0.552, 0.645, 0.516, 0.629, 0.595, 0.72, 0.638, 0.557, 0.588,
>
> 0.63, 0.744, 0.773, 0.571, 0.723, 0.769, 0.667, 0.667, 0.526,
>
> 0.476, 0.294, 0.323, 0.222, 0.556, 0.263, 0.37, 0.357, 0.25,
>
> 0.323, 0.778, 0.667, 0.636, 0.583, 0.432, 0.412, 0.333, 0.571,
>
> 0.39, 0.4, 0.452, 0.326, 0.471, 0.7, 0.75, 0.615, 0.462, 0.556,
>
> 0.4, 0.696, 0.465), year3 = c(0.435, 0.759, 0.759, 0.759, 0.714,
>
> 0.593, 0.651, 0.683, 0.513, 0.643, 0.652, 0.757, 0.791, 0.649,
>
> 0.78, 0.5, 0.5, 0.5, 0.533, 0.429, 0.333, 0.286, 0.231, 0.533,
>
> 0.303, 0.417, 0.333, 0.333, 0.357, 0.909, 1, 0.952, 0.8, 0.556,
>
> 0.529, 0.562, 0.762, 0.513, 0.733, 0.611, 0.733, 0.647, 0.909,
>
> 0.857, 0.8, 0.556, 0.588, 0.562, 0.857, 0.513), year4 = c(0.333,
>
> 0.533, 0.6, 0.483, 0.743, 0.5, 0.691, 0.619, 0.583, 0.385, 0.653,
>
> 0.762, 0.844, 0.64, 0.667, 0.571, 0.571, 0.615, 0.421, 0.5, 0.205,
>
> 0.308, 0.25, 0.6, 0.242, 0.308, 0.276, 0.235, 0.211, 0.9, 0.632,
>
> 0.72, 0.727, 0.356, 0.5, 0.368, 0.5, 0.41, 0.562, 0.514, 0.4,
>
> 0.409, 0.632, 0.72, 0.727, 0.4, 0.5, 0.421, 0.5, 0.462)), .Names = c("year1",
>
> "year2", "year3", "year4"), row.names = c(NA, -50L), class = "data.frame")
>
> head(daT)
>
> # null hypothesis; difference is equal to zero
>
> dif1.2<-daT$year2-daT$year1
>
> k=10000
>
> mysamples1.2=replicate(k, sample(dif1.2, replace=T))
>
> mymeans1.2=apply(mysamples1.2, 2, mean)
>
> quantile(mymeans1.2, c(0.025, 0.975))
>
> hist(mysamples1.2)
>
> mean(mymeans1.2)
>
> #what is p value?
>
>
> #similarly Now I want to compare between year 1 and year3,
>
> dif1.3<-daT$year3-daT$year1
>
> mysamples1.3=replicate(k, sample(dif1.3, replace=T))
>
> mymeans1.3=apply(mysamples1.3, 2, mean)
>
> quantile(mymeans1.3, c(0.025, 0.975))
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From federico@c@lboli @ending from kuleuven@be  Tue Sep 11 09:34:51 2018
From: federico@c@lboli @ending from kuleuven@be (Federico Calboli)
Date: Tue, 11 Sep 2018 07:34:51 +0000
Subject: [R] getting 21 very different colours
Message-ID: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>

Hi All,

I am plotting a scatterplot of 21 populations, and I am using rainbow(21)[pops.col] to generate 21 colours for the plot (which works).  Maybe it is because I can really process few colours at a time, but the differences between the colours are not as strong as I?d like.  I can specify start and end for rainbow(), but if anything that looks worse if I do not just stick to 0 and 1.  

Is there a way of getting a set of 21 colours that maximises the differences between them?  

I could pick them by hand, but that is about 15 colours more than I know (I have a detailed colourchart, but the visual differences between ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).

Cheers

F
--
Federico Calboli
LBEG - Laboratory of Biodiversity and Evolutionary Genomics
Charles Deberiotstraat 32 box 2439
3000 Leuven
+32 16 32 87 67






From S@Elli@on @ending from LGCGroup@com  Tue Sep 11 12:08:25 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Tue, 11 Sep 2018 10:08:25 +0000
Subject: [R] getting 21 very different colours
In-Reply-To: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
References: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
Message-ID: <cb3c3ea557ea4a2d85d1dba4077992ba@GBDCVPEXC08.corp.lgc-group.com>

You could look at combning a number of palettes from the RColorBrewer package to get the palette length you want.

S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Federico
> Calboli
> Sent: 11 September 2018 08:35
> To: r-help at r-project.org
> Subject: [R] getting 21 very different colours
> 
> Hi All,
> 
> I am plotting a scatterplot of 21 populations, and I am using
> rainbow(21)[pops.col] to generate 21 colours for the plot (which works).
> Maybe it is because I can really process few colours at a time, but the
> differences between the colours are not as strong as I?d like.  I can specify
> start and end for rainbow(), but if anything that looks worse if I do not just
> stick to 0 and 1.
> 
> Is there a way of getting a set of 21 colours that maximises the differences
> between them?
> 
> I could pick them by hand, but that is about 15 colours more than I know (I
> have a detailed colourchart, but the visual differences between ?skyblue? and
> ?slategrey? elude me when plotted as dots on a plot).
> 
> Cheers
> 
> F
> --
> Federico Calboli
> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
> Charles Deberiotstraat 32 box 2439
> 3000 Leuven
> +32 16 32 87 67
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From krylov@r00t @ending from gm@il@com  Tue Sep 11 12:31:28 2018
From: krylov@r00t @ending from gm@il@com (Ivan Krylov)
Date: Tue, 11 Sep 2018 13:31:28 +0300
Subject: [R] getting 21 very different colours
In-Reply-To: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
References: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
Message-ID: <20180911133128.6b30960f@Tarkus>

On Tue, 11 Sep 2018 07:34:51 +0000
Federico Calboli <federico.calboli at kuleuven.be> wrote:

> Is there a way of getting a set of 21 colours that maximises the
> differences between them?  

In my limited experience, getting even 10 colours to look different
enough is a serious undertaking. Take a look at RColorBrewer:
display.brewer.all(n, "qual") stops offering palettes for n>12.

When I needed a 10-colour categorical/qualitative palette, I opted for
brute force approach of maximising the minimal distance between points
in HCL colourspace, although later my colleague told me that I just
needed an existing algorithm to place the points uniformly. It has to
be HCL and not RGB because HCL signifies the way people perceive
different colours while RGB is only a good representation hardware-wise.

Here is my code; the usual disclaimers about stuff written between 1 and
3 AM apply:

# -------------------------8<---------------------------

require(nloptr)

h <- c(0,360)
c <- c(0,137) # see the warning about fixup in `?hcl`: not all HCL points are representable in RGB

# NOTE: depending on your plot background, you may have to change at least luminance range
l <- c(30,90)

npoints <- 24 # I had only 10 here

pts <- matrix(ncol=3, nrow=npoints, dimnames=list(NULL, c("h","c","l")))
pts[,"h"] <- runif(npoints, min=h[1], max=h[2])
pts[,"c"] <- runif(npoints, min=c[1], max=c[2])
pts[,"l"] <- runif(npoints, min=l[1], max=l[2])

lb <- cbind(h=rep(h[1],npoints), c=rep(c[1],npoints), l=rep(l[1],npoints))
ub <- cbind(h=rep(h[2],npoints), c=rep(c[2],npoints), l=rep(l[2],npoints))

obj <- function(x) {
        pts[,c("h","c","l")] <- x
	# somehow the best results were achieved by calculating Euclidean distance from cylindrical coordinates
        pts <- cbind(pts[,"c"]*sin(pts[,'h']/360*2*pi), pts[,'c']*cos(pts[,'h']/360*2*pi), pts[,'l'])
        d <- as.matrix(dist(pts))
        diag(d) <- NA
	# maximise minimal distance <=> minimize negative of minimal distance
        -min(d, na.rm=T)
}

# the stopping criterion is a bit lame, but the objective function here is very hard to minimize
# 1e6 iterations take a few minutes on a relatively modern desktop
sol <- nloptr(as.vector(pts), obj, lb=as.vector(lb), ub=as.vector(ub), opts=list(algorithm="NLOPT_GN_CRS2_LM", maxeval=1e6))

pts[,c("h","c",'l')] <- sol$solution

plot(pts[,"c"] * sin(pts[,"h"]/360*2*pi), pts[,"c"] * cos(pts[,"h"]/360*2*pi), col=hcl(pts[,"h"], pts[,"c"], l), pch=19, cex=2)

# -------------------------8<---------------------------

I couldn't get my code to produce 24 acceptably different colours, but
maybe you will succeed with a similar approach.

-- 
Best regards,
Ivan


From murdoch@dunc@n @ending from gm@il@com  Tue Sep 11 12:43:57 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Tue, 11 Sep 2018 06:43:57 -0400
Subject: [R] getting 21 very different colours
In-Reply-To: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
References: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
Message-ID: <8924791d-15e5-08f0-e3e3-c91e623bb4a7@gmail.com>

On 11/09/2018 3:34 AM, Federico Calboli wrote:
> Hi All,
> 
> I am plotting a scatterplot of 21 populations, and I am using rainbow(21)[pops.col] to generate 21 colours for the plot (which works).  Maybe it is because I can really process few colours at a time, but the differences between the colours are not as strong as I?d like.  I can specify start and end for rainbow(), but if anything that looks worse if I do not just stick to 0 and 1.
> 
> Is there a way of getting a set of 21 colours that maximises the differences between them?

The LAB and LUV color spaces (in the colorspace package) attempt to map 
perceptual differences to equal distances.  You could try using a grid 
of points in one of those spaces, but not all triples are valid.

However, 21 colours is probably too many for your purpose.  If you 
really want to distinguish 21 groups, you're likely going to have to use 
other characteristics as well, such as the symbol.  You could plot 21 
different letters in 5 different colours and it might work, but it's not 
going to be easy for viewers.

Duncan Murdoch

> 
> I could pick them by hand, but that is about 15 colours more than I know (I have a detailed colourchart, but the visual differences between ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).
> 
> Cheers
> 
> F
> --
> Federico Calboli
> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
> Charles Deberiotstraat 32 box 2439
> 3000 Leuven
> +32 16 32 87 67
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From h@medh@@eli @ending from gm@il@com  Tue Sep 11 14:38:38 2018
From: h@medh@@eli @ending from gm@il@com (Hamed Ha)
Date: Tue, 11 Sep 2018 13:38:38 +0100
Subject: [R] Problem with lm.resid() when weights are provided
In-Reply-To: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
References: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
Message-ID: <CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>

Dear R Help Team.

I get some weird results when I use the lm function with weight. The issue
can be reproduced by the example below:


The input data is (weights are intentionally designed to reflect some
structures in the data)


> df
y x weight
 1.51156139  0.55209240 2.117337e-34
-0.63653132 -0.12599316 2.117337e-34
 0.37782776  0.42095384 4.934135e-31
 3.03792318  1.40315446 2.679495e-24
 1.53646523  0.46076858 2.679495e-24
-2.37727874 -0.73963576 6.244160e-21
 0.37183065  0.20407468 1.455107e-17
-1.53917553 -0.95519361 1.455107e-17
 1.10926675  0.03897129 3.390908e-14
-0.37786333 -0.17523593 3.390908e-14
 2.43973603  0.97970095 7.902000e-11
-0.35432394 -0.03742559 7.902000e-11
 2.19296613  1.00355263 4.289362e-04
 0.49845532  0.34816207 4.289362e-04
 1.25005260  0.76306225 5.000000e-01
 0.84360691  0.45152356 5.000000e-01
 0.29565993  0.53880068 5.000000e-01
-0.54081334 -0.28104525 5.000000e-01
 0.83612836 -0.12885659 9.995711e-01
-1.42526769 -0.87107631 9.999998e-01
 0.10204789 -0.11649899 1.000000e+00
 1.14292898  0.37249631 1.000000e+00
-3.02942081 -1.28966997 1.000000e+00
-1.37549764 -0.74676145 1.000000e+00
-2.00118016 -0.55182759 1.000000e+00
-4.24441674 -1.94603608 1.000000e+00
 1.17168144  1.00868008 1.000000e+00
 2.64007761  1.26333069 1.000000e+00
 1.98550114  1.18509599 1.000000e+00
-0.58941683 -0.61972416 9.999998e-01
-4.57559611 -2.30914920 9.995711e-01
-0.82610544 -0.39347576 9.995711e-01
-0.02768220  0.20076910 9.995711e-01
 0.78186399  0.25690215 9.995711e-01
-0.88314153 -0.20200148 5.000000e-01
-4.17076452 -2.03547588 5.000000e-01
 0.93373070  0.54190626 4.289362e-04
-0.08517734  0.17692491 4.289362e-04
-4.47546619 -2.14876688 4.289362e-04
-1.65509103 -0.76898087 4.289362e-04
-0.39403030 -0.12689705 4.289362e-04
 0.01203300 -0.18689898 1.841442e-07
-4.82762639 -2.31391121 1.841442e-07
-0.72658380 -0.39751171 3.397282e-14
-2.35886866 -1.01082109 0.000000e+00
-2.03762707 -0.96439902 0.000000e+00
 0.90115123  0.60172286 0.000000e+00
 1.55999194  0.83433953 0.000000e+00
 3.07994058  1.30942776 0.000000e+00
 1.78871462  1.10605530 0.000000e+00



Running simple linear model returns:

> lm(y~x,data=df)

Call:
lm(formula = y ~ x, data = df)

Coefficients:
(Intercept)            x
   -0.04173      2.03790

and
> max(resid(lm(y~x,data=df)))
[1] 1.14046


*HOWEVER if I use the weighted model then:*

lm(formula = y ~ x, data = df, weights = df$weights)

Coefficients:
(Intercept)            x
   -0.05786      1.96087

and
> max(resid(lm(y~x,data=df,weights=df$weights)))
[1] 60.91888


as you see, the estimation of the coefficients are nearly the same but the
resid() function returns a giant residual (I have some cases where the
value is much much higher). Further, if I calculate the residuals by
simply predict(lm(y~x,data=df,weights=df$weights))-df$y then I get the true
value for the residuals.


Thanks.

Please do not hesitate to contact me for more details.
Regards,
Hamed.

	[[alternative HTML version deleted]]


From kri@ti@glover @ending from hotm@il@com  Tue Sep 11 15:55:18 2018
From: kri@ti@glover @ending from hotm@il@com (Kristi Glover)
Date: Tue, 11 Sep 2018 13:55:18 +0000
Subject: [R] loop for comparing two or more groups using bootstrapping
In-Reply-To: <CA+8X3fX6f6zT3VGbprbaOFMspKFijOncD0jiwodQ=cXShcnX_g@mail.gmail.com>
References: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>,
 <CA+8X3fX6f6zT3VGbprbaOFMspKFijOncD0jiwodQ=cXShcnX_g@mail.gmail.com>
Message-ID: <CY4PR1301MB21673838F1F43BB962933542FA040@CY4PR1301MB2167.namprd13.prod.outlook.com>

Dear Jim,

Thank you very much for the code. I run it but it gave me row names like "year224", "year142".

are these the difference between columns? If we want to get bootstrapping means of difference between years (year2-year1; year3-year1), its CI and exact p value, how can we get it?

thanks

KG

----

head(daT)

colname.mat<-combn(paste0("year",1:4),2)

samplenames<-apply(colname.mat,2,paste,collapse="")

k<-10

for(column in 1:ncol(colname.mat)) {

 assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,column]]),3,TRUE)))

}


> get(samplenames[1])
         [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
year224 0.556 0.667 0.571 0.526 0.629 0.696 0.323 0.526 0.256 0.667
year142 0.324 0.324 0.706 0.638 0.600 0.294 0.612 0.688 0.432 0.387
year237 0.571 0.696 0.629 0.471 0.462 0.471 0.452 0.595 0.333 0.435




________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: September 11, 2018 1:44 AM
To: Kristi Glover
Cc: r-help mailing list
Subject: Re: [R] loop for comparing two or more groups using bootstrapping

Hi Kristy,
Try this:

colname.mat<-combn(paste0("year",1:4),2)
samplenames<-apply(colname.mat,2,paste,collapse="")
k<-10000
for(column in 1:ncol(colname.mat)) {
 assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,column]]),3,TRUE)))
}

Then use get(samplenames[1]) and so on to access the values.

Jim
On Tue, Sep 11, 2018 at 4:52 PM Kristi Glover <kristi.glover at hotmail.com> wrote:
>
> Hi R users,
>
> I was trying to test a null hypothesis of difference between two groups was 0. I have many years data, such as year1, year2,, year3, year4 and I was trying to compare between year1 and year2, year1 and year3, year2 and year3 and so on and have used following code with an example data.
>
>
> I tried to make a loop but did not work to compare between many years, and also want to obtain the exact p value. Would you mind to help me to make a loop?
>
> Thanks for your help.
>
>
> KG
>
>
> daT<-structure(list(year1 = c(0.417, 0.538, 0.69, 0.688, 0.688, 0.606,
> 0.667, 0.7, 0.545, 0.462, 0.711, 0.642, 0.744, 0.604, 0.612,
> 0.667, 0.533, 0.556, 0.444, 0.526, 0.323, 0.308, 0.195, 0.333,
> 0.323, 0.256, 0.345, 0.205, 0.286, 0.706, 0.7, 0.6, 0.571, 0.364,
> 0.429, 0.326, 0.571, 0.424, 0.341, 0.387, 0.341, 0.324, 0.696,
> 0.696, 0.583, 0.556, 0.645, 0.435, 0.471, 0.556), year2 = c(0.385,
> 0.552, 0.645, 0.516, 0.629, 0.595, 0.72, 0.638, 0.557, 0.588,
> 0.63, 0.744, 0.773, 0.571, 0.723, 0.769, 0.667, 0.667, 0.526,
> 0.476, 0.294, 0.323, 0.222, 0.556, 0.263, 0.37, 0.357, 0.25,
> 0.323, 0.778, 0.667, 0.636, 0.583, 0.432, 0.412, 0.333, 0.571,
> 0.39, 0.4, 0.452, 0.326, 0.471, 0.7, 0.75, 0.615, 0.462, 0.556,
> 0.4, 0.696, 0.465), year3 = c(0.435, 0.759, 0.759, 0.759, 0.714,
> 0.593, 0.651, 0.683, 0.513, 0.643, 0.652, 0.757, 0.791, 0.649,
> 0.78, 0.5, 0.5, 0.5, 0.533, 0.429, 0.333, 0.286, 0.231, 0.533,
> 0.303, 0.417, 0.333, 0.333, 0.357, 0.909, 1, 0.952, 0.8, 0.556,
> 0.529, 0.562, 0.762, 0.513, 0.733, 0.611, 0.733, 0.647, 0.909,
> 0.857, 0.8, 0.556, 0.588, 0.562, 0.857, 0.513), year4 = c(0.333,
> 0.533, 0.6, 0.483, 0.743, 0.5, 0.691, 0.619, 0.583, 0.385, 0.653,
> 0.762, 0.844, 0.64, 0.667, 0.571, 0.571, 0.615, 0.421, 0.5, 0.205,
> 0.308, 0.25, 0.6, 0.242, 0.308, 0.276, 0.235, 0.211, 0.9, 0.632,
> 0.72, 0.727, 0.356, 0.5, 0.368, 0.5, 0.41, 0.562, 0.514, 0.4,
> 0.409, 0.632, 0.72, 0.727, 0.4, 0.5, 0.421, 0.5, 0.462)), .Names = c("year1",
> "year2", "year3", "year4"), row.names = c(NA, -50L), class = "data.frame")
>
> head(daT)
>
> # null hypothesis; difference is equal to zero
>
> dif1.2<-daT$year2-daT$year1
>
> k=10000
>
> mysamples1.2=replicate(k, sample(dif1.2, replace=T))
>
> mymeans1.2=apply(mysamples1.2, 2, mean)
>
> quantile(mymeans1.2, c(0.025, 0.975))
>
> hist(mysamples1.2)
>
> mean(mymeans1.2)
>
> #what is p value?
>
>
> #similarly Now I want to compare between year 1 and year3,
>
> dif1.3<-daT$year3-daT$year1
>
> mysamples1.3=replicate(k, sample(dif1.3, replace=T))
>
> mymeans1.3=apply(mysamples1.3, 2, mean)
>
> quantile(mymeans1.3, c(0.025, 0.975))
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help

thz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R, enhancements and patches to the source code and documentation of R, comparison and compatibility with S and S-plus, and for the posting of nice examples and benchmarks.



> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Tue Sep 11 16:50:07 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Tue, 11 Sep 2018 14:50:07 +0000
Subject: [R] For loop with multiple iteration indexes
In-Reply-To: <CACg0228eV_KsSyHpT6iBVhSyQ1hfFv2Nazj7a1JJrpMOfVQDLg@mail.gmail.com>
References: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
 <F226B06A-9457-47DF-A9F0-9B995D999475@ucsd.edu>
 <CACg0228eV_KsSyHpT6iBVhSyQ1hfFv2Nazj7a1JJrpMOfVQDLg@mail.gmail.com>
Message-ID: <062ad885a87b40cba826833940de1eff@tamu.edu>

Just for fun, there are ways to do this in R without an explicit loop:

> set.seed(42)
> dat <- matrix(rnorm(10*5), 10, 5)
> x <- sample(1:5)
> y <- sample(1:5)
> diag(cor(dat[, x], dat[, y]))
[1] -0.69156568 -0.06002371 -0.37492894  0.46477742 -0.37972866

You can use as.list() to convert the vector to a list.

> i <- seq_len(length(x))
> sapply(i, function(j) cor(dat[, x[j]], dat[, y[j]]))
[1] -0.69156568 -0.06002371 -0.37492894  0.46477742 -0.37972866
> xy <- cbind(x, y)
> sapply(i, function(j) cor(dat[, xy[j, ]])[1, 2])
[1] -0.69156568 -0.06002371 -0.37492894  0.46477742 -0.37972866

Change sapply() to lapply() to get list output.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of David Disabato
Sent: Monday, September 10, 2018 8:33 PM
To: r-help at r-project.org
Subject: Re: [R] For loop with multiple iteration indexes

Thank you everyone. After thinking about each response, I realized a fairly simple solution is available (obviously, other suggested approaches work as
well):

stopifnot(length(x) == length(y); stopifnot(length(x) > 0) r <- list() for (i in 1:length(x) ) {
   r[[i]] <- cor(x = dat[, x[i] ], y = dat[, y[i] ]) }
print(r)

On Mon, Sep 10, 2018 at 11:30 AM Berry, Charles <ccberry at ucsd.edu> wrote:

> I have a sense of deja vu:
>
> https://www.mail-archive.com/r-help at r-project.org/msg250494.html
>
> There is some good advice there.
>
> > On Sep 9, 2018, at 3:49 PM, David Disabato <ddisab01 at gmail.com> wrote:
> >
> > Hi R-help,
> >
> > I am trying to create a for loop with multiple iteration indexes. I 
> > don't want to use two different for loops nested together because I 
> > don't need the full matrix of the two indexes, just the diagonal 
> > elements (e.g.,
> i[1]
> > & j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to 
> > specify both i and j in a single for loop? Here is a simplified 
> > example of pseudo-code where x and y are equally sized character 
> > vectors with column names and dat is their dataframe (obviously this 
> > code doesn't run in R,
> but
> > hopefully you perceive my goal):
> >
> > r <- list()
> > n <- 0
> > for (i in x; j in y) {
> >   n <- n + 1
> >   r[[n]] <- cor(x = dat[, i], y = dat[, j]) }
> > print(r)
> >
> > I realize there are other solutions to this particular correlation
> example,
> > but my actual problem is much more complicated, so I am hoping for a 
> > solution that generalizes across any code within the for loop.
>
> A more aRtful way (than a for loop) to approach this is with mapply:
>
>
> i <- head(colnames(mtcars))
> j <- tail(colnames(mtcars))
>
> r <- mapply(function(i, j, dat) cor( x = dat[, i], y = dat[, j]),
>        i=i , j=j , MoreArgs = list( dat = mtcars),
>        SIMPLIFY = FALSE, USE.NAMES = FALSE)
>
>
> and if you want, maybe USE.NAMES = paste(i, j, sep="_")
>
> Chuck
>
>

--
David J. Disabato, M.A.
Clinical Psychology Doctoral Student
George Mason University
ddisabat at gmu.edu

Email is not a secure form of communication as information and confidentiality cannot be guaranteed. Information provided in an email is not intended to be a professional service. In the case of a crisis or emergency situation, call 911.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From b@rowling@on @ending from l@nc@@ter@@c@uk  Tue Sep 11 17:36:31 2018
From: b@rowling@on @ending from l@nc@@ter@@c@uk (Barry Rowlingson)
Date: Tue, 11 Sep 2018 16:36:31 +0100
Subject: [R] getting 21 very different colours
In-Reply-To: <048d1aa7d3f246d386bdae5812f94c9a@LNXP265MB1290.GBRP265.PROD.OUTLOOK.COM>
References: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
 <048d1aa7d3f246d386bdae5812f94c9a@LNXP265MB1290.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CANVKczNSEwrmkoFq8jNksC3N=SUacaWUB0Oho_REVUeRBBqZTw@mail.gmail.com>

On Tue, Sep 11, 2018 at 11:43 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 11/09/2018 3:34 AM, Federico Calboli wrote:
> > Hi All,
> >
> > I am plotting a scatterplot of 21 populations, and I am using
> rainbow(21)[pops.col] to generate 21 colours for the plot (which works).
> Maybe it is because I can really process few colours at a time, but the
> differences between the colours are not as strong as I?d like.  I can
> specify start and end for rainbow(), but if anything that looks worse if I
> do not just stick to 0 and 1.
> >
> > Is there a way of getting a set of 21 colours that maximises the
> differences between them?
>
> The LAB and LUV color spaces (in the colorspace package) attempt to map
> perceptual differences to equal distances.  You could try using a grid
> of points in one of those spaces, but not all triples are valid.
>
> However, 21 colours is probably too many for your purpose.  If you
> really want to distinguish 21 groups, you're likely going to have to use
> other characteristics as well, such as the symbol.  You could plot 21
> different letters in 5 different colours and it might work, but it's not
> going to be easy for viewers.
>
>
The `alphabet` and `alphabet2` palettes from the `pals` package claim 26
"distinguishable" colours:

Details:

     The ?alphabet? palette has 26 distinguishable colors that have
     logical names starting with the English alphabet letters A, B, ...
     Z. This palette is based on the work by Green-Armytage (2010), but
     uses the names 'orange' instead of 'orpiment', and 'magenta'
     instead of 'mallow'.

There are some other palettes in that help page (?alphabet) that might also
work. But 21 colours is pushing it.

Barry






> Duncan Murdoch
>
> >
> > I could pick them by hand, but that is about 15 colours more than I know
> (I have a detailed colourchart, but the visual differences between
> ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).
> >
> > Cheers
> >
> > F
> > --
> > Federico Calboli
> > LBEG - Laboratory of Biodiversity and Evolutionary Genomics
> > Charles Deberiotstraat 32 box 2439
> > 3000 Leuven
> > +32 16 32 87 67
> >
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @bouelm@k@rim1962 @ending from gm@il@com  Tue Sep 11 20:02:00 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Tue, 11 Sep 2018 14:02:00 -0400
Subject: [R] Bar Graph
Message-ID: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>

Dear All:


I do need your help on how to add frequency to bar plot on the top of each
bar.


here is the R code.


*Number.of.Death <- c(432, 217,93, 34, 224)    ##### Number of Death*

*Cause.of.Death <- c("Heart disease", "Cancer", "Stroke", "Accidents",
"Other")  *

*barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Grapg for
Death Data", ylab="Number of Death", xlab="Cause of Death") *



Thank you very much for your help in advance.


with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Tue Sep 11 20:24:13 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Tue, 11 Sep 2018 19:24:13 +0100
Subject: [R] Bar Graph
In-Reply-To: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
References: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
Message-ID: <00e960fd-71d4-453e-5c80-e3571f6ec76d@sapo.pt>

Hello,

Use function text() with the return of barplot() as x value and 
Number.of.Death as y.
Note that the limits of the y axis are not the automatic ones.



bp <- barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Graph for
Death Data", ylab="Number of Death", xlab="Cause of Death", ylim = c(0, 
500))

text(x = bp, y = Number.of.Death, labels = Number.of.Death, pos = 3)


Hope this helps,

Rui Barradas

On 11-09-2018 19:02, AbouEl-Makarim Aboueissa wrote:
> Dear All:
> 
> 
> I do need your help on how to add frequency to bar plot on the top of each
> bar.
> 
> 
> here is the R code.
> 
> 
> *Number.of.Death <- c(432, 217,93, 34, 224)    ##### Number of Death*
> 
> *Cause.of.Death <- c("Heart disease", "Cancer", "Stroke", "Accidents",
> "Other")  *
> 
> *barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Grapg for
> Death Data", ylab="Number of Death", xlab="Cause of Death") *
> 
> 
> 
> Thank you very much for your help in advance.
> 
> 
> with many thanks
> abou
> ______________________
> 
> 
> *AbouEl-Makarim Aboueissa, PhD*
> 
> *Professor of Statistics*
> *Graduate Coordinator*
> 
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @ending from gm@il@com  Tue Sep 11 20:47:36 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 11 Sep 2018 11:47:36 -0700
Subject: [R] Bar Graph
In-Reply-To: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
References: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
Message-ID: <CAGxFJbQCpLoqKxTuvtz3RMSKexYqNVSR_Z8=4WKVYG-pzVa0tw@mail.gmail.com>

Not quite -- he wanted the frequencies not the counts. So something
like this (using the adj argument to center the frequencies above each
bar:

bp <-barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar
Graph for Death Data", ylab="Number of Deaths", xlab="Cause of Death",
ylim = c(0,500) )

text(bp, y = Number.of.Death + 30, adj = .5,
     lab = round(Number.of.Death/sum(Number.of.Death),2))

Cheers,
Bert

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Sep 11, 2018 at 11:02 AM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear All:
>
>
> I do need your help on how to add frequency to bar plot on the top of each
> bar.
>
>
> here is the R code.
>
>
> *Number.of.Death <- c(432, 217,93, 34, 224)    ##### Number of Death*
>
> *Cause.of.Death <- c("Heart disease", "Cancer", "Stroke", "Accidents",
> "Other")  *
>
> *barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Grapg for
> Death Data", ylab="Number of Death", xlab="Cause of Death") *
>
>
>
> Thank you very much for your help in advance.
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@ul @ending from @t@t@@uckl@nd@@c@nz  Tue Sep 11 21:23:36 2018
From: p@ul @ending from @t@t@@uckl@nd@@c@nz (Paul Murrell)
Date: Wed, 12 Sep 2018 07:23:36 +1200
Subject: [R] [FORGED] Re:  getting 21 very different colours
In-Reply-To: <CANVKczNSEwrmkoFq8jNksC3N=SUacaWUB0Oho_REVUeRBBqZTw@mail.gmail.com>
References: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
 <048d1aa7d3f246d386bdae5812f94c9a@LNXP265MB1290.GBRP265.PROD.OUTLOOK.COM>
 <CANVKczNSEwrmkoFq8jNksC3N=SUacaWUB0Oho_REVUeRBBqZTw@mail.gmail.com>
Message-ID: <d3a5aaf0-81b6-2d33-6f93-72523639e290@stat.auckland.ac.nz>


You could also take a look at the 'Polychrome' package

Paul

On 12/09/18 03:36, Barry Rowlingson wrote:
> On Tue, Sep 11, 2018 at 11:43 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> 
>> On 11/09/2018 3:34 AM, Federico Calboli wrote:
>>> Hi All,
>>>
>>> I am plotting a scatterplot of 21 populations, and I am using
>> rainbow(21)[pops.col] to generate 21 colours for the plot (which works).
>> Maybe it is because I can really process few colours at a time, but the
>> differences between the colours are not as strong as I?d like.  I can
>> specify start and end for rainbow(), but if anything that looks worse if I
>> do not just stick to 0 and 1.
>>>
>>> Is there a way of getting a set of 21 colours that maximises the
>> differences between them?
>>
>> The LAB and LUV color spaces (in the colorspace package) attempt to map
>> perceptual differences to equal distances.  You could try using a grid
>> of points in one of those spaces, but not all triples are valid.
>>
>> However, 21 colours is probably too many for your purpose.  If you
>> really want to distinguish 21 groups, you're likely going to have to use
>> other characteristics as well, such as the symbol.  You could plot 21
>> different letters in 5 different colours and it might work, but it's not
>> going to be easy for viewers.
>>
>>
> The `alphabet` and `alphabet2` palettes from the `pals` package claim 26
> "distinguishable" colours:
> 
> Details:
> 
>       The ?alphabet? palette has 26 distinguishable colors that have
>       logical names starting with the English alphabet letters A, B, ...
>       Z. This palette is based on the work by Green-Armytage (2010), but
>       uses the names 'orange' instead of 'orpiment', and 'magenta'
>       instead of 'mallow'.
> 
> There are some other palettes in that help page (?alphabet) that might also
> work. But 21 colours is pushing it.
> 
> Barry
> 
> 
> 
> 
> 
> 
>> Duncan Murdoch
>>
>>>
>>> I could pick them by hand, but that is about 15 colours more than I know
>> (I have a detailed colourchart, but the visual differences between
>> ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).
>>>
>>> Cheers
>>>
>>> F
>>> --
>>> Federico Calboli
>>> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
>>> Charles Deberiotstraat 32 box 2439
>>> 3000 Leuven
>>> +32 16 32 87 67
>>>
>>>
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From @bouelm@k@rim1962 @ending from gm@il@com  Tue Sep 11 21:28:12 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Tue, 11 Sep 2018 15:28:12 -0400
Subject: [R] Bar Graph
In-Reply-To: <CAGxFJbQCpLoqKxTuvtz3RMSKexYqNVSR_Z8=4WKVYG-pzVa0tw@mail.gmail.com>
References: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
 <CAGxFJbQCpLoqKxTuvtz3RMSKexYqNVSR_Z8=4WKVYG-pzVa0tw@mail.gmail.com>
Message-ID: <CAE9stmfafQJ9mT_w_sX65GRjsQKdQhR9qKSYzw6wn9wk7UzETA@mail.gmail.com>

Dear Bert:

thank you very much

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Tue, Sep 11, 2018 at 2:47 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Not quite -- he wanted the frequencies not the counts. So something
> like this (using the adj argument to center the frequencies above each
> bar:
>
> bp <-barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar
> Graph for Death Data", ylab="Number of Deaths", xlab="Cause of Death",
> ylim = c(0,500) )
>
> text(bp, y = Number.of.Death + 30, adj = .5,
>      lab = round(Number.of.Death/sum(Number.of.Death),2))
>
> Cheers,
> Bert
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Sep 11, 2018 at 11:02 AM AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> >
> > Dear All:
> >
> >
> > I do need your help on how to add frequency to bar plot on the top of
> each
> > bar.
> >
> >
> > here is the R code.
> >
> >
> > *Number.of.Death <- c(432, 217,93, 34, 224)    ##### Number of Death*
> >
> > *Cause.of.Death <- c("Heart disease", "Cancer", "Stroke", "Accidents",
> > "Other")  *
> >
> > *barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Grapg for
> > Death Data", ylab="Number of Death", xlab="Cause of Death") *
> >
> >
> >
> > Thank you very much for your help in advance.
> >
> >
> > with many thanks
> > abou
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor of Statistics*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @bouelm@k@rim1962 @ending from gm@il@com  Tue Sep 11 21:28:57 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Tue, 11 Sep 2018 15:28:57 -0400
Subject: [R] Bar Graph
In-Reply-To: <00e960fd-71d4-453e-5c80-e3571f6ec76d@sapo.pt>
References: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
 <00e960fd-71d4-453e-5c80-e3571f6ec76d@sapo.pt>
Message-ID: <CAE9stmdOdTzRuMCUZPmSLLpmWZ99Z8axx+i_AcF+NBoW1-h-Hg@mail.gmail.com>

Dear  Rui:

thank you very much

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Tue, Sep 11, 2018 at 2:24 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Use function text() with the return of barplot() as x value and
> Number.of.Death as y.
> Note that the limits of the y axis are not the automatic ones.
>
>
>
> bp <- barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Graph
> for
> Death Data", ylab="Number of Death", xlab="Cause of Death", ylim = c(0,
> 500))
>
> text(x = bp, y = Number.of.Death, labels = Number.of.Death, pos = 3)
>
>
> Hope this helps,
>
> Rui Barradas
>
> On 11-09-2018 19:02, AbouEl-Makarim Aboueissa wrote:
> > Dear All:
> >
> >
> > I do need your help on how to add frequency to bar plot on the top of
> each
> > bar.
> >
> >
> > here is the R code.
> >
> >
> > *Number.of.Death <- c(432, 217,93, 34, 224)    ##### Number of Death*
> >
> > *Cause.of.Death <- c("Heart disease", "Cancer", "Stroke", "Accidents",
> > "Other")  *
> >
> > *barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Grapg for
> > Death Data", ylab="Number of Death", xlab="Cause of Death") *
> >
> >
> >
> > Thank you very much for your help in advance.
> >
> >
> > with many thanks
> > abou
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor of Statistics*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From @bouelm@k@rim1962 @ending from gm@il@com  Tue Sep 11 21:43:13 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Tue, 11 Sep 2018 15:43:13 -0400
Subject: [R] Remove plot axis values in dotplot graph
Message-ID: <CAE9stmdidxkAMbA-6+cFRPZMVppQt+rj6WYPJ-1AhHiqcPBpaA@mail.gmail.com>

Dear All:

One more thing. I want to Remove the plot x-axis values in dotplot graph. I
am trying to use xaxt = "n", but it seems NOT working. Also after removing
the x-axis values, I want to use the command axis(1, at=0:16, cex.axis=1)
to add x-axis values from 0 to 16, but it seems not working as expect.



Honey.Dosage<-c(12,11,15,11,10,13,10,4,15,16,9,14,10,6,10,8,11,12,12,8,12,9,11,15,10,15,9,13,8,12,10,8,9,5,12)

DM.Dosage<-c(4,6,9,4,7,7,7,9,12,10,11,6,3,4,9,12,7,6,8,12,12,4,12,13,7,10,13,9,4,4,10,15,9)

No.Dosage<-c(5,8,6,1,0,8,12,8,7,7,1,6,7,7,12,7,9,7,9,5,11,9,5,6,8,8,6,7,10,9,4,8,7,3,1,4,3)

scores<-c(Honey.Dosage,DM.Dosage,No.Dosage)

min(scores)
max(scores)

dotchart(scores,cex=1.5, pch = 18, col=c(1:3), xaxt = "n", main="Dot Plot
child?s cough data", xlab="cough Scores")

axis(1, at=0:16, cex.axis=1.5)




with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Tue Sep 11 23:46:24 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 14:46:24 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes
Message-ID: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>

   Every lattice xyplot() I've created before this one has tick marks on only
the left and bottom axes. The current plot has sprouted tick marks on the
top and right side, too, and I want to remove them. I've not found an answer
to this issue in Deepayan's book or on the web. I would appreciate also
learning why the extra tick marks appeared. The dput() data are included.

   The plotting command;

rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'h',
                        main = 'Monthly Total Precipitation\n2005-2018',
                        xlab = 'Year and Month', ylab = 'Precipitation (in)',
                        scales = list(x = list(at = seq(1,162,by=6), cex = 0.7, rot = 90)))

plot(rain.all.sum)

   The data:

structure(list(Month = structure(1:162, .Label = c("2005-01", 
"2005-02", "2005-03", "2005-04", "2005-05", "2005-06", "2005-07", 
"2005-08", "2005-09", "2005-10", "2005-11", "2005-12", "2006-01", 
"2006-02", "2006-03", "2006-04", "2006-05", "2006-06", "2006-07", 
"2006-08", "2006-09", "2006-10", "2006-11", "2006-12", "2007-01", 
"2007-02", "2007-03", "2007-04", "2007-05", "2007-06", "2007-07", 
"2007-08", "2007-09", "2007-10", "2007-11", "2007-12", "2008-01", 
"2008-02", "2008-03", "2008-04", "2008-05", "2008-06", "2008-07", 
"2008-08", "2008-09", "2008-10", "2008-11", "2008-12", "2009-01", 
"2009-02", "2009-03", "2009-04", "2009-05", "2009-06", "2009-07", 
"2009-08", "2009-09", "2009-10", "2009-11", "2009-12", "2010-01", 
"2010-02", "2010-03", "2010-04", "2010-05", "2010-06", "2010-07", 
"2010-08", "2010-09", "2010-10", "2010-11", "2010-12", "2011-01", 
"2011-02", "2011-03", "2011-04", "2011-05", "2011-06", "2011-07", 
"2011-08", "2011-09", "2011-10", "2011-11", "2011-12", "2012-01", 
"2012-02", "2012-03", "2012-04", "2012-05", "2012-06", "2012-07", 
"2012-08", "2012-09", "2012-10", "2012-11", "2012-12", "2013-01", 
"2013-02", "2013-03", "2013-04", "2013-05", "2013-06", "2013-07", 
"2013-08", "2013-09", "2013-10", "2013-11", "2013-12", "2014-01", 
"2014-02", "2014-03", "2014-04", "2014-05", "2014-06", "2014-07", 
"2014-08", "2014-09", "2014-10", "2014-11", "2014-12", "2015-01", 
"2015-02", "2015-03", "2015-04", "2015-05", "2015-06", "2015-07", 
"2015-08", "2015-09", "2015-10", "2015-11", "2015-12", "2016-01", 
"2016-02", "2016-03", "2016-04", "2016-05", "2016-06", "2016-07", 
"2016-08", "2016-09", "2016-10", "2016-11", "2016-12", "2017-01", 
"2017-02", "2017-03", "2017-04", "2017-05", "2017-06", "2017-07", 
"2017-08", "2017-09", "2017-10", "2017-11", "2017-12", "2018-01", 
"2018-02", "2018-03", "2018-04", "2018-05", "2018-06"), class = "factor"),
     Sum = c(53.51, 24.2, 88.54, 72.85, 77.3, 49.19, 8.77, 5.75,
     27.83, 79.75, 123.89, 168.29, 229.69, 70.91, 74.15, 62.3,
     43.56, 35.08, 3.6, 2.76, 26.83, 47.72, 293.23, 139.84, 103.48,
     120.91, 85.96, 55.91, 26.56, 29.44, 9.9, 15.38, 33.47, 93.6,
     105.61, 277.41, 279.38, 144.26, 220.88, 149.75, 82.28, 55.87,
     5.29, 52.27, 21.1, 64.76, 182.31, 207.13, 196.29, 89.27,
     187.72, 111.67, 111.72, 38.19, 6.07, 15.25, 52.46, 127.75,
     208.43, 146.62, 169.34, 94.54, 154.21, 131.39, 151.27, 135.46,
     9.98, 8.72, 86.67, 142.04, 225.61, 274.93, 196.68, 153.24,
     263.54, 231.49, 122.23, 58.26, 34.65, 2.96, 28.21, 103.92,
     217.52, 166.16, 305.27, 168.73, 333.28, 145.68, 101.2, 127.77,
     15.41, 1.85, 3.49, 245.99, 272.35, 297.05, 177.17, 105.71,
     118.44, 136.34, 161.01, 53.31, 1.15, 23.43, 200.97, 69.12,
     158.51, 131.67, 156.95, 266.38, 291.7, 147.15, 101.49, 78.89,
     26.99, 24.35, 35.76, 210.2, 225.55, 282.85, 153.91, 148.13,
     187.03, 133.99, 62.28, 17.58, 13.41, 35.58, 47.04, 154.92,
     317.77, 604.04, 288.91, 210.86, 266.04, 121.62, 78.17, 85.96,
     29.84, 7.02, 72.13, 404.33, 247.71, 255.5, 138.22, 339.5,
     368.99, 209.41, 110.08, 63.9, 0.62, 6.97, 133.75, 227.1,
     312.99, 178.58, 255.8, 155.05, 135.27, 225.55, 15.23, 1.58
     ), Median = c(0.01, 0, 0, 0.1, 0.1, 0, 0, 0, 0, 0.02, 0.1,
     0.04, 0.5, 0, 0.1, 0.07, 0, 0, 0, 0, 0, 0, 0.57, 0.03, 0,
     0.2, 0.055, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0.21, 0.02, 0.2,
     0.11, 0.02, 0, 0, 0, 0, 0, 0.1, 0.165, 0.01, 0.01, 0.15,
     0.01, 0, 0, 0, 0, 0, 0.02, 0.125, 0, 0.1, 0.08, 0.055, 0.1,
     0.13, 0.01, 0, 0, 0, 0, 0.2, 0.17, 0.02, 0.07, 0.23, 0.15,
     0.06, 0, 0, 0, 0, 0.03, 0.1, 0, 0.1, 0.1, 0.2, 0.07, 0, 0.02,
     0, 0, 0, 0.04, 0.115, 0.24, 0.02, 0.03, 0.01, 0.01, 0.02,
     0, 0, 0, 0, 0, 0.02, 0, 0, 0.2, 0.18, 0.05, 0, 0, 0, 0, 0,
     0.08, 0.07, 0.1, 0, 0.01, 0, 0.02, 0, 0, 0, 0, 0, 0, 0.09,
     0.4, 0.18, 0.1, 0.2, 0, 0, 0, 0, 0, 0, 0.29, 0.09, 0.09,
     0, 0.26, 0.3, 0.16, 0, 0, 0, 0, 0, 0, 0.25, 0, 0.16, 0.03,
     0.02, 0.08, 0, 0), Max = c(3, 1.1, 3.2, 1.2, 1.6, 1.48, 0.8,
     0.6, 3.2, 4.9, 3.1, 3.63, 3.4, 2.6, 2, 3.25, 1.6, 2.1, 0.4,
     0.5, 1.1, 2, 6.6, 3.2, 3.6, 5.8, 2.3, 1.7, 1.3, 1.2, 1, 2.1,
     2, 3, 3, 5.9, 3.3, 2.9, 5.2, 1.8, 1.4, 2.2, 0.6, 2.5, 1.02,
     2, 4.4, 3.6, 5.3, 2.2, 2.7, 2.5, 1.5, 1.4, 0.8, 1.4, 1.4,
     2.11, 2.1, 3.3, 3.12, 1.3, 2.4, 1.5, 2.4, 3.5, 0.9, 1.3,
     2.77, 2, 3.2, 2.6, 5.4, 3.4, 2.87, 2.6, 1.6, 1.4, 1.2, 0.2,
     0.91, 2.1, 2.2, 5.2, 4.75, 2.3, 3.4, 2.67, 1.8, 1.9, 0.61,
     0.2, 0.2, 3.4, 3.65, 3.1, 3.15, 2.2, 2, 2.7, 2.3, 1.18, 0.2,
     2.1, 3.3, 1.7, 2.47, 8.8, 2.8, 3.27, 3.29, 2.4, 2.1, 1.73,
     1.03, 1.4, 1.1, 2.9, 3.1, 5.7, 2.69, 2.7, 3.1, 1.3, 1.85,
     0.6, 1.5, 1.1, 1.5, 4.2, 3.8, 4.4, 2.5, 3.2, 2.61, 1.94,
     2.1, 2.1, 1, 0.57, 2.2, 5, 3.02, 2.8, 1.7, 3.08, 5, 2.54,
     2.7, 1.6, 0.1, 0.5, 2.6, 5.35, 3.5, 2.9, 2.3, 2.9, 1.2, 2.47,
     0.6, 0.25)), row.names = c(NA, -162L), class = "data.frame")

Rich


From bry@nm@c@24 @ending from gm@il@com  Tue Sep 11 21:28:57 2018
From: bry@nm@c@24 @ending from gm@il@com (Bryan Mac)
Date: Tue, 11 Sep 2018 12:28:57 -0700
Subject: [R] Hierarchical Cluster Analysis
Message-ID: <D8AD1348-0091-4BC5-BD7E-395CE465BEB7@gmail.com>


Bryan Mac
Data Scientist
Research Analytics
Ipsos Insight LLC





	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Sep 12 00:13:53 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 11 Sep 2018 15:13:53 -0700
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>

Well, you might try ?xyplot -- in particular the "scales" list section
and in particular there the "tck" parameter. Adding
tck = c(1, 0)
to the "scales ="  list will probably solve your problem.

-- Bert


On Tue, Sep 11, 2018 at 2:46 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
>    Every lattice xyplot() I've created before this one has tick marks on only
> the left and bottom axes. The current plot has sprouted tick marks on the
> top and right side, too, and I want to remove them. I've not found an answer
> to this issue in Deepayan's book or on the web. I would appreciate also
> learning why the extra tick marks appeared. The dput() data are included.
>
>    The plotting command;
>
> rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'h',
>                         main = 'Monthly Total Precipitation\n2005-2018',
>                         xlab = 'Year and Month', ylab = 'Precipitation (in)',
>                         scales = list(x = list(at = seq(1,162,by=6), cex = 0.7, rot = 90)))
>
> plot(rain.all.sum)
>
>    The data:
>
> structure(list(Month = structure(1:162, .Label = c("2005-01",
> "2005-02", "2005-03", "2005-04", "2005-05", "2005-06", "2005-07",
> "2005-08", "2005-09", "2005-10", "2005-11", "2005-12", "2006-01",
> "2006-02", "2006-03", "2006-04", "2006-05", "2006-06", "2006-07",
> "2006-08", "2006-09", "2006-10", "2006-11", "2006-12", "2007-01",
> "2007-02", "2007-03", "2007-04", "2007-05", "2007-06", "2007-07",
> "2007-08", "2007-09", "2007-10", "2007-11", "2007-12", "2008-01",
> "2008-02", "2008-03", "2008-04", "2008-05", "2008-06", "2008-07",
> "2008-08", "2008-09", "2008-10", "2008-11", "2008-12", "2009-01",
> "2009-02", "2009-03", "2009-04", "2009-05", "2009-06", "2009-07",
> "2009-08", "2009-09", "2009-10", "2009-11", "2009-12", "2010-01",
> "2010-02", "2010-03", "2010-04", "2010-05", "2010-06", "2010-07",
> "2010-08", "2010-09", "2010-10", "2010-11", "2010-12", "2011-01",
> "2011-02", "2011-03", "2011-04", "2011-05", "2011-06", "2011-07",
> "2011-08", "2011-09", "2011-10", "2011-11", "2011-12", "2012-01",
> "2012-02", "2012-03", "2012-04", "2012-05", "2012-06", "2012-07",
> "2012-08", "2012-09", "2012-10", "2012-11", "2012-12", "2013-01",
> "2013-02", "2013-03", "2013-04", "2013-05", "2013-06", "2013-07",
> "2013-08", "2013-09", "2013-10", "2013-11", "2013-12", "2014-01",
> "2014-02", "2014-03", "2014-04", "2014-05", "2014-06", "2014-07",
> "2014-08", "2014-09", "2014-10", "2014-11", "2014-12", "2015-01",
> "2015-02", "2015-03", "2015-04", "2015-05", "2015-06", "2015-07",
> "2015-08", "2015-09", "2015-10", "2015-11", "2015-12", "2016-01",
> "2016-02", "2016-03", "2016-04", "2016-05", "2016-06", "2016-07",
> "2016-08", "2016-09", "2016-10", "2016-11", "2016-12", "2017-01",
> "2017-02", "2017-03", "2017-04", "2017-05", "2017-06", "2017-07",
> "2017-08", "2017-09", "2017-10", "2017-11", "2017-12", "2018-01",
> "2018-02", "2018-03", "2018-04", "2018-05", "2018-06"), class = "factor"),
>      Sum = c(53.51, 24.2, 88.54, 72.85, 77.3, 49.19, 8.77, 5.75,
>      27.83, 79.75, 123.89, 168.29, 229.69, 70.91, 74.15, 62.3,
>      43.56, 35.08, 3.6, 2.76, 26.83, 47.72, 293.23, 139.84, 103.48,
>      120.91, 85.96, 55.91, 26.56, 29.44, 9.9, 15.38, 33.47, 93.6,
>      105.61, 277.41, 279.38, 144.26, 220.88, 149.75, 82.28, 55.87,
>      5.29, 52.27, 21.1, 64.76, 182.31, 207.13, 196.29, 89.27,
>      187.72, 111.67, 111.72, 38.19, 6.07, 15.25, 52.46, 127.75,
>      208.43, 146.62, 169.34, 94.54, 154.21, 131.39, 151.27, 135.46,
>      9.98, 8.72, 86.67, 142.04, 225.61, 274.93, 196.68, 153.24,
>      263.54, 231.49, 122.23, 58.26, 34.65, 2.96, 28.21, 103.92,
>      217.52, 166.16, 305.27, 168.73, 333.28, 145.68, 101.2, 127.77,
>      15.41, 1.85, 3.49, 245.99, 272.35, 297.05, 177.17, 105.71,
>      118.44, 136.34, 161.01, 53.31, 1.15, 23.43, 200.97, 69.12,
>      158.51, 131.67, 156.95, 266.38, 291.7, 147.15, 101.49, 78.89,
>      26.99, 24.35, 35.76, 210.2, 225.55, 282.85, 153.91, 148.13,
>      187.03, 133.99, 62.28, 17.58, 13.41, 35.58, 47.04, 154.92,
>      317.77, 604.04, 288.91, 210.86, 266.04, 121.62, 78.17, 85.96,
>      29.84, 7.02, 72.13, 404.33, 247.71, 255.5, 138.22, 339.5,
>      368.99, 209.41, 110.08, 63.9, 0.62, 6.97, 133.75, 227.1,
>      312.99, 178.58, 255.8, 155.05, 135.27, 225.55, 15.23, 1.58
>      ), Median = c(0.01, 0, 0, 0.1, 0.1, 0, 0, 0, 0, 0.02, 0.1,
>      0.04, 0.5, 0, 0.1, 0.07, 0, 0, 0, 0, 0, 0, 0.57, 0.03, 0,
>      0.2, 0.055, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0.21, 0.02, 0.2,
>      0.11, 0.02, 0, 0, 0, 0, 0, 0.1, 0.165, 0.01, 0.01, 0.15,
>      0.01, 0, 0, 0, 0, 0, 0.02, 0.125, 0, 0.1, 0.08, 0.055, 0.1,
>      0.13, 0.01, 0, 0, 0, 0, 0.2, 0.17, 0.02, 0.07, 0.23, 0.15,
>      0.06, 0, 0, 0, 0, 0.03, 0.1, 0, 0.1, 0.1, 0.2, 0.07, 0, 0.02,
>      0, 0, 0, 0.04, 0.115, 0.24, 0.02, 0.03, 0.01, 0.01, 0.02,
>      0, 0, 0, 0, 0, 0.02, 0, 0, 0.2, 0.18, 0.05, 0, 0, 0, 0, 0,
>      0.08, 0.07, 0.1, 0, 0.01, 0, 0.02, 0, 0, 0, 0, 0, 0, 0.09,
>      0.4, 0.18, 0.1, 0.2, 0, 0, 0, 0, 0, 0, 0.29, 0.09, 0.09,
>      0, 0.26, 0.3, 0.16, 0, 0, 0, 0, 0, 0, 0.25, 0, 0.16, 0.03,
>      0.02, 0.08, 0, 0), Max = c(3, 1.1, 3.2, 1.2, 1.6, 1.48, 0.8,
>      0.6, 3.2, 4.9, 3.1, 3.63, 3.4, 2.6, 2, 3.25, 1.6, 2.1, 0.4,
>      0.5, 1.1, 2, 6.6, 3.2, 3.6, 5.8, 2.3, 1.7, 1.3, 1.2, 1, 2.1,
>      2, 3, 3, 5.9, 3.3, 2.9, 5.2, 1.8, 1.4, 2.2, 0.6, 2.5, 1.02,
>      2, 4.4, 3.6, 5.3, 2.2, 2.7, 2.5, 1.5, 1.4, 0.8, 1.4, 1.4,
>      2.11, 2.1, 3.3, 3.12, 1.3, 2.4, 1.5, 2.4, 3.5, 0.9, 1.3,
>      2.77, 2, 3.2, 2.6, 5.4, 3.4, 2.87, 2.6, 1.6, 1.4, 1.2, 0.2,
>      0.91, 2.1, 2.2, 5.2, 4.75, 2.3, 3.4, 2.67, 1.8, 1.9, 0.61,
>      0.2, 0.2, 3.4, 3.65, 3.1, 3.15, 2.2, 2, 2.7, 2.3, 1.18, 0.2,
>      2.1, 3.3, 1.7, 2.47, 8.8, 2.8, 3.27, 3.29, 2.4, 2.1, 1.73,
>      1.03, 1.4, 1.1, 2.9, 3.1, 5.7, 2.69, 2.7, 3.1, 1.3, 1.85,
>      0.6, 1.5, 1.1, 1.5, 4.2, 3.8, 4.4, 2.5, 3.2, 2.61, 1.94,
>      2.1, 2.1, 1, 0.57, 2.2, 5, 3.02, 2.8, 1.7, 3.08, 5, 2.54,
>      2.7, 1.6, 0.1, 0.5, 2.6, 5.35, 3.5, 2.9, 2.3, 2.9, 1.2, 2.47,
>      0.6, 0.25)), row.names = c(NA, -162L), class = "data.frame")
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zp@imp@o @ending from gm@il@com  Wed Sep 12 00:30:20 2018
From: zp@imp@o @ending from gm@il@com (Zach Simpson)
Date: Wed, 12 Sep 2018 10:30:20 +1200
Subject: [R] getting 21 very different colours
Message-ID: <CAJByKzq-2aES1GoaPhesLKL_6r9G5c53m6-u1PUaeOD+geGvkw@mail.gmail.com>

Hi Federico

For a possible alternative, the scico package provides a nice
collection of color palettes that are designed to be both color-blind
friendly and differentiable:

https://www.data-imaginist.com/2018/scico-and-the-colour-conundrum/

You could generate a vector of 21 colors (spaced as far apart as
possible on the palette) to pass to your plot arguments with something
like:

library(scico)
scico(21, palette = 'oleron')

Not sure if this works for your case though. But maybe another feature
(shape?) could help differentiate the 21 points.

Hope this helps,
Zach Simpson

> Message: 11
> Date: Tue, 11 Sep 2018 07:34:51 +0000
> From: Federico Calboli <federico.calboli at kuleuven.be>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] getting 21 very different colours
> Message-ID: <08A6397B-4D67-4195-A53A-1FD394F72B6C at kuleuven.be>
> Content-Type: text/plain; charset="utf-8"
>
> Hi All,
>
> I am plotting a scatterplot of 21 populations, and I am using rainbow(21)[pops.col] to generate 21 colours for the plot (which works).  Maybe it is because I can really process few colours at a time, but the differences between the colours are not as strong as I?d like.  I can specify start and end for rainbow(), but if anything that looks worse if I do not just stick to 0 and 1.
>
> Is there a way of getting a set of 21 colours that maximises the differences between them?
>
> I could pick them by hand, but that is about 15 colours more than I know (I have a detailed colourchart, but the visual differences between ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).
>
> Cheers
>
> F
> --
> Federico Calboli
> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
> Charles Deberiotstraat 32 box 2439
> 3000 Leuven
> +32 16 32 87 67


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep 12 00:36:02 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 15:36:02 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes
Message-ID: <alpine.LNX.2.20.1809111535030.11930@salmo.appl-ecosys.com>

On Tue, 11 Sep 2018, Bert Gunter wrote:

> Well, you might try ?xyplot -- in particular the "scales" list section
> and in particular there the "tck" parameter. Adding
> tck = c(1, 0)
> to the "scales ="  list will probably solve your problem.

Bert,

   I missed the end of the tck description in the book (the same text as the
help file but with more information) where it mentions that tck can be a
vector of length 2 where the first element affects the left/bottom axes and
the second element affects the right/top axes. I also did not grok turning
the first element on and the second element off.

   Now I wonder why this wasn't an issue before now in the xyplots I created.

Thanks much,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep 12 00:41:19 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 15:41:19 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>

On Tue, 11 Sep 2018, Bert Gunter wrote:

> Adding
> tck = c(1, 0)
> to the "scales ="  list will probably solve your problem.

Bert,

   How interesting. This removed the tick marks on top but left them on the
right axes. Will think more about this.

Regards,

Rich


From drjimlemon @ending from gm@il@com  Wed Sep 12 00:43:36 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 12 Sep 2018 08:43:36 +1000
Subject: [R] loop for comparing two or more groups using bootstrapping
In-Reply-To: <CY4PR1301MB21673838F1F43BB962933542FA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
References: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
 <CA+8X3fX6f6zT3VGbprbaOFMspKFijOncD0jiwodQ=cXShcnX_g@mail.gmail.com>
 <CY4PR1301MB21673838F1F43BB962933542FA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
Message-ID: <CA+8X3fXs5+4EWqpm7cbTjZy0Eg=PK1bewy7GBnRjgSXSkS4-uw@mail.gmail.com>

Hi Kristi,
My fault, I only worked out how to assign the values to the names and pick
out the columns of daT for the calculations. I think this does what you
want, but I can't guarantee the result.

daT<-structure(list(year1=c(0.417,0.538,0.69,0.688,0.688,0.606,
0.667,0.7,0.545,0.462,0.711,0.642,0.744,0.604,0.612,
0.667,0.533,0.556,0.444,0.526,0.323,0.308,0.195,0.333,
0.323,0.256,0.345,0.205,0.286,0.706,0.7,0.6,0.571,0.364,
0.429,0.326,0.571,0.424,0.341,0.387,0.341,0.324,0.696,
0.696,0.583,0.556,0.645,0.435,0.471,0.556),year2=c(0.385,
0.552,0.645,0.516,0.629,0.595,0.72,0.638,0.557,0.588,
0.63,0.744,0.773,0.571,0.723,0.769,0.667,0.667,0.526,
0.476,0.294,0.323,0.222,0.556,0.263,0.37,0.357,0.25,
0.323,0.778,0.667,0.636,0.583,0.432,0.412,0.333,0.571,
0.39,0.4,0.452,0.326,0.471,0.7,0.75,0.615,0.462,0.556,
0.4,0.696,0.465),year3=c(0.435,0.759,0.759,0.759,0.714,
0.593,0.651,0.683,0.513,0.643,0.652,0.757,0.791,0.649,
0.78,0.5,0.5,0.5,0.533,0.429,0.333,0.286,0.231,0.533,
0.303,0.417,0.333,0.333,0.357,0.909,1,0.952,0.8,0.556,
0.529,0.562,0.762,0.513,0.733,0.611,0.733,0.647,0.909,
0.857,0.8,0.556,0.588,0.562,0.857,0.513),year4=c(0.333,
0.533,0.6,0.483,0.743,0.5,0.691,0.619,0.583,0.385,0.653,
0.762,0.844,0.64,0.667,0.571,0.571,0.615,0.421,0.5,0.205,
0.308,0.25,0.6,0.242,0.308,0.276,0.235,0.211,0.9,0.632,
0.72,0.727,0.356,0.5,0.368,0.5,0.41,0.562,0.514,0.4,
0.409,0.632,0.72,0.727,0.4,0.5,0.421,0.5,0.462)),.Names=c("year1",
"year2","year3","year4"),row.names=c(NA,-50L),class="data.frame")
colname.mat<-combn(paste0("year",1:4),2)
samplenames<-apply(colname.mat,2,paste,collapse="")
k<-10000
meandiff<-function(x) return(mean(x[[1]])-mean(x[[2]]))
for(column in 1:ncol(colname.mat)) {
 assign(samplenames[column],
  replicate(k,data.frame(sample(daT[,colname.mat[1,column]],3,TRUE),
   sample(daT[,colname.mat[2,column]],3,TRUE))))
 meandiffs<-unlist(apply(get(samplenames[column]),2,meandiff))
 cat(samplenames[column],"\n")
 cat("mean diff =",mean(meandiffs),"95% CI =",
  quantile(meandiffs,c(0.025,0.975)),"\n")
 png(paste0(samplenames[column],".png")
 hist(meandiffs)
 dev.off()
}

You should get a printout of the means and CIs and  bunch of PNG files with
the histograms.

Jim


On Tue, Sep 11, 2018 at 11:55 PM Kristi Glover <kristi.glover at hotmail.com>
wrote:

> Dear Jim,
>
> Thank you very much for the code. I run it but it gave me row names
> like "year224", "year142".
>
> are these the difference between columns? If we want to get bootstrapping
> means of difference between years (year2-year1; year3-year1), its CI and
> exact p value, how can we get it?
>
> thanks
>
> KG
>
> ----
>
> head(daT)
>
> colname.mat<-combn(paste0("year",1:4),2)
>
> samplenames<-apply(colname.mat,2,paste,collapse="")
>
> k<-10
>
> for(column in 1:ncol(colname.mat)) {
>
>  assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,
> column]]),3,TRUE)))
>
> }
>
> > get(samplenames[1])
>          [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
> year224 0.556 0.667 0.571 0.526 0.629 0.696 0.323 0.526 0.256 0.667
> year142 0.324 0.324 0.706 0.638 0.600 0.294 0.612 0.688 0.432 0.387
> year237 0.571 0.696 0.629 0.471 0.462 0.471 0.452 0.595 0.333 0.435
>
>
>
>
> ------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *Sent:* September 11, 2018 1:44 AM
> *To:* Kristi Glover
> *Cc:* r-help mailing list
> *Subject:* Re: [R] loop for comparing two or more groups using
> bootstrapping
>
> Hi Kristy,
> Try this:
>
> colname.mat<-combn(paste0("year",1:4),2)
> samplenames<-apply(colname.mat,2,paste,collapse="")
> k<-10000
> for(column in 1:ncol(colname.mat)) {
>
>  assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,column]]),3,TRUE)))
> }
>
> Then use get(samplenames[1]) and so on to access the values.
>
> Jim
> On Tue, Sep 11, 2018 at 4:52 PM Kristi Glover <kristi.glover at hotmail.com>
> wrote:
> >
> > Hi R users,
> >
> > I was trying to test a null hypothesis of difference between two groups
> was 0. I have many years data, such as year1, year2,, year3, year4 and I
> was trying to compare between year1 and year2, year1 and year3, year2 and
> year3 and so on and have used following code with an example data.
> >
> >
> > I tried to make a loop but did not work to compare between many years,
> and also want to obtain the exact p value. Would you mind to help me to
> make a loop?
> >
> > Thanks for your help.
> >
> >
> > KG
> >
> >
> > daT<-structure(list(year1 = c(0.417, 0.538, 0.69, 0.688, 0.688, 0.606,
> > 0.667, 0.7, 0.545, 0.462, 0.711, 0.642, 0.744, 0.604, 0.612,
> > 0.667, 0.533, 0.556, 0.444, 0.526, 0.323, 0.308, 0.195, 0.333,
> > 0.323, 0.256, 0.345, 0.205, 0.286, 0.706, 0.7, 0.6, 0.571, 0.364,
> > 0.429, 0.326, 0.571, 0.424, 0.341, 0.387, 0.341, 0.324, 0.696,
> > 0.696, 0.583, 0.556, 0.645, 0.435, 0.471, 0.556), year2 = c(0.385,
> > 0.552, 0.645, 0.516, 0.629, 0.595, 0.72, 0.638, 0.557, 0.588,
> > 0.63, 0.744, 0.773, 0.571, 0.723, 0.769, 0.667, 0.667, 0.526,
> > 0.476, 0.294, 0.323, 0.222, 0.556, 0.263, 0.37, 0.357, 0.25,
> > 0.323, 0.778, 0.667, 0.636, 0.583, 0.432, 0.412, 0.333, 0.571,
> > 0.39, 0.4, 0.452, 0.326, 0.471, 0.7, 0.75, 0.615, 0.462, 0.556,
> > 0.4, 0.696, 0.465), year3 = c(0.435, 0.759, 0.759, 0.759, 0.714,
> > 0.593, 0.651, 0.683, 0.513, 0.643, 0.652, 0.757, 0.791, 0.649,
> > 0.78, 0.5, 0.5, 0.5, 0.533, 0.429, 0.333, 0.286, 0.231, 0.533,
> > 0.303, 0.417, 0.333, 0.333, 0.357, 0.909, 1, 0.952, 0.8, 0.556,
> > 0.529, 0.562, 0.762, 0.513, 0.733, 0.611, 0.733, 0.647, 0.909,
> > 0.857, 0.8, 0.556, 0.588, 0.562, 0.857, 0.513), year4 = c(0.333,
> > 0.533, 0.6, 0.483, 0.743, 0.5, 0.691, 0.619, 0.583, 0.385, 0.653,
> > 0.762, 0.844, 0.64, 0.667, 0.571, 0.571, 0.615, 0.421, 0.5, 0.205,
> > 0.308, 0.25, 0.6, 0.242, 0.308, 0.276, 0.235, 0.211, 0.9, 0.632,
> > 0.72, 0.727, 0.356, 0.5, 0.368, 0.5, 0.41, 0.562, 0.514, 0.4,
> > 0.409, 0.632, 0.72, 0.727, 0.4, 0.5, 0.421, 0.5, 0.462)), .Names =
> c("year1",
> > "year2", "year3", "year4"), row.names = c(NA, -50L), class =
> "data.frame")
> >
> > head(daT)
> >
> > # null hypothesis; difference is equal to zero
> >
> > dif1.2<-daT$year2-daT$year1
> >
> > k=10000
> >
> > mysamples1.2=replicate(k, sample(dif1.2, replace=T))
> >
> > mymeans1.2=apply(mysamples1.2, 2, mean)
> >
> > quantile(mymeans1.2, c(0.025, 0.975))
> >
> > hist(mysamples1.2)
> >
> > mean(mymeans1.2)
> >
> > #what is p value?
> >
> >
> > #similarly Now I want to compare between year 1 and year3,
> >
> > dif1.3<-daT$year3-daT$year1
> >
> > mysamples1.3=replicate(k, sample(dif1.3, replace=T))
> >
> > mymeans1.3=apply(mysamples1.3, 2, mean)
> >
> > quantile(mymeans1.3, c(0.025, 0.975))
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> R-help -- Main R Mailing List: Primary help - Homepage - SfS
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> stat.ethz.ch
> The main R mailing list, for announcements about the development of R and
> the availability of new code, questions and answers about problems and
> solutions using R, enhancements and patches to the source code and
> documentation of R, comparison and compatibility with S and S-plus, and for
> the posting of nice examples and benchmarks.
>
>
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Achim@Zeilei@ @ending from uibk@@c@@t  Wed Sep 12 00:47:51 2018
From: Achim@Zeilei@ @ending from uibk@@c@@t (Achim Zeileis)
Date: Wed, 12 Sep 2018 00:47:51 +0200 (CEST)
Subject: [R] getting 21 very different colours
In-Reply-To: <CAJByKzq-2aES1GoaPhesLKL_6r9G5c53m6-u1PUaeOD+geGvkw@mail.gmail.com>
References: <CAJByKzq-2aES1GoaPhesLKL_6r9G5c53m6-u1PUaeOD+geGvkw@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.1809120044520.2287@paninaro>

Have a look at the Polychrome package by Kevin Coombes and Guy Brock:
https://CRAN.R-project.org/package=Polychrome

This employs the LUV space (with HCL = polar LUV) to get many distinct 
distinguishable colors. For a few first steps, see:
https://CRAN.R-project.org/web/packages/Polychrome/vignettes/polychrome.html

On Wed, 12 Sep 2018, Zach Simpson wrote:

> Hi Federico
>
> For a possible alternative, the scico package provides a nice
> collection of color palettes that are designed to be both color-blind
> friendly and differentiable:
>
> https://www.data-imaginist.com/2018/scico-and-the-colour-conundrum/
>
> You could generate a vector of 21 colors (spaced as far apart as
> possible on the palette) to pass to your plot arguments with something
> like:
>
> library(scico)
> scico(21, palette = 'oleron')
>
> Not sure if this works for your case though. But maybe another feature
> (shape?) could help differentiate the 21 points.
>
> Hope this helps,
> Zach Simpson
>
>> Message: 11
>> Date: Tue, 11 Sep 2018 07:34:51 +0000
>> From: Federico Calboli <federico.calboli at kuleuven.be>
>> To: "r-help at r-project.org" <r-help at r-project.org>
>> Subject: [R] getting 21 very different colours
>> Message-ID: <08A6397B-4D67-4195-A53A-1FD394F72B6C at kuleuven.be>
>> Content-Type: text/plain; charset="utf-8"
>>
>> Hi All,
>>
>> I am plotting a scatterplot of 21 populations, and I am using rainbow(21)[pops.col] to generate 21 colours for the plot (which works).  Maybe it is because I can really process few colours at a time, but the differences between the colours are not as strong as I?d like.  I can specify start and end for rainbow(), but if anything that looks worse if I do not just stick to 0 and 1.
>>
>> Is there a way of getting a set of 21 colours that maximises the differences between them?
>>
>> I could pick them by hand, but that is about 15 colours more than I know (I have a detailed colourchart, but the visual differences between ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).
>>
>> Cheers
>>
>> F
>> --
>> Federico Calboli
>> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
>> Charles Deberiotstraat 32 box 2439
>> 3000 Leuven
>> +32 16 32 87 67
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From drjimlemon @ending from gm@il@com  Wed Sep 12 00:52:34 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 12 Sep 2018 08:52:34 +1000
Subject: [R] Increasing size of label in Taylor plot of Plotrix package
In-Reply-To: <20180911083700.29178.qmail@f5mail-224-158.rediffmail.com>
References: <20180911083700.29178.qmail@f5mail-224-158.rediffmail.com>
Message-ID: <CA+8X3fUVp+R-QzRaiZq_D+yejchGxPqQYhbpvMjRPgXOky0LsA@mail.gmail.com>

Hi Sonam,
You're right. Although the cex.axis argument is present, it doesn't
seem to be used. I will have to debug this, which may take a day or
two.

Jim

On Tue, Sep 11, 2018 at 6:37 PM Sonam Sandeep Dash
<ssdash_swce at rediffmail.com> wrote:
>
> Respected Sir,
> I have created a Taylor plot using the plotrix package. However, I am unable to increase the size of labels of axis. I have tried so many ways but all are in vein. There is no change to size of label of either axis. Kindly tell me the procedure to do the same.
> Thank you,
>
> Regards:
> Sonam Sandeep Dash
> Research scholar
> School of Water Resources
> Indian Institute of Technology, Kharagpur
> West Bengal-721302


From bgunter@4567 @ending from gm@il@com  Wed Sep 12 00:55:21 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 11 Sep 2018 15:55:21 -0700
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>

??

Not when I run your code with the tck specification added. Show us
your xyplot invocation. It should be
scales = list(tck = c(1,0), x= etc.)

Bert

On Tue, Sep 11, 2018 at 3:51 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 11 Sep 2018, Bert Gunter wrote:
>
> > Adding
> > tck = c(1, 0)
> > to the "scales ="  list will probably solve your problem.
>
> Bert,
>
>    How interesting. This removed the tick marks on top but left them on the
> right axes. Will think more about this.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon @ending from gm@il@com  Wed Sep 12 01:14:14 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 12 Sep 2018 09:14:14 +1000
Subject: [R] Remove plot axis values in dotplot graph
In-Reply-To: <CAE9stmdidxkAMbA-6+cFRPZMVppQt+rj6WYPJ-1AhHiqcPBpaA@mail.gmail.com>
References: <CAE9stmdidxkAMbA-6+cFRPZMVppQt+rj6WYPJ-1AhHiqcPBpaA@mail.gmail.com>
Message-ID: <CA+8X3fVqRQABehfH48QMc5_BzTVqO3qaJOTxzyCmC+ovw7OXug@mail.gmail.com>

Hi Abou,
Surprisingly you can't omit the x axis in dotchart. This hack will work:

sink("dotchar_noax.R")
sink()

Edit the resulting file by joining the first two lines with the
assignment symbol (<-), delete the two lines at the bottom and comment
out the line "axis(1)".

source("dotchart.noax.R")
dotchart.noax(scores,cex=1.5, pch = 18, col=c(1:3), xaxt = "n", main="Dot Plot
 child?s cough data", xlab="cough Scores")
library(plotrix)
staxlab(1,0:16)

I used "staxlab" so that you could have all of the labels 0:16.

Jim


On Wed, Sep 12, 2018 at 5:57 AM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear All:
>
> One more thing. I want to Remove the plot x-axis values in dotplot graph. I
> am trying to use xaxt = "n", but it seems NOT working. Also after removing
> the x-axis values, I want to use the command axis(1, at=0:16, cex.axis=1)
> to add x-axis values from 0 to 16, but it seems not working as expect.
>
>
>
> Honey.Dosage<-c(12,11,15,11,10,13,10,4,15,16,9,14,10,6,10,8,11,12,12,8,12,9,11,15,10,15,9,13,8,12,10,8,9,5,12)
>
> DM.Dosage<-c(4,6,9,4,7,7,7,9,12,10,11,6,3,4,9,12,7,6,8,12,12,4,12,13,7,10,13,9,4,4,10,15,9)
>
> No.Dosage<-c(5,8,6,1,0,8,12,8,7,7,1,6,7,7,12,7,9,7,9,5,11,9,5,6,8,8,6,7,10,9,4,8,7,3,1,4,3)
>
> scores<-c(Honey.Dosage,DM.Dosage,No.Dosage)
>
> min(scores)
> max(scores)
>
> dotchart(scores,cex=1.5, pch = 18, col=c(1:3), xaxt = "n", main="Dot Plot
> child?s cough data", xlab="cough Scores")
>
> axis(1, at=0:16, cex.axis=1.5)
>
>
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon @ending from gm@il@com  Wed Sep 12 01:16:54 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 12 Sep 2018 09:16:54 +1000
Subject: [R] Hierarchical Cluster Analysis
In-Reply-To: <D8AD1348-0091-4BC5-BD7E-395CE465BEB7@gmail.com>
References: <D8AD1348-0091-4BC5-BD7E-395CE465BEB7@gmail.com>
Message-ID: <CA+8X3fX-GRh5F3OQiwotOLtKhG8tdSU7bDR1aUs7XqoBM+ncrg@mail.gmail.com>

agnes (cluster)

Jim
On Wed, Sep 12, 2018 at 8:10 AM Bryan Mac <bryanmac.24 at gmail.com> wrote:
>
>
> Bryan Mac
> Data Scientist
> Research Analytics
> Ipsos Insight LLC
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep 12 01:02:47 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 16:02:47 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
 <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>

On Tue, 11 Sep 2018, Bert Gunter wrote:

> Not when I run your code with the tck specification added. Show us
> your xyplot invocation. It should be
> scales = list(tck = c(1,0), x= etc.)

Bert,

   Command:

rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'h',
                        main = 'Monthly Total Precipitation\n2005-2018',
                        xlab = 'Year and Month', ylab = 'Precipitation (in)',
                        scales = list(x = list(tck = c(1, 0), at = seq(1,162,by=6),
                                               cex = 0.7, rot = 90)))

rain.all.sum.pdf attached.

Regards,

Rich

-------------- next part --------------
A non-text attachment was scrubbed...
Name: rain.all.sum.pdf
Type: application/pdf
Size: 6640 bytes
Desc: 
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180911/bc738398/attachment.pdf>

From bgunter@4567 @ending from gm@il@com  Wed Sep 12 02:21:38 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 11 Sep 2018 17:21:38 -0700
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
 <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
 <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTwayvLnE7aAtFO69pEQMABa5sC4YR+5tLzGPy=ZUPFJg@mail.gmail.com>

As I thought, you did not do what I told you to.

Look *carefully* at the two to see your error.

-- Bert


On Tue, Sep 11, 2018 at 5:01 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 11 Sep 2018, Bert Gunter wrote:
>
> > Not when I run your code with the tck specification added. Show us
> > your xyplot invocation. It should be
> > scales = list(tck = c(1,0), x= etc.)
>
> Bert,
>
>    Command:
>
> rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'h',
>                         main = 'Monthly Total Precipitation\n2005-2018',
>                         xlab = 'Year and Month', ylab = 'Precipitation (in)',
>                         scales = list(x = list(tck = c(1, 0), at = seq(1,162,by=6),
>                                                cex = 0.7, rot = 90)))
>
> rain.all.sum.pdf attached.
>
> Regards,
>
> Rich
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep 12 02:39:13 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 17:39:13 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <CAGxFJbTwayvLnE7aAtFO69pEQMABa5sC4YR+5tLzGPy=ZUPFJg@mail.gmail.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
 <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
 <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>
 <CAGxFJbTwayvLnE7aAtFO69pEQMABa5sC4YR+5tLzGPy=ZUPFJg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809111733320.21101@salmo.appl-ecosys.com>

On Tue, 11 Sep 2018, Bert Gunter wrote:

> As I thought, you did not do what I told you to.
> Look *carefully* at the two to see your error.

Bert,

   You're correct, of course. After moving the tck parameter in front of the
x list the right-side ticks are gone. Unfortunately, so are the data: the
panel is empty.

   Corrected command:

rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'p, h',
                        main = 'Monthly Total Precipitation\n2005-2018',
                        xlab = 'Year and Month', ylab = 'Precipitation (in)',
                        scales = list(tck = c(1,0), x = list(at = seq(1,162,by=6),
                                               cex = 0.7, rot = 90)))

   Tomorrow I'll work on why the panel display disappeared along with the
right axes tick marks. Parentheses all match according to emacs.

Thanks,

Rich


From bgunter@4567 @ending from gm@il@com  Wed Sep 12 03:02:30 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 11 Sep 2018 18:02:30 -0700
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <alpine.LNX.2.20.1809111733320.21101@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
 <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
 <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>
 <CAGxFJbTwayvLnE7aAtFO69pEQMABa5sC4YR+5tLzGPy=ZUPFJg@mail.gmail.com>
 <alpine.LNX.2.20.1809111733320.21101@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTW6YaVGpcdw4j1ZpFWdHr+A_CxFGXu+UQaLE+2+aL=nQ@mail.gmail.com>

You do that. Your error is obvious.
-- Bert


On Tue, Sep 11, 2018 at 5:39 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 11 Sep 2018, Bert Gunter wrote:
>
> > As I thought, you did not do what I told you to.
> > Look *carefully* at the two to see your error.
>
> Bert,
>
>    You're correct, of course. After moving the tck parameter in front of the
> x list the right-side ticks are gone. Unfortunately, so are the data: the
> panel is empty.
>
>    Corrected command:
>
> rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'p, h',
>                         main = 'Monthly Total Precipitation\n2005-2018',
>                         xlab = 'Year and Month', ylab = 'Precipitation (in)',
>                         scales = list(tck = c(1,0), x = list(at = seq(1,162,by=6),
>                                                cex = 0.7, rot = 90)))
>
>    Tomorrow I'll work on why the panel display disappeared along with the
> right axes tick marks. Parentheses all match according to emacs.
>
> Thanks,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep 12 03:28:04 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 18:28:04 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes [RESOLVED]
In-Reply-To: <CAGxFJbTW6YaVGpcdw4j1ZpFWdHr+A_CxFGXu+UQaLE+2+aL=nQ@mail.gmail.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
 <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
 <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>
 <CAGxFJbTwayvLnE7aAtFO69pEQMABa5sC4YR+5tLzGPy=ZUPFJg@mail.gmail.com>
 <alpine.LNX.2.20.1809111733320.21101@salmo.appl-ecosys.com>
 <CAGxFJbTW6YaVGpcdw4j1ZpFWdHr+A_CxFGXu+UQaLE+2+aL=nQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809111827150.22624@salmo.appl-ecosys.com>

On Tue, 11 Sep 2018, Bert Gunter wrote:

> You do that. Your error is obvious.

Bert,

   Yep. Forgot to remove the 'p' from the type attribute.

Mea culpa!

Rich


From ncecchino @ending from gm@il@com  Wed Sep 12 03:49:36 2018
From: ncecchino @ending from gm@il@com (Nicola Cecchino)
Date: Tue, 11 Sep 2018 21:49:36 -0400
Subject: [R] Correcting dates in research / medical record using R
Message-ID: <e8b5a2bf-4403-2353-1d50-27665c60b7a7@gmail.com>

Hi,

I'm not that well versed with R - I'm trying to correct the dates of 
service in a de-identified research medical record of several subjects.? 
The correct dates come from a csv file, in the VisitDate column,? that 
looks like this in Excel.? The empty cells have other data in them that 
I don't need and the? file name is DateR.csv:


Id1 	Id2 	
	
	
	
	
	VisitDate
12345 	12345 	
	
	
	
	
	4/3/2018


The research medical record is a text file and the "DATE OF SERVICE" in 
the top matter is in error in all of the subjects and needs to be 
replaced with the "VisitDate" in the csv file.? The file name for the 
medical records is test3.NEW.? Here is a screen grab of the top matter 
of the research medical record; below this data excerpt is other 
gathered data for that subject:


================================================================================

PATIENT NAME: CONFIDENTIAL,#12345
PATIENT ID #: 12345
DATE OF SERVICE: 04/10/2018
ACCESSION NUMBER: RR1234567

TEST PROCEDURE??????? HIGH/LOW? TEST RESULTS?????? UNITS NORMAL VALUES


As described above, I need to update the text file DATE OF SERVICE:? 
date with the VisitDate in the csv file.

I made several attempts at this to failure and so now I turn to you.? 
Here is the code that exhibits my attempts:


clinicVdate <- read.csv("DateR.csv")

rownames(clinicVdate) <- as.character(clinicVdate[,'Id2'])

Id2 <- NA

input_data <- readLines("D:/test/test3.NEW")
output_data <- c()

for(input_line in input_data){
 ? output_line = input_line
 ? if(length(grep('PATIENT ID #:', input_line))>0)? {
 ??? Id2 = as.character(strsplit(input_line, ':')[[1]][2])
 ? }

 ? if (length(grep( 'DATE OF SERVICE: ', input_line))){

 ??? output_line = paste('DATE OF SERVICE', clinicVdate[Id2, 
'VisitDate'], sep=':')

 ? }
 ? output_data = paste(output_data, output_line, sep='\n')
}

cat(output_data)


The results of the above remove the erroneous date and replace it with 
NA.? Here is an example of the results:


================================================================================

PATIENT NAME: CONFIDENTIAL,#12345
PATIENT ID #: 12345
DATE OF SERVICE: NA
ACCESSION NUMBER: RR1234567

TEST PROCEDURE??????? HIGH/LOW? TEST RESULTS?????? UNITS NORMAL VALUES


Where am I going wrong?? If I didn't pose my question appropriately, 
please let me know too!!? Any help with this would be greatly appreciated!!

Kind regards,

Nic Cecchino




	[[alternative HTML version deleted]]


From m@rn@@w@gley @ending from gm@il@com  Wed Sep 12 04:57:30 2018
From: m@rn@@w@gley @ending from gm@il@com (Marna Wagley)
Date: Tue, 11 Sep 2018 19:57:30 -0700
Subject: [R] loop for comparing two or more groups using bootstrapping
In-Reply-To: <CA+8X3fXs5+4EWqpm7cbTjZy0Eg=PK1bewy7GBnRjgSXSkS4-uw@mail.gmail.com>
References: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
 <CA+8X3fX6f6zT3VGbprbaOFMspKFijOncD0jiwodQ=cXShcnX_g@mail.gmail.com>
 <CY4PR1301MB21673838F1F43BB962933542FA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
 <CA+8X3fXs5+4EWqpm7cbTjZy0Eg=PK1bewy7GBnRjgSXSkS4-uw@mail.gmail.com>
Message-ID: <CAMwU6B0JpJ_=_5GL8LYyOSxUA29DX+oZ9Gj-4UsbDjBDeYesBA@mail.gmail.com>

Thank you Jim, it worked. I am very grateful for your help.
Thanks
KG

On Tue, Sep 11, 2018 at 3:51 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Kristi,
> My fault, I only worked out how to assign the values to the names and pick
> out the columns of daT for the calculations. I think this does what you
> want, but I can't guarantee the result.
>
> daT<-structure(list(year1=c(0.417,0.538,0.69,0.688,0.688,0.606,
> 0.667,0.7,0.545,0.462,0.711,0.642,0.744,0.604,0.612,
> 0.667,0.533,0.556,0.444,0.526,0.323,0.308,0.195,0.333,
> 0.323,0.256,0.345,0.205,0.286,0.706,0.7,0.6,0.571,0.364,
> 0.429,0.326,0.571,0.424,0.341,0.387,0.341,0.324,0.696,
> 0.696,0.583,0.556,0.645,0.435,0.471,0.556),year2=c(0.385,
> 0.552,0.645,0.516,0.629,0.595,0.72,0.638,0.557,0.588,
> 0.63,0.744,0.773,0.571,0.723,0.769,0.667,0.667,0.526,
> 0.476,0.294,0.323,0.222,0.556,0.263,0.37,0.357,0.25,
> 0.323,0.778,0.667,0.636,0.583,0.432,0.412,0.333,0.571,
> 0.39,0.4,0.452,0.326,0.471,0.7,0.75,0.615,0.462,0.556,
> 0.4,0.696,0.465),year3=c(0.435,0.759,0.759,0.759,0.714,
> 0.593,0.651,0.683,0.513,0.643,0.652,0.757,0.791,0.649,
> 0.78,0.5,0.5,0.5,0.533,0.429,0.333,0.286,0.231,0.533,
> 0.303,0.417,0.333,0.333,0.357,0.909,1,0.952,0.8,0.556,
> 0.529,0.562,0.762,0.513,0.733,0.611,0.733,0.647,0.909,
> 0.857,0.8,0.556,0.588,0.562,0.857,0.513),year4=c(0.333,
> 0.533,0.6,0.483,0.743,0.5,0.691,0.619,0.583,0.385,0.653,
> 0.762,0.844,0.64,0.667,0.571,0.571,0.615,0.421,0.5,0.205,
> 0.308,0.25,0.6,0.242,0.308,0.276,0.235,0.211,0.9,0.632,
> 0.72,0.727,0.356,0.5,0.368,0.5,0.41,0.562,0.514,0.4,
> 0.409,0.632,0.72,0.727,0.4,0.5,0.421,0.5,0.462)),.Names=c("year1",
> "year2","year3","year4"),row.names=c(NA,-50L),class="data.frame")
> colname.mat<-combn(paste0("year",1:4),2)
> samplenames<-apply(colname.mat,2,paste,collapse="")
> k<-10000
> meandiff<-function(x) return(mean(x[[1]])-mean(x[[2]]))
> for(column in 1:ncol(colname.mat)) {
>  assign(samplenames[column],
>   replicate(k,data.frame(sample(daT[,colname.mat[1,column]],3,TRUE),
>    sample(daT[,colname.mat[2,column]],3,TRUE))))
>  meandiffs<-unlist(apply(get(samplenames[column]),2,meandiff))
>  cat(samplenames[column],"\n")
>  cat("mean diff =",mean(meandiffs),"95% CI =",
>   quantile(meandiffs,c(0.025,0.975)),"\n")
>  png(paste0(samplenames[column],".png")
>  hist(meandiffs)
>  dev.off()
> }
>
> You should get a printout of the means and CIs and  bunch of PNG files with
> the histograms.
>
> Jim
>
>
> On Tue, Sep 11, 2018 at 11:55 PM Kristi Glover <kristi.glover at hotmail.com>
> wrote:
>
> > Dear Jim,
> >
> > Thank you very much for the code. I run it but it gave me row names
> > like "year224", "year142".
> >
> > are these the difference between columns? If we want to get bootstrapping
> > means of difference between years (year2-year1; year3-year1), its CI and
> > exact p value, how can we get it?
> >
> > thanks
> >
> > KG
> >
> > ----
> >
> > head(daT)
> >
> > colname.mat<-combn(paste0("year",1:4),2)
> >
> > samplenames<-apply(colname.mat,2,paste,collapse="")
> >
> > k<-10
> >
> > for(column in 1:ncol(colname.mat)) {
> >
> >  assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,
> > column]]),3,TRUE)))
> >
> > }
> >
> > > get(samplenames[1])
> >          [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
> > year224 0.556 0.667 0.571 0.526 0.629 0.696 0.323 0.526 0.256 0.667
> > year142 0.324 0.324 0.706 0.638 0.600 0.294 0.612 0.688 0.432 0.387
> > year237 0.571 0.696 0.629 0.471 0.462 0.471 0.452 0.595 0.333 0.435
> >
> >
> >
> >
> > ------------------------------
> > *From:* Jim Lemon <drjimlemon at gmail.com>
> > *Sent:* September 11, 2018 1:44 AM
> > *To:* Kristi Glover
> > *Cc:* r-help mailing list
> > *Subject:* Re: [R] loop for comparing two or more groups using
> > bootstrapping
> >
> > Hi Kristy,
> > Try this:
> >
> > colname.mat<-combn(paste0("year",1:4),2)
> > samplenames<-apply(colname.mat,2,paste,collapse="")
> > k<-10000
> > for(column in 1:ncol(colname.mat)) {
> >
> >
> assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,column]]),3,TRUE)))
> > }
> >
> > Then use get(samplenames[1]) and so on to access the values.
> >
> > Jim
> > On Tue, Sep 11, 2018 at 4:52 PM Kristi Glover <kristi.glover at hotmail.com
> >
> > wrote:
> > >
> > > Hi R users,
> > >
> > > I was trying to test a null hypothesis of difference between two groups
> > was 0. I have many years data, such as year1, year2,, year3, year4 and I
> > was trying to compare between year1 and year2, year1 and year3, year2 and
> > year3 and so on and have used following code with an example data.
> > >
> > >
> > > I tried to make a loop but did not work to compare between many years,
> > and also want to obtain the exact p value. Would you mind to help me to
> > make a loop?
> > >
> > > Thanks for your help.
> > >
> > >
> > > KG
> > >
> > >
> > > daT<-structure(list(year1 = c(0.417, 0.538, 0.69, 0.688, 0.688, 0.606,
> > > 0.667, 0.7, 0.545, 0.462, 0.711, 0.642, 0.744, 0.604, 0.612,
> > > 0.667, 0.533, 0.556, 0.444, 0.526, 0.323, 0.308, 0.195, 0.333,
> > > 0.323, 0.256, 0.345, 0.205, 0.286, 0.706, 0.7, 0.6, 0.571, 0.364,
> > > 0.429, 0.326, 0.571, 0.424, 0.341, 0.387, 0.341, 0.324, 0.696,
> > > 0.696, 0.583, 0.556, 0.645, 0.435, 0.471, 0.556), year2 = c(0.385,
> > > 0.552, 0.645, 0.516, 0.629, 0.595, 0.72, 0.638, 0.557, 0.588,
> > > 0.63, 0.744, 0.773, 0.571, 0.723, 0.769, 0.667, 0.667, 0.526,
> > > 0.476, 0.294, 0.323, 0.222, 0.556, 0.263, 0.37, 0.357, 0.25,
> > > 0.323, 0.778, 0.667, 0.636, 0.583, 0.432, 0.412, 0.333, 0.571,
> > > 0.39, 0.4, 0.452, 0.326, 0.471, 0.7, 0.75, 0.615, 0.462, 0.556,
> > > 0.4, 0.696, 0.465), year3 = c(0.435, 0.759, 0.759, 0.759, 0.714,
> > > 0.593, 0.651, 0.683, 0.513, 0.643, 0.652, 0.757, 0.791, 0.649,
> > > 0.78, 0.5, 0.5, 0.5, 0.533, 0.429, 0.333, 0.286, 0.231, 0.533,
> > > 0.303, 0.417, 0.333, 0.333, 0.357, 0.909, 1, 0.952, 0.8, 0.556,
> > > 0.529, 0.562, 0.762, 0.513, 0.733, 0.611, 0.733, 0.647, 0.909,
> > > 0.857, 0.8, 0.556, 0.588, 0.562, 0.857, 0.513), year4 = c(0.333,
> > > 0.533, 0.6, 0.483, 0.743, 0.5, 0.691, 0.619, 0.583, 0.385, 0.653,
> > > 0.762, 0.844, 0.64, 0.667, 0.571, 0.571, 0.615, 0.421, 0.5, 0.205,
> > > 0.308, 0.25, 0.6, 0.242, 0.308, 0.276, 0.235, 0.211, 0.9, 0.632,
> > > 0.72, 0.727, 0.356, 0.5, 0.368, 0.5, 0.41, 0.562, 0.514, 0.4,
> > > 0.409, 0.632, 0.72, 0.727, 0.4, 0.5, 0.421, 0.5, 0.462)), .Names =
> > c("year1",
> > > "year2", "year3", "year4"), row.names = c(NA, -50L), class =
> > "data.frame")
> > >
> > > head(daT)
> > >
> > > # null hypothesis; difference is equal to zero
> > >
> > > dif1.2<-daT$year2-daT$year1
> > >
> > > k=10000
> > >
> > > mysamples1.2=replicate(k, sample(dif1.2, replace=T))
> > >
> > > mymeans1.2=apply(mysamples1.2, 2, mean)
> > >
> > > quantile(mymeans1.2, c(0.025, 0.975))
> > >
> > > hist(mysamples1.2)
> > >
> > > mean(mymeans1.2)
> > >
> > > #what is p value?
> > >
> > >
> > > #similarly Now I want to compare between year 1 and year3,
> > >
> > > dif1.3<-daT$year3-daT$year1
> > >
> > > mysamples1.3=replicate(k, sample(dif1.3, replace=T))
> > >
> > > mymeans1.3=apply(mysamples1.3, 2, mean)
> > >
> > > quantile(mymeans1.3, c(0.025, 0.975))
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > R-help -- Main R Mailing List: Primary help - Homepage - SfS
> > <https://stat.ethz.ch/mailman/listinfo/r-help>
> > stat.ethz.ch
> > The main R mailing list, for announcements about the development of R and
> > the availability of new code, questions and answers about problems and
> > solutions using R, enhancements and patches to the source code and
> > documentation of R, comparison and compatibility with S and S-plus, and
> for
> > the posting of nice examples and benchmarks.
> >
> >
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ro@lin@ump @ending from gm@il@com  Wed Sep 12 08:20:40 2018
From: ro@lin@ump @ending from gm@il@com (roslinazairimah zakaria)
Date: Wed, 12 Sep 2018 14:20:40 +0800
Subject: [R] customise tick marks
Message-ID: <CANTvJZLMtZWX3BwUgagTMdxj0-gsz1z8SDP95-JLmM9Bvyp5Kg@mail.gmail.com>

Dear r-users,

I want to draw dotplot for mtcars data according to cyl. There are three
types of cylinder 4,6,8. However when we draw it does not use 4,6,8 instead
label it as 1,2,3.

I have this code and would like to customise the tick mark according to cyl
groups:


dotplot(cyl ~ mpg, data = mtcars, groups = cyl, cex=1.2,axes=FALSE,
  main="Gas Milage for Car Models",  xlab="Miles Per Gallon")
ticks = c(1,2,3)
axis(2, at = ticks, labels=c(4,6,8))

I got this message:

axis(2, at = ticks, labels=c(4,6,8))
Error in axis(2, at = ticks, labels = c(4, 6, 8)) :
  plot.new has not been called yet

Thank you so much for any help given.
-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Wed Sep 12 08:26:30 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 12 Sep 2018 06:26:30 +0000
Subject: [R] Correcting dates in research / medical record using R
In-Reply-To: <e8b5a2bf-4403-2353-1d50-27665c60b7a7@gmail.com>
References: <e8b5a2bf-4403-2353-1d50-27665c60b7a7@gmail.com>
Message-ID: <cfc5e11caf914d18aad819587de342d6@SRVEXCHCM1302.precheza.cz>

Hi

First of all you should not use HTML formated posts, it is big chance that it gets scrambled.

You should compare your ld2 after for cycle and result of

clinicVdate[Id2, 'VisitDate'], sep=':')

Most probably ld2 after for cycle does not conform to row names of clinicVdate.

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Nicola Cecchino
> Sent: Wednesday, September 12, 2018 3:50 AM
> To: R-help at r-project.org
> Subject: [R] Correcting dates in research / medical record using R
>
> Hi,
>
> I'm not that well versed with R - I'm trying to correct the dates of
> service in a de-identified research medical record of several subjects.
> The correct dates come from a csv file, in the VisitDate column,  that
> looks like this in Excel.  The empty cells have other data in them that
> I don't need and the  file name is DateR.csv:
>
>
> Id1 Id2
>
>
>
>
> VisitDate
> 12345 12345
>
>
>
>
> 4/3/2018
>
>
> The research medical record is a text file and the "DATE OF SERVICE" in
> the top matter is in error in all of the subjects and needs to be
> replaced with the "VisitDate" in the csv file.  The file name for the
> medical records is test3.NEW.  Here is a screen grab of the top matter
> of the research medical record; below this data excerpt is other
> gathered data for that subject:
>
>
> ===================================================================
> =============
>
> PATIENT NAME: CONFIDENTIAL,#12345
> PATIENT ID #: 12345
> DATE OF SERVICE: 04/10/2018
> ACCESSION NUMBER: RR1234567
>
> TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS NORMAL VALUES
>
>
> As described above, I need to update the text file DATE OF SERVICE:
> date with the VisitDate in the csv file.
>
> I made several attempts at this to failure and so now I turn to you.
> Here is the code that exhibits my attempts:
>
>
> clinicVdate <- read.csv("DateR.csv")
>
> rownames(clinicVdate) <- as.character(clinicVdate[,'Id2'])
>
> Id2 <- NA
>
> input_data <- readLines("D:/test/test3.NEW")
> output_data <- c()
>
> for(input_line in input_data){
>    output_line = input_line
>    if(length(grep('PATIENT ID #:', input_line))>0)  {
>      Id2 = as.character(strsplit(input_line, ':')[[1]][2])
>    }
>
>    if (length(grep( 'DATE OF SERVICE: ', input_line))){
>
>      output_line = paste('DATE OF SERVICE', clinicVdate[Id2,
> 'VisitDate'], sep=':')
>
>    }
>    output_data = paste(output_data, output_line, sep='\n')
> }
>
> cat(output_data)
>
>
> The results of the above remove the erroneous date and replace it with
> NA.  Here is an example of the results:
>
>
> ===================================================================
> =============
>
> PATIENT NAME: CONFIDENTIAL,#12345
> PATIENT ID #: 12345
> DATE OF SERVICE: NA
> ACCESSION NUMBER: RR1234567
>
> TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS NORMAL VALUES
>
>
> Where am I going wrong?  If I didn't pose my question appropriately,
> please let me know too!!  Any help with this would be greatly appreciated!!
>
> Kind regards,
>
> Nic Cecchino
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From chocold12 @ending from gm@il@com  Wed Sep 12 08:55:26 2018
From: chocold12 @ending from gm@il@com (lily li)
Date: Wed, 12 Sep 2018 14:55:26 +0800
Subject: [R] how to plot gridded data
Message-ID: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>

Hi R users,

I have a question about plotting gridded data. I have the files separately,
but do not know how to combine them. For example, each txt file has daily
precipitation data at a specific grid cell, named pr_lat_lon.txt. How to
plot all txt files for one surface (which is rectangular in this case), or
how to combine the txt files together? Thanks.

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Wed Sep 12 09:22:18 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 12 Sep 2018 07:22:18 +0000
Subject: [R] how to plot gridded data
In-Reply-To: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
References: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
Message-ID: <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>

Hi

1. Read files/lines into R ?read.table, ?read.lines
2. Merge files according to your specification ?merge, ?rbind
3. Plot values by suitable command(s) ?plot, ?ggplot
4. If you want more specific answer, please post more specific question, preferably with concise and clear example.
5. Avoid posting in HTML

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of lily li
> Sent: Wednesday, September 12, 2018 8:55 AM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] how to plot gridded data
>
> Hi R users,
>
> I have a question about plotting gridded data. I have the files separately, but do
> not know how to combine them. For example, each txt file has daily
> precipitation data at a specific grid cell, named pr_lat_lon.txt. How to plot all
> txt files for one surface (which is rectangular in this case), or how to combine
> the txt files together? Thanks.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From drjimlemon @ending from gm@il@com  Wed Sep 12 11:58:27 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 12 Sep 2018 19:58:27 +1000
Subject: [R] customise tick marks
In-Reply-To: <CANTvJZLMtZWX3BwUgagTMdxj0-gsz1z8SDP95-JLmM9Bvyp5Kg@mail.gmail.com>
References: <CANTvJZLMtZWX3BwUgagTMdxj0-gsz1z8SDP95-JLmM9Bvyp5Kg@mail.gmail.com>
Message-ID: <CA+8X3fUD1Txb6cfUwMvHzhvg=w6oUy+iRCqmv26WgQ+TAE6gzA@mail.gmail.com>

Hi Roslinazairimah,
You seem to be using the dotplot function from the lattice package. If so:

dotplot(cyl ~ mpg, data = mtcars, groups = cyl, cex=1.2,
 scales=list(y=list(labels=sort(unique(mtcars$cyl)))),
 main="Gas Milage for Car Models",  xlab="Miles Per Gallon")

Jim
On Wed, Sep 12, 2018 at 4:21 PM roslinazairimah zakaria
<roslinaump at gmail.com> wrote:
>
> Dear r-users,
>
> I want to draw dotplot for mtcars data according to cyl. There are three
> types of cylinder 4,6,8. However when we draw it does not use 4,6,8 instead
> label it as 1,2,3.
>
> I have this code and would like to customise the tick mark according to cyl
> groups:
>
>
> dotplot(cyl ~ mpg, data = mtcars, groups = cyl, cex=1.2,axes=FALSE,
>   main="Gas Milage for Car Models",  xlab="Miles Per Gallon")
> ticks = c(1,2,3)
> axis(2, at = ticks, labels=c(4,6,8))
>
> I got this message:
>
> axis(2, at = ticks, labels=c(4,6,8))
> Error in axis(2, at = ticks, labels = c(4, 6, 8)) :
>   plot.new has not been called yet
>
> Thank you so much for any help given.
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bog@@o@chri@tofer @ending from gm@il@com  Wed Sep 12 13:53:09 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Wed, 12 Sep 2018 17:23:09 +0530
Subject: [R] Obtaining exact pattern in list.files()
Message-ID: <CA+dpOJk=DBPfJ_SqT=K7feGOV8twPFAfw2dFVRHgt5hOHj1c9g@mail.gmail.com>

Hi,

In the list.files() function, there is an argument 'pattern' to locate the
desired files. However I failed to see if I can manage to fetch those files
that having an exact match.

For example, if there are 2 files that contain the expression 'File' and
'Second_File', then I should get the 1st one. However R is returning both
the files.

Any pointer on how to achieve that would be helpful. Thanks,

	[[alternative HTML version deleted]]


From i@t@z@hn @ending from gm@il@com  Wed Sep 12 15:07:44 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Wed, 12 Sep 2018 09:07:44 -0400
Subject: [R] Obtaining exact pattern in list.files()
In-Reply-To: <CA+dpOJk=DBPfJ_SqT=K7feGOV8twPFAfw2dFVRHgt5hOHj1c9g@mail.gmail.com>
References: <CA+dpOJk=DBPfJ_SqT=K7feGOV8twPFAfw2dFVRHgt5hOHj1c9g@mail.gmail.com>
Message-ID: <CA+vqiLGfS2Z6gpxEgfhSN_Pt6YYUEhMnrRedm0Zcei4m+t6tJQ@mail.gmail.com>

pattern = "^File$"

Best,
Ista
On Wed, Sep 12, 2018 at 7:53 AM Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
>
> Hi,
>
> In the list.files() function, there is an argument 'pattern' to locate the
> desired files. However I failed to see if I can manage to fetch those files
> that having an exact match.
>
> For example, if there are 2 files that contain the expression 'File' and
> 'Second_File', then I should get the 1st one. However R is returning both
> the files.
>
> Any pointer on how to achieve that would be helpful. Thanks,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Sep 12 15:20:53 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 12 Sep 2018 06:20:53 -0700
Subject: [R] Obtaining exact pattern in list.files()
In-Reply-To: <CA+dpOJk=DBPfJ_SqT=K7feGOV8twPFAfw2dFVRHgt5hOHj1c9g@mail.gmail.com>
References: <CA+dpOJk=DBPfJ_SqT=K7feGOV8twPFAfw2dFVRHgt5hOHj1c9g@mail.gmail.com>
Message-ID: <9D5CBBF2-D5CC-4073-B0E4-106C005221C0@dcn.davis.ca.us>

Study regular expressions via ?regex or any of the many websites you can find with a search engine. With no special characters, your search pattern matches anywhere in the string. Start your study by learning about the ^ and $ characters.

On September 12, 2018 4:53:09 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi,
>
>In the list.files() function, there is an argument 'pattern' to locate
>the
>desired files. However I failed to see if I can manage to fetch those
>files
>that having an exact match.
>
>For example, if there are 2 files that contain the expression 'File'
>and
>'Second_File', then I should get the 1st one. However R is returning
>both
>the files.
>
>Any pointer on how to achieve that would be helpful. Thanks,
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @bouelm@k@rim1962 @ending from gm@il@com  Wed Sep 12 18:09:16 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Wed, 12 Sep 2018 12:09:16 -0400
Subject: [R] Install R into mac
Message-ID: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>

Dear All:

One of my students has  mac software  OS X Yosemite, Version 10.10.5. He
could not install R into his mac laptop. I am not familiar with mac at all.
Any help will be appreciated.

with thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep 12 18:21:15 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 12 Sep 2018 09:21:15 -0700 (PDT)
Subject: [R] Save printed/plotted output to different directory
Message-ID: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>

   I run analyses in one directory and keep images and textual output in
other directories. My test involving a pdf output specifying an output
directory relative to the cwd produced a blank image. The command was like
this:
pdf('../images/filename.pdf')

   Will R accept an absolute path to an output directory or none at all?

TIA,

Rich


From bgunter@4567 @ending from gm@il@com  Wed Sep 12 18:25:11 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 12 Sep 2018 09:25:11 -0700
Subject: [R] Install R into mac
In-Reply-To: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>
References: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>
Message-ID: <CAGxFJbRoKoxOFfj_krrwV3Kgn=x752P=D2ccMburFX6zMHdN=A@mail.gmail.com>

You have given insufficient information for useful help. R installs
(from the Mac binary) without difficulty on my Mac.

Have your student post with sufficient details to the r-sig-mac list.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Sep 12, 2018 at 9:10 AM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear All:
>
> One of my students has  mac software  OS X Yosemite, Version 10.10.5. He
> could not install R into his mac laptop. I am not familiar with mac at all.
> Any help will be appreciated.
>
> with thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Wed Sep 12 18:26:41 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 12 Sep 2018 09:26:41 -0700
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>

Don't post. Try it and see.

-- Bert


On Wed, Sep 12, 2018 at 9:21 AM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
>    I run analyses in one directory and keep images and textual output in
> other directories. My test involving a pdf output specifying an output
> directory relative to the cwd produced a blank image. The command was like
> this:
> pdf('../images/filename.pdf')
>
>    Will R accept an absolute path to an output directory or none at all?
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep 12 18:38:35 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 12 Sep 2018 09:38:35 -0700 (PDT)
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
 <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809120937270.27645@salmo.appl-ecosys.com>

On Wed, 12 Sep 2018, Bert Gunter wrote:

> Don't post. Try it and see.

Bert,

   Tried using both $HOME and the full path without success and wondered if
there was a way to direct output to a different directory that hadn't
occurred to me.

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep 12 18:43:07 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 12 Sep 2018 09:43:07 -0700 (PDT)
Subject: [R] 
 Save printed/plotted output to different directory [ANSWERED]
In-Reply-To: <alpine.LNX.2.20.1809120937270.27645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
 <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
 <alpine.LNX.2.20.1809120937270.27645@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809120942250.27645@salmo.appl-ecosys.com>

On Wed, 12 Sep 2018, Rich Shepard wrote:

> Tried using both $HOME and the full path without success and wondered if
> there was a way to direct output to a different directory that hadn't
> occurred to me.

   Found the glitch. Now it works using relative paths.

Rich


From Bill@Poling @ending from zeli@@com  Wed Sep 12 19:10:18 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 12 Sep 2018 17:10:18 +0000
Subject: [R] Help with simple Map of US states to predefined regions
Message-ID: <SN6PR02MB508800BA681A2BE4FE6C59DCEA1B0@SN6PR02MB5088.namprd02.prod.outlook.com>

Hi I have this df with three columns ProviderState, ProviderStateCode, ProviderRegion

I have reviewed fiftystater pkg and map pkg but not sure how to simply take these three columns and plot a simple 5 color map based on the Region the state is in?

Do I need all the longitude and latitude data or can this be done with what I have?

https://cran.r-project.org/web/packages/fiftystater/vignettes/fiftystater.html
https://cran.r-project.org/web/packages/maps/maps.pdf


str(Map1)
Classes 'tbl_df', 'tbl' and 'data.frame':    54 obs. of  3 variables:
$ ProviderState    : chr  "ALASKA" "ALABAMA" "ARKANSAS" "ARIZONA" ...
$ ProviderStateCode: chr  "AK" "AL" "AR" "AZ" ...
$ ProviderRegion   : chr  "Pacific" "South" "South" "Pacific" ...
- attr(*, "spec")=List of 2
  ..$ cols   :List of 3
  .. ..$ ProviderState    : list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  .. ..$ ProviderStateCode: list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  .. ..$ ProviderRegion   : list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  ..$ default: list()
  .. ..- attr(*, "class")= chr  "collector_guess" "collector"
  ..- attr(*, "class")= chr "col_spec"

dput(Map1)
structure(list(ProviderState = c("ALASKA", "ALABAMA", "ARKANSAS",
"ARIZONA", "CALIFORNIA", "COLORADO", "CONNECTICUT", "DISTRICT OF COLUMBIA",
"DELAWARE", "FLORIDA", "GEORGIA", "GUAM", "HAWAII", "IOWA", "IDAHO",
"ILLINOIS", "INDIANA", "KANSAS", "KENTUCKY", "LOUISIANA", "MASSACHUSETTS",
"MARYLAND", "MAINE", "MICHIGAN", "MINNESOTA", "MISSOURI", "MISSISSIPPI",
"MONTANA", "NORTH CAROLINA", "NORTH DAKOTA", "NEBRASKA", "NEW HAMPSHIRE",
"NEW JERSEY", "NEW MEXICO", "NEVADA", "NEW YORK", "OHIO", "OKLAHOMA",
"OREGON", "PENNSYLVANIA", "PUERTO RICO", "RHODE ISLAND", "SOUTH CAROLINA",
"SOUTH DAKOTA", "TENNESSEE", "TEXAS", "UTAH", "VIRGINIA", "VIRGIN ISLANDS",
"VERMONT", "WASHINGTON", "WISCONSIN", "WEST VIRGINIA", "WYOMING"
), ProviderStateCode = c("AK", "AL", "AR", "AZ", "CA", "CO",
"CT", "DC", "DE", "FL", "GA", "GU", "HI", "IA", "ID", "IL", "IN",
"KS", "KY", "LA", "MA", "MD", "ME", "MI", "MN", "MO", "MS", "MT",
"NC", "ND", "NE", "NH", "NJ", "NM", "NV", "NY", "OH", "OK", "OR",
"PA", "PR", "RI", "SC", "SD", "TN", "TX", "UT", "VA", "VI", "VT",
"WA", "WI", "WV", "WY"), ProviderRegion = c("Pacific", "South",
"South", "Pacific", "Pacific", "Frontier", "Northeast", "Northeast",
"Northeast", "South", "South", "Pacific", "Pacific", "Midwest",
"Frontier", "Midwest", "Midwest", "Frontier", "South", "South",
"Northeast", "Northeast", "Northeast", "Midwest", "Midwest",
"Midwest", "South", "Frontier", "South", "Midwest", "Midwest",
"Northeast", "Northeast", "Frontier", "Pacific", "Northeast",
"Midwest", "Frontier", "Pacific", "Northeast", "Northeast", "Northeast",
"South", "Midwest", "South", "Frontier", "Frontier", "South",
"Northeast", "Northeast", "Pacific", "Midwest", "South", "Frontier"
)), row.names = c(NA, -54L), class = c("tbl_df", "tbl", "data.frame"
), spec = structure(list(cols = list(ProviderState = structure(list(), class = c("collector_character",
"collector")), ProviderStateCode = structure(list(), class = c("collector_character",
"collector")), ProviderRegion = structure(list(), class = c("collector_character",
"collector"))), default = structure(list(), class = c("collector_guess",
"collector"))), class = "col_spec"))

Thank you for any suggestions.

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From bgunter@4567 @ending from gm@il@com  Wed Sep 12 19:10:32 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 12 Sep 2018 10:10:32 -0700
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <alpine.LNX.2.20.1809120937270.27645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
 <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
 <alpine.LNX.2.20.1809120937270.27645@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbR0-HgTTeorqX6QS9y2jdgkfAo2L+H7Y-Rkf1Ldn5D8hQ@mail.gmail.com>

Insufficient info to diagnose. No code for what you did.

-- Bert


On Wed, Sep 12, 2018 at 9:43 AM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Wed, 12 Sep 2018, Bert Gunter wrote:
>
> > Don't post. Try it and see.
>
> Bert,
>
>    Tried using both $HOME and the full path without success and wondered if
> there was a way to direct output to a different directory that hadn't
> occurred to me.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Sep 12 21:33:34 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 12 Sep 2018 12:33:34 -0700
Subject: [R] Install R into mac
In-Reply-To: <CAGxFJbRoKoxOFfj_krrwV3Kgn=x752P=D2ccMburFX6zMHdN=A@mail.gmail.com>
References: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>
 <CAGxFJbRoKoxOFfj_krrwV3Kgn=x752P=D2ccMburFX6zMHdN=A@mail.gmail.com>
Message-ID: <6DE6E333-95E9-437B-9E38-00FB3C5D6DD8@dcn.davis.ca.us>

Also read the CRAN download web page which says 10.10.5 is too old for current supported versions of R. Could try an archived version or, better yet, upgrade the OS.

On September 12, 2018 9:25:11 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>You have given insufficient information for useful help. R installs
>(from the Mac binary) without difficulty on my Mac.
>
>Have your student post with sufficient details to the r-sig-mac list.
>
>-- Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Wed, Sep 12, 2018 at 9:10 AM AbouEl-Makarim Aboueissa
><abouelmakarim1962 at gmail.com> wrote:
>>
>> Dear All:
>>
>> One of my students has  mac software  OS X Yosemite, Version 10.10.5.
>He
>> could not install R into his mac laptop. I am not familiar with mac
>at all.
>> Any help will be appreciated.
>>
>> with thanks
>> abou
>> ______________________
>>
>>
>> *AbouEl-Makarim Aboueissa, PhD*
>>
>> *Professor of Statistics*
>> *Graduate Coordinator*
>>
>> *Department of Mathematics and Statistics*
>> *University of Southern Maine*
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Sep 12 21:43:11 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 12 Sep 2018 12:43:11 -0700
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
 <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
Message-ID: <1D816046-DC82-48A0-BA0D-C95BF464F352@dcn.davis.ca.us>

Yes. I do it all the time.

On September 12, 2018 9:26:41 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Don't post. Try it and see.
>
>-- Bert
>
>
>On Wed, Sep 12, 2018 at 9:21 AM Rich Shepard <rshepard at appl-ecosys.com>
>wrote:
>>
>>    I run analyses in one directory and keep images and textual output
>in
>> other directories. My test involving a pdf output specifying an
>output
>> directory relative to the cwd produced a blank image. The command was
>like
>> this:
>> pdf('../images/filename.pdf')
>>
>>    Will R accept an absolute path to an output directory or none at
>all?
>>
>> TIA,
>>
>> Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ncecchino @ending from gm@il@com  Wed Sep 12 21:43:22 2018
From: ncecchino @ending from gm@il@com (Nicola Cecchino)
Date: Wed, 12 Sep 2018 15:43:22 -0400
Subject: [R] Correcting dates in research records using R - 2 attempt
Message-ID: <CAO4oC1n=pa+jKpFpHHEiB29c6iYL=yxxS+wjE9y8bLgaaD5u+g@mail.gmail.com>

Hi,

I apologize - sent the first time around accidentally as HTML and not
text.  Thanks to the responder for pointing this out and providing
some feed back too.

I'm not that well versed with R - I'm trying to correct the dates of
service in a de-identified research medical record of several
subjects.  The correct dates come from a csv file, in the VisitDate
column,  that looks like this in Excel.  The empty cells have other
data in them that I don't need and the  file name is DateR.csv:


Id1       Id2                         VisitDate
12345 12345                       4/3/2018


The research medical record is a text file and the "DATE OF SERVICE"
in the top matter is in error in all of the subjects and needs to be
replaced with the "VisitDate" in the csv file.  The file name for the
medical records is test3.NEW.  Here is a screen grab of the top matter
of the research medical record; below this data excerpt is other
gathered data for that subject:


================================================================================

PATIENT NAME: CONFIDENTIAL,#12345
PATIENT ID #: 12345
DATE OF SERVICE: 04/10/2018
ACCESSION NUMBER: RR1234567

TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS       NORMAL VALUES


As described above, I need to update the text file DATE OF SERVICE:
date with the VisitDate in the csv file.

I made several attempts at this to failure and so now I turn to you.
Here is the code that exhibits my attempts:


clinicVdate <- read.csv("DateR.csv")

rownames(clinicVdate) <- as.character(clinicVdate[,'Id2'])

Id2 <- NA

input_data <- readLines("D:/test/test3.NEW")
output_data <- c()

for(input_line in input_data){
  output_line = input_line
  if(length(grep('PATIENT ID #:', input_line))>0)  {
    Id2 = as.character(strsplit(input_line, ':')[[1]][2])
  }

  if (length(grep( 'DATE OF SERVICE: ', input_line))){

    output_line = paste('DATE OF SERVICE', clinicVdate[Id2,
'VisitDate'], sep=':')

  }
  output_data = paste(output_data, output_line, sep='\n')
}

cat(output_data)


The results of the above remove the erroneous date and replace it with
NA.  Here is an example of the results:


================================================================================

PATIENT NAME: CONFIDENTIAL,#12345
PATIENT ID #: 12345
DATE OF SERVICE: NA
ACCESSION NUMBER: RR1234567

TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS       NORMAL VALUES


Where am I going wrong?  If I didn't pose my question appropriately,
please let me know too!!  Any help with this would be greatly
appreciated!!

Kind regards,

Nic Cecchino


From v@lkremk @ending from gm@il@com  Wed Sep 12 22:38:40 2018
From: v@lkremk @ending from gm@il@com (Val)
Date: Wed, 12 Sep 2018 15:38:40 -0500
Subject: [R] select and hold missing
Message-ID: <CAJOiR6YZGiEZvpbjgfJQuDg+Z1urq7gkwc5iEHN3GAo=JcmS5w@mail.gmail.com>

I have a data
dfc <- read.table( text= 'week v1 v2
  w1  11  11
  w1  .    42
  w1  31  32
  w2  31  52
  w2  41  .
  w3  51  82
  w2  11  22
  w3  11  12
  w4  21  202
  w1  31  72
  w2  71  52', header = TRUE, as.is = TRUE, na.strings=c("",".","NA") )

I want to create this new variable diff = v2-v1  and remove rows based
on this "diff" value as shown below.
dfc$diff <-  dfc$v2 - dfc$v1
I want to   remove row values  <=0  and any value greater than  >=
100   and keep all values including NAs
dfca      <- dfc[((dfc$diff) > 0) & ((dfc$diff) < 100), ]

 However, the result is not what I wanted. I want the output as follow,
  week v1 v2 diff
  w1 NA  42  NA
  w1 31 32    1
  w2 31 52   21
  w2 41  NA  NA
  w3 51 82   31
  w2 11 22   11
  w3 11 12    1
  w1 31 72   41

However, I got this,l. Why it is setting all row values  NA?
   week v1 v2 diff
  <NA> NA NA   NA
  w1 31 32    1
 w2 31 52   21
 <NA> NA NA   NA
  w3 51 82   31
  w2 11 22   11
  w3 11 12    1
  w1 31 72   41

Any help ?
Thank you.


From bgunter@4567 @ending from gm@il@com  Wed Sep 12 23:04:52 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 12 Sep 2018 14:04:52 -0700
Subject: [R] select and hold missing
In-Reply-To: <CAJOiR6YZGiEZvpbjgfJQuDg+Z1urq7gkwc5iEHN3GAo=JcmS5w@mail.gmail.com>
References: <CAJOiR6YZGiEZvpbjgfJQuDg+Z1urq7gkwc5iEHN3GAo=JcmS5w@mail.gmail.com>
Message-ID: <CAGxFJbTL1iQAtg6jRPRPGjxud3wBhpLdZbjALoXHiBf_U2U-_w@mail.gmail.com>

"Why it is setting all row values  NA?"

Because the row index is NA. e.g.

> z <- data.frame(a=letters[1:3],b = 1:3); x <- c(TRUE,NA,FALSE)
> z[x,]
      a  b
1     a  1
NA <NA> NA

Change your logical comparison to (using with() to simplify entry):

> dfc[with(dfc, diff > 0 & diff < 100 | is.na(diff)), ]
   week v1 v2 diff
2    w1 NA 42   NA
3    w1 31 32    1
4    w2 31 52   21
5    w2 41 NA   NA
6    w3 51 82   31
7    w2 11 22   11
8    w3 11 12    1
10   w1 31 72   41

Cheers,
Bert


On Wed, Sep 12, 2018 at 1:39 PM Val <valkremk at gmail.com> wrote:
>
> I have a data
> dfc <- read.table( text= 'week v1 v2
>   w1  11  11
>   w1  .    42
>   w1  31  32
>   w2  31  52
>   w2  41  .
>   w3  51  82
>   w2  11  22
>   w3  11  12
>   w4  21  202
>   w1  31  72
>   w2  71  52', header = TRUE, as.is = TRUE, na.strings=c("",".","NA") )
>
> I want to create this new variable diff = v2-v1  and remove rows based
> on this "diff" value as shown below.
> dfc$diff <-  dfc$v2 - dfc$v1
> I want to   remove row values  <=0  and any value greater than  >=
> 100   and keep all values including NAs
> dfca      <- dfc[((dfc$diff) > 0) & ((dfc$diff) < 100), ]
>
>  However, the result is not what I wanted. I want the output as follow,
>   week v1 v2 diff
>   w1 NA  42  NA
>   w1 31 32    1
>   w2 31 52   21
>   w2 41  NA  NA
>   w3 51 82   31
>   w2 11 22   11
>   w3 11 12    1
>   w1 31 72   41
>
> However, I got this,l. Why it is setting all row values  NA?
>    week v1 v2 diff
>   <NA> NA NA   NA
>   w1 31 32    1
>  w2 31 52   21
>  <NA> NA NA   NA
>   w3 51 82   31
>   w2 11 22   11
>   w3 11 12    1
>   w1 31 72   41
>
> Any help ?
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giu@epp@cef@lu @ending from gm@il@com  Wed Sep 12 23:06:44 2018
From: giu@epp@cef@lu @ending from gm@il@com (Giuseppa Cefalu)
Date: Wed, 12 Sep 2018 17:06:44 -0400
Subject: [R] How to insert a name from a list into a double loop
Message-ID: <CACGY-iReet=3eKPZWM-sGvmxqmok=tR5O=97ow8tLkGAT7xr3g@mail.gmail.com>

Hello,

The script below works well when I define the elementname <- list("name1",
"name2", "name3") .  Please see program below.
SCRIPT
```
glyCount1 <- function(answer = NULL, fileChoice = NULL, combination = NULL,
enteredValue = NULL, nameList) {

lc <- enteredValue
choseDataFiles = TRUE

first_path <- NULL
new_path <- NULL

new_dataFns <- list()

new_dataFns <- as.list(unlist(strsplit(as.character(nameList), ",")))

file_content <- NULL

elementname <- list("name1", "name2", "name3")

  for(i in 1:length(lc)){
     for(j in 1:length(lc[[i]])){
       first_path[j]<- paste(getwd(), "/", lc[[i]][j], sep = "")
       print(first_path[j])
      #  file_content[[j]] <- read.csv(file = first_path[[i]], header =
TRUE, sep = ",")
       for(k in 1:length(elementname)){
         if(k == i){
           new_path[j] <- paste(getwd(),"/", i, elementname[k], ".csv", sep
= "")
           print (new_path[j])
        }
      }
     }
  }
}

```
SCRIPT OUTPUT:

[1] "/home/giuseppa/Development/glycoPipeApp/1name1.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/1name1.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/1name1.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/1name1.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/2name2.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/2name2.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/2name2.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/3name3.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/3name3.csv"


However, If instead of using the list "elementname" I call the script
through an app and I enter the list of names through a textbox, which then
is passed to the glycoPipe1 function.  Please see below.  The same script
does not return the expected output.

'new_dataFns <- list()
new_dataFns <- as.list(unlist(strsplit(as.character(nameList), ","))) is
used in the script when the value passed to the function by the app's
textinput (nameList) is used, in which case I would substitute the
elementname list buythe new_dataFns list, please see block code below.

BLOCK OF CODE
```
  for(i in 1:length(lc)){
     for(j in 1:length(lc[[i]])){
       first_path[j]<- paste(getwd(), "/", lc[[i]][j], sep = "")
       print(first_path[j])
      #  file_content[[j]] <- read.csv(file = first_path[[i]], header =
TRUE, sep = ",")
       for(k in 1:length(elementname)){
         if(k == i){
           new_path[j] <- paste(getwd(),"/", i, elementname[k], ".csv", sep
= "")
           print (new_path[j])
        }
      }
         }
```

I am sending the app below just in case you need it.  but I wonder if it
has to do with the list:
new_dataFns <- as.list(unlist(strsplit(as.character(nameList), ","))) .  It
seams that elementname a new_dataFns do not work in the same way in the
script.

Am I am building the new_dataFns list incorrectly?.  It seems as if the
values could not be accessed.

Thank you for your help


APP PROGRAM
```
library(shiny)
library(shinyjs)

ui <- fluidPage(
  selectInput("combinefiles", label = h5(strong("Do you wish to combine any
data files, and compare the combined data sets? (Y/N) ")),
              choices = c("", "Y", "N"),selected = NULL),
  verbatimTextOutput("combiningFiles"),
  verbatimTextOutput("combineChosen"),
  #verbatimTextOutput("filesToCombine"),
  useShinyjs(),
  conditionalPanel(
    condition = "output.toCombine > '0'",
    selectInput(inputId = "select",label = h5(strong("Please select from
the list")), choices = c(Chose = "",
list.files("~/Development/glycoPipeApp")), multiple = TRUE, selectize =
TRUE)
  ),
  conditionalPanel(
    condition = "output.displayAddButton > '0'",
    actionButton('add','Add')
  ),
  verbatimTextOutput("samelist"),
  conditionalPanel(
    condition = "output.displayAddButton == 1",
    actionButton("sBtn", "Press the save button to end")
  ),

  conditionalPanel(
    condition = "output.displayTheSaveButton  > '0'",
    textInput("textbox", h5(strong("Please enter name/s to designate
combined set/s separated by comma")))),
  strong(verbatimTextOutput("list")),
  verbatimTextOutput("caption")


)

#selections = NULL,

glycoPipe <- function(response = NULL, fOfData = NULL, combineResult =
NULL, listContents = NULL, vals = NULL){

enteredValue = NULL
nameList = NULL
answer = NULL
fileChoice = NULL
combination = NULL
combinations = NULL
comb = NULL
nameListSize = NULL
choseDataFiles = NULL

if(!is.null(response)){
  answer = response
}
if(!is.null(fOfData)){
  fileChoice = fOfData
}

if(!is.null(combineResult)){
  combination = combineResult
}

if(!is.null(listContents)){
  enteredValue = listContents
}

if(!is.null(vals)){
  nameList <- vals
}

glyCount1(answer, fileChoice, combination, enteredValue, nameList)

}

  server <- function(input, output, session){
    listContents = NULL

    source("Utilities/utilities.R")
    source("glycoPipeFunctions/glycoPipe_fcns.R")
    source("glyCount1.R")

    output$toCombine <- reactive({
      req(input$combinefiles)
      return(length(input$combinefiles))
    })

    outputOptions(output, "toCombine", suspendWhenHidden = FALSE)

        output$displayAddButton <- reactive({
        req(input$combinefiles)
        return(length(input$combinefiles))
     })

    outputOptions(output, "displayAddButton", suspendWhenHidden = FALSE)

    output$displayTheSaveButton <- reactive({
       req(input$sBtn)
       return(input$sBtn)
     })

    outputOptions(output, "displayTheSaveButton", suspendWhenHidden = FALSE)

      myValues <- reactiveValues()
      observe({
      if(input$add > 0){
         myValues$dList <- c(isolate(myValues$dList),
isolate(list(input$select)))
       }
    })

    # #unlist(input$filescombine)
    output$samelist<-renderPrint({
       #listContents  <- list()

       listContents <- append(listContents, myValues$dList)
       print(listContents)
      if(input$sBtn > 0){
        numberOfSelectedSets <- glycoPipe(response = NULL, fOfData = NULL,
combineResult = NULL , listContents)
        paste("Please enter", numberOfSelectedSets$nameListSize, "names to
designate your", numberOfSelectedSets$nameListSize, "sets")
       }
     })

    VALUES <- list()
     observe({
       isolate({
         req(input$textbox)
         VALUES <- input$textbox
         VALUES <- append(VALUES, list(input$textbox))
         updateTextInput(session, inputId = "textbox", value = VALUES)

      })
     })

     output$caption <- renderPrint({
       vals <- list()
       vals <- append(vals, input$textbox)
       if(input$sBtn > 0){
         result <- glycoPipe(response = NULL, fOfData = NULL, combineResult
= NULL, listContents = NULL, vals)
         #unlist(input$filescombine)
      }
     })

    session$allowReconnect(TRUE)

  }
  shinyApp(ui = ui, server = server)
```

	[[alternative HTML version deleted]]


From ch@rlie @ending from @t@t@umn@edu  Wed Sep 12 23:14:16 2018
From: ch@rlie @ending from @t@t@umn@edu (Charles Geyer)
Date: Wed, 12 Sep 2018 16:14:16 -0500
Subject: [R] YAML for bookdown
Message-ID: <CAKctRd1azRoDE3T+CERNA-Ys=FBRSZhvxKeTEM5QLiMAa-2=QQ@mail.gmail.com>

Does anyone know where I can look up all the possible things that can be
set in the YAML for bookdown?  Is this documented anywhere?  The bookdown
book (https://bookdown.org/yihui/bookdown/) just provides a few example
things.  Is the only thing to do RTFS?  Really customizing this seems hard.

-- 
Charles Geyer
Professor, School of Statistics
Resident Fellow, Minnesota Center for Philosophy of Science
University of Minnesota
charlie at stat.umn.edu

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Wed Sep 12 23:27:42 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 12 Sep 2018 17:27:42 -0400
Subject: [R] YAML for bookdown
In-Reply-To: <CAKctRd1azRoDE3T+CERNA-Ys=FBRSZhvxKeTEM5QLiMAa-2=QQ@mail.gmail.com>
References: <CAKctRd1azRoDE3T+CERNA-Ys=FBRSZhvxKeTEM5QLiMAa-2=QQ@mail.gmail.com>
Message-ID: <a78448a5-fcdd-904d-b370-211729af404b@gmail.com>

On 12/09/2018 5:14 PM, Charles Geyer wrote:
> Does anyone know where I can look up all the possible things that can be
> set in the YAML for bookdown?  Is this documented anywhere?  The bookdown
> book (https://bookdown.org/yihui/bookdown/) just provides a few example
> things.  Is the only thing to do RTFS?  Really customizing this seems hard.

I think there is nothing special about bookdown except for options 
contained in the output declaration.  (I.e. other top level YAML is the 
same as for any other RMarkdown output.)

The possible entries within "output: bookdown::gitbook" are exactly the 
arguments to the bookdown::gitbook function.  It passes ... to 
rmarkdown::html_document, so those arguments are available too.

If you're using a different bookdown output format, the allowed entries 
will be the arguments to whatever function you use.

Duncan Murdoch


From jhunter @ending from idevelopment@info  Wed Sep 12 18:13:58 2018
From: jhunter @ending from idevelopment@info (Jeffrey Hunter)
Date: Wed, 12 Sep 2018 12:13:58 -0400
Subject: [R] Install R into mac
In-Reply-To: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>
References: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>
Message-ID: <D6F21D69-AE9E-4754-91D4-BDA3FAB91EBE@idevelopment.info>

Hi,

What type of issues is your student running into?

Please review the following video install.

https://medium.com/@GalarnykMichael/install-r-and-rstudio-on-mac-e911606ce4f4 <https://medium.com/@GalarnykMichael/install-r-and-rstudio-on-mac-e911606ce4f4>

Thanks,
Jeff

Jeffrey M. Hunter
Senior DBA, Mathematical Programmer, Author
jhunter at idevelopment.info
www.idevelopment.info

A computer without a Microsoft operating system is like a dog without bricks tied to its head.

God rot Windows and all its ugly, clunky, badly-designed horror.
Stephen Fry


> On Sep 12, 2018, at 12:09 PM, AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com> wrote:
> 
> Dear All:
> 
> One of my students has  mac software  OS X Yosemite, Version 10.10.5. He
> could not install R into his mac laptop. I am not familiar with mac at all.
> Any help will be appreciated.
> 
> with thanks
> abou
> ______________________
> 
> 
> *AbouEl-Makarim Aboueissa, PhD*
> 
> *Professor of Statistics*
> *Graduate Coordinator*
> 
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Thu Sep 13 02:29:37 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 13 Sep 2018 10:29:37 +1000
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
Message-ID: <CA+8X3fWKBSt4WVjcmXi++0pJJA7rTpdhW6tPxNJqQN5r_uZKNA@mail.gmail.com>

Hi Rich,
Sometimes an empty image is due to not closing the image file. If you
forgot to put:

dev.off()

after the plotting commands, or there was an error in the plotting
commands, the file may be left open. Try manually entering "dev.off()"
after you have run the code. If you don't get an error:

Error in dev.off() : cannot shut down device 1 (the null device)

it means that you had an open device.

Jim

On Thu, Sep 13, 2018 at 2:21 AM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
>    I run analyses in one directory and keep images and textual output in
> other directories. My test involving a pdf output specifying an output
> directory relative to the cwd produced a blank image. The command was like
> this:
> pdf('../images/filename.pdf')
>
>    Will R accept an absolute path to an output directory or none at all?
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Sep 13 03:33:15 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 12 Sep 2018 18:33:15 -0700 (PDT)
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <CA+8X3fWKBSt4WVjcmXi++0pJJA7rTpdhW6tPxNJqQN5r_uZKNA@mail.gmail.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
 <CA+8X3fWKBSt4WVjcmXi++0pJJA7rTpdhW6tPxNJqQN5r_uZKNA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809121829550.6031@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Jim Lemon wrote:

> Sometimes an empty image is due to not closing the image file. If you
> forgot to put:
>
> dev.off()
>
> after the plotting commands, or there was an error in the plotting
> commands, the file may be left open. Try manually entering "dev.off()"
> after you have run the code. If you don't get an error:

Jim,

   I thought of this and entered dev.off() a couple of times, to no avail.
Then I quit R and restarted it. That cleared the problem.

   A typo slipped in the script elsewhere when I modified the path for the
output PDF file. That probably jammed the device. Fixing the typo did not
address the constipation it caused, but killing the process and starting it
again did the job.

   Thanks for the information!

Best regards,

Rich


From ro@lin@ump @ending from gm@il@com  Thu Sep 13 09:00:39 2018
From: ro@lin@ump @ending from gm@il@com (roslinazairimah zakaria)
Date: Thu, 13 Sep 2018 15:00:39 +0800
Subject: [R] customise tick marks
In-Reply-To: <CA+8X3fUD1Txb6cfUwMvHzhvg=w6oUy+iRCqmv26WgQ+TAE6gzA@mail.gmail.com>
References: <CANTvJZLMtZWX3BwUgagTMdxj0-gsz1z8SDP95-JLmM9Bvyp5Kg@mail.gmail.com>
 <CA+8X3fUD1Txb6cfUwMvHzhvg=w6oUy+iRCqmv26WgQ+TAE6gzA@mail.gmail.com>
Message-ID: <CANTvJZLXjg_ti8DA1YNuSBcg3tmPbOe2DZCG14BA1cx4sZZdZQ@mail.gmail.com>

Hi Jim,
It works beautifully.

Thank you very much for your help.


On Wed, Sep 12, 2018 at 5:58 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Roslinazairimah,
> You seem to be using the dotplot function from the lattice package. If so:
>
> dotplot(cyl ~ mpg, data = mtcars, groups = cyl, cex=1.2,
>  scales=list(y=list(labels=sort(unique(mtcars$cyl)))),
>  main="Gas Milage for Car Models",  xlab="Miles Per Gallon")
>
> Jim
> On Wed, Sep 12, 2018 at 4:21 PM roslinazairimah zakaria
> <roslinaump at gmail.com> wrote:
> >
> > Dear r-users,
> >
> > I want to draw dotplot for mtcars data according to cyl. There are three
> > types of cylinder 4,6,8. However when we draw it does not use 4,6,8
> instead
> > label it as 1,2,3.
> >
> > I have this code and would like to customise the tick mark according to
> cyl
> > groups:
> >
> >
> > dotplot(cyl ~ mpg, data = mtcars, groups = cyl, cex=1.2,axes=FALSE,
> >   main="Gas Milage for Car Models",  xlab="Miles Per Gallon")
> > ticks = c(1,2,3)
> > axis(2, at = ticks, labels=c(4,6,8))
> >
> > I got this message:
> >
> > axis(2, at = ticks, labels=c(4,6,8))
> > Error in axis(2, at = ticks, labels = c(4, 6, 8)) :
> >   plot.new has not been called yet
> >
> > Thank you so much for any help given.
> > --
> > *Roslinazairimah Zakaria*
> > *Tel: +609-5492370; Fax. No.+609-5492766*
> >
> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> > roslinaump at gmail.com <roslinaump at gmail.com>*
> > Faculty of Industrial Sciences & Technology
> > University Malaysia Pahang
> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Thu Sep 13 09:53:48 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 13 Sep 2018 07:53:48 +0000
Subject: [R] Correcting dates in research / medical record using R
In-Reply-To: <415bccb8-71df-aff5-2d22-887a3f743629@gmail.com>
References: <e8b5a2bf-4403-2353-1d50-27665c60b7a7@gmail.com>
 <cfc5e11caf914d18aad819587de342d6@SRVEXCHCM1302.precheza.cz>
 <415bccb8-71df-aff5-2d22-887a3f743629@gmail.com>
Message-ID: <e2d74478a32e447a91a3dbe84c986e1b@SRVEXCHCM1302.precheza.cz>

Hi

You should send your responses to R helplist, others could offer better/different solutions.

I myself am not an expert for regex so if all your files are formated in the same way I would use strsplit.

# I read header to test object
test<-readLines("clipboard")
str(test)
 chr [1:4] "PATIENT NAME: CONFIDENTIAL,#12345" "PATIENT ID #: 12345" ...

# here is something similar to your csv file
test2<-read.table("clipboard")
test2
    Id1   Id2 VisitDate
1 12345 12345  4/3/2018
2 11111 11111  5/4/2018

# here I split second line of patient record, select 4th item and compare with Id2 value from csv file.

sel<-which(test2$Id2 == as.numeric(unlist(strsplit(test[2], " "))[4]))

# I take third line of patient record and split it
out<-unlist(strsplit(test[3], split=" "))

# and change 4th item with selected value from csv VisitDate
out[4] <- as.character(test2$VisitDate[sel])

# here you should be aware of difference between factors and characters
# and finally make collapsed line, which could be used to change third line in patient record
paste(out, collapse=" ")
[1] "DATE OF SERVICE: 4/3/2018"

But what you want to do with it? It actually manipulates objects in your R session and not original files. I believe that there are other tools more suitable for such tasks.

Cheers
Petr

> -----Original Message-----
> From: Nicola Cecchino <ncecchino at gmail.com>
> Sent: Thursday, September 13, 2018 5:04 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Subject: Re: [R] Correcting dates in research / medical record using R
>
> Hi Petr,
>
> Thank you for your help but I'm not sure what that code is supposed to do?  I'm
> really new to regular expressions and am having difficulties with this whole
> thing.
>
> Nic
>
>
>
>
> On 9/12/2018 2:26 AM, PIKAL Petr wrote:
> > Hi
> >
> > First of all you should not use HTML formated posts, it is big chance that it
> gets scrambled.
> >
> > You should compare your ld2 after for cycle and result of
> >
> > clinicVdate[Id2, 'VisitDate'], sep=':')
> >
> > Most probably ld2 after for cycle does not conform to row names of
> clinicVdate.
> >
> > Cheers
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Nicola
> >> Cecchino
> >> Sent: Wednesday, September 12, 2018 3:50 AM
> >> To: R-help at r-project.org
> >> Subject: [R] Correcting dates in research / medical record using R
> >>
> >> Hi,
> >>
> >> I'm not that well versed with R - I'm trying to correct the dates of
> >> service in a de-identified research medical record of several subjects.
> >> The correct dates come from a csv file, in the VisitDate column,
> >> that looks like this in Excel.  The empty cells have other data in
> >> them that I don't need and the  file name is DateR.csv:
> >>
> >>
> >> Id1 Id2
> >>
> >>
> >>
> >>
> >> VisitDate
> >> 12345 12345
> >>
> >>
> >>
> >>
> >> 4/3/2018
> >>
> >>
> >> The research medical record is a text file and the "DATE OF SERVICE"
> >> in the top matter is in error in all of the subjects and needs to be
> >> replaced with the "VisitDate" in the csv file.  The file name for the
> >> medical records is test3.NEW.  Here is a screen grab of the top
> >> matter of the research medical record; below this data excerpt is
> >> other gathered data for that subject:
> >>
> >>
> >>
> ===================================================================
> >> =============
> >>
> >> PATIENT NAME: CONFIDENTIAL,#12345
> >> PATIENT ID #: 12345
> >> DATE OF SERVICE: 04/10/2018
> >> ACCESSION NUMBER: RR1234567
> >>
> >> TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS NORMAL VALUES
> >>
> >>
> >> As described above, I need to update the text file DATE OF SERVICE:
> >> date with the VisitDate in the csv file.
> >>
> >> I made several attempts at this to failure and so now I turn to you.
> >> Here is the code that exhibits my attempts:
> >>
> >>
> >> clinicVdate <- read.csv("DateR.csv")
> >>
> >> rownames(clinicVdate) <- as.character(clinicVdate[,'Id2'])
> >>
> >> Id2 <- NA
> >>
> >> input_data <- readLines("D:/test/test3.NEW") output_data <- c()
> >>
> >> for(input_line in input_data){
> >>     output_line = input_line
> >>     if(length(grep('PATIENT ID #:', input_line))>0)  {
> >>       Id2 = as.character(strsplit(input_line, ':')[[1]][2])
> >>     }
> >>
> >>     if (length(grep( 'DATE OF SERVICE: ', input_line))){
> >>
> >>       output_line = paste('DATE OF SERVICE', clinicVdate[Id2,
> >> 'VisitDate'], sep=':')
> >>
> >>     }
> >>     output_data = paste(output_data, output_line, sep='\n') }
> >>
> >> cat(output_data)
> >>
> >>
> >> The results of the above remove the erroneous date and replace it
> >> with NA.  Here is an example of the results:
> >>
> >>
> >>
> ===================================================================
> >> =============
> >>
> >> PATIENT NAME: CONFIDENTIAL,#12345
> >> PATIENT ID #: 12345
> >> DATE OF SERVICE: NA
> >> ACCESSION NUMBER: RR1234567
> >>
> >> TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS NORMAL VALUES
> >>
> >>
> >> Where am I going wrong?  If I didn't pose my question appropriately,
> >> please let me know too!!  Any help with this would be greatly appreciated!!
> >>
> >> Kind regards,
> >>
> >> Nic Cecchino
> >>
> >>
> >>
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> > obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> > about processing and protection of business partner?s personal data
> > are available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the
> > legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From Bill@Poling @ending from zeli@@com  Thu Sep 13 14:14:33 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 13 Sep 2018 12:14:33 +0000
Subject: [R] Help with simple Map of US states with predefined regions
 Version 2
Message-ID: <SN6PR02MB5088847E2A3E48B54FAB2C82EA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>

Hi,

I hope someone can help me finalize this please.

I am coming close to what I need using variations from two ggplot2 tutorials.

This first gives me the map of the US with AK & HI but I cannot figure out how to get my 5 regions colored

#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1


library(ggplot2)
install.packages("ggalt")
library(ggalt)     # coord_proj
library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
install.packages("ggthemes")
library(ggthemes)  # theme_map
install.packages("rgeos")
library(rgeos)     # centroids
library(dplyr)

# composite map with AK & HI
usa_map <- usa_composite()

# calculate the centroids for each state
gCentroid(usa_map, byid=TRUE) %>%
  as.data.frame() %>%
  mutate(state=usa_map at data$iso_3166_2) -> centroids

# make it usable in ggplot2
usa_map <- fortify(usa_map)

View(usa_map)
t1 <- head(usa_map,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))

#

  # |long      |lat      | group| order|  region|subregion |
  # |:---------|:--------|-----:|-----:|-------:|:---------|
  # |-87.46201 |30.38968 |     1|     1| alabama|NA        |
  # |-87.48493 |30.37249 |     1|     2| alabama|NA        |
  # |-87.52503 |30.37249 |     1|     3| alabama|NA        |
  # |-87.53076 |30.33239 |     1|     4| alabama|NA        |
  # |-87.57087 |30.32665 |     1|     5| alabama|NA        |

usa_map <- fortify(usa_map)
gg <- ggplot()
gg <- gg + geom_map(data=usa_map, map=usa_map,
                    aes(long, lat, map_id=id),
                    color="#2b2b2b", size=0.1, fill=NA)

gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
gg <- gg + coord_proj(us_laea_proj)
gg <- gg + theme_map()
gg




#************************************************************************************************************************************************************************************/

This second is an alternative (however not liking AK&HI, not coming into the map like scenario one above) but also ignoring new Mexico (because recognizing a seventh field value) and I suspect it will do the same for new York and new jersey etc.. when I add them to the list.

Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :  line 12 did not have 6 elements

When I use newmexico (all one word) it appears white in the map like the other states not in the table statement

#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors

library(ggplot2)

read.table(text="State.Code   region            St_Abbr   Num_Estab  colors
                      1          1   alaska       Ak        13123    #f7931e
                      3          1   arizona      AZ        18053    #f7931e
                      5          1   california   CA       143937    #f7931e
                      2          1   hawaii       HI       123456    #f7931e
                      4          1   nevada       NV       654321    #f7931e
                      6          1   oregon       OR       321456    #f7931e
                      7          1   washington   WA       456123    #f7931e
                      8          2   colorado     CO       987654    #787878
                      9          2   idaho        ID       13549     #787878
                     10          2   kansas       KS       94531     #787878
                     11          2   montana      MT       456321    #787878
                     12          2   new mexico   NM     582310            #787878 <---Not liking new mexico, saying not 6
                     13          2   oklahoma     OK       214567    #787878
                     14          2   texas        TX       675421    #787878
                     15          2   utah         UT       754321    #787878
                     16          2   wyoming      WY       543124    #787878 ",
stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df

usa_map1 <- map_data("state")
t1 <- head(usa_map1,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
View(usa_map1)
#
#   |long      |lat      | group| order|  region|subregion |
#   |:---------|:--------|-----:|-----:|-------:|:---------|
#   |-87.46201 |30.38968 |     1|     1| alabama|NA        |
#   |-87.48493 |30.37249 |     1|     2| alabama|NA        |
#   |-87.52503 |30.37249 |     1|     3| alabama|NA        |
#   |-87.53076 |30.33239 |     1|     4| alabama|NA        |
#   |-87.57087 |30.32665 |     1|     5| alabama|NA        |



gg <- ggplot()
#View(gg)
gg <- gg + geom_map(data=usa_map1, map=usa_map1,
                    aes(long, lat, map_id=region),
                    color="#2b2b2b", size=0.15, fill=NA)

gg <- gg + geom_map(data=df, map=usa_map1,
                    aes(fill=colors, map_id=region),
                    color="#2b2b2b", size=0.15)


gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
gg <- gg + coord_proj(us_laea_proj)
gg <- gg + theme_map()
gg


gg <- gg + scale_color_identity()
gg <- gg + coord_map("polyconic")
gg <- gg + ggthemes::theme_map()
gg

#c( "colorado", "idaho", "kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") )
#c("alaska", "arizona", "california", "hawaii", "nevada", "oregon","washington"))



William H. Poling, Ph.D., MPH




Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Sep 13 16:28:59 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 13 Sep 2018 07:28:59 -0700
Subject: [R] Help with simple Map of US states with predefined regions
 Version 2
In-Reply-To: <SN6PR02MB5088847E2A3E48B54FAB2C82EA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>
References: <SN6PR02MB5088847E2A3E48B54FAB2C82EA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>
Message-ID: <E7C8ACD6-49FC-4ECC-9CED-1249F3301A26@dcn.davis.ca.us>

Your data appear to be in fixed format, not  space-delimited (or delimited by any other special character), so you should use read.fwf to read it in rather that read.table.

?read.fwf

In the future you should try to identify where your errors are or your data don't look right and ask focused questions about that (reproducible) problem rather than spilling your whole script into an email. That is, your error occurred in the single read.table command and the rest of it was working fine.

On September 13, 2018 5:14:33 AM PDT, Bill Poling <Bill.Poling at zelis.com> wrote:
>Hi,
>
>I hope someone can help me finalize this please.
>
>I am coming close to what I need using variations from two ggplot2
>tutorials.
>
>This first gives me the map of the US with AK & HI but I cannot figure
>out how to get my 5 regions colored
>
>#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1
>
>
>library(ggplot2)
>install.packages("ggalt")
>library(ggalt)     # coord_proj
>library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
>install.packages("ggthemes")
>library(ggthemes)  # theme_map
>install.packages("rgeos")
>library(rgeos)     # centroids
>library(dplyr)
>
># composite map with AK & HI
>usa_map <- usa_composite()
>
># calculate the centroids for each state
>gCentroid(usa_map, byid=TRUE) %>%
>  as.data.frame() %>%
>  mutate(state=usa_map at data$iso_3166_2) -> centroids
>
># make it usable in ggplot2
>usa_map <- fortify(usa_map)
>
>View(usa_map)
>t1 <- head(usa_map,n=5)
>knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
>
>#
>
>  # |long      |lat      | group| order|  region|subregion |
>  # |:---------|:--------|-----:|-----:|-------:|:---------|
>  # |-87.46201 |30.38968 |     1|     1| alabama|NA        |
>  # |-87.48493 |30.37249 |     1|     2| alabama|NA        |
>  # |-87.52503 |30.37249 |     1|     3| alabama|NA        |
>  # |-87.53076 |30.33239 |     1|     4| alabama|NA        |
>  # |-87.57087 |30.32665 |     1|     5| alabama|NA        |
>
>usa_map <- fortify(usa_map)
>gg <- ggplot()
>gg <- gg + geom_map(data=usa_map, map=usa_map,
>                    aes(long, lat, map_id=id),
>                    color="#2b2b2b", size=0.1, fill=NA)
>
>gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
>gg <- gg + coord_proj(us_laea_proj)
>gg <- gg + theme_map()
>gg
>
>
>
>
>#************************************************************************************************************************************************************************************/
>
>This second is an alternative (however not liking AK&HI, not coming
>into the map like scenario one above) but also ignoring new Mexico
>(because recognizing a seventh field value) and I suspect it will do
>the same for new York and new jersey etc.. when I add them to the list.
>
>Error in scan(file = file, what = what, sep = sep, quote = quote, dec =
>dec,  :  line 12 did not have 6 elements
>
>When I use newmexico (all one word) it appears white in the map like
>the other states not in the table statement
>
>#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors
>
>library(ggplot2)
>
>read.table(text="State.Code   region            St_Abbr   Num_Estab
>colors
>                 1          1   alaska       Ak        13123    #f7931e
>                 3          1   arizona      AZ        18053    #f7931e
>                 5          1   california   CA       143937    #f7931e
>                 2          1   hawaii       HI       123456    #f7931e
>                 4          1   nevada       NV       654321    #f7931e
>                 6          1   oregon       OR       321456    #f7931e
>                 7          1   washington   WA       456123    #f7931e
>                 8          2   colorado     CO       987654    #787878
>                 9          2   idaho        ID       13549     #787878
>                10          2   kansas       KS       94531     #787878
>                11          2   montana      MT       456321    #787878
>12          2   new mexico   NM     582310            #787878 <---Not
>liking new mexico, saying not 6
>                13          2   oklahoma     OK       214567    #787878
>                14          2   texas        TX       675421    #787878
>                15          2   utah         UT       754321    #787878
>             16          2   wyoming      WY       543124    #787878 ",
>stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df
>
>usa_map1 <- map_data("state")
>t1 <- head(usa_map1,n=5)
>knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
>View(usa_map1)
>#
>#   |long      |lat      | group| order|  region|subregion |
>#   |:---------|:--------|-----:|-----:|-------:|:---------|
>#   |-87.46201 |30.38968 |     1|     1| alabama|NA        |
>#   |-87.48493 |30.37249 |     1|     2| alabama|NA        |
>#   |-87.52503 |30.37249 |     1|     3| alabama|NA        |
>#   |-87.53076 |30.33239 |     1|     4| alabama|NA        |
>#   |-87.57087 |30.32665 |     1|     5| alabama|NA        |
>
>
>
>gg <- ggplot()
>#View(gg)
>gg <- gg + geom_map(data=usa_map1, map=usa_map1,
>                    aes(long, lat, map_id=region),
>                    color="#2b2b2b", size=0.15, fill=NA)
>
>gg <- gg + geom_map(data=df, map=usa_map1,
>                    aes(fill=colors, map_id=region),
>                    color="#2b2b2b", size=0.15)
>
>
>gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
>gg <- gg + coord_proj(us_laea_proj)
>gg <- gg + theme_map()
>gg
>
>
>gg <- gg + scale_color_identity()
>gg <- gg + coord_map("polyconic")
>gg <- gg + ggthemes::theme_map()
>gg
>
>#c( "colorado", "idaho", "kansas", "montana", "new mexico",
>"oklahoma","texas", "utah", "wyoming") )
>#c("alaska", "arizona", "california", "hawaii", "nevada",
>"oregon","washington"))
>
>
>
>William H. Poling, Ph.D., MPH
>
>
>
>
>Confidentiality Notice This message is sent from Zelis.
>...{{dropped:13}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From Bill@Poling @ending from zeli@@com  Thu Sep 13 20:31:55 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 13 Sep 2018 18:31:55 +0000
Subject: [R] Help with simple Map of US states with predefined regions
 Version 2
In-Reply-To: <E7C8ACD6-49FC-4ECC-9CED-1249F3301A26@dcn.davis.ca.us>
References: <SN6PR02MB5088847E2A3E48B54FAB2C82EA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>
 <E7C8ACD6-49FC-4ECC-9CED-1249F3301A26@dcn.davis.ca.us>
Message-ID: <SN6PR02MB50885E53405A2781213DC21FEA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>

Thank you Jeff.

Cannot seem to get this to work in the fashion I want it to appear no matter how many websites and packages I investigate.

Letting it go for the moment.

Always appreciate your advice Sir!

WHP
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Thursday, September 13, 2018 10:29 AM
To: r-help at r-project.org; Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with simple Map of US states with predefined regions Version 2

Your data appear to be in fixed format, not space-delimited (or delimited by any other special character), so you should use read.fwf to read it in rather that read.table.

?read.fwf

In the future you should try to identify where your errors are or your data don't look right and ask focused questions about that (reproducible) problem rather than spilling your whole script into an email. That is, your error occurred in the single read.table command and the rest of it was working fine.

On September 13, 2018 5:14:33 AM PDT, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>Hi,
>
>I hope someone can help me finalize this please.
>
>I am coming close to what I need using variations from two ggplot2
>tutorials.
>
>This first gives me the map of the US with AK & HI but I cannot figure
>out how to get my 5 regions colored
>
>#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1<https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1>
>
>
>library(ggplot2)
>install.packages("ggalt")
>library(ggalt) # coord_proj
>library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
>install.packages("ggthemes")
>library(ggthemes) # theme_map
>install.packages("rgeos")
>library(rgeos) # centroids
>library(dplyr)
>
># composite map with AK & HI
>usa_map <- usa_composite()
>
># calculate the centroids for each state
>gCentroid(usa_map, byid=TRUE) %>%
> as.data.frame() %>%
> mutate(state=usa_map at data$iso_3166_2) -> centroids
>
># make it usable in ggplot2
>usa_map <- fortify(usa_map)
>
>View(usa_map)
>t1 <- head(usa_map,n=5)
>knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
>
>#
>
> # |long |lat | group| order| region|subregion |
> # |:---------|:--------|-----:|-----:|-------:|:---------|
> # |-87.46201 |30.38968 | 1| 1| alabama|NA |
> # |-87.48493 |30.37249 | 1| 2| alabama|NA |
> # |-87.52503 |30.37249 | 1| 3| alabama|NA |
> # |-87.53076 |30.33239 | 1| 4| alabama|NA |
> # |-87.57087 |30.32665 | 1| 5| alabama|NA |
>
>usa_map <- fortify(usa_map)
>gg <- ggplot()
>gg <- gg + geom_map(data=usa_map, map=usa_map,
> aes(long, lat, map_id=id),
> color="#2b2b2b", size=0.1, fill=NA)
>
>gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
>gg <- gg + coord_proj(us_laea_proj)
>gg <- gg + theme_map()
>gg
>
>
>
>
>#************************************************************************************************************************************************************************************/
>
>This second is an alternative (however not liking AK&HI, not coming
>into the map like scenario one above) but also ignoring new Mexico
>(because recognizing a seventh field value) and I suspect it will do
>the same for new York and new jersey etc.. when I add them to the list.
>
>Error in scan(file = file, what = what, sep = sep, quote = quote, dec =
>dec, : line 12 did not have 6 elements
>
>When I use newmexico (all one word) it appears white in the map like
>the other states not in the table statement
>
>#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors<https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors>
>
>library(ggplot2)
>
>read.table(text="State.Code region St_Abbr Num_Estab
>colors
> 1 1 alaska Ak 13123 #f7931e
> 3 1 arizona AZ 18053 #f7931e
> 5 1 california CA 143937 #f7931e
> 2 1 hawaii HI 123456 #f7931e
> 4 1 nevada NV 654321 #f7931e
> 6 1 oregon OR 321456 #f7931e
> 7 1 washington WA 456123 #f7931e
> 8 2 colorado CO 987654 #787878
> 9 2 idaho ID 13549 #787878
> 10 2 kansas KS 94531 #787878
> 11 2 montana MT 456321 #787878
>12 2 new mexico NM 582310 #787878 <---Not
>liking new mexico, saying not 6
> 13 2 oklahoma OK 214567 #787878
> 14 2 texas TX 675421 #787878
> 15 2 utah UT 754321 #787878
> 16 2 wyoming WY 543124 #787878 ",
>stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df
>
>usa_map1 <- map_data("state")
>t1 <- head(usa_map1,n=5)
>knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
>View(usa_map1)
>#
># |long |lat | group| order| region|subregion |
># |:---------|:--------|-----:|-----:|-------:|:---------|
># |-87.46201 |30.38968 | 1| 1| alabama|NA |
># |-87.48493 |30.37249 | 1| 2| alabama|NA |
># |-87.52503 |30.37249 | 1| 3| alabama|NA |
># |-87.53076 |30.33239 | 1| 4| alabama|NA |
># |-87.57087 |30.32665 | 1| 5| alabama|NA |
>
>
>
>gg <- ggplot()
>#View(gg)
>gg <- gg + geom_map(data=usa_map1, map=usa_map1,
> aes(long, lat, map_id=region),
> color="#2b2b2b", size=0.15, fill=NA)
>
>gg <- gg + geom_map(data=df, map=usa_map1,
> aes(fill=colors, map_id=region),
> color="#2b2b2b", size=0.15)
>
>
>gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
>gg <- gg + coord_proj(us_laea_proj)
>gg <- gg + theme_map()
>gg
>
>
>gg <- gg + scale_color_identity()
>gg <- gg + coord_map("polyconic")
>gg <- gg + ggthemes::theme_map()
>gg
>
>#c( "colorado", "idaho", "kansas", "montana", "new mexico",
>"oklahoma","texas", "utah", "wyoming") )
>#c("alaska", "arizona", "california", "hawaii", "nevada",
>"oregon","washington"))
>
>
>
>William H. Poling, Ph.D., MPH
>
>
>
>
>Confidentiality Notice This message is sent from Zelis.
>...{{dropped:13}}
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From motyoc@k@ @ending from y@hoo@com  Thu Sep 13 21:11:21 2018
From: motyoc@k@ @ending from y@hoo@com (Andras Farkas)
Date: Thu, 13 Sep 2018 19:11:21 +0000 (UTC)
Subject: [R] ddply (or other suitable solution) question
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
Message-ID: <1075990829.2369338.1536865881254@mail.yahoo.com>

Dear All,

I have data frame:
set.seed(123.456)
df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
? ? ? ? ? ? ? ? read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
? ? ? ? ? ? ? ? int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
? ? ? ? ? ? ? ? z=rnorm(13,1,5),
? ? ? ? ? ? ? ? y=rnorm(13,1,5))

what I would like to achieve (as best as I see it now) is to create multiple lists (and lists within lists using the data in df) that would be based on the groups in the ID column ("top level of list") and "join together" each line item within the group followed by the next line item ("bottom level list"), so would look like this for?

[[ID=1]]
[[1]][[1]]
? ID read int? ? ? ? z? ? ? ? y
? 1? ? 1? ?1 5.188935 5.107905
? 1? ? 1? ?1 1.766866 4.443201
[[ID=2]]
[[2]][[1]]? ID read int? ? ? ? ?z? ? ? ? ?y
? 2? ? 0? ?0 -4.690685 3.7695883
? 2? ? 1? ?0? 7.269075 0.6904414[[ID=2]]
[[2]][[2]]? ID read int? ? ? ? z? ? ? ? ? y
? 2? ? 1? ?0 7.269075? 0.6904414
? 2? ? 1? ?0 3.132321 -0.5298133[[ID=3]]
[[3]][[1]]? ID read int? ? ? ? ? z? ? ? ? ?y
? 3? ? 1? ?1 -0.4753574 -0.902355
? 3? ? 0? ?1? 5.4756283 -2.473535
[[ID=3]]
[[3]][[2]]
? 3? ? 0? ?1 5.475628 -2.47353489
? 3? ? 0? ?0 5.390667 -0.03958639


hoping example clear enough... all our help is appreciated,

thanks,



Andras?


From jeremieju@te @ending from gm@il@com  Thu Sep 13 22:11:32 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Thu, 13 Sep 2018 22:11:32 +0200
Subject: [R] ddply (or other suitable solution) question
In-Reply-To: <1075990829.2369338.1536865881254@mail.yahoo.com> (Andras Farkas
 via's message of "Thu, 13 Sep 2018 19:11:21 +0000 (UTC)")
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
 <1075990829.2369338.1536865881254@mail.yahoo.com>
Message-ID: <87d0thp37v.fsf@gmail.com>

Andras Farkas via R-help <r-help at r-project.org> writes:

Hello,

 set.seed(123.456)
 
 df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
 read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
 int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
 z=rnorm(13,1,5),
 y=rnorm(13,1,5))

May this will suffice?

lapply(unique(df$ID),function(x) df[df$ID==x,])



HTH,

Jeremie


From bgunter@4567 @ending from gm@il@com  Thu Sep 13 22:40:39 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 13 Sep 2018 13:40:39 -0700
Subject: [R] ddply (or other suitable solution) question
In-Reply-To: <1075990829.2369338.1536865881254@mail.yahoo.com>
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
 <1075990829.2369338.1536865881254@mail.yahoo.com>
Message-ID: <CAGxFJbSxu7KKy2hzYKUtq54fp+farc4S0fdzFWw5BwkTb+3ULQ@mail.gmail.com>

What if there is only one read in the id?


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 13, 2018 at 12:11 PM Andras Farkas via R-help
<r-help at r-project.org> wrote:
>
> Dear All,
>
> I have data frame:
> set.seed(123.456)
> df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
>                 read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
>                 int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
>                 z=rnorm(13,1,5),
>                 y=rnorm(13,1,5))
>
> what I would like to achieve (as best as I see it now) is to create multiple lists (and lists within lists using the data in df) that would be based on the groups in the ID column ("top level of list") and "join together" each line item within the group followed by the next line item ("bottom level list"), so would look like this for
>
> [[ID=1]]
> [[1]][[1]]
>   ID read int        z        y
>   1    1   1 5.188935 5.107905
>   1    1   1 1.766866 4.443201
> [[ID=2]]
> [[2]][[1]]  ID read int         z         y
>   2    0   0 -4.690685 3.7695883
>   2    1   0  7.269075 0.6904414[[ID=2]]
> [[2]][[2]]  ID read int        z          y
>   2    1   0 7.269075  0.6904414
>   2    1   0 3.132321 -0.5298133[[ID=3]]
> [[3]][[1]]  ID read int          z         y
>   3    1   1 -0.4753574 -0.902355
>   3    0   1  5.4756283 -2.473535
> [[ID=3]]
> [[3]][[2]]
>   3    0   1 5.475628 -2.47353489
>   3    0   0 5.390667 -0.03958639
>
>
> hoping example clear enough... all our help is appreciated,
>
> thanks,
>
>
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Thu Sep 13 23:16:40 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 13 Sep 2018 14:16:40 -0700
Subject: [R] ddply (or other suitable solution) question
In-Reply-To: <CAGxFJbSxu7KKy2hzYKUtq54fp+farc4S0fdzFWw5BwkTb+3ULQ@mail.gmail.com>
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
 <1075990829.2369338.1536865881254@mail.yahoo.com>
 <CAGxFJbSxu7KKy2hzYKUtq54fp+farc4S0fdzFWw5BwkTb+3ULQ@mail.gmail.com>
Message-ID: <CAGxFJbQYwJwdarhdrgs=Gs28n6E84GysZGcs3ny3hweLE=cj-g@mail.gmail.com>

Mod my earlier question, it seems that you just want to replicate all
rows within an id if there more than 2 rows. If this is incorrect,
ignore the rest of this post.

Otherwise...

(I assume the data frame is listed in ID order, whatever that is)

set.seed(123.456)
df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
                read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
                int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
                z=rnorm(13,1,5),
                y=rnorm(13,1,5))

yielded on my Mac and R version 3.5.1

> df
   ID read int          z           y
1   1    1   1 -1.8023782  1.55341358
2   1    1   1 -0.1508874 -1.77920567
3   2    0   0  8.7935416  9.93456568
4   2    1   0  1.3525420  3.48925239
5   2    1   0  1.6464387 -8.83308578
6   3    1   1  9.5753249  4.50677951
7   3    0   1  3.3045810 -1.36395704
8   3    0   0 -5.3253062 -4.33911853
9   3    0   0 -2.4342643 -0.08987457
10  4    1   1 -1.2283099 -4.13002224
11  4    0   1  7.1204090 -2.64445615
12  5    0   1  2.7990691 -2.12519634
13  5    0   1  3.0038573 -7.43346655

## The following doubles up the rows by ID
> ix <- tapply(seq_len(nrow(df)),df$ID,
+              function(x){
+                 lenx <- length(x)
+                 if(lenx > 2)
+                    c(x[1],rep(x[2]:x[lenx-1],e=2),x[lenx])
+                 else x
+              }
+    )
> ix
$`1`
[1] 1 2

$`2`
[1] 3 4 4 5

$`3`
[1] 6 7 7 8 8 9

$`4`
[1] 10 11

$`5`
[1] 12 13

## now use the ix list to break up df:

> lapply(ix, function(i)df[i,])
$`1`
  ID read int          z         y
1  1    1   1 -1.8023782  1.553414
2  1    1   1 -0.1508874 -1.779206

$`2`
    ID read int        z         y
3    2    0   0 8.793542  9.934566
4    2    1   0 1.352542  3.489252
4.1  2    1   0 1.352542  3.489252
5    2    1   0 1.646439 -8.833086

$`3`
    ID read int         z           y
6    3    1   1  9.575325  4.50677951
7    3    0   1  3.304581 -1.36395704
7.1  3    0   1  3.304581 -1.36395704
8    3    0   0 -5.325306 -4.33911853
8.1  3    0   0 -5.325306 -4.33911853
9    3    0   0 -2.434264 -0.08987457

$`4`
   ID read int         z         y
10  4    1   1 -1.228310 -4.130022
11  4    0   1  7.120409 -2.644456

$`5`
   ID read int        z         y
12  5    0   1 2.799069 -2.125196
13  5    0   1 3.003857 -7.433467

I leave it to you to modify the lapply() function to break up each id
data frame into sublists of pairs if that is what you wish to do.
Assuming again that this is actually what you want.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Thu, Sep 13, 2018 at 1:40 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> What if there is only one read in the id?
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 13, 2018 at 12:11 PM Andras Farkas via R-help
> <r-help at r-project.org> wrote:
> >
> > Dear All,
> >
> > I have data frame:
> > set.seed(123.456)
> > df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
> >                 read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
> >                 int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
> >                 z=rnorm(13,1,5),
> >                 y=rnorm(13,1,5))
> >
> > what I would like to achieve (as best as I see it now) is to create multiple lists (and lists within lists using the data in df) that would be based on the groups in the ID column ("top level of list") and "join together" each line item within the group followed by the next line item ("bottom level list"), so would look like this for
> >
> > [[ID=1]]
> > [[1]][[1]]
> >   ID read int        z        y
> >   1    1   1 5.188935 5.107905
> >   1    1   1 1.766866 4.443201
> > [[ID=2]]
> > [[2]][[1]]  ID read int         z         y
> >   2    0   0 -4.690685 3.7695883
> >   2    1   0  7.269075 0.6904414[[ID=2]]
> > [[2]][[2]]  ID read int        z          y
> >   2    1   0 7.269075  0.6904414
> >   2    1   0 3.132321 -0.5298133[[ID=3]]
> > [[3]][[1]]  ID read int          z         y
> >   3    1   1 -0.4753574 -0.902355
> >   3    0   1  5.4756283 -2.473535
> > [[ID=3]]
> > [[3]][[2]]
> >   3    0   1 5.475628 -2.47353489
> >   3    0   0 5.390667 -0.03958639
> >
> >
> > hoping example clear enough... all our help is appreciated,
> >
> > thanks,
> >
> >
> >
> > Andras
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 00:32:46 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 15:32:46 -0700 (PDT)
Subject: [R] sink() output to another directory
Message-ID: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>

   Neither ?sink nor ?capture.output indicates how the output file can be
specified to be in a directory other than the cwd.

   When the cwd is ../analyses/ and I want the output to be in
../analyses/stat-summaries/ how do I write this?

   sink('example-output.txt')
   print(summary(df))
   sink()

writes output to the current directory. My attempts to prefix the file name
with ./ or just / don't sit well with R. What is the proper syntax?

TIA,

Rich


From henrik@bengt@@on @ending from gm@il@com  Fri Sep 14 00:42:26 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Thu, 13 Sep 2018 15:42:26 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
Message-ID: <CAFDcVCS2a7hWu716CCtmX3BduMXqvppu4kuxmQNm79pEyyTb9w@mail.gmail.com>

On Thu, Sep 13, 2018 at 3:33 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
>    Neither ?sink nor ?capture.output indicates how the output file can be
> specified to be in a directory other than the cwd.
>
>    When the cwd is ../analyses/ and I want the output to be in
> ../analyses/stat-summaries/ how do I write this?
>
>    sink('example-output.txt')
>    print(summary(df))
>    sink()
>
> writes output to the current directory. My attempts to prefix the file name
> with ./ or just / don't sit well with R.

Hi welcome to R-help. Please help the helper(s) to help you by being
as explicit as possible what you've tried (i.e. cut'n'paste your
code), provide error messages (cut'n'paste) you get, if any, and/or
what you mean by "don't sit well with R" (that can mean many different
things).

/Henrik

> What is the proper syntax?
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 00:49:52 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 15:49:52 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
Message-ID: <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Duncan Murdoch wrote:

> What did you try?  Prefixing with either ./ or / doesn't make any sense.

Duncan,

   Using linux (and perhaps other unices) ./ and / refer to the current
directory. My code, to print to the sub-directory
(../analyses/stat-summaries/) when the script is being run in ../analyses:

sink('stat-summaries/estacada-wnw-precip.txt')
print(/summary(estacada_wnw_wx))
sink()

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 00:58:16 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 15:58:16 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Rich Shepard wrote:

>  sink('example-output.txt')
>  print(summary(df))
>  sink()

   Let me expand on this. When the script contains

# Open PDF device to save plot
pdf('../images/rainfall-estacada-se.pdf')
...
plot(rain_est_se)
dev.off()

the file, rainfall-estacada-se.pdf is placed in the images directory, which
is on the same directory level as the one in which the script is being run.
I thought the equivalent syntax with sink() would work, but the print
command rejects the forward slash that plot() accepts:

Error in source("rainfall-dubois-crk-all.r") :
   rainfall-dubois-crk-all.r:25:7: unexpected '/'

   Is this more clear?

Thanks,

Rich


From peter@l@ngfelder @ending from gm@il@com  Fri Sep 14 01:04:41 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Thu, 13 Sep 2018 16:04:41 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>
Message-ID: <CA+hbrhU6S9-pofo4A1WZehxEVjPdiJazkWKE1D2nc0vEb-oZHQ@mail.gmail.com>

Remove the / from the print command, it does not belong there.

sink("../directory/file.txt");
print(summary(foo))
sink(NULL)


On Thu, Sep 13, 2018 at 4:03 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 13 Sep 2018, Rich Shepard wrote:
>
> >  sink('example-output.txt')
> >  print(summary(df))
> >  sink()
>
>    Let me expand on this. When the script contains
>
> # Open PDF device to save plot
> pdf('../images/rainfall-estacada-se.pdf')
> ...
> plot(rain_est_se)
> dev.off()
>
> the file, rainfall-estacada-se.pdf is placed in the images directory, which
> is on the same directory level as the one in which the script is being run.
> I thought the equivalent syntax with sink() would work, but the print
> command rejects the forward slash that plot() accepts:
>
> Error in source("rainfall-dubois-crk-all.r") :
>    rainfall-dubois-crk-all.r:25:7: unexpected '/'
>
>    Is this more clear?
>
> Thanks,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Fri Sep 14 01:25:28 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Fri, 14 Sep 2018 11:25:28 +1200
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
Message-ID: <4d557f8b-20af-cfa5-a400-f850ebcdde31@auckland.ac.nz>


On 09/14/2018 10:49 AM, Rich Shepard wrote:

> On Thu, 13 Sep 2018, Duncan Murdoch wrote:
> 
>> What did you try?? Prefixing with either ./ or / doesn't make any sense.
> 
> Duncan,
> 
>  ? Using linux (and perhaps other unices) ./ and / refer to the current
> directory.

This is simply incorrect; "./" refers to the current directory but "/" 
refers to the root directory.

Note that sink("./mung.txt") gives the same result as sink("mung.txt"). 
I.e. the "./" is redundant.

If you have a directory "gorp" in your current directory, then

     sink("gorp/mung.txt")

will put the sink() output into the file "mung.txt" in the directory "gorp".

<SNIP>

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 01:28:09 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 16:28:09 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <CA+hbrhU6S9-pofo4A1WZehxEVjPdiJazkWKE1D2nc0vEb-oZHQ@mail.gmail.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>
 <CA+hbrhU6S9-pofo4A1WZehxEVjPdiJazkWKE1D2nc0vEb-oZHQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809131625560.10298@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Peter Langfelder wrote:

> Remove the / from the print command, it does not belong there.

Peter,

   So the print() function cannot accept a relative path to a different
directory for its output? This does seem to be the case:

source('rainfall-dubois-crk-all.r')
Error in source("rainfall-dubois-crk-all.r") :
   rainfall-dubois-crk-all.r:25:7: unexpected '/'
24: sink('stat-summaries/estacada-wnw-precip.txt')
25: print(/
           ^

   Then I'll print to the cwd and move the files manually afterwards.

Thanks,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 01:32:04 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 16:32:04 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <4d557f8b-20af-cfa5-a400-f850ebcdde31@auckland.ac.nz>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <4d557f8b-20af-cfa5-a400-f850ebcdde31@auckland.ac.nz>
Message-ID: <alpine.LNX.2.20.1809131628440.10298@salmo.appl-ecosys.com>

On Fri, 14 Sep 2018, Rolf Turner wrote:

> This is simply incorrect; "./" refers to the current directory but "/" refers 
> to the root directory.

Rolf,

   I was not sufficientl clear.

> Note that sink("./mung.txt") gives the same result as sink("mung.txt"). I.e. 
> the "./" is redundant.
>
> If you have a directory "gorp" in your current directory, then
>
>    sink("gorp/mung.txt")
>
> will put the sink() output into the file "mung.txt" in the directory "gorp".

sink('stat-summaries/estacada-wnw-precip.txt')
print(summary(estacada_se_wx))
sink()

results in

24: sink('stat-summaries/estacada-wnw-precip.txt')
25: print(/
           ^
   Does not matter if I use single or double quotes.

Regards,

Rich


From m@cqueen1 @ending from llnl@gov  Fri Sep 14 01:51:16 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 13 Sep 2018 23:51:16 +0000
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
Message-ID: <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>

In my experience, any path that can be used at the shell prompt in a unix-alike can be used anywhere that R wants a file name.

[that is, when running R on a unix-alike system, and when pwd at the shell prompt returns the same value as getwd() in R]

Hopefully, that helps...


-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/13/18, 3:49 PM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

    On Thu, 13 Sep 2018, Duncan Murdoch wrote:
    
    > What did you try?  Prefixing with either ./ or / doesn't make any sense.
    
    Duncan,
    
       Using linux (and perhaps other unices) ./ and / refer to the current
    directory. My code, to print to the sub-directory
    (../analyses/stat-summaries/) when the script is being run in ../analyses:
    
    sink('stat-summaries/estacada-wnw-precip.txt')
    print(/summary(estacada_wnw_wx))
    sink()
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Sep 14 02:50:33 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 13 Sep 2018 17:50:33 -0700
Subject: [R] ddply (or other suitable solution) question
In-Reply-To: <1075990829.2369338.1536865881254@mail.yahoo.com>
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
 <1075990829.2369338.1536865881254@mail.yahoo.com>
Message-ID: <174D482F-C120-4503-B948-FEB0DC75C171@dcn.davis.ca.us>

The input example seems explicit enough, but I get confused understanding your desired output. Can you create an example data structure in your global environment "by hand" and use dput to give it to us?

On September 13, 2018 12:11:21 PM PDT, Andras Farkas via R-help <r-help at r-project.org> wrote:
>Dear All,
>
>I have data frame:
>set.seed(123.456)
>df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
>? ? ? ? ? ? ? ? read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
>? ? ? ? ? ? ? ? int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
>? ? ? ? ? ? ? ? z=rnorm(13,1,5),
>? ? ? ? ? ? ? ? y=rnorm(13,1,5))
>
>what I would like to achieve (as best as I see it now) is to create
>multiple lists (and lists within lists using the data in df) that would
>be based on the groups in the ID column ("top level of list") and "join
>together" each line item within the group followed by the next line
>item ("bottom level list"), so would look like this for?
>
>[[ID=1]]
>[[1]][[1]]
>? ID read int? ? ? ? z? ? ? ? y
>? 1? ? 1? ?1 5.188935 5.107905
>? 1? ? 1? ?1 1.766866 4.443201
>[[ID=2]]
>[[2]][[1]]? ID read int? ? ? ? ?z? ? ? ? ?y
>? 2? ? 0? ?0 -4.690685 3.7695883
>? 2? ? 1? ?0? 7.269075 0.6904414[[ID=2]]
>[[2]][[2]]? ID read int? ? ? ? z? ? ? ? ? y
>? 2? ? 1? ?0 7.269075? 0.6904414
>? 2? ? 1? ?0 3.132321 -0.5298133[[ID=3]]
>[[3]][[1]]? ID read int? ? ? ? ? z? ? ? ? ?y
>? 3? ? 1? ?1 -0.4753574 -0.902355
>? 3? ? 0? ?1? 5.4756283 -2.473535
>[[ID=3]]
>[[3]][[2]]
>? 3? ? 0? ?1 5.475628 -2.47353489
>? 3? ? 0? ?0 5.390667 -0.03958639
>
>
>hoping example clear enough... all our help is appreciated,
>
>thanks,
>
>
>
>Andras?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 03:05:15 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 18:05:15 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
Message-ID: <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, MacQueen, Don wrote:

> In my experience, any path that can be used at the shell prompt in a
> unix-alike can be used anywhere that R wants a file name.

Don,

   That's been my experiences, too.

> Hopefully, that helps...

   That's why I don't understand why the plot() function accepts the
different directory while the sink() function (here) doesn't.

   I showed R rejecting:

sink('stat-summaries/estacada-se-precip.txt')
print(summary(estacada_se_wx))
sink()

while accepting:

pdf('../images/rainfall-estacada-se.pdf')
  <snip xyplot() function>
plot(rain_est_se)
dev.off()

   Changing the sink() file to
'./stat-summaries/estacada-se-precip.txt'

generates the same error while I regularly use this syntax to copy files or
specify the relative path to an executable file.

Regards,

Rich


From henrik@bengt@@on @ending from gm@il@com  Fri Sep 14 03:15:38 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Thu, 13 Sep 2018 18:15:38 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
Message-ID: <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>

On Thu, Sep 13, 2018 at 6:05 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Thu, 13 Sep 2018, MacQueen, Don wrote:
>
> > In my experience, any path that can be used at the shell prompt in a
> > unix-alike can be used anywhere that R wants a file name.
>
> Don,
>
>    That's been my experiences, too.
>
> > Hopefully, that helps...
>
>    That's why I don't understand why the plot() function accepts the
> different directory while the sink() function (here) doesn't.
>
>    I showed R rejecting:
>
> sink('stat-summaries/estacada-se-precip.txt')
> print(summary(estacada_se_wx))
> sink()
>
> while accepting:
>
> pdf('../images/rainfall-estacada-se.pdf')
>   <snip xyplot() function>
> plot(rain_est_se)
> dev.off()
>
>    Changing the sink() file to
> './stat-summaries/estacada-se-precip.txt'
>
> generates the same error

"same error" as what? (ambiguity is the reason for not being able to
help you - all the replies in this thread this far are correct and on
the spot)

BTW, not that it should matter, what is your operating system and version of R?

/Henrik

> while I regularly use this syntax to copy files or
> specify the relative path to an executable file.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From FAGuo @ending from corner@tone@com  Thu Sep 13 22:15:01 2018
From: FAGuo @ending from corner@tone@com (Guo, Fang (Associate))
Date: Thu, 13 Sep 2018 20:15:01 +0000
Subject: [R] Question on Binom.Confint
Message-ID: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>

Hi,

I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!


Fang Guo
Associate

CORNERSTONE RESEARCH
699 Boylston Street, 5th Floor
Boston, MA 02116-2836
617.927.3042 direct
faguo at cornerstone.com<mailto:faguo at cornerstone.com>

www.cornerstone.com<http://www.cornerstone.com/>


***********************************************************
Warning: This email may contain confidential or privileged information
intended only for the use of the individual or entity to whom it is
addressed. If you are not the intended recipient, please understand 
that any disclosure, copying, distribution, or use of the contents 
of this email is strictly prohibited.
***********************************************************

	[[alternative HTML version deleted]]


From @imin@@t@work @ending from gm@il@com  Thu Sep 13 23:31:50 2018
From: @imin@@t@work @ending from gm@il@com (Aimin Yan)
Date: Thu, 13 Sep 2018 17:31:50 -0400
Subject: [R] Change the position of label when using R package eulerr
Message-ID: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>

I am using eulerr to get venn.
My code is like:

fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
"LAD&nonXL_MEF" = 541,
                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")

plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
= 1),alpha=0.7)

After I get the figure, I find the position of some  labels need to be
adjusted.

Does anyone has some idea about how to process this?


Thank you,

Aimin

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Fri Sep 14 03:56:58 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 13 Sep 2018 18:56:58 -0700
Subject: [R] Change the position of label when using R package eulerr
In-Reply-To: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
Message-ID: <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>


> On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> 
> I am using eulerr to get venn.
> My code is like:
> 
> fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
>                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> "LAD&nonXL_MEF" = 541,
>                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> 
> plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
> = 1),alpha=0.7)
> 
> After I get the figure, I find the position of some  labels need to be
> adjusted.
> 
> Does anyone has some idea about how to process this?

Looking at the code of plot.euler we see that the plotting paradigm is grid. So you could assign the output to a data.object name, search for list items that match the names of the labels you want to reposition, and modify the position values. You would need to be more specific, if you want a worked example.

As far as I can see the lables and postions are fairly deep inside a list structure:

 $ children     :List of 1
  ..$ GRID.gTree.12:List of 5
  .. ..$ children
         $ diagram.grob.1     
            $children
.. .. .. .. ..$ labels.grob    :List of 11
  .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
  .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native 69.2native 11.9native
  .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
  .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
  .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native 5.24native 27.86native
  .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
  .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"

-- 
David.
> 
> 
> Thank you,
> 
> Aimin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dwin@emiu@ @ending from comc@@t@net  Fri Sep 14 03:58:33 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 13 Sep 2018 18:58:33 -0700
Subject: [R] Question on Binom.Confint
In-Reply-To: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
Message-ID: <DF7D1D63-B3F3-491F-AAE2-98F89C240FC0@comcast.net>


> On Sep 13, 2018, at 1:15 PM, Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
> 
> Hi,
> 
> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!

First you need to tell use where you are getting Binom.Confint.

Error: object 'Binom.Confint' not found

-- 
David,
> 
> 
> Fang Guo
> Associate
> 
> CORNERSTONE RESEARCH
> 699 Boylston Street, 5th Floor
> Boston, MA 02116-2836
> 617.927.3042 direct
> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
> 
> www.cornerstone.com<http://www.cornerstone.com/>
> 
> 
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand 
> that any disclosure, copying, distribution, or use of the contents 
> of this email is strictly prohibited.
> ***********************************************************
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From r@turner @ending from @uckl@nd@@c@nz  Fri Sep 14 04:01:52 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Fri, 14 Sep 2018 14:01:52 +1200
Subject: [R] [FORGED]  Question on Binom.Confint
In-Reply-To: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
Message-ID: <b1545005-4871-177d-ac0d-6aed93a5a3f8@auckland.ac.nz>


On 09/14/2018 08:15 AM, Guo, Fang (Associate) wrote:

> Hi,
> 
> I have a question with the function Binom.Confint(x,n,"method"=lrt).
> For likelihood ratio test, I'd like to ask how you define the upper
> limit when the frequency of successes is zero. Thanks!

Point 1:  This question is inappropriate for this list, since it is 
about statistical theory and not about R syntax and programming.

Point 2: Where did you find the function Binom.Confint()?  I can find no 
such function anywhere.  I did manage to locate a function 
binom.confint() (note the lower case "b" and "c") but it does not have
an argument "method".  Please do not expect those whom you are 
addressing to be telepathic.

Point 3:  Having "method"=lrt in the call is decidedly weird.  Perhaps 
you meant method="lrt"; this is entirely different.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From chocold12 @ending from gm@il@com  Fri Sep 14 04:02:53 2018
From: chocold12 @ending from gm@il@com (lily li)
Date: Fri, 14 Sep 2018 10:02:53 +0800
Subject: [R] how to plot gridded data
In-Reply-To: <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>
References: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
 <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>

Hi Petr,

I have merged the data using cbind. The dataset is like this:
DF
lat1_lon1  lat1_lon2  lat1_lon3  ...  lat2_lon1
  1.20           1.30          2.11      ...     1.28
  1.50           1.81          3.12      ...     2.34
  2.41           2.22          1.56      ...     2.50
  3.11           4.21          2.12      ...     3.21

The other file is a shapfile, which I can open using readOGR. Then it shows
a polygon according to geographical latitude and longitude in degrees. How
to overlay the values in DF onto the polygon? note that DF has the
coordinates for a rectangular box that includes the shapefile, but is
larger. I don't know how to do this. Thanks for your help.

On Wed, Sep 12, 2018 at 3:22 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> 1. Read files/lines into R ?read.table, ?read.lines
> 2. Merge files according to your specification ?merge, ?rbind
> 3. Plot values by suitable command(s) ?plot, ?ggplot
> 4. If you want more specific answer, please post more specific question,
> preferably with concise and clear example.
> 5. Avoid posting in HTML
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of lily li
> > Sent: Wednesday, September 12, 2018 8:55 AM
> > To: R mailing list <r-help at r-project.org>
> > Subject: [R] how to plot gridded data
> >
> > Hi R users,
> >
> > I have a question about plotting gridded data. I have the files
> separately, but do
> > not know how to combine them. For example, each txt file has daily
> > precipitation data at a specific grid cell, named pr_lat_lon.txt. How to
> plot all
> > txt files for one surface (which is rectangular in this case), or how to
> combine
> > the txt files together? Thanks.
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> zasady-ochrany-osobnich-udaju/ | Information about processing and
> protection of business partner?s personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Sep 14 04:04:14 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 13 Sep 2018 19:04:14 -0700
Subject: [R] Question on Binom.Confint
In-Reply-To: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
Message-ID: <CAGxFJbQGbPhj0sRSqVjGOkPXoM_NoAHeE6n1WsMbxUFJpaTu9w@mail.gmail.com>

In what package?
Binomial confidence interval functions are in several.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 13, 2018 at 6:38 PM Guo, Fang (Associate)
<FAGuo at cornerstone.com> wrote:
>
> Hi,
>
> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
>
>
> Fang Guo
> Associate
>
> CORNERSTONE RESEARCH
> 699 Boylston Street, 5th Floor
> Boston, MA 02116-2836
> 617.927.3042 direct
> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
>
> www.cornerstone.com<http://www.cornerstone.com/>
>
>
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand
> that any disclosure, copying, distribution, or use of the contents
> of this email is strictly prohibited.
> ***********************************************************
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 04:12:00 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 19:12:00 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Henrik Bengtsson wrote:

>> sink('stat-summaries/estacada-se-precip.txt')
>> print(summary(estacada_se_wx))
>> sink()
>>
>> while accepting:
>>
>> pdf('../images/rainfall-estacada-se.pdf')
>>   <snip xyplot() function>
>> plot(rain_est_se)
>> dev.off()
>>
>>    Changing the sink() file to
>> './stat-summaries/estacada-se-precip.txt'
>>
>> generates the same error
>
> "same error" as what? (ambiguity is the reason for not being able to
> help you - all the replies in this thread this far are correct and on
> the spot)
>
> BTW, not that it should matter, what is your operating system and version of R?

Henrik,

   As I wrote in earlier messages:

sink('stat-summaries/estacada-wnw-precip.txt')
print(summary(estacada_se_wx))
sink()

results in

24: sink('stat-summaries/estacada-wnw-precip.txt')
25: print(/
            ^
    Does not matter if I use single or double quotes.

   The message that print() doesn't like the forward slash results when I
specify 'stat-summaries/estacada-wnw-precip.txt' or
'./stat-summaries/estacada-wnw-precip.txt'.

   Running R-3.5.1 on Slackware-14.2.

Rich


From roy@mendel@@ohn @ending from no@@@gov  Fri Sep 14 04:15:12 2018
From: roy@mendel@@ohn @ending from no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 13 Sep 2018 19:15:12 -0700
Subject: [R] how to plot gridded data
In-Reply-To: <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
References: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
 <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>
 <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
Message-ID: <BB3A0BB1-E552-4098-B060-DC70C3DF6938@noaa.gov>

Hi Lily:

I haven't used it to any extent to give you specifics,  but I strongly suggest you look at the package sf,  it is designed to do these sorts of things.  sf can read in the shapefile,  and it has features to covert the dataframe you describe to one of its objects,  and to combine objects.  There are even plotting functions I believe,  or if not there is a ggplot2::geom_sf()

HTH,

-Roy


> On Sep 13, 2018, at 7:02 PM, lily li <chocold12 at gmail.com> wrote:
> 
> Hi Petr,
> 
> I have merged the data using cbind. The dataset is like this:
> DF
> lat1_lon1  lat1_lon2  lat1_lon3  ...  lat2_lon1
>  1.20           1.30          2.11      ...     1.28
>  1.50           1.81          3.12      ...     2.34
>  2.41           2.22          1.56      ...     2.50
>  3.11           4.21          2.12      ...     3.21
> 
> The other file is a shapfile, which I can open using readOGR. Then it shows
> a polygon according to geographical latitude and longitude in degrees. How
> to overlay the values in DF onto the polygon? note that DF has the
> coordinates for a rectangular box that includes the shapefile, but is
> larger. I don't know how to do this. Thanks for your help.
> 
> On Wed, Sep 12, 2018 at 3:22 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
>> Hi
>> 
>> 1. Read files/lines into R ?read.table, ?read.lines
>> 2. Merge files according to your specification ?merge, ?rbind
>> 3. Plot values by suitable command(s) ?plot, ?ggplot
>> 4. If you want more specific answer, please post more specific question,
>> preferably with concise and clear example.
>> 5. Avoid posting in HTML
>> 
>> Cheers
>> Petr
>> 
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of lily li
>>> Sent: Wednesday, September 12, 2018 8:55 AM
>>> To: R mailing list <r-help at r-project.org>
>>> Subject: [R] how to plot gridded data
>>> 
>>> Hi R users,
>>> 
>>> I have a question about plotting gridded data. I have the files
>> separately, but do
>>> not know how to combine them. For example, each txt file has daily
>>> precipitation data at a specific grid cell, named pr_lat_lon.txt. How to
>> plot all
>>> txt files for one surface (which is rectangular in this case), or how to
>> combine
>>> the txt files together? Thanks.
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
>> zasady-ochrany-osobnich-udaju/ | Information about processing and
>> protection of business partner?s personal data are available on website:
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>> documents attached to it may be confidential and are subject to the legally
>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From peter@l@ngfelder @ending from gm@il@com  Fri Sep 14 05:11:49 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Thu, 13 Sep 2018 20:11:49 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
Message-ID: <CA+hbrhUXYExhDCo9M5Cj6qjCdyJ3Xk=dP2R=Vh6eptB+7VQkzw@mail.gmail.com>

For the second time: Rich, there should be no slash in the print() command.

Use the form

sink("../directory/file")
print(summary(foo)) ### no slashes here
sink(NULL)

Peter

On Thu, Sep 13, 2018 at 7:12 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 13 Sep 2018, Henrik Bengtsson wrote:
>
> >> sink('stat-summaries/estacada-se-precip.txt')
> >> print(summary(estacada_se_wx))
> >> sink()
> >>
> >> while accepting:
> >>
> >> pdf('../images/rainfall-estacada-se.pdf')
> >>   <snip xyplot() function>
> >> plot(rain_est_se)
> >> dev.off()
> >>
> >>    Changing the sink() file to
> >> './stat-summaries/estacada-se-precip.txt'
> >>
> >> generates the same error
> >
> > "same error" as what? (ambiguity is the reason for not being able to
> > help you - all the replies in this thread this far are correct and on
> > the spot)
> >
> > BTW, not that it should matter, what is your operating system and
> version of R?
>
> Henrik,
>
>    As I wrote in earlier messages:
>
> sink('stat-summaries/estacada-wnw-precip.txt')
> print(summary(estacada_se_wx))
> sink()
>
> results in
>
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>             ^
>     Does not matter if I use single or double quotes.
>
>    The message that print() doesn't like the forward slash results when I
> specify 'stat-summaries/estacada-wnw-precip.txt' or
> './stat-summaries/estacada-wnw-precip.txt'.
>
>    Running R-3.5.1 on Slackware-14.2.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chocold12 @ending from gm@il@com  Fri Sep 14 04:11:14 2018
From: chocold12 @ending from gm@il@com (lily li)
Date: Fri, 14 Sep 2018 10:11:14 +0800
Subject: [R] how to plot gridded data
In-Reply-To: <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
References: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
 <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>
 <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
Message-ID: <CAN5afy-6=LaYF=3q2EM9=mYQCAAv0TBwB2Sh7OUkNSiE6tuRNw@mail.gmail.com>

I think it may be feasible to transform the dataset DF, so that the column
names lat_lon can be a surface, where the values locate at each surface.
But I don't know how to transform DF.

On Fri, Sep 14, 2018 at 10:02 AM, lily li <chocold12 at gmail.com> wrote:

> Hi Petr,
>
> I have merged the data using cbind. The dataset is like this:
> DF
> lat1_lon1  lat1_lon2  lat1_lon3  ...  lat2_lon1
>   1.20           1.30          2.11      ...     1.28
>   1.50           1.81          3.12      ...     2.34
>   2.41           2.22          1.56      ...     2.50
>   3.11           4.21          2.12      ...     3.21
>
> The other file is a shapfile, which I can open using readOGR. Then it
> shows a polygon according to geographical latitude and longitude in
> degrees. How to overlay the values in DF onto the polygon? note that DF has
> the coordinates for a rectangular box that includes the shapefile, but is
> larger. I don't know how to do this. Thanks for your help.
>
> On Wed, Sep 12, 2018 at 3:22 PM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
>> Hi
>>
>> 1. Read files/lines into R ?read.table, ?read.lines
>> 2. Merge files according to your specification ?merge, ?rbind
>> 3. Plot values by suitable command(s) ?plot, ?ggplot
>> 4. If you want more specific answer, please post more specific question,
>> preferably with concise and clear example.
>> 5. Avoid posting in HTML
>>
>> Cheers
>> Petr
>>
>> > -----Original Message-----
>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of lily li
>> > Sent: Wednesday, September 12, 2018 8:55 AM
>> > To: R mailing list <r-help at r-project.org>
>> > Subject: [R] how to plot gridded data
>> >
>> > Hi R users,
>> >
>> > I have a question about plotting gridded data. I have the files
>> separately, but do
>> > not know how to combine them. For example, each txt file has daily
>> > precipitation data at a specific grid cell, named pr_lat_lon.txt. How
>> to plot all
>> > txt files for one surface (which is rectangular in this case), or how
>> to combine
>> > the txt files together? Thanks.
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady
>> -ochrany-osobnich-udaju/ | Information about processing and protection
>> of business partner?s personal data are available on website:
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>> documents attached to it may be confidential and are subject to the legally
>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Sep 14 04:30:27 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 13 Sep 2018 19:30:27 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSbXoqL6df3qFqu5uyEsYLze2EvDj=Qv-BEYzQdWqviGw@mail.gmail.com>

I find your "explanation" confusing. You appear to be misusing
print(). Please read ?print carefully. You print objects in R, not
files. Objects in R do not have "/" in their names (without some
trickery). See ?make.names .

-- Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 13, 2018 at 7:12 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Thu, 13 Sep 2018, Henrik Bengtsson wrote:
>
> >> sink('stat-summaries/estacada-se-precip.txt')
> >> print(summary(estacada_se_wx))
> >> sink()
> >>
> >> while accepting:
> >>
> >> pdf('../images/rainfall-estacada-se.pdf')
> >>   <snip xyplot() function>
> >> plot(rain_est_se)
> >> dev.off()
> >>
> >>    Changing the sink() file to
> >> './stat-summaries/estacada-se-precip.txt'
> >>
> >> generates the same error
> >
> > "same error" as what? (ambiguity is the reason for not being able to
> > help you - all the replies in this thread this far are correct and on
> > the spot)
> >
> > BTW, not that it should matter, what is your operating system and version of R?
>
> Henrik,
>
>    As I wrote in earlier messages:
>
> sink('stat-summaries/estacada-wnw-precip.txt')
> print(summary(estacada_se_wx))
> sink()
>
> results in
>
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>             ^
>     Does not matter if I use single or double quotes.
>
>    The message that print() doesn't like the forward slash results when I
> specify 'stat-summaries/estacada-wnw-precip.txt' or
> './stat-summaries/estacada-wnw-precip.txt'.
>
>    Running R-3.5.1 on Slackware-14.2.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Fri Sep 14 04:33:52 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 13 Sep 2018 19:33:52 -0700
Subject: [R] how to plot gridded data
In-Reply-To: <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
References: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
 <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>
 <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
Message-ID: <CAGxFJbSi5Xg7CvZyF+jLH1faNEqxjQWZbML8ywVQq5i4trrgvg@mail.gmail.com>

You may wish to consider posting on r-sig-geo, where you may be more
likely to find expertise for this sort of thing.
-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 13, 2018 at 7:08 PM lily li <chocold12 at gmail.com> wrote:
>
> Hi Petr,
>
> I have merged the data using cbind. The dataset is like this:
> DF
> lat1_lon1  lat1_lon2  lat1_lon3  ...  lat2_lon1
>   1.20           1.30          2.11      ...     1.28
>   1.50           1.81          3.12      ...     2.34
>   2.41           2.22          1.56      ...     2.50
>   3.11           4.21          2.12      ...     3.21
>
> The other file is a shapfile, which I can open using readOGR. Then it shows
> a polygon according to geographical latitude and longitude in degrees. How
> to overlay the values in DF onto the polygon? note that DF has the
> coordinates for a rectangular box that includes the shapefile, but is
> larger. I don't know how to do this. Thanks for your help.
>
> On Wed, Sep 12, 2018 at 3:22 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > Hi
> >
> > 1. Read files/lines into R ?read.table, ?read.lines
> > 2. Merge files according to your specification ?merge, ?rbind
> > 3. Plot values by suitable command(s) ?plot, ?ggplot
> > 4. If you want more specific answer, please post more specific question,
> > preferably with concise and clear example.
> > 5. Avoid posting in HTML
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: R-help <r-help-bounces at r-project.org> On Behalf Of lily li
> > > Sent: Wednesday, September 12, 2018 8:55 AM
> > > To: R mailing list <r-help at r-project.org>
> > > Subject: [R] how to plot gridded data
> > >
> > > Hi R users,
> > >
> > > I have a question about plotting gridded data. I have the files
> > separately, but do
> > > not know how to combine them. For example, each txt file has daily
> > > precipitation data at a specific grid cell, named pr_lat_lon.txt. How to
> > plot all
> > > txt files for one surface (which is rectangular in this case), or how to
> > combine
> > > the txt files together? Thanks.
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> > partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> > zasady-ochrany-osobnich-udaju/ | Information about processing and
> > protection of business partner?s personal data are available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the legally
> > binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @ending from @uckl@nd@@c@nz  Fri Sep 14 04:51:41 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Fri, 14 Sep 2018 14:51:41 +1200
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
Message-ID: <bd31e734-4c84-c3c7-4420-e58746976377@auckland.ac.nz>

On 09/14/2018 02:12 PM, Rich Shepard wrote:
> On Thu, 13 Sep 2018, Henrik Bengtsson wrote:
> 
>>> sink('stat-summaries/estacada-se-precip.txt')
>>> print(summary(estacada_se_wx))
>>> sink()
>>>
>>> while accepting:
>>>
>>> pdf('../images/rainfall-estacada-se.pdf')
>>> ? <snip xyplot() function>
>>> plot(rain_est_se)
>>> dev.off()
>>>
>>> ?? Changing the sink() file to
>>> './stat-summaries/estacada-se-precip.txt'
>>>
>>> generates the same error
>>
>> "same error" as what? (ambiguity is the reason for not being able to
>> help you - all the replies in this thread this far are correct and on
>> the spot)
>>
>> BTW, not that it should matter, what is your operating system and 
>> version of R?
> 
> Henrik,
> 
>  ? As I wrote in earlier messages:
> 
> sink('stat-summaries/estacada-wnw-precip.txt')
> print(summary(estacada_se_wx))
> sink()
> 
> results in
> 
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>  ?????????? ^
>  ?? Does not matter if I use single or double quotes.
> 
>  ? The message that print() doesn't like the forward slash results when I
> specify 'stat-summaries/estacada-wnw-precip.txt' or
> './stat-summaries/estacada-wnw-precip.txt'.
> 
>  ? Running R-3.5.1 on Slackware-14.2.

This would appear to have nothing to do with sink().  There is something
weird about your data set estacada_se_wx or the summary thereof that 
print() doesn't like.

If I do:

> system("mkdir stat-summaries")
> estacada_se_wx <- rnorm(10)
> sink('stat-summaries/estacada-se-precip.txt')
> print(summary(estacada_se_wx))
> sink()
> system("cat stat-summaries/estacada-se-precip.txt")

I get:

>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
> -1.7292 -0.7621  0.5428  0.2808  1.2603  1.7702 

OMMMMMMM!!!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @pencer@gr@ve@ @ending from effectivedefen@e@org  Fri Sep 14 05:12:38 2018
From: @pencer@gr@ve@ @ending from effectivedefen@e@org (Spencer Graves)
Date: Thu, 13 Sep 2018 22:12:38 -0500
Subject: [R] Question on Binom.Confint
In-Reply-To: <DF7D1D63-B3F3-491F-AAE2-98F89C240FC0@comcast.net>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <DF7D1D63-B3F3-491F-AAE2-98F89C240FC0@comcast.net>
Message-ID: <d9effcbb-069b-237e-c31d-2415eb8aba3d@effectivedefense.org>



On 2018-09-13 20:58, David Winsemius wrote:
>> On Sep 13, 2018, at 1:15 PM, Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
>>
>> Hi,
>>
>> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
> First you need to tell use where you are getting Binom.Confint.
>
> Error: object 'Binom.Confint' not found
>

 ????? sos::findFn('Binom.Confint') found NO function named 
"Binom.Confint", but it did find two named "binom.confint", one in the 
"binom" package and the other in the "NNTbiomarker" package. The same 
search in "rdocumentation.org" returned the same results. The indicated 
command would not work in either.


 ????? Spencer


From peter@l@ngfelder @ending from gm@il@com  Fri Sep 14 05:12:48 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Thu, 13 Sep 2018 20:12:48 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131625560.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>
 <CA+hbrhU6S9-pofo4A1WZehxEVjPdiJazkWKE1D2nc0vEb-oZHQ@mail.gmail.com>
 <alpine.LNX.2.20.1809131625560.10298@salmo.appl-ecosys.com>
Message-ID: <CA+hbrhWjtnbJ0iSAVwS8XwjnBGFc8+TZ8HFFQwm+7ziYjGnoyw@mail.gmail.com>

There is no path in print. The path (file) is set in sink().

Peter

On Thu, Sep 13, 2018 at 4:35 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 13 Sep 2018, Peter Langfelder wrote:
>
> > Remove the / from the print command, it does not belong there.
>
> Peter,
>
>    So the print() function cannot accept a relative path to a different
> directory for its output? This does seem to be the case:
>
> source('rainfall-dubois-crk-all.r')
> Error in source("rainfall-dubois-crk-all.r") :
>    rainfall-dubois-crk-all.r:25:7: unexpected '/'
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>            ^
>
>    Then I'll print to the cwd and move the files manually afterwards.
>
> Thanks,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Fri Sep 14 05:50:18 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Fri, 14 Sep 2018 13:50:18 +1000
Subject: [R] Question on Binom.Confint
In-Reply-To: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
Message-ID: <CA+8X3fUbws98+JWq5YOeEbTVjO-00TN7UKcdccMxHAzxi8H=fw@mail.gmail.com>

Hi Fang,
Let's assume that you are using the "binom.confint" function in the
"binom" package and you have made a spelling mistake or two. This
function employs nine methods for estimating the binomial confidence
interval. Sadly, none of these is "lrt". The zero condition is
discussed in the help page for four of these methods. Assuming you
want to use another method, you will have to look up the method. A
good start is:

https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval

Jim

On Fri, Sep 14, 2018 at 11:38 AM Guo, Fang (Associate)
<FAGuo at cornerstone.com> wrote:
>
> Hi,
>
> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
>
>
> Fang Guo
> Associate
>
> CORNERSTONE RESEARCH
> 699 Boylston Street, 5th Floor
> Boston, MA 02116-2836
> 617.927.3042 direct
> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
>
> www.cornerstone.com<http://www.cornerstone.com/>
>
>
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand
> that any disclosure, copying, distribution, or use of the contents
> of this email is strictly prohibited.
> ***********************************************************
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Sep 14 06:59:17 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 13 Sep 2018 21:59:17 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <CAFDcVCS2a7hWu716CCtmX3BduMXqvppu4kuxmQNm79pEyyTb9w@mail.gmail.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <CAFDcVCS2a7hWu716CCtmX3BduMXqvppu4kuxmQNm79pEyyTb9w@mail.gmail.com>
Message-ID: <B21FCD80-771D-4D9D-82B6-EE5328C749BD@dcn.davis.ca.us>

It is not possible for the current working directory to begin with "../". That is like saying n=n-1, because once follow the two dots up to the next directory the two dots refer to the next directory up.

I don't think anyone in this list understands what is going on for you, so I recommend using the reprex package to create a confirmed-reproducible example and send that along so we can identify the bug or user error that is puzzling you.

On September 13, 2018 3:42:26 PM PDT, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>On Thu, Sep 13, 2018 at 3:33 PM Rich Shepard <rshepard at appl-ecosys.com>
>wrote:
>>
>>    Neither ?sink nor ?capture.output indicates how the output file
>can be
>> specified to be in a directory other than the cwd.
>>
>>    When the cwd is ../analyses/ and I want the output to be in
>> ../analyses/stat-summaries/ how do I write this?
>>
>>    sink('example-output.txt')
>>    print(summary(df))
>>    sink()
>>
>> writes output to the current directory. My attempts to prefix the
>file name
>> with ./ or just / don't sit well with R.
>
>Hi welcome to R-help. Please help the helper(s) to help you by being
>as explicit as possible what you've tried (i.e. cut'n'paste your
>code), provide error messages (cut'n'paste) you get, if any, and/or
>what you mean by "don't sit well with R" (that can mean many different
>things).
>
>/Henrik
>
>> What is the proper syntax?
>>
>> TIA,
>>
>> Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From henrik@bengt@@on @ending from gm@il@com  Fri Sep 14 07:01:44 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Thu, 13 Sep 2018 22:01:44 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
Message-ID: <CAFDcVCSfz02e2QRppOpek01MOnPBo2Uv=vUmi+4bztxdNOphxQ@mail.gmail.com>

On Thu, Sep 13, 2018 at 7:12 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Thu, 13 Sep 2018, Henrik Bengtsson wrote:
>
> >> sink('stat-summaries/estacada-se-precip.txt')
> >> print(summary(estacada_se_wx))
> >> sink()
> >>
> >> while accepting:
> >>
> >> pdf('../images/rainfall-estacada-se.pdf')
> >>   <snip xyplot() function>
> >> plot(rain_est_se)
> >> dev.off()
> >>
> >>    Changing the sink() file to
> >> './stat-summaries/estacada-se-precip.txt'
> >>
> >> generates the same error
> >
> > "same error" as what? (ambiguity is the reason for not being able to
> > help you - all the replies in this thread this far are correct and on
> > the spot)
> >
> > BTW, not that it should matter, what is your operating system and version of R?
>
> Henrik,
>
>    As I wrote in earlier messages:
>
> sink('stat-summaries/estacada-wnw-precip.txt')
> print(summary(estacada_se_wx))
> sink()
>
> results in
>
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>             ^
>     Does not matter if I use single or double quotes.
>
>    The message that print() doesn't like the forward slash results when I
> specify 'stat-summaries/estacada-wnw-precip.txt' or
> './stat-summaries/estacada-wnw-precip.txt'.

Since it is impossible to get that error message (which is a syntax
error, i.e. the R parser does not accept the code as written and it
never gets to the point where the R engine even runs your code) for
the code you are showing, I strongly suspect that you didn't source()
the same file that you were editing (the one that contains the
three-line code you are displaying above).

I see from one of your later message that you've got it to work now.

/Henrik

>
>    Running R-3.5.1 on Slackware-14.2.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter@l@ngfelder @ending from gm@il@com  Fri Sep 14 07:00:13 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Thu, 13 Sep 2018 22:00:13 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131625560.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>
 <CA+hbrhU6S9-pofo4A1WZehxEVjPdiJazkWKE1D2nc0vEb-oZHQ@mail.gmail.com>
 <alpine.LNX.2.20.1809131625560.10298@salmo.appl-ecosys.com>
Message-ID: <CA+hbrhVP7MDWf9zEmR_mwzwsfgweQb+TrdppM32+FdAa3jUfEA@mail.gmail.com>

Apologies if my advice wasn't clear: the file you want to write to goes in
the sink() function/command. You can put the file anywhere on your file
system, no need to write into current directory and then move the file.

The print command is completely unaware of the file you point to in sink().
Technically, print() sends output to a device called "standard output"
which is usually screen, but it can be changed to a file (_any_ writable
file) using the sink() command.

Hope this helps,

Peter

On Thu, Sep 13, 2018 at 4:35 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 13 Sep 2018, Peter Langfelder wrote:
>
> > Remove the / from the print command, it does not belong there.
>
> Peter,
>
>    So the print() function cannot accept a relative path to a different
> directory for its output? This does seem to be the case:
>
> source('rainfall-dubois-crk-all.r')
> Error in source("rainfall-dubois-crk-all.r") :
>    rainfall-dubois-crk-all.r:25:7: unexpected '/'
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>            ^
>
>    Then I'll print to the cwd and move the files manually afterwards.
>
> Thanks,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @imin @ending from jimmy@h@rv@rd@edu  Thu Sep 13 23:13:04 2018
From: @imin @ending from jimmy@h@rv@rd@edu (Aimin Yan)
Date: Thu, 13 Sep 2018 17:13:04 -0400
Subject: [R] Change the position of label when using R package eulerr
Message-ID: <CAPz5e0rhBfCW9mkS6bpo9f6L-9VAaFZ24CuKvDs0LduWvKDdBw@mail.gmail.com>

I am using eulerr to get venn.
My code is like:

fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
"LAD&nonXL_MEF" = 541,
                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")

plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
= 1),alpha=0.7)

After I get the figure, I find the position of some  labels need to be
adjusted.

Does anyone has some idea about how to process this?


Thank you,

Aimin

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Fri Sep 14 09:57:33 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 14 Sep 2018 07:57:33 +0000
Subject: [R] [R-sig-Geo] Help with simple Map of US states with predefined
 regions Version 2 (Solved)
Message-ID: <SN6PR02MB50887A3625E768243B557564EA190@SN6PR02MB5088.namprd02.prod.outlook.com>

Good morning Don, I cannot thank you enough for your support and the trouble you went to.
I am novice useR and the only analyst in the shop asked to learn R and the demands are growing faster than my knowledge intake, lots of laughs!

Best regards

WHP

From: MacQueen, Don <macqueen1 at llnl.gov>
Sent: Thursday, September 13, 2018 4:41 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Help with simple Map of US states with predefined regions Version 2

I know this is not a complete solution -- and it's a very different approach -- but it should at least show you a way to reliably get states colored by region.
(I also left out Alaska and Hawaii, since the point here is how to color the regions)

require(sp)
require(rgdal)

## US Census Bureau Tiger file -- polygons of each US State
## try this URL for download
## https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2017&layergroup=States+%28and+equivalent%29<https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2017&layergroup=States+%28and+equivalent%29>

## unzip to working directory ( '.' )
ustf <- readOGR('.', 'tl_2017_us_state', stringsAsFactors=FALSE)

## note, the Tiger file includes 6 additional territories
dim(ustf)
## [1] 56 14

## get rid of the extra six territories (state.name<http://state.name> comes with R)
cus <- subset(ustf, NAME %in% state.name<http://state.name>)

## cheap rename
cus$state <- cus$NAME
cus$abb <- cus$STUSPS

## invent ridiculous groupings of states
cus$grp <- 'a'
cus$grp[11:20] <- 'b'
cus$grp[21:30] <- 'c'
cus$grp[31:40] <- 'd'
cus$grp[41:50] <- 'e'

## assign colors to the groups
cus$color <- 'red'
cus$color[cus$grp=='b'] <- 'green'
cus$color[cus$grp=='c'] <- 'blue'
cus$color[cus$grp=='d'] <- 'brown'
cus$color[cus$grp=='e'] <- 'cyan'

## exclude Alaska, Hawaii
cus <- subset(cus, !(state %in% c('Alaska','Hawaii')))

## get rid of extraneous variables (optional)
cus <- cus[ , c('state','REGION','abb', 'grp') ]

## plot colored by regions as defined in the Census Bureau Tiger file
plot(cus, col=cus$REGION, usePolypath=FALSE)

## color "1" is black, looks bad, do this instead
plot(cus, col=as.numeric(cus$REGION)+1, usePolypath=FALSE)
text(coordinates(cus), cus$abb, col='white', cex=0.75)

## colors specified by a color variable in the data
plot(cus, col=cus$color, usePolypath=FALSE)
text(coordinates(cus), cus$abb, col='white', cex=0.75)

(my preferred graphics device does not support Polypath, but probably most others do, so one can omit usePolypath=FALSE)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



?On 9/13/18, 5:17 AM, "R-sig-Geo on behalf of Bill Poling" <r-sig-geo-bounces at r-project.org on behalf of Bill.Poling at zelis.com<mailto:r-sig-geo-bounces at r-project.org%20on%20behalf%20of%20Bill.Poling at zelis.com>> wrote:

Hi,

I hope someone can help me finalize this please.

I am coming close to what I need using variations from two ggplot2 tutorials.

This first gives me the map of the US with AK & HI but I cannot figure out how to get my 5 regions colored

#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1<https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1>


library(ggplot2)
install.packages("ggalt")
library(ggalt) # coord_proj
library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
install.packages("ggthemes")
library(ggthemes) # theme_map
install.packages("rgeos")
library(rgeos) # centroids
library(dplyr)

# composite map with AK & HI
usa_map <- usa_composite()

# calculate the centroids for each state gCentroid(usa_map, byid=TRUE) %>%
as.data.frame() %>%
mutate(state=usa_map at data$iso_3166_2) -> centroids

# make it usable in ggplot2
usa_map <- fortify(usa_map)

View(usa_map)
t1 <- head(usa_map,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))

#

# |long |lat | group| order| region|subregion |
# |:---------|:--------|-----:|-----:|-------:|:---------|
# |-87.46201 |30.38968 | 1| 1| alabama|NA |
# |-87.48493 |30.37249 | 1| 2| alabama|NA |
# |-87.52503 |30.37249 | 1| 3| alabama|NA |
# |-87.53076 |30.33239 | 1| 4| alabama|NA |
# |-87.57087 |30.32665 | 1| 5| alabama|NA |

usa_map <- fortify(usa_map)
gg <- ggplot()
gg <- gg + geom_map(data=usa_map, map=usa_map,
aes(long, lat, map_id=id),
color="#2b2b2b", size=0.1, fill=NA)

gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2) gg <- gg + coord_proj(us_laea_proj) gg <- gg + theme_map() gg




#************************************************************************************************************************************************************************************/

This second is an alternative (however not liking AK&HI, not coming into the map like scenario one above) but also ignoring new Mexico (because recognizing a seventh field value) and I suspect it will do the same for new York and new jersey etc.. when I add them to the list.

Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec, : line 12 did not have 6 elements

When I use newmexico (all one word) it appears white in the map like the other states not in the table statement

#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors<https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors>

library(ggplot2)

read.table(text="State.Code region St_Abbr Num_Estab colors
1 1 alaska Ak 13123 #f7931e
3 1 arizona AZ 18053 #f7931e
5 1 california CA 143937 #f7931e
2 1 hawaii HI 123456 #f7931e
4 1 nevada NV 654321 #f7931e
6 1 oregon OR 321456 #f7931e
7 1 washington WA 456123 #f7931e
8 2 colorado CO 987654 #787878
9 2 idaho ID 13549 #787878
10 2 kansas KS 94531 #787878
11 2 montana MT 456321 #787878
12 2 new mexico NM 582310 #787878 <---Not liking new mexico, saying not 6
13 2 oklahoma OK 214567 #787878
14 2 texas TX 675421 #787878
15 2 utah UT 754321 #787878
16 2 wyoming WY 543124 #787878 ",
stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df

usa_map1 <- map_data("state")
t1 <- head(usa_map1,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
View(usa_map1)
#
# |long |lat | group| order| region|subregion |
# |:---------|:--------|-----:|-----:|-------:|:---------|
# |-87.46201 |30.38968 | 1| 1| alabama|NA |
# |-87.48493 |30.37249 | 1| 2| alabama|NA |
# |-87.52503 |30.37249 | 1| 3| alabama|NA |
# |-87.53076 |30.33239 | 1| 4| alabama|NA |
# |-87.57087 |30.32665 | 1| 5| alabama|NA |



gg <- ggplot()
#View(gg)
gg <- gg + geom_map(data=usa_map1, map=usa_map1,
aes(long, lat, map_id=region),
color="#2b2b2b", size=0.15, fill=NA)

gg <- gg + geom_map(data=df, map=usa_map1,
aes(fill=colors, map_id=region),
color="#2b2b2b", size=0.15)


gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2) gg <- gg + coord_proj(us_laea_proj) gg <- gg + theme_map() gg


gg <- gg + scale_color_identity()
gg <- gg + coord_map("polyconic")
gg <- gg + ggthemes::theme_map()
gg

#c( "colorado", "idaho", "kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") ) #c("alaska", "arizona", "california", "hawaii", "nevada", "oregon","washington"))



William H. Poling, Ph.D., MPH




Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>


Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From jeremieju@te @ending from gm@il@com  Fri Sep 14 10:33:53 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Fri, 14 Sep 2018 10:33:53 +0200
Subject: [R] modify the supposed return value of a function during
 evaluation?
Message-ID: <871s9wpjf2.fsf@gmail.com>


Hello,

I'm wondering it is possible and if yes would it be desirable to modify
the return value of functions during evaluation.

I supposed this would be very useful during debugging

myfun <- function(x) {res <- x+3 ; browser()  ; res}

let say I run the following function myfun(3)  and drop in the browser. I then happened to notice that I should 
multiply <x> by 3 instead of adding. I was thinking to do return(x*3)
but the return value is still 6.

> myfun(3)
Called from: myfun(3)
Browse[1]> 
debug at #1: res
Browse[2]> return(3*3)
[1] 6
> 


This feature could be valuable if the following setting

function(){
        tmp_res <- time_consuming_function_with_browser(param)

         some_other_function(tmp_res)
                
}

Best regards,

Jeremie


From r@turner @ending from @uckl@nd@@c@nz  Fri Sep 14 10:56:40 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Fri, 14 Sep 2018 20:56:40 +1200
Subject: [R] 
 [FORGED] modify the supposed return value of a function during
 evaluation?
In-Reply-To: <871s9wpjf2.fsf@gmail.com>
References: <871s9wpjf2.fsf@gmail.com>
Message-ID: <81071a7b-5feb-8eed-1657-cc5bbbab9ee3@auckland.ac.nz>

On 09/14/2018 08:33 PM, Jeremie Juste wrote:
> 
> Hello,
> 
> I'm wondering it is possible and if yes would it be desirable to modify
> the return value of functions during evaluation.
> 
> I supposed this would be very useful during debugging
> 
> myfun <- function(x) {res <- x+3 ; browser()  ; res}
> 
> let say I run the following function myfun(3)  and drop in the browser. I then happened to notice that I should
> multiply <x> by 3 instead of adding. I was thinking to do return(x*3)
> but the return value is still 6.
> 
>> myfun(3)
> Called from: myfun(3)
> Browse[1]>
> debug at #1: res
> Browse[2]> return(3*3)
> [1] 6

Don't use return().  Change the value of "res" and then "continue".
Browse[1]> res <- x*3
Browse[1]> c

You will get the value 9 returned by "myfun(3)".  (God how I hate this 
stupid egocentric sounding "mythis" and "mythat" syntax that Micro$oft 
has inflicted upon the world. But never mind.)

I am however very sure that your proposed approach is Not A Good Idea.

If you want an interactive structure for your function, make it 
interactive. In a well thought out and well organised manner.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ktitcombe02 @ending from gm@il@com  Fri Sep 14 10:02:01 2018
From: ktitcombe02 @ending from gm@il@com (Kim Titcombe)
Date: Fri, 14 Sep 2018 10:02:01 +0200
Subject: [R] Help with setting locale
Message-ID: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>

*Query or Set Aspects of the Locale*

 I have an issue with setting LOCALE in installation (new  installation on
new computer but have installed and used R before).

I am based in Switzerland but work in English (Windows in English), hence
want English as default.

Console contains following message:

# During startup - Warning message:

# Setting LC_CTYPE= failed

-------------------------------------------------

Solutions I tried found on ?help? and in R manual as follows?.

# Sys.getlocale(category = ?LC_ALL?)

1]
"LC_COLLATE=English_Switzerland.65001;LC_CTYPE=C;LC_MONETARY=English_Switzerland.65001;LC_NUMERIC=C;LC_TIME=English_Switzerland.65001"

# Sys.setlocale(category=?LC_ALL?, locale = ? ?)

or

# Sys.setlocale(category=?LC_ALL?, local=?Switzerland.65001?)

Output

# OS reports request to set locale to "Switzerland.65001" cannot be honoured

Tried various commands specific for 'LC_CTYPE' (as this is where
installation failed) for language string such as

# Sys.setlocale("LC_CTYPE","en-GB")

Output:

In Sys.setlocale("LC_CTYPE", "en-GB") :

  OS reports request to set locale to "en-GB" cannot be honoured

Would anyone have any further suggestions for correct command.

With thanks

	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Fri Sep 14 14:35:42 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Fri, 14 Sep 2018 12:35:42 +0000
Subject: [R] Problem with lm.resid() when weights are provided
In-Reply-To: <22333_1536669565_w8BCdOUV005487_CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>
References: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
 <22333_1536669565_w8BCdOUV005487_CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368B0E61@FHSDB2D11-2.csu.mcmaster.ca>

Dear Hamed,

I don't think that anyone has picked up on this problem.

What's peculiar about your weights is that several are 0 within rounding error but not exactly 0:

> head(df)
           y          x       weight
1  1.5115614  0.5520924 2.117337e-34
2 -0.6365313 -0.1259932 2.117337e-34
3  0.3778278  0.4209538 4.934135e-31
4  3.0379232  1.4031545 2.679495e-24
5  1.5364652  0.4607686 2.679495e-24
6 -2.3772787 -0.7396358 6.244160e-21

I can reproduce the results that you report:

> (mod.1 <- lm(y ~ x, data=df))

Call:
lm(formula = y ~ x, data = df)

Coefficients:
(Intercept)            x  
   -0.04173      2.03790  

> max(resid(mod.1))
[1] 1.14046
> (mod.2 <- lm(y ~ x, data=df, weights=weight))

Call:
lm(formula = y ~ x, data = df, weights = weight)

Coefficients:
(Intercept)            x  
   -0.05786      1.96087  

> max(resid(mod.2))
[1] 36.84939

But the problem disappears when the tiny nonzero weight are set to 0:

> df2 <- df
> df2$weight <- zapsmall(df2$weight)
> head(df2)
           y          x weight
1  1.5115614  0.5520924      0
2 -0.6365313 -0.1259932      0
3  0.3778278  0.4209538      0
4  3.0379232  1.4031545      0
5  1.5364652  0.4607686      0
6 -2.3772787 -0.7396358      0
> (mod.3 <- update(mod.2, data=df2))

Call:
lm(formula = y ~ x, data = df2, weights = weight)

Coefficients:
(Intercept)            x  
   -0.05786      1.96087  

> max(resid(mod.3))
[1] 1.146663

I don't know exactly why this happens, but suspect numerical instability produced by the near-zero weights, which are smaller than the machine double-epsilon

> .Machine$double.neg.eps
[1] 1.110223e-16

The problem also disappears, e.g., if the tiny weight are set to 1e-15 rather than 0.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Hamed Ha
> Sent: Tuesday, September 11, 2018 8:39 AM
> To: r-help at r-project.org
> Subject: [R] Problem with lm.resid() when weights are provided
> 
> Dear R Help Team.
> 
> I get some weird results when I use the lm function with weight. The issue can
> be reproduced by the example below:
> 
> 
> The input data is (weights are intentionally designed to reflect some
> structures in the data)
> 
> 
> > df
> y x weight
>  1.51156139  0.55209240 2.117337e-34
> -0.63653132 -0.12599316 2.117337e-34
>  0.37782776  0.42095384 4.934135e-31
>  3.03792318  1.40315446 2.679495e-24
>  1.53646523  0.46076858 2.679495e-24
> -2.37727874 -0.73963576 6.244160e-21
>  0.37183065  0.20407468 1.455107e-17
> -1.53917553 -0.95519361 1.455107e-17
>  1.10926675  0.03897129 3.390908e-14
> -0.37786333 -0.17523593 3.390908e-14
>  2.43973603  0.97970095 7.902000e-11
> -0.35432394 -0.03742559 7.902000e-11
>  2.19296613  1.00355263 4.289362e-04
>  0.49845532  0.34816207 4.289362e-04
>  1.25005260  0.76306225 5.000000e-01
>  0.84360691  0.45152356 5.000000e-01
>  0.29565993  0.53880068 5.000000e-01
> -0.54081334 -0.28104525 5.000000e-01
>  0.83612836 -0.12885659 9.995711e-01
> -1.42526769 -0.87107631 9.999998e-01
>  0.10204789 -0.11649899 1.000000e+00
>  1.14292898  0.37249631 1.000000e+00
> -3.02942081 -1.28966997 1.000000e+00
> -1.37549764 -0.74676145 1.000000e+00
> -2.00118016 -0.55182759 1.000000e+00
> -4.24441674 -1.94603608 1.000000e+00
>  1.17168144  1.00868008 1.000000e+00
>  2.64007761  1.26333069 1.000000e+00
>  1.98550114  1.18509599 1.000000e+00
> -0.58941683 -0.61972416 9.999998e-01
> -4.57559611 -2.30914920 9.995711e-01
> -0.82610544 -0.39347576 9.995711e-01
> -0.02768220  0.20076910 9.995711e-01
>  0.78186399  0.25690215 9.995711e-01
> -0.88314153 -0.20200148 5.000000e-01
> -4.17076452 -2.03547588 5.000000e-01
>  0.93373070  0.54190626 4.289362e-04
> -0.08517734  0.17692491 4.289362e-04
> -4.47546619 -2.14876688 4.289362e-04
> -1.65509103 -0.76898087 4.289362e-04
> -0.39403030 -0.12689705 4.289362e-04
>  0.01203300 -0.18689898 1.841442e-07
> -4.82762639 -2.31391121 1.841442e-07
> -0.72658380 -0.39751171 3.397282e-14
> -2.35886866 -1.01082109 0.000000e+00
> -2.03762707 -0.96439902 0.000000e+00
>  0.90115123  0.60172286 0.000000e+00
>  1.55999194  0.83433953 0.000000e+00
>  3.07994058  1.30942776 0.000000e+00
>  1.78871462  1.10605530 0.000000e+00
> 
> 
> 
> Running simple linear model returns:
> 
> > lm(y~x,data=df)
> 
> Call:
> lm(formula = y ~ x, data = df)
> 
> Coefficients:
> (Intercept)            x
>    -0.04173      2.03790
> 
> and
> > max(resid(lm(y~x,data=df)))
> [1] 1.14046
> 
> 
> *HOWEVER if I use the weighted model then:*
> 
> lm(formula = y ~ x, data = df, weights = df$weights)
> 
> Coefficients:
> (Intercept)            x
>    -0.05786      1.96087
> 
> and
> > max(resid(lm(y~x,data=df,weights=df$weights)))
> [1] 60.91888
> 
> 
> as you see, the estimation of the coefficients are nearly the same but the
> resid() function returns a giant residual (I have some cases where the value is
> much much higher). Further, if I calculate the residuals by simply
> predict(lm(y~x,data=df,weights=df$weights))-df$y then I get the true value for
> the residuals.
> 
> 
> Thanks.
> 
> Please do not hesitate to contact me for more details.
> Regards,
> Hamed.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 14:38:34 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 05:38:34 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <CAGxFJbSbXoqL6df3qFqu5uyEsYLze2EvDj=Qv-BEYzQdWqviGw@mail.gmail.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
 <CAGxFJbSbXoqL6df3qFqu5uyEsYLze2EvDj=Qv-BEYzQdWqviGw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809140532490.27826@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Bert Gunter wrote:

> I find your "explanation" confusing. You appear to be misusing print().
> Please read ?print carefully. You print objects in R, not files. Objects
> in R do not have "/" in their names (without some trickery). See
> ?make.names .

Bert,

   I had read both ?print and ?print.default looking for information about
placing the printed object in another directory, and found nothing.

   My initial assumption was that print() worked similar to plot(). I use
plot() after specifying a pdf file as output and thought that sink() (which
?sink tells me diverts R output to a connection (and stops it as dev.off
stops writing to the pdf file). That sink() apparently does not work the
same way is why I posted my question.

Regards,

Rich


From j@orkin @ending from @om@um@ryl@nd@edu  Fri Sep 14 16:01:24 2018
From: j@orkin @ending from @om@um@ryl@nd@edu (Sorkin, John)
Date: Fri, 14 Sep 2018 14:01:24 +0000
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809140532490.27826@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
 <CAGxFJbSbXoqL6df3qFqu5uyEsYLze2EvDj=Qv-BEYzQdWqviGw@mail.gmail.com>,
 <alpine.LNX.2.20.1809140532490.27826@salmo.appl-ecosys.com>
Message-ID: <CO2PR03MB22326B3617E42ACA09200BAFE2190@CO2PR03MB2232.namprd03.prod.outlook.com>

As has been pointed out, the correct way to direct printing to a given location is using sink( . . . put path here . . . ) then print() and then sink() without any argument to turn off print direction. A helpful addition to this strategy is to use the file.path function to define a variable that specifies the path, i.e.


path <- file.path( . . . specify path here, see documentation of file.path . . .)

sink(path)

print(. . . an R object . . .)

sink()

The nice feature about using file.path is that it by default it formats the path correctly for the OS on which you are running R; paths are specified differently (i.e. use of slashes vs. back slashes) when using Linux vs. windows systems. Note that when specifying the path using file.path rather than having to format the path according to the dictates of your OS, all you need to do is to specify the elements of the path

path <- file.path("data",''FIPSstudy","exercisetests"). The result will be a character string that is formatted properly for your OS.


John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Rich Shepard <rshepard at appl-ecosys.com>
Sent: Friday, September 14, 2018 8:38 AM
To: R-help
Subject: Re: [R] sink() output to another directory

CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.



On Thu, 13 Sep 2018, Bert Gunter wrote:

> I find your "explanation" confusing. You appear to be misusing print().
> Please read ?print carefully. You print objects in R, not files. Objects
> in R do not have "/" in their names (without some trickery). See
> ?make.names .

Bert,

   I had read both ?print and ?print.default looking for information about
placing the printed object in another directory, and found nothing.

   My initial assumption was that print() worked similar to plot(). I use
plot() after specifying a pdf file as output and thought that sink() (which
?sink tells me diverts R output to a connection (and stops it as dev.off
stops writing to the pdf file). That sink() apparently does not work the
same way is why I posted my question.

Regards,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 16:05:21 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 07:05:21 -0700 (PDT)
Subject: [R] sink() output to another directory [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809140659210.27826@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Rich Shepard wrote:

>  sink('stat-summary/example-output.txt')
>  print(summary(df))
>  sink()

   My apologies to everyone for not seeing a typo further in the script.

   I had the path to the appropriate directory in the sink() function and the
print() function had only the command as above. Except for one dataframe. In
that one I had stuck a '/' in front of the summary() function and that
caused the problem.

   I just found an R equivalent to lint to find such syntactical errors before I
embarrass myself again. Has anyone used lintr from github? I will definitely
start using this on my scripts.

Mea culpa,

Rich


From krylov@r00t @ending from gm@il@com  Fri Sep 14 16:11:10 2018
From: krylov@r00t @ending from gm@il@com (Ivan Krylov)
Date: Fri, 14 Sep 2018 17:11:10 +0300
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
Message-ID: <20180914171110.464d61d3@trisector>

? Thu, 13 Sep 2018 15:49:52 -0700 (PDT)
Rich Shepard <rshepard at appl-ecosys.com> ?????:

> sink('stat-summaries/estacada-wnw-precip.txt')
> print(/summary(estacada_wnw_wx))
> sink()

Just remove the slash from your print command (line 25 of
rainfall-dubois-crk-all.r) because it's a syntax error (must be a typo).
I.e. the above should be print(summary(estacada_wnw_wx)), not
print(/summary(estacada_wnw_wx)) (do you notice the difference?). The
rest of your sequence of commands is fine.

-- 
Best regards,
Ivan


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 16:19:16 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 07:19:16 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <20180914171110.464d61d3@trisector>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <20180914171110.464d61d3@trisector>
Message-ID: <alpine.LNX.2.20.1809140717360.27826@salmo.appl-ecosys.com>

On Fri, 14 Sep 2018, Ivan Krylov wrote:

> Just remove the slash from your print command (line 25 of
> rainfall-dubois-crk-all.r) because it's a syntax error (must be a typo).
> I.e. the above should be print(summary(estacada_wnw_wx)), not
> print(/summary(estacada_wnw_wx)) (do you notice the difference?). The rest
> of your sequence of commands is fine.

Ivan,

   Yes, it was and I did not see it each time I looked at the code, ignoring
the error message point me to it.

   I've now installed lintr and will use that on all my scripts before I run
them.

Regards,

Rich


From motyoc@k@ @ending from y@hoo@com  Fri Sep 14 16:19:53 2018
From: motyoc@k@ @ending from y@hoo@com (Andras Farkas)
Date: Fri, 14 Sep 2018 14:19:53 +0000 (UTC)
Subject: [R] ddply (or other suitable solution) question
In-Reply-To: <CAGxFJbQYwJwdarhdrgs=Gs28n6E84GysZGcs3ny3hweLE=cj-g@mail.gmail.com>
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
 <1075990829.2369338.1536865881254@mail.yahoo.com>
 <CAGxFJbSxu7KKy2hzYKUtq54fp+farc4S0fdzFWw5BwkTb+3ULQ@mail.gmail.com>
 <CAGxFJbQYwJwdarhdrgs=Gs28n6E84GysZGcs3ny3hweLE=cj-g@mail.gmail.com>
Message-ID: <955022905.4938494.1536934793945@mail.yahoo.com>

thank you all, Bert's idea will get it done... good question also re what if 1 row: have a separate plan for that... Anyhow, finishing up Bert's lines with?
z<-lapply(ix, function(i)? ?df[i,])
lapply(z, function(x) split(x, rep(1:ceiling(nrow(x)/2), each=2)[1:nrow(x)]))


seems to do what I need,
thanks again...

Andras? 

    On Thursday, September 13, 2018, 5:16:54 PM EDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:  
 
 Mod my earlier question, it seems that you just want to replicate all
rows within an id if there more than 2 rows. If this is incorrect,
ignore the rest of this post.

Otherwise...

(I assume the data frame is listed in ID order, whatever that is)

set.seed(123.456)
df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
? ? ? ? ? ? ? ? read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
? ? ? ? ? ? ? ? int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
? ? ? ? ? ? ? ? z=rnorm(13,1,5),
? ? ? ? ? ? ? ? y=rnorm(13,1,5))

yielded on my Mac and R version 3.5.1

> df
? ID read int? ? ? ? ? z? ? ? ? ? y
1? 1? ? 1? 1 -1.8023782? 1.55341358
2? 1? ? 1? 1 -0.1508874 -1.77920567
3? 2? ? 0? 0? 8.7935416? 9.93456568
4? 2? ? 1? 0? 1.3525420? 3.48925239
5? 2? ? 1? 0? 1.6464387 -8.83308578
6? 3? ? 1? 1? 9.5753249? 4.50677951
7? 3? ? 0? 1? 3.3045810 -1.36395704
8? 3? ? 0? 0 -5.3253062 -4.33911853
9? 3? ? 0? 0 -2.4342643 -0.08987457
10? 4? ? 1? 1 -1.2283099 -4.13002224
11? 4? ? 0? 1? 7.1204090 -2.64445615
12? 5? ? 0? 1? 2.7990691 -2.12519634
13? 5? ? 0? 1? 3.0038573 -7.43346655

## The following doubles up the rows by ID
> ix <- tapply(seq_len(nrow(df)),df$ID,
+? ? ? ? ? ? ? function(x){
+? ? ? ? ? ? ? ? lenx <- length(x)
+? ? ? ? ? ? ? ? if(lenx > 2)
+? ? ? ? ? ? ? ? ? ? c(x[1],rep(x[2]:x[lenx-1],e=2),x[lenx])
+? ? ? ? ? ? ? ? else x
+? ? ? ? ? ? ? }
+? ? )
> ix
$`1`
[1] 1 2

$`2`
[1] 3 4 4 5

$`3`
[1] 6 7 7 8 8 9

$`4`
[1] 10 11

$`5`
[1] 12 13

## now use the ix list to break up df:

> lapply(ix, function(i)df[i,])
$`1`
? ID read int? ? ? ? ? z? ? ? ? y
1? 1? ? 1? 1 -1.8023782? 1.553414
2? 1? ? 1? 1 -0.1508874 -1.779206

$`2`
? ? ID read int? ? ? ? z? ? ? ? y
3? ? 2? ? 0? 0 8.793542? 9.934566
4? ? 2? ? 1? 0 1.352542? 3.489252
4.1? 2? ? 1? 0 1.352542? 3.489252
5? ? 2? ? 1? 0 1.646439 -8.833086

$`3`
? ? ID read int? ? ? ? z? ? ? ? ? y
6? ? 3? ? 1? 1? 9.575325? 4.50677951
7? ? 3? ? 0? 1? 3.304581 -1.36395704
7.1? 3? ? 0? 1? 3.304581 -1.36395704
8? ? 3? ? 0? 0 -5.325306 -4.33911853
8.1? 3? ? 0? 0 -5.325306 -4.33911853
9? ? 3? ? 0? 0 -2.434264 -0.08987457

$`4`
? ID read int? ? ? ? z? ? ? ? y
10? 4? ? 1? 1 -1.228310 -4.130022
11? 4? ? 0? 1? 7.120409 -2.644456

$`5`
? ID read int? ? ? ? z? ? ? ? y
12? 5? ? 0? 1 2.799069 -2.125196
13? 5? ? 0? 1 3.003857 -7.433467

I leave it to you to modify the lapply() function to break up each id
data frame into sublists of pairs if that is what you wish to do.
Assuming again that this is actually what you want.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Thu, Sep 13, 2018 at 1:40 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> What if there is only one read in the id?
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 13, 2018 at 12:11 PM Andras Farkas via R-help
> <r-help at r-project.org> wrote:
> >
> > Dear All,
> >
> > I have data frame:
> > set.seed(123.456)
> > df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
> >? ? ? ? ? ? ? ? read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
> >? ? ? ? ? ? ? ? int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
> >? ? ? ? ? ? ? ? z=rnorm(13,1,5),
> >? ? ? ? ? ? ? ? y=rnorm(13,1,5))
> >
> > what I would like to achieve (as best as I see it now) is to create multiple lists (and lists within lists using the data in df) that would be based on the groups in the ID column ("top level of list") and "join together" each line item within the group followed by the next line item ("bottom level list"), so would look like this for
> >
> > [[ID=1]]
> > [[1]][[1]]
> >? ID read int? ? ? ? z? ? ? ? y
> >? 1? ? 1? 1 5.188935 5.107905
> >? 1? ? 1? 1 1.766866 4.443201
> > [[ID=2]]
> > [[2]][[1]]? ID read int? ? ? ? z? ? ? ? y
> >? 2? ? 0? 0 -4.690685 3.7695883
> >? 2? ? 1? 0? 7.269075 0.6904414[[ID=2]]
> > [[2]][[2]]? ID read int? ? ? ? z? ? ? ? ? y
> >? 2? ? 1? 0 7.269075? 0.6904414
> >? 2? ? 1? 0 3.132321 -0.5298133[[ID=3]]
> > [[3]][[1]]? ID read int? ? ? ? ? z? ? ? ? y
> >? 3? ? 1? 1 -0.4753574 -0.902355
> >? 3? ? 0? 1? 5.4756283 -2.473535
> > [[ID=3]]
> > [[3]][[2]]
> >? 3? ? 0? 1 5.475628 -2.47353489
> >? 3? ? 0? 0 5.390667 -0.03958639
> >
> >
> > hoping example clear enough... all our help is appreciated,
> >
> > thanks,
> >
> >
> >
> > Andras
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Sep 14 16:36:17 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 14 Sep 2018 07:36:17 -0700
Subject: [R] Question on Binom.Confint
In-Reply-To: <25d985786e3c428ab38f1e4fbb977b86@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <CAGxFJbQGbPhj0sRSqVjGOkPXoM_NoAHeE6n1WsMbxUFJpaTu9w@mail.gmail.com>
 <25d985786e3c428ab38f1e4fbb977b86@CRCOEXCH2.cornerstone.com>
Message-ID: <CAGxFJbTrkQNjouUFEZ9FJm++XO27t9ghEifhQcq87tbMv2++kg@mail.gmail.com>

Then it's binom.confint (case matters in R -- PLEASE DO A TUTORIAL OR
TWO!) and there is no "lrt"  option. So no idea what you're referring
to.

-- Bert


On Fri, Sep 14, 2018 at 6:53 AM Guo, Fang (Associate)
<FAGuo at cornerstone.com> wrote:
>
> I used library(binom).
>
> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Thursday, September 13, 2018 10:04 PM
> To: Guo, Fang (Associate) <FAGuo at cornerstone.com>
> Cc: r-help-request at r-project.org; R-help <r-help at r-project.org>
> Subject: Re: [R] Question on Binom.Confint
>
> In what package?
> Binomial confidence interval functions are in several.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 13, 2018 at 6:38 PM Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
> >
> > Hi,
> >
> > I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
> >
> >
> > Fang Guo
> > Associate
> >
> > CORNERSTONE RESEARCH
> > 699 Boylston Street, 5th Floor
> > Boston, MA 02116-2836
> > 617.927.3042 direct
> > faguo at cornerstone.com<mailto:faguo at cornerstone.com>
> >
> > www.cornerstone.com<http://www.cornerstone.com/>
> >
> >
> > ***********************************************************
> > Warning: This email may contain confidential or privileged information
> > intended only for the use of the individual or entity to whom it is
> > addressed. If you are not the intended recipient, please understand
> > that any disclosure, copying, distribution, or use of the contents of
> > this email is strictly prohibited.
> > ***********************************************************
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand
> that any disclosure, copying, distribution, or use of the contents
> of this email is strictly prohibited.
> ***********************************************************


From FAGuo @ending from corner@tone@com  Fri Sep 14 15:52:15 2018
From: FAGuo @ending from corner@tone@com (Guo, Fang (Associate))
Date: Fri, 14 Sep 2018 13:52:15 +0000
Subject: [R] [FORGED]  Question on Binom.Confint
In-Reply-To: <b1545005-4871-177d-ac0d-6aed93a5a3f8@auckland.ac.nz>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <b1545005-4871-177d-ac0d-6aed93a5a3f8@auckland.ac.nz>
Message-ID: <d8ee54b0b44d43e6915750bef37ef2bc@CRCOEXCH2.cornerstone.com>

It's method="lrt" and I used the "binom" package.

-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz] 
Sent: Thursday, September 13, 2018 10:02 PM
To: Guo, Fang (Associate) <FAGuo at cornerstone.com>
Cc: r-help at R-project.org
Subject: Re: [FORGED] [R] Question on Binom.Confint


On 09/14/2018 08:15 AM, Guo, Fang (Associate) wrote:

> Hi,
> 
> I have a question with the function Binom.Confint(x,n,"method"=lrt).
> For likelihood ratio test, I'd like to ask how you define the upper 
> limit when the frequency of successes is zero. Thanks!

Point 1:  This question is inappropriate for this list, since it is about statistical theory and not about R syntax and programming.

Point 2: Where did you find the function Binom.Confint()?  I can find no such function anywhere.  I did manage to locate a function
binom.confint() (note the lower case "b" and "c") but it does not have an argument "method".  Please do not expect those whom you are addressing to be telepathic.

Point 3:  Having "method"=lrt in the call is decidedly weird.  Perhaps you meant method="lrt"; this is entirely different.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
***********************************************************
Warning: This email may contain confidential or privileged information
intended only for the use of the individual or entity to whom it is
addressed. If you are not the intended recipient, please understand 
that any disclosure, copying, distribution, or use of the contents 
of this email is strictly prohibited.
***********************************************************

From FAGuo @ending from corner@tone@com  Fri Sep 14 15:53:05 2018
From: FAGuo @ending from corner@tone@com (Guo, Fang (Associate))
Date: Fri, 14 Sep 2018 13:53:05 +0000
Subject: [R] Question on Binom.Confint
In-Reply-To: <CAGxFJbQGbPhj0sRSqVjGOkPXoM_NoAHeE6n1WsMbxUFJpaTu9w@mail.gmail.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <CAGxFJbQGbPhj0sRSqVjGOkPXoM_NoAHeE6n1WsMbxUFJpaTu9w@mail.gmail.com>
Message-ID: <25d985786e3c428ab38f1e4fbb977b86@CRCOEXCH2.cornerstone.com>

I used library(binom). 

-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Thursday, September 13, 2018 10:04 PM
To: Guo, Fang (Associate) <FAGuo at cornerstone.com>
Cc: r-help-request at r-project.org; R-help <r-help at r-project.org>
Subject: Re: [R] Question on Binom.Confint

In what package?
Binomial confidence interval functions are in several.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 13, 2018 at 6:38 PM Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
>
> Hi,
>
> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
>
>
> Fang Guo
> Associate
>
> CORNERSTONE RESEARCH
> 699 Boylston Street, 5th Floor
> Boston, MA 02116-2836
> 617.927.3042 direct
> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
>
> www.cornerstone.com<http://www.cornerstone.com/>
>
>
> ***********************************************************
> Warning: This email may contain confidential or privileged information 
> intended only for the use of the individual or entity to whom it is 
> addressed. If you are not the intended recipient, please understand 
> that any disclosure, copying, distribution, or use of the contents of 
> this email is strictly prohibited.
> ***********************************************************
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
***********************************************************
Warning: This email may contain confidential or privileged information
intended only for the use of the individual or entity to whom it is
addressed. If you are not the intended recipient, please understand 
that any disclosure, copying, distribution, or use of the contents 
of this email is strictly prohibited.
***********************************************************

From FAGuo @ending from corner@tone@com  Fri Sep 14 17:04:21 2018
From: FAGuo @ending from corner@tone@com (Guo, Fang (Associate))
Date: Fri, 14 Sep 2018 15:04:21 +0000
Subject: [R] Question on Binom.Confint
In-Reply-To: <CA+8X3fUbws98+JWq5YOeEbTVjO-00TN7UKcdccMxHAzxi8H=fw@mail.gmail.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <CA+8X3fUbws98+JWq5YOeEbTVjO-00TN7UKcdccMxHAzxi8H=fw@mail.gmail.com>
Message-ID: <8e5f599f81dd4754a8bf03707fe8331f@CRCOEXCH2.cornerstone.com>

I did use library(binom). However, I was able to use the method "lrt" which is short for likelihood ratio test. 
-----Original Message-----
From: Jim Lemon [mailto:drjimlemon at gmail.com] 
Sent: Thursday, September 13, 2018 11:50 PM
To: Guo, Fang (Associate) <FAGuo at cornerstone.com>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Question on Binom.Confint

Hi Fang,
Let's assume that you are using the "binom.confint" function in the "binom" package and you have made a spelling mistake or two. This function employs nine methods for estimating the binomial confidence interval. Sadly, none of these is "lrt". The zero condition is discussed in the help page for four of these methods. Assuming you want to use another method, you will have to look up the method. A good start is:

https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval

Jim

On Fri, Sep 14, 2018 at 11:38 AM Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
>
> Hi,
>
> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
>
>
> Fang Guo
> Associate
>
> CORNERSTONE RESEARCH
> 699 Boylston Street, 5th Floor
> Boston, MA 02116-2836
> 617.927.3042 direct
> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
>
> www.cornerstone.com<http://www.cornerstone.com/>
>
>
> ***********************************************************
> Warning: This email may contain confidential or privileged information 
> intended only for the use of the individual or entity to whom it is 
> addressed. If you are not the intended recipient, please understand 
> that any disclosure, copying, distribution, or use of the contents of 
> this email is strictly prohibited.
> ***********************************************************
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
***********************************************************
Warning: This email may contain confidential or privileged information
intended only for the use of the individual or entity to whom it is
addressed. If you are not the intended recipient, please understand 
that any disclosure, copying, distribution, or use of the contents 
of this email is strictly prohibited.
***********************************************************

From dwin@emiu@ @ending from comc@@t@net  Fri Sep 14 17:44:56 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Fri, 14 Sep 2018 08:44:56 -0700
Subject: [R] Help with setting locale
In-Reply-To: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
References: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
Message-ID: <B5922BF1-1A5F-4748-A049-CFA87574FE65@comcast.net>


> On Sep 14, 2018, at 1:02 AM, Kim Titcombe <ktitcombe02 at gmail.com> wrote:
> 
> *Query or Set Aspects of the Locale*
> 
> I have an issue with setting LOCALE in installation (new  installation on
> new computer but have installed and used R before).
> 
> I am based in Switzerland but work in English (Windows in English), hence
> want English as default.
> 
> Console contains following message:
> 
> # During startup - Warning message:
> 
> # Setting LC_CTYPE= failed
> 
> -------------------------------------------------
> 
> Solutions I tried found on ?help? and in R manual as follows?.
> 
> # Sys.getlocale(category = ?LC_ALL?)
> 
> 1]
> "LC_COLLATE=English_Switzerland.65001;LC_CTYPE=C;LC_MONETARY=English_Switzerland.65001;LC_NUMERIC=C;LC_TIME=English_Switzerland.65001"
> 
> # Sys.setlocale(category=?LC_ALL?, locale = ? ?)
> 
> or
> 
> # Sys.setlocale(category=?LC_ALL?, local=?Switzerland.65001?)
> 
> Output
> 
> # OS reports request to set locale to "Switzerland.65001" cannot be honoured
> 
> Tried various commands specific for 'LC_CTYPE' (as this is where
> installation failed) for language string such as
> 
> # Sys.setlocale("LC_CTYPE","en-GB")

You may get better results with an underscore rather than a dash.

Try: 

Sys.setlocale("LC_CTYPE","en_GB")



On my machine you can get the acceptable locale strings with:

locales <- system("locale -a", intern = TRUE)
locales[ grep("GB",locales) ]  # Just the GB strings
[1] "en_GB"            "en_GB.ISO8859-1"  "en_GB.ISO8859-15" "en_GB.US-ASCII"   "en_GB.UTF-8"      "zh_CN.GB18030"    "zh_CN.GB2312"    
[8] "zh_CN.GBK"       



> 
> Output:
> 
> In Sys.setlocale("LC_CTYPE", "en-GB") :
> 
>  OS reports request to set locale to "en-GB" cannot be honoured
> 
> Would anyone have any further suggestions for correct command.
> 
> With thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dwin@emiu@ @ending from comc@@t@net  Fri Sep 14 17:51:19 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Fri, 14 Sep 2018 08:51:19 -0700
Subject: [R] Help with setting locale
In-Reply-To: <B5922BF1-1A5F-4748-A049-CFA87574FE65@comcast.net>
References: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
 <B5922BF1-1A5F-4748-A049-CFA87574FE65@comcast.net>
Message-ID: <402B2D9C-F4FD-42A1-88C0-81A001B9E4A4@comcast.net>


> On Sep 14, 2018, at 8:44 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Sep 14, 2018, at 1:02 AM, Kim Titcombe <ktitcombe02 at gmail.com> wrote:
>> 
>> *Query or Set Aspects of the Locale*
>> 
>> I have an issue with setting LOCALE in installation (new  installation on
>> new computer but have installed and used R before).
>> 
>> I am based in Switzerland but work in English (Windows in English), hence
>> want English as default.
>> 
>> Console contains following message:
>> 
>> # During startup - Warning message:
>> 
>> # Setting LC_CTYPE= failed
>> 
>> -------------------------------------------------
>> 
>> Solutions I tried found on ?help? and in R manual as follows?.
>> 
>> # Sys.getlocale(category = ?LC_ALL?)
>> 
>> 1]
>> "LC_COLLATE=English_Switzerland.65001;LC_CTYPE=C;LC_MONETARY=English_Switzerland.65001;LC_NUMERIC=C;LC_TIME=English_Switzerland.65001"
>> 
>> # Sys.setlocale(category=?LC_ALL?, locale = ? ?)
>> 
>> or
>> 
>> # Sys.setlocale(category=?LC_ALL?, local=?Switzerland.65001?)
>> 
>> Output
>> 
>> # OS reports request to set locale to "Switzerland.65001" cannot be honoured
>> 
>> Tried various commands specific for 'LC_CTYPE' (as this is where
>> installation failed) for language string such as
>> 
>> # Sys.setlocale("LC_CTYPE","en-GB")
> 
> You may get better results with an underscore rather than a dash.
> 
> Try: 
> 
> Sys.setlocale("LC_CTYPE","en_GB")
> 
> 
> 
> On my machine you can get the acceptable locale strings with:
> 
> locales <- system("locale -a", intern = TRUE)
> locales[ grep("GB",locales) ]  # Just the GB strings
> [1] "en_GB"            "en_GB.ISO8859-1"  "en_GB.ISO8859-15" "en_GB.US-ASCII"   "en_GB.UTF-8"      "zh_CN.GB18030"    "zh_CN.GB2312"    
> [8] "zh_CN.GBK"       

I should have admitted that I use a Mac. If you use Windoze, then consult the MS authorities for naming. Perhaps this page: https://docs.microsoft.com/en-us/windows/desktop/Intl/language-identifier-constants-and-strings , which suggests to me using 'UK' rather than 'GB' might be needed and 'ENGLISH' rather than 'en'.


> 
> 
> 
>> 
>> Output:
>> 
>> In Sys.setlocale("LC_CTYPE", "en-GB") :
>> 
>> OS reports request to set locale to "en-GB" cannot be honoured
>> 
>> Would anyone have any further suggestions for correct command.
>> 
>> With thanks
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From gor@n@bro@trom @ending from umu@@e  Fri Sep 14 17:52:49 2018
From: gor@n@bro@trom @ending from umu@@e (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Fri, 14 Sep 2018 17:52:49 +0200
Subject: [R] Question on Binom.Confint
In-Reply-To: <8e5f599f81dd4754a8bf03707fe8331f@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <CA+8X3fUbws98+JWq5YOeEbTVjO-00TN7UKcdccMxHAzxi8H=fw@mail.gmail.com>
 <8e5f599f81dd4754a8bf03707fe8331f@CRCOEXCH2.cornerstone.com>
Message-ID: <d92a8aba-0035-55ba-89b0-f78de3c15de6@umu.se>



On 2018-09-14 17:04, Guo, Fang (Associate) wrote:
> I did use library(binom). However, I was able to use the method "lrt" which is short for likelihood ratio test.

You are right, there is a method "lrt", but it is not mentioned in the 
documentation. (Look at the code.)

G?ran

> -----Original Message-----
> From: Jim Lemon [mailto:drjimlemon at gmail.com]
> Sent: Thursday, September 13, 2018 11:50 PM
> To: Guo, Fang (Associate) <FAGuo at cornerstone.com>; r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Question on Binom.Confint
> 
> Hi Fang,
> Let's assume that you are using the "binom.confint" function in the "binom" package and you have made a spelling mistake or two. This function employs nine methods for estimating the binomial confidence interval. Sadly, none of these is "lrt". The zero condition is discussed in the help page for four of these methods. Assuming you want to use another method, you will have to look up the method. A good start is:
> 
> https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval
> 
> Jim
> 
> On Fri, Sep 14, 2018 at 11:38 AM Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
>>
>> Hi,
>>
>> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
>>
>>
>> Fang Guo
>> Associate
>>
>> CORNERSTONE RESEARCH
>> 699 Boylston Street, 5th Floor
>> Boston, MA 02116-2836
>> 617.927.3042 direct
>> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
>>
>> www.cornerstone.com<http://www.cornerstone.com/>
>>
>>
>> ***********************************************************
>> Warning: This email may contain confidential or privileged information
>> intended only for the use of the individual or entity to whom it is
>> addressed. If you are not the intended recipient, please understand
>> that any disclosure, copying, distribution, or use of the contents of
>> this email is strictly prohibited.
>> ***********************************************************
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand
> that any disclosure, copying, distribution, or use of the contents
> of this email is strictly prohibited.
> ***********************************************************
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ktitcombe02 @ending from gm@il@com  Fri Sep 14 18:01:30 2018
From: ktitcombe02 @ending from gm@il@com (Kim Titcombe)
Date: Fri, 14 Sep 2018 18:01:30 +0200
Subject: [R] Help with setting locale
In-Reply-To: <402B2D9C-F4FD-42A1-88C0-81A001B9E4A4@comcast.net>
References: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
 <B5922BF1-1A5F-4748-A049-CFA87574FE65@comcast.net>
 <402B2D9C-F4FD-42A1-88C0-81A001B9E4A4@comcast.net>
Message-ID: <CAE9q8v=Hjx8e9NWjxrscHXci6S2eSTWnxy1e8HdRxmYtyNge0Q@mail.gmail.com>

Thanks for the tip!
Kim

On Fri, 14 Sep 2018, 17:51 David Winsemius, <dwinsemius at comcast.net> wrote:

>
> > On Sep 14, 2018, at 8:44 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >
> >> On Sep 14, 2018, at 1:02 AM, Kim Titcombe <ktitcombe02 at gmail.com>
> wrote:
> >>
> >> *Query or Set Aspects of the Locale*
> >>
> >> I have an issue with setting LOCALE in installation (new  installation
> on
> >> new computer but have installed and used R before).
> >>
> >> I am based in Switzerland but work in English (Windows in English),
> hence
> >> want English as default.
> >>
> >> Console contains following message:
> >>
> >> # During startup - Warning message:
> >>
> >> # Setting LC_CTYPE= failed
> >>
> >> -------------------------------------------------
> >>
> >> Solutions I tried found on ?help? and in R manual as follows?.
> >>
> >> # Sys.getlocale(category = ?LC_ALL?)
> >>
> >> 1]
> >>
> "LC_COLLATE=English_Switzerland.65001;LC_CTYPE=C;LC_MONETARY=English_Switzerland.65001;LC_NUMERIC=C;LC_TIME=English_Switzerland.65001"
> >>
> >> # Sys.setlocale(category=?LC_ALL?, locale = ? ?)
> >>
> >> or
> >>
> >> # Sys.setlocale(category=?LC_ALL?, local=?Switzerland.65001?)
> >>
> >> Output
> >>
> >> # OS reports request to set locale to "Switzerland.65001" cannot be
> honoured
> >>
> >> Tried various commands specific for 'LC_CTYPE' (as this is where
> >> installation failed) for language string such as
> >>
> >> # Sys.setlocale("LC_CTYPE","en-GB")
> >
> > You may get better results with an underscore rather than a dash.
> >
> > Try:
> >
> > Sys.setlocale("LC_CTYPE","en_GB")
> >
> >
> >
> > On my machine you can get the acceptable locale strings with:
> >
> > locales <- system("locale -a", intern = TRUE)
> > locales[ grep("GB",locales) ]  # Just the GB strings
> > [1] "en_GB"            "en_GB.ISO8859-1"  "en_GB.ISO8859-15"
> "en_GB.US-ASCII"   "en_GB.UTF-8"      "zh_CN.GB18030"    "zh_CN.GB2312"
> > [8] "zh_CN.GBK"
>
> I should have admitted that I use a Mac. If you use Windoze, then consult
> the MS authorities for naming. Perhaps this page:
> https://docs.microsoft.com/en-us/windows/desktop/Intl/language-identifier-constants-and-strings
> , which suggests to me using 'UK' rather than 'GB' might be needed and
> 'ENGLISH' rather than 'en'.
>
>
> >
> >
> >
> >>
> >> Output:
> >>
> >> In Sys.setlocale("LC_CTYPE", "en-GB") :
> >>
> >> OS reports request to set locale to "en-GB" cannot be honoured
> >>
> >> Would anyone have any further suggestions for correct command.
> >>
> >> With thanks
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @ending from effectivedefen@e@org  Fri Sep 14 18:34:04 2018
From: @pencer@gr@ve@ @ending from effectivedefen@e@org (Spencer Graves)
Date: Fri, 14 Sep 2018 11:34:04 -0500
Subject: [R] [FORGED] Question on Binom.Confint
In-Reply-To: <d8ee54b0b44d43e6915750bef37ef2bc@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <b1545005-4871-177d-ac0d-6aed93a5a3f8@auckland.ac.nz>
 <d8ee54b0b44d43e6915750bef37ef2bc@CRCOEXCH2.cornerstone.com>
Message-ID: <999f81bd-2066-7b1b-04d7-c986eae7b83a@effectivedefense.org>



On 2018-09-14 08:52, Guo, Fang (Associate) wrote:
> It's method="lrt" and I used the "binom" package.


 ????? The ultimate answer can be obtained as follows:


 > debug(binom.confint)
 > binom.confint(x = 0, n = 100, tol = 1e-8, method='lrt')


 ????? Then walk through the code line by line.


 ????? Reading the code, I find the following:


 ? if (any(method == "lrt") || all.methods) {
 ??????? res.lrt <- binom.lrt(x, n, conf.level = conf.level, ...)
 ??????? res <- if (is.null(res))
 ??????????? res.lrt
 ??????? else rbind(res, res.lrt)
 ??? }


 ????? Then check the help page for "binom.lrt".? That includes the 
following:


Confidence intervals are based on profiling the binomial deviance in the 
neighbourhood of the MLE. If x == 0 or x == n and bayes is TRUE, then a 
Bayesian adjustment is made to move the log-likelihood function away 
from Inf. Specifically, these values are replaced by (x + 0.5)/(n + 1), 
which is the posterier mode of f(p|x) using Jeffrey's prior on p. 
Furthermore, if conf.adj is TRUE, then the upper (or lower) bound uses a 
1 - alpha confidence level. Typically, the observed mean will not be 
inside the estimated confidence interval. If bayes is FALSE, then the 
Clopper-Pearson exact method is used on the endpoints. This tends to 
make confidence intervals at the end too conservative, though the 
observed mean is guaranteed to be within the estimated confidence limits.


 ????? Spencer
>
> -----Original Message-----
> From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
> Sent: Thursday, September 13, 2018 10:02 PM
> To: Guo, Fang (Associate) <FAGuo at cornerstone.com>
> Cc: r-help at R-project.org
> Subject: Re: [FORGED] [R] Question on Binom.Confint
>
>
> On 09/14/2018 08:15 AM, Guo, Fang (Associate) wrote:
>
>> Hi,
>>
>> I have a question with the function Binom.Confint(x,n,"method"=lrt).
>> For likelihood ratio test, I'd like to ask how you define the upper
>> limit when the frequency of successes is zero. Thanks!
> Point 1:  This question is inappropriate for this list, since it is about statistical theory and not about R syntax and programming.
>
> Point 2: Where did you find the function Binom.Confint()?  I can find no such function anywhere.  I did manage to locate a function
> binom.confint() (note the lower case "b" and "c") but it does not have an argument "method".  Please do not expect those whom you are addressing to be telepathic.
>
> Point 3:  Having "method"=lrt in the call is decidedly weird.  Perhaps you meant method="lrt"; this is entirely different.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand
> that any disclosure, copying, distribution, or use of the contents
> of this email is strictly prohibited.
> ***********************************************************
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@k@hholly @ending from gm@il@com  Fri Sep 14 19:13:02 2018
From: m@k@hholly @ending from gm@il@com (greg holly)
Date: Fri, 14 Sep 2018 12:13:02 -0500
Subject: [R] label and font problems in Vennerable
Message-ID: <CAM9Qe4jbR7JZBOHjgke19tWoz-kytysZScHrnV2dqjHt80jtWw@mail.gmail.com>

Hi everyone;

I am running Vennerable with 7 sets of variables. The labels are not very
clear and the font size is not very visible. Does anyone know how I can
change the label colors and font sizes?

Regards,

Greg

	[[alternative HTML version deleted]]


From outlook_5DC74CB3034CB0A2 @ending from outlook@com  Fri Sep 14 20:00:05 2018
From: outlook_5DC74CB3034CB0A2 @ending from outlook@com (Jim Blackburn)
Date: Fri, 14 Sep 2018 18:00:05 +0000
Subject: [R] New to R
Message-ID: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>

I am newly subscribed to r-project.


I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)



I am attempting to download tickers as a time series.  I can successfully create RDA files but I want to convert them to CVS.  Following is the code I have created so far.



if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')

library(BatchGetSymbols)

tickers <- c('SPY','VCR', 'RPG')

first.date <- Sys.Date()-365

last.date <- Sys.Date

l.out <- BatchGetSymbols(tickers = tickers,

       first.date = first.date,

       last.date = last.date,

cache.folder = file.path("c://Users/Owner/Documents/R",

+    'BGS_Cache') )

print(l.out$df.control)

print(l.out$df.tickers)







I can print(l.out) and see that it contains all the data, but it is not a data.frame



Can anyone help with creating a data.frame and then converting to CSV?



Any help is GREATLY appreciated!



Thanks



Jim


Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


	[[alternative HTML version deleted]]


From @imin@@t@work @ending from gm@il@com  Fri Sep 14 23:03:53 2018
From: @imin@@t@work @ending from gm@il@com (Aimin Yan)
Date: Fri, 14 Sep 2018 17:03:53 -0400
Subject: [R] Change the position of label when using R package eulerr
In-Reply-To: <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
Message-ID: <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>

Thank you,

I figure out a way like this:

fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
"LAD&nonXL_MEF" = 541,
                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")

plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
= 1),alpha=0.7)

grid.ls()
t <- grid.get("quantities.grob")
names(t)

# Change these value will change the location of label.

grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
                                         unit(-14.883684319653, "native"),
                                         unit(13.9805892820006, "native"),
                                         unit(-12.8808987356981, "native"),
                                         unit(-11.488226371243, "native"),
                                         unit(-9.51474016085318, "native"),
                                         unit(-1.00436055190216, "native")))

grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
                                         unit(4.78718651828883, "native"),
                                         unit(0.25941593099694, "native"),
                                         unit(-4.32200781461293, "native"),
                                         unit(25.7349463488991, "native"),
                                         unit(-22.7610031110325, "native"),
                                         unit(14.5001560838519, "native")))

However, here I just want to change the x and y  value of 4th label, does
anyone know how to set it?

Aimin

On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> >
> > I am using eulerr to get venn.
> > My code is like:
> >
> > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> > "LAD&nonXL_MEF" = 541,
> >                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> >
> > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
> list(font
> > = 1),alpha=0.7)
> >
> > After I get the figure, I find the position of some  labels need to be
> > adjusted.
> >
> > Does anyone has some idea about how to process this?
>
> Looking at the code of plot.euler we see that the plotting paradigm is
> grid. So you could assign the output to a data.object name, search for list
> items that match the names of the labels you want to reposition, and modify
> the position values. You would need to be more specific, if you want a
> worked example.
>
> As far as I can see the lables and postions are fairly deep inside a list
> structure:
>
>  $ children     :List of 1
>   ..$ GRID.gTree.12:List of 5
>   .. ..$ children
>          $ diagram.grob.1
>             $children
> .. .. .. .. ..$ labels.grob    :List of 11
>   .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
>   .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native
> 69.2native 11.9native
>   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
>   .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native
> 5.24native 27.86native
>   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
>
> --
> David.
> >
> >
> > Thank you,
> >
> > Aimin
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Sep 14 23:08:09 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 14 Sep 2018 14:08:09 -0700
Subject: [R] New to R
In-Reply-To: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
References: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
Message-ID: <CAGxFJbQx_vKKqj0PooGf86P54yjmchF9pjx3C_ViZireKDQ3ZQ@mail.gmail.com>

Others may help, but I suggest first going through an R tutorial or
two to learn about R's basic data structures, i/o, etc. This list can
help, but cannot substitute for such homework. Some tutorial
recommendations can be found here:
https://www.rstudio.com/online-learning/#r-programming

There are many more, of course.

See also:
?read.table (etc. in the Help page)
?write.table

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Fri, Sep 14, 2018 at 1:56 PM Jim Blackburn
<outlook_5DC74CB3034CB0A2 at outlook.com> wrote:
>
> I am newly subscribed to r-project.
>
>
> I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)
>
>
>
> I am attempting to download tickers as a time series.  I can successfully create RDA files but I want to convert them to CVS.  Following is the code I have created so far.
>
>
>
> if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')
>
> library(BatchGetSymbols)
>
> tickers <- c('SPY','VCR', 'RPG')
>
> first.date <- Sys.Date()-365
>
> last.date <- Sys.Date
>
> l.out <- BatchGetSymbols(tickers = tickers,
>
>        first.date = first.date,
>
>        last.date = last.date,
>
> cache.folder = file.path("c://Users/Owner/Documents/R",
>
> +    'BGS_Cache') )
>
> print(l.out$df.control)
>
> print(l.out$df.tickers)
>
>
>
>
>
>
>
> I can print(l.out) and see that it contains all the data, but it is not a data.frame
>
>
>
> Can anyone help with creating a data.frame and then converting to CSV?
>
>
>
> Any help is GREATLY appreciated!
>
>
>
> Thanks
>
>
>
> Jim
>
>
> Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@cqueen1 @ending from llnl@gov  Fri Sep 14 23:15:50 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 14 Sep 2018 21:15:50 +0000
Subject: [R] New to R
Message-ID: <D9BFDB97-7AFD-41AC-81AC-3AA3EA7ED26C@llnl.gov>

If l.out is not a data frame, what is it? A list? A matrix? Some other structure? Try

  str(l.out)
  class(l.out)

and see what you get.

Can't help you convert it to a data frame without knowing what it is.

After you have a data frame, then write.table(), write.csv(), or write.csv2() will "convert" it to a CSV (assuming that's what you meant by "CVS".

-Don

p.s. use reply-all if you want to add that extra information .

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/14/18, 11:00 AM, "R-help on behalf of Jim Blackburn" <r-help-bounces at r-project.org on behalf of outlook_5DC74CB3034CB0A2 at outlook.com> wrote:

    I am newly subscribed to r-project.
    
    
    I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)
    
    
    
    I am attempting to download tickers as a time series.  I can successfully create RDA files but I want to convert them to CVS.  Following is the code I have created so far.
    
    
    
    if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')
    
    library(BatchGetSymbols)
    
    tickers <- c('SPY','VCR', 'RPG')
    
    first.date <- Sys.Date()-365
    
    last.date <- Sys.Date
    
    l.out <- BatchGetSymbols(tickers = tickers,
    
           first.date = first.date,
    
           last.date = last.date,
    
    cache.folder = file.path("c://Users/Owner/Documents/R",
    
    +    'BGS_Cache') )
    
    print(l.out$df.control)
    
    print(l.out$df.tickers)
    
    
    
    
    
    
    
    I can print(l.out) and see that it contains all the data, but it is not a data.frame
    
    
    
    Can anyone help with creating a data.frame and then converting to CSV?
    
    
    
    Any help is GREATLY appreciated!
    
    
    
    Thanks
    
    
    
    Jim
    
    
    Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10
    
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jfox @ending from mcm@@ter@c@  Fri Sep 14 23:46:09 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Fri, 14 Sep 2018 21:46:09 +0000
Subject: [R] Problem with lm.resid() when weights are provided
In-Reply-To: <CAAC89xexc0tHnC8n_n0Z+=3xtPDFmB394=U75V3KLe9RQ6OWdA@mail.gmail.com>
References: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
 <22333_1536669565_w8BCdOUV005487_CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368B0E61@FHSDB2D11-2.csu.mcmaster.ca>
 <CAAC89xexc0tHnC8n_n0Z+=3xtPDFmB394=U75V3KLe9RQ6OWdA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368B12FB@FHSDB2D11-2.csu.mcmaster.ca>

Dear Hamed,

When you post a question to r-help, generally you should cc subsequent messages there as well, as I've done to this response.

The algorithm that lm() uses is much more numerically stable than inverting the weighted sum-of-squares-and-product matrix. If you want to see how the computations are done, look at lm.wfit(), in which the residuals and fits are computed as 

    z$residuals <- z$residuals/wts
    z$fitted.values <- y - z$residuals

Zero weights are handled specially, and your tiny weights are thus the source of the problem. When you divide by a number less than the machine double-epsilon, you can't expect numerically stable results. I suppose that lm.wfit() could check for 0 weights to a tolerance rather than exactly.

John

> -----Original Message-----
> From: Hamed Ha [mailto:hamedhaseli at gmail.com]
> Sent: Friday, September 14, 2018 5:34 PM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: Re: [R] Problem with lm.resid() when weights are provided
> 
> Hi John,
> 
> Thank you for your reply.
> 
> I agree that the small weights are the potential source of the instability in the
> result. I also suspected that there are some failure/bugs in the actual
> algorithm that R uses for fitting the model. I remember that at some points I
> checked the theoretical estimation of the parameters, solve(t(x) %*% w %*%
> x) %*% t(x) %*% w %*% y, (besides the point that I had to set tol parameter in
> solve() to a super small value) and realised  that lm() and the theoretical
> results match together. That is the parameter estimation is right in R.
> Moreover, I checked the predictions, predict(lm.fit), and it was right. Then the
> only source of error remained was resid() function. I further checked this
> function and it is nothing more than calling a sub-element from and lm() fit.
> Putting all together, I think that there is something wrong/bug/miss-
> configuration in the lm() algorithm and I highly recommend the R core team to
> fix that.
> 
> Please feel free to contact me for more details if required.
> 
> Warm regards,
> Hamed.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On Fri, 14 Sep 2018 at 13:35, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Hamed,
> 
> 	I don't think that anyone has picked up on this problem.
> 
> 	What's peculiar about your weights is that several are 0 within
> rounding error but not exactly 0:
> 
> 	> head(df)
> 	           y          x       weight
> 	1  1.5115614  0.5520924 2.117337e-34
> 	2 -0.6365313 -0.1259932 2.117337e-34
> 	3  0.3778278  0.4209538 4.934135e-31
> 	4  3.0379232  1.4031545 2.679495e-24
> 	5  1.5364652  0.4607686 2.679495e-24
> 	6 -2.3772787 -0.7396358 6.244160e-21
> 
> 	I can reproduce the results that you report:
> 
> 	> (mod.1 <- lm(y ~ x, data=df))
> 
> 	Call:
> 	lm(formula = y ~ x, data = df)
> 
> 	Coefficients:
> 	(Intercept)            x
> 	   -0.04173      2.03790
> 
> 	> max(resid(mod.1))
> 	[1] 1.14046
> 	> (mod.2 <- lm(y ~ x, data=df, weights=weight))
> 
> 	Call:
> 	lm(formula = y ~ x, data = df, weights = weight)
> 
> 	Coefficients:
> 	(Intercept)            x
> 	   -0.05786      1.96087
> 
> 	> max(resid(mod.2))
> 	[1] 36.84939
> 
> 	But the problem disappears when the tiny nonzero weight are set to 0:
> 
> 	> df2 <- df
> 	> df2$weight <- zapsmall(df2$weight)
> 	> head(df2)
> 	           y          x weight
> 	1  1.5115614  0.5520924      0
> 	2 -0.6365313 -0.1259932      0
> 	3  0.3778278  0.4209538      0
> 	4  3.0379232  1.4031545      0
> 	5  1.5364652  0.4607686      0
> 	6 -2.3772787 -0.7396358      0
> 	> (mod.3 <- update(mod.2, data=df2))
> 
> 	Call:
> 	lm(formula = y ~ x, data = df2, weights = weight)
> 
> 	Coefficients:
> 	(Intercept)            x
> 	   -0.05786      1.96087
> 
> 	> max(resid(mod.3))
> 	[1] 1.146663
> 
> 	I don't know exactly why this happens, but suspect numerical
> instability produced by the near-zero weights, which are smaller than the
> machine double-epsilon
> 
> 	> .Machine$double.neg.eps
> 	[1] 1.110223e-16
> 
> 	The problem also disappears, e.g., if the tiny weight are set to 1e-15
> rather than 0.
> 
> 	I hope this helps,
> 	 John
> 
> 	-----------------------------------------------------------------
> 	John Fox
> 	Professor Emeritus
> 	McMaster University
> 	Hamilton, Ontario, Canada
> 	Web: https://socialsciences.mcmaster.ca/jfox/
> 
> 
> 
> 	> -----Original Message-----
> 	> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org> ] On Behalf Of Hamed Ha
> 	> Sent: Tuesday, September 11, 2018 8:39 AM
> 	> To: r-help at r-project.org <mailto:r-help at r-project.org>
> 	> Subject: [R] Problem with lm.resid() when weights are provided
> 	>
> 	> Dear R Help Team.
> 	>
> 	> I get some weird results when I use the lm function with weight. The
> issue can
> 	> be reproduced by the example below:
> 	>
> 	>
> 	> The input data is (weights are intentionally designed to reflect some
> 	> structures in the data)
> 	>
> 	>
> 	> > df
> 	> y x weight
> 	>  1.51156139  0.55209240 2.117337e-34
> 	> -0.63653132 -0.12599316 2.117337e-34
> 	>  0.37782776  0.42095384 4.934135e-31
> 	>  3.03792318  1.40315446 2.679495e-24
> 	>  1.53646523  0.46076858 2.679495e-24
> 	> -2.37727874 -0.73963576 6.244160e-21
> 	>  0.37183065  0.20407468 1.455107e-17
> 	> -1.53917553 -0.95519361 1.455107e-17
> 	>  1.10926675  0.03897129 3.390908e-14
> 	> -0.37786333 -0.17523593 3.390908e-14
> 	>  2.43973603  0.97970095 7.902000e-11
> 	> -0.35432394 -0.03742559 7.902000e-11
> 	>  2.19296613  1.00355263 4.289362e-04
> 	>  0.49845532  0.34816207 4.289362e-04
> 	>  1.25005260  0.76306225 5.000000e-01
> 	>  0.84360691  0.45152356 5.000000e-01
> 	>  0.29565993  0.53880068 5.000000e-01
> 	> -0.54081334 -0.28104525 5.000000e-01
> 	>  0.83612836 -0.12885659 9.995711e-01
> 	> -1.42526769 -0.87107631 9.999998e-01
> 	>  0.10204789 -0.11649899 1.000000e+00
> 	>  1.14292898  0.37249631 1.000000e+00
> 	> -3.02942081 -1.28966997 1.000000e+00
> 	> -1.37549764 -0.74676145 1.000000e+00
> 	> -2.00118016 -0.55182759 1.000000e+00
> 	> -4.24441674 -1.94603608 1.000000e+00
> 	>  1.17168144  1.00868008 1.000000e+00
> 	>  2.64007761  1.26333069 1.000000e+00
> 	>  1.98550114  1.18509599 1.000000e+00
> 	> -0.58941683 -0.61972416 9.999998e-01
> 	> -4.57559611 -2.30914920 9.995711e-01
> 	> -0.82610544 -0.39347576 9.995711e-01
> 	> -0.02768220  0.20076910 9.995711e-01
> 	>  0.78186399  0.25690215 9.995711e-01
> 	> -0.88314153 -0.20200148 5.000000e-01
> 	> -4.17076452 -2.03547588 5.000000e-01
> 	>  0.93373070  0.54190626 4.289362e-04
> 	> -0.08517734  0.17692491 4.289362e-04
> 	> -4.47546619 -2.14876688 4.289362e-04
> 	> -1.65509103 -0.76898087 4.289362e-04
> 	> -0.39403030 -0.12689705 4.289362e-04
> 	>  0.01203300 -0.18689898 1.841442e-07
> 	> -4.82762639 -2.31391121 1.841442e-07
> 	> -0.72658380 -0.39751171 3.397282e-14
> 	> -2.35886866 -1.01082109 0.000000e+00
> 	> -2.03762707 -0.96439902 0.000000e+00
> 	>  0.90115123  0.60172286 0.000000e+00
> 	>  1.55999194  0.83433953 0.000000e+00
> 	>  3.07994058  1.30942776 0.000000e+00
> 	>  1.78871462  1.10605530 0.000000e+00
> 	>
> 	>
> 	>
> 	> Running simple linear model returns:
> 	>
> 	> > lm(y~x,data=df)
> 	>
> 	> Call:
> 	> lm(formula = y ~ x, data = df)
> 	>
> 	> Coefficients:
> 	> (Intercept)            x
> 	>    -0.04173      2.03790
> 	>
> 	> and
> 	> > max(resid(lm(y~x,data=df)))
> 	> [1] 1.14046
> 	>
> 	>
> 	> *HOWEVER if I use the weighted model then:*
> 	>
> 	> lm(formula = y ~ x, data = df, weights = df$weights)
> 	>
> 	> Coefficients:
> 	> (Intercept)            x
> 	>    -0.05786      1.96087
> 	>
> 	> and
> 	> > max(resid(lm(y~x,data=df,weights=df$weights)))
> 	> [1] 60.91888
> 	>
> 	>
> 	> as you see, the estimation of the coefficients are nearly the same
> but the
> 	> resid() function returns a giant residual (I have some cases where
> the value is
> 	> much much higher). Further, if I calculate the residuals by simply
> 	> predict(lm(y~x,data=df,weights=df$weights))-df$y then I get the true
> value for
> 	> the residuals.
> 	>
> 	>
> 	> Thanks.
> 	>
> 	> Please do not hesitate to contact me for more details.
> 	> Regards,
> 	> Hamed.
> 	>
> 	>       [[alternative HTML version deleted]]
> 	>
> 	> ______________________________________________
> 	> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list --
> To UNSUBSCRIBE and more, see
> 	> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> PLEASE do read the posting guide http://www.R-project.org/posting-
> 	> guide.html
> 	> and provide commented, minimal, self-contained, reproducible
> code.
> 


From dwin@emiu@ @ending from comc@@t@net  Sat Sep 15 00:18:02 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Fri, 14 Sep 2018 15:18:02 -0700
Subject: [R] New to R
In-Reply-To: <D9BFDB97-7AFD-41AC-81AC-3AA3EA7ED26C@llnl.gov>
References: <D9BFDB97-7AFD-41AC-81AC-3AA3EA7ED26C@llnl.gov>
Message-ID: <1387982A-D691-4DD2-BFE9-849A6FBF1DD1@comcast.net>


> On Sep 14, 2018, at 2:15 PM, MacQueen, Don via R-help <r-help at r-project.org> wrote:
> 
> If l.out is not a data frame, what is it? A list? A matrix? Some other structure? Try

I thought it would be one of those variants of a zoo object. Matrix structure with specialized row.names that can handle time-date range operators.

Bert's advice to learn some basic R certainly makes sense. After fixing the two errors in the code and substituting a proper path I get:

str(l.out)
List of 2
 $ df.control:'data.frame':	3 obs. of  6 variables:
  ..$ ticker              : Factor w/ 3 levels "SPY","VCR","RPG": 1 2 3
  ..$ src                 : Factor w/ 1 level "yahoo": 1 1 1
  ..$ download.status     : Factor w/ 1 level "OK": 1 1 1
  ..$ total.obs           : int [1:3] 252 252 252
  ..$ perc.benchmark.dates: num [1:3] 1 1 1
  ..$ threshold.decision  : Factor w/ 1 level "KEEP": 1 1 1
 $ df.tickers:'data.frame':	756 obs. of  10 variables:
  ..$ price.open         : num [1:756] 250 249 250 250 250 ...
  ..$ price.high         : num [1:756] 250 249 250 250 250 ...
  ..$ price.low          : num [1:756] 250 249 249 250 249 ...
  ..$ price.close        : num [1:756] 250 249 250 250 250 ...
  ..$ volume             : num [1:756] 95446300 95432400 46235200 47108100 59574100 ...
  ..$ price.adjusted     : num [1:756] 245 246 246 247 247 ...
  ..$ ref.date           : Date[1:756], format: "2017-09-14" "2017-09-15" "2017-09-18" "2017-09-19" ...
  ..$ ticker             : chr [1:756] "SPY" "SPY" "SPY" "SPY" ...
  ..$ ret.adjusted.prices: num [1:756] NA 0.00135 0.00213 0.001 0.00036 ...
  ..$ ret.closing.prices : num [1:756] NA -0.0036 0.00213 0.001 0.00036 ...


So the data.frame would be:  l.out$df.tickers


It's got the data in a long-format arrangement:

table( l.out$df.tickers$ticker)

RPG SPY VCR 
252 252 252 
-- 
David.
> 
>  str(l.out)
>  class(l.out)
> 
> and see what you get.
> 
> Can't help you convert it to a data frame without knowing what it is.
> 
> After you have a data frame, then write.table(), write.csv(), or write.csv2() will "convert" it to a CSV (assuming that's what you meant by "CVS".
> 
> -Don
> 
> p.s. use reply-all if you want to add that extra information .
> 
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
> 
> 
> 
> ?On 9/14/18, 11:00 AM, "R-help on behalf of Jim Blackburn" <r-help-bounces at r-project.org on behalf of outlook_5DC74CB3034CB0A2 at outlook.com> wrote:
> 
>    I am newly subscribed to r-project.
> 
> 
>    I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)
> 
> 
> 
>    I am attempting to download tickers as a time series.  I can successfully create RDA files but I want to convert them to CVS.  Following is the code I have created so far.
> 
> 
> 
>    if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')
> 
>    library(BatchGetSymbols)
> 
>    tickers <- c('SPY','VCR', 'RPG')
> 
>    first.date <- Sys.Date()-365
> 
>    last.date <- Sys.Date
> 
>    l.out <- BatchGetSymbols(tickers = tickers,
> 
>           first.date = first.date,
> 
>           last.date = last.date,
> 
>    cache.folder = file.path("c://Users/Owner/Documents/R",
> 
>    +    'BGS_Cache') )
> 
>    print(l.out$df.control)
> 
>    print(l.out$df.tickers)
> 
> 
> 
> 
> 
> 
> 
>    I can print(l.out) and see that it contains all the data, but it is not a data.frame
> 
> 
> 
>    Can anyone help with creating a data.frame and then converting to CSV?
> 
> 
> 
>    Any help is GREATLY appreciated!
> 
> 
> 
>    Thanks
> 
> 
> 
>    Jim
> 
> 
>    Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10
> 
> 
>    	[[alternative HTML version deleted]]
> 
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dwin@emiu@ @ending from comc@@t@net  Sat Sep 15 00:46:59 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Fri, 14 Sep 2018 15:46:59 -0700
Subject: [R] Change the position of label when using R package eulerr
In-Reply-To: <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
 <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
Message-ID: <72EA8C05-D7CB-4949-B483-98EDBDB40934@comcast.net>


> On Sep 14, 2018, at 2:03 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> 
> Thank you,
> 
> I figure out a way like this:
> 
> fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
>                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101, "LAD&nonXL_MEF" = 541,
>                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
>     
> plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font = 1),alpha=0.7)
>    
> grid.ls()
> t <- grid.get("quantities.grob")
> names(t)
> 
> # Change these value will change the location of label.
>  
> grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
>                                          unit(-14.883684319653, "native"),
>                                          unit(13.9805892820006, "native"),
>                                          unit(-12.8808987356981, "native"),
>                                          unit(-11.488226371243, "native"),
>                                          unit(-9.51474016085318, "native"),
>                                          unit(-1.00436055190216, "native")))
>                 
> grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
>                                          unit(4.78718651828883, "native"),
>                                          unit(0.25941593099694, "native"),
>                                          unit(-4.32200781461293, "native"),
>                                          unit(25.7349463488991, "native"),
>                                          unit(-22.7610031110325, "native"),
>                                          unit(14.5001560838519, "native")))
> 
> However, here I just want to change the x and y  value of 4th label, does anyone know how to set it?

If the t object were a complete grid object, it might have been:

grid.edit("quantities.grob", x[[4]]= unit(-12.8808987356981, "native")
           )               
grid.edit("quantities.grob", y[[4]]= unit(-4.32200781461293, "native"),
           )


But I don't think that will succeed since you never assigned the value of the plot operation to a name. Instead you pulled out part of the grid object that was sitting "free" and unassigned to a name. If you assign that value of plot(....) to `my.plot` you get:

 grid.ls(my.plot)
euler.diagram
  GRID.gTree.11
    diagram.grob.1
      fills.grob.1
      fills.grob.2
      fills.grob.3
      fills.grob.4
      fills.grob.5
      fills.grob.6
      fills.grob.7
      edges.grob
      labels.grob
      quantities.grob

I think you need to work with the tutorials in the grid package.

Look at:

help("grid-package")

-- 
David.

> 
> Aimin
> 
> On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> > 
> > I am using eulerr to get venn.
> > My code is like:
> > 
> > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> > "LAD&nonXL_MEF" = 541,
> >                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> > 
> > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
> > = 1),alpha=0.7)
> > 
> > After I get the figure, I find the position of some  labels need to be
> > adjusted.
> > 
> > Does anyone has some idea about how to process this?
> 
> Looking at the code of plot.euler we see that the plotting paradigm is grid. So you could assign the output to a data.object name, search for list items that match the names of the labels you want to reposition, and modify the position values. You would need to be more specific, if you want a worked example.
> 
> As far as I can see the lables and postions are fairly deep inside a list structure:
> 
>  $ children     :List of 1
>   ..$ GRID.gTree.12:List of 5
>   .. ..$ children
>          $ diagram.grob.1     
>             $children
> .. .. .. .. ..$ labels.grob    :List of 11
>   .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
>   .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native 69.2native 11.9native
>   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
>   .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native 5.24native 27.86native
>   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> 
> -- 
> David.
> > 
> > 
> > Thank you,
> > 
> > Aimin
> > 
> >       [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From li@t@ @ending from dewey@myzen@co@uk  Sat Sep 15 14:23:52 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Sat, 15 Sep 2018 13:23:52 +0100
Subject: [R] New to R
In-Reply-To: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
References: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
Message-ID: <0fdeabf7-dcc3-575a-a0a6-ee5de67b00e0@dewey.myzen.co.uk>

Dear Jim

Without knowing what l.out is this might be tricky. What does str(l.out) 
tell you it is. And is CVS a typo for csv?

Michael

On 14/09/2018 19:00, Jim Blackburn wrote:
> I am newly subscribed to r-project.
> 
> 
> I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)
> 
> 
> 
> I am attempting to download tickers as a time series.  I can successfully create RDA files but I want to convert them to CVS.  Following is the code I have created so far.
> 
> 
> 
> if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')
> 
> library(BatchGetSymbols)
> 
> tickers <- c('SPY','VCR', 'RPG')
> 
> first.date <- Sys.Date()-365
> 
> last.date <- Sys.Date
> 
> l.out <- BatchGetSymbols(tickers = tickers,
> 
>         first.date = first.date,
> 
>         last.date = last.date,
> 
> cache.folder = file.path("c://Users/Owner/Documents/R",
> 
> +    'BGS_Cache') )
> 
> print(l.out$df.control)
> 
> print(l.out$df.tickers)
> 
> 
> 
> 
> 
> 
> 
> I can print(l.out) and see that it contains all the data, but it is not a data.frame
> 
> 
> 
> Can anyone help with creating a data.frame and then converting to CSV?
> 
> 
> 
> Any help is GREATLY appreciated!
> 
> 
> 
> Thanks
> 
> 
> 
> Jim
> 
> 
> Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From hwborcher@ @ending from gm@il@com  Sat Sep 15 21:38:22 2018
From: hwborcher@ @ending from gm@il@com (Hans W Borchers)
Date: Sat, 15 Sep 2018 21:38:22 +0200
Subject: [R] How can I know the Hausdorff dimensions of fractals in the
 'fractalcurve' function of package 'pracma'?
Message-ID: <CAML4n3OZwpBSG+VVe6wpHrVSt6CYmfT+3hffLO7PoE-ECeWQHw@mail.gmail.com>

> Dear Dr. Hans W. Borchers,

This is a public mailing list; do not address specific people here,
everyone can read and (possibly) answer your questions. And please send
e-mail in plain text format, not as HTML.

> I'm using your 'pracma' package. It is very useful. May I have a small
> question for the 'fractalcurve' function? How can I know the Hausdorff
> dimension for every option below?
> c("hilbert", "sierpinski", "snowflake", "dragon", "triangle",
>    "arrowhead", "flowsnake", "molecule")
> For the "dragon" option, its Hausdorff dimension is log(4)/log(2) = 2.
> For the others, what are the Hausdorff dimensions?

I don't know. Have you tried the *fractaldim* package to find at least a
plausible numerical value for the Hausdorff dimension?

> I have found the list of some fractals by Hausforff dimensions.
> I don't know which in the above option corresponds to which in Wikepedia.

Guess you mean the "List of fractals by Hausdorff dimension". Well, "hilbert"
is obviously the Hilbert curve and has a Hausdorff dimension of 2 -- because
it is a 'space-filling' curve.[^1]

Otherwise, use `fractalcurve()` to generate plots of the fractal curves and
compare with the pictures shown on the Wikipedia page. Not all the
curves may be present on this list, though.

> Thanks a lot!
> Best wishes,
> Peijian Shi

---
[1] By the way, I doubt your estimation that the dragon curve has Hausdorff
    dimension 2; it looks more like 1.5236.


From @imin@@t@work @ending from gm@il@com  Sat Sep 15 22:27:37 2018
From: @imin@@t@work @ending from gm@il@com (Aimin Yan)
Date: Sat, 15 Sep 2018 16:27:37 -0400
Subject: [R] Change the position of label when using R package eulerr
In-Reply-To: <72EA8C05-D7CB-4949-B483-98EDBDB40934@comcast.net>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
 <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
 <72EA8C05-D7CB-4949-B483-98EDBDB40934@comcast.net>
Message-ID: <CALn2QVjDVUXEg3UBz6dy5-qLPKpPwVafGNcn4qe7BYy1jrkcyA@mail.gmail.com>

Thank you, I tried your code, but I still got error:

  fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
"LAD&nonXL_MEF" = 541,
                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")

    fit1.plot <- plot(fit1,quantities = TRUE,fill = rainbow(7),lty =
1:2,labels = list(font = 1),alpha=0.7)
    fit1.plot
    grid.ls(fit1.plot)
    t <- grid.get("quantities.grob")
    names(t)
    t$label
    t$x
    t$y

    # Try to change the x and y value of the 4th label "2"
    grid.edit("quantities.grob",x[[4]]=unit(-11.8262244206465, "native"))
    grid.edit("quantities.grob",y[[4]]=unit(-5.19720701058398, "native"))

Error: unexpected '=' in "grid.edit("quantities.grob",x[[4]]="

Aimin

On Fri, Sep 14, 2018 at 6:47 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 14, 2018, at 2:03 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> >
> > Thank you,
> >
> > I figure out a way like this:
> >
> > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> "LAD&nonXL_MEF" = 541,
> >                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> >
> > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
> list(font = 1),alpha=0.7)
> >
> > grid.ls()
> > t <- grid.get("quantities.grob")
> > names(t)
> >
> > # Change these value will change the location of label.
> >
> > grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
> >                                          unit(-14.883684319653,
> "native"),
> >                                          unit(13.9805892820006,
> "native"),
> >                                          unit(-12.8808987356981,
> "native"),
> >                                          unit(-11.488226371243,
> "native"),
> >                                          unit(-9.51474016085318,
> "native"),
> >                                          unit(-1.00436055190216,
> "native")))
> >
> > grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
> >                                          unit(4.78718651828883,
> "native"),
> >                                          unit(0.25941593099694,
> "native"),
> >                                          unit(-4.32200781461293,
> "native"),
> >                                          unit(25.7349463488991,
> "native"),
> >                                          unit(-22.7610031110325,
> "native"),
> >                                          unit(14.5001560838519,
> "native")))
> >
> > However, here I just want to change the x and y  value of 4th label,
> does anyone know how to set it?
>
> If the t object were a complete grid object, it might have been:
>
> grid.edit("quantities.grob", x[[4]]= unit(-12.8808987356981, "native")
>            )
> grid.edit("quantities.grob", y[[4]]= unit(-4.32200781461293, "native"),
>            )
>
>
> But I don't think that will succeed since you never assigned the value of
> the plot operation to a name. Instead you pulled out part of the grid
> object that was sitting "free" and unassigned to a name. If you assign that
> value of plot(....) to `my.plot` you get:
>
>  grid.ls(my.plot)
> euler.diagram
>   GRID.gTree.11
>     diagram.grob.1
>       fills.grob.1
>       fills.grob.2
>       fills.grob.3
>       fills.grob.4
>       fills.grob.5
>       fills.grob.6
>       fills.grob.7
>       edges.grob
>       labels.grob
>       quantities.grob
>
> I think you need to work with the tutorials in the grid package.
>
> Look at:
>
> help("grid-package")
>
> --
> David.
>
> >
> > Aimin
> >
> > On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com>
> wrote:
> > >
> > > I am using eulerr to get venn.
> > > My code is like:
> > >
> > > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> > >                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> > > "LAD&nonXL_MEF" = 541,
> > >                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> > >
> > > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
> list(font
> > > = 1),alpha=0.7)
> > >
> > > After I get the figure, I find the position of some  labels need to be
> > > adjusted.
> > >
> > > Does anyone has some idea about how to process this?
> >
> > Looking at the code of plot.euler we see that the plotting paradigm is
> grid. So you could assign the output to a data.object name, search for list
> items that match the names of the labels you want to reposition, and modify
> the position values. You would need to be more specific, if you want a
> worked example.
> >
> > As far as I can see the lables and postions are fairly deep inside a
> list structure:
> >
> >  $ children     :List of 1
> >   ..$ GRID.gTree.12:List of 5
> >   .. ..$ children
> >          $ diagram.grob.1
> >             $children
> > .. .. .. .. ..$ labels.grob    :List of 11
> >   .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
> >   .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native
> 69.2native 11.9native
> >   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> >   .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native
> 5.24native 27.86native
> >   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> >
> > --
> > David.
> > >
> > >
> > > Thank you,
> > >
> > > Aimin
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Sun Sep 16 00:25:16 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sat, 15 Sep 2018 15:25:16 -0700
Subject: [R] Change the position of label when using R package eulerr
In-Reply-To: <CALn2QVjDVUXEg3UBz6dy5-qLPKpPwVafGNcn4qe7BYy1jrkcyA@mail.gmail.com>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
 <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
 <72EA8C05-D7CB-4949-B483-98EDBDB40934@comcast.net>
 <CALn2QVjDVUXEg3UBz6dy5-qLPKpPwVafGNcn4qe7BYy1jrkcyA@mail.gmail.com>
Message-ID: <08E2A6F0-F2C9-4C02-A9E7-CF053D6FB739@comcast.net>


> On Sep 15, 2018, at 1:27 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> 
> Thank you, I tried your code, but I still got error:
> 
>   fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
>                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101, "LAD&nonXL_MEF" = 541,
>                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
>     
>     fit1.plot <- plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font = 1),alpha=0.7)
>     fit1.plot
>     grid.ls(fit1.plot)

I don't think you are editing the right object (and I don't think you have honored my prior efforts to get you to read the documentation for the grid package):

names(fit1.plot)
#[1] "name"          "gp"            "vp"            "children"      "childrenOrder"
names(fit1.plot$children)
#[1] "GRID.gTree.12"
 names(fit1.plot$children$GRID.gTree.12)
#[1] "name"          "gp"            "vp"            "children"      "childrenOrder"
 names(fit1.plot$children$GRID.gTree.12$children)
#[1] "diagram.grob.1"
 names(fit1.plot$children$GRID.gTree.12$children$diagram.grob.1)
#[1] "name"          "gp"            "vp"            "children"      "childrenOrder"

 names()
 #[1] "fills.grob.1"    "fills.grob.2"    "fills.grob.3"    "fills.grob.4"    "fills.grob.5"    "fills.grob.6"    "fills.grob.7"   
 #[8] "edges.grob"      "labels.grob"     "quantities.grob"

My suggested target for editing, in place, would be:

fit1.plot$children$GRID.gTree.12$children$diagram.grob.1$children$quantities.grob

str( fit1.plot$children$GRID.gTree.12$children$diagram.grob.1$children$quantities.grob )
#----------------------
List of 11
 $ label        : chr [1:7] "3" "101" "541" "2" ...
 $ x            : 'unit' num [1:7] -4.35native -11.01native 16.5native -4.01native -28.09native ...
  ..- attr(*, "valid.unit")= int 4
  ..- attr(*, "unit")= chr "native"
 $ y            : 'unit' num [1:7] -2.569native 15.889native 4.732native -0.788native -7.157native ...
  ..- attr(*, "valid.unit")= int 4
  ..- attr(*, "unit")= chr "native"
 $ just         : chr "centre"
 $ hjust        : NULL
 $ vjust        : num [1:7] 0.5 0.5 0.5 0.5 1 1 1
 $ rot          : num [1:7] 0 0 0 0 0 0 0
 $ check.overlap: logi FALSE
 $ name         : chr "quantities.grob"
 $ gp           :List of 7
  ..$ col       : int [1:7] 1 1 1 1 1 1 1
  ..$ alpha     : num [1:7] 1 1 1 1 1 1 1
  ..$ fontsize  : num [1:7] 12 12 12 12 12 12 12
  ..$ cex       : num [1:7] 1 1 1 1 1 1 1
  ..$ fontfamily: chr [1:7] "" "" "" "" ...
  ..$ lineheight: num [1:7] 1.2 1.2 1.2 1.2 1.2 1.2 1.2
  ..$ font      : int [1:7] 1 1 1 1 1 1 1
  ..- attr(*, "class")= chr "gpar"
 $ vp           : NULL
 - attr(*, "class")= chr [1:3] "text" "grob" "gDesc"

 str( fit1.plot$children$GRID.gTree.12$children$diagram.grob.1$children$quantities.grob$x )
#----------
 'unit' num [1:7] -4.35native -11.01native 16.5native -4.01native -28.09native ...
 - attr(*, "valid.unit")= int 4
 - attr(*, "unit")= chr "native"
#-------
 str( fit1.plot$children$GRID.gTree.12$children$diagram.grob.1$children$quantities.grob$y )
#________
 'unit' num [1:7] -2.569native 15.889native 4.732native -0.788native -7.157native ...
 - attr(*, "valid.unit")= int 4
 - attr(*, "unit")= chr "native"

-- 
David




>     t <- grid.get("quantities.grob")
>     names(t)
>     t$label
>     t$x
>     t$y
> 
>     # Try to change the x and y value of the 4th label "2"
>     grid.edit("quantities.grob",x[[4]]=unit(-11.8262244206465, "native"))
>     grid.edit("quantities.grob",y[[4]]=unit(-5.19720701058398, "native"))
> 
> Error: unexpected '=' in "grid.edit("quantities.grob",x[[4]]="
> 
> Aimin
> 
> On Fri, Sep 14, 2018 at 6:47 PM David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Sep 14, 2018, at 2:03 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> > 
> > Thank you,
> > 
> > I figure out a way like this:
> > 
> > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101, "LAD&nonXL_MEF" = 541,
> >                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> >     
> > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font = 1),alpha=0.7)
> >    
> > grid.ls()
> > t <- grid.get("quantities.grob")
> > names(t)
> > 
> > # Change these value will change the location of label.
> >  
> > grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
> >                                          unit(-14.883684319653, "native"),
> >                                          unit(13.9805892820006, "native"),
> >                                          unit(-12.8808987356981, "native"),
> >                                          unit(-11.488226371243, "native"),
> >                                          unit(-9.51474016085318, "native"),
> >                                          unit(-1.00436055190216, "native")))
> >                 
> > grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
> >                                          unit(4.78718651828883, "native"),
> >                                          unit(0.25941593099694, "native"),
> >                                          unit(-4.32200781461293, "native"),
> >                                          unit(25.7349463488991, "native"),
> >                                          unit(-22.7610031110325, "native"),
> >                                          unit(14.5001560838519, "native")))
> > 
> > However, here I just want to change the x and y  value of 4th label, does anyone know how to set it?
> 
> If the t object were a complete grid object, it might have been:
> 
> grid.edit("quantities.grob", x[[4]]= unit(-12.8808987356981, "native")
>            )               
> grid.edit("quantities.grob", y[[4]]= unit(-4.32200781461293, "native"),
>            )
> 
> 
> But I don't think that will succeed since you never assigned the value of the plot operation to a name. Instead you pulled out part of the grid object that was sitting "free" and unassigned to a name. If you assign that value of plot(....) to `my.plot` you get:
> 
>  grid.ls(my.plot)
> euler.diagram
>   GRID.gTree.11
>     diagram.grob.1
>       fills.grob.1
>       fills.grob.2
>       fills.grob.3
>       fills.grob.4
>       fills.grob.5
>       fills.grob.6
>       fills.grob.7
>       edges.grob
>       labels.grob
>       quantities.grob
> 
> I think you need to work with the tutorials in the grid package.
> 
> Look at:
> 
> help("grid-package")
> 
> -- 
> David.
> 
> > 
> > Aimin
> > 
> > On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net> wrote:
> > 
> > > On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> > > 
> > > I am using eulerr to get venn.
> > > My code is like:
> > > 
> > > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> > >                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> > > "LAD&nonXL_MEF" = 541,
> > >                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> > > 
> > > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
> > > = 1),alpha=0.7)
> > > 
> > > After I get the figure, I find the position of some  labels need to be
> > > adjusted.
> > > 
> > > Does anyone has some idea about how to process this?
> > 
> > Looking at the code of plot.euler we see that the plotting paradigm is grid. So you could assign the output to a data.object name, search for list items that match the names of the labels you want to reposition, and modify the position values. You would need to be more specific, if you want a worked example.
> > 
> > As far as I can see the lables and postions are fairly deep inside a list structure:
> > 
> >  $ children     :List of 1
> >   ..$ GRID.gTree.12:List of 5
> >   .. ..$ children
> >          $ diagram.grob.1     
> >             $children
> > .. .. .. .. ..$ labels.grob    :List of 11
> >   .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
> >   .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native 69.2native 11.9native
> >   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> >   .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native 5.24native 27.86native
> >   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> > 
> > -- 
> > David.
> > > 
> > > 
> > > Thank you,
> > > 
> > > Aimin
> > > 
> > >       [[alternative HTML version deleted]]
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> > David Winsemius
> > Alameda, CA, USA
> > 
> > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> > 
> > 
> > 
> > 
> > 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From krylov@r00t @ending from gm@il@com  Sun Sep 16 18:21:58 2018
From: krylov@r00t @ending from gm@il@com (Ivan Krylov)
Date: Sun, 16 Sep 2018 19:21:58 +0300
Subject: [R] Help with setting locale
In-Reply-To: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
References: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
Message-ID: <20180916192158.2a45b3fb@Tarkus>

On Fri, 14 Sep 2018 10:02:01 +0200
Kim Titcombe <ktitcombe02 at gmail.com> wrote:

> I am based in Switzerland but work in English (Windows in English),
> hence want English as default.

Which Windows version do you use? Which languages/language packs do you
have installed?

-- 
Best regards,
Ivan


From lei@liu @ending from wu@tl@edu  Sun Sep 16 19:39:41 2018
From: lei@liu @ending from wu@tl@edu (Liu, Lei)
Date: Sun, 16 Sep 2018 17:39:41 +0000
Subject: [R] bootstrap sample for clustered data
Message-ID: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>

Hi there,

I tried to generate bootstrap samples for clustered data. Here is some code I found in the web to do the work:

id=c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2)
x=c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1 )

xx=data.frame(id, x, y)

boot.cluster <- function(x, id){

  boot.id <- sample(unique(id), replace=T)
  out <- lapply(boot.id, function(i) x[id%in%i,])

  return( do.call("rbind",out) )

}

boot.pro=boot.cluster(xx, xx$id)

Now I have the output

   id x   y
5   3 0 0.4
6   3 0 1.0
51  3 0 0.4
61  3 0 1.0
9   5 1 0.5
10  5 1 2.0
52  3 0 0.4
62  3 0 1.0
3   2 1 0.4
4   2 1 0.3

However, the id variable is the original id, while I want to take the new id as (1, 1, 2, 2, 3, 3, 4, 4, 5, 5) for later analysis. Can anyone show me how to do it? Of note, the same original id may have duplicates since the bootstrap sample is drawn with replacement. Thanks a lot!

Lei


	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sun Sep 16 21:20:45 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 16 Sep 2018 12:20:45 -0700
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
References: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbQ51K8m6YgsRPHdKjWNX2GmcxEzE-kQDJ3XzdZT8Hm_0g@mail.gmail.com>

I can't make any sense of your post. Id 3 occurs 6 times, and 2 and 5 occur
twice each in your example.. How do you get (1,1,2,2,3,3,4,4,5,5) out of
that? In other words, specify the mapping of old id's to new.

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 16, 2018 at 11:51 AM Liu, Lei <lei.liu at wustl.edu> wrote:

> Hi there,
>
> I tried to generate bootstrap samples for clustered data. Here is some
> code I found in the web to do the work:
>
> id=c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
> y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2)
> x=c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1 )
>
> xx=data.frame(id, x, y)
>
> boot.cluster <- function(x, id){
>
>   boot.id <- sample(unique(id), replace=T)
>   out <- lapply(boot.id, function(i) x[id%in%i,])
>
>   return( do.call("rbind",out) )
>
> }
>
> boot.pro=boot.cluster(xx, xx$id)
>
> Now I have the output
>
>    id x   y
> 5   3 0 0.4
> 6   3 0 1.0
> 51  3 0 0.4
> 61  3 0 1.0
> 9   5 1 0.5
> 10  5 1 2.0
> 52  3 0 0.4
> 62  3 0 1.0
> 3   2 1 0.4
> 4   2 1 0.3
>
> However, the id variable is the original id, while I want to take the new
> id as (1, 1, 2, 2, 3, 3, 4, 4, 5, 5) for later analysis. Can anyone show me
> how to do it? Of note, the same original id may have duplicates since the
> bootstrap sample is drawn with replacement. Thanks a lot!
>
> Lei
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sun Sep 16 22:39:24 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 16 Sep 2018 13:39:24 -0700
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <CAGxFJbTOQCLNnK_Ewn50udoMjg8kW5UBGZzheBWm7WUYMjYCEA@mail.gmail.com>
References: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <CAGxFJbQ51K8m6YgsRPHdKjWNX2GmcxEzE-kQDJ3XzdZT8Hm_0g@mail.gmail.com>
 <SN4PR0201MB3405D3F4FDD6DB4863D3C037F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <CAGxFJbTOQCLNnK_Ewn50udoMjg8kW5UBGZzheBWm7WUYMjYCEA@mail.gmail.com>
Message-ID: <CAGxFJbTcQK_eeSe+q1j+SST-oKZg3nvQGyLFveioqDG+rLPwJg@mail.gmail.com>

(I neglected to cc this to the list -- Bert)


On Sun, Sep 16, 2018 at 1:36 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> You can do a mixed effects model using the existing id's without recoding.
>
> But if you insist, is this the sort of thing you want?
>
> set.seed(-12345) # for reprodicibility
>
> id <- factor(sample(2:5, 10, rep=TRUE))
> id
> new.id <- factor(id,labels = seq_along(levels(id)))
> new.id
>
> Note: There's a slightly slicker way to do this, but it bypasses the
> factor() API, and I prefer not to do that.
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Sep 16, 2018 at 12:52 PM Liu, Lei <lei.liu at wustl.edu> wrote:
>
>> Sorry for the confusion. I just want to recode the id variable to 1 to 5
>> in the bootstrapped sample. This way I can do e.g., a mixed effects model
>> using the new id as the cluster. Thanks!
>>
>> Lei
>>
>>
>>
>> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> *Sent:* Sunday, September 16, 2018 2:21 PM
>> *To:* Liu, Lei <lei.liu at wustl.edu>
>> *Cc:* R-help <r-help at r-project.org>
>> *Subject:* Re: [R] bootstrap sample for clustered data
>>
>>
>>
>> I can't make any sense of your post. Id 3 occurs 6 times, and 2 and 5
>> occur twice each in your example.. How do you get (1,1,2,2,3,3,4,4,5,5) out
>> of that? In other words, specify the mapping of old id's to new.
>>
>>
>>
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>
>>
>>
>> On Sun, Sep 16, 2018 at 11:51 AM Liu, Lei <lei.liu at wustl.edu> wrote:
>>
>> Hi there,
>>
>> I tried to generate bootstrap samples for clustered data. Here is some
>> code I found in the web to do the work:
>>
>> id=c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
>> y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2)
>> x=c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1 )
>>
>> xx=data.frame(id, x, y)
>>
>> boot.cluster <- function(x, id){
>>
>>   boot.id <- sample(unique(id), replace=T)
>>   out <- lapply(boot.id, function(i) x[id%in%i,])
>>
>>   return( do.call("rbind",out) )
>>
>> }
>>
>> boot.pro=boot.cluster(xx, xx$id)
>>
>> Now I have the output
>>
>>    id x   y
>> 5   3 0 0.4
>> 6   3 0 1.0
>> 51  3 0 0.4
>> 61  3 0 1.0
>> 9   5 1 0.5
>> 10  5 1 2.0
>> 52  3 0 0.4
>> 62  3 0 1.0
>> 3   2 1 0.4
>> 4   2 1 0.3
>>
>> However, the id variable is the original id, while I want to take the new
>> id as (1, 1, 2, 2, 3, 3, 4, 4, 5, 5) for later analysis. Can anyone show me
>> how to do it? Of note, the same original id may have duplicates since the
>> bootstrap sample is drawn with replacement. Thanks a lot!
>>
>> Lei
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From lei@liu @ending from wu@tl@edu  Sun Sep 16 21:52:52 2018
From: lei@liu @ending from wu@tl@edu (Liu, Lei)
Date: Sun, 16 Sep 2018 19:52:52 +0000
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <CAGxFJbQ51K8m6YgsRPHdKjWNX2GmcxEzE-kQDJ3XzdZT8Hm_0g@mail.gmail.com>
References: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <CAGxFJbQ51K8m6YgsRPHdKjWNX2GmcxEzE-kQDJ3XzdZT8Hm_0g@mail.gmail.com>
Message-ID: <SN4PR0201MB3405D3F4FDD6DB4863D3C037F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>

Sorry for the confusion. I just want to recode the id variable to 1 to 5 in the bootstrapped sample. This way I can do e.g., a mixed effects model using the new id as the cluster. Thanks!

Lei

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Sunday, September 16, 2018 2:21 PM
To: Liu, Lei <lei.liu at wustl.edu>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] bootstrap sample for clustered data

I can't make any sense of your post. Id 3 occurs 6 times, and 2 and 5 occur twice each in your example.. How do you get (1,1,2,2,3,3,4,4,5,5) out of that? In other words, specify the mapping of old id's to new.

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 16, 2018 at 11:51 AM Liu, Lei <lei.liu at wustl.edu<mailto:lei.liu at wustl.edu>> wrote:
Hi there,

I tried to generate bootstrap samples for clustered data. Here is some code I found in the web to do the work:

id=c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2)
x=c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1 )

xx=data.frame(id, x, y)

boot.cluster <- function(x, id){

  boot.id<http://boot.id> <- sample(unique(id), replace=T)
  out <- lapply(boot.id<http://boot.id>, function(i) x[id%in%i,])

  return( do.call("rbind",out) )

}

boot.pro<http://boot.pro>=boot.cluster(xx, xx$id)

Now I have the output

   id x   y
5   3 0 0.4
6   3 0 1.0
51  3 0 0.4
61  3 0 1.0
9   5 1 0.5
10  5 1 2.0
52  3 0 0.4
62  3 0 1.0
3   2 1 0.4
4   2 1 0.3

However, the id variable is the original id, while I want to take the new id as (1, 1, 2, 2, 3, 3, 4, 4, 5, 5) for later analysis. Can anyone show me how to do it? Of note, the same original id may have duplicates since the bootstrap sample is drawn with replacement. Thanks a lot!

Lei


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From zhhhw@ng @ending from umich@edu  Mon Sep 17 00:23:09 2018
From: zhhhw@ng @ending from umich@edu (Zhihao Huang)
Date: Sun, 16 Sep 2018 18:23:09 -0400
Subject: [R] makeCluster() hangs infinitely
Message-ID: <CADBpgp0PsJ7M5MATA8jkMQA1DnJ-HmQRXzGLcq=TyKe8UWG7Ag@mail.gmail.com>

Hi all,

The function makeCluster() of parallel does not work on my laptop. It hangs
infinitely.

*1. Problem Summary:*

> # Loading parallel packages

> library(parallel)

> cl <- makeCluster(2) # It hangs at this line of code.
It hangs at the second line of the code.

*2. Potential Reason*
I also tried to see the details of what it does internally by using the
following code.

> library(future)

> cl <- future::makeClusterPSOCK(1L, verbose = TRUE) # It hangs at this
line of code.
And it returns the following descriptions and hangs.

*Workers: [n = 1] ?localhost?*

*Base port: 11214*

*Creating node 1 of 1 ...*

*- setting up node*

*Starting worker #1 on ?localhost?:
'/Library/Frameworks/R.framework/Resources/bin/Rscript'
--default-packages=datasets,utils,grDevices,graphics,stats,methods -e
'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT=/dev/null
TIMEOUT=2592000 XDR=TRUE*

*Waiting for worker #1 on ?localhost? to connect back*
So the problem is that the "worker #1 on 'local host'" never connects back,
and that's why it hangs forever. I have no idea what causes this.

*3. my sessionInfo():*

R version 3.5.1 (2018-07-02)

Platform: x86_64-apple-darwin15.6.0 (64-bit)

Running under: macOS High Sierra 10.13.6


Matrix products: default

BLAS:
/Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib

LAPACK:
/Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib


locale:

[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_3.5.1

I spent hours searching for the solutions but failed. It looks like some
other people met similar problem here
<http://r.789695.n4.nabble.com/makeCluster-hangs-td4748238.html>. Also, I
posted this question online here
<https://stackoverflow.com/questions/52264460/r-parallel-makecluster-hangs-infinitely-on-mac/52284709#52284709>
a
week ago.

Any suggestion would be appreciated. Thanks a lot!

Thanks,
Zhihao
--
Zhihao (Daniel) Huang
Graduate Student
Department of Statistics,
University of Michigan, Ann Arbor
Email: zhhhwang at umich.edu

-- 
? ??
Zhihao Huang

Graduate Student
Department of Statistics,
University of Michigan, Ann Arbor
Email: zhhhwang at umich.edu

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Sep 17 03:05:09 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 16 Sep 2018 18:05:09 -0700
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <SN4PR0201MB3405F2A5E3D547295238C395F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
References: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <CAGxFJbQ51K8m6YgsRPHdKjWNX2GmcxEzE-kQDJ3XzdZT8Hm_0g@mail.gmail.com>
 <SN4PR0201MB3405D3F4FDD6DB4863D3C037F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <CAGxFJbTOQCLNnK_Ewn50udoMjg8kW5UBGZzheBWm7WUYMjYCEA@mail.gmail.com>
 <SN4PR0201MB3405F2A5E3D547295238C395F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbSAr=UJhNsqYZCkpP5htbNaJSdBiTndWiP7WKReZELUrw@mail.gmail.com>

Unless there is good reason not to -- which is not the case here --
**always" cc the list. I have done that here.

"Can you help me with it?"
Nope. I'm not a private consultant, and I already made an attempt to do so,
which you seem to have completely ignored. So I'm done.
By the way, "Unfortunately it couldn?t work for my case" is a completely
meaningless comment. You need to explicitly show what you did and what
error messages you received. Read the posting guide below for how to post
an intelligible question.
FInally, if you think this is a mixed model issue -- which I believe you
are confused about, but as I can't penetrate your comments, maybe I'm wrong
-- post on the r-sig-mixed-models list,not here. Same comments go for
posting an intelligible question apply there.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 16, 2018 at 5:34 PM Liu, Lei <lei.liu at wustl.edu> wrote:

> Hi Bert,
>
>
>
> Thanks for your help. Unfortunately it couldn?t work for my case. Please
> see my code below. Here id is the cluster. Note different clusters have
> different number of subjects, some have 2, some have 3.
>
>
>
> id=c(1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5)
>
> y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2, 2.2, 3)
>
> x=c(0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1 )
>
>
>
> xx=data.frame(id, x, y)
>
>
>
> boot.cluster <- function(x, id){
>
>
>
>   boot.id <- sample(unique(id), replace=T)
>
>   out <- lapply(boot.id, function(i) x[id%in%i,])
>
>
>
>   return( do.call("rbind",out) )
>
>
>
> }
>
>
>
> boot.xx=boot.cluster(xx, xx$id)
>
>
>
> Here is the boot.xx dataset:
>
>
>
>    id x   y
>
> 5   3 0 0.4
>
> 6   3 0 1.0
>
> 7   3 0 0.9
>
> 1   1 0 0.5
>
> 2   1 0 0.6
>
> 11  5 1 2.2
>
> 12  5 1 3.0
>
> 3   2 1 0.4
>
> 4   2 1 0.3
>
> 13  1 0 0.5
>
> 21  1 0 0.6
>
>
>
> You can see that some clusters (ids) appears multiple times (e.g., id 1
> appears in two places ? 4 rows), since bootstrap does a sample *with
> replacement*, we could have the same cluster multiple times. Thus, we
> cannot do a mixed effects model using this data, as we should assume all
> the clusters are different in this new data. Instead, I will reorganize the
> data as below. This is the step I need help:
>
>
>
> new.id x   y
>
> 5   1 0 0.4
>
> 6   1 0 1.0
>
> 7   1 0 0.9
>
> 1   2 0 0.5
>
> 2   2 0 0.6
>
> 11  3 1 2.2
>
> 12  3 1 3.0
>
> 3   4 1 0.4
>
> 4   4 1 0.3
>
> 13  5 0 0.5
>
> 21  5 0 0.6
>
>
>
> Can you help me with it? Thanks a lot!
>
>
>
> Lei
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Sunday, September 16, 2018 3:36 PM
> *To:* Liu, Lei <lei.liu at wustl.edu>
> *Subject:* Re: [R] bootstrap sample for clustered data
>
>
>
> You can do a mixed effects model using the existing id's without recoding.
>
>
>
> But if you insist, is this the sort of thing you want?
>
>
>
> set.seed(-12345) # for reprodicibility
>
> id <- factor(sample(2:5, 10, rep=TRUE))
> id
> new.id <- factor(id,labels = seq_along(levels(id)))
> new.id
>
>
>
> Note: There's a slightly slicker way to do this, but it bypasses the
> factor() API, and I prefer not to do that.
>
>
>
> Cheers,
>
> Bert
>
>
>
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
>
>
> On Sun, Sep 16, 2018 at 12:52 PM Liu, Lei <lei.liu at wustl.edu> wrote:
>
> Sorry for the confusion. I just want to recode the id variable to 1 to 5
> in the bootstrapped sample. This way I can do e.g., a mixed effects model
> using the new id as the cluster. Thanks!
>
> Lei
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Sunday, September 16, 2018 2:21 PM
> *To:* Liu, Lei <lei.liu at wustl.edu>
> *Cc:* R-help <r-help at r-project.org>
> *Subject:* Re: [R] bootstrap sample for clustered data
>
>
>
> I can't make any sense of your post. Id 3 occurs 6 times, and 2 and 5
> occur twice each in your example.. How do you get (1,1,2,2,3,3,4,4,5,5) out
> of that? In other words, specify the mapping of old id's to new.
>
>
>
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
>
>
> On Sun, Sep 16, 2018 at 11:51 AM Liu, Lei <lei.liu at wustl.edu> wrote:
>
> Hi there,
>
> I tried to generate bootstrap samples for clustered data. Here is some
> code I found in the web to do the work:
>
> id=c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
> y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2)
> x=c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1 )
>
> xx=data.frame(id, x, y)
>
> boot.cluster <- function(x, id){
>
>   boot.id <- sample(unique(id), replace=T)
>   out <- lapply(boot.id, function(i) x[id%in%i,])
>
>   return( do.call("rbind",out) )
>
> }
>
> boot.pro=boot.cluster(xx, xx$id)
>
> Now I have the output
>
>    id x   y
> 5   3 0 0.4
> 6   3 0 1.0
> 51  3 0 0.4
> 61  3 0 1.0
> 9   5 1 0.5
> 10  5 1 2.0
> 52  3 0 0.4
> 62  3 0 1.0
> 3   2 1 0.4
> 4   2 1 0.3
>
> However, the id variable is the original id, while I want to take the new
> id as (1, 1, 2, 2, 3, 3, 4, 4, 5, 5) for later analysis. Can anyone show me
> how to do it? Of note, the same original id may have duplicates since the
> bootstrap sample is drawn with replacement. Thanks a lot!
>
> Lei
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From j@ck@onmrodrigue@ @ending from gm@il@com  Mon Sep 17 05:03:20 2018
From: j@ck@onmrodrigue@ @ending from gm@il@com (Jackson Rodrigues)
Date: Mon, 17 Sep 2018 00:03:20 -0300
Subject: [R] Set the same colour range for 2 != rasters
Message-ID: <CAPL76w89=D1YRax-gN_ZRoeJfwspHcS5duMe8zxqsoc5S1rnrQ@mail.gmail.com>

Dear all,

My name is Jackson.
I am trying to set the same colour range for 2 rasters (max and min
temperatures). Both rasters have different numerical ranges but the same
dimensions
dimensions  : 4346, 4365, 18970290, 1  (nrow, ncol, ncell, nlayers)

The lowest value is 3 and the highest is 31. So my colour palette should
range from 3 to 31 and be useful for both temperatures

However I got a message saying that S4 and vector cannot be coerced.
So far I understand why it is not working but how to fix it?

A few lines from my code.

####
cols<-colorRampPalette(c("royalblue","springgreen","yellow","orange","red"))(29)

Temp.interval = seq(from=3, to=31)

# creating colour vectors
col1 <- cols[findInterval(TMin_masked$prj, vec =  Temp.interval  )]

Error in as.double(x) :
  cannot coerce type 'S4' to vector of type 'double'
####

Thank you all!

Best regards.

Jackson

	[[alternative HTML version deleted]]


From p@ul @ending from @t@t@@uckl@nd@@c@nz  Mon Sep 17 05:00:01 2018
From: p@ul @ending from @t@t@@uckl@nd@@c@nz (Paul Murrell)
Date: Mon, 17 Sep 2018 15:00:01 +1200
Subject: [R] 
 [FORGED] Re: Change the position of label when using R package
 eulerr
In-Reply-To: <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
 <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
Message-ID: <6de0953e-2ba4-70d9-e24c-a9025362c030@stat.auckland.ac.nz>

Hi

The 'x' component of the 't' grob that you get back from grid.get() is a 
unit object, which you can subset and assign to a subset, for example 
this code nudges the fourth label up and to the right 1mm in each 
direction ...


x <- t$x
y <- t$y

x[4] <- t$x[4] + unit(1, "mm")
y[4] <- t$y[4] + unit(1, "mm")

grid.edit("quantities.grob", x=x, y=y)


... is that the sort of thing you were looking for ?

Paul

On 15/09/18 09:03, Aimin Yan wrote:
> Thank you,
> 
> I figure out a way like this:
> 
> fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
>                      "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> "LAD&nonXL_MEF" = 541,
>                      "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> 
> plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
> = 1),alpha=0.7)
> 
> grid.ls()
> t <- grid.get("quantities.grob")
> names(t)
> 
> # Change these value will change the location of label.
> 
> grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
>                                           unit(-14.883684319653, "native"),
>                                           unit(13.9805892820006, "native"),
>                                           unit(-12.8808987356981, "native"),
>                                           unit(-11.488226371243, "native"),
>                                           unit(-9.51474016085318, "native"),
>                                           unit(-1.00436055190216, "native")))
> 
> grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
>                                           unit(4.78718651828883, "native"),
>                                           unit(0.25941593099694, "native"),
>                                           unit(-4.32200781461293, "native"),
>                                           unit(25.7349463488991, "native"),
>                                           unit(-22.7610031110325, "native"),
>                                           unit(14.5001560838519, "native")))
> 
> However, here I just want to change the x and y  value of 4th label, does
> anyone know how to set it?
> 
> Aimin
> 
> On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net>
> wrote:
> 
>>
>>> On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
>>>
>>> I am using eulerr to get venn.
>>> My code is like:
>>>
>>> fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
>>>                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
>>> "LAD&nonXL_MEF" = 541,
>>>                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
>>>
>>> plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
>> list(font
>>> = 1),alpha=0.7)
>>>
>>> After I get the figure, I find the position of some  labels need to be
>>> adjusted.
>>>
>>> Does anyone has some idea about how to process this?
>>
>> Looking at the code of plot.euler we see that the plotting paradigm is
>> grid. So you could assign the output to a data.object name, search for list
>> items that match the names of the labels you want to reposition, and modify
>> the position values. You would need to be more specific, if you want a
>> worked example.
>>
>> As far as I can see the lables and postions are fairly deep inside a list
>> structure:
>>
>>   $ children     :List of 1
>>    ..$ GRID.gTree.12:List of 5
>>    .. ..$ children
>>           $ diagram.grob.1
>>              $children
>> .. .. .. .. ..$ labels.grob    :List of 11
>>    .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
>>    .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native
>> 69.2native 11.9native
>>    .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>>    .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
>>    .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native
>> 5.24native 27.86native
>>    .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>>    .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
>>
>> --
>> David.
>>>
>>>
>>> Thank you,
>>>
>>> Aimin
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'
>>   -Gehm's Corollary to Clarke's Third Law
>>
>>
>>
>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From lei@liu @ending from wu@tl@edu  Mon Sep 17 05:22:44 2018
From: lei@liu @ending from wu@tl@edu (Liu, Lei)
Date: Mon, 17 Sep 2018 03:22:44 +0000
Subject: [R] bootstrap sample for clustered data
Message-ID: <SN4PR0201MB340568ED119F5665F16A9386F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>

Hi there,

I posted this message before but there may be some confusion in my previous post. So here is a clearer version:

I'd like to do a bootstrap sampling for clustered data. Then I will run some complicated models (say mixed effects models) on the bootstrapped sample. Here id is the cluster. Note different clusters have different number of subjects, e.g., id 2 has 2 observations, id 3 has 3 observations.

id=c(1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5)
y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2, 2.2, 3)
x=c(0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1 )

xx=data.frame(id, x, y)

boot.cluster <- function(x, id){

  boot.id <- sample(unique(id), replace=T)
  out <- lapply(boot.id, function(i) x[id%in%i,])

  return( do.call("rbind",out) )

}

boot.xx=boot.cluster(xx, xx$id)

Here is the generated boot.xx dataset:

   id x y
   3 0 0.4
   3 0 1.0
   3 0 0.9
   1 0 0.5
   1 0 0.6
   5 1 2.2
   5 1 3.0
   2 1 0.4
   2 1 0.3
   1 0 0.5
   1 0 0.6

You can see that some clusters (ids) appears multiple times (e.g., id 1 appears in two places - 4 rows), since bootstrap does a sample with replacement, we could have the same cluster multiple times. Thus, we cannot do a mixed effects model using this data, as we should assume all the clusters are different in this new data. Instead, I will reorganize the data as below (id is reordered from the above boot.xx data). This is the step I need help:

  id x  y
   1 0 0.4
   1 0 1.0
   1 0 0.9
   2 0 0.5
   2 0 0.6
   3 1 2.2
   3 1 3.0
   4 1 0.4
   4 1 0.3
   5 0 0.5
   5 0 0.6

Can someone help me with it? Thanks!

Lei Liu
Professor of Biostatistics
Washington University in St. Louis


	[[alternative HTML version deleted]]


From henrik@bengt@@on @ending from gm@il@com  Mon Sep 17 06:37:39 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Sun, 16 Sep 2018 21:37:39 -0700
Subject: [R] makeCluster() hangs infinitely
In-Reply-To: <CADBpgp0PsJ7M5MATA8jkMQA1DnJ-HmQRXzGLcq=TyKe8UWG7Ag@mail.gmail.com>
References: <CADBpgp0PsJ7M5MATA8jkMQA1DnJ-HmQRXzGLcq=TyKe8UWG7Ag@mail.gmail.com>
Message-ID: <CAFDcVCSvR_=-EEqkkq-yfNpFZ8TGLxa3M4teko935ZMCKMzsAw@mail.gmail.com>

Hi,

did you see my answer on StackOverflow? Specifically, if you set
argument 'outfile = NULL' to either of those two functions, you'll get
a little bit more information that *might* provide some clues.

/Henrik


On Sun, Sep 16, 2018 at 5:38 PM Zhihao Huang <zhhhwang at umich.edu> wrote:
>
> Hi all,
>
> The function makeCluster() of parallel does not work on my laptop. It hangs
> infinitely.
>
> *1. Problem Summary:*
>
> > # Loading parallel packages
>
> > library(parallel)
>
> > cl <- makeCluster(2) # It hangs at this line of code.
> It hangs at the second line of the code.
>
> *2. Potential Reason*
> I also tried to see the details of what it does internally by using the
> following code.
>
> > library(future)
>
> > cl <- future::makeClusterPSOCK(1L, verbose = TRUE) # It hangs at this
> line of code.
> And it returns the following descriptions and hangs.
>
> *Workers: [n = 1] ?localhost?*
>
> *Base port: 11214*
>
> *Creating node 1 of 1 ...*
>
> *- setting up node*
>
> *Starting worker #1 on ?localhost?:
> '/Library/Frameworks/R.framework/Resources/bin/Rscript'
> --default-packages=datasets,utils,grDevices,graphics,stats,methods -e
> 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT=/dev/null
> TIMEOUT=2592000 XDR=TRUE*
>
> *Waiting for worker #1 on ?localhost? to connect back*
> So the problem is that the "worker #1 on 'local host'" never connects back,
> and that's why it hangs forever. I have no idea what causes this.
>
> *3. my sessionInfo():*
>
> R version 3.5.1 (2018-07-02)
>
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>
> Running under: macOS High Sierra 10.13.6
>
>
> Matrix products: default
>
> BLAS:
> /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
>
> LAPACK:
> /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
>
>
> locale:
>
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> loaded via a namespace (and not attached):
>
> [1] compiler_3.5.1
>
> I spent hours searching for the solutions but failed. It looks like some
> other people met similar problem here
> <http://r.789695.n4.nabble.com/makeCluster-hangs-td4748238.html>. Also, I
> posted this question online here
> <https://stackoverflow.com/questions/52264460/r-parallel-makecluster-hangs-infinitely-on-mac/52284709#52284709>
> a
> week ago.
>
> Any suggestion would be appreciated. Thanks a lot!
>
> Thanks,
> Zhihao
> --
> Zhihao (Daniel) Huang
> Graduate Student
> Department of Statistics,
> University of Michigan, Ann Arbor
> Email: zhhhwang at umich.edu
>
> --
> ? ??
> Zhihao Huang
>
> Graduate Student
> Department of Statistics,
> University of Michigan, Ann Arbor
> Email: zhhhwang at umich.edu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giftedlife2014 @ending from gm@il@com  Mon Sep 17 09:17:03 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Mon, 17 Sep 2018 08:17:03 +0100
Subject: [R] Data.frame of Different Length
Message-ID: <CAC8ss33yoTC1R03t=eHLLBGQO7B5y=rqoQ12nbqsq+Ktd_J2gQ@mail.gmail.com>

Dear Contributors,

I have two data frame of different column lengths. I am trying to have them
in one data frame.
Using
A<-d1$date
B<-d2$date
a<-data.table(A )[ , I := .I][data.table(B )[ , I := .I], on = "I"]
I got
1: 2005-01-04  1 2005-01-04
 2: 2005-01-19  2 2005-01-19
 3: 2005-01-22  3 2005-01-22
 4: 2005-02-24  4 2005-02-19
 5: 2005-05-09  5 2005-02-24
 6: 2005-05-16  6 2005-05-09
 7: 2005-06-17  7 2005-05-11
 8: 2005-07-17  8 2005-05-16
 9: 2005-08-07  9 2005-06-13
10: 2005-09-11 10 2005-06-17
11: 2005-09-13 11 2005-06-22
12: 2005-09-15 12 2005-07-18
13:         NA 13 2005-08-03
14:         NA 14 2005-08-07
15:         NA 15 2005-08-10
16:         NA 16 2005-08-25
17:         NA 17 2005-09-13
18:         NA 18 2005-09-15
19:         NA 19 2005-10-13
20:         NA 20 2005-12-15
which is fine.

I have two more problems:
1) how to remove the nos 1 to 20 inserted at the middle of the dates.

2) how to include more columns.

I have about 5 columns of different lengths which I wish to have in one
data frame.

I will remain grateful if assisted.

Best regards
Ogbos

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Sep 17 09:32:12 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 17 Sep 2018 00:32:12 -0700
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <SN4PR0201MB340568ED119F5665F16A9386F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
References: <SN4PR0201MB340568ED119F5665F16A9386F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
Message-ID: <894A4868-409A-44DA-A8D8-2C6CE7F252A6@dcn.davis.ca.us>

You are telling us that the ID values in your data set indicate clusters. However you went about making that determination in the first place might be an obvious(?) way to do it again with your bootstrapped sample, ignoring the cluster assignments you have in place. This is the wrong place to have a discussion about which theoretical method for cluster identification you should use, and if you do know that then searching the web or using the sos package would be the appropriate way to find implementations of a specific clustering algorithm.

I am not an ME expert, but AFAIK "complicated" analyses such as mixed effects models tend to have rather hefty appetites for data completeness, so you may have to design a special sampling plan in order to avoid generating data sets for which those analyses won't break, and you will probably need a very large data set to start with in order to have sufficient data in each cluster. That is, you may be better off keeping the original cluster identification and just restructuring your bootstrap sampling to sample within clusters.

The R-sig-me mailing list is probably a better venue for your questions. 

On September 16, 2018 8:22:44 PM PDT, "Liu, Lei" <lei.liu at wustl.edu> wrote:
>Hi there,
>
>I posted this message before but there may be some confusion in my
>previous post. So here is a clearer version:
>
>I'd like to do a bootstrap sampling for clustered data. Then I will run
>some complicated models (say mixed effects models) on the bootstrapped
>sample. Here id is the cluster. Note different clusters have different
>number of subjects, e.g., id 2 has 2 observations, id 3 has 3
>observations.
>
>id=c(1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5)
>y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2, 2.2, 3)
>x=c(0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1 )
>
>xx=data.frame(id, x, y)
>
>boot.cluster <- function(x, id){
>
>  boot.id <- sample(unique(id), replace=T)
>  out <- lapply(boot.id, function(i) x[id%in%i,])
>
>  return( do.call("rbind",out) )
>
>}
>
>boot.xx=boot.cluster(xx, xx$id)
>
>Here is the generated boot.xx dataset:
>
>   id x y
>   3 0 0.4
>   3 0 1.0
>   3 0 0.9
>   1 0 0.5
>   1 0 0.6
>   5 1 2.2
>   5 1 3.0
>   2 1 0.4
>   2 1 0.3
>   1 0 0.5
>   1 0 0.6
>
>You can see that some clusters (ids) appears multiple times (e.g., id 1
>appears in two places - 4 rows), since bootstrap does a sample with
>replacement, we could have the same cluster multiple times. Thus, we
>cannot do a mixed effects model using this data, as we should assume
>all the clusters are different in this new data. Instead, I will
>reorganize the data as below (id is reordered from the above boot.xx
>data). This is the step I need help:
>
>  id x  y
>   1 0 0.4
>   1 0 1.0
>   1 0 0.9
>   2 0 0.5
>   2 0 0.6
>   3 1 2.2
>   3 1 3.0
>   4 1 0.4
>   4 1 0.3
>   5 0 0.5
>   5 0 0.6
>
>Can someone help me with it? Thanks!
>
>Lei Liu
>Professor of Biostatistics
>Washington University in St. Louis
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From h@medh@@eli @ending from gm@il@com  Mon Sep 17 09:55:59 2018
From: h@medh@@eli @ending from gm@il@com (Hamed Ha)
Date: Mon, 17 Sep 2018 08:55:59 +0100
Subject: [R] Problem with lm.resid() when weights are provided
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8368B12FB@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
 <22333_1536669565_w8BCdOUV005487_CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368B0E61@FHSDB2D11-2.csu.mcmaster.ca>
 <CAAC89xexc0tHnC8n_n0Z+=3xtPDFmB394=U75V3KLe9RQ6OWdA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368B12FB@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAAC89xdt93_tGBsLrHQqMjjAA9uEJ2eRH4ptiVz0gWJ2CJa8VA@mail.gmail.com>

H i John,

Thank you for your reply.

I see your point, thanks. I checked lm.wfit() and realised that there is a
tol parameter that is already set to 10^-7. This is not even the half
decimal to the machine precision. Furthermore, plying with tol parameter
does not solve the problem, as far as I checked.

I still see this issue as critical and we should report it to the R core
team to be investigated more. What do you think?


Regards,
Hamed.


On Fri, 14 Sep 2018 at 22:46, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Hamed,
>
> When you post a question to r-help, generally you should cc subsequent
> messages there as well, as I've done to this response.
>
> The algorithm that lm() uses is much more numerically stable than
> inverting the weighted sum-of-squares-and-product matrix. If you want to
> see how the computations are done, look at lm.wfit(), in which the
> residuals and fits are computed as
>
>     z$residuals <- z$residuals/wts
>     z$fitted.values <- y - z$residuals
>
> Zero weights are handled specially, and your tiny weights are thus the
> source of the problem. When you divide by a number less than the machine
> double-epsilon, you can't expect numerically stable results. I suppose that
> lm.wfit() could check for 0 weights to a tolerance rather than exactly.
>
> John
>
> > -----Original Message-----
> > From: Hamed Ha [mailto:hamedhaseli at gmail.com]
> > Sent: Friday, September 14, 2018 5:34 PM
> > To: Fox, John <jfox at mcmaster.ca>
> > Subject: Re: [R] Problem with lm.resid() when weights are provided
> >
> > Hi John,
> >
> > Thank you for your reply.
> >
> > I agree that the small weights are the potential source of the
> instability in the
> > result. I also suspected that there are some failure/bugs in the actual
> > algorithm that R uses for fitting the model. I remember that at some
> points I
> > checked the theoretical estimation of the parameters, solve(t(x) %*% w
> %*%
> > x) %*% t(x) %*% w %*% y, (besides the point that I had to set tol
> parameter in
> > solve() to a super small value) and realised  that lm() and the
> theoretical
> > results match together. That is the parameter estimation is right in R.
> > Moreover, I checked the predictions, predict(lm.fit), and it was right.
> Then the
> > only source of error remained was resid() function. I further checked
> this
> > function and it is nothing more than calling a sub-element from and lm()
> fit.
> > Putting all together, I think that there is something wrong/bug/miss-
> > configuration in the lm() algorithm and I highly recommend the R core
> team to
> > fix that.
> >
> > Please feel free to contact me for more details if required.
> >
> > Warm regards,
> > Hamed.
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > On Fri, 14 Sep 2018 at 13:35, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca> > wrote:
> >
> >
> >       Dear Hamed,
> >
> >       I don't think that anyone has picked up on this problem.
> >
> >       What's peculiar about your weights is that several are 0 within
> > rounding error but not exactly 0:
> >
> >       > head(df)
> >                  y          x       weight
> >       1  1.5115614  0.5520924 2.117337e-34
> >       2 -0.6365313 -0.1259932 2.117337e-34
> >       3  0.3778278  0.4209538 4.934135e-31
> >       4  3.0379232  1.4031545 2.679495e-24
> >       5  1.5364652  0.4607686 2.679495e-24
> >       6 -2.3772787 -0.7396358 6.244160e-21
> >
> >       I can reproduce the results that you report:
> >
> >       > (mod.1 <- lm(y ~ x, data=df))
> >
> >       Call:
> >       lm(formula = y ~ x, data = df)
> >
> >       Coefficients:
> >       (Intercept)            x
> >          -0.04173      2.03790
> >
> >       > max(resid(mod.1))
> >       [1] 1.14046
> >       > (mod.2 <- lm(y ~ x, data=df, weights=weight))
> >
> >       Call:
> >       lm(formula = y ~ x, data = df, weights = weight)
> >
> >       Coefficients:
> >       (Intercept)            x
> >          -0.05786      1.96087
> >
> >       > max(resid(mod.2))
> >       [1] 36.84939
> >
> >       But the problem disappears when the tiny nonzero weight are set to
> 0:
> >
> >       > df2 <- df
> >       > df2$weight <- zapsmall(df2$weight)
> >       > head(df2)
> >                  y          x weight
> >       1  1.5115614  0.5520924      0
> >       2 -0.6365313 -0.1259932      0
> >       3  0.3778278  0.4209538      0
> >       4  3.0379232  1.4031545      0
> >       5  1.5364652  0.4607686      0
> >       6 -2.3772787 -0.7396358      0
> >       > (mod.3 <- update(mod.2, data=df2))
> >
> >       Call:
> >       lm(formula = y ~ x, data = df2, weights = weight)
> >
> >       Coefficients:
> >       (Intercept)            x
> >          -0.05786      1.96087
> >
> >       > max(resid(mod.3))
> >       [1] 1.146663
> >
> >       I don't know exactly why this happens, but suspect numerical
> > instability produced by the near-zero weights, which are smaller than the
> > machine double-epsilon
> >
> >       > .Machine$double.neg.eps
> >       [1] 1.110223e-16
> >
> >       The problem also disappears, e.g., if the tiny weight are set to
> 1e-15
> > rather than 0.
> >
> >       I hope this helps,
> >        John
> >
> >       -----------------------------------------------------------------
> >       John Fox
> >       Professor Emeritus
> >       McMaster University
> >       Hamilton, Ontario, Canada
> >       Web: https://socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >       > -----Original Message-----
> >       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:
> r-help-
> > bounces at r-project.org> ] On Behalf Of Hamed Ha
> >       > Sent: Tuesday, September 11, 2018 8:39 AM
> >       > To: r-help at r-project.org <mailto:r-help at r-project.org>
> >       > Subject: [R] Problem with lm.resid() when weights are provided
> >       >
> >       > Dear R Help Team.
> >       >
> >       > I get some weird results when I use the lm function with weight.
> The
> > issue can
> >       > be reproduced by the example below:
> >       >
> >       >
> >       > The input data is (weights are intentionally designed to reflect
> some
> >       > structures in the data)
> >       >
> >       >
> >       > > df
> >       > y x weight
> >       >  1.51156139  0.55209240 2.117337e-34
> >       > -0.63653132 -0.12599316 2.117337e-34
> >       >  0.37782776  0.42095384 4.934135e-31
> >       >  3.03792318  1.40315446 2.679495e-24
> >       >  1.53646523  0.46076858 2.679495e-24
> >       > -2.37727874 -0.73963576 6.244160e-21
> >       >  0.37183065  0.20407468 1.455107e-17
> >       > -1.53917553 -0.95519361 1.455107e-17
> >       >  1.10926675  0.03897129 3.390908e-14
> >       > -0.37786333 -0.17523593 3.390908e-14
> >       >  2.43973603  0.97970095 7.902000e-11
> >       > -0.35432394 -0.03742559 7.902000e-11
> >       >  2.19296613  1.00355263 4.289362e-04
> >       >  0.49845532  0.34816207 4.289362e-04
> >       >  1.25005260  0.76306225 5.000000e-01
> >       >  0.84360691  0.45152356 5.000000e-01
> >       >  0.29565993  0.53880068 5.000000e-01
> >       > -0.54081334 -0.28104525 5.000000e-01
> >       >  0.83612836 -0.12885659 9.995711e-01
> >       > -1.42526769 -0.87107631 9.999998e-01
> >       >  0.10204789 -0.11649899 1.000000e+00
> >       >  1.14292898  0.37249631 1.000000e+00
> >       > -3.02942081 -1.28966997 1.000000e+00
> >       > -1.37549764 -0.74676145 1.000000e+00
> >       > -2.00118016 -0.55182759 1.000000e+00
> >       > -4.24441674 -1.94603608 1.000000e+00
> >       >  1.17168144  1.00868008 1.000000e+00
> >       >  2.64007761  1.26333069 1.000000e+00
> >       >  1.98550114  1.18509599 1.000000e+00
> >       > -0.58941683 -0.61972416 9.999998e-01
> >       > -4.57559611 -2.30914920 9.995711e-01
> >       > -0.82610544 -0.39347576 9.995711e-01
> >       > -0.02768220  0.20076910 9.995711e-01
> >       >  0.78186399  0.25690215 9.995711e-01
> >       > -0.88314153 -0.20200148 5.000000e-01
> >       > -4.17076452 -2.03547588 5.000000e-01
> >       >  0.93373070  0.54190626 4.289362e-04
> >       > -0.08517734  0.17692491 4.289362e-04
> >       > -4.47546619 -2.14876688 4.289362e-04
> >       > -1.65509103 -0.76898087 4.289362e-04
> >       > -0.39403030 -0.12689705 4.289362e-04
> >       >  0.01203300 -0.18689898 1.841442e-07
> >       > -4.82762639 -2.31391121 1.841442e-07
> >       > -0.72658380 -0.39751171 3.397282e-14
> >       > -2.35886866 -1.01082109 0.000000e+00
> >       > -2.03762707 -0.96439902 0.000000e+00
> >       >  0.90115123  0.60172286 0.000000e+00
> >       >  1.55999194  0.83433953 0.000000e+00
> >       >  3.07994058  1.30942776 0.000000e+00
> >       >  1.78871462  1.10605530 0.000000e+00
> >       >
> >       >
> >       >
> >       > Running simple linear model returns:
> >       >
> >       > > lm(y~x,data=df)
> >       >
> >       > Call:
> >       > lm(formula = y ~ x, data = df)
> >       >
> >       > Coefficients:
> >       > (Intercept)            x
> >       >    -0.04173      2.03790
> >       >
> >       > and
> >       > > max(resid(lm(y~x,data=df)))
> >       > [1] 1.14046
> >       >
> >       >
> >       > *HOWEVER if I use the weighted model then:*
> >       >
> >       > lm(formula = y ~ x, data = df, weights = df$weights)
> >       >
> >       > Coefficients:
> >       > (Intercept)            x
> >       >    -0.05786      1.96087
> >       >
> >       > and
> >       > > max(resid(lm(y~x,data=df,weights=df$weights)))
> >       > [1] 60.91888
> >       >
> >       >
> >       > as you see, the estimation of the coefficients are nearly the
> same
> > but the
> >       > resid() function returns a giant residual (I have some cases
> where
> > the value is
> >       > much much higher). Further, if I calculate the residuals by
> simply
> >       > predict(lm(y~x,data=df,weights=df$weights))-df$y then I get the
> true
> > value for
> >       > the residuals.
> >       >
> >       >
> >       > Thanks.
> >       >
> >       > Please do not hesitate to contact me for more details.
> >       > Regards,
> >       > Hamed.
> >       >
> >       >       [[alternative HTML version deleted]]
> >       >
> >       > ______________________________________________
> >       > R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list --
> > To UNSUBSCRIBE and more, see
> >       > https://stat.ethz.ch/mailman/listinfo/r-help
> >       > PLEASE do read the posting guide
> http://www.R-project.org/posting-
> >       > guide.html
> >       > and provide commented, minimal, self-contained, reproducible
> > code.
> >
>
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Sep 17 10:07:46 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 17 Sep 2018 01:07:46 -0700
Subject: [R] Data.frame of Different Length
In-Reply-To: <CAC8ss33yoTC1R03t=eHLLBGQO7B5y=rqoQ12nbqsq+Ktd_J2gQ@mail.gmail.com>
References: <CAC8ss33yoTC1R03t=eHLLBGQO7B5y=rqoQ12nbqsq+Ktd_J2gQ@mail.gmail.com>
Message-ID: <1B8E640A-0123-4A3F-B6B3-C7492858E938@dcn.davis.ca.us>

There are many ways to combine data frames, but the method you have chosen is extremely rare because you do not appear to be creating sensible relationships in the rows of the data frame, so your final result seems unlikely to be understandable by normal interpretation of tabular data. See ?merge for more normal ways to combine data frames.

However, with respect to your questions:

1) The usual way to remove a column is to use negative integer indexing:
a <- a[ , -2 ]

2) To add more columns, just do it again with the answer you have. I do think you are taking an over-complicated approach:

n <- max( nrow(d1), nrow(d2), nrow(d3))
ix <- seq.int( n )
a <- data.frame( d1_date=d1$date[ix], d2_date=d2$date[ix], d3_date=d3$date[ix] )

On September 17, 2018 12:17:03 AM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Contributors,
>
>I have two data frame of different column lengths. I am trying to have
>them
>in one data frame.
>Using
>A<-d1$date
>B<-d2$date
>a<-data.table(A )[ , I := .I][data.table(B )[ , I := .I], on = "I"]
>I got
>1: 2005-01-04  1 2005-01-04
> 2: 2005-01-19  2 2005-01-19
> 3: 2005-01-22  3 2005-01-22
> 4: 2005-02-24  4 2005-02-19
> 5: 2005-05-09  5 2005-02-24
> 6: 2005-05-16  6 2005-05-09
> 7: 2005-06-17  7 2005-05-11
> 8: 2005-07-17  8 2005-05-16
> 9: 2005-08-07  9 2005-06-13
>10: 2005-09-11 10 2005-06-17
>11: 2005-09-13 11 2005-06-22
>12: 2005-09-15 12 2005-07-18
>13:         NA 13 2005-08-03
>14:         NA 14 2005-08-07
>15:         NA 15 2005-08-10
>16:         NA 16 2005-08-25
>17:         NA 17 2005-09-13
>18:         NA 18 2005-09-15
>19:         NA 19 2005-10-13
>20:         NA 20 2005-12-15
>which is fine.
>
>I have two more problems:
>1) how to remove the nos 1 to 20 inserted at the middle of the dates.
>
>2) how to include more columns.
>
>I have about 5 columns of different lengths which I wish to have in one
>data frame.
>
>I will remain grateful if assisted.
>
>Best regards
>Ogbos
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From giftedlife2014 @ending from gm@il@com  Mon Sep 17 10:35:54 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Mon, 17 Sep 2018 09:35:54 +0100
Subject: [R] Data.frame of Different Length
In-Reply-To: <1B8E640A-0123-4A3F-B6B3-C7492858E938@dcn.davis.ca.us>
References: <CAC8ss33yoTC1R03t=eHLLBGQO7B5y=rqoQ12nbqsq+Ktd_J2gQ@mail.gmail.com>
 <1B8E640A-0123-4A3F-B6B3-C7492858E938@dcn.davis.ca.us>
Message-ID: <CAC8ss32_cCkcEW_nYeX5Jz30kEHEWY2vqjqqNeSZhjVWFtMx=w@mail.gmail.com>

Dear Jeff,

Yours is like reciting A, B,C or 1, 2, 3 ...

I am greatly relieved.

Many thanks.
Ogbos

On Mon, Sep 17, 2018 at 9:07 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> There are many ways to combine data frames, but the method you have chosen
> is extremely rare because you do not appear to be creating sensible
> relationships in the rows of the data frame, so your final result seems
> unlikely to be understandable by normal interpretation of tabular data. See
> ?merge for more normal ways to combine data frames.
>
> However, with respect to your questions:
>
> 1) The usual way to remove a column is to use negative integer indexing:
> a <- a[ , -2 ]
>
> 2) To add more columns, just do it again with the answer you have. I do
> think you are taking an over-complicated approach:
>
> n <- max( nrow(d1), nrow(d2), nrow(d3))
> ix <- seq.int( n )
> a <- data.frame( d1_date=d1$date[ix], d2_date=d2$date[ix],
> d3_date=d3$date[ix] )
>
> On September 17, 2018 12:17:03 AM PDT, Ogbos Okike <
> giftedlife2014 at gmail.com> wrote:
> >Dear Contributors,
> >
> >I have two data frame of different column lengths. I am trying to have
> >them
> >in one data frame.
> >Using
> >A<-d1$date
> >B<-d2$date
> >a<-data.table(A )[ , I := .I][data.table(B )[ , I := .I], on = "I"]
> >I got
> >1: 2005-01-04  1 2005-01-04
> > 2: 2005-01-19  2 2005-01-19
> > 3: 2005-01-22  3 2005-01-22
> > 4: 2005-02-24  4 2005-02-19
> > 5: 2005-05-09  5 2005-02-24
> > 6: 2005-05-16  6 2005-05-09
> > 7: 2005-06-17  7 2005-05-11
> > 8: 2005-07-17  8 2005-05-16
> > 9: 2005-08-07  9 2005-06-13
> >10: 2005-09-11 10 2005-06-17
> >11: 2005-09-13 11 2005-06-22
> >12: 2005-09-15 12 2005-07-18
> >13:         NA 13 2005-08-03
> >14:         NA 14 2005-08-07
> >15:         NA 15 2005-08-10
> >16:         NA 16 2005-08-25
> >17:         NA 17 2005-09-13
> >18:         NA 18 2005-09-15
> >19:         NA 19 2005-10-13
> >20:         NA 20 2005-12-15
> >which is fine.
> >
> >I have two more problems:
> >1) how to remove the nos 1 to 20 inserted at the middle of the dates.
> >
> >2) how to include more columns.
> >
> >I have about 5 columns of different lengths which I wish to have in one
> >data frame.
> >
> >I will remain grateful if assisted.
> >
> >Best regards
> >Ogbos
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From krylov@r00t @ending from gm@il@com  Mon Sep 17 10:42:08 2018
From: krylov@r00t @ending from gm@il@com (Ivan Krylov)
Date: Mon, 17 Sep 2018 11:42:08 +0300
Subject: [R] Help with setting locale
In-Reply-To: <CAE9q8vk7huCkPSp3yQcSOWRGbODxB0t20Urqd-UssrRVsciK5w@mail.gmail.com>
References: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
 <20180916192158.2a45b3fb@Tarkus>
 <CAE9q8vk7huCkPSp3yQcSOWRGbODxB0t20Urqd-UssrRVsciK5w@mail.gmail.com>
Message-ID: <20180917114208.3821dd0d@Tarkus>

On Sun, 16 Sep 2018 21:18:45 +0200
Kim Titcombe <ktitcombe02 at gmail.com> wrote:

> I have Windows 10. English version.

Do you have any other problems, besides the warning message at startup?

According to MSDN[1], the combination of English language
and Swiss cultural rules should be supported in Windows 10 >=
v1607 with a call like Sys.setlocale(locale="English_Switzerland"). If
that doesn't work, Sys.setlocale(locale="English") seemed to work even
on my Windows 2008 machine[2]. However, for some reason, when I call
setlocale() with two-letter arguments exactly as described on that page
("en-US", "en-CH", etc) the call fails.

-- 
Best regards,
Ivan

[1]: https://msdn.microsoft.com/library/cc233982.aspx

[2]: Also worked:

> Sys.setlocale(locale="English_United States")
[1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> Sys.setlocale(locale="English_United Kingdom")
[1] "LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252"


From m@ij@@@irkj@rvi @ending from gm@il@com  Mon Sep 17 11:41:17 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Mon, 17 Sep 2018 12:41:17 +0300
Subject: [R] constraints are inconsistent, no solution!
Message-ID: <CAJxz9NaP8WoVhMP6sCOE=ea72omJ+-nZGVFKo09-yW9aTLZiew@mail.gmail.com>

Hi!

I'm solving a quadratic programming problem with some constraints. The
problem is the second set of Amat conditions, which seem to be
inconsistent, but I cannot see why. Do you have any idea, what could be the
problem?

Thanks in advance for your help!
Maija


for(j in 1:J){
  hs[j] <-(-(gEst$KernelRegPartLin..Phi[j]^(-1.2)))
}
hs

Dmat <- matrix(0,nrow= J, ncol=J)
diag(Dmat) <- 1
dvec <- -hs
Aeq <- 0
beq <- 0
Amat <- matrix(0,J,2*J-3)
bvec <- matrix(0,2*J-3,1)

for(j in 2:nrow(Amat)){
  Amat[j-1,j-1] = -1
  Amat[j,j] = 1
}

for(j in 3:nrow(Amat)){
  Amat[j,J-1+j-2] = -1/(Q[j]-Q[j-1])
  Amat[j-1,J-1+j-2] = 1/(Q[j]-Q[j-1])
  Amat[j-2,J-1+j-2] = -1/(Q[j-1]-Q[j-2])
}

for(j in 2:ncol(bvec)) {
  bvec[j-1] = Delta1
}

for(j in 3:ncol(bvec)) {
  bvec[J-1+j-2] = Delta2
}

solution <- solve.QP(Dmat,dvec,Amat,bvec=bvec)
solution

	[[alternative HTML version deleted]]


From @imin@@t@work @ending from gm@il@com  Mon Sep 17 16:22:36 2018
From: @imin@@t@work @ending from gm@il@com (Aimin Yan)
Date: Mon, 17 Sep 2018 10:22:36 -0400
Subject: [R] 
 [FORGED] Re: Change the position of label when using R package
 eulerr
In-Reply-To: <6de0953e-2ba4-70d9-e24c-a9025362c030@stat.auckland.ac.nz>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
 <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
 <6de0953e-2ba4-70d9-e24c-a9025362c030@stat.auckland.ac.nz>
Message-ID: <CALn2QVj1PZsp-MRJR-W9uEfVxruU7bMJ-_Tt8MWYBpWdA_K=xw@mail.gmail.com>

Yes, it does. Thank you.

Aimin

On Sun, Sep 16, 2018 at 11:00 PM Paul Murrell <paul at stat.auckland.ac.nz>
wrote:

> Hi
>
> The 'x' component of the 't' grob that you get back from grid.get() is a
> unit object, which you can subset and assign to a subset, for example
> this code nudges the fourth label up and to the right 1mm in each
> direction ...
>
>
> x <- t$x
> y <- t$y
>
> x[4] <- t$x[4] + unit(1, "mm")
> y[4] <- t$y[4] + unit(1, "mm")
>
> grid.edit("quantities.grob", x=x, y=y)
>
>
> ... is that the sort of thing you were looking for ?
>
> Paul
>
> On 15/09/18 09:03, Aimin Yan wrote:
> > Thank you,
> >
> > I figure out a way like this:
> >
> > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >                      "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> > "LAD&nonXL_MEF" = 541,
> >                      "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> >
> > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
> list(font
> > = 1),alpha=0.7)
> >
> > grid.ls()
> > t <- grid.get("quantities.grob")
> > names(t)
> >
> > # Change these value will change the location of label.
> >
> > grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
> >                                           unit(-14.883684319653,
> "native"),
> >                                           unit(13.9805892820006,
> "native"),
> >                                           unit(-12.8808987356981,
> "native"),
> >                                           unit(-11.488226371243,
> "native"),
> >                                           unit(-9.51474016085318,
> "native"),
> >                                           unit(-1.00436055190216,
> "native")))
> >
> > grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
> >                                           unit(4.78718651828883,
> "native"),
> >                                           unit(0.25941593099694,
> "native"),
> >                                           unit(-4.32200781461293,
> "native"),
> >                                           unit(25.7349463488991,
> "native"),
> >                                           unit(-22.7610031110325,
> "native"),
> >                                           unit(14.5001560838519,
> "native")))
> >
> > However, here I just want to change the x and y  value of 4th label, does
> > anyone know how to set it?
> >
> > Aimin
> >
> > On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net>
> > wrote:
> >
> >>
> >>> On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com>
> wrote:
> >>>
> >>> I am using eulerr to get venn.
> >>> My code is like:
> >>>
> >>> fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >>>                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> >>> "LAD&nonXL_MEF" = 541,
> >>>                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> >>>
> >>> plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
> >> list(font
> >>> = 1),alpha=0.7)
> >>>
> >>> After I get the figure, I find the position of some  labels need to be
> >>> adjusted.
> >>>
> >>> Does anyone has some idea about how to process this?
> >>
> >> Looking at the code of plot.euler we see that the plotting paradigm is
> >> grid. So you could assign the output to a data.object name, search for
> list
> >> items that match the names of the labels you want to reposition, and
> modify
> >> the position values. You would need to be more specific, if you want a
> >> worked example.
> >>
> >> As far as I can see the lables and postions are fairly deep inside a
> list
> >> structure:
> >>
> >>   $ children     :List of 1
> >>    ..$ GRID.gTree.12:List of 5
> >>    .. ..$ children
> >>           $ diagram.grob.1
> >>              $children
> >> .. .. .. .. ..$ labels.grob    :List of 11
> >>    .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
> >>    .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native
> >> 69.2native 11.9native
> >>    .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >>    .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> >>    .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native
> >> 5.24native 27.86native
> >>    .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >>    .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> >>
> >> --
> >> David.
> >>>
> >>>
> >>> Thank you,
> >>>
> >>> Aimin
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >> 'Any technology distinguishable from magic is insufficiently advanced.'
> >>   -Gehm's Corollary to Clarke's Third Law
> >>
> >>
> >>
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>

	[[alternative HTML version deleted]]


From lei@liu @ending from wu@tl@edu  Mon Sep 17 17:29:48 2018
From: lei@liu @ending from wu@tl@edu (Liu, Lei)
Date: Mon, 17 Sep 2018 15:29:48 +0000
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <894A4868-409A-44DA-A8D8-2C6CE7F252A6@dcn.davis.ca.us>
References: <SN4PR0201MB340568ED119F5665F16A9386F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <894A4868-409A-44DA-A8D8-2C6CE7F252A6@dcn.davis.ca.us>
Message-ID: <SN4PR0201MB340523E42114316FC94E7837F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>

Thanks for the help. My friend helped me and here is the solution:

boot.cluster <- function(x, id){
  boot.id <- sample(unique(id), replace=T)
  out <- lapply(1:length(boot.id), function(newid){cbind(x[id%in%boot.id[newid],],newid)})
  return( do.call("rbind",out) )
}

Lei

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Monday, September 17, 2018 2:32 AM
To: r-help at r-project.org; Liu, Lei <lei.liu at wustl.edu>; r-help at R-project.org
Subject: Re: [R] bootstrap sample for clustered data

You are telling us that the ID values in your data set indicate clusters. However you went about making that determination in the first place might be an obvious(?) way to do it again with your bootstrapped sample, ignoring the cluster assignments you have in place. This is the wrong place to have a discussion about which theoretical method for cluster identification you should use, and if you do know that then searching the web or using the sos package would be the appropriate way to find implementations of a specific clustering algorithm.

I am not an ME expert, but AFAIK "complicated" analyses such as mixed effects models tend to have rather hefty appetites for data completeness, so you may have to design a special sampling plan in order to avoid generating data sets for which those analyses won't break, and you will probably need a very large data set to start with in order to have sufficient data in each cluster. That is, you may be better off keeping the original cluster identification and just restructuring your bootstrap sampling to sample within clusters.

The R-sig-me mailing list is probably a better venue for your questions. 

On September 16, 2018 8:22:44 PM PDT, "Liu, Lei" <lei.liu at wustl.edu> wrote:
>Hi there,
>
>I posted this message before but there may be some confusion in my 
>previous post. So here is a clearer version:
>
>I'd like to do a bootstrap sampling for clustered data. Then I will run 
>some complicated models (say mixed effects models) on the bootstrapped 
>sample. Here id is the cluster. Note different clusters have different 
>number of subjects, e.g., id 2 has 2 observations, id 3 has 3 
>observations.
>
>id=c(1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5) y=c(.5, .6, .4, .3, .4, 1, .9, 
>1, .5, 2, 2.2, 3) x=c(0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1 )
>
>xx=data.frame(id, x, y)
>
>boot.cluster <- function(x, id){
>
>  boot.id <- sample(unique(id), replace=T)  out <- lapply(boot.id, 
> function(i) x[id%in%i,])
>
>  return( do.call("rbind",out) )
>
>}
>
>boot.xx=boot.cluster(xx, xx$id)
>
>Here is the generated boot.xx dataset:
>
>   id x y
>   3 0 0.4
>   3 0 1.0
>   3 0 0.9
>   1 0 0.5
>   1 0 0.6
>   5 1 2.2
>   5 1 3.0
>   2 1 0.4
>   2 1 0.3
>   1 0 0.5
>   1 0 0.6
>
>You can see that some clusters (ids) appears multiple times (e.g., id 1 
>appears in two places - 4 rows), since bootstrap does a sample with 
>replacement, we could have the same cluster multiple times. Thus, we 
>cannot do a mixed effects model using this data, as we should assume 
>all the clusters are different in this new data. Instead, I will 
>reorganize the data as below (id is reordered from the above boot.xx 
>data). This is the step I need help:
>
>  id x  y
>   1 0 0.4
>   1 0 1.0
>   1 0 0.9
>   2 0 0.5
>   2 0 0.6
>   3 1 2.2
>   3 1 3.0
>   4 1 0.4
>   4 1 0.3
>   5 0 0.5
>   5 0 0.6
>
>Can someone help me with it? Thanks!
>
>Lei Liu
>Professor of Biostatistics
>Washington University in St. Louis
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

From rj@innet @ending from gm@il@com  Mon Sep 17 18:14:47 2018
From: rj@innet @ending from gm@il@com (RUPJYOTI DAS)
Date: Mon, 17 Sep 2018 21:44:47 +0530
Subject: [R] Unable to update R 3.4 to R 3.5 in Ubuntu 18.04 LTS
Message-ID: <CAMo+egkiwPriFXCbSvMH3234BEitjBMxuwmYBC4gEjPdzUqA8g@mail.gmail.com>

Dear All,
I am using R to carry out RNA-Seq workflow in my standalone machine which
needs the latest R version >=3.5. I was trying to update firstly removing
the R 3.4 and reinstalling from scratch again the latest version. Can
anybody just guide me how to carry out the process as I am getting only R
3.4 again and again.
Also when I remove the
*deb ... bionic-cran35 (mirror for R cran )*

from the* source.list* file (opened by* sudo gedit /etc/apt/sources.list*)
the command *sudo apt-get update* works fine which does not upgrade the R
3.4 to R 3.5.1.
Adding the line
*deb ... bionic-cran35/ *
gives the attached error log*. **Please find the attached file and  do
check.*

Any answers and suggestions will be of immense help!

Thanking you!

*Rupjyoti Das*
*M.Tech*, Information Technology
Tezpur University
Assam, India 784028
Mob. +91-8812807195

From jfox @ending from mcm@@ter@c@  Mon Sep 17 19:16:19 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Mon, 17 Sep 2018 17:16:19 +0000
Subject: [R] Problem with lm.resid() when weights are provided
In-Reply-To: <CAAC89xdt93_tGBsLrHQqMjjAA9uEJ2eRH4ptiVz0gWJ2CJa8VA@mail.gmail.com>
References: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
 <22333_1536669565_w8BCdOUV005487_CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368B0E61@FHSDB2D11-2.csu.mcmaster.ca>
 <CAAC89xexc0tHnC8n_n0Z+=3xtPDFmB394=U75V3KLe9RQ6OWdA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368B12FB@FHSDB2D11-2.csu.mcmaster.ca>
 <CAAC89xdt93_tGBsLrHQqMjjAA9uEJ2eRH4ptiVz0gWJ2CJa8VA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368CC82D@FHSDB2D11-2.csu.mcmaster.ca>

Dear Hamed,

> -----Original Message-----
> From: Hamed Ha [mailto:hamedhaseli at gmail.com]
> Sent: Monday, September 17, 2018 3:56 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help at r-project.org
> Subject: Re: [R] Problem with lm.resid() when weights are provided
> 
> H i John,
> 
> 
> Thank you for your reply.
> 
> 
> I see your point, thanks. I checked lm.wfit() and realised that there is a tol
> parameter that is already set to 10^-7. This is not even the half decimal to the
> machine precision. Furthermore, plying with tol parameter does not solve the
> problem, as far as I checked.

tol plays a different role in lm.wfit(). It's for the QR decomposition (done in C code), I suppose to determine the rank of the weighted model matrix. Generally in this kind of context, you'd use something like the square root of the machine double epsilon to define a number that's effectively 0, and the tolerance used here isn't too far off that -- about an order of magnitude larger.
 
I'm not an expert in computer arithmetic or numerical linear algebra, so I don't have anything more to say about this.

> 
> 
> I still see this issue as critical and we should report it to the R core team to be
> investigated more. What do you think?

I don't think that it's a critical issue because it isn't sensible to specify nonzero weights so close to 0. A simple solution is to change these weights to 0 in your code calling lm().

That said, I suppose that it might be better to make lm.wfit() more robust to near-zero weights. If you feel strongly about this, you can file a bug report, but I'm not interested in pursuing it.

Best,
 John

> 
> 
> Regards,
> Hamed.
> 
> 
> On Fri, 14 Sep 2018 at 22:46, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Hamed,
> 
> 	When you post a question to r-help, generally you should cc
> subsequent messages there as well, as I've done to this response.
> 
> 	The algorithm that lm() uses is much more numerically stable than
> inverting the weighted sum-of-squares-and-product matrix. If you want to see
> how the computations are done, look at lm.wfit(), in which the residuals and
> fits are computed as
> 
> 	    z$residuals <- z$residuals/wts
> 	    z$fitted.values <- y - z$residuals
> 
> 	Zero weights are handled specially, and your tiny weights are thus the
> source of the problem. When you divide by a number less than the machine
> double-epsilon, you can't expect numerically stable results. I suppose that
> lm.wfit() could check for 0 weights to a tolerance rather than exactly.
> 
> 	John
> 
> 	> -----Original Message-----
> 	> From: Hamed Ha [mailto:hamedhaseli at gmail.com
> <mailto:hamedhaseli at gmail.com> ]
> 	> Sent: Friday, September 14, 2018 5:34 PM
> 	> To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> >
> 	> Subject: Re: [R] Problem with lm.resid() when weights are provided
> 	>
> 	> Hi John,
> 	>
> 	> Thank you for your reply.
> 	>
> 	> I agree that the small weights are the potential source of the
> instability in the
> 	> result. I also suspected that there are some failure/bugs in the actual
> 	> algorithm that R uses for fitting the model. I remember that at some
> points I
> 	> checked the theoretical estimation of the parameters, solve(t(x)
> %*% w %*%
> 	> x) %*% t(x) %*% w %*% y, (besides the point that I had to set tol
> parameter in
> 	> solve() to a super small value) and realised  that lm() and the
> theoretical
> 	> results match together. That is the parameter estimation is right in
> R.
> 	> Moreover, I checked the predictions, predict(lm.fit), and it was right.
> Then the
> 	> only source of error remained was resid() function. I further checked
> this
> 	> function and it is nothing more than calling a sub-element from and
> lm() fit.
> 	> Putting all together, I think that there is something wrong/bug/miss-
> 	> configuration in the lm() algorithm and I highly recommend the R
> core team to
> 	> fix that.
> 	>
> 	> Please feel free to contact me for more details if required.
> 	>
> 	> Warm regards,
> 	> Hamed.
> 	>
> 	>
> 	>
> 	>
> 	>
> 	>
> 	>
> 	>
> 	>
> 	> On Fri, 14 Sep 2018 at 13:35, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca>
> 	> <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > > wrote:
> 	>
> 	>
> 	>       Dear Hamed,
> 	>
> 	>       I don't think that anyone has picked up on this problem.
> 	>
> 	>       What's peculiar about your weights is that several are 0 within
> 	> rounding error but not exactly 0:
> 	>
> 	>       > head(df)
> 	>                  y          x       weight
> 	>       1  1.5115614  0.5520924 2.117337e-34
> 	>       2 -0.6365313 -0.1259932 2.117337e-34
> 	>       3  0.3778278  0.4209538 4.934135e-31
> 	>       4  3.0379232  1.4031545 2.679495e-24
> 	>       5  1.5364652  0.4607686 2.679495e-24
> 	>       6 -2.3772787 -0.7396358 6.244160e-21
> 	>
> 	>       I can reproduce the results that you report:
> 	>
> 	>       > (mod.1 <- lm(y ~ x, data=df))
> 	>
> 	>       Call:
> 	>       lm(formula = y ~ x, data = df)
> 	>
> 	>       Coefficients:
> 	>       (Intercept)            x
> 	>          -0.04173      2.03790
> 	>
> 	>       > max(resid(mod.1))
> 	>       [1] 1.14046
> 	>       > (mod.2 <- lm(y ~ x, data=df, weights=weight))
> 	>
> 	>       Call:
> 	>       lm(formula = y ~ x, data = df, weights = weight)
> 	>
> 	>       Coefficients:
> 	>       (Intercept)            x
> 	>          -0.05786      1.96087
> 	>
> 	>       > max(resid(mod.2))
> 	>       [1] 36.84939
> 	>
> 	>       But the problem disappears when the tiny nonzero weight are set
> to 0:
> 	>
> 	>       > df2 <- df
> 	>       > df2$weight <- zapsmall(df2$weight)
> 	>       > head(df2)
> 	>                  y          x weight
> 	>       1  1.5115614  0.5520924      0
> 	>       2 -0.6365313 -0.1259932      0
> 	>       3  0.3778278  0.4209538      0
> 	>       4  3.0379232  1.4031545      0
> 	>       5  1.5364652  0.4607686      0
> 	>       6 -2.3772787 -0.7396358      0
> 	>       > (mod.3 <- update(mod.2, data=df2))
> 	>
> 	>       Call:
> 	>       lm(formula = y ~ x, data = df2, weights = weight)
> 	>
> 	>       Coefficients:
> 	>       (Intercept)            x
> 	>          -0.05786      1.96087
> 	>
> 	>       > max(resid(mod.3))
> 	>       [1] 1.146663
> 	>
> 	>       I don't know exactly why this happens, but suspect numerical
> 	> instability produced by the near-zero weights, which are smaller
> than the
> 	> machine double-epsilon
> 	>
> 	>       > .Machine$double.neg.eps
> 	>       [1] 1.110223e-16
> 	>
> 	>       The problem also disappears, e.g., if the tiny weight are set to 1e-
> 15
> 	> rather than 0.
> 	>
> 	>       I hope this helps,
> 	>        John
> 	>
> 	>       -----------------------------------------------------------------
> 	>       John Fox
> 	>       Professor Emeritus
> 	>       McMaster University
> 	>       Hamilton, Ontario, Canada
> 	>       Web: https://socialsciences.mcmaster.ca/jfox/
> 	>
> 	>
> 	>
> 	>       > -----Original Message-----
> 	>       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-
> help-bounces at r-project.org>  <mailto:r-help- <mailto:r-help->
> 	> bounces at r-project.org <mailto:bounces at r-project.org> > ] On
> Behalf Of Hamed Ha
> 	>       > Sent: Tuesday, September 11, 2018 8:39 AM
> 	>       > To: r-help at r-project.org <mailto:r-help at r-project.org>
> <mailto:r-help at r-project.org <mailto:r-help at r-project.org> >
> 	>       > Subject: [R] Problem with lm.resid() when weights are provided
> 	>       >
> 	>       > Dear R Help Team.
> 	>       >
> 	>       > I get some weird results when I use the lm function with weight.
> The
> 	> issue can
> 	>       > be reproduced by the example below:
> 	>       >
> 	>       >
> 	>       > The input data is (weights are intentionally designed to reflect
> some
> 	>       > structures in the data)
> 	>       >
> 	>       >
> 	>       > > df
> 	>       > y x weight
> 	>       >  1.51156139  0.55209240 2.117337e-34
> 	>       > -0.63653132 -0.12599316 2.117337e-34
> 	>       >  0.37782776  0.42095384 4.934135e-31
> 	>       >  3.03792318  1.40315446 2.679495e-24
> 	>       >  1.53646523  0.46076858 2.679495e-24
> 	>       > -2.37727874 -0.73963576 6.244160e-21
> 	>       >  0.37183065  0.20407468 1.455107e-17
> 	>       > -1.53917553 -0.95519361 1.455107e-17
> 	>       >  1.10926675  0.03897129 3.390908e-14
> 	>       > -0.37786333 -0.17523593 3.390908e-14
> 	>       >  2.43973603  0.97970095 7.902000e-11
> 	>       > -0.35432394 -0.03742559 7.902000e-11
> 	>       >  2.19296613  1.00355263 4.289362e-04
> 	>       >  0.49845532  0.34816207 4.289362e-04
> 	>       >  1.25005260  0.76306225 5.000000e-01
> 	>       >  0.84360691  0.45152356 5.000000e-01
> 	>       >  0.29565993  0.53880068 5.000000e-01
> 	>       > -0.54081334 -0.28104525 5.000000e-01
> 	>       >  0.83612836 -0.12885659 9.995711e-01
> 	>       > -1.42526769 -0.87107631 9.999998e-01
> 	>       >  0.10204789 -0.11649899 1.000000e+00
> 	>       >  1.14292898  0.37249631 1.000000e+00
> 	>       > -3.02942081 -1.28966997 1.000000e+00
> 	>       > -1.37549764 -0.74676145 1.000000e+00
> 	>       > -2.00118016 -0.55182759 1.000000e+00
> 	>       > -4.24441674 -1.94603608 1.000000e+00
> 	>       >  1.17168144  1.00868008 1.000000e+00
> 	>       >  2.64007761  1.26333069 1.000000e+00
> 	>       >  1.98550114  1.18509599 1.000000e+00
> 	>       > -0.58941683 -0.61972416 9.999998e-01
> 	>       > -4.57559611 -2.30914920 9.995711e-01
> 	>       > -0.82610544 -0.39347576 9.995711e-01
> 	>       > -0.02768220  0.20076910 9.995711e-01
> 	>       >  0.78186399  0.25690215 9.995711e-01
> 	>       > -0.88314153 -0.20200148 5.000000e-01
> 	>       > -4.17076452 -2.03547588 5.000000e-01
> 	>       >  0.93373070  0.54190626 4.289362e-04
> 	>       > -0.08517734  0.17692491 4.289362e-04
> 	>       > -4.47546619 -2.14876688 4.289362e-04
> 	>       > -1.65509103 -0.76898087 4.289362e-04
> 	>       > -0.39403030 -0.12689705 4.289362e-04
> 	>       >  0.01203300 -0.18689898 1.841442e-07
> 	>       > -4.82762639 -2.31391121 1.841442e-07
> 	>       > -0.72658380 -0.39751171 3.397282e-14
> 	>       > -2.35886866 -1.01082109 0.000000e+00
> 	>       > -2.03762707 -0.96439902 0.000000e+00
> 	>       >  0.90115123  0.60172286 0.000000e+00
> 	>       >  1.55999194  0.83433953 0.000000e+00
> 	>       >  3.07994058  1.30942776 0.000000e+00
> 	>       >  1.78871462  1.10605530 0.000000e+00
> 	>       >
> 	>       >
> 	>       >
> 	>       > Running simple linear model returns:
> 	>       >
> 	>       > > lm(y~x,data=df)
> 	>       >
> 	>       > Call:
> 	>       > lm(formula = y ~ x, data = df)
> 	>       >
> 	>       > Coefficients:
> 	>       > (Intercept)            x
> 	>       >    -0.04173      2.03790
> 	>       >
> 	>       > and
> 	>       > > max(resid(lm(y~x,data=df)))
> 	>       > [1] 1.14046
> 	>       >
> 	>       >
> 	>       > *HOWEVER if I use the weighted model then:*
> 	>       >
> 	>       > lm(formula = y ~ x, data = df, weights = df$weights)
> 	>       >
> 	>       > Coefficients:
> 	>       > (Intercept)            x
> 	>       >    -0.05786      1.96087
> 	>       >
> 	>       > and
> 	>       > > max(resid(lm(y~x,data=df,weights=df$weights)))
> 	>       > [1] 60.91888
> 	>       >
> 	>       >
> 	>       > as you see, the estimation of the coefficients are nearly the
> same
> 	> but the
> 	>       > resid() function returns a giant residual (I have some cases
> where
> 	> the value is
> 	>       > much much higher). Further, if I calculate the residuals by
> simply
> 	>       > predict(lm(y~x,data=df,weights=df$weights))-df$y then I get the
> true
> 	> value for
> 	>       > the residuals.
> 	>       >
> 	>       >
> 	>       > Thanks.
> 	>       >
> 	>       > Please do not hesitate to contact me for more details.
> 	>       > Regards,
> 	>       > Hamed.
> 	>       >
> 	>       >       [[alternative HTML version deleted]]
> 	>       >
> 	>       > ______________________________________________
> 	>       > R-help at r-project.org <mailto:R-help at r-project.org>
> <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing list --
> 	> To UNSUBSCRIBE and more, see
> 	>       > https://stat.ethz.ch/mailman/listinfo/r-help
> 	>       > PLEASE do read the posting guide http://www.R-
> project.org/posting-
> 	>       > guide.html
> 	>       > and provide commented, minimal, self-contained, reproducible
> 	> code.
> 	>
> 
> 


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Sep 17 20:54:28 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Mon, 17 Sep 2018 11:54:28 -0700 (PDT)
Subject: [R] Applying by() when groups have different lengths
Message-ID: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>

   My dataframe has 113K rows split by a factor into 58 separate data.frames,
with a different numbers of rows (see error output below).

   I cannot think of a way of proving a sample of data; if a sample for a MWE
is desired advice on produing one using dput() is needed.

   To summarize each group within this dataframe I'm using by() and getting
an error because of the different number of rows:

> by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
+ mean.rain <- mean(rainfall_by_site[, 'prcp'])
+ })
Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  :
   arguments imply differing number of rows: 4900, 1085, 1894, 2844, 3520,
  647, 239, 3652, 3701, 3063, 176, 4713, 4887, 119, 165, 1221, 3358, 1457,
  4896, 166, 690, 1110, 212, 1727, 227, 236, 1175, 1485, 186, 769, 139, 203,
  2727, 4357, 1035, 1329, 1454, 973, 4536, 208, 350, 125, 3437, 731, 4894,
  2598, 2419, 752, 427, 136, 685, 4849, 914, 171

   My web searches have not found anything relevant; perhaps my search terms
(such as 'R: apply by() with different factor row numbers') can be improved.

   The help pages found using apropos('by') appear the same: ?by,
?by.data.frame, ?by.default and provide no hint on how to work with unequal
rows per factor.

   How can I apply by() on these data.frames?

Rich


From wdunl@p @ending from tibco@com  Mon Sep 17 21:25:50 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Mon, 17 Sep 2018 12:25:50 -0700
Subject: [R] Applying by() when groups have different lengths
In-Reply-To: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcahiUWXnwMO7LV+jOmmYGahO5m_GUtp8imdWuaG5Mqzng@mail.gmail.com>

>
> by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
>
+ mean.rain <- mean(rainfall_by_site[, 'prcp'])
+ })

Note that you define a function of x which does not use x in it.
Hence, even if the function gave a value, it would give the same
value for each group.  To see what the 'x' in that function will
be, use the identity function:

> d <- data.frame(X=2^(0:5), Y=2^(6:11), Group=c("A","B","C","A","B","A"))
> by(d[,1:2], d$Group, function(x)x)
d$Group: A
   X    Y
1  1   64
4  8  512
6 32 2048
------------------------------------------------------------
d$Group: B
   X    Y
2  2  128
5 16 1024
------------------------------------------------------------
d$Group: C
  X   Y
3 4 256

I suspect you want to use the aggregate function.

> aggregate(d[,1:2], list(Group=d$Group), sum)
  Group  X    Y
1     A 41 2624
2     B 18 1152
3     C  4  256

or the functions in the dplyr package:

> d %>% group_by(Group) %>% summarize(sumX=sum(X), meanY=mean(Y))
# A tibble: 3 x 3
  Group  sumX meanY
  <fct> <dbl> <dbl>
1 A        41  875.
2 B        18  576
3 C         4  256






Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Sep 17, 2018 at 11:54 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>   My dataframe has 113K rows split by a factor into 58 separate
> data.frames,
> with a different numbers of rows (see error output below).
>
>   I cannot think of a way of proving a sample of data; if a sample for a
> MWE
> is desired advice on produing one using dput() is needed.
>
>   To summarize each group within this dataframe I'm using by() and getting
> an error because of the different number of rows:
>
> by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
>>
> + mean.rain <- mean(rainfall_by_site[, 'prcp'])
> + })
> Error in (function (..., row.names = NULL, check.rows = FALSE, check.names
> = TRUE,  :
>   arguments imply differing number of rows: 4900, 1085, 1894, 2844, 3520,
>  647, 239, 3652, 3701, 3063, 176, 4713, 4887, 119, 165, 1221, 3358, 1457,
>  4896, 166, 690, 1110, 212, 1727, 227, 236, 1175, 1485, 186, 769, 139, 203,
>  2727, 4357, 1035, 1329, 1454, 973, 4536, 208, 350, 125, 3437, 731, 4894,
>  2598, 2419, 752, 427, 136, 685, 4849, 914, 171
>
>   My web searches have not found anything relevant; perhaps my search terms
> (such as 'R: apply by() with different factor row numbers') can be
> improved.
>
>   The help pages found using apropos('by') appear the same: ?by,
> ?by.data.frame, ?by.default and provide no hint on how to work with unequal
> rows per factor.
>
>   How can I apply by() on these data.frames?
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Mon Sep 17 21:26:38 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 17 Sep 2018 19:26:38 +0000
Subject: [R] Applying by() when groups have different lengths
In-Reply-To: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
Message-ID: <604AEC5B-08C4-4467-8A7B-EB74A6DA300E@llnl.gov>

Try changing it to 

     by(rainfall_by_site, rainfall_by_site[, 'name'],
    function(x) {mean.rain <- mean(x[, 'prcp'])
     })

Inside the function, so to speak, the function sees an object named "x", because that's how the function is defined:  function(x).
So you have to operate on x inside the function.  

For sure, the fact that the subgroups have different numbers of rows is not the problem.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/17/18, 11:54 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       My dataframe has 113K rows split by a factor into 58 separate data.frames,
    with a different numbers of rows (see error output below).
    
       I cannot think of a way of proving a sample of data; if a sample for a MWE
    is desired advice on produing one using dput() is needed.
    
       To summarize each group within this dataframe I'm using by() and getting
    an error because of the different number of rows:
    
    > by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
    + mean.rain <- mean(rainfall_by_site[, 'prcp'])
    + })
    Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  :
       arguments imply differing number of rows: 4900, 1085, 1894, 2844, 3520,
      647, 239, 3652, 3701, 3063, 176, 4713, 4887, 119, 165, 1221, 3358, 1457,
      4896, 166, 690, 1110, 212, 1727, 227, 236, 1175, 1485, 186, 769, 139, 203,
      2727, 4357, 1035, 1329, 1454, 973, 4536, 208, 350, 125, 3437, 731, 4894,
      2598, 2419, 752, 427, 136, 685, 4849, 914, 171
    
       My web searches have not found anything relevant; perhaps my search terms
    (such as 'R: apply by() with different factor row numbers') can be improved.
    
       The help pages found using apropos('by') appear the same: ?by,
    ?by.data.frame, ?by.default and provide no hint on how to work with unequal
    rows per factor.
    
       How can I apply by() on these data.frames?
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From m@cqueen1 @ending from llnl@gov  Mon Sep 17 21:35:36 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 17 Sep 2018 19:35:36 +0000
Subject: [R] Applying by() when groups have different lengths
In-Reply-To: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
Message-ID: <C045A3F5-26F3-4F18-8BC1-BF2E163FDB49@llnl.gov>

I'm also going to guess that maybe your object
   rainfall_by_site
has already been split into separate data frames (because of its name).

But by() does the splitting internally, so you should be passing it the original unsplit data frame.

You could supply example data by providing the first few rows of each of the first few groups. That would be enough to test with.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/17/18, 11:54 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       My dataframe has 113K rows split by a factor into 58 separate data.frames,
    with a different numbers of rows (see error output below).
    
       I cannot think of a way of proving a sample of data; if a sample for a MWE
    is desired advice on produing one using dput() is needed.
    
       To summarize each group within this dataframe I'm using by() and getting
    an error because of the different number of rows:
    
    > by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
    + mean.rain <- mean(rainfall_by_site[, 'prcp'])
    + })
    Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  :
       arguments imply differing number of rows: 4900, 1085, 1894, 2844, 3520,
      647, 239, 3652, 3701, 3063, 176, 4713, 4887, 119, 165, 1221, 3358, 1457,
      4896, 166, 690, 1110, 212, 1727, 227, 236, 1175, 1485, 186, 769, 139, 203,
      2727, 4357, 1035, 1329, 1454, 973, 4536, 208, 350, 125, 3437, 731, 4894,
      2598, 2419, 752, 427, 136, 685, 4849, 914, 171
    
       My web searches have not found anything relevant; perhaps my search terms
    (such as 'R: apply by() with different factor row numbers') can be improved.
    
       The help pages found using apropos('by') appear the same: ?by,
    ?by.data.frame, ?by.default and provide no hint on how to work with unequal
    rows per factor.
    
       How can I apply by() on these data.frames?
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @ending from gm@il@com  Mon Sep 17 21:38:01 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 17 Sep 2018 12:38:01 -0700
Subject: [R] Applying by() when groups have different lengths
In-Reply-To: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbR4q6hG=b_w2Lo6W1=6o-364-mBdMRhnMniMwfSAkt_Gw@mail.gmail.com>

Inline.

Bert



On Mon, Sep 17, 2018 at 11:54 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>    My dataframe has 113K rows split by a factor into 58 separate
> data.frames,
> with a different numbers of rows (see error output below).
>
>    I cannot think of a way of proving a sample of data; if a sample for a
> MWE
> is desired advice on produing one using dput() is needed.
>

This is gibberish. What does "proving a sample of data" mean? etc. Please
proofread and edit.

>
>    To summarize each group within this dataframe I'm using by() and getting
> an error because of the different number of rows:
>

> > by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
> + mean.rain <- mean(rainfall_by_site[, 'prcp'])
> + })
>

You are misspecifying your function. It has argument x, but you do not use
x in your function. Also the assignment at the end is unnecessary and
probably wrong for your use case. Please go through a tutorial on how to
write functions in R.

You are probably also misusing by(), but as you did not provided sufficient
information -- head(your_data_frame) or similar would have told us its
structure, rather than having us guess -- nor a reproducible example, it's
hard (for me) to figure out your intent. **PLEASE** follow the posting
guide and provide such information. You have been requested to do this
several times already.

Here is the sort of thing I think you wanted to do:

> set.seed(54321) ## for reproducibility
> df <- data.frame(f = sample(LETTERS[1:3], 12, rep = TRUE), y = runif(12))
> df
   f          y
1  B 0.04529991
2  B 0.65272100
3  A 0.99406601
4  A 0.67763735
5  A 0.91854517
6  C 0.46244494
7  A 0.57141480
8  A 0.45193882
9  B 0.16770701
10 B 0.06826135
11 A 0.89691069
12 C 0.27383703

> by(df, df$f, function(x)mean(x$y))
df$f: A
[1] 0.7517521
------------------------------------------------------
df$f: B
[1] 0.2334973
------------------------------------------------------
df$f: C
[1] 0.368141

Note that you do not first break up the df into separate df's, which sounds
like what you tried to do.

However, note that if all you want to do is summarize a *single* numeric
column by a factor, you do not need to use by() at all, which is designed
to work on (several columns of) the whole data frame simultaneously. For a
single column, tapply() is all you need (or as Duncan noted, functionality
in the dplyr package.

> with(df,tapply(y,f,mean))
        A         B         C
0.7517521 0.2334973 0.3681410

Finally, if I have misunderstood your intent, my apologies. I tried.

-- Bert



mean.rain <- by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
+ mean.rain <- mean(rainfall_by_site[, 'prcp'])
+ })

> Error in (function (..., row.names = NULL, check.rows = FALSE, check.names
> = TRUE,  :
>    arguments imply differing number of rows: 4900, 1085, 1894, 2844, 3520,
>   647, 239, 3652, 3701, 3063, 176, 4713, 4887, 119, 165, 1221, 3358, 1457,
>   4896, 166, 690, 1110, 212, 1727, 227, 236, 1175, 1485, 186, 769, 139,
> 203,
>   2727, 4357, 1035, 1329, 1454, 973, 4536, 208, 350, 125, 3437, 731, 4894,
>   2598, 2419, 752, 427, 136, 685, 4849, 914, 171
>
>    My web searches have not found anything relevant; perhaps my search
> terms
> (such as 'R: apply by() with different factor row numbers') can be
> improved.
>
>    The help pages found using apropos('by') appear the same: ?by,
> ?by.data.frame, ?by.default and provide no hint on how to work with unequal
> rows per factor.
>
>    How can I apply by() on these data.frames?
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Sep 17 21:56:04 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Mon, 17 Sep 2018 12:56:04 -0700 (PDT)
Subject: [R] Applying by() when groups have different lengths [RESOLVED]
In-Reply-To: <C045A3F5-26F3-4F18-8BC1-BF2E163FDB49@llnl.gov>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
 <C045A3F5-26F3-4F18-8BC1-BF2E163FDB49@llnl.gov>
Message-ID: <alpine.LNX.2.20.1809171252290.19471@salmo.appl-ecosys.com>

On Mon, 17 Sep 2018, MacQueen, Don wrote:

> I'm also going to guess that maybe your object rainfall_by_site has
> already been split into separate data frames (because of its name). But
> by() does the splitting internally, so you should be passing it the
> original unsplit data frame.

Don,

   I did not pick up on by() doing the splitting for me when I read the help
file and a few web sites!

   Using the unsplit data.frame did the job; e.g.,

rainfall[, "name"]: Sandy 1.4 NE
[1] 0.1636066
------------------------------------------------------------ 
rainfall[, "name"]: Sandy 1.7 SSW
[1] 0.2021324
------------------------------------------------------------ 
rainfall[, "name"]: Sherwood 3.3 SE
[1] 0.1461752

   Now I know how to properly apply by() to an unsplit dataframe. Thanks for
the insightful lesson.

Best regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Sep 17 22:10:16 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Mon, 17 Sep 2018 13:10:16 -0700 (PDT)
Subject: [R] Applying by() when groups have different lengths
In-Reply-To: <CAGxFJbR4q6hG=b_w2Lo6W1=6o-364-mBdMRhnMniMwfSAkt_Gw@mail.gmail.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
 <CAGxFJbR4q6hG=b_w2Lo6W1=6o-364-mBdMRhnMniMwfSAkt_Gw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809171309291.19471@salmo.appl-ecosys.com>

On Mon, 17 Sep 2018, Bert Gunter wrote:

>>    I cannot think of a way of proving a sample of data; if a sample for a

   Typo: s/proving/providing/

Rich


From henrik@bengt@@on @ending from gm@il@com  Mon Sep 17 22:13:59 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Mon, 17 Sep 2018 13:13:59 -0700
Subject: [R] makeCluster() hangs infinitely
In-Reply-To: <CADBpgp3DNPHPaHmPkmS+PhF6XAo0cHPgHtGx=eC42o5TUyJQTw@mail.gmail.com>
References: <CADBpgp0PsJ7M5MATA8jkMQA1DnJ-HmQRXzGLcq=TyKe8UWG7Ag@mail.gmail.com>
 <CAFDcVCSvR_=-EEqkkq-yfNpFZ8TGLxa3M4teko935ZMCKMzsAw@mail.gmail.com>
 <CADBpgp3DNPHPaHmPkmS+PhF6XAo0cHPgHtGx=eC42o5TUyJQTw@mail.gmail.com>
Message-ID: <CAFDcVCT083NAze_fjmj94qva2iGxJS0amAMV-m3R=mS7W9+RTQ@mail.gmail.com>

On Mon, Sep 17, 2018 at 12:56 PM Zhihao Huang <zhhhwang at umich.edu> wrote:
>
> Hi Henrik,
>
> Thanks for the suggestions! I tried your approach, and obtained the following output, which is pretty similar to the previous ones.
>
> > cl <- future::makeClusterPSOCK(1, outfile = NULL, verbose = TRUE)
> Workers: [n = 1] ?localhost?
> Base port: 11214
> Creating node 1 of 1 ...
> - setting up node
> Starting worker #1 on ?localhost?: '/Library/Frameworks/R.framework/Resources/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT= TIMEOUT=2592000 XDR=TRUE
> Waiting for worker #1 on ?localhost? to connect back
> starting worker pid=13731 on localhost:11214 at 15:48:41.991
>
> I guess this is a connection problem. I am not sure what these numbers mean. Do you have any further idea on this? I very much appreciate it!

Yes, it looks similar with the important difference of displaying:

"starting worker pid=13731 on localhost:11214 at 15:48:41.991"

That tells us that the background worker (separate R session running
parallel:::.slaveRSOCK()) was successfully launched, which is good.

BTW, you should see something similar with:

    cl <- parallel::makeCluster(1, outfile = NULL)

which helps others help you (in case they say "oh, it might be a
problem with the future package - as the maintainer").

Yes, it looks like a "connection problem" - this could be a firewall
issue or similar.  I'm not on macOS, so I cannot help you there, but
maybe others can pitch in.

/Henrik

>
> Thanks,
> Zhihao
> --
> Zhihao (Daniel) Huang
> Graduate Student
> Department of Statistics,
> University of Michigan, Ann Arbor
> Email: zhhhwang at umich.edu
>
>
>
> On Mon, Sep 17, 2018 at 12:38 AM Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>
>> Hi,
>>
>> did you see my answer on StackOverflow? Specifically, if you set
>> argument 'outfile = NULL' to either of those two functions, you'll get
>> a little bit more information that *might* provide some clues.
>>
>> /Henrik
>>
>>
>> On Sun, Sep 16, 2018 at 5:38 PM Zhihao Huang <zhhhwang at umich.edu> wrote:
>> >
>> > Hi all,
>> >
>> > The function makeCluster() of parallel does not work on my laptop. It hangs
>> > infinitely.
>> >
>> > *1. Problem Summary:*
>> >
>> > > # Loading parallel packages
>> >
>> > > library(parallel)
>> >
>> > > cl <- makeCluster(2) # It hangs at this line of code.
>> > It hangs at the second line of the code.
>> >
>> > *2. Potential Reason*
>> > I also tried to see the details of what it does internally by using the
>> > following code.
>> >
>> > > library(future)
>> >
>> > > cl <- future::makeClusterPSOCK(1L, verbose = TRUE) # It hangs at this
>> > line of code.
>> > And it returns the following descriptions and hangs.
>> >
>> > *Workers: [n = 1] ?localhost?*
>> >
>> > *Base port: 11214*
>> >
>> > *Creating node 1 of 1 ...*
>> >
>> > *- setting up node*
>> >
>> > *Starting worker #1 on ?localhost?:
>> > '/Library/Frameworks/R.framework/Resources/bin/Rscript'
>> > --default-packages=datasets,utils,grDevices,graphics,stats,methods -e
>> > 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT=/dev/null
>> > TIMEOUT=2592000 XDR=TRUE*
>> >
>> > *Waiting for worker #1 on ?localhost? to connect back*
>> > So the problem is that the "worker #1 on 'local host'" never connects back,
>> > and that's why it hangs forever. I have no idea what causes this.
>> >
>> > *3. my sessionInfo():*
>> >
>> > R version 3.5.1 (2018-07-02)
>> >
>> > Platform: x86_64-apple-darwin15.6.0 (64-bit)
>> >
>> > Running under: macOS High Sierra 10.13.6
>> >
>> >
>> > Matrix products: default
>> >
>> > BLAS:
>> > /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
>> >
>> > LAPACK:
>> > /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
>> >
>> >
>> > locale:
>> >
>> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> >
>> >
>> > attached base packages:
>> >
>> > [1] stats     graphics  grDevices utils     datasets  methods   base
>> >
>> >
>> > loaded via a namespace (and not attached):
>> >
>> > [1] compiler_3.5.1
>> >
>> > I spent hours searching for the solutions but failed. It looks like some
>> > other people met similar problem here
>> > <http://r.789695.n4.nabble.com/makeCluster-hangs-td4748238.html>. Also, I
>> > posted this question online here
>> > <https://stackoverflow.com/questions/52264460/r-parallel-makecluster-hangs-infinitely-on-mac/52284709#52284709>
>> > a
>> > week ago.
>> >
>> > Any suggestion would be appreciated. Thanks a lot!
>> >
>> > Thanks,
>> > Zhihao
>> > --
>> > Zhihao (Daniel) Huang
>> > Graduate Student
>> > Department of Statistics,
>> > University of Michigan, Ann Arbor
>> > Email: zhhhwang at umich.edu
>> >
>> > --
>> > ? ??
>> > Zhihao Huang
>> >
>> > Graduate Student
>> > Department of Statistics,
>> > University of Michigan, Ann Arbor
>> > Email: zhhhwang at umich.edu
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Mon Sep 17 22:32:41 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 17 Sep 2018 13:32:41 -0700
Subject: [R] Applying by() when groups have different lengths [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.1809171252290.19471@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
 <C045A3F5-26F3-4F18-8BC1-BF2E163FDB49@llnl.gov>
 <alpine.LNX.2.20.1809171252290.19471@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSKjy_wBSFwJ3pC_MV71Xw6066C3xw_1m43CG4eg9nCSQ@mail.gmail.com>

"  I did not pick up on by() doing the splitting for me when I read the
help..."

>From ?by:
"A data frame is split by row into data frames subsetted by the values of
one or more factors, and function FUN is applied to each subset in turn."

I do not understand how it could be more clearly stated than that. Care to
elaborate?
Did you run the examples? You should **always** do so.

-- Bert


On Mon, Sep 17, 2018 at 12:56 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Mon, 17 Sep 2018, MacQueen, Don wrote:
>
> > I'm also going to guess that maybe your object rainfall_by_site has
> > already been split into separate data frames (because of its name). But
> > by() does the splitting internally, so you should be passing it the
> > original unsplit data frame.
>
> Don,
>
>    I did not pick up on by() doing the splitting for me when I read the
> help
> file and a few web sites!
>
>    Using the unsplit data.frame did the job; e.g.,
>
> rainfall[, "name"]: Sandy 1.4 NE
> [1] 0.1636066
> ------------------------------------------------------------
> rainfall[, "name"]: Sandy 1.7 SSW
> [1] 0.2021324
> ------------------------------------------------------------
> rainfall[, "name"]: Sherwood 3.3 SE
> [1] 0.1461752
>
>    Now I know how to properly apply by() to an unsplit dataframe. Thanks
> for
> the insightful lesson.
>
> Best regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jmh@nnon@ucd@vi@ @ending from gm@il@com  Mon Sep 17 23:57:15 2018
From: jmh@nnon@ucd@vi@ @ending from gm@il@com (Michael Hannon)
Date: Mon, 17 Sep 2018 14:57:15 -0700
Subject: [R] Unable to update R 3.4 to R 3.5 in Ubuntu 18.04 LTS
In-Reply-To: <CAMo+egkiwPriFXCbSvMH3234BEitjBMxuwmYBC4gEjPdzUqA8g@mail.gmail.com>
References: <CAMo+egkiwPriFXCbSvMH3234BEitjBMxuwmYBC4gEjPdzUqA8g@mail.gmail.com>
Message-ID: <CACdH2ZZn5w6+u4kW01K_t5U9v4JLRu78_M-mSSn4n=xa4btWZw@mail.gmail.com>

I didn't find an attached file, but I'm using Ubuntu 18.04 and have upgraded R
to version 3.5.

I don't recall exactly how I did the upgrade, but it must have been something
like:

https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-18-04-quickstart

-- Mike

$ cat /etc/os-release
NAME="Ubuntu"
VERSION="18.04.1 LTS (Bionic Beaver)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 18.04.1 LTS"
VERSION_ID="18.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic

$ grep cloud /etc/apt/sources.list
deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/


> devtools::session_info()
Session info ------------------------------------------------------------------
 setting  value
 version  R version 3.5.1 (2018-07-02)
 system   x86_64, linux-gnu
 ui       X11
 language (EN)
 collate  en_US.UTF-8
 tz       America/Los_Angeles
 date     2018-09-17

Packages ----------------------------------------------------------------------
 package   * version date       source
 base      * 3.5.1   2018-07-03 local
 compiler    3.5.1   2018-07-03 local
 datasets  * 3.5.1   2018-07-03 local
 devtools    1.13.6  2018-06-27 CRAN (R 3.5.1)
 digest      0.6.17  2018-09-12 CRAN (R 3.5.1)
 graphics  * 3.5.1   2018-07-03 local
 grDevices * 3.5.1   2018-07-03 local
 memoise     1.1.0   2017-04-21 CRAN (R 3.5.1)
 methods   * 3.5.1   2018-07-03 local
 stats     * 3.5.1   2018-07-03 local
 utils     * 3.5.1   2018-07-03 local
 withr       2.1.2   2018-03-15 CRAN (R 3.5.1)
On Mon, Sep 17, 2018 at 10:12 AM RUPJYOTI DAS <rj.innet at gmail.com> wrote:
>
> Dear All,
> I am using R to carry out RNA-Seq workflow in my standalone machine which
> needs the latest R version >=3.5. I was trying to update firstly removing
> the R 3.4 and reinstalling from scratch again the latest version. Can
> anybody just guide me how to carry out the process as I am getting only R
> 3.4 again and again.
> Also when I remove the
> *deb ... bionic-cran35 (mirror for R cran )*
>
> from the* source.list* file (opened by* sudo gedit /etc/apt/sources.list*)
> the command *sudo apt-get update* works fine which does not upgrade the R
> 3.4 to R 3.5.1.
> Adding the line
> *deb ... bionic-cran35/ *
> gives the attached error log*. **Please find the attached file and  do
> check.*
>
> Any answers and suggestions will be of immense help!
>
> Thanking you!
>
> *Rupjyoti Das*
> *M.Tech*, Information Technology
> Tezpur University
> Assam, India 784028
> Mob. +91-8812807195
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zhhhw@ng @ending from umich@edu  Mon Sep 17 21:55:27 2018
From: zhhhw@ng @ending from umich@edu (Zhihao Huang)
Date: Mon, 17 Sep 2018 15:55:27 -0400
Subject: [R] makeCluster() hangs infinitely
In-Reply-To: <CAFDcVCSvR_=-EEqkkq-yfNpFZ8TGLxa3M4teko935ZMCKMzsAw@mail.gmail.com>
References: <CADBpgp0PsJ7M5MATA8jkMQA1DnJ-HmQRXzGLcq=TyKe8UWG7Ag@mail.gmail.com>
 <CAFDcVCSvR_=-EEqkkq-yfNpFZ8TGLxa3M4teko935ZMCKMzsAw@mail.gmail.com>
Message-ID: <CADBpgp3DNPHPaHmPkmS+PhF6XAo0cHPgHtGx=eC42o5TUyJQTw@mail.gmail.com>

Hi Henrik,

Thanks for the suggestions! I tried your approach, and obtained the
following output, which is pretty similar to the previous ones.

> cl <- future::makeClusterPSOCK(1, outfile = NULL, verbose = TRUE)

*Workers: [n = 1] ?localhost?*

*Base port: 11214*

*Creating node 1 of 1 ...*

*- setting up node*

*Starting worker #1 on ?localhost?:
'/Library/Frameworks/R.framework/Resources/bin/Rscript'
--default-packages=datasets,utils,grDevices,graphics,stats,methods -e
'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT= TIMEOUT=2592000
XDR=TRUE*

*Waiting for worker #1 on ?localhost? to connect back*

starting worker pid=13731 on localhost:11214 at 15:48:41.991
I guess this is a connection problem. I am not sure what these numbers
mean. Do you have any further idea on this? I very much appreciate it!

Thanks,
Zhihao
--
Zhihao (Daniel) Huang
Graduate Student
Department of Statistics,
University of Michigan, Ann Arbor
Email: zhhhwang at umich.edu



On Mon, Sep 17, 2018 at 12:38 AM Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> Hi,
>
> did you see my answer on StackOverflow? Specifically, if you set
> argument 'outfile = NULL' to either of those two functions, you'll get
> a little bit more information that *might* provide some clues.
>
> /Henrik
>
>
> On Sun, Sep 16, 2018 at 5:38 PM Zhihao Huang <zhhhwang at umich.edu> wrote:
> >
> > Hi all,
> >
> > The function makeCluster() of parallel does not work on my laptop. It
> hangs
> > infinitely.
> >
> > *1. Problem Summary:*
> >
> > > # Loading parallel packages
> >
> > > library(parallel)
> >
> > > cl <- makeCluster(2) # It hangs at this line of code.
> > It hangs at the second line of the code.
> >
> > *2. Potential Reason*
> > I also tried to see the details of what it does internally by using the
> > following code.
> >
> > > library(future)
> >
> > > cl <- future::makeClusterPSOCK(1L, verbose = TRUE) # It hangs at this
> > line of code.
> > And it returns the following descriptions and hangs.
> >
> > *Workers: [n = 1] ?localhost?*
> >
> > *Base port: 11214*
> >
> > *Creating node 1 of 1 ...*
> >
> > *- setting up node*
> >
> > *Starting worker #1 on ?localhost?:
> > '/Library/Frameworks/R.framework/Resources/bin/Rscript'
> > --default-packages=datasets,utils,grDevices,graphics,stats,methods -e
> > 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT=/dev/null
> > TIMEOUT=2592000 XDR=TRUE*
> >
> > *Waiting for worker #1 on ?localhost? to connect back*
> > So the problem is that the "worker #1 on 'local host'" never connects
> back,
> > and that's why it hangs forever. I have no idea what causes this.
> >
> > *3. my sessionInfo():*
> >
> > R version 3.5.1 (2018-07-02)
> >
> > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> >
> > Running under: macOS High Sierra 10.13.6
> >
> >
> > Matrix products: default
> >
> > BLAS:
> >
> /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
> >
> > LAPACK:
> >
> /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
> >
> >
> > locale:
> >
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >
> >
> > attached base packages:
> >
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> >
> > loaded via a namespace (and not attached):
> >
> > [1] compiler_3.5.1
> >
> > I spent hours searching for the solutions but failed. It looks like some
> > other people met similar problem here
> > <http://r.789695.n4.nabble.com/makeCluster-hangs-td4748238.html>. Also,
> I
> > posted this question online here
> > <
> https://stackoverflow.com/questions/52264460/r-parallel-makecluster-hangs-infinitely-on-mac/52284709#52284709
> >
> > a
> > week ago.
> >
> > Any suggestion would be appreciated. Thanks a lot!
> >
> > Thanks,
> > Zhihao
> > --
> > Zhihao (Daniel) Huang
> > Graduate Student
> > Department of Statistics,
> > University of Michigan, Ann Arbor
> > Email: zhhhwang at umich.edu
> >
> > --
> > ? ??
> > Zhihao Huang
> >
> > Graduate Student
> > Department of Statistics,
> > University of Michigan, Ann Arbor
> > Email: zhhhwang at umich.edu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @rt@tem@u@ @ending from gm@il@com  Mon Sep 17 23:29:59 2018
From: @rt@tem@u@ @ending from gm@il@com (Art U)
Date: Mon, 17 Sep 2018 17:29:59 -0400
Subject: [R] pdredge error
Message-ID: <CAKY_brGivpC-t=LHxphUKoLxfw41i2Q1NL=jn8zUz=xbp=vWBQ@mail.gmail.com>

Hello,

I'm trying to use parallel computing in MuMIn package. It worked a couple
month ago, but now I'm getting the error. Here is a code:

#Data
x1 = rnorm(1000)
x2 = rnorm(1000)
x3 = rnorm(1000)
z = 1 + 0.5*x1 - x2
pr = 1/(1+exp(-z))
y = rbinom(1000, 1, pr)
dataD = cbind(y=y, x1=x1 ,x2=x2, x3=x3)

#Fixed variable
fix.var = c("x1")

#Model averaging
cl <- makeCluster(detectCores())
clusterExport(cl, c("dataD"), envir=environment())
clusterExport(cl, c("y"), envir=environment())
clusterExport(cl, c("fix.var"), envir=environment())
clusterEvalQ(cl, library(MuMIn))
d = data.frame(dataD)
      options(na.action = "na.fail")
      m.inc = glm(y~., family=binomial, data=d)
      MA.inc = pdredge(global.model = m.inc, rank = "AIC" , fixed =
fix.var, cluster=cl)
      mo.inc = model.avg(MA.inc, rank =  "AIC")
      atr.inc = attr(mo.inc, "modelList")
 stopCluster(cl)

The error says that data frame 'd' is not found and the pdredge result is
empty:

Warning messages:
1: In is.data.frame(data) : object 'd' not found (model 0 skipped)
2: In is.data.frame(data) : object 'd' not found (model 1 skipped)
3: In is.data.frame(data) : object 'd' not found (model 2 skipped)
4: In is.data.frame(data) : object 'd' not found (model 3 skipped)
5: In is.data.frame(data) : object 'd' not found (model 4 skipped)
Error in pdredge(global.model = m.inc, rank = "AIC" , fixed = fix.var,    :
  the result is empty



-- 
*I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
or plague*... *Whatever*. *No-one left to act normal for. No need to hide
who I really am. It would be... freeing*. *...*

	[[alternative HTML version deleted]]


From giftedlife2014 @ending from gm@il@com  Tue Sep 18 04:24:37 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Tue, 18 Sep 2018 03:24:37 +0100
Subject: [R] customizing the number of decimal places in xtable
Message-ID: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>

Dear Volunteers,

I have a table involving many decimal places:
2005-01-04 -2.13339817688037
2005-01-19 -6.86312349695117
2005-01-22 -4.33662370554386
2005-02-10 -1.40789214441639
2005-02-13 -1.1334121785854
2005-02-19 -1.28411233010119
2005-05-09 -1.6895978161324
2005-05-16 -3.07664523496947
2005-06-17 -1.69904491217129
2005-07-17 -3.44289318667434
2005-08-07 -2.29676435700659
2005-08-10 -1.08915071542227
2005-08-24 -1.8244123081697
2005-09-13 -4.57899147546373
2005-09-15 -3.96591895962343
 I used xtable to covert this to form of latex table.

The result I have is:
1 & 2005-01-04 & -2.13 \\
  2 & 2005-01-19 & -6.86 \\
  3 & 2005-01-22 & -4.34 \\
  4 & 2005-02-10 & -1.41 \\
  5 & 2005-02-13 & -1.13 \\
  6 & 2005-02-19 & -1.28 \\
  7 & 2005-05-09 & -1.69 \\
  8 & 2005-05-16 & -3.08 \\
  9 & 2005-06-17 & -1.70 \\
  10 & 2005-07-17 & -3.44 \\
  11 & 2005-08-07 & -2.30 \\
  12 & 2005-08-10 & -1.09 \\
  13 & 2005-08-24 & -1.82 \\
  14 & 2005-09-13 & -4.58 \\
  15 & 2005-09-15 & -3.97 \\.

It has truncated the long decimal places. Since it is not want I want, I
have to copy from the original table and place into xtable.

Can you please tell me how to customize the xtable so that I will be
responsible for the number of decimal places it displays.

Many thanks for your precious time.

Warmest regards
Ogbos

	[[alternative HTML version deleted]]


From chocold12 @ending from gm@il@com  Tue Sep 18 06:44:45 2018
From: chocold12 @ending from gm@il@com (lily li)
Date: Tue, 18 Sep 2018 12:44:45 +0800
Subject: [R] Open netcdf file in linux
Message-ID: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>

Hi R users,

I have installed ncdf4 package in R from the linux terminal, but have met
this problem when using nc_open to open a .nc file. What is the problem?
Any help would be appreciated.

Error in R_nc4_open: Is a directory

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Sep 18 07:27:29 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 17 Sep 2018 22:27:29 -0700
Subject: [R] customizing the number of decimal places in xtable
In-Reply-To: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>
References: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>
Message-ID: <EE269AA9-F2B2-4082-BB99-E237BC9E7266@dcn.davis.ca.us>

Have you read

?xtable


On September 17, 2018 7:24:37 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Volunteers,
>
>I have a table involving many decimal places:
>2005-01-04 -2.13339817688037
>2005-01-19 -6.86312349695117
>2005-01-22 -4.33662370554386
>2005-02-10 -1.40789214441639
>2005-02-13 -1.1334121785854
>2005-02-19 -1.28411233010119
>2005-05-09 -1.6895978161324
>2005-05-16 -3.07664523496947
>2005-06-17 -1.69904491217129
>2005-07-17 -3.44289318667434
>2005-08-07 -2.29676435700659
>2005-08-10 -1.08915071542227
>2005-08-24 -1.8244123081697
>2005-09-13 -4.57899147546373
>2005-09-15 -3.96591895962343
> I used xtable to covert this to form of latex table.
>
>The result I have is:
>1 & 2005-01-04 & -2.13 \\
>  2 & 2005-01-19 & -6.86 \\
>  3 & 2005-01-22 & -4.34 \\
>  4 & 2005-02-10 & -1.41 \\
>  5 & 2005-02-13 & -1.13 \\
>  6 & 2005-02-19 & -1.28 \\
>  7 & 2005-05-09 & -1.69 \\
>  8 & 2005-05-16 & -3.08 \\
>  9 & 2005-06-17 & -1.70 \\
>  10 & 2005-07-17 & -3.44 \\
>  11 & 2005-08-07 & -2.30 \\
>  12 & 2005-08-10 & -1.09 \\
>  13 & 2005-08-24 & -1.82 \\
>  14 & 2005-09-13 & -4.58 \\
>  15 & 2005-09-15 & -3.97 \\.
>
>It has truncated the long decimal places. Since it is not want I want,
>I
>have to copy from the original table and place into xtable.
>
>Can you please tell me how to customize the xtable so that I will be
>responsible for the number of decimal places it displays.
>
>Many thanks for your precious time.
>
>Warmest regards
>Ogbos
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Sep 18 07:33:10 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 17 Sep 2018 22:33:10 -0700
Subject: [R] Open netcdf file in linux
In-Reply-To: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>
References: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>
Message-ID: <16A5250F-1718-4D98-86D8-D5813C24D562@dcn.davis.ca.us>

I really don't know how you expect an answer when you don't show what you did or pointed us to an example of a file that yields this error. My best blind guess is that you have not given the name of an ncdf file to the function.

On September 17, 2018 9:44:45 PM PDT, lily li <chocold12 at gmail.com> wrote:
>Hi R users,
>
>I have installed ncdf4 package in R from the linux terminal, but have
>met
>this problem when using nc_open to open a .nc file. What is the
>problem?
>Any help would be appreciated.
>
>Error in R_nc4_open: Is a directory
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From giftedlife2014 @ending from gm@il@com  Tue Sep 18 07:49:43 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Tue, 18 Sep 2018 06:49:43 +0100
Subject: [R] 
 customizing the number of decimal places in xtable: RESOLVED
In-Reply-To: <EE269AA9-F2B2-4082-BB99-E237BC9E7266@dcn.davis.ca.us>
References: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>
 <EE269AA9-F2B2-4082-BB99-E237BC9E7266@dcn.davis.ca.us>
Message-ID: <CAC8ss33H5f4=BndZ7EwmfwbE=HnKW0p-GqAHKxu3w+r-zN=ezw@mail.gmail.com>

Dear Jeff,

Thank you please.

I did search before but could not get it resolved. But with your query now,
just typed ?xtable as key  search word and the first document I opened gave
an indication of digits. Without knowing what it was saying, I tried it in
my data and it gave the result I have been looking for.

xtable(data, digits=12) and I am fine.

Thank you so much.

Ogbos

On Tue, Sep 18, 2018 at 6:27 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Have you read
>
> ?xtable
>
>
> On September 17, 2018 7:24:37 PM PDT, Ogbos Okike <
> giftedlife2014 at gmail.com> wrote:
> >Dear Volunteers,
> >
> >I have a table involving many decimal places:
> >2005-01-04 -2.13339817688037
> >2005-01-19 -6.86312349695117
> >2005-01-22 -4.33662370554386
> >2005-02-10 -1.40789214441639
> >2005-02-13 -1.1334121785854
> >2005-02-19 -1.28411233010119
> >2005-05-09 -1.6895978161324
> >2005-05-16 -3.07664523496947
> >2005-06-17 -1.69904491217129
> >2005-07-17 -3.44289318667434
> >2005-08-07 -2.29676435700659
> >2005-08-10 -1.08915071542227
> >2005-08-24 -1.8244123081697
> >2005-09-13 -4.57899147546373
> >2005-09-15 -3.96591895962343
> > I used xtable to covert this to form of latex table.
> >
> >The result I have is:
> >1 & 2005-01-04 & -2.13 \\
> >  2 & 2005-01-19 & -6.86 \\
> >  3 & 2005-01-22 & -4.34 \\
> >  4 & 2005-02-10 & -1.41 \\
> >  5 & 2005-02-13 & -1.13 \\
> >  6 & 2005-02-19 & -1.28 \\
> >  7 & 2005-05-09 & -1.69 \\
> >  8 & 2005-05-16 & -3.08 \\
> >  9 & 2005-06-17 & -1.70 \\
> >  10 & 2005-07-17 & -3.44 \\
> >  11 & 2005-08-07 & -2.30 \\
> >  12 & 2005-08-10 & -1.09 \\
> >  13 & 2005-08-24 & -1.82 \\
> >  14 & 2005-09-13 & -4.58 \\
> >  15 & 2005-09-15 & -3.97 \\.
> >
> >It has truncated the long decimal places. Since it is not want I want,
> >I
> >have to copy from the original table and place into xtable.
> >
> >Can you please tell me how to customize the xtable so that I will be
> >responsible for the number of decimal places it displays.
> >
> >Many thanks for your precious time.
> >
> >Warmest regards
> >Ogbos
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From @@himk@poor @ending from gm@il@com  Tue Sep 18 07:51:21 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Tue, 18 Sep 2018 11:21:21 +0530
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
Message-ID: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>

Dear All,

I was reading this page --->
https://cran.r-project.org/bin/linux/ubuntu/README.html

It says: R 3.4 packages for Ubuntu on i386 and amd64 are available for all
stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04) until
their official end of life date.

The page also shows how to install R 3.5 on Ubuntu 18.04.1

My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we only
install R 3.5 ?

Many thanks,
Ashim

	[[alternative HTML version deleted]]


From f@bi@no@fr@nc@d@ @ending from hotm@il@com  Tue Sep 18 04:34:30 2018
From: f@bi@no@fr@nc@d@ @ending from hotm@il@com (=?Windows-1252?Q?Fabiano_Fran=E7a?=)
Date: Tue, 18 Sep 2018 02:34:30 +0000
Subject: [R] =?windows-1252?q?How_to_troubleshoot_error_=93cannot_coerce_?=
 =?windows-1252?q?class_=94=93group=94=93_to_a_data=2Eframe=94=3F?=
Message-ID: <CY4PR13MB0966DE9F77B10894B45F0EA3831D0@CY4PR13MB0966.namprd13.prod.outlook.com>

Dear Volunteers,
When running the scriptbelow, specifically in the part of reproduction of the data.framesreturned the error:

Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) : cannot coerce class ""group"" to a data.frame

I searched the internet and could not reproduce the suggestions for my case, does anyone tell me a way?

setwd("https://drive.google.com/open?id=1FDMZfWrEjsvleVdNOUiPh8REGjvQHKQx")
rend <- read.table('IVCM.txt', header = TRUE, sep="\t")
rend <- transform(rend, Fungicidas=factor(Fungicidas), Doses=factor(Doses), Rep=factor(Rep))
str(rend)#---------------------------------------------------------------------------# unfolding the interaction in Tukey tests

require(agricolae)
require(plyr)

KinA <- sapply(levels(rend$Doses), simplify=FALSE,
               function(Doses){
                 with(subset(rend, Doses==Doses),
                      HSD.test(IVCM, Fungicidas,
                               DFerror=df.residual(m0),
                               MSerror=deviance(m0)/df.residual(m0)))
               })

KinA <- llply(KinA, NULL)
KinA$M <- gsub(" ", "", KinA$M, fixed=TRUE)
KinA$trt <- as.factor(as.numeric(as.character(KinA$trt)))
str(KinA)

AinK <- sapply(levels(rend$Fungicidas), simplify=FALSE,
               function(Fungicidas){
                 with(subset(rend, Fungicidas==Fungicidas),
                      HSD.test(IVCM, Doses,
                               DFerror=df.residual(m0),
                               MSerror=deviance(m0)/df.residual(m0)))
               })

AinK <- llply(AinK, NULL)
AinK$M <- toupper(gsub(" ", "", AinK$M, fixed=TRUE))
AinK$trt <- as.factor(as.numeric(as.character(AinK$trt)))
str(AinK)

Many thanks

Regards,

Fabiano Fran?a da Silva
Doutorando em Fitotecnia - ESALQ/USP
MSc Fitotecnia - UFLA
Eng?. Agr?nomo - UFLA
(35) 9 9155-5443 TIM



	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Tue Sep 18 08:19:02 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Tue, 18 Sep 2018 07:19:02 +0100
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
Message-ID: <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>

Hello,

I am not completely sure but I think I installed Ubuntu 18.04 LTS first 
and R 3.5 days later, so yes, if I'm right it is possible to run R 3.4 
on 18.04.

(You ask whether we can *install* R 3.4 on Ubuntu 18.04.1, I'm saying it 
can be *run* on Ubuntu 18.04.1.)

Hope this helps,

Rui Barradas


?s 06:51 de 18/09/2018, Ashim Kapoor escreveu:
> Dear All,
> 
> I was reading this page --->
> https://cran.r-project.org/bin/linux/ubuntu/README.html
> 
> It says: R 3.4 packages for Ubuntu on i386 and amd64 are available for all
> stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04) until
> their official end of life date.
> 
> The page also shows how to install R 3.5 on Ubuntu 18.04.1
> 
> My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we only
> install R 3.5 ?
> 
> Many thanks,
> Ashim
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chocold12 @ending from gm@il@com  Tue Sep 18 08:53:22 2018
From: chocold12 @ending from gm@il@com (lily li)
Date: Tue, 18 Sep 2018 14:53:22 +0800
Subject: [R] Open netcdf file in linux
In-Reply-To: <16A5250F-1718-4D98-86D8-D5813C24D562@dcn.davis.ca.us>
References: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>
 <16A5250F-1718-4D98-86D8-D5813C24D562@dcn.davis.ca.us>
Message-ID: <CAN5afy8A8uNCCMHKU8dd8fkxczoDuoEx4AH94ScMF=4WtcJhQg@mail.gmail.com>

Thanks, you are right that the file path is not correct. I just typed:
nc_open("file.nc"), and it gave the error above.

On Tue, Sep 18, 2018 at 1:33 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I really don't know how you expect an answer when you don't show what you
> did or pointed us to an example of a file that yields this error. My best
> blind guess is that you have not given the name of an ncdf file to the
> function.
>
> On September 17, 2018 9:44:45 PM PDT, lily li <chocold12 at gmail.com> wrote:
> >Hi R users,
> >
> >I have installed ncdf4 package in R from the linux terminal, but have
> >met
> >this problem when using nc_open to open a .nc file. What is the
> >problem?
> >Any help would be appreciated.
> >
> >Error in R_nc4_open: Is a directory
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From chocold12 @ending from gm@il@com  Tue Sep 18 08:59:05 2018
From: chocold12 @ending from gm@il@com (lily li)
Date: Tue, 18 Sep 2018 14:59:05 +0800
Subject: [R] Problem in installing rgdal package in linux
Message-ID: <CAN5afy-vwcHWqVCsm5xt5RDB4d2JdBT60HHLTk42VrayhqxPSA@mail.gmail.com>

Hi all,

I am installing rgdal package in linux for R, and got the error below. I
typed: $ install.packages("rgdal", repos= "http://cran.us.r-project.org")

What is the problem and how to correct it? Thanks for your kind help.

============================== print the error message here

downloaded 1.6 MB


* installing *source* package ?rgdal? ...

** package ?rgdal? successfully unpacked and MD5 sums checked

configure: R_HOME: /usr/lib64/R

configure: CC: gcc -m64 -std=gnu99

configure: CXX: g++ -m64

configure: C++11 support available

configure: rgdal: 1.3-4

checking for /usr/bin/svnversion... yes

configure: svn revision: 766

checking for gdal-config... no

no

configure: error: gdal-config not found or not executable.

ERROR: configuration failed for package ?rgdal?

* removing ?/directory/R/x86_64-redhat-linux-gnu-library/3.5/rgdal?


The downloaded source packages are in

?/tmp/RtmpplM8mi/downloaded_packages?

Warning message:

In install.packages("rgdal") :

  installation of package ?rgdal? had non-zero exit status

	[[alternative HTML version deleted]]


From @@himk@poor @ending from gm@il@com  Tue Sep 18 09:24:06 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Tue, 18 Sep 2018 12:54:06 +0530
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
Message-ID: <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>

Dear Rui,

I am a little confused.

See this ---> : R 3.4 packages for Ubuntu on i386 and amd64 are available
for all stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04)
until their official end of life date. However, only the latest Long Term
Support (LTS) release is fully supported. As of June 11, 2018 the supported
releases are Artful Aardvark (17.10), Xenial Xerus (16.04; LTS), and Trusty
Tahr (14.04; LTS).

Bionic Beaver ( Ubuntu 18.04 ) is NOT in the list of supported releases for
R 3.4  What does this mean ? Can you please clarify ?

Many thanks,
Ashim

On Tue, Sep 18, 2018 at 11:49 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I am not completely sure but I think I installed Ubuntu 18.04 LTS first
> and R 3.5 days later, so yes, if I'm right it is possible to run R 3.4
> on 18.04.
>
> (You ask whether we can *install* R 3.4 on Ubuntu 18.04.1, I'm saying it
> can be *run* on Ubuntu 18.04.1.)
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 06:51 de 18/09/2018, Ashim Kapoor escreveu:
> > Dear All,
> >
> > I was reading this page --->
> > https://cran.r-project.org/bin/linux/ubuntu/README.html
> >
> > It says: R 3.4 packages for Ubuntu on i386 and amd64 are available for
> all
> > stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04) until
> > their official end of life date.
> >
> > The page also shows how to install R 3.5 on Ubuntu 18.04.1
> >
> > My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we only
> > install R 3.5 ?
> >
> > Many thanks,
> > Ashim
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Sep 18 09:24:31 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 18 Sep 2018 00:24:31 -0700
Subject: [R] 
 customizing the number of decimal places in xtable: RESOLVED
In-Reply-To: <CAC8ss33H5f4=BndZ7EwmfwbE=HnKW0p-GqAHKxu3w+r-zN=ezw@mail.gmail.com>
References: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>
 <EE269AA9-F2B2-4082-BB99-E237BC9E7266@dcn.davis.ca.us>
 <CAC8ss33H5f4=BndZ7EwmfwbE=HnKW0p-GqAHKxu3w+r-zN=ezw@mail.gmail.com>
Message-ID: <E841EFA0-1BB1-47C9-8D9F-C27D16C92E50@dcn.davis.ca.us>

I gather you find the content of the help page for the xtable function hard to understand, but you need to build the skill of reading them and gathering clues about functions you call from them.

* They always have a usage section that briefly summarizes how the function is called and what the default values are for those parameters that do have defaults.

* They always mention what each parameter is for. (The help page may not always be thorough enough to suit your preference, but CRAN requires the author to make some effort to describe every parameter. Note that people posting packages on GitHub have no one insisting that they put in this effort, so beware that quality may vary more if you start using non-CRAN packages.) The digits parameter is used by many data formatting functions, and it can usually be specified as a vector with each element affecting a corresponding column of data in order.

* They always indicate what kind of Value will be returned from the function.

* They usually have Notes on how the function reacts to different input values.

* They often have Examples of how to use the function.

* They often have  a See Also section indicating what other functions you might find relevant when using this function.

* They sometimes have a section listing References to read to learn more about the theory behind the function.

Not all authors of help pages put the same level of effort into making help pages readable, and there is undoubtedly some shorthand notation that gives you key information more compactly than you might wish for as a beginner. However, if you ask for help interpreting specific help pages then you may learn more about how they work or the authors may re-write certain help pages based on your questions to address the source of your confusion.  Beware that if you don't read them first and mention why they didn't answer your question then you may get less helpful responses when when you do ask questions.

On September 17, 2018 10:49:43 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Jeff,
>
>Thank you please.
>
>I did search before but could not get it resolved. But with your query
>now,
>just typed ?xtable as key  search word and the first document I opened
>gave
>an indication of digits. Without knowing what it was saying, I tried it
>in
>my data and it gave the result I have been looking for.
>
>xtable(data, digits=12) and I am fine.
>
>Thank you so much.
>
>Ogbos
>
>On Tue, Sep 18, 2018 at 6:27 AM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Have you read
>>
>> ?xtable
>>
>>
>> On September 17, 2018 7:24:37 PM PDT, Ogbos Okike <
>> giftedlife2014 at gmail.com> wrote:
>> >Dear Volunteers,
>> >
>> >I have a table involving many decimal places:
>> >2005-01-04 -2.13339817688037
>> >2005-01-19 -6.86312349695117
>> >2005-01-22 -4.33662370554386
>> >2005-02-10 -1.40789214441639
>> >2005-02-13 -1.1334121785854
>> >2005-02-19 -1.28411233010119
>> >2005-05-09 -1.6895978161324
>> >2005-05-16 -3.07664523496947
>> >2005-06-17 -1.69904491217129
>> >2005-07-17 -3.44289318667434
>> >2005-08-07 -2.29676435700659
>> >2005-08-10 -1.08915071542227
>> >2005-08-24 -1.8244123081697
>> >2005-09-13 -4.57899147546373
>> >2005-09-15 -3.96591895962343
>> > I used xtable to covert this to form of latex table.
>> >
>> >The result I have is:
>> >1 & 2005-01-04 & -2.13 \\
>> >  2 & 2005-01-19 & -6.86 \\
>> >  3 & 2005-01-22 & -4.34 \\
>> >  4 & 2005-02-10 & -1.41 \\
>> >  5 & 2005-02-13 & -1.13 \\
>> >  6 & 2005-02-19 & -1.28 \\
>> >  7 & 2005-05-09 & -1.69 \\
>> >  8 & 2005-05-16 & -3.08 \\
>> >  9 & 2005-06-17 & -1.70 \\
>> >  10 & 2005-07-17 & -3.44 \\
>> >  11 & 2005-08-07 & -2.30 \\
>> >  12 & 2005-08-10 & -1.09 \\
>> >  13 & 2005-08-24 & -1.82 \\
>> >  14 & 2005-09-13 & -4.58 \\
>> >  15 & 2005-09-15 & -3.97 \\.
>> >
>> >It has truncated the long decimal places. Since it is not want I
>want,
>> >I
>> >have to copy from the original table and place into xtable.
>> >
>> >Can you please tell me how to customize the xtable so that I will be
>> >responsible for the number of decimal places it displays.
>> >
>> >Many thanks for your precious time.
>> >
>> >Warmest regards
>> >Ogbos
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From chocold12 @ending from gm@il@com  Tue Sep 18 09:38:57 2018
From: chocold12 @ending from gm@il@com (lily li)
Date: Tue, 18 Sep 2018 15:38:57 +0800
Subject: [R] Open netcdf file in linux
In-Reply-To: <F4222F62-5F35-41ED-AE0F-B7B87F5E54BF@dcn.davis.ca.us>
References: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>
 <16A5250F-1718-4D98-86D8-D5813C24D562@dcn.davis.ca.us>
 <CAN5afy8A8uNCCMHKU8dd8fkxczoDuoEx4AH94ScMF=4WtcJhQg@mail.gmail.com>
 <F4222F62-5F35-41ED-AE0F-B7B87F5E54BF@dcn.davis.ca.us>
Message-ID: <CAN5afy975bGHuUxoxztjeph_1at4794nzKRZVw9J6pXdbTv4xQ@mail.gmail.com>

I did not set the correct path for the .nc file earlier. Now it is working
properly.



> I find your response confusing still... did you now no longer need help?
>
> If you are still puzzled, then what does
>
> file.info("file.nc")
>
> return?
>
> Do you see that file in your current directory via your operating system?
>
> On September 17, 2018 11:53:22 PM PDT, lily li <chocold12 at gmail.com>
> wrote:
> >Thanks, you are right that the file path is not correct. I just typed:
> >nc_open("file.nc"), and it gave the error above.
> >
> >On Tue, Sep 18, 2018 at 1:33 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> I really don't know how you expect an answer when you don't show what
> >you
> >> did or pointed us to an example of a file that yields this error. My
> >best
> >> blind guess is that you have not given the name of an ncdf file to
> >the
> >> function.
> >>
> >> On September 17, 2018 9:44:45 PM PDT, lily li <chocold12 at gmail.com>
> >wrote:
> >> >Hi R users,
> >> >
> >> >I have installed ncdf4 package in R from the linux terminal, but
> >have
> >> >met
> >> >this problem when using nc_open to open a .nc file. What is the
> >> >problem?
> >> >Any help would be appreciated.
> >> >
> >> >Error in R_nc4_open: Is a directory
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Sep 18 09:40:28 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 18 Sep 2018 00:40:28 -0700
Subject: [R] Problem in installing rgdal package in linux
In-Reply-To: <CAN5afy-vwcHWqVCsm5xt5RDB4d2JdBT60HHLTk42VrayhqxPSA@mail.gmail.com>
References: <CAN5afy-vwcHWqVCsm5xt5RDB4d2JdBT60HHLTk42VrayhqxPSA@mail.gmail.com>
Message-ID: <5221D1FD-B479-4178-B47D-B144D03E8F34@dcn.davis.ca.us>

Read [1], in particular about System Requirements. Some packages have underlying configuration that needs to be handled through your operating system before the package can be installed.

[1] https://cran.r-project.org/web/packages/rgdal/index.html

On September 17, 2018 11:59:05 PM PDT, lily li <chocold12 at gmail.com> wrote:
>Hi all,
>
>I am installing rgdal package in linux for R, and got the error below.
>I
>typed: $ install.packages("rgdal", repos=
>"http://cran.us.r-project.org")
>
>What is the problem and how to correct it? Thanks for your kind help.
>
>============================== print the error message here
>
>downloaded 1.6 MB
>
>
>* installing *source* package ?rgdal? ...
>
>** package ?rgdal? successfully unpacked and MD5 sums checked
>
>configure: R_HOME: /usr/lib64/R
>
>configure: CC: gcc -m64 -std=gnu99
>
>configure: CXX: g++ -m64
>
>configure: C++11 support available
>
>configure: rgdal: 1.3-4
>
>checking for /usr/bin/svnversion... yes
>
>configure: svn revision: 766
>
>checking for gdal-config... no
>
>no
>
>configure: error: gdal-config not found or not executable.
>
>ERROR: configuration failed for package ?rgdal?
>
>* removing ?/directory/R/x86_64-redhat-linux-gnu-library/3.5/rgdal?
>
>
>The downloaded source packages are in
>
>?/tmp/RtmpplM8mi/downloaded_packages?
>
>Warning message:
>
>In install.packages("rgdal") :
>
>  installation of package ?rgdal? had non-zero exit status
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @lk@uffm @ending from f@@tm@il@fm  Tue Sep 18 09:30:47 2018
From: @lk@uffm @ending from f@@tm@il@fm (Albrecht Kauffmann)
Date: Tue, 18 Sep 2018 09:30:47 +0200
Subject: [R] Problem in installing rgdal package in linux
In-Reply-To: <CAN5afy-vwcHWqVCsm5xt5RDB4d2JdBT60HHLTk42VrayhqxPSA@mail.gmail.com>
References: <CAN5afy-vwcHWqVCsm5xt5RDB4d2JdBT60HHLTk42VrayhqxPSA@mail.gmail.com>
Message-ID: <1537255847.1561271.1511785856.56E37487@webmail.messagingengine.com>

Hi Lily,

did you install gdal on your system?

Best,
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Di, 18. Sep 2018, um 08:59, schrieb lily li:
> Hi all,
> 
> I am installing rgdal package in linux for R, and got the error below. I
> typed: $ install.packages("rgdal", repos= "http://cran.us.r-project.org")
> 
> What is the problem and how to correct it? Thanks for your kind help.
> 
> ============================== print the error message here
> 
> downloaded 1.6 MB
> 
> 
> * installing *source* package ?rgdal? ...
> 
> ** package ?rgdal? successfully unpacked and MD5 sums checked
> 
> configure: R_HOME: /usr/lib64/R
> 
> configure: CC: gcc -m64 -std=gnu99
> 
> configure: CXX: g++ -m64
> 
> configure: C++11 support available
> 
> configure: rgdal: 1.3-4
> 
> checking for /usr/bin/svnversion... yes
> 
> configure: svn revision: 766
> 
> checking for gdal-config... no
> 
> no
> 
> configure: error: gdal-config not found or not executable.
> 
> ERROR: configuration failed for package ?rgdal?
> 
> * removing ?/directory/R/x86_64-redhat-linux-gnu-library/3.5/rgdal?
> 
> 
> The downloaded source packages are in
> 
> ?/tmp/RtmpplM8mi/downloaded_packages?
> 
> Warning message:
> 
> In install.packages("rgdal") :
> 
>   installation of package ?rgdal? had non-zero exit status
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giftedlife2014 @ending from gm@il@com  Tue Sep 18 09:31:20 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Tue, 18 Sep 2018 08:31:20 +0100
Subject: [R] 
 customizing the number of decimal places in xtable: RESOLVED
In-Reply-To: <E841EFA0-1BB1-47C9-8D9F-C27D16C92E50@dcn.davis.ca.us>
References: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>
 <EE269AA9-F2B2-4082-BB99-E237BC9E7266@dcn.davis.ca.us>
 <CAC8ss33H5f4=BndZ7EwmfwbE=HnKW0p-GqAHKxu3w+r-zN=ezw@mail.gmail.com>
 <E841EFA0-1BB1-47C9-8D9F-C27D16C92E50@dcn.davis.ca.us>
Message-ID: <CAC8ss31EgPgUV8TjjowBcoga-xoOYk145qjNE=m4_9a=qmH2ng@mail.gmail.com>

Dear Jeff,

Great!! Thanks for your concern/good advice.

Best regards
Ogbos

On Tue, Sep 18, 2018 at 8:24 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I gather you find the content of the help page for the xtable function
> hard to understand, but you need to build the skill of reading them and
> gathering clues about functions you call from them.
>
> * They always have a usage section that briefly summarizes how the
> function is called and what the default values are for those parameters
> that do have defaults.
>
> * They always mention what each parameter is for. (The help page may not
> always be thorough enough to suit your preference, but CRAN requires the
> author to make some effort to describe every parameter. Note that people
> posting packages on GitHub have no one insisting that they put in this
> effort, so beware that quality may vary more if you start using non-CRAN
> packages.) The digits parameter is used by many data formatting functions,
> and it can usually be specified as a vector with each element affecting a
> corresponding column of data in order.
>
> * They always indicate what kind of Value will be returned from the
> function.
>
> * They usually have Notes on how the function reacts to different input
> values.
>
> * They often have Examples of how to use the function.
>
> * They often have  a See Also section indicating what other functions you
> might find relevant when using this function.
>
> * They sometimes have a section listing References to read to learn more
> about the theory behind the function.
>
> Not all authors of help pages put the same level of effort into making
> help pages readable, and there is undoubtedly some shorthand notation that
> gives you key information more compactly than you might wish for as a
> beginner. However, if you ask for help interpreting specific help pages
> then you may learn more about how they work or the authors may re-write
> certain help pages based on your questions to address the source of your
> confusion.  Beware that if you don't read them first and mention why they
> didn't answer your question then you may get less helpful responses when
> when you do ask questions.
>
> On September 17, 2018 10:49:43 PM PDT, Ogbos Okike <
> giftedlife2014 at gmail.com> wrote:
> >Dear Jeff,
> >
> >Thank you please.
> >
> >I did search before but could not get it resolved. But with your query
> >now,
> >just typed ?xtable as key  search word and the first document I opened
> >gave
> >an indication of digits. Without knowing what it was saying, I tried it
> >in
> >my data and it gave the result I have been looking for.
> >
> >xtable(data, digits=12) and I am fine.
> >
> >Thank you so much.
> >
> >Ogbos
> >
> >On Tue, Sep 18, 2018 at 6:27 AM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> Have you read
> >>
> >> ?xtable
> >>
> >>
> >> On September 17, 2018 7:24:37 PM PDT, Ogbos Okike <
> >> giftedlife2014 at gmail.com> wrote:
> >> >Dear Volunteers,
> >> >
> >> >I have a table involving many decimal places:
> >> >2005-01-04 -2.13339817688037
> >> >2005-01-19 -6.86312349695117
> >> >2005-01-22 -4.33662370554386
> >> >2005-02-10 -1.40789214441639
> >> >2005-02-13 -1.1334121785854
> >> >2005-02-19 -1.28411233010119
> >> >2005-05-09 -1.6895978161324
> >> >2005-05-16 -3.07664523496947
> >> >2005-06-17 -1.69904491217129
> >> >2005-07-17 -3.44289318667434
> >> >2005-08-07 -2.29676435700659
> >> >2005-08-10 -1.08915071542227
> >> >2005-08-24 -1.8244123081697
> >> >2005-09-13 -4.57899147546373
> >> >2005-09-15 -3.96591895962343
> >> > I used xtable to covert this to form of latex table.
> >> >
> >> >The result I have is:
> >> >1 & 2005-01-04 & -2.13 \\
> >> >  2 & 2005-01-19 & -6.86 \\
> >> >  3 & 2005-01-22 & -4.34 \\
> >> >  4 & 2005-02-10 & -1.41 \\
> >> >  5 & 2005-02-13 & -1.13 \\
> >> >  6 & 2005-02-19 & -1.28 \\
> >> >  7 & 2005-05-09 & -1.69 \\
> >> >  8 & 2005-05-16 & -3.08 \\
> >> >  9 & 2005-06-17 & -1.70 \\
> >> >  10 & 2005-07-17 & -3.44 \\
> >> >  11 & 2005-08-07 & -2.30 \\
> >> >  12 & 2005-08-10 & -1.09 \\
> >> >  13 & 2005-08-24 & -1.82 \\
> >> >  14 & 2005-09-13 & -4.58 \\
> >> >  15 & 2005-09-15 & -3.97 \\.
> >> >
> >> >It has truncated the long decimal places. Since it is not want I
> >want,
> >> >I
> >> >have to copy from the original table and place into xtable.
> >> >
> >> >Can you please tell me how to customize the xtable so that I will be
> >> >responsible for the number of decimal places it displays.
> >> >
> >> >Many thanks for your precious time.
> >> >
> >> >Warmest regards
> >> >Ogbos
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Sep 18 09:36:51 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 18 Sep 2018 00:36:51 -0700
Subject: [R] Open netcdf file in linux
In-Reply-To: <CAN5afy8A8uNCCMHKU8dd8fkxczoDuoEx4AH94ScMF=4WtcJhQg@mail.gmail.com>
References: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>
 <16A5250F-1718-4D98-86D8-D5813C24D562@dcn.davis.ca.us>
 <CAN5afy8A8uNCCMHKU8dd8fkxczoDuoEx4AH94ScMF=4WtcJhQg@mail.gmail.com>
Message-ID: <F4222F62-5F35-41ED-AE0F-B7B87F5E54BF@dcn.davis.ca.us>

I find your response confusing still... did you now no longer need help?

If you are still puzzled, then what does 

file.info("file.nc")

return?

Do you see that file in your current directory via your operating system?

On September 17, 2018 11:53:22 PM PDT, lily li <chocold12 at gmail.com> wrote:
>Thanks, you are right that the file path is not correct. I just typed:
>nc_open("file.nc"), and it gave the error above.
>
>On Tue, Sep 18, 2018 at 1:33 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> I really don't know how you expect an answer when you don't show what
>you
>> did or pointed us to an example of a file that yields this error. My
>best
>> blind guess is that you have not given the name of an ncdf file to
>the
>> function.
>>
>> On September 17, 2018 9:44:45 PM PDT, lily li <chocold12 at gmail.com>
>wrote:
>> >Hi R users,
>> >
>> >I have installed ncdf4 package in R from the linux terminal, but
>have
>> >met
>> >this problem when using nc_open to open a .nc file. What is the
>> >problem?
>> >Any help would be appreciated.
>> >
>> >Error in R_nc4_open: Is a directory
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Sep 18 10:04:35 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 18 Sep 2018 01:04:35 -0700
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <SN4PR0201MB340523E42114316FC94E7837F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
References: <SN4PR0201MB340568ED119F5665F16A9386F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <894A4868-409A-44DA-A8D8-2C6CE7F252A6@dcn.davis.ca.us>
 <SN4PR0201MB340523E42114316FC94E7837F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
Message-ID: <CEC78D7D-9465-4898-93DE-FD6D02C47DF0@dcn.davis.ca.us>

Seeing what you regard as a satisfactory solution, I think Bert's recommendation to create a factor was superior since it allows you to maintain consistent labeling of your clusters even as the set of clusters changes.

I also still think you are setting the stage for frequent failures of the analyses you plan to apply to these data, but that discussion is out of scope here.

On September 17, 2018 8:29:48 AM PDT, "Liu, Lei" <lei.liu at wustl.edu> wrote:
>Thanks for the help. My friend helped me and here is the solution:
>
>boot.cluster <- function(x, id){
>  boot.id <- sample(unique(id), replace=T)
>out <- lapply(1:length(boot.id),
>function(newid){cbind(x[id%in%boot.id[newid],],newid)})
>  return( do.call("rbind",out) )
>}
>
>Lei
>
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
>Sent: Monday, September 17, 2018 2:32 AM
>To: r-help at r-project.org; Liu, Lei <lei.liu at wustl.edu>;
>r-help at R-project.org
>Subject: Re: [R] bootstrap sample for clustered data
>
>You are telling us that the ID values in your data set indicate
>clusters. However you went about making that determination in the first
>place might be an obvious(?) way to do it again with your bootstrapped
>sample, ignoring the cluster assignments you have in place. This is the
>wrong place to have a discussion about which theoretical method for
>cluster identification you should use, and if you do know that then
>searching the web or using the sos package would be the appropriate way
>to find implementations of a specific clustering algorithm.
>
>I am not an ME expert, but AFAIK "complicated" analyses such as mixed
>effects models tend to have rather hefty appetites for data
>completeness, so you may have to design a special sampling plan in
>order to avoid generating data sets for which those analyses won't
>break, and you will probably need a very large data set to start with
>in order to have sufficient data in each cluster. That is, you may be
>better off keeping the original cluster identification and just
>restructuring your bootstrap sampling to sample within clusters.
>
>The R-sig-me mailing list is probably a better venue for your
>questions. 
>
>On September 16, 2018 8:22:44 PM PDT, "Liu, Lei" <lei.liu at wustl.edu>
>wrote:
>>Hi there,
>>
>>I posted this message before but there may be some confusion in my 
>>previous post. So here is a clearer version:
>>
>>I'd like to do a bootstrap sampling for clustered data. Then I will
>run 
>>some complicated models (say mixed effects models) on the bootstrapped
>
>>sample. Here id is the cluster. Note different clusters have different
>
>>number of subjects, e.g., id 2 has 2 observations, id 3 has 3 
>>observations.
>>
>>id=c(1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5) y=c(.5, .6, .4, .3, .4, 1,
>.9, 
>>1, .5, 2, 2.2, 3) x=c(0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1 )
>>
>>xx=data.frame(id, x, y)
>>
>>boot.cluster <- function(x, id){
>>
>>  boot.id <- sample(unique(id), replace=T)  out <- lapply(boot.id, 
>> function(i) x[id%in%i,])
>>
>>  return( do.call("rbind",out) )
>>
>>}
>>
>>boot.xx=boot.cluster(xx, xx$id)
>>
>>Here is the generated boot.xx dataset:
>>
>>   id x y
>>   3 0 0.4
>>   3 0 1.0
>>   3 0 0.9
>>   1 0 0.5
>>   1 0 0.6
>>   5 1 2.2
>>   5 1 3.0
>>   2 1 0.4
>>   2 1 0.3
>>   1 0 0.5
>>   1 0 0.6
>>
>>You can see that some clusters (ids) appears multiple times (e.g., id
>1 
>>appears in two places - 4 rows), since bootstrap does a sample with 
>>replacement, we could have the same cluster multiple times. Thus, we 
>>cannot do a mixed effects model using this data, as we should assume 
>>all the clusters are different in this new data. Instead, I will 
>>reorganize the data as below (id is reordered from the above boot.xx 
>>data). This is the step I need help:
>>
>>  id x  y
>>   1 0 0.4
>>   1 0 1.0
>>   1 0 0.9
>>   2 0 0.5
>>   2 0 0.6
>>   3 1 2.2
>>   3 1 3.0
>>   4 1 0.4
>>   4 1 0.3
>>   5 0 0.5
>>   5 0 0.6
>>
>>Can someone help me with it? Thanks!
>>
>>Lei Liu
>>Professor of Biostatistics
>>Washington University in St. Louis
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From ruipb@rr@d@@ @ending from @@po@pt  Tue Sep 18 12:42:30 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Tue, 18 Sep 2018 11:42:30 +0100
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
 <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
Message-ID: <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>

Hello,

R 3.4.0 was released 2017-04-21 09:14 and R 3.4.4 2018-03-15 09:04. This 
is before the release of Ubuntu 18.04 LTS so that version of Ubuntu was 
not supported by any sub-version of R 3.4.

At least this is how I understand it. If you want to give R 3.4/Ubuntu 
18.04 a try, you can download older versions of R from CRAN and install 
them.

Do you have any practical reason for asking this?

Rui Barradas

?s 08:24 de 18/09/2018, Ashim Kapoor escreveu:
> Dear Rui,
> 
> I am a little confused.
> 
> See this ---> : R 3.4 packages for Ubuntu on i386 and amd64 are 
> available for all stable Desktop releases of Ubuntu prior to Bionic 
> Beaver (18.04) until their official end of life date. However, only the 
> latest Long Term Support (LTS) release is fully supported. As of June 
> 11, 2018 the supported releases are Artful Aardvark (17.10), Xenial 
> Xerus (16.04; LTS), and Trusty Tahr (14.04; LTS).
> 
> Bionic Beaver ( Ubuntu 18.04 ) is NOT in the list of supported releases 
> for R 3.4? What does this mean ? Can you please clarify ?
> 
> Many thanks,
> Ashim
> 
> On Tue, Sep 18, 2018 at 11:49 AM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     I am not completely sure but I think I installed Ubuntu 18.04 LTS first
>     and R 3.5 days later, so yes, if I'm right it is possible to run R 3.4
>     on 18.04.
> 
>     (You ask whether we can *install* R 3.4 on Ubuntu 18.04.1, I'm
>     saying it
>     can be *run* on Ubuntu 18.04.1.)
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
> 
>     ?s 06:51 de 18/09/2018, Ashim Kapoor escreveu:
>      > Dear All,
>      >
>      > I was reading this page --->
>      > https://cran.r-project.org/bin/linux/ubuntu/README.html
>      >
>      > It says: R 3.4 packages for Ubuntu on i386 and amd64 are
>     available for all
>      > stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04)
>     until
>      > their official end of life date.
>      >
>      > The page also shows how to install R 3.5 on Ubuntu 18.04.1
>      >
>      > My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we only
>      > install R 3.5 ?
>      >
>      > Many thanks,
>      > Ashim
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From @@himk@poor @ending from gm@il@com  Tue Sep 18 12:45:56 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Tue, 18 Sep 2018 16:15:56 +0530
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
 <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
 <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>
Message-ID: <CAC8=1eoiB+mzu8mWO9ZmxRYnWOZD3VJojqvcPH_HOfdt+=OUeQ@mail.gmail.com>

Dear Rui,

I tried R 3.4.4 on Ubuntu 18.04.1. It runs FINE except for an inhouse
package created by us. That is why I asked.

Best,
Ashim

On Tue, Sep 18, 2018 at 4:12 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> R 3.4.0 was released 2017-04-21 09:14 and R 3.4.4 2018-03-15 09:04. This
> is before the release of Ubuntu 18.04 LTS so that version of Ubuntu was
> not supported by any sub-version of R 3.4.
>
> At least this is how I understand it. If you want to give R 3.4/Ubuntu
> 18.04 a try, you can download older versions of R from CRAN and install
> them.
>
> Do you have any practical reason for asking this?
>
> Rui Barradas
>
> ?s 08:24 de 18/09/2018, Ashim Kapoor escreveu:
> > Dear Rui,
> >
> > I am a little confused.
> >
> > See this ---> : R 3.4 packages for Ubuntu on i386 and amd64 are
> > available for all stable Desktop releases of Ubuntu prior to Bionic
> > Beaver (18.04) until their official end of life date. However, only the
> > latest Long Term Support (LTS) release is fully supported. As of June
> > 11, 2018 the supported releases are Artful Aardvark (17.10), Xenial
> > Xerus (16.04; LTS), and Trusty Tahr (14.04; LTS).
> >
> > Bionic Beaver ( Ubuntu 18.04 ) is NOT in the list of supported releases
> > for R 3.4  What does this mean ? Can you please clarify ?
> >
> > Many thanks,
> > Ashim
> >
> > On Tue, Sep 18, 2018 at 11:49 AM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     I am not completely sure but I think I installed Ubuntu 18.04 LTS
> first
> >     and R 3.5 days later, so yes, if I'm right it is possible to run R
> 3.4
> >     on 18.04.
> >
> >     (You ask whether we can *install* R 3.4 on Ubuntu 18.04.1, I'm
> >     saying it
> >     can be *run* on Ubuntu 18.04.1.)
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >
> >     ?s 06:51 de 18/09/2018, Ashim Kapoor escreveu:
> >      > Dear All,
> >      >
> >      > I was reading this page --->
> >      > https://cran.r-project.org/bin/linux/ubuntu/README.html
> >      >
> >      > It says: R 3.4 packages for Ubuntu on i386 and amd64 are
> >     available for all
> >      > stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04)
> >     until
> >      > their official end of life date.
> >      >
> >      > The page also shows how to install R 3.5 on Ubuntu 18.04.1
> >      >
> >      > My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we
> only
> >      > install R 3.5 ?
> >      >
> >      > Many thanks,
> >      > Ashim
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >      > and provide commented, minimal, self-contained, reproducible code.
> >      >
> >
>

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Tue Sep 18 12:49:35 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Tue, 18 Sep 2018 11:49:35 +0100
Subject: [R] 
 =?utf-8?q?How_to_troubleshoot_error_=E2=80=9Ccannot_coerce_c?=
 =?utf-8?b?bGFzcyDigJ3igJxncm91cOKAneKAnCB0byBhIGRhdGEuZnJhbWXigJ0/?=
In-Reply-To: <CY4PR13MB0966DE9F77B10894B45F0EA3831D0@CY4PR13MB0966.namprd13.prod.outlook.com>
References: <CY4PR13MB0966DE9F77B10894B45F0EA3831D0@CY4PR13MB0966.namprd13.prod.outlook.com>
Message-ID: <366a886a-c183-d114-7b83-7a80f88fee66@sapo.pt>

Hello,

This is cross-posted from StackOverflow em Portugu?s [1].
Cross-posting is not well seen and you should wait for a while for an 
answer given where you have you original question before posting 
somewhere else.

[1] 
https://pt.stackoverflow.com/questions/330200/como-solucionar-erro-cannot-coerce-class-group-to-a-data-frame

Note: I will try to answer to it, if I have the time, in SOpt. This does 
not mean that you will not get other answers, for instance in R-Help.

Rui Barradas


?s 03:34 de 18/09/2018, Fabiano Fran?a escreveu:
> Dear Volunteers,
> When running the scriptbelow, specifically in the part of reproduction of the data.framesreturned the error:
> 
> Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) : cannot coerce class ""group"" to a data.frame
> 
> I searched the internet and could not reproduce the suggestions for my case, does anyone tell me a way?
> 
> setwd("https://drive.google.com/open?id=1FDMZfWrEjsvleVdNOUiPh8REGjvQHKQx")
> rend <- read.table('IVCM.txt', header = TRUE, sep="\t")
> rend <- transform(rend, Fungicidas=factor(Fungicidas), Doses=factor(Doses), Rep=factor(Rep))
> str(rend)#---------------------------------------------------------------------------# unfolding the interaction in Tukey tests
> 
> require(agricolae)
> require(plyr)
> 
> KinA <- sapply(levels(rend$Doses), simplify=FALSE,
>                 function(Doses){
>                   with(subset(rend, Doses==Doses),
>                        HSD.test(IVCM, Fungicidas,
>                                 DFerror=df.residual(m0),
>                                 MSerror=deviance(m0)/df.residual(m0)))
>                 })
> 
> KinA <- llply(KinA, NULL)
> KinA$M <- gsub(" ", "", KinA$M, fixed=TRUE)
> KinA$trt <- as.factor(as.numeric(as.character(KinA$trt)))
> str(KinA)
> 
> AinK <- sapply(levels(rend$Fungicidas), simplify=FALSE,
>                 function(Fungicidas){
>                   with(subset(rend, Fungicidas==Fungicidas),
>                        HSD.test(IVCM, Doses,
>                                 DFerror=df.residual(m0),
>                                 MSerror=deviance(m0)/df.residual(m0)))
>                 })
> 
> AinK <- llply(AinK, NULL)
> AinK$M <- toupper(gsub(" ", "", AinK$M, fixed=TRUE))
> AinK$trt <- as.factor(as.numeric(as.character(AinK$trt)))
> str(AinK)
> 
> Many thanks
> 
> Regards,
> 
> Fabiano Fran?a da Silva
> Doutorando em Fitotecnia - ESALQ/USP
> MSc Fitotecnia - UFLA
> Eng?. Agr?nomo - UFLA
> (35) 9 9155-5443 TIM
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From i@t@z@hn @ending from gm@il@com  Tue Sep 18 15:08:18 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Tue, 18 Sep 2018 09:08:18 -0400
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <CAC8=1eoiB+mzu8mWO9ZmxRYnWOZD3VJojqvcPH_HOfdt+=OUeQ@mail.gmail.com>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
 <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
 <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>
 <CAC8=1eoiB+mzu8mWO9ZmxRYnWOZD3VJojqvcPH_HOfdt+=OUeQ@mail.gmail.com>
Message-ID: <CA+vqiLHkJLonpbG6uC8+ZtZZgLQ2LaK8ejVqP3JcuaqtOKwh8g@mail.gmail.com>

This is really the wrong place for this discussion. Please post ubuntu
specific questions to r-sig-debian.

Best,
Ista
On Tue, Sep 18, 2018 at 6:52 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> Dear Rui,
>
> I tried R 3.4.4 on Ubuntu 18.04.1. It runs FINE except for an inhouse
> package created by us. That is why I asked.
>
> Best,
> Ashim
>
> On Tue, Sep 18, 2018 at 4:12 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> > Hello,
> >
> > R 3.4.0 was released 2017-04-21 09:14 and R 3.4.4 2018-03-15 09:04. This
> > is before the release of Ubuntu 18.04 LTS so that version of Ubuntu was
> > not supported by any sub-version of R 3.4.
> >
> > At least this is how I understand it. If you want to give R 3.4/Ubuntu
> > 18.04 a try, you can download older versions of R from CRAN and install
> > them.
> >
> > Do you have any practical reason for asking this?
> >
> > Rui Barradas
> >
> > ?s 08:24 de 18/09/2018, Ashim Kapoor escreveu:
> > > Dear Rui,
> > >
> > > I am a little confused.
> > >
> > > See this ---> : R 3.4 packages for Ubuntu on i386 and amd64 are
> > > available for all stable Desktop releases of Ubuntu prior to Bionic
> > > Beaver (18.04) until their official end of life date. However, only the
> > > latest Long Term Support (LTS) release is fully supported. As of June
> > > 11, 2018 the supported releases are Artful Aardvark (17.10), Xenial
> > > Xerus (16.04; LTS), and Trusty Tahr (14.04; LTS).
> > >
> > > Bionic Beaver ( Ubuntu 18.04 ) is NOT in the list of supported releases
> > > for R 3.4  What does this mean ? Can you please clarify ?
> > >
> > > Many thanks,
> > > Ashim
> > >
> > > On Tue, Sep 18, 2018 at 11:49 AM Rui Barradas <ruipbarradas at sapo.pt
> > > <mailto:ruipbarradas at sapo.pt>> wrote:
> > >
> > >     Hello,
> > >
> > >     I am not completely sure but I think I installed Ubuntu 18.04 LTS
> > first
> > >     and R 3.5 days later, so yes, if I'm right it is possible to run R
> > 3.4
> > >     on 18.04.
> > >
> > >     (You ask whether we can *install* R 3.4 on Ubuntu 18.04.1, I'm
> > >     saying it
> > >     can be *run* on Ubuntu 18.04.1.)
> > >
> > >     Hope this helps,
> > >
> > >     Rui Barradas
> > >
> > >
> > >     ?s 06:51 de 18/09/2018, Ashim Kapoor escreveu:
> > >      > Dear All,
> > >      >
> > >      > I was reading this page --->
> > >      > https://cran.r-project.org/bin/linux/ubuntu/README.html
> > >      >
> > >      > It says: R 3.4 packages for Ubuntu on i386 and amd64 are
> > >     available for all
> > >      > stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04)
> > >     until
> > >      > their official end of life date.
> > >      >
> > >      > The page also shows how to install R 3.5 on Ubuntu 18.04.1
> > >      >
> > >      > My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we
> > only
> > >      > install R 3.5 ?
> > >      >
> > >      > Many thanks,
> > >      > Ashim
> > >      >
> > >      >       [[alternative HTML version deleted]]
> > >      >
> > >      > ______________________________________________
> > >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> > >     -- To UNSUBSCRIBE and more, see
> > >      > https://stat.ethz.ch/mailman/listinfo/r-help
> > >      > PLEASE do read the posting guide
> > >     http://www.R-project.org/posting-guide.html
> > >      > and provide commented, minimal, self-contained, reproducible code.
> > >      >
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @@r@h@go@lee @ending from gm@il@com  Tue Sep 18 15:25:35 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Tue, 18 Sep 2018 09:25:35 -0400
Subject: [R] Set the same colour range for 2 != rasters
In-Reply-To: <CAPL76w89=D1YRax-gN_ZRoeJfwspHcS5duMe8zxqsoc5S1rnrQ@mail.gmail.com>
References: <CAPL76w89=D1YRax-gN_ZRoeJfwspHcS5duMe8zxqsoc5S1rnrQ@mail.gmail.com>
Message-ID: <CAM_vjuk1bJPD9u9MCGfa6SHXvAJT_i3uZSJtv6K8-pzO71CeaA@mail.gmail.com>

Hi Jackson,

I think you would have gotten a faster response if you'd provided a
reproducible example. I at least let this message sit until I had time
to figure out what you were doing. If you have more raster questions,
there's also a r-sig-geo mailing list that would be more appropriate.

Nonetheless, you seem to be overthinking the problem. Is this what you need:

library(raster)

r1 <- matrix(sample(seq( 3, 20), size=25, replace=TRUE), 5, 5)
r2 <- matrix(sample(seq(15, 31), size=25, replace=TRUE), 5, 5)

r1 <- raster(r1)
r2 <- raster(r2)

cols <-colorRampPalette(c("royalblue","springgreen","yellow","orange","red"))(29)

# plot two rasters with different ranges but the same colors
par(mfrow=c(1, 2))
plot(r1, col=cols, zlim=c(3, 31))
plot(r2, col=cols, zlim=c(3, 31))

Sarah

On Sun, Sep 16, 2018 at 10:59 PM Jackson Rodrigues
<jacksonmrodrigues at gmail.com> wrote:
>
> Dear all,
>
> My name is Jackson.
> I am trying to set the same colour range for 2 rasters (max and min
> temperatures). Both rasters have different numerical ranges but the same
> dimensions
> dimensions  : 4346, 4365, 18970290, 1  (nrow, ncol, ncell, nlayers)
>
> The lowest value is 3 and the highest is 31. So my colour palette should
> range from 3 to 31 and be useful for both temperatures
>
> However I got a message saying that S4 and vector cannot be coerced.
> So far I understand why it is not working but how to fix it?
>
> A few lines from my code.
>
> ####
> cols<-colorRampPalette(c("royalblue","springgreen","yellow","orange","red"))(29)
>
> Temp.interval = seq(from=3, to=31)
>
> # creating colour vectors
> col1 <- cols[findInterval(TMin_masked$prj, vec =  Temp.interval  )]
>
> Error in as.double(x) :
>   cannot coerce type 'S4' to vector of type 'double'
> ####
>
> Thank you all!
>
> Best regards.
>
> Jackson
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From benoit@v@ill@nt @ending from no-log@org  Tue Sep 18 15:38:15 2018
From: benoit@v@ill@nt @ending from no-log@org (Benoit Vaillant)
Date: Tue, 18 Sep 2018 15:38:15 +0200
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <CA+vqiLHkJLonpbG6uC8+ZtZZgLQ2LaK8ejVqP3JcuaqtOKwh8g@mail.gmail.com>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
 <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
 <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>
 <CAC8=1eoiB+mzu8mWO9ZmxRYnWOZD3VJojqvcPH_HOfdt+=OUeQ@mail.gmail.com>
 <CA+vqiLHkJLonpbG6uC8+ZtZZgLQ2LaK8ejVqP3JcuaqtOKwh8g@mail.gmail.com>
Message-ID: <20180918133815.sgl7hqg22v5u4vxt@auroras.fr>

Hello,

On Tue, Sep 18, 2018 at 09:08:18AM -0400, Ista Zahn wrote:
> This is really the wrong place for this discussion. Please post ubuntu
> specific questions to r-sig-debian.

While i guess your asking to get on to r-sig-debian is a true start,
the package that seems to be causing troubles is "in house".

No matter the mailing-list the user should end up, the appropriate
consideration should be to get back at who made that package.

Cheers, :)

-- 
Beno?t Vaillant

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 866 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180918/33b7d99c/attachment.sig>

From r@turner @ending from @uckl@nd@@c@nz  Tue Sep 18 22:35:05 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Wed, 19 Sep 2018 08:35:05 +1200
Subject: [R] 
 [FORGED]  Unable to update R 3.4 to R 3.5 in Ubuntu 18.04 LTS
In-Reply-To: <CAMo+egkiwPriFXCbSvMH3234BEitjBMxuwmYBC4gEjPdzUqA8g@mail.gmail.com>
References: <CAMo+egkiwPriFXCbSvMH3234BEitjBMxuwmYBC4gEjPdzUqA8g@mail.gmail.com>
Message-ID: <a0bb17da-92a6-dca6-0e92-11f390989efc@auckland.ac.nz>

On 09/18/2018 04:14 AM, RUPJYOTI DAS wrote:
> Dear All,
> I am using R to carry out RNA-Seq workflow in my standalone machine which
> needs the latest R version >=3.5. I was trying to update firstly removing
> the R 3.4 and reinstalling from scratch again the latest version. Can
> anybody just guide me how to carry out the process as I am getting only R
> 3.4 again and again.
> Also when I remove the
> *deb ... bionic-cran35 (mirror for R cran )*
> 
> from the* source.list* file (opened by* sudo gedit /etc/apt/sources.list*)
> the command *sudo apt-get update* works fine which does not upgrade the R
> 3.4 to R 3.5.1.
> Adding the line
> *deb ... bionic-cran35/ *
> gives the attached error log*. **Please find the attached file and  do
> check.*
> 
> Any answers and suggestions will be of immense help!
> 
> Thanking you!

You may find the following link helpful.  I did.

https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-18-04-quickstart

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @@himk@poor @ending from gm@il@com  Wed Sep 19 05:42:58 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Wed, 19 Sep 2018 09:12:58 +0530
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <20180918133815.sgl7hqg22v5u4vxt@auroras.fr>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
 <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
 <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>
 <CAC8=1eoiB+mzu8mWO9ZmxRYnWOZD3VJojqvcPH_HOfdt+=OUeQ@mail.gmail.com>
 <CA+vqiLHkJLonpbG6uC8+ZtZZgLQ2LaK8ejVqP3JcuaqtOKwh8g@mail.gmail.com>
 <20180918133815.sgl7hqg22v5u4vxt@auroras.fr>
Message-ID: <CAC8=1erW2XVM605E9e4Bqzf5rK7JPi5VEuJk1XhQ7MUevUxzXw@mail.gmail.com>

Dear All,

Okay and thank you.

Best Regards,
Ashim

On Wed, Sep 19, 2018 at 3:32 AM Benoit Vaillant <benoit.vaillant at no-log.org>
wrote:

> Hello,
>
> On Tue, Sep 18, 2018 at 09:08:18AM -0400, Ista Zahn wrote:
> > This is really the wrong place for this discussion. Please post ubuntu
> > specific questions to r-sig-debian.
>
> While i guess your asking to get on to r-sig-debian is a true start,
> the package that seems to be causing troubles is "in house".
>
> No matter the mailing-list the user should end up, the appropriate
> consideration should be to get back at who made that package.
>
> Cheers, :)
>
> --
> Beno?t Vaillant
>

	[[alternative HTML version deleted]]


From ph@edru@v @ending from gm@il@com  Wed Sep 19 13:00:23 2018
From: ph@edru@v @ending from gm@il@com (Andrew)
Date: Wed, 19 Sep 2018 12:00:23 +0100
Subject: [R] Smallest Space Analysis (SSA) in R
Message-ID: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>

Hi

As part of my forensics psych course, we have been introduced to 
Guttman's smallest space analysis (SSA). I want to explore this approach 
using R, but despite finding some queries on the web about this same 
thing, have yet to find any answers. The MASS package doesn't seem to do 
the job, and the only thing I have been able to find is some proprietary 
software HUDAP? (Hebrew University Data Analysis Package) which may/ not 
be compatible with R (or GNU/Linux for that matter).

Does anyone have information on how to do SSA using R?

Many thanks

Andrew


	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Wed Sep 19 14:37:29 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 19 Sep 2018 12:37:29 +0000
Subject: [R] New to R
In-Reply-To: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
References: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
Message-ID: <BN7PR02MB5073092B6387599CE474622CEA1C0@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello Jim, as new use"R" myself, 1.5 years I HIGHLY recommend emersion.

Subscribe to :
https://www.r-bloggers.com/

https://stackoverflow.com

http://blog.revolutionanalytics.com/

Anything Hadley Wickam, he has several free e-books.

Depending on  r-help (r-help at r-project.org<mailto:r-help at r-project.org>) is a tough way to go, they can be hard on new users without the formality of:
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>

Be prepared for partial suggestions that depend on your further research, trial and error!

WHP



From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Blackburn
Sent: Friday, September 14, 2018 2:00 PM
To: r-help at r-project.org
Subject: [R] New to R

I am newly subscribed to r-project.


I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)



I am attempting to download tickers as a time series. I can successfully create RDA files but I want to convert them to CVS. Following is the code I have created so far.



if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')

library(BatchGetSymbols)

tickers <- c('SPY','VCR', 'RPG')

first.date<http://first.date> <- Sys.Date()-365

last.date<http://last.date> <- Sys.Date<http://Sys.Date>

l.out <- BatchGetSymbols(tickers = tickers,

first.date<http://first.date> = first.date<http://first.date>,

last.date<http://last.date> = last.date<http://last.date>,

cache.folder = file.path("c://Users/Owner/Documents/R",

+ 'BGS_Cache') )

print(l.out$df.control)

print(l.out$df.tickers)







I can print(l.out) and see that it contains all the data, but it is not a data.frame



Can anyone help with creating a data.frame and then converting to CSV?



Any help is GREATLY appreciated!



Thanks



Jim


Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986<https://go.microsoft.com/fwlink/?LinkId=550986>> for Windows 10


[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From reichm@nj @ending from @bcglob@l@net  Wed Sep 19 15:07:41 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Wed, 19 Sep 2018 08:07:41 -0500
Subject: [R] frequent-pattern tree
Message-ID: <000a01d45019$c043a490$40caedb0$@sbcglobal.net>

r-help

 

Is there a r-package that will construct a frequent-pattern (FP) tree ?

 

Jeff Reichman


	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Wed Sep 19 15:18:02 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Wed, 19 Sep 2018 09:18:02 -0400
Subject: [R] frequent-pattern tree
In-Reply-To: <000a01d45019$c043a490$40caedb0$@sbcglobal.net>
References: <000a01d45019$c043a490$40caedb0$@sbcglobal.net>
Message-ID: <CAM_vjukY2HajzUEdbjrs2f5YjB6Vxy1L1pDKPWbcbFns1ZyK=Q@mail.gmail.com>

A quick search on the incredibly useful rseek.org turns up a couple of
possibilities, including the rCBA package, and

https://stackoverflow.com/questions/38240190/frequent-pattern-growth-in-r-or-python

This is out of my area, but the searching suggests that FP tree and FP
growth are closely linked algorithms, at least.

With more knowledgeable search terms you can likely do a better job on
rseek.org yourself.

Sarah
On Wed, Sep 19, 2018 at 9:08 AM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>
> r-help
>
>
>
> Is there a r-package that will construct a frequent-pattern (FP) tree ?
>
>
>
> Jeff Reichman
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From giftedlife2014 @ending from gm@il@com  Wed Sep 19 16:55:04 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 19 Sep 2018 15:55:04 +0100
Subject: [R] as.Date and ylim in empty plot
Message-ID: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>

Dear Experts,
I generated the plot attached. Every other thing is OK except the black
horizontal lines which should appear like points or dots as the coloured
ones. I can't understand why.

I tried to change it to look like dots by calling empty plots so that I
will add them as points.

Since I have a range of date that can fall any where within 2005, I tried:

plot(1, type="n", xlab="", ylab="",
xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")), ylim=c(-.5, -10))

ylim worked fine but xlim instead of appearing like date as indicated on
the x-axes of the attached plot, translated to ordinary numbers (12800,
12900,13000, 13100).

All the data is of the same format:
2005-01-04 -2.76105935648091
2005-01-19 -9.60813496025994
2005-01-22 -7.92101965866777
2005-02-19 -1.61308152604905
2005-02-24 -1.51497015807712
2005-05-09 -2.06465797304654
2005-05-11 -1.14840389007051
2005-05-16 -3.85281900888504
2005-06-13 -1.18659683796617
2005-06-17 -3.48787712566258
2005-06-22 -1.14223758296308
2005-07-18 -4.96013018907366
2005-08-03 -1.24313324914368
2005-08-07 -2.96672894841722
2005-08-10 -1.11868063781156
2005-08-25 -1.46453734930983
2005-09-13 -8.00895215754776
2005-09-15 -6.63439065989452
2005-10-13 -2.25054996925846
2005-12-15 -1.08933890547705

Thank you so much for your input.

Best regards
Ogbos

From m@cqueen1 @ending from llnl@gov  Thu Sep 20 00:20:53 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Wed, 19 Sep 2018 22:20:53 +0000
Subject: [R] as.Date and ylim in empty plot
In-Reply-To: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
References: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
Message-ID: <463D5957-3728-4AC6-A83E-FF2F1662052F@llnl.gov>

I'm a little surprised at some of what happens, but you can get date labels on the x axis like this:

drng <- as.Date( c('2005-1-1' , '2005-12-31') )
plot(1, type="n", xlab="", ylab="", xaxt='n', xlim=drng, ylim=c(-.5, -10))
axis(1, at= pretty(drng), lab=format(pretty(drng)))

and if you prefer some other date format, specify it in the call to format()

Did you intend to reverse the direction of your  y axis?

-Don
--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/19/18, 7:55 AM, "R-help on behalf of Ogbos Okike" <r-help-bounces at r-project.org on behalf of giftedlife2014 at gmail.com> wrote:

    Dear Experts,
    I generated the plot attached. Every other thing is OK except the black
    horizontal lines which should appear like points or dots as the coloured
    ones. I can't understand why.
    
    I tried to change it to look like dots by calling empty plots so that I
    will add them as points.
    
    Since I have a range of date that can fall any where within 2005, I tried:
    
    plot(1, type="n", xlab="", ylab="",
    xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")), ylim=c(-.5, -10))
    
    ylim worked fine but xlim instead of appearing like date as indicated on
    the x-axes of the attached plot, translated to ordinary numbers (12800,
    12900,13000, 13100).
    
    All the data is of the same format:
    2005-01-04 -2.76105935648091
    2005-01-19 -9.60813496025994
    2005-01-22 -7.92101965866777
    2005-02-19 -1.61308152604905
    2005-02-24 -1.51497015807712
    2005-05-09 -2.06465797304654
    2005-05-11 -1.14840389007051
    2005-05-16 -3.85281900888504
    2005-06-13 -1.18659683796617
    2005-06-17 -3.48787712566258
    2005-06-22 -1.14223758296308
    2005-07-18 -4.96013018907366
    2005-08-03 -1.24313324914368
    2005-08-07 -2.96672894841722
    2005-08-10 -1.11868063781156
    2005-08-25 -1.46453734930983
    2005-09-13 -8.00895215754776
    2005-09-15 -6.63439065989452
    2005-10-13 -2.25054996925846
    2005-12-15 -1.08933890547705
    
    Thank you so much for your input.
    
    Best regards
    Ogbos
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From dwin@emiu@ @ending from comc@@t@net  Thu Sep 20 00:34:45 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Wed, 19 Sep 2018 15:34:45 -0700
Subject: [R] as.Date and ylim in empty plot
In-Reply-To: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
References: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
Message-ID: <431EE567-5F41-4638-B31A-F6E7E3E95782@comcast.net>


> On Sep 19, 2018, at 7:55 AM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Dear Experts,
> I generated the plot attached. Every other thing is OK except the black
> horizontal lines which should appear like points or dots as the coloured
> ones. I can't understand why.
> 
> I tried to change it to look like dots by calling empty plots so that I
> will add them as points.
> 
> Since I have a range of date that can fall any where within 2005, I tried:
> 
> plot(1, type="n", xlab="", ylab="",
> xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")), ylim=c(-.5, -10))
> 
> ylim worked fine but xlim instead of appearing like date as indicated on
> the x-axes of the attached plot, translated to ordinary numbers (12800,
> 12900,13000, 13100).
> 
> All the data is of the same format:
> 2005-01-04 -2.76105935648091
> 2005-01-19 -9.60813496025994
> 2005-01-22 -7.92101965866777
> 2005-02-19 -1.61308152604905
> 2005-02-24 -1.51497015807712
> 2005-05-09 -2.06465797304654
> 2005-05-11 -1.14840389007051
> 2005-05-16 -3.85281900888504
> 2005-06-13 -1.18659683796617
> 2005-06-17 -3.48787712566258
> 2005-06-22 -1.14223758296308
> 2005-07-18 -4.96013018907366
> 2005-08-03 -1.24313324914368
> 2005-08-07 -2.96672894841722
> 2005-08-10 -1.11868063781156
> 2005-08-25 -1.46453734930983
> 2005-09-13 -8.00895215754776
> 2005-09-15 -6.63439065989452
> 2005-10-13 -2.25054996925846
> 2005-12-15 -1.08933890547705

You did not succeed in creating a plot that the rhelp mail server would accept. My guess is that the first column is a factor variable and that you did not use colClasses when doing your data input.

dd <- read.table(text="2005-01-04 -2.76105935648091
2005-01-19 -9.60813496025994
2005-01-22 -7.92101965866777
2005-02-19 -1.61308152604905
2005-02-24 -1.51497015807712
2005-05-09 -2.06465797304654
2005-05-11 -1.14840389007051
2005-05-16 -3.85281900888504
2005-06-13 -1.18659683796617
2005-06-17 -3.48787712566258
2005-06-22 -1.14223758296308
2005-07-18 -4.96013018907366
2005-08-03 -1.24313324914368
2005-08-07 -2.96672894841722
2005-08-10 -1.11868063781156
2005-08-25 -1.46453734930983
2005-09-13 -8.00895215754776
2005-09-15 -6.63439065989452
2005-10-13 -2.25054996925846
2005-12-15 -1.08933890547705", colClasses=c("Date","numeric")
)


No problems with:

 plot(dd[[1]], dd[[2]], xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")))

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 4727 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180919/0a6f7326/attachment.pdf>

-------------- next part --------------


(Not a particularly good test of the use of an xlim argument since nothing was excluded.)

PDF's are accepted. PNGs are not.

-- 
David.
> 
> Thank you so much for your input.
> 
> Best regards
> Ogbos
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law






From giftedlife2014 @ending from gm@il@com  Thu Sep 20 07:48:55 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Thu, 20 Sep 2018 06:48:55 +0100
Subject: [R] as.Date and ylim in empty plot: RESOLVED
In-Reply-To: <431EE567-5F41-4638-B31A-F6E7E3E95782@comcast.net>
References: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
 <431EE567-5F41-4638-B31A-F6E7E3E95782@comcast.net>
Message-ID: <CAC8ss31dX7fnhWUXv97z_Fjd4pk8jmfqP1=Gc8ijUvYf1WwvpA@mail.gmail.com>

Hi David,
That's it!!! The outcome is attached.

Many thanks please.

Best
Ogbos

On Wed, Sep 19, 2018 at 11:34 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 19, 2018, at 7:55 AM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >
> > Dear Experts,
> > I generated the plot attached. Every other thing is OK except the black
> > horizontal lines which should appear like points or dots as the coloured
> > ones. I can't understand why.
> >
> > I tried to change it to look like dots by calling empty plots so that I
> > will add them as points.
> >
> > Since I have a range of date that can fall any where within 2005, I
> tried:
> >
> > plot(1, type="n", xlab="", ylab="",
> > xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")), ylim=c(-.5, -10))
> >
> > ylim worked fine but xlim instead of appearing like date as indicated on
> > the x-axes of the attached plot, translated to ordinary numbers (12800,
> > 12900,13000, 13100).
> >
> > All the data is of the same format:
> > 2005-01-04 -2.76105935648091
> > 2005-01-19 -9.60813496025994
> > 2005-01-22 -7.92101965866777
> > 2005-02-19 -1.61308152604905
> > 2005-02-24 -1.51497015807712
> > 2005-05-09 -2.06465797304654
> > 2005-05-11 -1.14840389007051
> > 2005-05-16 -3.85281900888504
> > 2005-06-13 -1.18659683796617
> > 2005-06-17 -3.48787712566258
> > 2005-06-22 -1.14223758296308
> > 2005-07-18 -4.96013018907366
> > 2005-08-03 -1.24313324914368
> > 2005-08-07 -2.96672894841722
> > 2005-08-10 -1.11868063781156
> > 2005-08-25 -1.46453734930983
> > 2005-09-13 -8.00895215754776
> > 2005-09-15 -6.63439065989452
> > 2005-10-13 -2.25054996925846
> > 2005-12-15 -1.08933890547705
>
> You did not succeed in creating a plot that the rhelp mail server would
> accept. My guess is that the first column is a factor variable and that you
> did not use colClasses when doing your data input.
>
> dd <- read.table(text="2005-01-04 -2.76105935648091
> 2005-01-19 -9.60813496025994
> 2005-01-22 -7.92101965866777
> 2005-02-19 -1.61308152604905
> 2005-02-24 -1.51497015807712
> 2005-05-09 -2.06465797304654
> 2005-05-11 -1.14840389007051
> 2005-05-16 -3.85281900888504
> 2005-06-13 -1.18659683796617
> 2005-06-17 -3.48787712566258
> 2005-06-22 -1.14223758296308
> 2005-07-18 -4.96013018907366
> 2005-08-03 -1.24313324914368
> 2005-08-07 -2.96672894841722
> 2005-08-10 -1.11868063781156
> 2005-08-25 -1.46453734930983
> 2005-09-13 -8.00895215754776
> 2005-09-15 -6.63439065989452
> 2005-10-13 -2.25054996925846
> 2005-12-15 -1.08933890547705", colClasses=c("Date","numeric")
> )
>
>
> No problems with:
>
>  plot(dd[[1]], dd[[2]],
> xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")))
>
>
> (Not a particularly good test of the use of an xlim argument since nothing
> was excluded.)
>
> PDF's are accepted. PNGs are not.
>
> --
> David.
> >
> > Thank you so much for your input.
> >
> > Best regards
> > Ogbos
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Ogbos.pdf
Type: application/pdf
Size: 5483 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180920/e97bcfc1/attachment.pdf>

From t@n@@@ @ending from gm@il@com  Thu Sep 20 09:26:12 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Thu, 20 Sep 2018 00:26:12 -0700
Subject: [R] about the series of numbers
Message-ID: <CA+JEM009nvbnNzm3twbxx+UxSTxnvH6vnYVmbs6L5RdCanTZgQ@mail.gmail.com>

Dear all,

if I may ask please a question that is likely very naive :

shall I write in R > "1:9", it will generate "1 2 3 4 5 6 7 8 9"

shall I write > "0.1:0.9", why does it generate only 0.1 ?

thank you !

-- bogdan

	[[alternative HTML version deleted]]


From @lk@uffm @ending from f@@tm@il@fm  Thu Sep 20 09:32:34 2018
From: @lk@uffm @ending from f@@tm@il@fm (Albrecht Kauffmann)
Date: Thu, 20 Sep 2018 09:32:34 +0200
Subject: [R] about the series of numbers
In-Reply-To: <CA+JEM009nvbnNzm3twbxx+UxSTxnvH6vnYVmbs6L5RdCanTZgQ@mail.gmail.com>
References: <CA+JEM009nvbnNzm3twbxx+UxSTxnvH6vnYVmbs6L5RdCanTZgQ@mail.gmail.com>
Message-ID: <1537428754.3568899.1514420408.520B336F@webmail.messagingengine.com>

Dear Bogdan,

for increments <>1, it needs "by". Try

seq(.1,.9,.1)

Best,
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Do, 20. Sep 2018, um 09:26, schrieb Bogdan Tanasa:
> Dear all,
> 
> if I may ask please a question that is likely very naive :
> 
> shall I write in R > "1:9", it will generate "1 2 3 4 5 6 7 8 9"
> 
> shall I write > "0.1:0.9", why does it generate only 0.1 ?
> 
> thank you !
> 
> -- bogdan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@pik@l @ending from prechez@@cz  Thu Sep 20 11:20:36 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 20 Sep 2018 09:20:36 +0000
Subject: [R] about the series of numbers
In-Reply-To: <CA+JEM009nvbnNzm3twbxx+UxSTxnvH6vnYVmbs6L5RdCanTZgQ@mail.gmail.com>
References: <CA+JEM009nvbnNzm3twbxx+UxSTxnvH6vnYVmbs6L5RdCanTZgQ@mail.gmail.com>
Message-ID: <e32aebcc1a124571ba495df9c451a37f@SRVEXCHCM1302.precheza.cz>

Hi

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Bogdan Tanasa
> Sent: Thursday, September 20, 2018 9:26 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] about the series of numbers
>
> Dear all,
>
> if I may ask please a question that is likely very naive :
>
> shall I write in R > "1:9", it will generate "1 2 3 4 5 6 7 8 9"
>
> shall I write > "0.1:0.9", why does it generate only 0.1 ?

Because it is said in help page!!!

"For other arguments from:to is equivalent to seq(from, to), and generates a sequence from *from* to *to* in steps of 1 or -1."

sequence from 0.1 to 0.9 in steps 1 starts at 0.1 but the second item is 1.1 which is bigger than 0.9 therefore the result is only one item 0.1.

Cheers
Petr

>
> thank you !
>
> -- bogdan
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From momtoom@x @ending from gm@il@com  Thu Sep 20 17:08:30 2018
From: momtoom@x @ending from gm@il@com (Lynette Chang)
Date: Thu, 20 Sep 2018 11:08:30 -0400
Subject: [R] How to vectorize this function
Message-ID: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>

Hello everyone,

     I?ve a function with five input argument and one output number. 
	  impVolC <- function(callM, K, T, F, r)

     I hope this function can take five vectors as input, then return one vector as output. My vectorization ran into problems with the nested if-else operation. As a result, I have to write another for loop to call this function. Can anyone suggest some methods to overcome it? I put my code below, thanks.

impVolC <- function(callM, K, T, F, r){


 if(y >= 0){
     call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
     if(callM <= call0){
       sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
     }else{
       sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
     }
 }else{
     call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
     if(callM <= call0){
       sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
     }else{
       sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
     }
 }
 sig
} 

for(i in 1:length(call)){
 sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r = r_m)  
}


From dc@rl@on @ending from t@mu@edu  Thu Sep 20 18:05:12 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Thu, 20 Sep 2018 16:05:12 +0000
Subject: [R] How to vectorize this function
In-Reply-To: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
Message-ID: <8c47b717c4b646429f29411e37c5dc98@tamu.edu>

Your function takes an argument "F" that is never used and uses an object "y" which is not defined. Give us some data to use for testing different approaches along with the answer you expect. It may be possible to use two ifelse() functions instead of the loop.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Lynette Chang
Sent: Thursday, September 20, 2018 10:09 AM
To: r-help at r-project.org
Subject: [R] How to vectorize this function

Hello everyone,

     I?ve a function with five input argument and one output number. 
	  impVolC <- function(callM, K, T, F, r)

     I hope this function can take five vectors as input, then return one vector as output. My vectorization ran into problems with the nested if-else operation. As a result, I have to write another for loop to call this function. Can anyone suggest some methods to overcome it? I put my code below, thanks.

impVolC <- function(callM, K, T, F, r){


 if(y >= 0){
     call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
     if(callM <= call0){
       sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
     }else{
       sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
     }
 }else{
     call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
     if(callM <= call0){
       sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
     }else{
       sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
     }
 }
 sig
} 

for(i in 1:length(call)){
 sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r = r_m) }

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bgunter@4567 @ending from gm@il@com  Thu Sep 20 18:42:42 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 20 Sep 2018 09:42:42 -0700
Subject: [R] How to vectorize this function
In-Reply-To: <8c47b717c4b646429f29411e37c5dc98@tamu.edu>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
 <8c47b717c4b646429f29411e37c5dc98@tamu.edu>
Message-ID: <CAGxFJbRxE+PApCwW7fb2peZZJZ9DtHCqWYV5UBMHP9nUCg6n5g@mail.gmail.com>

Also:

What package does polya() come from and "gamma" (as a numeric value)is
undefined (it is a function).


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 20, 2018 at 9:06 AM David L Carlson <dcarlson at tamu.edu> wrote:

> Your function takes an argument "F" that is never used and uses an object
> "y" which is not defined. Give us some data to use for testing different
> approaches along with the answer you expect. It may be possible to use two
> ifelse() functions instead of the loop.
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Lynette Chang
> Sent: Thursday, September 20, 2018 10:09 AM
> To: r-help at r-project.org
> Subject: [R] How to vectorize this function
>
> Hello everyone,
>
>      I?ve a function with five input argument and one output number.
>           impVolC <- function(callM, K, T, F, r)
>
>      I hope this function can take five vectors as input, then return one
> vector as output. My vectorization ran into problems with the nested
> if-else operation. As a result, I have to write another for loop to call
> this function. Can anyone suggest some methods to overcome it? I put my
> code below, thanks.
>
> impVolC <- function(callM, K, T, F, r){
>
>
>  if(y >= 0){
>      call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
>      if(callM <= call0){
>        sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>      }else{
>        sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>      }
>  }else{
>      call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
>      if(callM <= call0){
>        sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
>      }else{
>        sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>      }
>  }
>  sig
> }
>
> for(i in 1:length(call)){
>  sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r =
> r_m) }
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @bouelm@k@rim1962 @ending from gm@il@com  Thu Sep 20 19:14:41 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Thu, 20 Sep 2018 13:14:41 -0400
Subject: [R] =?utf-8?q?Make_Month_variable_be_called_=E2=80=9CMay?=
	=?utf-8?b?4oCdLOKAnEp1bmXigJ0gZXRjLiwgaW5zdGVhZCBvZiBhIG51bWVyaWMg?=
	=?utf-8?q?quantity_5=2C6=2C_etc=2E?=
Message-ID: <CAE9stmevB6+5zfMOwa-HmfEa2gn8nSbpCicXGkwDTvmC5cCRCQ@mail.gmail.com>

Dear All:

*Re:* How to make the Month variable be called ?May?,?June?, "July",
"August", "September" instead of a numeric quantity (5,6,7,8,9)


In the airquality data set, please see the code below; How to make the
Month variable be called ?May?,?June?, "July", "August", "September"
instead of a numeric quantity (5,6,7,8,9)



data(airquality)

head(airquality)


#### Making Day and Month categorical variables


airquality$Day <- factor(airquality$Day)

airquality$Month <- factor(airquality$Month)


head(airquality)


> head(airquality)
  Ozone Solar.R Wind Temp Month Day
1    41     190  7.4   67     5   1
2    36     118  8.0   72     5   2
3    12     149 12.6   74     5   3
4    18     313 11.5   62     5   4
5    NA      NA 14.3   56     5   5
6    28      NA 14.9   66     5   6
>



Thank you very much for your help in advance


with thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Sep 20 19:36:59 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 20 Sep 2018 10:36:59 -0700
Subject: [R] =?utf-8?q?Make_Month_variable_be_called_=E2=80=9CMay?=
 =?utf-8?b?4oCdLOKAnEp1bmXigJ0gZXRjLiwgaW5zdGVhZCBvZiBhIG51bWVyaWMgcXVh?=
 =?utf-8?b?bnRpdHkgNSw2LCBldGMu?=
In-Reply-To: <CAE9stmevB6+5zfMOwa-HmfEa2gn8nSbpCicXGkwDTvmC5cCRCQ@mail.gmail.com>
References: <CAE9stmevB6+5zfMOwa-HmfEa2gn8nSbpCicXGkwDTvmC5cCRCQ@mail.gmail.com>
Message-ID: <39BBA96A-667F-4CE2-A513-26816EFAA570@dcn.davis.ca.us>

airquality$Month <- factor(airquality$Month, levels=1:12, labels=month.name )

On September 20, 2018 10:14:41 AM PDT, AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com> wrote:
>Dear All:
>
>*Re:* How to make the Month variable be called ?May?,?June?, "July",
>"August", "September" instead of a numeric quantity (5,6,7,8,9)
>
>
>In the airquality data set, please see the code below; How to make the
>Month variable be called ?May?,?June?, "July", "August", "September"
>instead of a numeric quantity (5,6,7,8,9)
>
>
>
>data(airquality)
>
>head(airquality)
>
>
>#### Making Day and Month categorical variables
>
>
>airquality$Day <- factor(airquality$Day)
>
>airquality$Month <- factor(airquality$Month)
>
>
>head(airquality)
>
>
>> head(airquality)
>  Ozone Solar.R Wind Temp Month Day
>1    41     190  7.4   67     5   1
>2    36     118  8.0   72     5   2
>3    12     149 12.6   74     5   3
>4    18     313 11.5   62     5   4
>5    NA      NA 14.3   56     5   5
>6    28      NA 14.9   66     5   6
>>
>
>
>
>Thank you very much for your help in advance
>
>
>with thanks
>abou
>______________________
>
>
>*AbouEl-Makarim Aboueissa, PhD*
>
>*Professor of Statistics*
>*Graduate Coordinator*
>
>*Department of Mathematics and Statistics*
>*University of Southern Maine*
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@cqueen1 @ending from llnl@gov  Thu Sep 20 19:56:22 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 20 Sep 2018 17:56:22 +0000
Subject: [R] How to vectorize this function
In-Reply-To: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
Message-ID: <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>

In addition to what the other said, if callM is a vector then an expression of the form
   if (callM <= call0)
is inappropriate. Objects inside the parentheses of   if()  should have length one. For example,

> if (1:5 < 3) 'a' else 'b'
[1] "a"
Warning message:
In if (1:5 < 3) "a" else "b" :
  the condition has length > 1 and only the first element will be used


instead of what you have:
         if(callM <= call0){
           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
         }else{
           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
        }

Here are a couple of (untested) possibilities:

  M.gt.0 <- callM > call0
  sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
  sig[M.gt.0] <- (1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y)))[M.gt.0]

or

    sig <- 1/sqrt(T)*(sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) * sqrt(gamma - y))

incidentally, I would write
   sig <- (sqrt(gamma + y) - sqrt(gamma - y))/sqrt(T)
instead of
   sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/20/18, 8:08 AM, "R-help on behalf of Lynette Chang" <r-help-bounces at r-project.org on behalf of momtoomax at gmail.com> wrote:

    Hello everyone,
    
         I?ve a function with five input argument and one output number. 
    	  impVolC <- function(callM, K, T, F, r)
    
         I hope this function can take five vectors as input, then return one vector as output. My vectorization ran into problems with the nested if-else operation. As a result, I have to write another for loop to call this function. Can anyone suggest some methods to overcome it? I put my code below, thanks.
    
    impVolC <- function(callM, K, T, F, r){
    
    
     if(y >= 0){
         call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
         if(callM <= call0){
           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
         }else{
           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
         }
     }else{
         call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
         if(callM <= call0){
           sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
         }else{
           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
         }
     }
     sig
    } 
    
    for(i in 1:length(call)){
     sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r = r_m)  
    }
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Sep 20 21:36:06 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 20 Sep 2018 12:36:06 -0700
Subject: [R] How to vectorize this function
In-Reply-To: <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
 <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
Message-ID: <B9078087-DB4F-45CF-BF79-C6AAB866E4FB@dcn.davis.ca.us>

re: your last comment... why do you prefer to multiply by the reciprocal?

On September 20, 2018 10:56:22 AM PDT, "MacQueen, Don via R-help" <r-help at r-project.org> wrote:
>In addition to what the other said, if callM is a vector then an
>expression of the form
>   if (callM <= call0)
>is inappropriate. Objects inside the parentheses of   if()  should have
>length one. For example,
>
>> if (1:5 < 3) 'a' else 'b'
>[1] "a"
>Warning message:
>In if (1:5 < 3) "a" else "b" :
>  the condition has length > 1 and only the first element will be used
>
>
>instead of what you have:
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>        }
>
>Here are a couple of (untested) possibilities:
>
>  M.gt.0 <- callM > call0
>  sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
> sig[M.gt.0] <- (1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y)))[M.gt.0]
>
>or
>
>sig <- 1/sqrt(T)*(sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) *
>sqrt(gamma - y))
>
>incidentally, I would write
>   sig <- (sqrt(gamma + y) - sqrt(gamma - y))/sqrt(T)
>instead of
>   sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>
>--
>Don MacQueen
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>Lab cell 925-724-7509
> 
> 
>
>?On 9/20/18, 8:08 AM, "R-help on behalf of Lynette Chang"
><r-help-bounces at r-project.org on behalf of momtoomax at gmail.com> wrote:
>
>    Hello everyone,
>    
>       I?ve a function with five input argument and one output number. 
>    	  impVolC <- function(callM, K, T, F, r)
>    
>I hope this function can take five vectors as input, then return one
>vector as output. My vectorization ran into problems with the nested
>if-else operation. As a result, I have to write another for loop to
>call this function. Can anyone suggest some methods to overcome it? I
>put my code below, thanks.
>    
>    impVolC <- function(callM, K, T, F, r){
>    
>    
>     if(y >= 0){
>         call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>         }
>     }else{
>         call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>         }
>     }
>     sig
>    } 
>    
>    for(i in 1:length(call)){
>sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r =
>r_m)  
>    }
>    
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
>    
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ericjberger @ending from gm@il@com  Thu Sep 20 22:28:27 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Thu, 20 Sep 2018 23:28:27 +0300
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
Message-ID: <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>

Hi Andrew,
I don't have any experience in this area but I was intrigued by your
question. Here is what I learned.

1, A bit of poking around turned up a thread on stats.stackexchange that
mentions that "smallest space analysis" (SSA) is a special case of
"multidimensional scaling" (MDS).
See the thread here:
https://stats.stackexchange.com/questions/82462/guttmans-smallest-space-analysis

2. The R package SMACOF implements some solutions for MDS. See the
documentation "Multidimensional Scaling in R: SMACOF" available at
https://mran.microsoft.com/snapshot/2018-05-13/web/packages/smacof/vignettes/smacof.pdf

HTH,
Eric



On Wed, Sep 19, 2018 at 2:00 PM, Andrew <phaedrusv at gmail.com> wrote:

> Hi
>
> As part of my forensics psych course, we have been introduced to
> Guttman's smallest space analysis (SSA). I want to explore this approach
> using R, but despite finding some queries on the web about this same
> thing, have yet to find any answers. The MASS package doesn't seem to do
> the job, and the only thing I have been able to find is some proprietary
> software HUDAP  (Hebrew University Data Analysis Package) which may/ not
> be compatible with R (or GNU/Linux for that matter).
>
> Does anyone have information on how to do SSA using R?
>
> Many thanks
>
> Andrew
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @bouelm@k@rim1962 @ending from gm@il@com  Thu Sep 20 22:37:06 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Thu, 20 Sep 2018 16:37:06 -0400
Subject: [R] =?utf-8?q?Make_Month_variable_be_called_=E2=80=9CMay?=
	=?utf-8?b?4oCdLOKAnEp1bmXigJ0gZXRjLiwgaW5zdGVhZCBvZiBhIG51bWVyaWMg?=
	=?utf-8?q?quantity_5=2C6=2C_etc=2E?=
In-Reply-To: <39BBA96A-667F-4CE2-A513-26816EFAA570@dcn.davis.ca.us>
References: <CAE9stmevB6+5zfMOwa-HmfEa2gn8nSbpCicXGkwDTvmC5cCRCQ@mail.gmail.com>
 <39BBA96A-667F-4CE2-A513-26816EFAA570@dcn.davis.ca.us>
Message-ID: <CAE9stmePX9niYMU+L-KOVn85pbQD9qNf4+XJwebuJ8yfoWSVWA@mail.gmail.com>

Dear Jeff:

thank you very much

abou

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Thu, Sep 20, 2018 at 1:37 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> airquality$Month <- factor(airquality$Month, levels=1:12, labels=
> month.name )
>
> On September 20, 2018 10:14:41 AM PDT, AbouEl-Makarim Aboueissa <
> abouelmakarim1962 at gmail.com> wrote:
> >Dear All:
> >
> >*Re:* How to make the Month variable be called ?May?,?June?, "July",
> >"August", "September" instead of a numeric quantity (5,6,7,8,9)
> >
> >
> >In the airquality data set, please see the code below; How to make the
> >Month variable be called ?May?,?June?, "July", "August", "September"
> >instead of a numeric quantity (5,6,7,8,9)
> >
> >
> >
> >data(airquality)
> >
> >head(airquality)
> >
> >
> >#### Making Day and Month categorical variables
> >
> >
> >airquality$Day <- factor(airquality$Day)
> >
> >airquality$Month <- factor(airquality$Month)
> >
> >
> >head(airquality)
> >
> >
> >> head(airquality)
> >  Ozone Solar.R Wind Temp Month Day
> >1    41     190  7.4   67     5   1
> >2    36     118  8.0   72     5   2
> >3    12     149 12.6   74     5   3
> >4    18     313 11.5   62     5   4
> >5    NA      NA 14.3   56     5   5
> >6    28      NA 14.9   66     5   6
> >>
> >
> >
> >
> >Thank you very much for your help in advance
> >
> >
> >with thanks
> >abou
> >______________________
> >
> >
> >*AbouEl-Makarim Aboueissa, PhD*
> >
> >*Professor of Statistics*
> >*Graduate Coordinator*
> >
> >*Department of Mathematics and Statistics*
> >*University of Southern Maine*
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From ph@edru@v @ending from gm@il@com  Thu Sep 20 22:48:21 2018
From: ph@edru@v @ending from gm@il@com (Andrew)
Date: Thu, 20 Sep 2018 21:48:21 +0100
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>
Message-ID: <2b9aa89c-1141-5b8d-44ca-158c6472c0fa@gmail.com>

Hi Eric

I will need to dig into this a bit deeper, but this looks like it might 
hold some promise. The web link you shared seems familiar - perhaps I 
came across it but not at the site you linked to. I will read the 
sources with interest.

Thank you for bringing them to my attention.

Regards,
Andrew


On 20/09/18 21:28, Eric Berger wrote:
> Hi Andrew,
> I don't have any experience in this area but I was intrigued by your 
> question. Here is what I learned.
>
> 1, A bit of poking around turned up a thread on stats.stackexchange 
> that mentions that "smallest space analysis" (SSA) is a special case 
> of "multidimensional scaling" (MDS).
> See the thread here:
> https://stats.stackexchange.com/questions/82462/guttmans-smallest-space-analysis
>
> 2. The R package SMACOF implements some solutions for MDS. See the 
> documentation "Multidimensional Scaling in R: SMACOF" available at
> https://mran.microsoft.com/snapshot/2018-05-13/web/packages/smacof/vignettes/smacof.pdf
>
> HTH,
> Eric
>
>
>
> On Wed, Sep 19, 2018 at 2:00 PM, Andrew <phaedrusv at gmail.com 
> <mailto:phaedrusv at gmail.com>> wrote:
>
>     Hi
>
>     As part of my forensics psych course, we have been introduced to
>     Guttman's smallest space analysis (SSA). I want to explore this
>     approach
>     using R, but despite finding some queries on the web about this same
>     thing, have yet to find any answers. The MASS package doesn't seem
>     to do
>     the job, and the only thing I have been able to find is some
>     proprietary
>     software HUDAP? (Hebrew University Data Analysis Package) which
>     may/ not
>     be compatible with R (or GNU/Linux for that matter).
>
>     Does anyone have information on how to do SSA using R?
>
>     Many thanks
>
>     Andrew
>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Thu Sep 20 22:53:03 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 20 Sep 2018 20:53:03 +0000
Subject: [R] How to vectorize this function
In-Reply-To: <B9078087-DB4F-45CF-BF79-C6AAB866E4FB@dcn.davis.ca.us>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
 <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
 <B9078087-DB4F-45CF-BF79-C6AAB866E4FB@dcn.davis.ca.us>
Message-ID: <BEC4139D-DD18-4346-A3B8-24AD4EEDA81E@llnl.gov>

You're asking me?

I prefer
> 4/2
[1] 2

not
> 1/2*4
[1] 2

(I think that's what I said)

And if I did want to multiply by the reciprocal, which does happen from time to time, I'd certainly do it this way:
   (1/2)*4

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/20/18, 12:36 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

    re: your last comment... why do you prefer to multiply by the reciprocal?
    
    On September 20, 2018 10:56:22 AM PDT, "MacQueen, Don via R-help" <r-help at r-project.org> wrote:
    >In addition to what the other said, if callM is a vector then an
    >expression of the form
    >   if (callM <= call0)
    >is inappropriate. Objects inside the parentheses of   if()  should have
    >length one. For example,
    >
    >> if (1:5 < 3) 'a' else 'b'
    >[1] "a"
    >Warning message:
    >In if (1:5 < 3) "a" else "b" :
    >  the condition has length > 1 and only the first element will be used
    >
    >
    >instead of what you have:
    >         if(callM <= call0){
    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
    >         }else{
    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
    >        }
    >
    >Here are a couple of (untested) possibilities:
    >
    >  M.gt.0 <- callM > call0
    >  sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
    > sig[M.gt.0] <- (1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y)))[M.gt.0]
    >
    >or
    >
    >sig <- 1/sqrt(T)*(sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) *
    >sqrt(gamma - y))
    >
    >incidentally, I would write
    >   sig <- (sqrt(gamma + y) - sqrt(gamma - y))/sqrt(T)
    >instead of
    >   sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
    >
    >--
    >Don MacQueen
    >Lawrence Livermore National Laboratory
    >7000 East Ave., L-627
    >Livermore, CA 94550
    >925-423-1062
    >Lab cell 925-724-7509
    > 
    > 
    >
    >On 9/20/18, 8:08 AM, "R-help on behalf of Lynette Chang"
    ><r-help-bounces at r-project.org on behalf of momtoomax at gmail.com> wrote:
    >
    >    Hello everyone,
    >    
    >       I?ve a function with five input argument and one output number. 
    >    	  impVolC <- function(callM, K, T, F, r)
    >    
    >I hope this function can take five vectors as input, then return one
    >vector as output. My vectorization ran into problems with the nested
    >if-else operation. As a result, I have to write another for loop to
    >call this function. Can anyone suggest some methods to overcome it? I
    >put my code below, thanks.
    >    
    >    impVolC <- function(callM, K, T, F, r){
    >    
    >    
    >     if(y >= 0){
    >         call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
    >         if(callM <= call0){
    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
    >         }else{
    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
    >         }
    >     }else{
    >         call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
    >         if(callM <= call0){
    >           sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
    >         }else{
    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
    >         }
    >     }
    >     sig
    >    } 
    >    
    >    for(i in 1:length(call)){
    >sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r =
    >r_m)  
    >    }
    >    
    >    ______________________________________________
    >    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >    https://stat.ethz.ch/mailman/listinfo/r-help
    >PLEASE do read the posting guide
    >http://www.R-project.org/posting-guide.html
    >    and provide commented, minimal, self-contained, reproducible code.
    >    
    >
    >______________________________________________
    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >https://stat.ethz.ch/mailman/listinfo/r-help
    >PLEASE do read the posting guide
    >http://www.R-project.org/posting-guide.html
    >and provide commented, minimal, self-contained, reproducible code.
    
    -- 
    Sent from my phone. Please excuse my brevity.
    


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Sep 21 00:04:21 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 20 Sep 2018 15:04:21 -0700
Subject: [R] How to vectorize this function
In-Reply-To: <BEC4139D-DD18-4346-A3B8-24AD4EEDA81E@llnl.gov>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
 <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
 <B9078087-DB4F-45CF-BF79-C6AAB866E4FB@dcn.davis.ca.us>
 <BEC4139D-DD18-4346-A3B8-24AD4EEDA81E@llnl.gov>
Message-ID: <B9D72AA8-A00E-4B67-86B8-C1E25698600B@dcn.davis.ca.us>

Sorry, misread your comment, I agree. 4/2 has one arithmetic operation, (1/2)*4 has two to accomplish the same calculation.

On September 20, 2018 1:53:03 PM PDT, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
>You're asking me?
>
>I prefer
>> 4/2
>[1] 2
>
>not
>> 1/2*4
>[1] 2
>
>(I think that's what I said)
>
>And if I did want to multiply by the reciprocal, which does happen from
>time to time, I'd certainly do it this way:
>   (1/2)*4
>
>-Don
>
>--
>Don MacQueen
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>Lab cell 925-724-7509
> 
> 
>
>?On 9/20/18, 12:36 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>re: your last comment... why do you prefer to multiply by the
>reciprocal?
>    
>On September 20, 2018 10:56:22 AM PDT, "MacQueen, Don via R-help"
><r-help at r-project.org> wrote:
>    >In addition to what the other said, if callM is a vector then an
>    >expression of the form
>    >   if (callM <= call0)
>>is inappropriate. Objects inside the parentheses of   if()  should
>have
>    >length one. For example,
>    >
>    >> if (1:5 < 3) 'a' else 'b'
>    >[1] "a"
>    >Warning message:
>    >In if (1:5 < 3) "a" else "b" :
>>  the condition has length > 1 and only the first element will be used
>    >
>    >
>    >instead of what you have:
>    >         if(callM <= call0){
>    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>    >         }else{
>    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>    >        }
>    >
>    >Here are a couple of (untested) possibilities:
>    >
>    >  M.gt.0 <- callM > call0
>    >  sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>> sig[M.gt.0] <- (1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma -
>y)))[M.gt.0]
>    >
>    >or
>    >
>  >sig <- 1/sqrt(T)*(sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) *
>    >sqrt(gamma - y))
>    >
>    >incidentally, I would write
>    >   sig <- (sqrt(gamma + y) - sqrt(gamma - y))/sqrt(T)
>    >instead of
>    >   sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>    >
>    >--
>    >Don MacQueen
>    >Lawrence Livermore National Laboratory
>    >7000 East Ave., L-627
>    >Livermore, CA 94550
>    >925-423-1062
>    >Lab cell 925-724-7509
>    > 
>    > 
>    >
>    >On 9/20/18, 8:08 AM, "R-help on behalf of Lynette Chang"
>><r-help-bounces at r-project.org on behalf of momtoomax at gmail.com> wrote:
>    >
>    >    Hello everyone,
>    >    
>>       I?ve a function with five input argument and one output number.
>
>    >    	  impVolC <- function(callM, K, T, F, r)
>    >    
>  >I hope this function can take five vectors as input, then return one
>  >vector as output. My vectorization ran into problems with the nested
>   >if-else operation. As a result, I have to write another for loop to
> >call this function. Can anyone suggest some methods to overcome it? I
>    >put my code below, thanks.
>    >    
>    >    impVolC <- function(callM, K, T, F, r){
>    >    
>    >    
>    >     if(y >= 0){
>    >         call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
>    >         if(callM <= call0){
>    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>    >         }else{
>    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>    >         }
>    >     }else{
>    >         call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
>    >         if(callM <= call0){
>    >           sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
>    >         }else{
>    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>    >         }
>    >     }
>    >     sig
>    >    } 
>    >    
>    >    for(i in 1:length(call)){
>>sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r
>=
>    >r_m)  
>    >    }
>    >    
>    >    ______________________________________________
> >    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    >    https://stat.ethz.ch/mailman/listinfo/r-help
>    >PLEASE do read the posting guide
>    >http://www.R-project.org/posting-guide.html
>>    and provide commented, minimal, self-contained, reproducible code.
>    >    
>    >
>    >______________________________________________
>    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    >https://stat.ethz.ch/mailman/listinfo/r-help
>    >PLEASE do read the posting guide
>    >http://www.R-project.org/posting-guide.html
>    >and provide commented, minimal, self-contained, reproducible code.
>    
>    -- 
>    Sent from my phone. Please excuse my brevity.
>    

-- 
Sent from my phone. Please excuse my brevity.


From erinm@hodge@@ @ending from gm@il@com  Fri Sep 21 02:50:04 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Thu, 20 Sep 2018 18:50:04 -0600
Subject: [R] tibble question with a mean
Message-ID: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>

Hello!

Here is a toy tibble problem:

xt <-
tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
str(xt)
Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
 $ x: chr  "A" "B" "C" "D"
 $ y: int  1 2 3 4
 $ z: num  0.3246 0.0504 0.339 0.4872
 $ a: chr  "dog" "cat" "tree" "ferret"
#No surprise
 xt %>% mean
[1] NA
Warning message:
In mean.default(.) : argument is not numeric or logical: returning NA
#surprised!
mean(xt[2:3])
[1] NA
Warning message:
In mean.default(xt[2:3]) : argument is not numeric or logical: returning NA
 xt[, 2:3] %>% mean
[1] NA
Warning message:
In mean.default(.) : argument is not numeric or logical: returning NA

I have a feeling that I'm doing something silly wrong.  Has anyone run into
this, please?  I saw something like this on this list, but didn't see a
solution.

Thanks,
Erin


Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From peter@l@ngfelder @ending from gm@il@com  Fri Sep 21 03:07:35 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Thu, 20 Sep 2018 18:07:35 -0700
Subject: [R] tibble question with a mean
In-Reply-To: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
Message-ID: <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>

I don't know tibble, so I'll do the same with a plain data frame:

a =
data.frame(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> a
  x y           z      a
1 A 1 -0.08264865    dog
2 B 2  0.32344426    cat
3 C 3 -0.80416061   tree
4 D 4  1.27052529 ferret
> mean(a[2:3])
[1] NA
Warning message:
In mean.default(a[2:3]) : argument is not numeric or logical: returning NA
> mean(as.matrix(a[2:3]))
[1] 1.338395

The reason you get an error on mean(a[2:3]) is that a[2:3] is still a data
frame (a special list) and you cannot simply apply mean to a list. You need
to first convert to a matrix or vector which can then be fed to mean().

Peter


On Thu, Sep 20, 2018 at 5:50 PM Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello!
>
> Here is a toy tibble problem:
>
> xt <-
> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> str(xt)
> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
>  $ x: chr  "A" "B" "C" "D"
>  $ y: int  1 2 3 4
>  $ z: num  0.3246 0.0504 0.339 0.4872
>  $ a: chr  "dog" "cat" "tree" "ferret"
> #No surprise
>  xt %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
> #surprised!
> mean(xt[2:3])
> [1] NA
> Warning message:
> In mean.default(xt[2:3]) : argument is not numeric or logical: returning NA
>  xt[, 2:3] %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
>
> I have a feeling that I'm doing something silly wrong.  Has anyone run into
> this, please?  I saw something like this on this list, but didn't see a
> solution.
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Fri Sep 21 03:38:26 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Fri, 21 Sep 2018 13:38:26 +1200
Subject: [R] [FORGED] Re:  tibble question with a mean
In-Reply-To: <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
 <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
Message-ID: <1b86773c-a2c6-933c-1710-164c5952fa4e@auckland.ac.nz>


Please see inline below.

n 09/21/2018 01:07 PM, Peter Langfelder wrote:
> I don't know tibble, so I'll do the same with a plain data frame:
> 
> a =
> data.frame(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
>> a
>    x y           z      a
> 1 A 1 -0.08264865    dog
> 2 B 2  0.32344426    cat
> 3 C 3 -0.80416061   tree
> 4 D 4  1.27052529 ferret
>> mean(a[2:3])
> [1] NA
> Warning message:
> In mean.default(a[2:3]) : argument is not numeric or logical: returning NA
>> mean(as.matrix(a[2:3]))
> [1] 1.338395
> 
> The reason you get an error on mean(a[2:3]) is that a[2:3] is still a data
> frame (a special list) and you cannot simply apply mean to a list. You need
> to first convert to a matrix or vector which can then be fed to mean().

Perhaps

sapply(a[2:3],mean)?

cheers,

Rolf

> 
> Peter
> 
> 
> On Thu, Sep 20, 2018 at 5:50 PM Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> 
>> Hello!
>>
>> Here is a toy tibble problem:
>>
>> xt <-
>> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
>> str(xt)
>> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
>>   $ x: chr  "A" "B" "C" "D"
>>   $ y: int  1 2 3 4
>>   $ z: num  0.3246 0.0504 0.339 0.4872
>>   $ a: chr  "dog" "cat" "tree" "ferret"
>> #No surprise
>>   xt %>% mean
>> [1] NA
>> Warning message:
>> In mean.default(.) : argument is not numeric or logical: returning NA
>> #surprised!
>> mean(xt[2:3])
>> [1] NA
>> Warning message:
>> In mean.default(xt[2:3]) : argument is not numeric or logical: returning NA
>>   xt[, 2:3] %>% mean
>> [1] NA
>> Warning message:
>> In mean.default(.) : argument is not numeric or logical: returning NA
>>
>> I have a feeling that I'm doing something silly wrong.  Has anyone run into
>> this, please?  I saw something like this on this list, but didn't see a
>> solution.
>>
>> Thanks,
>> Erin


From erinm@hodge@@ @ending from gm@il@com  Fri Sep 21 03:56:11 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Thu, 20 Sep 2018 19:56:11 -0600
Subject: [R] [FORGED] Re:  tibble question with a mean
In-Reply-To: <1b86773c-a2c6-933c-1710-164c5952fa4e@auckland.ac.nz>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
 <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
 <1b86773c-a2c6-933c-1710-164c5952fa4e@auckland.ac.nz>
Message-ID: <CACxE24kThEWrL4Do5HK4prtu_+JcsLxMdazQ_xmfuqUvrbqMwA@mail.gmail.com>

Thanks to all for the good suggestions!!!

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Thu, Sep 20, 2018 at 7:38 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> Please see inline below.
>
> n 09/21/2018 01:07 PM, Peter Langfelder wrote:
> > I don't know tibble, so I'll do the same with a plain data frame:
> >
> > a =
> >
> data.frame(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> >> a
> >    x y           z      a
> > 1 A 1 -0.08264865    dog
> > 2 B 2  0.32344426    cat
> > 3 C 3 -0.80416061   tree
> > 4 D 4  1.27052529 ferret
> >> mean(a[2:3])
> > [1] NA
> > Warning message:
> > In mean.default(a[2:3]) : argument is not numeric or logical: returning
> NA
> >> mean(as.matrix(a[2:3]))
> > [1] 1.338395
> >
> > The reason you get an error on mean(a[2:3]) is that a[2:3] is still a
> data
> > frame (a special list) and you cannot simply apply mean to a list. You
> need
> > to first convert to a matrix or vector which can then be fed to mean().
>
> Perhaps
>
> sapply(a[2:3],mean)?
>
> cheers,
>
> Rolf
>
> >
> > Peter
> >
> >
> > On Thu, Sep 20, 2018 at 5:50 PM Erin Hodgess <erinm.hodgess at gmail.com>
> > wrote:
> >
> >> Hello!
> >>
> >> Here is a toy tibble problem:
> >>
> >> xt <-
> >> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> >> str(xt)
> >> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
> >>   $ x: chr  "A" "B" "C" "D"
> >>   $ y: int  1 2 3 4
> >>   $ z: num  0.3246 0.0504 0.339 0.4872
> >>   $ a: chr  "dog" "cat" "tree" "ferret"
> >> #No surprise
> >>   xt %>% mean
> >> [1] NA
> >> Warning message:
> >> In mean.default(.) : argument is not numeric or logical: returning NA
> >> #surprised!
> >> mean(xt[2:3])
> >> [1] NA
> >> Warning message:
> >> In mean.default(xt[2:3]) : argument is not numeric or logical:
> returning NA
> >>   xt[, 2:3] %>% mean
> >> [1] NA
> >> Warning message:
> >> In mean.default(.) : argument is not numeric or logical: returning NA
> >>
> >> I have a feeling that I'm doing something silly wrong.  Has anyone run
> into
> >> this, please?  I saw something like this on this list, but didn't see a
> >> solution.
> >>
> >> Thanks,
> >> Erin
>

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Fri Sep 21 05:19:14 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Fri, 21 Sep 2018 03:19:14 +0000
Subject: [R] tibble question with a mean
In-Reply-To: <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
 <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
Message-ID: <61f17d3932514396a5be003c26bf3b03@tamu.edu>

> xt[, 2:3] %>% colMeans
         y          z 
 2.5000000 -0.4401625

> xt[2] %>% colMeans
  y 
2.5 
> t(xt[, 2]) %>% mean
[1] 2.5

-------------------------
David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter Langfelder
Sent: Thursday, September 20, 2018 8:08 PM
To: Erin Hodgess <erinm.hodgess at gmail.com>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] tibble question with a mean

I don't know tibble, so I'll do the same with a plain data frame:

a =
data.frame(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> a
  x y           z      a
1 A 1 -0.08264865    dog
2 B 2  0.32344426    cat
3 C 3 -0.80416061   tree
4 D 4  1.27052529 ferret
> mean(a[2:3])
[1] NA
Warning message:
In mean.default(a[2:3]) : argument is not numeric or logical: returning NA
> mean(as.matrix(a[2:3]))
[1] 1.338395

The reason you get an error on mean(a[2:3]) is that a[2:3] is still a data
frame (a special list) and you cannot simply apply mean to a list. You need
to first convert to a matrix or vector which can then be fed to mean().

Peter


On Thu, Sep 20, 2018 at 5:50 PM Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello!
>
> Here is a toy tibble problem:
>
> xt <-
> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> str(xt)
> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
>  $ x: chr  "A" "B" "C" "D"
>  $ y: int  1 2 3 4
>  $ z: num  0.3246 0.0504 0.339 0.4872
>  $ a: chr  "dog" "cat" "tree" "ferret"
> #No surprise
>  xt %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
> #surprised!
> mean(xt[2:3])
> [1] NA
> Warning message:
> In mean.default(xt[2:3]) : argument is not numeric or logical: returning NA
>  xt[, 2:3] %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
>
> I have a feeling that I'm doing something silly wrong.  Has anyone run into
> this, please?  I saw something like this on this list, but didn't see a
> solution.
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From erinm@hodge@@ @ending from gm@il@com  Fri Sep 21 06:01:05 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Thu, 20 Sep 2018 22:01:05 -0600
Subject: [R] tibble question with a mean
In-Reply-To: <61f17d3932514396a5be003c26bf3b03@tamu.edu>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
 <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
 <61f17d3932514396a5be003c26bf3b03@tamu.edu>
Message-ID: <CACxE24k+4Sxsp7uRCYz1LAp6zQm4bxy6+2mfrSwvgHT+YRfE7A@mail.gmail.com>

David
That's awesome!

Thank you!!!

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Thu, Sep 20, 2018 at 9:19 PM David L Carlson <dcarlson at tamu.edu> wrote:

> > xt[, 2:3] %>% colMeans
>          y          z
>  2.5000000 -0.4401625
>
> > xt[2] %>% colMeans
>   y
> 2.5
> > t(xt[, 2]) %>% mean
> [1] 2.5
>
> -------------------------
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter
> Langfelder
> Sent: Thursday, September 20, 2018 8:08 PM
> To: Erin Hodgess <erinm.hodgess at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] tibble question with a mean
>
> I don't know tibble, so I'll do the same with a plain data frame:
>
> a =
>
> data.frame(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> > a
>   x y           z      a
> 1 A 1 -0.08264865    dog
> 2 B 2  0.32344426    cat
> 3 C 3 -0.80416061   tree
> 4 D 4  1.27052529 ferret
> > mean(a[2:3])
> [1] NA
> Warning message:
> In mean.default(a[2:3]) : argument is not numeric or logical: returning NA
> > mean(as.matrix(a[2:3]))
> [1] 1.338395
>
> The reason you get an error on mean(a[2:3]) is that a[2:3] is still a data
> frame (a special list) and you cannot simply apply mean to a list. You need
> to first convert to a matrix or vector which can then be fed to mean().
>
> Peter
>
>
> On Thu, Sep 20, 2018 at 5:50 PM Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
>
> > Hello!
> >
> > Here is a toy tibble problem:
> >
> > xt <-
> > tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> > str(xt)
> > Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
> >  $ x: chr  "A" "B" "C" "D"
> >  $ y: int  1 2 3 4
> >  $ z: num  0.3246 0.0504 0.339 0.4872
> >  $ a: chr  "dog" "cat" "tree" "ferret"
> > #No surprise
> >  xt %>% mean
> > [1] NA
> > Warning message:
> > In mean.default(.) : argument is not numeric or logical: returning NA
> > #surprised!
> > mean(xt[2:3])
> > [1] NA
> > Warning message:
> > In mean.default(xt[2:3]) : argument is not numeric or logical: returning
> NA
> >  xt[, 2:3] %>% mean
> > [1] NA
> > Warning message:
> > In mean.default(.) : argument is not numeric or logical: returning NA
> >
> > I have a feeling that I'm doing something silly wrong.  Has anyone run
> into
> > this, please?  I saw something like this on this list, but didn't see a
> > solution.
> >
> > Thanks,
> > Erin
> >
> >
> > Erin Hodgess, PhD
> > mailto: erinm.hodgess at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From momtoom@x @ending from gm@il@com  Thu Sep 20 23:46:01 2018
From: momtoom@x @ending from gm@il@com (Lynette Chang)
Date: Thu, 20 Sep 2018 17:46:01 -0400
Subject: [R] How to vectorize this function
In-Reply-To: <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
 <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
Message-ID: <C5A9E207-E383-411E-960B-395B52FB69A8@gmail.com>

Here are the code and data file. I?m not sure if I put too much unrelated information here. 

My goal is to factor out volatilities from the data. I hope I can get sigV <- impVolC(callM, K, T, F, r), which has five vectors as input, and one vector as output. The length of all those six vectors are the same. However, I got stuck in the nested if-else sentence, as if-condition cannot handle vectors. I rewrite it as you guys suggestions, however, I still have one layer of if-condition. Any thoughts to improve it? Thanks.

Lynette

-------------- next part --------------


df <- read.csv(file = "/S&P500_ETF_Option_0917.csv", header = TRUE, 
               colClasses = c("integer", "character", "numeric", "numeric", "numeric",
                              "character", "numeric", "numeric", "numeric"))

call <- (df$callBid + df$callAsk)/2
put <- (df$putBid + df$putAsk)/2

y <- call - put
A <- cbind(rep(1, dim(df)[1]), -df$Strike)

x <- solve(t(A)%*%A)%*%t(A)%*%y
PVF <- x[1]
disc <- x[2]

S <- 2381



library(timeDate)
# Lets work in your environment:
getRmetricsOptions("myFinCenter")
setRmetricsOptions(myFinCenter = "America/New_York")

# define a sequence of days with  timeSequence 
t1 <- timeSequence(from = "2017-03-16", to = "2017-09-29")

# Define a calendar for your exchange (use an available one as a template, e.g. holidayNYSE) 
# subindex the sequence with isBizday using your calendar as an argument 
holidayNYSE(2017)
isBizday(t1, holidayNYSE())
t2 <- t1[isBizday(t1, holidayNYSE(2017))]

T <- length(t2)/252
q_m <- -log(PVF/S)/T
r_m <- log(disc)/(-T)


polya <- function(x){
  1/2 + sign(x)/2* sqrt(1- exp(-2*x^2/pi))
}
impVolC <- function(callM, K, T, F, r){
  
  y <- log(F/K)
  alpha <- callM/(K*exp(-r*T))
  R <- 2*alpha - exp(y) + 1
  
  A <- (exp((1 - 2/pi)*y) - exp(-(1 - 2/pi)*y))^2
  B <- 4*(exp(2/pi*y) + exp(-2/pi*y)) - 2*exp(-y)*(exp((1-2/pi)*y)+exp(-(1-2/pi)*y))*(exp(2*y) + 1 - R^2)
  C <- exp(-2*y)*(R^2 - (exp(y) -1)^2)*((exp(y) + 1)^2 - R^2)                                                
  
  beta <- (2*C)/(B + sqrt(B^2 + 4*A*C))
  gamma <- -pi/2*log(beta)
  
  if(y >= 0){
    call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
    sig <- (sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) * sqrt(gamma - y))/sqrt(T)
  }else{
    call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
    sig <-  (ifelse(callM <= call0, -1, 1)*sqrt(gamma + y)  +  sqrt(gamma - y))/sqrt(T)
  }
  sig
}

F <- PVF*exp(r_m*T)
sigV <- rep(0, length(call))

for(i in 1:length(call)){
  sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r = r_m)  
}


> On Sep 20, 2018, at 1:56 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> 
> In addition to what the other said, if callM is a vector then an expression of the form
>   if (callM <= call0)
> is inappropriate. Objects inside the parentheses of   if()  should have length one. For example,
> 
>> if (1:5 < 3) 'a' else 'b'
> [1] "a"
> Warning message:
> In if (1:5 < 3) "a" else "b" :
>  the condition has length > 1 and only the first element will be used
> 
> 
> instead of what you have:
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>        }
> 
> Here are a couple of (untested) possibilities:
> 
>  M.gt.0 <- callM > call0
>  sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>  sig[M.gt.0] <- (1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y)))[M.gt.0]
> 
> or
> 
>    sig <- 1/sqrt(T)*(sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) * sqrt(gamma - y))
> 
> incidentally, I would write
>   sig <- (sqrt(gamma + y) - sqrt(gamma - y))/sqrt(T)
> instead of
>   sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
> 
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
> 
> 
> 
> ?On 9/20/18, 8:08 AM, "R-help on behalf of Lynette Chang" <r-help-bounces at r-project.org on behalf of momtoomax at gmail.com> wrote:
> 
>    Hello everyone,
> 
>         I?ve a function with five input argument and one output number. 
>    	  impVolC <- function(callM, K, T, F, r)
> 
>         I hope this function can take five vectors as input, then return one vector as output. My vectorization ran into problems with the nested if-else operation. As a result, I have to write another for loop to call this function. Can anyone suggest some methods to overcome it? I put my code below, thanks.
> 
>    impVolC <- function(callM, K, T, F, r){
> 
> 
>     if(y >= 0){
>         call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>         }
>     }else{
>         call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>         }
>     }
>     sig
>    } 
> 
>    for(i in 1:length(call)){
>     sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r = r_m)  
>    }
> 
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
> 
> 


From mikorym @ending from protonm@il@com  Fri Sep 21 07:31:07 2018
From: mikorym @ending from protonm@il@com (mikorym)
Date: Fri, 21 Sep 2018 05:31:07 +0000
Subject: [R] Fitting Production Curves
Message-ID: <_O_DvHZPLvQF7D5L6IDkx8lNvgTbN1NFC4xxX70VFIgOazkxU_PwIkJcJtvr25M4d0lzDuHySSUZnkrkUO9FWnL-qn1amYvUr04T5Nu-roQ=@protonmail.com>

Hi All,

By a production curve I mean for example the output of a mine, peak oil production or the yield of a farm over time within the same season. It is this last example that we should take as the prototypical case.

What I would like to do is to fit a curve that inherits qualities of the discrete production data (such as area of the curve equaling the total production for the season). Fitting a curve with least squares (such as a Gaussean or Hubbert) presents some issues (with regards to accuracy of inherited features). My next logical attempt would be to fit a sum of curves, such as a Fourier or Wavelet sum. Perhaps there is something simpler or more flexible in the way I am thinking?

My question is:

1. What would be an effective approach be to fit generalised production curves?
2. If a Wavelet sum is one of the best approaches, what would be a good way of implementing such curve fitting (including calculated coefficients) in R?
3. Is there anything else or another way that I should rather be thinking about this instead?

Best regards
Phillip-Jan van Zyl
MSc Mathematics, Stellenbosch


From m@echler @ending from @t@t@m@th@ethz@ch  Fri Sep 21 08:46:27 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 21 Sep 2018 08:46:27 +0200
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>
Message-ID: <23460.37827.406552.35154@stat.math.ethz.ch>

>>>>> Eric Berger 
>>>>>     on Thu, 20 Sep 2018 23:28:27 +0300 writes:

    > Hi Andrew,
    > I don't have any experience in this area but I was intrigued by your
    > question. Here is what I learned.

    > 1, A bit of poking around turned up a thread on stats.stackexchange that
    > mentions that "smallest space analysis" (SSA) is a special case of
    > "multidimensional scaling" (MDS).
    > See the thread here:
    > https://stats.stackexchange.com/questions/82462/guttmans-smallest-space-analysis

    > 2. The R package SMACOF implements some solutions for MDS. See the
    > documentation "Multidimensional Scaling in R: SMACOF" available at
    > https://mran.microsoft.com/snapshot/2018-05-13/web/packages/smacof/vignettes/smacof.pdf

Well, but MDS  is "old" and already available in standard R in
its classical form:

> apropos("MDS")
[1] "cmdscale"
> ?cmdscale  # "Classical Multidimensional Scaling"

then gives the help page for 'cmdscale' which in its 'See Also:'
mentions the

	isomds()
	sammon()

functions from package MASS which (as formally "Recommended"
pkg) is part of every full R installation.

So, at first, there's no need for any extra package...


    > HTH,
    > Eric



    > On Wed, Sep 19, 2018 at 2:00 PM, Andrew <phaedrusv at gmail.com> wrote:

    >> Hi
    >> 
    >> As part of my forensics psych course, we have been introduced to
    >> Guttman's smallest space analysis (SSA). I want to explore this approach
    >> using R, but despite finding some queries on the web about this same
    >> thing, have yet to find any answers. The MASS package doesn't seem to do
    >> the job, and the only thing I have been able to find is some proprietary
    >> software HUDAP  (Hebrew University Data Analysis Package) which may/ not
    >> be compatible with R (or GNU/Linux for that matter).
    >> 
    >> Does anyone have information on how to do SSA using R?
    >> 
    >> Many thanks
    >> 
    >> Andrew
    >> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/
    >> posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >> 

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From ph@edru@v @ending from gm@il@com  Fri Sep 21 09:41:27 2018
From: ph@edru@v @ending from gm@il@com (Andrew)
Date: Fri, 21 Sep 2018 08:41:27 +0100
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <23460.37827.406552.35154@stat.math.ethz.ch>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>
 <23460.37827.406552.35154@stat.math.ethz.ch>
Message-ID: <958b392f-075c-f494-5eb1-e6afbf167ee6@gmail.com>

Hi Martin

I was aware of the 'old' MDS package, thanks.

Hi Eric

I've now read the paper you referenced, thanks. Still didn't see 
anything about SSA however, so will keep looking.

However, if anyone on this list comes across something specific to SSA, 
could you kindly drop me a line to let me know?

Many thanks
Andrew


On 21/09/18 07:46, Martin Maechler wrote:
>>>>>> Eric Berger
>>>>>>      on Thu, 20 Sep 2018 23:28:27 +0300 writes:
>      > Hi Andrew,
>      > I don't have any experience in this area but I was intrigued by your
>      > question. Here is what I learned.
>
>      > 1, A bit of poking around turned up a thread on stats.stackexchange that
>      > mentions that "smallest space analysis" (SSA) is a special case of
>      > "multidimensional scaling" (MDS).
>      > See the thread here:
>      > https://stats.stackexchange.com/questions/82462/guttmans-smallest-space-analysis
>
>      > 2. The R package SMACOF implements some solutions for MDS. See the
>      > documentation "Multidimensional Scaling in R: SMACOF" available at
>      > https://mran.microsoft.com/snapshot/2018-05-13/web/packages/smacof/vignettes/smacof.pdf
>
> Well, but MDS  is "old" and already available in standard R in
> its classical form:
>
>> apropos("MDS")
> [1] "cmdscale"
>> ?cmdscale  # "Classical Multidimensional Scaling"
> then gives the help page for 'cmdscale' which in its 'See Also:'
> mentions the
>
> 	isomds()
> 	sammon()
>
> functions from package MASS which (as formally "Recommended"
> pkg) is part of every full R installation.
>
> So, at first, there's no need for any extra package...
>
>
>      > HTH,
>      > Eric
>
>
>
>      > On Wed, Sep 19, 2018 at 2:00 PM, Andrew <phaedrusv at gmail.com> wrote:
>
>      >> Hi
>      >>
>      >> As part of my forensics psych course, we have been introduced to
>      >> Guttman's smallest space analysis (SSA). I want to explore this approach
>      >> using R, but despite finding some queries on the web about this same
>      >> thing, have yet to find any answers. The MASS package doesn't seem to do
>      >> the job, and the only thing I have been able to find is some proprietary
>      >> software HUDAP  (Hebrew University Data Analysis Package) which may/ not
>      >> be compatible with R (or GNU/Linux for that matter).
>      >>
>      >> Does anyone have information on how to do SSA using R?
>      >>
>      >> Many thanks
>      >>
>      >> Andrew
>      >>
>      >>
>      >> [[alternative HTML version deleted]]
>      >>
>      >> ______________________________________________
>      >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      >> https://stat.ethz.ch/mailman/listinfo/r-help
>      >> PLEASE do read the posting guide http://www.R-project.org/
>      >> posting-guide.html
>      >> and provide commented, minimal, self-contained, reproducible code.
>      >>
>
>      > [[alternative HTML version deleted]]
>
>      > ______________________________________________
>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>


From @igbert @ending from wiwi@hu-berlin@de  Fri Sep 21 10:54:56 2018
From: @igbert @ending from wiwi@hu-berlin@de (Sigbert Klinke)
Date: Fri, 21 Sep 2018 10:54:56 +0200
Subject: [R] Link from vignette to package documentation
Message-ID: <d9953a1b-8ff6-70ff-e847-d08059f683bb@wiwi.hu-berlin.de>

Hi,

is it possible to make a link from a vignette to a (Rd) help files in my 
own or other packages?

Best Sigbert

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From murdoch@dunc@n @ending from gm@il@com  Fri Sep 21 11:02:32 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Fri, 21 Sep 2018 05:02:32 -0400
Subject: [R] Link from vignette to package documentation
In-Reply-To: <d9953a1b-8ff6-70ff-e847-d08059f683bb@wiwi.hu-berlin.de>
References: <d9953a1b-8ff6-70ff-e847-d08059f683bb@wiwi.hu-berlin.de>
Message-ID: <1392b368-3045-36cd-5e03-ff83a0cc95f4@gmail.com>

On 21/09/2018 4:54 AM, Sigbert Klinke wrote:
> Hi,
> 
> is it possible to make a link from a vignette to a (Rd) help files in my
> own or other packages?

Only with some significant compromises.  R normally acts as the web 
server for Rd files, and the URL is not really predictable.  So you 
would need to make the URL predictable, either by something like

options(help.ports = 12345)

(which will put help on port 12345, blocking that port for any other 
use, including help in another R session), or by putting a static copy 
of the help pages on some other web server.

Duncan Murdoch


From bog@@o@chri@tofer @ending from gm@il@com  Fri Sep 21 12:34:35 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Fri, 21 Sep 2018 16:04:35 +0530
Subject: [R] How to remove backslash
Message-ID: <CA+dpOJns1pSGZfgH+=bR56ok8gGJ2RYFyiVBNirE3U4WskvGYQ@mail.gmail.com>

Hi,

I have below string where I am trying to remove Backslash from. I tried
with gsub() function, however failed to remove that:

> str = '<span id=\"ctl00'
> gsub("\\", "", str)
Error in gsub("\\", "", str) :
  invalid regular expression '\', reason 'Trailing backslash'


Any pointer to the right approach?

Thanks for your time

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Fri Sep 21 12:48:55 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Fri, 21 Sep 2018 11:48:55 +0100
Subject: [R] How to remove backslash
In-Reply-To: <CA+dpOJns1pSGZfgH+=bR56ok8gGJ2RYFyiVBNirE3U4WskvGYQ@mail.gmail.com>
References: <CA+dpOJns1pSGZfgH+=bR56ok8gGJ2RYFyiVBNirE3U4WskvGYQ@mail.gmail.com>
Message-ID: <ee6367b8-6a6d-e5cd-d495-f0309739356e@sapo.pt>

Hello,

The backslash is not a character of the string str. test it with nchar:

str = '<span id=\"ctl00'
nchar(str)
#[1] 15


It is there just to escape the double quotes.
if you want a backslash you would need to escape it, like in str1.


str1 = '<span id=\\"ctl00'
nchar(str1)
#[1] 16


Now yes, you can remove it.

str2 <- gsub("\\", "", str1, fixed = TRUE)
identical(str, str2)
#[1] TRUE



Hope this helps,

Rui Barradas

?s 11:34 de 21/09/2018, Christofer Bogaso escreveu:
> Hi,
> 
> I have below string where I am trying to remove Backslash from. I tried
> with gsub() function, however failed to remove that:
> 
>> str = '<span id=\"ctl00'
>> gsub("\\", "", str)
> Error in gsub("\\", "", str) :
>    invalid regular expression '\', reason 'Trailing backslash'
> 
> 
> Any pointer to the right approach?
> 
> Thanks for your time
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From friendly @ending from yorku@c@  Fri Sep 21 15:07:35 2018
From: friendly @ending from yorku@c@ (Michael Friendly)
Date: Fri, 21 Sep 2018 09:07:35 -0400
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
Message-ID: <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>

Smallest space analysis (SSA) is just the name given to software 
developed by Guttman & Lingoes around the time the various versions
of multidimensional scaling were being developed.  Call it Israeli MDS
or Falafel MDS if you prefer. The reason you encountered it in your
course is presumably that the instructor was trained in that.

There are several variants of MDS-like algorithms for embedding
points representing objects in a space, using data representing
similarities or distances among objects -- metric (cmdscale)
and non-metric (MASS::isoMDS), using only rank order information, and a 
variety of
measures of goodness-of-fit ("stress").  I don't recall the details
of the SSA programs, but that should matter little conceptually.

The smacof package offers the widest array of possibilities.

-Michael


On 9/19/2018 7:00 AM, Andrew wrote:
> Hi
> 
> As part of my forensics psych course, we have been introduced to
> Guttman's smallest space analysis (SSA). I want to explore this approach
> using R, but despite finding some queries on the web about this same
> thing, have yet to find any answers. The MASS package doesn't seem to do
> the job, and the only thing I have been able to find is some proprietary
> software HUDAP? (Hebrew University Data Analysis Package) which may/ not
> be compatible with R (or GNU/Linux for that matter).
> 
> Does anyone have information on how to do SSA using R?
> 
> Many thanks
> 
> Andrew
> 
> 
> 	[[alternative HTML version deleted]]
>


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Sep 21 16:57:06 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 21 Sep 2018 07:57:06 -0700
Subject: [R] How to remove backslash
In-Reply-To: <ee6367b8-6a6d-e5cd-d495-f0309739356e@sapo.pt>
References: <CA+dpOJns1pSGZfgH+=bR56ok8gGJ2RYFyiVBNirE3U4WskvGYQ@mail.gmail.com>
 <ee6367b8-6a6d-e5cd-d495-f0309739356e@sapo.pt>
Message-ID: <589B2804-08FF-4ED1-AE9D-C7C174D7015F@dcn.davis.ca.us>

Even more convincing than nchar is cat vs. print:

s <- "<span id=\"ctl00"
cat( s )
print( s )

The print function formats character strings in a manner that allows you to copy and paste them into source files. The cat function just dumps the contents of the string out to the console, which can trigger the control behaviors of the terminal (moving cursor around, clearing the screen, beeping, etc.) but without the escapes needed to encode those characters in into source code.

Note that the whole reason R uses two kinds of quotes for character literals is to allow you to use fewer escape slashes:

s <- '<span id="ctl00'

A double quote inside a single-quote-delimited string is an ordinary character because there is no possible confusion that it might be the end of the string.

BTW the str symbol is a commonly-used function from base R... it is not a good idea to use it as a throwaway variable.


On September 21, 2018 3:48:55 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>Hello,
>
>The backslash is not a character of the string str. test it with nchar:
>
>str = '<span id=\"ctl00'
>nchar(str)
>#[1] 15
>
>
>It is there just to escape the double quotes.
>if you want a backslash you would need to escape it, like in str1.
>
>
>str1 = '<span id=\\"ctl00'
>nchar(str1)
>#[1] 16
>
>
>Now yes, you can remove it.
>
>str2 <- gsub("\\", "", str1, fixed = TRUE)
>identical(str, str2)
>#[1] TRUE
>
>
>
>Hope this helps,
>
>Rui Barradas
>
>?s 11:34 de 21/09/2018, Christofer Bogaso escreveu:
>> Hi,
>> 
>> I have below string where I am trying to remove Backslash from. I
>tried
>> with gsub() function, however failed to remove that:
>> 
>>> str = '<span id=\"ctl00'
>>> gsub("\\", "", str)
>> Error in gsub("\\", "", str) :
>>    invalid regular expression '\', reason 'Trailing backslash'
>> 
>> 
>> Any pointer to the right approach?
>> 
>> Thanks for your time
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Fri Sep 21 17:28:32 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 21 Sep 2018 08:28:32 -0700
Subject: [R] Fitting Production Curves
In-Reply-To: <_O_DvHZPLvQF7D5L6IDkx8lNvgTbN1NFC4xxX70VFIgOazkxU_PwIkJcJtvr25M4d0lzDuHySSUZnkrkUO9FWnL-qn1amYvUr04T5Nu-roQ=@protonmail.com>
References: <_O_DvHZPLvQF7D5L6IDkx8lNvgTbN1NFC4xxX70VFIgOazkxU_PwIkJcJtvr25M4d0lzDuHySSUZnkrkUO9FWnL-qn1amYvUr04T5Nu-roQ=@protonmail.com>
Message-ID: <CAGxFJbT0wkNQ_W+ix9RNFM9sQi=P7dt3CnS6=YmZ0nmvjFsyEQ@mail.gmail.com>

This list doesn't do statistics -- it does R programming, though statistics
does occur incidentally sometimes in that context. Not in your post
though. You should post on a statistics site like stats.stackexchange.com
for statistics questions.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 20, 2018 at 10:38 PM mikorym via R-help <r-help at r-project.org>
wrote:

> Hi All,
>
> By a production curve I mean for example the output of a mine, peak oil
> production or the yield of a farm over time within the same season. It is
> this last example that we should take as the prototypical case.
>
> What I would like to do is to fit a curve that inherits qualities of the
> discrete production data (such as area of the curve equaling the total
> production for the season). Fitting a curve with least squares (such as a
> Gaussean or Hubbert) presents some issues (with regards to accuracy of
> inherited features). My next logical attempt would be to fit a sum of
> curves, such as a Fourier or Wavelet sum. Perhaps there is something
> simpler or more flexible in the way I am thinking?
>
> My question is:
>
> 1. What would be an effective approach be to fit generalised production
> curves?
> 2. If a Wavelet sum is one of the best approaches, what would be a good
> way of implementing such curve fitting (including calculated coefficients)
> in R?
> 3. Is there anything else or another way that I should rather be thinking
> about this instead?
>
> Best regards
> Phillip-Jan van Zyl
> MSc Mathematics, Stellenbosch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Fri Sep 21 18:32:33 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 21 Sep 2018 09:32:33 -0700
Subject: [R] tibble question with a mean
In-Reply-To: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
Message-ID: <CAF8bMcat-QX561L23puZ7g5EbNUYteei876rnHNtUtRG6+TjgA@mail.gmail.com>

Since you are using tibbles you may want to go whole-hog and use the dplyr
package as well.

> xt <-
tibble(x=LETTERS[1:4],y=1:4,z=log2(1:4),a=c("dog","cat","tree","ferret"))
> xt %>% summarize(yMean=mean(y), zMean=mean(z), aLast=last(a))
# A tibble: 1 x 3
  yMean zMean aLast
  <dbl> <dbl> <chr>
1   2.5  1.15 ferret


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Sep 20, 2018 at 5:50 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello!
>
> Here is a toy tibble problem:
>
> xt <-
> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> str(xt)
> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
>  $ x: chr  "A" "B" "C" "D"
>  $ y: int  1 2 3 4
>  $ z: num  0.3246 0.0504 0.339 0.4872
>  $ a: chr  "dog" "cat" "tree" "ferret"
> #No surprise
>  xt %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
> #surprised!
> mean(xt[2:3])
> [1] NA
> Warning message:
> In mean.default(xt[2:3]) : argument is not numeric or logical: returning NA
>  xt[, 2:3] %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
>
> I have a feeling that I'm doing something silly wrong.  Has anyone run into
> this, please?  I saw something like this on this list, but didn't see a
> solution.
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From erinm@hodge@@ @ending from gm@il@com  Fri Sep 21 18:34:11 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Fri, 21 Sep 2018 10:34:11 -0600
Subject: [R] tibble question with a mean
In-Reply-To: <CAF8bMcat-QX561L23puZ7g5EbNUYteei876rnHNtUtRG6+TjgA@mail.gmail.com>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
 <CAF8bMcat-QX561L23puZ7g5EbNUYteei876rnHNtUtRG6+TjgA@mail.gmail.com>
Message-ID: <CACxE24kjDNwDqNp0See=1A3=sKz4k6wM+O2UFkO0tAqP=3Surg@mail.gmail.com>

Nice!

I didn?t realize you could do all that!

Thanks!


On Fri, Sep 21, 2018 at 10:32 AM William Dunlap <wdunlap at tibco.com> wrote:

> Since you are using tibbles you may want to go whole-hog and use the dplyr
> package as well.
>
> > xt <-
> tibble(x=LETTERS[1:4],y=1:4,z=log2(1:4),a=c("dog","cat","tree","ferret"))
> > xt %>% summarize(yMean=mean(y), zMean=mean(z), aLast=last(a))
> # A tibble: 1 x 3
>   yMean zMean aLast
>   <dbl> <dbl> <chr>
> 1   2.5  1.15 ferret
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Sep 20, 2018 at 5:50 PM, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
>
>> Hello!
>>
>> Here is a toy tibble problem:
>>
>> xt <-
>> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
>> str(xt)
>> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
>>  $ x: chr  "A" "B" "C" "D"
>>  $ y: int  1 2 3 4
>>  $ z: num  0.3246 0.0504 0.339 0.4872
>>  $ a: chr  "dog" "cat" "tree" "ferret"
>> #No surprise
>>  xt %>% mean
>> [1] NA
>> Warning message:
>> In mean.default(.) : argument is not numeric or logical: returning NA
>> #surprised!
>> mean(xt[2:3])
>> [1] NA
>> Warning message:
>> In mean.default(xt[2:3]) : argument is not numeric or logical: returning
>> NA
>>  xt[, 2:3] %>% mean
>> [1] NA
>> Warning message:
>> In mean.default(.) : argument is not numeric or logical: returning NA
>>
>> I have a feeling that I'm doing something silly wrong.  Has anyone run
>> into
>> this, please?  I saw something like this on this list, but didn't see a
>> solution.
>>
>> Thanks,
>> Erin
>>
>>
>> Erin Hodgess, PhD
>> mailto: erinm.hodgess at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From tomm@c @ending from nov@@edu  Fri Sep 21 20:17:10 2018
From: tomm@c @ending from nov@@edu (Thomas MacFarland)
Date: Fri, 21 Sep 2018 18:17:10 +0000
Subject: [R] Use ggplot to create a state map with counties and county names
 as labels
Message-ID: <BN3PR0601MB105772455B4C42AD73F96239AF120@BN3PR0601MB1057.namprd06.prod.outlook.com>

Everyone:

Using multiple resources I've been able to create a state (Kentucky) map that shows all 120 counties, with two selected counties highlighted in red.

Fine, except - I also want to show the names of the two selected counties, likely as labels.

Any ideas on how to achieve this aim would be greatly appreciated.

The code shows below.

Best wishes.

Tom

library(ggplot2)
library(ggthemes)
library(ggmap)
library(maps)
library(mapdata)

ls()
rm(list=ls(all=TRUE))
ls()


# U.S. States

states <- map_data("state")
head(states)
str(states)
ky_df <- subset(states, region == "kentucky")
head(ky_df)
str(states)

# U.S. Counties

counties <- map_data("county")
ky_county <- subset(counties, region == "kentucky")
head(ky_county)
str(ky_county)

ky_base <- ggplot2::ggplot(data = ky_df,
  mapping = aes(x = long, y = lat, group = group)) +
coord_fixed(1.3) +
geom_polygon(color = "black", fill = "aliceblue")
par(ask=TRUE); ky_base # Map of Kentucky with no counties, yet

par(ask=TRUE)
ky_base +
geom_polygon(data = ky_county, fill = NA, color = "black") +
geom_polygon(color = "black", fill = NA)  # Map of Kentucky with counties

# Select Pike County and Warren County as subregions
multiple_county_ky <- subset(ky_county, subregion=="pike" | subregion=="warren")

# Create a map with Pike County and Warren County in red
ky_base +
labs(title = "Kentucky Counties of Importance to the Study") +
geom_polygon(data = ky_county, fill = NA, color = "black") +
geom_polygon(color = "black", fill = NA) +
geom_polygon(data = multiple_county_ky, fill = "red", color = "white") +
theme_void()

# But how can I add the county name as a label to the two
# selected counties, Pike County and Warren County?


----------
Thomas W. MacFarland, Ed.D.
Senior Research Associate; Institutional Effectiveness and Associate Professor
Nova Southeastern University
Voice 954-262-5395 tommac at nova.edu<mailto:tommac at nova.edu>


	[[alternative HTML version deleted]]


From jwd @ending from @urewe@t@net  Fri Sep 21 23:19:37 2018
From: jwd @ending from @urewe@t@net (John)
Date: Fri, 21 Sep 2018 14:19:37 -0700
Subject: [R] 
 Use ggplot to create a state map with counties and county names
 as labels
In-Reply-To: <BN3PR0601MB105772455B4C42AD73F96239AF120@BN3PR0601MB1057.namprd06.prod.outlook.com>
References: <BN3PR0601MB105772455B4C42AD73F96239AF120@BN3PR0601MB1057.namprd06.prod.outlook.com>
Message-ID: <20180921141937.1ee00fce@Draco.localdomain>

On Fri, 21 Sep 2018 18:17:10 +0000
Thomas MacFarland <tommac at nova.edu> wrote:

> Everyone:
> 
> Using multiple resources I've been able to create a state (Kentucky)
> map that shows all 120 counties, with two selected counties
> highlighted in red.
> 
> Fine, except - I also want to show the names of the two selected
> counties, likely as labels.
> 
> Any ideas on how to achieve this aim would be greatly appreciated.
> 
> The code shows below.
> 
> Best wishes.
> 
> Tom
You might want to try the ggplot2 group at Google Groups instead.  They
are specifically ggplot2.

JWDougherty


From eyibum+658k2q6uzl4qg m@ili@g off guerrill@m@il@com  Fri Sep 21 19:58:50 2018
From: eyibum+658k2q6uzl4qg m@ili@g off guerrill@m@il@com (eyibum+658k2q6uzl4qg m@ili@g off guerrill@m@il@com)
Date: Fri, 21 Sep 2018 17:58:50 +0000
Subject: [R] =?utf-8?b?UmNtZHIgcHJvYmxlbSByZXR1cm4oUmNtZHIg5ZWP6aGM5Zue?=
 =?utf-8?b?5aCxKQ==?=
Message-ID: <453982ae23baea4548a5c61682b137fef88@guerrillamail.com>

????R????????????R Commander ????????????????Excel???????(???????????)?????????!!(?????????)


??Hello, I am a hobby user of R. I recently used R Commander to select data from the toolbar ? import data ? import into Excel, but I can't import it (and I don't have a screen to choose from), I hope I can improve it soon!!(If you receive it, please reply.)


                                                                    ???????(Problem return user)?JML
                                                                    ????(E-mail)?my9890866 at yahoo.com.tw





----
Sent using Guerrillamail.com
Block or report abuse: https://www.guerrillamail.com//abuse/?a=Uwx8AAEQY4ZYmBy7%2BnscZlrIX80%3D

-------------- next part --------------
A non-text attachment was scrubbed...
Name: =?UTF-8?B?5pyq5ZG95ZCNLnBuZw==?=
Type: image/png
Size: 267789 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180921/18f57a5d/attachment.png>

From m@echler @ending from @t@t@m@th@ethz@ch  Sat Sep 22 10:14:51 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sat, 22 Sep 2018 10:14:51 +0200
Subject: [R] Link from vignette to package documentation
In-Reply-To: <1392b368-3045-36cd-5e03-ff83a0cc95f4@gmail.com>
References: <d9953a1b-8ff6-70ff-e847-d08059f683bb@wiwi.hu-berlin.de>
 <1392b368-3045-36cd-5e03-ff83a0cc95f4@gmail.com>
Message-ID: <23461.63995.924257.175982@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Fri, 21 Sep 2018 05:02:32 -0400 writes:

    > On 21/09/2018 4:54 AM, Sigbert Klinke wrote:
    >> Hi,
    >> 
    >> is it possible to make a link from a vignette to a (Rd)
    >> help files in my own or other packages?

    > Only with some significant compromises.  R normally acts
    > as the web server for Rd files, and the URL is not really
    > predictable.  So you would need to make the URL
    > predictable, either by something like

    > options(help.ports = 12345)

    > (which will put help on port 12345, blocking that port for
    > any other use, including help in another R session), or by
    > putting a static copy of the help pages on some other web
    > server.

    > Duncan Murdoch

Yes, and the other way around -- making working links from
package (*.Rmd or *.Rnw) vignettes to help pages of the same
package is also not easily and portably possible AFAICS.

Both would be desirable quite desirable for improved R
documentation and ideally so in a way that could also work with
an internet connection.

[and if we continue this, it may become more of an issue for
'R-devel' instead of 'R-help' ...]

Martin Maechler


From ph@edru@v @ending from gm@il@com  Sat Sep 22 12:49:02 2018
From: ph@edru@v @ending from gm@il@com (Andrew)
Date: Sat, 22 Sep 2018 11:49:02 +0100
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>
Message-ID: <c226c952-b8f3-3c1a-6c62-5d19530afce6@gmail.com>

Hi Michael

This looks like it could be really helpful in moving my project forwards 
thank you.

I remember many years ago using (proprietary) software from the 
University of Liverpool which did a nice job of allowing regions to be 
defined, and then for the space to be rotated to obtain visual 
inspection of relative distance from different angles. I appreciate that 
smacof will not do that, but as long as the analysis allows for the 
graph to be plotted and analysed, that's what's important.

Thank you again, and to all of those who responded.

Best wishes
Andrew


On 21/09/18 14:07, Michael Friendly wrote:
> Smallest space analysis (SSA) is just the name given to software 
> developed by Guttman & Lingoes around the time the various versions
> of multidimensional scaling were being developed.? Call it Israeli MDS
> or Falafel MDS if you prefer. The reason you encountered it in your
> course is presumably that the instructor was trained in that.
>
> There are several variants of MDS-like algorithms for embedding
> points representing objects in a space, using data representing
> similarities or distances among objects -- metric (cmdscale)
> and non-metric (MASS::isoMDS), using only rank order information, and 
> a variety of
> measures of goodness-of-fit ("stress").? I don't recall the details
> of the SSA programs, but that should matter little conceptually.
>
> The smacof package offers the widest array of possibilities.
>
> -Michael
>
>
> On 9/19/2018 7:00 AM, Andrew wrote:
>> Hi
>>
>> As part of my forensics psych course, we have been introduced to
>> Guttman's smallest space analysis (SSA). I want to explore this approach
>> using R, but despite finding some queries on the web about this same
>> thing, have yet to find any answers. The MASS package doesn't seem to do
>> the job, and the only thing I have been able to find is some proprietary
>> software HUDAP? (Hebrew University Data Analysis Package) which may/ not
>> be compatible with R (or GNU/Linux for that matter).
>>
>> Does anyone have information on how to do SSA using R?
>>
>> Many thanks
>>
>> Andrew
>>
>>
>> ????[[alternative HTML version deleted]]
>>
>
>


From murdoch@dunc@n @ending from gm@il@com  Sat Sep 22 12:49:15 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sat, 22 Sep 2018 06:49:15 -0400
Subject: [R] Link from vignette to package documentation
In-Reply-To: <23461.63995.924257.175982@stat.math.ethz.ch>
References: <d9953a1b-8ff6-70ff-e847-d08059f683bb@wiwi.hu-berlin.de>
 <1392b368-3045-36cd-5e03-ff83a0cc95f4@gmail.com>
 <23461.63995.924257.175982@stat.math.ethz.ch>
Message-ID: <35418624-a144-93be-9dfa-c635eae24be8@gmail.com>

On 22/09/2018 4:14 AM, Martin Maechler wrote:
>>>>>> Duncan Murdoch
>>>>>>      on Fri, 21 Sep 2018 05:02:32 -0400 writes:
> 
>      > On 21/09/2018 4:54 AM, Sigbert Klinke wrote:
>      >> Hi,
>      >>
>      >> is it possible to make a link from a vignette to a (Rd)
>      >> help files in my own or other packages?
> 
>      > Only with some significant compromises.  R normally acts
>      > as the web server for Rd files, and the URL is not really
>      > predictable.  So you would need to make the URL
>      > predictable, either by something like
> 
>      > options(help.ports = 12345)
> 
>      > (which will put help on port 12345, blocking that port for
>      > any other use, including help in another R session), or by
>      > putting a static copy of the help pages on some other web
>      > server.
> 
>      > Duncan Murdoch
> 
> Yes, and the other way around -- making working links from
> package (*.Rmd or *.Rnw) vignettes to help pages of the same
> package is also not easily and portably possible AFAICS.

Actually I was overly pessimistic above.  If both the vignette and the 
help page are being viewed in a web browser, it should be possible using 
relative links.

My rgl package does this:  the "rgl Overview" vignette is written in R 
Markdown and displayed in HTML.  It has links to the help pages.  There 
are some limitations:  the links only work while the same R session is 
running.

To make a link to help topic "points3d", it inserts code that produces 
the anchor

<a href="../../rgl/help/points3d">`points3d`</a>

in the text.  (It should also work to replace the prefix "../../rgl/" 
with just "../", but the longer path allows for links to help pages in 
other packages.)

This won't work if you are looking at the vignette somewhere else (e.g. 
at https://cran.r-project.org/web/packages/rgl/vignettes/rgl.html).

Duncan Murdoch


> 
> Both would be desirable quite desirable for improved R
> documentation and ideally so in a way that could also work with
> an internet connection.
> 
> [and if we continue this, it may become more of an issue for
> 'R-devel' instead of 'R-help' ...]
> 
> Martin Maechler
>


From dwin@emiu@ @ending from comc@@t@net  Sat Sep 22 18:51:25 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sat, 22 Sep 2018 09:51:25 -0700
Subject: [R] as.Date and ylim in empty plot: RESOLVED
In-Reply-To: <CAC8ss31dX7fnhWUXv97z_Fjd4pk8jmfqP1=Gc8ijUvYf1WwvpA@mail.gmail.com>
References: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
 <431EE567-5F41-4638-B31A-F6E7E3E95782@comcast.net>
 <CAC8ss31dX7fnhWUXv97z_Fjd4pk8jmfqP1=Gc8ijUvYf1WwvpA@mail.gmail.com>
Message-ID: <5B38B320-CB43-42D4-88AC-1CB15099C983@comcast.net>


> On Sep 19, 2018, at 10:48 PM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Hi David,
> That's it!!! The outcome is attached.

The explanation for this is that columns that have digits separated by dashes will not be interpreted by R's read.table() as numeric or dates, but rather as the default for text entries:  as R factors. Factors are stored as numbers with an associated attribute that gets used to display the meaning of those numbers. Since the numbers used are integers from 1 to the count of unique items, using the xlim = as.numeric(as.Date(.)) creates values are far outside the range of the factor integers and nothing gets displayed as a result. If you had used range(as.numeric(<factor-variable-name>)) you might have seen something. Whether it was what you wanted to see .... well, that's another matter!

Good luck understanding R factors. Some research centers have adopted a policy of setting the option used by read.table for that behavior with:

options(stringsAsFactors= FALSE)  # can be set in .Rprofile or other "startup" file.

That produces text rather than factors by default and might result in less confusion.

-- 
David.
> 
> Many thanks please.
> 
> Best
> Ogbos
> 
> On Wed, Sep 19, 2018 at 11:34 PM David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Sep 19, 2018, at 7:55 AM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> > 
> > Dear Experts,
> > I generated the plot attached. Every other thing is OK except the black
> > horizontal lines which should appear like points or dots as the coloured
> > ones. I can't understand why.
> > 
> > I tried to change it to look like dots by calling empty plots so that I
> > will add them as points.
> > 
> > Since I have a range of date that can fall any where within 2005, I tried:
> > 
> > plot(1, type="n", xlab="", ylab="",
> > xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")), ylim=c(-.5, -10))
> > 
> > ylim worked fine but xlim instead of appearing like date as indicated on
> > the x-axes of the attached plot, translated to ordinary numbers (12800,
> > 12900,13000, 13100).
> > 
> > All the data is of the same format:
> > 2005-01-04 -2.76105935648091
> > 2005-01-19 -9.60813496025994
> > 2005-01-22 -7.92101965866777
> > 2005-02-19 -1.61308152604905
> > 2005-02-24 -1.51497015807712
> > 2005-05-09 -2.06465797304654
> > 2005-05-11 -1.14840389007051
> > 2005-05-16 -3.85281900888504
> > 2005-06-13 -1.18659683796617
> > 2005-06-17 -3.48787712566258
> > 2005-06-22 -1.14223758296308
> > 2005-07-18 -4.96013018907366
> > 2005-08-03 -1.24313324914368
> > 2005-08-07 -2.96672894841722
> > 2005-08-10 -1.11868063781156
> > 2005-08-25 -1.46453734930983
> > 2005-09-13 -8.00895215754776
> > 2005-09-15 -6.63439065989452
> > 2005-10-13 -2.25054996925846
> > 2005-12-15 -1.08933890547705
> 
> You did not succeed in creating a plot that the rhelp mail server would accept. My guess is that the first column is a factor variable and that you did not use colClasses when doing your data input.
> 
> dd <- read.table(text="2005-01-04 -2.76105935648091
> 2005-01-19 -9.60813496025994
> 2005-01-22 -7.92101965866777
> 2005-02-19 -1.61308152604905
> 2005-02-24 -1.51497015807712
> 2005-05-09 -2.06465797304654
> 2005-05-11 -1.14840389007051
> 2005-05-16 -3.85281900888504
> 2005-06-13 -1.18659683796617
> 2005-06-17 -3.48787712566258
> 2005-06-22 -1.14223758296308
> 2005-07-18 -4.96013018907366
> 2005-08-03 -1.24313324914368
> 2005-08-07 -2.96672894841722
> 2005-08-10 -1.11868063781156
> 2005-08-25 -1.46453734930983
> 2005-09-13 -8.00895215754776
> 2005-09-15 -6.63439065989452
> 2005-10-13 -2.25054996925846
> 2005-12-15 -1.08933890547705", colClasses=c("Date","numeric")
> )
> 
> 
> No problems with:
> 
>  plot(dd[[1]], dd[[2]], xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")))
> 
> 
> (Not a particularly good test of the use of an xlim argument since nothing was excluded.)
> 
> PDF's are accepted. PNGs are not.
> 
> -- 
> David.
> > 
> > Thank you so much for your input.
> > 
> > Best regards
> > Ogbos
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> <Ogbos.pdf>

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From r@herry8 @ending from comc@@t@net  Sat Sep 22 23:16:27 2018
From: r@herry8 @ending from comc@@t@net (rsherry8)
Date: Sat, 22 Sep 2018 17:16:27 -0400
Subject: [R] For Loop
Message-ID: <5BA6B12B.3090606@comcast.net>


It is my impression that good R programmers make very little use of the 
for statement. Please consider  the following
R statement:
         for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
One problem I have found with this statement is that s must exist before 
the statement is run. Can it be written without using a for
loop? Would that be better?

Thanks,
Bob


From bgunter@4567 @ending from gm@il@com  Sat Sep 22 23:42:30 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 22 Sep 2018 14:42:30 -0700
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <CAGxFJbTcO47F11YT8EcPL=f0JytDY8TvPqXFTyESWyURR-FaEA@mail.gmail.com>

Bob:

Please, please spend some time with an R tutorial or two before you post
here. This list can help, but I think we assume that you have already made
an effort to learn basic R on your own. Your question is about as basic as
it gets, so it appears to me that you have not done this. There are many
many R tutorials out there. Some suggestions, by no means comprehensive,
can be found here:
https://www.rstudio.com/online-learning/#r-programming

Others will no doubt respond, but you can answer it yourself after only a
few minutes with most R tutorials.

Cheers,
Bert




On Sat, Sep 22, 2018 at 2:16 PM rsherry8 <rsherry8 at comcast.net> wrote:

>
> It is my impression that good R programmers make very little use of the
> for statement. Please consider  the following
> R statement:
>          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> One problem I have found with this statement is that s must exist before
> the statement is run. Can it be written without using a for
> loop? Would that be better?
>
> Thanks,
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh @ending from temple@edu  Sat Sep 22 23:57:32 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Sat, 22 Sep 2018 17:57:32 -0400
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <CAGx1TMBT53Pj=Ts4TVBiuuu2Ud86ysaLajh6M_6=k3jWdbXJHA@mail.gmail.com>

c1 <- 1:1000000
len <- 1000000
system.time(
s1 <- log(c1[-1]/c1[-len])
)
s <- c1[-len]
system.time(
for (i in 1:(len-1)) s[i] <- log(c1[i+1]/c1[i])
)
all.equal(s,s1)


>
> c1 <- 1:1000000
> len <- 1000000
> system.time(
+ s1 <- log(c1[-1]/c1[-len])
+ )
   user  system elapsed
  0.032   0.005   0.037
> s <- c1[-len]
> system.time(
+ for (i in 1:(len-1)) s[i] <- log(c1[i+1]/c1[i])
+ )
   user  system elapsed
  0.226   0.002   0.232
> all.equal(s,s1)
[1] TRUE
>

much faster, and much easier to understand when vectorized

On Sat, Sep 22, 2018 at 5:16 PM, rsherry8 <rsherry8 at comcast.net> wrote:
>
> It is my impression that good R programmers make very little use of the for
> statement. Please consider  the following
> R statement:
>         for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> One problem I have found with this statement is that s must exist before the
> statement is run. Can it be written without using a for
> loop? Would that be better?
>
> Thanks,
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e@@wiek @ending from gm@il@com  Sun Sep 23 01:22:05 2018
From: e@@wiek @ending from gm@il@com (Ek Esawi)
Date: Sat, 22 Sep 2018 19:22:05 -0400
Subject: [R] error "The system cannot find the file specified..."
Message-ID: <CA+ZkTxuJSPgPL-QWjGOXLP7eRP2HW0DZR7MA4Jc6-VBF0oqbpw@mail.gmail.com>

Hi All,

I am using the R Tabulizer package to extract tables from a set of pdf
files. Tabulizer creates a list of data frames; each corresponds to a
table in a file. My aim is to create a list of lists, one for each
file.i have 8 files
The code below kept giving me the error "Error in
normalizePath(path.expand(path), winslash, mustWork) : path[1]="April
24.PDF": The system cannot find the file specified". But when i used
table_extract (file) for individual files, it works perfectly.

Any help is greatly appreciated.


EK


path = "C:/Users/name/Documents/TextMining/"
file.names <- dir(path, pattern =".PDF")
A <- vector("list", length(file.names))
for(i in 1:length(file.names)){
  A[i] <- extract_tables(file.names[i])}


From bgunter@4567 @ending from gm@il@com  Sun Sep 23 02:45:55 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 22 Sep 2018 17:45:55 -0700
Subject: [R] error "The system cannot find the file specified..."
In-Reply-To: <CA+ZkTxuJSPgPL-QWjGOXLP7eRP2HW0DZR7MA4Jc6-VBF0oqbpw@mail.gmail.com>
References: <CA+ZkTxuJSPgPL-QWjGOXLP7eRP2HW0DZR7MA4Jc6-VBF0oqbpw@mail.gmail.com>
Message-ID: <CAGxFJbRTKwLayx+NkhPvCZyXBTbYNQ85yjO48wmB9kYXZ+G1mA@mail.gmail.com>

You probably want pattern = "\\.PDF" , as "." has a special meaning for
regex's. However, that really shouldn't make any difference.

Obvious questions:
1. dir() returns a vector of file names. Are they pdf's "PDF" or "pdf"
(case matters!) ?
2. extract.tables() almost certainly wants the full path names to the
files, not just the file names, if your working directory isn't set to the
directory containing the files. So what does getwd() give?

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Sep 22, 2018 at 4:22 PM Ek Esawi <esawiek at gmail.com> wrote:

> Hi All,
>
> I am using the R Tabulizer package to extract tables from a set of pdf
> files. Tabulizer creates a list of data frames; each corresponds to a
> table in a file. My aim is to create a list of lists, one for each
> file.i have 8 files
> The code below kept giving me the error "Error in
> normalizePath(path.expand(path), winslash, mustWork) : path[1]="April
> 24.PDF": The system cannot find the file specified". But when i used
> table_extract (file) for individual files, it works perfectly.
>
> Any help is greatly appreciated.
>
>
> EK
>
>
> path = "C:/Users/name/Documents/TextMining/"
> file.names <- dir(path, pattern =".PDF")
> A <- vector("list", length(file.names))
> for(i in 1:length(file.names)){
>   A[i] <- extract_tables(file.names[i])}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From liuwen@ui @ending from gm@il@com  Sun Sep 23 02:53:38 2018
From: liuwen@ui @ending from gm@il@com (Wensui Liu)
Date: Sat, 22 Sep 2018 19:53:38 -0500
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <CAKyN3iA+ZeVatA=O5cz=czDLHvZr60qgWTkgan-zd27Nn+fkBg@mail.gmail.com>

another version just for fun

s <- parallel::pvec(1:len, function(i) log(c1[i + 1] / c1[i]))
On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>
>
> It is my impression that good R programmers make very little use of the
> for statement. Please consider  the following
> R statement:
>          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> One problem I have found with this statement is that s must exist before
> the statement is run. Can it be written without using a for
> loop? Would that be better?
>
> Thanks,
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From liuwen@ui @ending from gm@il@com  Sun Sep 23 02:57:56 2018
From: liuwen@ui @ending from gm@il@com (Wensui Liu)
Date: Sat, 22 Sep 2018 19:57:56 -0500
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>

or this one:

(Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))

On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>
>
> It is my impression that good R programmers make very little use of the
> for statement. Please consider  the following
> R statement:
>          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> One problem I have found with this statement is that s must exist before
> the statement is run. Can it be written without using a for
> loop? Would that be better?
>
> Thanks,
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Sep 23 03:45:52 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 22 Sep 2018 18:45:52 -0700
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <9D7649DE-E0B7-4E6D-8306-544E8C7F95E7@dcn.davis.ca.us>

I do use for loops a few times per month, but only wrapped around large chunks of vectorized calculations, not for this kind of use case. In those cases I also pre-allocate output vectors/lists (e.g. vector( "list", len )) to avoid memory thrashing as you grow lists or other vectors one element at a time (v <- c( v, new value ) is an inefficient trick). I also create variables to hold intermediate results that would yield the same answer each time before going into the loop (e.g. exp(1)).

As regards your toy example, I would use a one-liner:

s <- diff( log( c1 ) )

which avoids executing exp(1) at all, much less every time through the loop, and it uses vectorized incremental subtraction rather than division (laws of logarithms from algebra). The default base for the log function is e, so it is unnecessary to specify it. Note that your loop calculates logs involving all but the first and last elements of c1 twice... once when indexing for i+1, and again in the next iteration of the loop it is accessed as index i.

You would be surprised how many iterative algorithms can be accomplished with cumsum and diff. Bill Dunlap has demonstrated examples quite a few times in the mailing list archives if you have time  to search.

On September 22, 2018 2:16:27 PM PDT, rsherry8 <rsherry8 at comcast.net> wrote:
>
>It is my impression that good R programmers make very little use of the
>
>for statement. Please consider  the following
>R statement:
>       for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>One problem I have found with this statement is that s must exist
>before 
>the statement is run. Can it be written without using a for
>loop? Would that be better?
>
>Thanks,
>Bob
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From f@bi@no@fr@nc@d@ @ending from hotm@il@com  Sun Sep 23 06:26:06 2018
From: f@bi@no@fr@nc@d@ @ending from hotm@il@com (=?iso-8859-1?Q?Fabiano_Fran=E7a?=)
Date: Sun, 23 Sep 2018 04:26:06 +0000
Subject: [R] How to adjust the regression script R/Rstudio?
Message-ID: <CY4PR13MB0966785A2048D84E3A0B38DD83100@CY4PR13MB0966.namprd13.prod.outlook.com>

Dear, how to set up the equation of the straight line and the R ^ 2, remove the bars of the chart area and the caption to the right?

Follow the attached file containing the data. We used the R version 3.4.4.

library(plotly)
library(ggplot2)


setwd("C:\\Users\\Fabiano\\Desktop\\Artigo OE")
dados <- read.table('IVCM.txt', header =T)

lm_labels <- function(dados) {
  mod <- lm(IVCM ~ Doses, data=dados)
  formula <- sprintf("italic(y) == %.2f %+.2f * italic(x)",
                     round(coef(mod)[1], 2), round(coef(mod)[2], 2))

  r <- cor(dados$Doses, dados$IVCM)
  r2 <- sprintf("italic(R^2) == %.2f", r^2)
  data.frame(formula=formula, r2=r2, stringsAsFactors=FALSE)
}

library(plyr) # For the ddply() function
labels <- ddply(dados, "Fungicidas", lm_labels)
labels

f_labels <- data.frame(Fungicidas = c("?gua", "Frowncide", "Cravo", "Canela", "Capim-Lim?o", "Tomilho"), label = c("H2O", "F500SC", "cv", "Can", "CL", "Tom"))

p <- ggplot(dados, aes(x=Doses, y=IVCM, add = "reg.line", conf.int = TRUE, parse = TRUE)) +
  geom_point(size = .5) +
  facet_wrap(~ Fungicidas) +
  stat_smooth(aes(colour = Fungicidas), add = "loess", method = "lm", formula = y ~ x) +
  geom_text(x=0.6, y=9.5, size = 3, aes(label=formula), data=labels, parse=TRUE, hjust=0) +
  geom_text(x=0.6, y=9, size = 3, aes(label=r2), data=labels, parse=TRUE, hjust=0) +
  theme_bw()



(p=ggplotly(p))

Best regards,

Fabiano Fran?a da Silva
Doutorando em Fitotecnia - ESALQ/USP
MSc Fitotecnia - UFLA
Eng?. Agr?nomo - UFLA
(35) 9 9155-5443 TIM



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: IVCM.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180923/f8e28835/attachment.txt>

From ruipb@rr@d@@ @ending from @@po@pt  Sun Sep 23 11:29:59 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Sun, 23 Sep 2018 10:29:59 +0100
Subject: [R] error "The system cannot find the file specified..."
In-Reply-To: <CAGxFJbRTKwLayx+NkhPvCZyXBTbYNQ85yjO48wmB9kYXZ+G1mA@mail.gmail.com>
References: <CA+ZkTxuJSPgPL-QWjGOXLP7eRP2HW0DZR7MA4Jc6-VBF0oqbpw@mail.gmail.com>
 <CAGxFJbRTKwLayx+NkhPvCZyXBTbYNQ85yjO48wmB9kYXZ+G1mA@mail.gmail.com>
Message-ID: <efc0ee37-e464-3ec3-ba7d-c60575c3e192@sapo.pt>

Hello,

I would add that it's probably better to assign

for(i in seq_along(file.names)){
   A[[i]] <- extract_tables(file.names[i])
}


(It's a list so double [[, not just [).

Hope this helps,

Rui Barradas

?s 01:45 de 23/09/2018, Bert Gunter escreveu:
> for(i in 1:length(file.names)){
>    A[i] <- extract_tables(file.names[i])}


From ericjberger @ending from gm@il@com  Sun Sep 23 12:15:11 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Sun, 23 Sep 2018 13:15:11 +0300
Subject: [R] Packaged exe and Shiny
In-Reply-To: <4C65246C-FDF7-4D4C-9F40-E510D50F9206@dcn.davis.ca.us>
References: <d71e9b46-7a37-4e1c-b6ca-8142baaadbcd@me.com>
 <CA+8X3fUQYVu2zhrd6DDu-a3wP2OVuF0DUBcFvwd5iG-US0x=ZQ@mail.gmail.com>
 <4C65246C-FDF7-4D4C-9F40-E510D50F9206@dcn.davis.ca.us>
Message-ID: <CAGgJW74c3LH2ihEgCWh+mQdEHFGR76GaCBwoEURsZ0F9aTMcAA@mail.gmail.com>

Hi Kevin,
I did something along these lines using shiny and I had a good experience
with it.
You would require a server (virtual or physical) to run the shiny-server
program.
This approach is particularly suitable if your target users do not know (or
use) R.
If you go down this route I also suggest that your server be separate from
your
development machine. This way you can test new functionality and reboot your
development machine as you wish without causing issues for your users.
In my case I created a virtual server so there was no requirement to buy
additional hardware.

HTH,
Eric





On Tue, Sep 11, 2018 at 1:58 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> IMO the best short answer is don't target making an install package or msi
> at all... the obstacles are quite significant. Aim for building most of
> your capabilities in packages and having people install them. You can setup
> an in-house package repo to simplify this and give them a startup script
> that configures their R environment.
>
> There is also the option to use R-Portable [1] but this leads to massive
> deployment files that don't upgrade easily.
>
> I also think that when the time crunch happens many people will go to the
> internet and copy-paste solutions that you would be unlikely to have
> anticipated. Closing off that scary console completely will keep you in the
> hot seat indefinitely, whereas giving them the option to go around your UI
> lets more resources be allocated later.
>
> [1] https://www.r-bloggers.com/deploying-desktop-apps-with-r/amp/
>
> On September 10, 2018 3:17:02 PM PDT, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >Hi Kevin,
> >It might be just as easy to write R scripts that would do basic
> >analyses. Users could "source" these scripts in an R session or from
> >the command line. The scripts would be much more compact than the .exe
> >files that you describe.
> >
> >Jim
> >
> >On Tue, Sep 11, 2018 at 8:06 AM Kevin Kowitski via R-help
> ><r-help at r-project.org> wrote:
> >>
> >> Hey Everyone,
> >>
> >>   I do not know if this topic has been covered, I'm sure it must
> >have, but is there a good environment for packaging R code into a
> >distributed exe. (which includes all of the required libraries, etc.)?
> >I have seen that Shiny is a good GUI / Web library for sharing R
> >programs, but I have never used it.
> >>
> >> What is the groups input on this?
> >>
> >> My goal is to create some basic tools (with interfaces) at work for
> >analyzing .csv files and generating basic graphs and output csv files.
> >These tools would be distributed to team members to have on their
> >desktops.   I considered doing this in Java, but I am more well versed
> >in R so it would be quicker for me to whip up the varying tools in R
> >than re-learning Java.
> >>
> >> Thank you!
> >>
> >> -Kevin
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From i@t@z@hn @ending from gm@il@com  Sun Sep 23 14:53:51 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Sun, 23 Sep 2018 08:53:51 -0400
Subject: [R] For Loop
In-Reply-To: <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
Message-ID: <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>

On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
>
> or this one:
>
> (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))

Oh dear god no.

>
> On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> >
> >
> > It is my impression that good R programmers make very little use of the
> > for statement. Please consider  the following
> > R statement:
> >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> > One problem I have found with this statement is that s must exist before
> > the statement is run. Can it be written without using a for
> > loop? Would that be better?
> >
> > Thanks,
> > Bob
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From friendly @ending from yorku@c@  Sun Sep 23 16:22:58 2018
From: friendly @ending from yorku@c@ (Michael Friendly)
Date: Sun, 23 Sep 2018 10:22:58 -0400
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <c226c952-b8f3-3c1a-6c62-5d19530afce6@gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>
 <c226c952-b8f3-3c1a-6c62-5d19530afce6@gmail.com>
Message-ID: <4d2400ea-28ef-875a-064e-79a0bd7325ac@yorku.ca>

On 9/22/2018 6:49 AM, Andrew wrote:
> Hi Michael
> 
> This looks like it could be really helpful in moving my project forwards 
> thank you.
> 
> I remember many years ago using (proprietary) software from the 
> University of Liverpool which did a nice job of allowing regions to be 
> defined, and then for the space to be rotated to obtain visual 
> inspection of relative distance from different angles. I appreciate that 
> smacof will not do that, but as long as the analysis allows for the 
> graph to be plotted and analysed, that's what's important.

You need not rely on the plots provided directly by a given package.
Just roll your own using standard plotting libraries.
Here is just the first Google hit on "R MDS 3D plot"

http://omnilogia.blogspot.com/2014/05/basic-2d-3d-multi-dimensional-scaling.html

which shows a rotating 3D plot, colored by a grouping variable.  Here is 
another:

http://whatzcookinlab.blogspot.com/2013/05/spinning-3d-mds-plot.html

The vegan and ade4 packages also have a variety of plots and related 
methods.


-Michael

> 
> Thank you again, and to all of those who responded.
> 
> Best wishes
> Andrew
> 
> 
> On 21/09/18 14:07, Michael Friendly wrote:
>> Smallest space analysis (SSA) is just the name given to software 
>> developed by Guttman & Lingoes around the time the various versions
>> of multidimensional scaling were being developed.? Call it Israeli MDS
>> or Falafel MDS if you prefer. The reason you encountered it in your
>> course is presumably that the instructor was trained in that.
>>
>> There are several variants of MDS-like algorithms for embedding
>> points representing objects in a space, using data representing
>> similarities or distances among objects -- metric (cmdscale)
>> and non-metric (MASS::isoMDS), using only rank order information, and 
>> a variety of
>> measures of goodness-of-fit ("stress").? I don't recall the details
>> of the SSA programs, but that should matter little conceptually.
>>
>> The smacof package offers the widest array of possibilities.
>>
>> -Michael
>>
>>
>> On 9/19/2018 7:00 AM, Andrew wrote:
>>> Hi
>>>
>>> As part of my forensics psych course, we have been introduced to
>>> Guttman's smallest space analysis (SSA). I want to explore this approach
>>> using R, but despite finding some queries on the web about this same
>>> thing, have yet to find any answers. The MASS package doesn't seem to do
>>> the job, and the only thing I have been able to find is some proprietary
>>> software HUDAP? (Hebrew University Data Analysis Package) which may/ not
>>> be compatible with R (or GNU/Linux for that matter).
>>>
>>> Does anyone have information on how to do SSA using R?
>>>
>>> Many thanks
>>>
>>> Andrew
>>>
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>
>>
>


From i@t@z@hn @ending from gm@il@com  Sun Sep 23 19:32:50 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Sun, 23 Sep 2018 13:32:50 -0400
Subject: [R] For Loop
In-Reply-To: <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
Message-ID: <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>

On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
>
> Why?

The operations required for this algorithm are vectorized, as are most
operations in R. There is no need to iterate through each element.
Using Vectorize to achieve the iteration is no better than using
*apply or a for-loop, and betrays the same basic lack of insight into
basic principles of programming in R.

And/or, if you want a more practical reason:

> c1 <- 1:1000000
> len <- 1000000
> system.time( s1 <- log(c1[-1]/c1[-len]))
   user  system elapsed
  0.031   0.004   0.035
> system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
   user  system elapsed
  1.258   0.022   1.282

Best,
Ista

>
> On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
>>
>> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
>> >
>> > or this one:
>> >
>> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>
>> Oh dear god no.
>>
>> >
>> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>> > >
>> > >
>> > > It is my impression that good R programmers make very little use of the
>> > > for statement. Please consider  the following
>> > > R statement:
>> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>> > > One problem I have found with this statement is that s must exist before
>> > > the statement is run. Can it be written without using a for
>> > > loop? Would that be better?
>> > >
>> > > Thanks,
>> > > Bob
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From liuwen@ui @ending from gm@il@com  Sun Sep 23 19:46:32 2018
From: liuwen@ui @ending from gm@il@com (Wensui Liu)
Date: Sun, 23 Sep 2018 12:46:32 -0500
Subject: [R] For Loop
In-Reply-To: <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
Message-ID: <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>

actually, by the parallel pvec, the user time is a lot shorter. or did
I somewhere miss your invaluable insight?

> c1 <- 1:1000000
> len <- length(c1)
> rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
                  test replications elapsed relative user.self sys.self
1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
  user.child sys.child
1          0         0
> rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
                                                               test
1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
  replications elapsed relative user.self sys.self user.child sys.child
1          100   9.079        1     2.571    4.138      9.736     8.046
On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
>
> On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
> >
> > Why?
>
> The operations required for this algorithm are vectorized, as are most
> operations in R. There is no need to iterate through each element.
> Using Vectorize to achieve the iteration is no better than using
> *apply or a for-loop, and betrays the same basic lack of insight into
> basic principles of programming in R.
>
> And/or, if you want a more practical reason:
>
> > c1 <- 1:1000000
> > len <- 1000000
> > system.time( s1 <- log(c1[-1]/c1[-len]))
>    user  system elapsed
>   0.031   0.004   0.035
> > system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>    user  system elapsed
>   1.258   0.022   1.282
>
> Best,
> Ista
>
> >
> > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
> >>
> >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
> >> >
> >> > or this one:
> >> >
> >> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> >>
> >> Oh dear god no.
> >>
> >> >
> >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> >> > >
> >> > >
> >> > > It is my impression that good R programmers make very little use of the
> >> > > for statement. Please consider  the following
> >> > > R statement:
> >> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> >> > > One problem I have found with this statement is that s must exist before
> >> > > the statement is run. Can it be written without using a for
> >> > > loop? Would that be better?
> >> > >
> >> > > Thanks,
> >> > > Bob
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.


From i@t@z@hn @ending from gm@il@com  Sun Sep 23 20:18:25 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Sun, 23 Sep 2018 14:18:25 -0400
Subject: [R] For Loop
In-Reply-To: <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
Message-ID: <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>

On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
>
> actually, by the parallel pvec, the user time is a lot shorter. or did
> I somewhere miss your invaluable insight?
>
> > c1 <- 1:1000000
> > len <- length(c1)
> > rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
>                   test replications elapsed relative user.self sys.self
> 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
>   user.child sys.child
> 1          0         0
> > rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
>                                                                test
> 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
>   replications elapsed relative user.self sys.self user.child sys.child
> 1          100   9.079        1     2.571    4.138      9.736     8.046

Your output is mangled in my email, but on my system your pvec
approach takes more than twice as long:

c1 <- 1:1000000
len <- length(c1)
library(parallel)
library(rbenchmark)

regular <- function() log(c1[-1]/c1[-len])
iterate.parallel <- function() {
  pvec(1:(len - 1), mc.cores = 4,
       function(i) log(c1[i + 1] / c1[i]))
}

benchmark(regular(), iterate.parallel(),
          replications = 100,
          columns = c("test", "elapsed", "relative"))
##                 test elapsed relative
## 2 iterate.parallel()   7.517    2.482
## 1          regular()   3.028    1.000

Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
to understand and it runs pretty fast. There is usually no reason to
make it more complicated.
--Ista

> On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
> >
> > On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
> > >
> > > Why?
> >
> > The operations required for this algorithm are vectorized, as are most
> > operations in R. There is no need to iterate through each element.
> > Using Vectorize to achieve the iteration is no better than using
> > *apply or a for-loop, and betrays the same basic lack of insight into
> > basic principles of programming in R.
> >
> > And/or, if you want a more practical reason:
> >
> > > c1 <- 1:1000000
> > > len <- 1000000
> > > system.time( s1 <- log(c1[-1]/c1[-len]))
> >    user  system elapsed
> >   0.031   0.004   0.035
> > > system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> >    user  system elapsed
> >   1.258   0.022   1.282
> >
> > Best,
> > Ista
> >
> > >
> > > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
> > >>
> > >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
> > >> >
> > >> > or this one:
> > >> >
> > >> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > >>
> > >> Oh dear god no.
> > >>
> > >> >
> > >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> > >> > >
> > >> > >
> > >> > > It is my impression that good R programmers make very little use of the
> > >> > > for statement. Please consider  the following
> > >> > > R statement:
> > >> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> > >> > > One problem I have found with this statement is that s must exist before
> > >> > > the statement is run. Can it be written without using a for
> > >> > > loop? Would that be better?
> > >> > >
> > >> > > Thanks,
> > >> > > Bob
> > >> > >
> > >> > > ______________________________________________
> > >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> > > and provide commented, minimal, self-contained, reproducible code.
> > >> >
> > >> > ______________________________________________
> > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> > and provide commented, minimal, self-contained, reproducible code.


From liuwen@ui @ending from gm@il@com  Sun Sep 23 20:26:32 2018
From: liuwen@ui @ending from gm@il@com (Wensui Liu)
Date: Sun, 23 Sep 2018 13:26:32 -0500
Subject: [R] For Loop
In-Reply-To: <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
Message-ID: <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>

what you measures is the "elapsed" time in the default setting. you
might need to take a closer look at the beautiful benchmark() function
and see what time I am talking about.

I just provided tentative solution for the person asking for it  and
believe he has enough wisdom to decide what's best. why bother to
judge others subjectively?
On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>
> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
> >
> > actually, by the parallel pvec, the user time is a lot shorter. or did
> > I somewhere miss your invaluable insight?
> >
> > > c1 <- 1:1000000
> > > len <- length(c1)
> > > rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
> >                   test replications elapsed relative user.self sys.self
> > 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
> >   user.child sys.child
> > 1          0         0
> > > rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
> >                                                                test
> > 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
> >   replications elapsed relative user.self sys.self user.child sys.child
> > 1          100   9.079        1     2.571    4.138      9.736     8.046
>
> Your output is mangled in my email, but on my system your pvec
> approach takes more than twice as long:
>
> c1 <- 1:1000000
> len <- length(c1)
> library(parallel)
> library(rbenchmark)
>
> regular <- function() log(c1[-1]/c1[-len])
> iterate.parallel <- function() {
>   pvec(1:(len - 1), mc.cores = 4,
>        function(i) log(c1[i + 1] / c1[i]))
> }
>
> benchmark(regular(), iterate.parallel(),
>           replications = 100,
>           columns = c("test", "elapsed", "relative"))
> ##                 test elapsed relative
> ## 2 iterate.parallel()   7.517    2.482
> ## 1          regular()   3.028    1.000
>
> Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
> to understand and it runs pretty fast. There is usually no reason to
> make it more complicated.
> --Ista
>
> > On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
> > >
> > > On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
> > > >
> > > > Why?
> > >
> > > The operations required for this algorithm are vectorized, as are most
> > > operations in R. There is no need to iterate through each element.
> > > Using Vectorize to achieve the iteration is no better than using
> > > *apply or a for-loop, and betrays the same basic lack of insight into
> > > basic principles of programming in R.
> > >
> > > And/or, if you want a more practical reason:
> > >
> > > > c1 <- 1:1000000
> > > > len <- 1000000
> > > > system.time( s1 <- log(c1[-1]/c1[-len]))
> > >    user  system elapsed
> > >   0.031   0.004   0.035
> > > > system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > >    user  system elapsed
> > >   1.258   0.022   1.282
> > >
> > > Best,
> > > Ista
> > >
> > > >
> > > > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
> > > >>
> > > >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
> > > >> >
> > > >> > or this one:
> > > >> >
> > > >> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > > >>
> > > >> Oh dear god no.
> > > >>
> > > >> >
> > > >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> > > >> > >
> > > >> > >
> > > >> > > It is my impression that good R programmers make very little use of the
> > > >> > > for statement. Please consider  the following
> > > >> > > R statement:
> > > >> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> > > >> > > One problem I have found with this statement is that s must exist before
> > > >> > > the statement is run. Can it be written without using a for
> > > >> > > loop? Would that be better?
> > > >> > >
> > > >> > > Thanks,
> > > >> > > Bob
> > > >> > >
> > > >> > > ______________________________________________
> > > >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> > > and provide commented, minimal, self-contained, reproducible code.
> > > >> >
> > > >> > ______________________________________________
> > > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> > and provide commented, minimal, self-contained, reproducible code.


From j@orkin @ending from @om@um@ryl@nd@edu  Sun Sep 23 20:36:17 2018
From: j@orkin @ending from @om@um@ryl@nd@edu (Sorkin, John)
Date: Sun, 23 Sep 2018 18:36:17 +0000
Subject: [R] For Loop
In-Reply-To: <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>,
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
Message-ID: <CO2PR03MB2232C408FB8829CCB53C17D5E2100@CO2PR03MB2232.namprd03.prod.outlook.com>

At the risk of asking something fundamental . . . .

does log(c1[-1]/c1[-len]

do the following


(1) use all elements of c and perform the calculation

(2) delete the first element of c and perform the calculation,

(2) delete the first two elements of c and perform the calculation,

 . . .

(n) use only the last element of c and perform the calculation.


Thank you,

John



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Wensui Liu <liuwensui at gmail.com>
Sent: Sunday, September 23, 2018 2:26 PM
To: Ista Zahn
Cc: r-help at r-project.org
Subject: Re: [R] For Loop

CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.



what you measures is the "elapsed" time in the default setting. you
might need to take a closer look at the beautiful benchmark() function
and see what time I am talking about.

I just provided tentative solution for the person asking for it  and
believe he has enough wisdom to decide what's best. why bother to
judge others subjectively?
On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>
> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
> >
> > actually, by the parallel pvec, the user time is a lot shorter. or did
> > I somewhere miss your invaluable insight?
> >
> > > c1 <- 1:1000000
> > > len <- length(c1)
> > > rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
> >                   test replications elapsed relative user.self sys.self
> > 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
> >   user.child sys.child
> > 1          0         0
> > > rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
> >                                                                test
> > 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
> >   replications elapsed relative user.self sys.self user.child sys.child
> > 1          100   9.079        1     2.571    4.138      9.736     8.046
>
> Your output is mangled in my email, but on my system your pvec
> approach takes more than twice as long:
>
> c1 <- 1:1000000
> len <- length(c1)
> library(parallel)
> library(rbenchmark)
>
> regular <- function() log(c1[-1]/c1[-len])
> iterate.parallel <- function() {
>   pvec(1:(len - 1), mc.cores = 4,
>        function(i) log(c1[i + 1] / c1[i]))
> }
>
> benchmark(regular(), iterate.parallel(),
>           replications = 100,
>           columns = c("test", "elapsed", "relative"))
> ##                 test elapsed relative
> ## 2 iterate.parallel()   7.517    2.482
> ## 1          regular()   3.028    1.000
>
> Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
> to understand and it runs pretty fast. There is usually no reason to
> make it more complicated.
> --Ista
>
> > On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
> > >
> > > On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
> > > >
> > > > Why?
> > >
> > > The operations required for this algorithm are vectorized, as are most
> > > operations in R. There is no need to iterate through each element.
> > > Using Vectorize to achieve the iteration is no better than using
> > > *apply or a for-loop, and betrays the same basic lack of insight into
> > > basic principles of programming in R.
> > >
> > > And/or, if you want a more practical reason:
> > >
> > > > c1 <- 1:1000000
> > > > len <- 1000000
> > > > system.time( s1 <- log(c1[-1]/c1[-len]))
> > >    user  system elapsed
> > >   0.031   0.004   0.035
> > > > system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > >    user  system elapsed
> > >   1.258   0.022   1.282
> > >
> > > Best,
> > > Ista
> > >
> > > >
> > > > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
> > > >>
> > > >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
> > > >> >
> > > >> > or this one:
> > > >> >
> > > >> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > > >>
> > > >> Oh dear god no.
> > > >>
> > > >> >
> > > >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> > > >> > >
> > > >> > >
> > > >> > > It is my impression that good R programmers make very little use of the
> > > >> > > for statement. Please consider  the following
> > > >> > > R statement:
> > > >> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> > > >> > > One problem I have found with this statement is that s must exist before
> > > >> > > the statement is run. Can it be written without using a for
> > > >> > > loop? Would that be better?
> > > >> > >
> > > >> > > Thanks,
> > > >> > > Bob
> > > >> > >
> > > >> > > ______________________________________________
> > > >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> > > and provide commented, minimal, self-contained, reproducible code.
> > > >> >
> > > >> > ______________________________________________
> > > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> > and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Sun Sep 23 20:48:52 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sun, 23 Sep 2018 14:48:52 -0400
Subject: [R] For Loop
In-Reply-To: <CO2PR03MB2232C408FB8829CCB53C17D5E2100@CO2PR03MB2232.namprd03.prod.outlook.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <CO2PR03MB2232C408FB8829CCB53C17D5E2100@CO2PR03MB2232.namprd03.prod.outlook.com>
Message-ID: <bcbc32e2-bd01-51d0-c2d1-38d08d442f38@gmail.com>

On 23/09/2018 2:36 PM, Sorkin, John wrote:
> At the risk of asking something fundamental . . . .
> 
> does log(c1[-1]/c1[-len]
> 
> do the following
> 
> 
> (1) use all elements of c and perform the calculation
> 
> (2) delete the first element of c and perform the calculation,
> 
> (2) delete the first two elements of c and perform the calculation,
> 
>   . . .
> 
> (n) use only the last element of c and perform the calculation.

c1[-1] creates a new vector which is a copy of c1 leaving out element 1, 
and c1[-len] creates a new vector which copies everything except element 
len.  So your (1) is closest to the truth.

It is very similar to (but probably a little faster than)

log(c1[2:len]/c1[1:(len-1)])

There are differences in borderline cases (like length(c1) != len, or 
len < 2) that are not relevant in the original context.

Duncan Murdoch
> 
> 
> Thank you,
> 
> John
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> 
> ________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Wensui Liu <liuwensui at gmail.com>
> Sent: Sunday, September 23, 2018 2:26 PM
> To: Ista Zahn
> Cc: r-help at r-project.org
> Subject: Re: [R] For Loop
> 
> CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.
> 
> 
> 
> what you measures is the "elapsed" time in the default setting. you
> might need to take a closer look at the beautiful benchmark() function
> and see what time I am talking about.
> 
> I just provided tentative solution for the person asking for it  and
> believe he has enough wisdom to decide what's best. why bother to
> judge others subjectively?
> On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>>
>> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>
>>> actually, by the parallel pvec, the user time is a lot shorter. or did
>>> I somewhere miss your invaluable insight?
>>>
>>>> c1 <- 1:1000000
>>>> len <- length(c1)
>>>> rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
>>>                    test replications elapsed relative user.self sys.self
>>> 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
>>>    user.child sys.child
>>> 1          0         0
>>>> rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
>>>                                                                 test
>>> 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
>>>    replications elapsed relative user.self sys.self user.child sys.child
>>> 1          100   9.079        1     2.571    4.138      9.736     8.046
>>
>> Your output is mangled in my email, but on my system your pvec
>> approach takes more than twice as long:
>>
>> c1 <- 1:1000000
>> len <- length(c1)
>> library(parallel)
>> library(rbenchmark)
>>
>> regular <- function() log(c1[-1]/c1[-len])
>> iterate.parallel <- function() {
>>    pvec(1:(len - 1), mc.cores = 4,
>>         function(i) log(c1[i + 1] / c1[i]))
>> }
>>
>> benchmark(regular(), iterate.parallel(),
>>            replications = 100,
>>            columns = c("test", "elapsed", "relative"))
>> ##                 test elapsed relative
>> ## 2 iterate.parallel()   7.517    2.482
>> ## 1          regular()   3.028    1.000
>>
>> Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
>> to understand and it runs pretty fast. There is usually no reason to
>> make it more complicated.
>> --Ista
>>
>>> On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
>>>>
>>>> On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>
>>>>> Why?
>>>>
>>>> The operations required for this algorithm are vectorized, as are most
>>>> operations in R. There is no need to iterate through each element.
>>>> Using Vectorize to achieve the iteration is no better than using
>>>> *apply or a for-loop, and betrays the same basic lack of insight into
>>>> basic principles of programming in R.
>>>>
>>>> And/or, if you want a more practical reason:
>>>>
>>>>> c1 <- 1:1000000
>>>>> len <- 1000000
>>>>> system.time( s1 <- log(c1[-1]/c1[-len]))
>>>>     user  system elapsed
>>>>    0.031   0.004   0.035
>>>>> system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>     user  system elapsed
>>>>    1.258   0.022   1.282
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>>>
>>>>> On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
>>>>>>
>>>>>> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>>>
>>>>>>> or this one:
>>>>>>>
>>>>>>> (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>>>
>>>>>> Oh dear god no.
>>>>>>
>>>>>>>
>>>>>>> On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>> It is my impression that good R programmers make very little use of the
>>>>>>>> for statement. Please consider  the following
>>>>>>>> R statement:
>>>>>>>>           for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>>>>>>>> One problem I have found with this statement is that s must exist before
>>>>>>>> the statement is run. Can it be written without using a for
>>>>>>>> loop? Would that be better?
>>>>>>>>
>>>>>>>> Thanks,
>>>>>>>> Bob
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Sep 23 20:58:27 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 23 Sep 2018 11:58:27 -0700 (PDT)
Subject: [R] For Loop
In-Reply-To: <CO2PR03MB2232C408FB8829CCB53C17D5E2100@CO2PR03MB2232.namprd03.prod.outlook.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>,
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <CO2PR03MB2232C408FB8829CCB53C17D5E2100@CO2PR03MB2232.namprd03.prod.outlook.com>
Message-ID: <alpine.BSF.2.00.1809231147110.94794@pedal.dcn.davis.ca.us>

Below...

On Sun, 23 Sep 2018, Sorkin, John wrote:

> At the risk of asking something fundamental . . . .
>
> does log(c1[-1]/c1[-len]

You dropped the closing parenthesis.

log( c1[-1] / c1[-len] )

>
> do the following
>
>
> (1) use all elements of c and perform the calculation

No. a) "c" is the base "concatenate" function, and b) it is using two 
different subsets of the elements in c1.

> (2) delete the first element of c and perform the calculation,

It does not change c1. c1[-1] is an expression that creates an entirely 
new (but unnamed) vector that contains everything but the first element of 
c1.

> (2) delete the first two elements of c and perform the calculation,

You are wandering into the weeds here...

> . . .
>
> (n) use only the last element of c and perform the calculation.

No, c1[-len] creates a temporary array that contains all elements except 
the one(s) in the variable "len".  Note that the more conventional syntax 
here is c1[ length(c1) ].

c1 <- 1:3
c1[ -1 ]
#> [1] 2 3
c1[ -length(c1) ]
#> [1] 1 2
c1[ -1 ] / c1[ -length( c1 ) ] # c(2,3)/c(1,2)
#> [1] 2.0 1.5
log( c1[ -1 ] / c1[ -length( c1 ) ] ) # log( c(2, 1.5) )
#> [1] 0.6931472 0.4054651

#' Created on 2018-09-23 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).

>
>
> Thank you,
>
> John
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
> ________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Wensui Liu <liuwensui at gmail.com>
> Sent: Sunday, September 23, 2018 2:26 PM
> To: Ista Zahn
> Cc: r-help at r-project.org
> Subject: Re: [R] For Loop
>
> CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.
>
>
>
> what you measures is the "elapsed" time in the default setting. you
> might need to take a closer look at the beautiful benchmark() function
> and see what time I am talking about.
>
> I just provided tentative solution for the person asking for it  and
> believe he has enough wisdom to decide what's best. why bother to
> judge others subjectively?
> On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>>
>> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>
>>> actually, by the parallel pvec, the user time is a lot shorter. or did
>>> I somewhere miss your invaluable insight?
>>>
>>>> c1 <- 1:1000000
>>>> len <- length(c1)
>>>> rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
>>>                   test replications elapsed relative user.self sys.self
>>> 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
>>>   user.child sys.child
>>> 1          0         0
>>>> rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
>>>                                                                test
>>> 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
>>>   replications elapsed relative user.self sys.self user.child sys.child
>>> 1          100   9.079        1     2.571    4.138      9.736     8.046
>>
>> Your output is mangled in my email, but on my system your pvec
>> approach takes more than twice as long:
>>
>> c1 <- 1:1000000
>> len <- length(c1)
>> library(parallel)
>> library(rbenchmark)
>>
>> regular <- function() log(c1[-1]/c1[-len])
>> iterate.parallel <- function() {
>>   pvec(1:(len - 1), mc.cores = 4,
>>        function(i) log(c1[i + 1] / c1[i]))
>> }
>>
>> benchmark(regular(), iterate.parallel(),
>>           replications = 100,
>>           columns = c("test", "elapsed", "relative"))
>> ##                 test elapsed relative
>> ## 2 iterate.parallel()   7.517    2.482
>> ## 1          regular()   3.028    1.000
>>
>> Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
>> to understand and it runs pretty fast. There is usually no reason to
>> make it more complicated.
>> --Ista
>>
>>> On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
>>>>
>>>> On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>
>>>>> Why?
>>>>
>>>> The operations required for this algorithm are vectorized, as are most
>>>> operations in R. There is no need to iterate through each element.
>>>> Using Vectorize to achieve the iteration is no better than using
>>>> *apply or a for-loop, and betrays the same basic lack of insight into
>>>> basic principles of programming in R.
>>>>
>>>> And/or, if you want a more practical reason:
>>>>
>>>>> c1 <- 1:1000000
>>>>> len <- 1000000
>>>>> system.time( s1 <- log(c1[-1]/c1[-len]))
>>>>    user  system elapsed
>>>>   0.031   0.004   0.035
>>>>> system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>    user  system elapsed
>>>>   1.258   0.022   1.282
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>>>
>>>>> On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
>>>>>>
>>>>>> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>>>
>>>>>>> or this one:
>>>>>>>
>>>>>>> (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>>>
>>>>>> Oh dear god no.
>>>>>>
>>>>>>>
>>>>>>> On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>> It is my impression that good R programmers make very little use of the
>>>>>>>> for statement. Please consider  the following
>>>>>>>> R statement:
>>>>>>>>          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>>>>>>>> One problem I have found with this statement is that s must exist before
>>>>>>>> the statement is run. Can it be written without using a for
>>>>>>>> loop? Would that be better?
>>>>>>>>
>>>>>>>> Thanks,
>>>>>>>> Bob
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From i@t@z@hn @ending from gm@il@com  Sun Sep 23 21:13:06 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Sun, 23 Sep 2018 15:13:06 -0400
Subject: [R] For Loop
In-Reply-To: <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
Message-ID: <CA+vqiLF9mb5+Da4kPzm3i4ZhYdc8Dav7WrND3kxhBnj=hQ1HcQ@mail.gmail.com>

On Sun, Sep 23, 2018 at 2:26 PM Wensui Liu <liuwensui at gmail.com> wrote:
>
> what you measures is the "elapsed" time in the default setting. you
> might need to take a closer look at the beautiful benchmark() function
> and see what time I am talking about.

I'm pretty sure you do not know what you are talking about.

>
> I just provided tentative solution for the person asking for it  and
> believe he has enough wisdom to decide what's best. why bother to
> judge others subjectively?

You are giving bad and confused advice. Please stop doing that.

--Ista

> On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
> >
> > On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
> > >
> > > actually, by the parallel pvec, the user time is a lot shorter. or did
> > > I somewhere miss your invaluable insight?
> > >
> > > > c1 <- 1:1000000
> > > > len <- length(c1)
> > > > rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
> > >                   test replications elapsed relative user.self sys.self
> > > 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
> > >   user.child sys.child
> > > 1          0         0
> > > > rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
> > >                                                                test
> > > 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
> > >   replications elapsed relative user.self sys.self user.child sys.child
> > > 1          100   9.079        1     2.571    4.138      9.736     8.046
> >
> > Your output is mangled in my email, but on my system your pvec
> > approach takes more than twice as long:
> >
> > c1 <- 1:1000000
> > len <- length(c1)
> > library(parallel)
> > library(rbenchmark)
> >
> > regular <- function() log(c1[-1]/c1[-len])
> > iterate.parallel <- function() {
> >   pvec(1:(len - 1), mc.cores = 4,
> >        function(i) log(c1[i + 1] / c1[i]))
> > }
> >
> > benchmark(regular(), iterate.parallel(),
> >           replications = 100,
> >           columns = c("test", "elapsed", "relative"))
> > ##                 test elapsed relative
> > ## 2 iterate.parallel()   7.517    2.482
> > ## 1          regular()   3.028    1.000
> >
> > Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
> > to understand and it runs pretty fast. There is usually no reason to
> > make it more complicated.
> > --Ista
> >
> > > On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
> > > >
> > > > On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
> > > > >
> > > > > Why?
> > > >
> > > > The operations required for this algorithm are vectorized, as are most
> > > > operations in R. There is no need to iterate through each element.
> > > > Using Vectorize to achieve the iteration is no better than using
> > > > *apply or a for-loop, and betrays the same basic lack of insight into
> > > > basic principles of programming in R.
> > > >
> > > > And/or, if you want a more practical reason:
> > > >
> > > > > c1 <- 1:1000000
> > > > > len <- 1000000
> > > > > system.time( s1 <- log(c1[-1]/c1[-len]))
> > > >    user  system elapsed
> > > >   0.031   0.004   0.035
> > > > > system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > > >    user  system elapsed
> > > >   1.258   0.022   1.282
> > > >
> > > > Best,
> > > > Ista
> > > >
> > > > >
> > > > > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
> > > > >>
> > > > >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
> > > > >> >
> > > > >> > or this one:
> > > > >> >
> > > > >> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > > > >>
> > > > >> Oh dear god no.
> > > > >>
> > > > >> >
> > > > >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> > > > >> > >
> > > > >> > >
> > > > >> > > It is my impression that good R programmers make very little use of the
> > > > >> > > for statement. Please consider  the following
> > > > >> > > R statement:
> > > > >> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> > > > >> > > One problem I have found with this statement is that s must exist before
> > > > >> > > the statement is run. Can it be written without using a for
> > > > >> > > loop? Would that be better?
> > > > >> > >
> > > > >> > > Thanks,
> > > > >> > > Bob
> > > > >> > >
> > > > >> > > ______________________________________________
> > > > >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > >> > > and provide commented, minimal, self-contained, reproducible code.
> > > > >> >
> > > > >> > ______________________________________________
> > > > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > >> > and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Sep 23 21:31:50 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 23 Sep 2018 12:31:50 -0700 (PDT)
Subject: [R] For Loop
In-Reply-To: <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>

On Sun, 23 Sep 2018, Wensui Liu wrote:

> what you measures is the "elapsed" time in the default setting. you
> might need to take a closer look at the beautiful benchmark() function
> and see what time I am talking about.

When I am waiting for the answer, elapsed time is what matters to me. 
Also, since each person usually has different hardware, running benchmark 
with multiple expressions as Ista did lets you pay attention to relative 
comparisons.

Keep in mind that parallel processing requires extra time just to 
distribute the calculations to the workers, so it doesn't pay to 
distribute tiny tasks like calculating the division of two numeric vector 
elements. That is the essence of vectorizing... bundle your simple 
calculations together so the processor can focus on getting answers rather 
than managing processes or even interpreting R for loops.

> I just provided tentative solution for the person asking for it  and
> believe he has enough wisdom to decide what's best. why bother to
> judge others subjectively?

I would say that Ista has backed up his objections with measurable 
performance metrics, so while his initial reaction was pretty subjective I 
think your reaction at this point is really off the mark.

One confusing aspect of your response is that Ista reacted to your 
use of the Vectorize function, but you responded as though he reacted 
to your use of the pvec function. I mentioned drawbacks of using pvec 
above, but it really is important to stress that the Vectorize function is 
a usability facade and is in no way a performance enhancement to be 
associated with what we refer to as vectorized (lowercase) code.

The Vectorize function creates a function that calls lapply, which in turn 
calls the C function do_lapply, which calls your R function with scalar 
inputs as many times as desired, storing the results in a list, which 
Vectorize then gives to mapply which runs another for loop over to create 
a matrix or vector result. This is clearly less efficient than a simple 
for loop would have been, rather than more efficient as a true vectorized 
solution such as log(c1[-1]/c1[-len]) will normally be. Vectorize is 
syntactic sugar with a performance penalty.

Please pay attention to the comments offered by others on this list... 
being told your solution is inferior doesn't feel good but it is a very 
real opportunity for you to improve.

End comment.

> On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>>
>> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>
>>> actually, by the parallel pvec, the user time is a lot shorter. or did
>>> I somewhere miss your invaluable insight?
>>>
>>>> c1 <- 1:1000000
>>>> len <- length(c1)
>>>> rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
>>>                   test replications elapsed relative user.self sys.self
>>> 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
>>>   user.child sys.child
>>> 1          0         0
>>>> rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
>>>                                                                test
>>> 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
>>>   replications elapsed relative user.self sys.self user.child sys.child
>>> 1          100   9.079        1     2.571    4.138      9.736     8.046
>>
>> Your output is mangled in my email, but on my system your pvec
>> approach takes more than twice as long:
>>
>> c1 <- 1:1000000
>> len <- length(c1)
>> library(parallel)
>> library(rbenchmark)
>>
>> regular <- function() log(c1[-1]/c1[-len])
>> iterate.parallel <- function() {
>>   pvec(1:(len - 1), mc.cores = 4,
>>        function(i) log(c1[i + 1] / c1[i]))
>> }
>>
>> benchmark(regular(), iterate.parallel(),
>>           replications = 100,
>>           columns = c("test", "elapsed", "relative"))
>> ##                 test elapsed relative
>> ## 2 iterate.parallel()   7.517    2.482
>> ## 1          regular()   3.028    1.000
>>
>> Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
>> to understand and it runs pretty fast. There is usually no reason to
>> make it more complicated.
>> --Ista
>>
>>> On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
>>>>
>>>> On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>
>>>>> Why?
>>>>
>>>> The operations required for this algorithm are vectorized, as are most
>>>> operations in R. There is no need to iterate through each element.
>>>> Using Vectorize to achieve the iteration is no better than using
>>>> *apply or a for-loop, and betrays the same basic lack of insight into
>>>> basic principles of programming in R.
>>>>
>>>> And/or, if you want a more practical reason:
>>>>
>>>>> c1 <- 1:1000000
>>>>> len <- 1000000
>>>>> system.time( s1 <- log(c1[-1]/c1[-len]))
>>>>    user  system elapsed
>>>>   0.031   0.004   0.035
>>>>> system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>    user  system elapsed
>>>>   1.258   0.022   1.282
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>>>
>>>>> On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
>>>>>>
>>>>>> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>>>
>>>>>>> or this one:
>>>>>>>
>>>>>>> (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>>>
>>>>>> Oh dear god no.
>>>>>>
>>>>>>>
>>>>>>> On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>> It is my impression that good R programmers make very little use of the
>>>>>>>> for statement. Please consider  the following
>>>>>>>> R statement:
>>>>>>>>          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>>>>>>>> One problem I have found with this statement is that s must exist before
>>>>>>>> the statement is run. Can it be written without using a for
>>>>>>>> loop? Would that be better?
>>>>>>>>
>>>>>>>> Thanks,
>>>>>>>> Bob
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From murdoch@dunc@n @ending from gm@il@com  Sun Sep 23 21:42:28 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sun, 23 Sep 2018 15:42:28 -0400
Subject: [R] For Loop
In-Reply-To: <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
Message-ID: <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>

On 23/09/2018 3:31 PM, Jeff Newmiller wrote:

[lots of good stuff deleted]

> Vectorize is
> syntactic sugar with a performance penalty.

[More deletions.]

I would say Vectorize isn't just "syntactic sugar".  When I use that 
term, I mean something that looks nice but is functionally equivalent.

However, Vectorize() really does something useful:  some functions (e.g. 
outer()) take other functions as arguments, but they assume the argument 
is a vectorized function.  If it is not, they fail, or generate garbage 
results.  Vectorize() is designed to modify the interface to a function 
so it acts as if it is vectorized.

The "performance penalty" part of your statement is true.  It will 
generally save some computing cycles to write a new function using a for 
loop instead of using Vectorize().  But that may waste some programmer time.

Duncan Murdoch
(writing as one of the authors of Vectorize())

P.S. I'd give an example of syntactic sugar, but I don't want to bruise 
some other author's feelings :-).


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Sep 23 22:03:42 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 23 Sep 2018 13:03:42 -0700 (PDT)
Subject: [R] For Loop
In-Reply-To: <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
 <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
Message-ID: <alpine.BSF.2.00.1809231250390.94794@pedal.dcn.davis.ca.us>

On Sun, 23 Sep 2018, Duncan Murdoch wrote:

> On 23/09/2018 3:31 PM, Jeff Newmiller wrote:
>
> [lots of good stuff deleted]
>
>> Vectorize is
>> syntactic sugar with a performance penalty.
>
> [More deletions.]
>
> I would say Vectorize isn't just "syntactic sugar".  When I use that term, I 
> mean something that looks nice but is functionally equivalent.
>
> However, Vectorize() really does something useful:  some functions (e.g. 
> outer()) take other functions as arguments, but they assume the argument is a 
> vectorized function.  If it is not, they fail, or generate garbage results. 
> Vectorize() is designed to modify the interface to a function so it acts as 
> if it is vectorized.
>
> The "performance penalty" part of your statement is true.  It will generally 
> save some computing cycles to write a new function using a for loop instead 
> of using Vectorize().  But that may waste some programmer time.
>
> Duncan Murdoch
> (writing as one of the authors of Vectorize())
>
> P.S. I'd give an example of syntactic sugar, but I don't want to bruise some 
> other author's feelings :-).

Perhaps my writing needs some syntactic sugar: inefficient looping 
algorithms can make sense when the calculations performed in each 
iteration are long and/or involve large amounts of data. As I mentioned 
earlier in this thread I use for loops fairly often, and I use other 
inefficient syntactic sugar as well but only to organize large 
blocks of already-vectorized (lowercase) calculation units.

In addition to the potential for inefficient use of programmer time, 
vectorizing code increases the maximum amount of memory used during 
execution of your program. A for loop is one simple way to allow memory 
re-use so really large problems can be solved with limited resources, and 
some syntactic sugar such as Vectorize can make it easier to keep track of 
those for loops.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From liuwen@ui @ending from gm@il@com  Sun Sep 23 22:00:09 2018
From: liuwen@ui @ending from gm@il@com (Wensui Liu)
Date: Sun, 23 Sep 2018 15:00:09 -0500
Subject: [R] For Loop
In-Reply-To: <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
 <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
Message-ID: <CAKyN3iD_nq-TeZWVxwWtFnRp00jTNxESg0arW8v4+VJi72t4mw@mail.gmail.com>

Very insightful. Thanks, Duncan

Based on your opinion, is there any benefit to use the parallelism in the
corporate computing environment where the size of data is far more than
million rows and there are multiple cores in the server.

Actually the practice of going concurrency or not is more related to my
production tasks instead of something academic.

Really appreciate your thoughts.

On Sun, Sep 23, 2018 at 2:42 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 23/09/2018 3:31 PM, Jeff Newmiller wrote:
>
> [lots of good stuff deleted]
>
> > Vectorize is
> > syntactic sugar with a performance penalty.
>
> [More deletions.]
>
> I would say Vectorize isn't just "syntactic sugar".  When I use that
> term, I mean something that looks nice but is functionally equivalent.
>
> However, Vectorize() really does something useful:  some functions (e.g.
> outer()) take other functions as arguments, but they assume the argument
> is a vectorized function.  If it is not, they fail, or generate garbage
> results.  Vectorize() is designed to modify the interface to a function
> so it acts as if it is vectorized.
>
> The "performance penalty" part of your statement is true.  It will
> generally save some computing cycles to write a new function using a for
> loop instead of using Vectorize().  But that may waste some programmer
> time.
>
> Duncan Murdoch
> (writing as one of the authors of Vectorize())
>
> P.S. I'd give an example of syntactic sugar, but I don't want to bruise
> some other author's feelings :-).
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Sun Sep 23 22:10:57 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sun, 23 Sep 2018 16:10:57 -0400
Subject: [R] For Loop
In-Reply-To: <CAKyN3iD_nq-TeZWVxwWtFnRp00jTNxESg0arW8v4+VJi72t4mw@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
 <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
 <CAKyN3iD_nq-TeZWVxwWtFnRp00jTNxESg0arW8v4+VJi72t4mw@mail.gmail.com>
Message-ID: <54fed059-9e92-304f-a7e6-4a8518f3a7a7@gmail.com>

On 23/09/2018 4:00 PM, Wensui Liu wrote:
> Very insightful. Thanks, Duncan
> 
> Based on your opinion, is there any benefit to use the parallelism in 
> the corporate computing environment where the size of data is far more 
> than million rows and there are multiple cores in the server.

I would say "try it and see".  Sometimes it probably helps a lot, 
sometimes it's probably detrimental.

Duncan Murdoch

P.S. I last worked in a corporate computing environment 40 years ago 
when I was still wet behind the ears, so you'd probably want to ask 
someone else.  However, more recently I worked in an academic 
environment where I learned to say "try it and see" in many different 
ways.  You just got the basic one today.


> 
> Actually the practice of going concurrency or not is more related to my 
> production tasks instead of something academic.
> 
> Really appreciate your thoughts.
> 
> On Sun, Sep 23, 2018 at 2:42 PM Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 23/09/2018 3:31 PM, Jeff Newmiller wrote:
> 
>     [lots of good stuff deleted]
> 
>      > Vectorize is
>      > syntactic sugar with a performance penalty.
> 
>     [More deletions.]
> 
>     I would say Vectorize isn't just "syntactic sugar".? When I use that
>     term, I mean something that looks nice but is functionally equivalent.
> 
>     However, Vectorize() really does something useful:? some functions
>     (e.g.
>     outer()) take other functions as arguments, but they assume the
>     argument
>     is a vectorized function.? If it is not, they fail, or generate garbage
>     results.? Vectorize() is designed to modify the interface to a function
>     so it acts as if it is vectorized.
> 
>     The "performance penalty" part of your statement is true.? It will
>     generally save some computing cycles to write a new function using a
>     for
>     loop instead of using Vectorize().? But that may waste some
>     programmer time.
> 
>     Duncan Murdoch
>     (writing as one of the authors of Vectorize())
> 
>     P.S. I'd give an example of syntactic sugar, but I don't want to bruise
>     some other author's feelings :-).
>


From e@@wiek @ending from gm@il@com  Sun Sep 23 23:06:17 2018
From: e@@wiek @ending from gm@il@com (Ek Esawi)
Date: Sun, 23 Sep 2018 17:06:17 -0400
Subject: [R] error "The system cannot find the file specified..."
In-Reply-To: <efc0ee37-e464-3ec3-ba7d-c60575c3e192@sapo.pt>
References: <CA+ZkTxuJSPgPL-QWjGOXLP7eRP2HW0DZR7MA4Jc6-VBF0oqbpw@mail.gmail.com>
 <CAGxFJbRTKwLayx+NkhPvCZyXBTbYNQ85yjO48wmB9kYXZ+G1mA@mail.gmail.com>
 <efc0ee37-e464-3ec3-ba7d-c60575c3e192@sapo.pt>
Message-ID: <CA+ZkTxs++gXPLzHnyeOOq9wG1xhWauhwpm90EpFBdpuqXgu7Hw@mail.gmail.com>

Thank you Bert and Rui. Everything mentioned on your posts was OK with
the exception of a typo in my original post where [a] was instead
[[a]]. I stumbled one something that stated if i delete the
sub-directory and create it it again might work. In my case once that
was done, it worked.

Thanks again,
EK
On Sun, Sep 23, 2018 at 5:30 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> I would add that it's probably better to assign
>
> for(i in seq_along(file.names)){
>    A[[i]] <- extract_tables(file.names[i])
> }
>
>
> (It's a list so double [[, not just [).
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 01:45 de 23/09/2018, Bert Gunter escreveu:
> > for(i in 1:length(file.names)){
> >    A[i] <- extract_tables(file.names[i])}


From bgunter@4567 @ending from gm@il@com  Sun Sep 23 23:08:59 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 23 Sep 2018 14:08:59 -0700
Subject: [R] For Loop
In-Reply-To: <54fed059-9e92-304f-a7e6-4a8518f3a7a7@gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
 <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
 <CAKyN3iD_nq-TeZWVxwWtFnRp00jTNxESg0arW8v4+VJi72t4mw@mail.gmail.com>
 <54fed059-9e92-304f-a7e6-4a8518f3a7a7@gmail.com>
Message-ID: <CAGxFJbQp3PMvTKV5MFpM-6xWPHE9jXk5CggLzmYXRN7VaSQF1g@mail.gmail.com>

"... I learned to say "try it and see" in many different ways. "

Version 2: *Never* parallelize your computations  .... except when you
should.

;-)

-- Bert



On Sun, Sep 23, 2018 at 1:20 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 23/09/2018 4:00 PM, Wensui Liu wrote:
> > Very insightful. Thanks, Duncan
> >
> > Based on your opinion, is there any benefit to use the parallelism in
> > the corporate computing environment where the size of data is far more
> > than million rows and there are multiple cores in the server.
>
> I would say "try it and see".  Sometimes it probably helps a lot,
> sometimes it's probably detrimental.
>
> Duncan Murdoch
>
> P.S. I last worked in a corporate computing environment 40 years ago
> when I was still wet behind the ears, so you'd probably want to ask
> someone else.  However, more recently I worked in an academic
> environment where I learned to say "try it and see" in many different
> ways.  You just got the basic one today.
>
>
> >
> > Actually the practice of going concurrency or not is more related to my
> > production tasks instead of something academic.
> >
> > Really appreciate your thoughts.
> >
> > On Sun, Sep 23, 2018 at 2:42 PM Duncan Murdoch <murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com>> wrote:
> >
> >     On 23/09/2018 3:31 PM, Jeff Newmiller wrote:
> >
> >     [lots of good stuff deleted]
> >
> >      > Vectorize is
> >      > syntactic sugar with a performance penalty.
> >
> >     [More deletions.]
> >
> >     I would say Vectorize isn't just "syntactic sugar".  When I use that
> >     term, I mean something that looks nice but is functionally
> equivalent.
> >
> >     However, Vectorize() really does something useful:  some functions
> >     (e.g.
> >     outer()) take other functions as arguments, but they assume the
> >     argument
> >     is a vectorized function.  If it is not, they fail, or generate
> garbage
> >     results.  Vectorize() is designed to modify the interface to a
> function
> >     so it acts as if it is vectorized.
> >
> >     The "performance penalty" part of your statement is true.  It will
> >     generally save some computing cycles to write a new function using a
> >     for
> >     loop instead of using Vectorize().  But that may waste some
> >     programmer time.
> >
> >     Duncan Murdoch
> >     (writing as one of the authors of Vectorize())
> >
> >     P.S. I'd give an example of syntactic sugar, but I don't want to
> bruise
> >     some other author's feelings :-).
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From reichm@nj @ending from @bcglob@l@net  Mon Sep 24 00:18:07 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Sun, 23 Sep 2018 17:18:07 -0500
Subject: [R] Consequent  sorting
Message-ID: <000001d4538b$4ebbb130$ec331390$@sbcglobal.net>

r-help Forum

 

I'm using the following code to sort the "right-hand side (rhs, consequent)
of the rules output from the arules packages, which works.  But what I'd
really like is the ability to subset my rules where the rhs = "some item
set"

 

rules_info <-

  data.frame(

    LHS = labels(lhs(rules)), 

    RHS = labels(rhs(rules)),          

    quality(rules)

  )

 

rules_info[ order(rules_info$RHS=), ]

 

For example using my code above I'm able to sort as follow's

 

179  {Cereals,Eggs,Tomatoes,Vinegar}    {Bread} 0.1428571  1.0000000
1.1666667     1

184           {Eggs,Milk,Pork,Sugar}    {Bread} 0.1428571  1.0000000
1.1666667     1

189        {Eggs,Milk,Pork,Tomatoes}    {Bread} 0.1428571  1.0000000
1.1666667     1

1                                 {}  {Cereals} 0.2857143  0.2857143
1.0000000     2

8                          {Vinegar}  {Cereals} 0.1428571  1.0000000
3.5000000     1

15                        {Tomatoes}  {Cereals} 0.1428571  0.5000000
1.7500000     1

17                            {Eggs}  {Cereals} 0.2857143  0.3333333
1.1666667     2

 

But what I'd really like to do is just get (say) {Bread} like .

 

                                 LHS        RHS   support confidence
lift count

179  {Cereals,Eggs,Tomatoes,Vinegar}    {Bread} 0.1428571  1.0000000
1.1666667     1

184           {Eggs,Milk,Pork,Sugar}    {Bread} 0.1428571  1.0000000
1.1666667     1

189        {Eggs,Milk,Pork,Tomatoes}    {Bread} 0.1428571  1.0000000
1.1666667     1

 

Jeff Reichman

 


	[[alternative HTML version deleted]]


From reichm@nj @ending from @bcglob@l@net  Mon Sep 24 01:29:20 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Sun, 23 Sep 2018 18:29:20 -0500
Subject: [R] Consequent  sorting
In-Reply-To: <000001d4538b$4ebbb130$ec331390$@sbcglobal.net>
References: <000001d4538b$4ebbb130$ec331390$@sbcglobal.net>
Message-ID: <000501d45395$41ff7440$c5fe5cc0$@sbcglobal.net>

Never mind.  Working with the arules package notes I was able to figure it
out

rules <- apriori(fp.trans,
                 parameter = list(supp = 0.1, conf = 0.2, target = "rules"),
                 appearance = list(rhs="Sugar", default="lhs"),
                 control = list(verbose=F))
rules.sorted <- sort(rules, by="lift")
inspect(rules.sorted)

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Reichman
Sent: Sunday, September 23, 2018 5:18 PM
To: r-help at r-project.org
Subject: [R] Consequent sorting

r-help Forum

 I'm using the following code to sort the "right-hand side (rhs, consequent)
of the rules output from the arules packages, which works.  But what I'd
really like is the ability to subset my rules where the rhs = "some item
set"


rules_info <-
  data.frame(
    LHS = labels(lhs(rules)), 
    RHS = labels(rhs(rules)),          
    quality(rules)
  )

rules_info[ order(rules_info$RHS=), ]

For example using my code above I'm able to sort as follow's

179  {Cereals,Eggs,Tomatoes,Vinegar}   	{Bread} 0.1428571  1.0000000
1.1666667     1
184           {Eggs,Milk,Pork,Sugar}   	{Bread} 0.1428571  1.0000000
1.1666667     1
189        {Eggs,Milk,Pork,Tomatoes}    	{Bread} 0.1428571  1.0000000
1.1666667     1
1                                 {}  			{Cereals} 0.2857143
0.2857143 1.0000000     2
8                          {Vinegar}  		{Cereals} 0.1428571
1.0000000 3.5000000     1
15                        {Tomatoes} 		{Cereals} 0.1428571
0.5000000 1.7500000     1

But what I'd really like to do is just get (say) {Bread} like .

179  {Cereals,Eggs,Tomatoes,Vinegar}    {Bread} 0.1428571  1.0000000
1.1666667     1
184           {Eggs,Milk,Pork,Sugar}    {Bread} 0.1428571  1.0000000
1.1666667     1
189        {Eggs,Milk,Pork,Tomatoes}    {Bread} 0.1428571  1.0000000
1.1666667     1


Jeff Reichman


______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To
UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ph@edru@v @ending from gm@il@com  Mon Sep 24 15:18:16 2018
From: ph@edru@v @ending from gm@il@com (Andrew)
Date: Mon, 24 Sep 2018 14:18:16 +0100
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <4d2400ea-28ef-875a-064e-79a0bd7325ac@yorku.ca>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>
 <c226c952-b8f3-3c1a-6c62-5d19530afce6@gmail.com>
 <4d2400ea-28ef-875a-064e-79a0bd7325ac@yorku.ca>
Message-ID: <ce6d102d-0ac0-853c-2741-e08a6214381c@gmail.com>

Ha! Even better - thank you. Plenty here for me to play around with.

Many thanks
Andrew


On 23/09/18 15:22, Michael Friendly wrote:
> On 9/22/2018 6:49 AM, Andrew wrote:
>> Hi Michael
>>
>> This looks like it could be really helpful in moving my project 
>> forwards thank you.
>>
>> I remember many years ago using (proprietary) software from the 
>> University of Liverpool which did a nice job of allowing regions to 
>> be defined, and then for the space to be rotated to obtain visual 
>> inspection of relative distance from different angles. I appreciate 
>> that smacof will not do that, but as long as the analysis allows for 
>> the graph to be plotted and analysed, that's what's important.
>
> You need not rely on the plots provided directly by a given package.
> Just roll your own using standard plotting libraries.
> Here is just the first Google hit on "R MDS 3D plot"
>
> http://omnilogia.blogspot.com/2014/05/basic-2d-3d-multi-dimensional-scaling.html 
>
>
> which shows a rotating 3D plot, colored by a grouping variable. Here 
> is another:
>
> http://whatzcookinlab.blogspot.com/2013/05/spinning-3d-mds-plot.html
>
> The vegan and ade4 packages also have a variety of plots and related 
> methods.
>
>
> -Michael
>
>>
>> Thank you again, and to all of those who responded.
>>
>> Best wishes
>> Andrew
>>
>>
>> On 21/09/18 14:07, Michael Friendly wrote:
>>> Smallest space analysis (SSA) is just the name given to software 
>>> developed by Guttman & Lingoes around the time the various versions
>>> of multidimensional scaling were being developed.? Call it Israeli MDS
>>> or Falafel MDS if you prefer. The reason you encountered it in your
>>> course is presumably that the instructor was trained in that.
>>>
>>> There are several variants of MDS-like algorithms for embedding
>>> points representing objects in a space, using data representing
>>> similarities or distances among objects -- metric (cmdscale)
>>> and non-metric (MASS::isoMDS), using only rank order information, 
>>> and a variety of
>>> measures of goodness-of-fit ("stress").? I don't recall the details
>>> of the SSA programs, but that should matter little conceptually.
>>>
>>> The smacof package offers the widest array of possibilities.
>>>
>>> -Michael
>>>
>>>
>>> On 9/19/2018 7:00 AM, Andrew wrote:
>>>> Hi
>>>>
>>>> As part of my forensics psych course, we have been introduced to
>>>> Guttman's smallest space analysis (SSA). I want to explore this 
>>>> approach
>>>> using R, but despite finding some queries on the web about this same
>>>> thing, have yet to find any answers. The MASS package doesn't seem 
>>>> to do
>>>> the job, and the only thing I have been able to find is some 
>>>> proprietary
>>>> software HUDAP? (Hebrew University Data Analysis Package) which 
>>>> may/ not
>>>> be compatible with R (or GNU/Linux for that matter).
>>>>
>>>> Does anyone have information on how to do SSA using R?
>>>>
>>>> Many thanks
>>>>
>>>> Andrew
>>>>
>>>>
>>>> ????[[alternative HTML version deleted]]
>>>>
>>>
>>>
>>
>
>


From jo@ecl@udio@f@ri@ @ending from gm@il@com  Mon Sep 24 16:32:19 2018
From: jo@ecl@udio@f@ri@ @ending from gm@il@com (Jose Claudio Faria)
Date: Mon, 24 Sep 2018 11:32:19 -0300
Subject: [R] cut{base}: is it a bug?
Message-ID: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>

Dears members,

Is the below a bug of the cut {base} function?

dat <- c(
 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
 )

# making class from function "cut"
(f <- cut(dat,
          breaks= seq(from=.6, to=2.2, by=.2),
          include.lowest=TRUE,
          dig.lab=10L,
          right=FALSE))

# more easy to see the table
as.matrix(tb <- table(f))

# Checking
print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]

Best,
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
55(73)98817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms;
if you have good software, you have arms and legs;
if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Mon Sep 24 17:14:09 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Mon, 24 Sep 2018 15:14:09 +0000
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
Message-ID: <a73f82dbede144399b2376a1b5e27f44@tamu.edu>

You've been bitten by FAQ 7.31: Why doesn't R think these numbers are equal?
https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

Your boundaries and your data values are not what you think they are. This is a limitation of digital computing not R.

> print(seq(from=.6, to=2.2, by=.2), digits=17)
[1] 0.59999999999999998 0.80000000000000004 1.00000000000000000 1.20000000000000018
[5] 1.39999999999999991 1.60000000000000009 1.80000000000000027 2.00000000000000000
[9] 2.20000000000000018

> print(dat, digits=17)
 [1] 0.59999999999999998 0.59999999999999998 0.59999999999999998 0.69999999999999996
 [5] 0.69999999999999996 0.69999999999999996 0.69999999999999996 0.69999999999999996
 [9] 0.80000000000000004 0.80000000000000004 0.80000000000000004 0.90000000000000002
[13] 0.90000000000000002 0.90000000000000002 0.90000000000000002 1.00000000000000000
[17] 1.00000000000000000 1.00000000000000000 1.00000000000000000 1.10000000000000009
[21] 1.10000000000000009 1.10000000000000009 1.19999999999999996 1.19999999999999996
[25] 1.19999999999999996 1.19999999999999996 1.30000000000000004 1.30000000000000004
[29] 1.30000000000000004 1.39999999999999991 1.39999999999999991 1.39999999999999991
[33] 1.50000000000000000 1.50000000000000000 1.50000000000000000 1.60000000000000009
[37] 1.60000000000000009 1.69999999999999996 1.69999999999999996 1.69999999999999996
[41] 1.69999999999999996 1.80000000000000004 1.80000000000000004 1.80000000000000004
[45] 1.89999999999999991 1.89999999999999991 2.00000000000000000 2.00000000000000000
[49] 2.00000000000000000 2.00000000000000000 2.00000000000000000 2.10000000000000009

The simplest solution is to subtract a bit. This also means you don't need the include.lowest= or right= arguments:

> f <- cut(dat,
+           breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
+           dig.lab=10L)
> as.matrix(tb <- table(f))
            [,1]
[0.59,0.79)    8
[0.79,0.99)    7
[0.99,1.19)    7
[1.19,1.39)    7
[1.39,1.59)    6
[1.59,1.79)    6
[1.79,1.99)    5
[1.99,2.19]    6

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jose Claudio Faria
Sent: Monday, September 24, 2018 9:32 AM
To: r-help at r-project.org
Subject: [R] cut{base}: is it a bug?

Dears members,

Is the below a bug of the cut {base} function?

dat <- c(
 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
 )

# making class from function "cut"
(f <- cut(dat,
          breaks= seq(from=.6, to=2.2, by=.2),
          include.lowest=TRUE,
          dig.lab=10L,
          right=FALSE))

# more easy to see the table
as.matrix(tb <- table(f))

# Checking
print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1] print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2] print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5] print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]

Best,
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
55(73)98817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms; if you have good software, you have arms and legs; if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Sep 24 17:40:32 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 24 Sep 2018 08:40:32 -0700
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
 <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
Message-ID: <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>

"Subtracting a bit" only fixes the problem for the test data... it introduces a bias in any continuous data you happen to throw at it. However, if you have data with known rounding applied (e.g. published tabular data) then the subtracting trick can be useful. In general you should not expect floating point fractions to behave like exact values in your analysis.

On September 24, 2018 8:14:09 AM PDT, David L Carlson <dcarlson at tamu.edu> wrote:
>You've been bitten by FAQ 7.31: Why doesn't R think these numbers are
>equal?
>https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>
>Your boundaries and your data values are not what you think they are.
>This is a limitation of digital computing not R.
>
>> print(seq(from=.6, to=2.2, by=.2), digits=17)
>[1] 0.59999999999999998 0.80000000000000004 1.00000000000000000
>1.20000000000000018
>[5] 1.39999999999999991 1.60000000000000009 1.80000000000000027
>2.00000000000000000
>[9] 2.20000000000000018
>
>> print(dat, digits=17)
>[1] 0.59999999999999998 0.59999999999999998 0.59999999999999998
>0.69999999999999996
>[5] 0.69999999999999996 0.69999999999999996 0.69999999999999996
>0.69999999999999996
>[9] 0.80000000000000004 0.80000000000000004 0.80000000000000004
>0.90000000000000002
>[13] 0.90000000000000002 0.90000000000000002 0.90000000000000002
>1.00000000000000000
>[17] 1.00000000000000000 1.00000000000000000 1.00000000000000000
>1.10000000000000009
>[21] 1.10000000000000009 1.10000000000000009 1.19999999999999996
>1.19999999999999996
>[25] 1.19999999999999996 1.19999999999999996 1.30000000000000004
>1.30000000000000004
>[29] 1.30000000000000004 1.39999999999999991 1.39999999999999991
>1.39999999999999991
>[33] 1.50000000000000000 1.50000000000000000 1.50000000000000000
>1.60000000000000009
>[37] 1.60000000000000009 1.69999999999999996 1.69999999999999996
>1.69999999999999996
>[41] 1.69999999999999996 1.80000000000000004 1.80000000000000004
>1.80000000000000004
>[45] 1.89999999999999991 1.89999999999999991 2.00000000000000000
>2.00000000000000000
>[49] 2.00000000000000000 2.00000000000000000 2.00000000000000000
>2.10000000000000009
>
>The simplest solution is to subtract a bit. This also means you don't
>need the include.lowest= or right= arguments:
>
>> f <- cut(dat,
>+           breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
>+           dig.lab=10L)
>> as.matrix(tb <- table(f))
>            [,1]
>[0.59,0.79)    8
>[0.79,0.99)    7
>[0.99,1.19)    7
>[1.19,1.39)    7
>[1.39,1.59)    6
>[1.59,1.79)    6
>[1.79,1.99)    5
>[1.99,2.19]    6
>
>----------------------------------------
>David L Carlson
>Department of Anthropology
>Texas A&M University
>College Station, TX 77843-4352
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Jose Claudio
>Faria
>Sent: Monday, September 24, 2018 9:32 AM
>To: r-help at r-project.org
>Subject: [R] cut{base}: is it a bug?
>
>Dears members,
>
>Is the below a bug of the cut {base} function?
>
>dat <- c(
> 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
> 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
> 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
> 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
> 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
> 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
> 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
> 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
> )
>
># making class from function "cut"
>(f <- cut(dat,
>          breaks= seq(from=.6, to=2.2, by=.2),
>          include.lowest=TRUE,
>          dig.lab=10L,
>          right=FALSE))
>
># more easy to see the table
>as.matrix(tb <- table(f))
>
># Checking
>print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
>print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
>print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
>print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
>print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
>print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
>print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
>print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]
>
>Best,
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>Jose Claudio Faria
>UESC/DCET/Brasil
>joseclaudio.faria at gmail.com
>Telefones:
>55(73)3680.5545 - UESC
>55(73)99966.9100 - VIVO
>55(73)98817.6159 - OI
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>
>If you have software to deal with statistics, you have arms; if you
>have good software, you have arms and legs; if you have software like
>R, you have arms, legs and wings...
>the height of your flight depends only on you!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@cqueen1 @ending from llnl@gov  Mon Sep 24 18:13:43 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 24 Sep 2018 16:13:43 +0000
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <15902D1C-2E14-439A-9D24-0E64E1AD6902@llnl.gov>

In my opinion this is a pretty reasonable question for someone new to R.

Yes, it can be written without a for loop, and it would be better. Rich Heiberger gave a good solution early on, but I'd like to add an outline of the reasoning that leads to the solution.

You are taking the log of a ratio, and in the ratio, the numerator uses elements 2 through len, and the denominator uses elements 1 through (len-1). So, just write it that way:

   c1[2:len]/c1[1:(len-1)]

or, taking advantage of using negative numbers when indexing vectors,

   c1[-1]/c1[-len]

then take the log

   s <- log( c1[-1]/c1[-len] )

Comparing this with the loop version makes an example of why people say the R language is vectorized.

Do good R programmers make very little use of the for statement? Since R is vectorized, the for statement is necessary less often than in  non-vectorized languages. But "very little use" would be too broad a generalization. It will depend on what problems are being solved.

Finally, if using the loop in this case, it's true that s must exist before the statement is run. But that's not much of a problem. Just put
  s <- numeric( len-1)
before the loop.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/22/18, 2:16 PM, "R-help on behalf of rsherry8" <r-help-bounces at r-project.org on behalf of rsherry8 at comcast.net> wrote:

    
    It is my impression that good R programmers make very little use of the 
    for statement. Please consider  the following
    R statement:
             for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
    One problem I have found with this statement is that s must exist before 
    the statement is run. Can it be written without using a for
    loop? Would that be better?
    
    Thanks,
    Bob
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From profjcn@@h @ending from gm@il@com  Mon Sep 24 18:36:07 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Mon, 24 Sep 2018 12:36:07 -0400
Subject: [R] For Loop
In-Reply-To: <15902D1C-2E14-439A-9D24-0E64E1AD6902@llnl.gov>
References: <5BA6B12B.3090606@comcast.net>
 <15902D1C-2E14-439A-9D24-0E64E1AD6902@llnl.gov>
Message-ID: <30e2d3ae-a489-ef37-38ec-69f1071882c4@gmail.com>

One issue I haven't seen mentioned (and apologize if I've missed it) is that
of making programs readable for long-term use. In the histoRicalg project to
try to document and test some of the codes from long ago that are the underpinnings
of some important R computations, things like the negative index approach require
what we might term "local knowledge" i.e., to R. In such cases the old fashioned
for loop is easier for humans to understand.

The i:j form is a bit easier.

Compromise is to comment, and if your code is EVER to be used later, especially
by non-R users, it is a good idea to do so.

i.e.,

 c1[-1] # does loop from 2 to end of vector

John Nash

histoRicalg links, to which all welcome:
https://gitlab.com/nashjc/histoRicalg
https://gitlab.com/nashjc/histoRicalg/wikis/home
https://lists.r-consortium.org/g/rconsortium-project-histoRicalg

On 2018-09-24 12:13 PM, MacQueen, Don via R-help wrote:
> In my opinion this is a pretty reasonable question for someone new to R.
> 
> Yes, it can be written without a for loop, and it would be better. Rich Heiberger gave a good solution early on, but I'd like to add an outline of the reasoning that leads to the solution.
> 
> You are taking the log of a ratio, and in the ratio, the numerator uses elements 2 through len, and the denominator uses elements 1 through (len-1). So, just write it that way:
> 
>    c1[2:len]/c1[1:(len-1)]
> 
> or, taking advantage of using negative numbers when indexing vectors,
> 
>    c1[-1]/c1[-len]
> 
> then take the log
> 
>    s <- log( c1[-1]/c1[-len] )
> 
> Comparing this with the loop version makes an example of why people say the R language is vectorized.
> 
> Do good R programmers make very little use of the for statement? Since R is vectorized, the for statement is necessary less often than in  non-vectorized languages. But "very little use" would be too broad a generalization. It will depend on what problems are being solved.
> 
> Finally, if using the loop in this case, it's true that s must exist before the statement is run. But that's not much of a problem. Just put
>   s <- numeric( len-1)
> before the loop.
> 
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>  
>  
> 
> ?On 9/22/18, 2:16 PM, "R-help on behalf of rsherry8" <r-help-bounces at r-project.org on behalf of rsherry8 at comcast.net> wrote:
> 
>     
>     It is my impression that good R programmers make very little use of the 
>     for statement. Please consider  the following
>     R statement:
>              for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>     One problem I have found with this statement is that s must exist before 
>     the statement is run. Can it be written without using a for
>     loop? Would that be better?
>     
>     Thanks,
>     Bob
>     
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>     
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tmg1970 @ending from gm@il@com  Mon Sep 24 19:37:12 2018
From: tmg1970 @ending from gm@il@com (Tania Morgado Garcia)
Date: Mon, 24 Sep 2018 12:37:12 -0500
Subject: [R] About uniroot error
Message-ID: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>

Thanks for your answers. I continue to learn R and now I am detained in an
error with uniroot that I see happens to others but I can not find the
solution. Next the code

x1 <- BAaxOrd$V1
y1 <- BAaxOrd$V2
x1R <- BAaxOrdRCOS$V1
y1R <- BAaxOrdRCOS$V2
FCOS1 <- splinefun(smooth.spline(x1,y1))
FRCOS1 <- splinefun(smooth.spline(x1R,y1R))
FCOS1 <- Vectorize(FCOS1)
FRCOS1 <- Vectorize(FRCOS1)

req(input$file1)
      tryCatch(
      {
        df <- read.csv(input$file1$datapath,
                       header = input$header,
                       sep = "\t",
                       quote = '"')
      },
      error = function(e) {
        # return a safeError if a parsing error occurs
        stop(safeError(e))
      }
    )

    #if(input$disp == "head") {
     # return(head(df))
    #}
    #else {

      # Determine Carbon Reserve
      for (row in 1:nrow(df)) {
        if(df$ts==1) {
           prof <-
uniroot(f=function(x){FCOS1(x1)-df$carbono},interval=c(0,20))$root
           limsup <- prof + df$pu
           reserva <- integrate(FRCOS1,prof,limsup)$value
        }

The if is because there are several types of soil, but I only put one.  The
error is

Warning in if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
  the condition has length > 1 and only the first element will be used
Warning in if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
  the condition has length > 1 and only the first element will be used
Warning: Error in uniroot: f() values at end points not of opposite sign

The file that I load with data has a single row with the values ts = 1,
carbon = 2.04 and pu = 15 (I left only that row to be able to determine the
origin of the error). The functions FCOS1 and FRCOS1 are monotone
decreasing.Graphic attachment of FCOS1

I would appreciate some help in this regard

thanks a lot

From dc@rl@on @ending from t@mu@edu  Mon Sep 24 19:42:52 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Mon, 24 Sep 2018 17:42:52 +0000
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
 <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
 <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>
Message-ID: <c266d1a09f8742ee900ee491e8c74977@tamu.edu>

Yes, I should have included that point. The cut() function "encourages" exact comparison of values by including the right= argument without a warning that this may create unexpected results. With truly continuous data, values falling exactly on the boundary would be rare. 

Most data arrives from instruments that measure to limited precision. Introductory statistics texts deal with this by distinguishing between "true" and "stated" class limits. Or, like Lyman Ott, recommend choosing the starting point interval such that "no measurement falls on a point of division between two intervals."

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Monday, September 24, 2018 10:41 AM
To: r-help at r-project.org; David L Carlson <dcarlson at tamu.edu>; Jose Claudio Faria <joseclaudio.faria at gmail.com>; r-help at r-project.org
Subject: Re: [R] cut{base}: is it a bug?

"Subtracting a bit" only fixes the problem for the test data... it introduces a bias in any continuous data you happen to throw at it. However, if you have data with known rounding applied (e.g. published tabular data) then the subtracting trick can be useful. In general you should not expect floating point fractions to behave like exact values in your analysis.

On September 24, 2018 8:14:09 AM PDT, David L Carlson <dcarlson at tamu.edu> wrote:
>You've been bitten by FAQ 7.31: Why doesn't R think these numbers are
>equal?
>https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>
>Your boundaries and your data values are not what you think they are.
>This is a limitation of digital computing not R.
>
>> print(seq(from=.6, to=2.2, by=.2), digits=17)
>[1] 0.59999999999999998 0.80000000000000004 1.00000000000000000
>1.20000000000000018
>[5] 1.39999999999999991 1.60000000000000009 1.80000000000000027
>2.00000000000000000
>[9] 2.20000000000000018
>
>> print(dat, digits=17)
>[1] 0.59999999999999998 0.59999999999999998 0.59999999999999998
>0.69999999999999996
>[5] 0.69999999999999996 0.69999999999999996 0.69999999999999996
>0.69999999999999996
>[9] 0.80000000000000004 0.80000000000000004 0.80000000000000004
>0.90000000000000002
>[13] 0.90000000000000002 0.90000000000000002 0.90000000000000002
>1.00000000000000000
>[17] 1.00000000000000000 1.00000000000000000 1.00000000000000000
>1.10000000000000009
>[21] 1.10000000000000009 1.10000000000000009 1.19999999999999996
>1.19999999999999996
>[25] 1.19999999999999996 1.19999999999999996 1.30000000000000004
>1.30000000000000004
>[29] 1.30000000000000004 1.39999999999999991 1.39999999999999991
>1.39999999999999991
>[33] 1.50000000000000000 1.50000000000000000 1.50000000000000000
>1.60000000000000009
>[37] 1.60000000000000009 1.69999999999999996 1.69999999999999996
>1.69999999999999996
>[41] 1.69999999999999996 1.80000000000000004 1.80000000000000004
>1.80000000000000004
>[45] 1.89999999999999991 1.89999999999999991 2.00000000000000000
>2.00000000000000000
>[49] 2.00000000000000000 2.00000000000000000 2.00000000000000000
>2.10000000000000009
>
>The simplest solution is to subtract a bit. This also means you don't
>need the include.lowest= or right= arguments:
>
>> f <- cut(dat,
>+           breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
>+           dig.lab=10L)
>> as.matrix(tb <- table(f))
>            [,1]
>[0.59,0.79)    8
>[0.79,0.99)    7
>[0.99,1.19)    7
>[1.19,1.39)    7
>[1.39,1.59)    6
>[1.59,1.79)    6
>[1.79,1.99)    5
>[1.99,2.19]    6
>
>----------------------------------------
>David L Carlson
>Department of Anthropology
>Texas A&M University
>College Station, TX 77843-4352
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Jose Claudio
>Faria
>Sent: Monday, September 24, 2018 9:32 AM
>To: r-help at r-project.org
>Subject: [R] cut{base}: is it a bug?
>
>Dears members,
>
>Is the below a bug of the cut {base} function?
>
>dat <- c(
> 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
> 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
> 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
> 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
> 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
> 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
> 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
> 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
> )
>
># making class from function "cut"
>(f <- cut(dat,
>          breaks= seq(from=.6, to=2.2, by=.2),
>          include.lowest=TRUE,
>          dig.lab=10L,
>          right=FALSE))
>
># more easy to see the table
>as.matrix(tb <- table(f))
>
># Checking
>print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
>print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
>print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
>print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
>print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
>print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
>print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
>print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]
>
>Best,
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>Jose Claudio Faria
>UESC/DCET/Brasil
>joseclaudio.faria at gmail.com
>Telefones:
>55(73)3680.5545 - UESC
>55(73)99966.9100 - VIVO
>55(73)98817.6159 - OI
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>
>If you have software to deal with statistics, you have arms; if you
>have good software, you have arms and legs; if you have software like
>R, you have arms, legs and wings...
>the height of your flight depends only on you!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.

From profjcn@@h @ending from gm@il@com  Mon Sep 24 19:46:57 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Mon, 24 Sep 2018 13:46:57 -0400
Subject: [R] About uniroot error
In-Reply-To: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>
References: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>
Message-ID: <710d3514-91e8-a5d0-d871-9b2067628709@gmail.com>

uniroot REQUIRES that the function be of opposite sign at each end
of the starting interval.

I won't address the other issues raised, but you can use simple stepping
from a starting argument until a sign change occurs. Or you could try a
different type of rootfinder, such as newtonRaphson in package pracma.

There's some discussion in the (still in draft) vignette

https://gitlab.com/nashjc/histoRicalg/blob/master/provenance-of-rootfinding/rootfinder.pdf

by Oliver Dechant and myself as part of an investigation of "older"
codes.

JN


On 2018-09-24 01:37 PM, Tania Morgado Garcia wrote:
> Thanks for your answers. I continue to learn R and now I am detained in an
> error with uniroot that I see happens to others but I can not find the
> solution. Next the code
> 
> x1 <- BAaxOrd$V1
> y1 <- BAaxOrd$V2
> x1R <- BAaxOrdRCOS$V1
> y1R <- BAaxOrdRCOS$V2
> FCOS1 <- splinefun(smooth.spline(x1,y1))
> FRCOS1 <- splinefun(smooth.spline(x1R,y1R))
> FCOS1 <- Vectorize(FCOS1)
> FRCOS1 <- Vectorize(FRCOS1)
> 
> req(input$file1)
>       tryCatch(
>       {
>         df <- read.csv(input$file1$datapath,
>                        header = input$header,
>                        sep = "\t",
>                        quote = '"')
>       },
>       error = function(e) {
>         # return a safeError if a parsing error occurs
>         stop(safeError(e))
>       }
>     )
> 
>     #if(input$disp == "head") {
>      # return(head(df))
>     #}
>     #else {
> 
>       # Determine Carbon Reserve
>       for (row in 1:nrow(df)) {
>         if(df$ts==1) {
>            prof <-
> uniroot(f=function(x){FCOS1(x1)-df$carbono},interval=c(0,20))$root
>            limsup <- prof + df$pu
>            reserva <- integrate(FRCOS1,prof,limsup)$value
>         }
> 
> The if is because there are several types of soil, but I only put one.  The
> error is
> 
> Warning in if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
>   the condition has length > 1 and only the first element will be used
> Warning in if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
>   the condition has length > 1 and only the first element will be used
> Warning: Error in uniroot: f() values at end points not of opposite sign
> 
> The file that I load with data has a single row with the values ts = 1,
> carbon = 2.04 and pu = 15 (I left only that row to be able to determine the
> origin of the error). The functions FCOS1 and FRCOS1 are monotone
> decreasing.Graphic attachment of FCOS1
> 
> I would appreciate some help in this regard
> 
> thanks a lot
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gkr@emer @ending from bgc-jen@@mpg@de  Mon Sep 24 15:43:01 2018
From: gkr@emer @ending from bgc-jen@@mpg@de (Guido Kraemer)
Date: Mon, 24 Sep 2018 15:43:01 +0200
Subject: [R] object 'nativeRoutines' not found
Message-ID: <76b118ab-4235-f0fd-4499-eb56aa7ab8bc@bgc-jena.mpg.de>

Hi all,

Since a couple of days travis-ci fails for my package coRanking with "R: 
devel".
The error message is:

Error in nativeRoutines[[lib]] <- routines :
object 'nativeRoutines' not found

"R: release" and "R: oldrel" work fine. Did some R internals change or 
is the "R: devel" on travis currently broken?

I also sent the package to winbuilder and it works fine with R-devel

You can find the travis build here:

https://travis-ci.org/gdkrmr/coRanking/jobs/428661435

Best Regards,

Guido


From m@k@hholly @ending from gm@il@com  Mon Sep 24 20:26:39 2018
From: m@k@hholly @ending from gm@il@com (greg holly)
Date: Mon, 24 Sep 2018 13:26:39 -0500
Subject: [R] reading data problem
Message-ID: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>

Hi Dear all;

I have a dataset with 151*291 dimension. After making data read into R I am
getting a data with 96*291 dimension. Even though  I have no error message
from R I could not understand the reason why I cannot get data correctly?

Here are my codes to make read the data
a<-read.table("for_R_graphs.csv", header=T, sep=",")
a<-read.table("for_R_graphs.txt", header=T, sep="\t")

Regards,

Greg

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Sep 24 20:36:05 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 24 Sep 2018 11:36:05 -0700
Subject: [R] reading data problem
In-Reply-To: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
Message-ID: <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>

*Perhaps* useful questions (perhaps *not*, though):

1. What is your OS? What is your R version?
2. How do you know that your data has 151 rows?
3. Are there stray characters -- perhaps a stray eof -- in your data? Have
you checked around row 96 to see what's there?
4. Are the data you did get in R what you expect?

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com> wrote:

> Hi Dear all;
>
> I have a dataset with 151*291 dimension. After making data read into R I am
> getting a data with 96*291 dimension. Even though  I have no error message
> from R I could not understand the reason why I cannot get data correctly?
>
> Here are my codes to make read the data
> a<-read.table("for_R_graphs.csv", header=T, sep=",")
> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
>
> Regards,
>
> Greg
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Sep 24 20:40:47 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 24 Sep 2018 11:40:47 -0700
Subject: [R] reading data problem
In-Reply-To: <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
Message-ID: <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>

One more question:

5. Have you tried shutting down, restarting R, and rereading?

-- Bert

On Mon, Sep 24, 2018 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> *Perhaps* useful questions (perhaps *not*, though):
>
> 1. What is your OS? What is your R version?
> 2. How do you know that your data has 151 rows?
> 3. Are there stray characters -- perhaps a stray eof -- in your data? Have
> you checked around row 96 to see what's there?
> 4. Are the data you did get in R what you expect?
>
> -- Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com> wrote:
>
>> Hi Dear all;
>>
>> I have a dataset with 151*291 dimension. After making data read into R I
>> am
>> getting a data with 96*291 dimension. Even though  I have no error message
>> from R I could not understand the reason why I cannot get data correctly?
>>
>> Here are my codes to make read the data
>> a<-read.table("for_R_graphs.csv", header=T, sep=",")
>> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
>>
>> Regards,
>>
>> Greg
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From jttkim @ending from googlem@il@com  Mon Sep 24 21:04:48 2018
From: jttkim @ending from googlem@il@com (Jan T Kim)
Date: Mon, 24 Sep 2018 20:04:48 +0100
Subject: [R] reading data problem
In-Reply-To: <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
 <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>
Message-ID: <20180924190447.GE26688@paftolwp3a>

Yet one more: have you tried adding quote="" to your read.table
parameters? Quote characters have a 50% chance of being balanced,
and they can encompass multiple lines...

On Mon, Sep 24, 2018 at 11:40:47AM -0700, Bert Gunter wrote:
> One more question:
> 
> 5. Have you tried shutting down, restarting R, and rereading?
> 
> -- Bert
> 
> On Mon, Sep 24, 2018 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> > *Perhaps* useful questions (perhaps *not*, though):
> >
> > 1. What is your OS? What is your R version?
> > 2. How do you know that your data has 151 rows?
> > 3. Are there stray characters -- perhaps a stray eof -- in your data? Have
> > you checked around row 96 to see what's there?
> > 4. Are the data you did get in R what you expect?
> >
> > -- Bert
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com> wrote:
> >
> >> Hi Dear all;
> >>
> >> I have a dataset with 151*291 dimension. After making data read into R I
> >> am
> >> getting a data with 96*291 dimension. Even though  I have no error message
> >> from R I could not understand the reason why I cannot get data correctly?
> >>
> >> Here are my codes to make read the data
> >> a<-read.table("for_R_graphs.csv", header=T, sep=",")
> >> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
> >>
> >> Regards,
> >>
> >> Greg
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jo@ecl@udio@f@ri@ @ending from gm@il@com  Mon Sep 24 21:00:58 2018
From: jo@ecl@udio@f@ri@ @ending from gm@il@com (Jose Claudio Faria)
Date: Mon, 24 Sep 2018 16:00:58 -0300
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <c266d1a09f8742ee900ee491e8c74977@tamu.edu>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
 <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
 <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>
 <c266d1a09f8742ee900ee491e8c74977@tamu.edu>
Message-ID: <CAN+Emd9SX4eZkNVS0-NHXYguGi=Qge4-xnKh59-xri7GBBig1g@mail.gmail.com>

Dears,

Thank you for your contribution!

However, this function is important in a generic usage package for
frequency distribution tables: fdth (
https://cran.r-project.org/web/packages/fdth/index.html).

In this case, when I do not know in advance what the user data is, what is
the best option to avoid deviations as centuados as the example?

The data used in the example was sent to me from a teacher trying to
reproduce in class the table of a book.

Best,

///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
55(73)98817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms;
if you have good software, you have arms and legs;
if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

2018-09-24 14:42 GMT-03:00 David L Carlson <dcarlson at tamu.edu>:

> Yes, I should have included that point. The cut() function "encourages"
> exact comparison of values by including the right= argument without a
> warning that this may create unexpected results. With truly continuous
> data, values falling exactly on the boundary would be rare.
>
> Most data arrives from instruments that measure to limited precision.
> Introductory statistics texts deal with this by distinguishing between
> "true" and "stated" class limits. Or, like Lyman Ott, recommend choosing
> the starting point interval such that "no measurement falls on a point of
> division between two intervals."
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
> -----Original Message-----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Sent: Monday, September 24, 2018 10:41 AM
> To: r-help at r-project.org; David L Carlson <dcarlson at tamu.edu>; Jose
> Claudio Faria <joseclaudio.faria at gmail.com>; r-help at r-project.org
> Subject: Re: [R] cut{base}: is it a bug?
>
> "Subtracting a bit" only fixes the problem for the test data... it
> introduces a bias in any continuous data you happen to throw at it.
> However, if you have data with known rounding applied (e.g. published
> tabular data) then the subtracting trick can be useful. In general you
> should not expect floating point fractions to behave like exact values in
> your analysis.
>
> On September 24, 2018 8:14:09 AM PDT, David L Carlson <dcarlson at tamu.edu>
> wrote:
> >You've been bitten by FAQ 7.31: Why doesn't R think these numbers are
> >equal?
> >https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_
> 0027t-R-think-these-numbers-are-equal_003f
> >
> >Your boundaries and your data values are not what you think they are.
> >This is a limitation of digital computing not R.
> >
> >> print(seq(from=.6, to=2.2, by=.2), digits=17)
> >[1] 0.59999999999999998 0.80000000000000004 1.00000000000000000
> >1.20000000000000018
> >[5] 1.39999999999999991 1.60000000000000009 1.80000000000000027
> >2.00000000000000000
> >[9] 2.20000000000000018
> >
> >> print(dat, digits=17)
> >[1] 0.59999999999999998 0.59999999999999998 0.59999999999999998
> >0.69999999999999996
> >[5] 0.69999999999999996 0.69999999999999996 0.69999999999999996
> >0.69999999999999996
> >[9] 0.80000000000000004 0.80000000000000004 0.80000000000000004
> >0.90000000000000002
> >[13] 0.90000000000000002 0.90000000000000002 0.90000000000000002
> >1.00000000000000000
> >[17] 1.00000000000000000 1.00000000000000000 1.00000000000000000
> >1.10000000000000009
> >[21] 1.10000000000000009 1.10000000000000009 1.19999999999999996
> >1.19999999999999996
> >[25] 1.19999999999999996 1.19999999999999996 1.30000000000000004
> >1.30000000000000004
> >[29] 1.30000000000000004 1.39999999999999991 1.39999999999999991
> >1.39999999999999991
> >[33] 1.50000000000000000 1.50000000000000000 1.50000000000000000
> >1.60000000000000009
> >[37] 1.60000000000000009 1.69999999999999996 1.69999999999999996
> >1.69999999999999996
> >[41] 1.69999999999999996 1.80000000000000004 1.80000000000000004
> >1.80000000000000004
> >[45] 1.89999999999999991 1.89999999999999991 2.00000000000000000
> >2.00000000000000000
> >[49] 2.00000000000000000 2.00000000000000000 2.00000000000000000
> >2.10000000000000009
> >
> >The simplest solution is to subtract a bit. This also means you don't
> >need the include.lowest= or right= arguments:
> >
> >> f <- cut(dat,
> >+           breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
> >+           dig.lab=10L)
> >> as.matrix(tb <- table(f))
> >            [,1]
> >[0.59,0.79)    8
> >[0.79,0.99)    7
> >[0.99,1.19)    7
> >[1.19,1.39)    7
> >[1.39,1.59)    6
> >[1.59,1.79)    6
> >[1.79,1.99)    5
> >[1.99,2.19]    6
> >
> >----------------------------------------
> >David L Carlson
> >Department of Anthropology
> >Texas A&M University
> >College Station, TX 77843-4352
> >
> >
> >-----Original Message-----
> >From: R-help <r-help-bounces at r-project.org> On Behalf Of Jose Claudio
> >Faria
> >Sent: Monday, September 24, 2018 9:32 AM
> >To: r-help at r-project.org
> >Subject: [R] cut{base}: is it a bug?
> >
> >Dears members,
> >
> >Is the below a bug of the cut {base} function?
> >
> >dat <- c(
> > 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
> > 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
> > 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
> > 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
> > 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
> > 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
> > 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
> > 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
> > )
> >
> ># making class from function "cut"
> >(f <- cut(dat,
> >          breaks= seq(from=.6, to=2.2, by=.2),
> >          include.lowest=TRUE,
> >          dig.lab=10L,
> >          right=FALSE))
> >
> ># more easy to see the table
> >as.matrix(tb <- table(f))
> >
> ># Checking
> >print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
> >print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
> >print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
> >print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
> >print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
> >print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
> >print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
> >print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]
> >
> >Best,
> >///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> >Jose Claudio Faria
> >UESC/DCET/Brasil
> >joseclaudio.faria at gmail.com
> >Telefones:
> >55(73)3680.5545 - UESC
> >55(73)99966.9100 - VIVO
> >55(73)98817.6159 - OI
> >///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> >
> >If you have software to deal with statistics, you have arms; if you
> >have good software, you have arms and legs; if you have software like
> >R, you have arms, legs and wings...
> >the height of your flight depends only on you!
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From m@k@hholly @ending from gm@il@com  Mon Sep 24 21:36:58 2018
From: m@k@hholly @ending from gm@il@com (greg holly)
Date: Mon, 24 Sep 2018 14:36:58 -0500
Subject: [R] reading data problem
In-Reply-To: <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
Message-ID: <CAM9Qe4gxdmP6pOnsYey9XO4F6scUBZUiaLh_w7vbY0+gFPaHGw@mail.gmail.com>

Hi Bert;

Thanks for writing. Here are my answers to your questions:

Regards,

Greg

1. What is your OS? What is your R version?          *The version is 3.5.0*
2. How do you know that your data has 151 rows?  *Because I looked in excel
also I work on the same data in SAS*
3. Are there stray characters -- perhaps a stray eof -- in your data? Have
you checked around row 96 to see what's there?  *I don't think so if I have
stray characters*
4. Are the data you did get in R what you expect? * I will run for some
graphics*
5. Have you tried shutting down, restarting R, and rereading?  *Yes and
again I had the same problem*

On Mon, Sep 24, 2018 at 1:36 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> *Perhaps* useful questions (perhaps *not*, though):
>
> 1. What is your OS? What is your R version?
> 2. How do you know that your data has 151 rows?
> 3. Are there stray characters -- perhaps a stray eof -- in your data? Have
> you checked around row 96 to see what's there?
> 4. Are the data you did get in R what you expect?
>
> -- Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com> wrote:
>
>> Hi Dear all;
>>
>> I have a dataset with 151*291 dimension. After making data read into R I
>> am
>> getting a data with 96*291 dimension. Even though  I have no error message
>> from R I could not understand the reason why I cannot get data correctly?
>>
>> Here are my codes to make read the data
>> a<-read.table("for_R_graphs.csv", header=T, sep=",")
>> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
>>
>> Regards,
>>
>> Greg
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From m@k@hholly @ending from gm@il@com  Mon Sep 24 21:39:49 2018
From: m@k@hholly @ending from gm@il@com (greg holly)
Date: Mon, 24 Sep 2018 14:39:49 -0500
Subject: [R] reading data problem
In-Reply-To: <20180924190447.GE26688@paftolwp3a>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
 <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>
 <20180924190447.GE26688@paftolwp3a>
Message-ID: <CAM9Qe4gOQ1U6SJbMQjBJTmqxRzU4GjSRHmng2vkHAxbHDYNY+g@mail.gmail.com>

Hi Jan;

Thanks so much for this. Yes, I did. Her is my code to read
data: a<-read.csv("for_R_graphs.csv", header=T, sep=",")

On Mon, Sep 24, 2018 at 2:07 PM Jan T Kim via R-help <r-help at r-project.org>
wrote:

> Yet one more: have you tried adding quote="" to your read.table
> parameters? Quote characters have a 50% chance of being balanced,
> and they can encompass multiple lines...
>
> On Mon, Sep 24, 2018 at 11:40:47AM -0700, Bert Gunter wrote:
> > One more question:
> >
> > 5. Have you tried shutting down, restarting R, and rereading?
> >
> > -- Bert
> >
> > On Mon, Sep 24, 2018 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > > *Perhaps* useful questions (perhaps *not*, though):
> > >
> > > 1. What is your OS? What is your R version?
> > > 2. How do you know that your data has 151 rows?
> > > 3. Are there stray characters -- perhaps a stray eof -- in your data?
> Have
> > > you checked around row 96 to see what's there?
> > > 4. Are the data you did get in R what you expect?
> > >
> > > -- Bert
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> and
> > > sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com>
> wrote:
> > >
> > >> Hi Dear all;
> > >>
> > >> I have a dataset with 151*291 dimension. After making data read into
> R I
> > >> am
> > >> getting a data with 96*291 dimension. Even though  I have no error
> message
> > >> from R I could not understand the reason why I cannot get data
> correctly?
> > >>
> > >> Here are my codes to make read the data
> > >> a<-read.table("for_R_graphs.csv", header=T, sep=",")
> > >> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
> > >>
> > >> Regards,
> > >>
> > >> Greg
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jttkim @ending from googlem@il@com  Mon Sep 24 22:05:18 2018
From: jttkim @ending from googlem@il@com (Jan T Kim)
Date: Mon, 24 Sep 2018 21:05:18 +0100
Subject: [R] reading data problem
In-Reply-To: <CAM9Qe4gOQ1U6SJbMQjBJTmqxRzU4GjSRHmng2vkHAxbHDYNY+g@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
 <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>
 <20180924190447.GE26688@paftolwp3a>
 <CAM9Qe4gOQ1U6SJbMQjBJTmqxRzU4GjSRHmng2vkHAxbHDYNY+g@mail.gmail.com>
Message-ID: <CAGLFf7qCsYLrShg7VhqUZiduSBVcYh-3+O7xztrc-HbJiM48Ow@mail.gmail.com>

hmm... I don't see the quote="" paraneter in your read.csv call


Best regards, Jan
--
Sent from my mobile. Apologies for typos and terseness

On Mon, Sep 24, 2018, 20:40 greg holly <mak.hholly at gmail.com> wrote:

> Hi Jan;
>
> Thanks so much for this. Yes, I did. Her is my code to read
> data: a<-read.csv("for_R_graphs.csv", header=T, sep=",")
>
> On Mon, Sep 24, 2018 at 2:07 PM Jan T Kim via R-help <r-help at r-project.org>
> wrote:
>
>> Yet one more: have you tried adding quote="" to your read.table
>> parameters? Quote characters have a 50% chance of being balanced,
>> and they can encompass multiple lines...
>>
>> On Mon, Sep 24, 2018 at 11:40:47AM -0700, Bert Gunter wrote:
>> > One more question:
>> >
>> > 5. Have you tried shutting down, restarting R, and rereading?
>> >
>> > -- Bert
>> >
>> > On Mon, Sep 24, 2018 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >
>> > > *Perhaps* useful questions (perhaps *not*, though):
>> > >
>> > > 1. What is your OS? What is your R version?
>> > > 2. How do you know that your data has 151 rows?
>> > > 3. Are there stray characters -- perhaps a stray eof -- in your data?
>> Have
>> > > you checked around row 96 to see what's there?
>> > > 4. Are the data you did get in R what you expect?
>> > >
>> > > -- Bert
>> > >
>> > > Bert Gunter
>> > >
>> > > "The trouble with having an open mind is that people keep coming
>> along and
>> > > sticking things into it."
>> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> > >
>> > >
>> > > On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com>
>> wrote:
>> > >
>> > >> Hi Dear all;
>> > >>
>> > >> I have a dataset with 151*291 dimension. After making data read into
>> R I
>> > >> am
>> > >> getting a data with 96*291 dimension. Even though  I have no error
>> message
>> > >> from R I could not understand the reason why I cannot get data
>> correctly?
>> > >>
>> > >> Here are my codes to make read the data
>> > >> a<-read.table("for_R_graphs.csv", header=T, sep=",")
>> > >> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
>> > >>
>> > >> Regards,
>> > >>
>> > >> Greg
>> > >>
>> > >>         [[alternative HTML version deleted]]
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide
>> > >> http://www.R-project.org/posting-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >>
>> > >
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From m@k@hholly @ending from gm@il@com  Mon Sep 24 22:08:50 2018
From: m@k@hholly @ending from gm@il@com (greg holly)
Date: Mon, 24 Sep 2018 15:08:50 -0500
Subject: [R] reading data problem
In-Reply-To: <CAGLFf7qCsYLrShg7VhqUZiduSBVcYh-3+O7xztrc-HbJiM48Ow@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
 <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>
 <20180924190447.GE26688@paftolwp3a>
 <CAM9Qe4gOQ1U6SJbMQjBJTmqxRzU4GjSRHmng2vkHAxbHDYNY+g@mail.gmail.com>
 <CAGLFf7qCsYLrShg7VhqUZiduSBVcYh-3+O7xztrc-HbJiM48Ow@mail.gmail.com>
Message-ID: <CAM9Qe4gOgeGOUuWubhC4yE6zNDJzMkHcOizT4n15BXZVDa5WEw@mail.gmail.com>

Hi Jan;

Thanks so much. It is much appreciated. The problem has been solved.

Regards,

Greg

On Mon, Sep 24, 2018 at 3:05 PM Jan T Kim <jttkim at googlemail.com> wrote:

> hmm... I don't see the quote="" paraneter in your read.csv call
>
>
> Best regards, Jan
> --
> Sent from my mobile. Apologies for typos and terseness
>
> On Mon, Sep 24, 2018, 20:40 greg holly <mak.hholly at gmail.com> wrote:
>
>> Hi Jan;
>>
>> Thanks so much for this. Yes, I did. Her is my code to read
>> data: a<-read.csv("for_R_graphs.csv", header=T, sep=",")
>>
>> On Mon, Sep 24, 2018 at 2:07 PM Jan T Kim via R-help <
>> r-help at r-project.org> wrote:
>>
>>> Yet one more: have you tried adding quote="" to your read.table
>>> parameters? Quote characters have a 50% chance of being balanced,
>>> and they can encompass multiple lines...
>>>
>>> On Mon, Sep 24, 2018 at 11:40:47AM -0700, Bert Gunter wrote:
>>> > One more question:
>>> >
>>> > 5. Have you tried shutting down, restarting R, and rereading?
>>> >
>>> > -- Bert
>>> >
>>> > On Mon, Sep 24, 2018 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> >
>>> > > *Perhaps* useful questions (perhaps *not*, though):
>>> > >
>>> > > 1. What is your OS? What is your R version?
>>> > > 2. How do you know that your data has 151 rows?
>>> > > 3. Are there stray characters -- perhaps a stray eof -- in your
>>> data? Have
>>> > > you checked around row 96 to see what's there?
>>> > > 4. Are the data you did get in R what you expect?
>>> > >
>>> > > -- Bert
>>> > >
>>> > > Bert Gunter
>>> > >
>>> > > "The trouble with having an open mind is that people keep coming
>>> along and
>>> > > sticking things into it."
>>> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> > >
>>> > >
>>> > > On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com>
>>> wrote:
>>> > >
>>> > >> Hi Dear all;
>>> > >>
>>> > >> I have a dataset with 151*291 dimension. After making data read
>>> into R I
>>> > >> am
>>> > >> getting a data with 96*291 dimension. Even though  I have no error
>>> message
>>> > >> from R I could not understand the reason why I cannot get data
>>> correctly?
>>> > >>
>>> > >> Here are my codes to make read the data
>>> > >> a<-read.table("for_R_graphs.csv", header=T, sep=",")
>>> > >> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
>>> > >>
>>> > >> Regards,
>>> > >>
>>> > >> Greg
>>> > >>
>>> > >>         [[alternative HTML version deleted]]
>>> > >>
>>> > >> ______________________________________________
>>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >> PLEASE do read the posting guide
>>> > >> http://www.R-project.org/posting-guide.html
>>> > >> and provide commented, minimal, self-contained, reproducible code.
>>> > >>
>>> > >
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Mon Sep 24 22:12:34 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Mon, 24 Sep 2018 13:12:34 -0700
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <CAN+Emd9SX4eZkNVS0-NHXYguGi=Qge4-xnKh59-xri7GBBig1g@mail.gmail.com>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
 <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
 <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>
 <c266d1a09f8742ee900ee491e8c74977@tamu.edu>
 <CAN+Emd9SX4eZkNVS0-NHXYguGi=Qge4-xnKh59-xri7GBBig1g@mail.gmail.com>
Message-ID: <DEBE1C75-7709-4846-97B6-50AFE597FBE3@comcast.net>


> On Sep 24, 2018, at 12:00 PM, Jose Claudio Faria <joseclaudio.faria at gmail.com> wrote:
> 
> Dears,
> 
> Thank you for your contribution!
> 
> However, this function is important in a generic usage package for
> frequency distribution tables: fdth (
> https://cran.r-project.org/web/packages/fdth/index.html).
> 
> In this case, when I do not know in advance what the user data is, what is
> the best option to avoid deviations as centuados as the example?
> 
> The data used in the example was sent to me from a teacher trying to
> reproduce in class the table of a book.

If you want to provide tools that protect unsuspecting users from falling into common numerical and well understood potential traps, then why don't you process your data inputs with round( obj, 8) or something similar to your liking.

> round( 3*.1, 8) == 3*.1
[1] FALSE
> 0.3 == 3*.1
[1] FALSE
> round( 3*.1, 8) == 0.3
[1] TRUE


-- 
David.
> 
> Best,
> 
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> Jose Claudio Faria
> UESC/DCET/Brasil
> joseclaudio.faria at gmail.com
> Telefones:
> 55(73)3680.5545 - UESC
> 55(73)99966.9100 - VIVO
> 55(73)98817.6159 - OI
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> 
> If you have software to deal with statistics, you have arms;
> if you have good software, you have arms and legs;
> if you have software like R, you have arms, legs and wings...
> the height of your flight depends only on you!
> 
> 2018-09-24 14:42 GMT-03:00 David L Carlson <dcarlson at tamu.edu>:
> 
>> Yes, I should have included that point. The cut() function "encourages"
>> exact comparison of values by including the right= argument without a
>> warning that this may create unexpected results. With truly continuous
>> data, values falling exactly on the boundary would be rare.
>> 
>> Most data arrives from instruments that measure to limited precision.
>> Introductory statistics texts deal with this by distinguishing between
>> "true" and "stated" class limits. Or, like Lyman Ott, recommend choosing
>> the starting point interval such that "no measurement falls on a point of
>> division between two intervals."
>> 
>> ----------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77843-4352
>> 
>> -----Original Message-----
>> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> Sent: Monday, September 24, 2018 10:41 AM
>> To: r-help at r-project.org; David L Carlson <dcarlson at tamu.edu>; Jose
>> Claudio Faria <joseclaudio.faria at gmail.com>; r-help at r-project.org
>> Subject: Re: [R] cut{base}: is it a bug?
>> 
>> "Subtracting a bit" only fixes the problem for the test data... it
>> introduces a bias in any continuous data you happen to throw at it.
>> However, if you have data with known rounding applied (e.g. published
>> tabular data) then the subtracting trick can be useful. In general you
>> should not expect floating point fractions to behave like exact values in
>> your analysis.
>> 
>> On September 24, 2018 8:14:09 AM PDT, David L Carlson <dcarlson at tamu.edu>
>> wrote:
>>> You've been bitten by FAQ 7.31: Why doesn't R think these numbers are
>>> equal?
>>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_
>> 0027t-R-think-these-numbers-are-equal_003f
>>> 
>>> Your boundaries and your data values are not what you think they are.
>>> This is a limitation of digital computing not R.
>>> 
>>>> print(seq(from=.6, to=2.2, by=.2), digits=17)
>>> [1] 0.59999999999999998 0.80000000000000004 1.00000000000000000
>>> 1.20000000000000018
>>> [5] 1.39999999999999991 1.60000000000000009 1.80000000000000027
>>> 2.00000000000000000
>>> [9] 2.20000000000000018
>>> 
>>>> print(dat, digits=17)
>>> [1] 0.59999999999999998 0.59999999999999998 0.59999999999999998
>>> 0.69999999999999996
>>> [5] 0.69999999999999996 0.69999999999999996 0.69999999999999996
>>> 0.69999999999999996
>>> [9] 0.80000000000000004 0.80000000000000004 0.80000000000000004
>>> 0.90000000000000002
>>> [13] 0.90000000000000002 0.90000000000000002 0.90000000000000002
>>> 1.00000000000000000
>>> [17] 1.00000000000000000 1.00000000000000000 1.00000000000000000
>>> 1.10000000000000009
>>> [21] 1.10000000000000009 1.10000000000000009 1.19999999999999996
>>> 1.19999999999999996
>>> [25] 1.19999999999999996 1.19999999999999996 1.30000000000000004
>>> 1.30000000000000004
>>> [29] 1.30000000000000004 1.39999999999999991 1.39999999999999991
>>> 1.39999999999999991
>>> [33] 1.50000000000000000 1.50000000000000000 1.50000000000000000
>>> 1.60000000000000009
>>> [37] 1.60000000000000009 1.69999999999999996 1.69999999999999996
>>> 1.69999999999999996
>>> [41] 1.69999999999999996 1.80000000000000004 1.80000000000000004
>>> 1.80000000000000004
>>> [45] 1.89999999999999991 1.89999999999999991 2.00000000000000000
>>> 2.00000000000000000
>>> [49] 2.00000000000000000 2.00000000000000000 2.00000000000000000
>>> 2.10000000000000009
>>> 
>>> The simplest solution is to subtract a bit. This also means you don't
>>> need the include.lowest= or right= arguments:
>>> 
>>>> f <- cut(dat,
>>> +           breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
>>> +           dig.lab=10L)
>>>> as.matrix(tb <- table(f))
>>>           [,1]
>>> [0.59,0.79)    8
>>> [0.79,0.99)    7
>>> [0.99,1.19)    7
>>> [1.19,1.39)    7
>>> [1.39,1.59)    6
>>> [1.59,1.79)    6
>>> [1.79,1.99)    5
>>> [1.99,2.19]    6
>>> 
>>> ----------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77843-4352
>>> 
>>> 
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jose Claudio
>>> Faria
>>> Sent: Monday, September 24, 2018 9:32 AM
>>> To: r-help at r-project.org
>>> Subject: [R] cut{base}: is it a bug?
>>> 
>>> Dears members,
>>> 
>>> Is the below a bug of the cut {base} function?
>>> 
>>> dat <- c(
>>> 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
>>> 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
>>> 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
>>> 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
>>> 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
>>> 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
>>> 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
>>> 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
>>> )
>>> 
>>> # making class from function "cut"
>>> (f <- cut(dat,
>>>         breaks= seq(from=.6, to=2.2, by=.2),
>>>         include.lowest=TRUE,
>>>         dig.lab=10L,
>>>         right=FALSE))
>>> 
>>> # more easy to see the table
>>> as.matrix(tb <- table(f))
>>> 
>>> # Checking
>>> print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
>>> print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
>>> print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
>>> print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
>>> print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
>>> print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
>>> print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
>>> print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]
>>> 
>>> Best,
>>> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>>> Jose Claudio Faria
>>> UESC/DCET/Brasil
>>> joseclaudio.faria at gmail.com
>>> Telefones:
>>> 55(73)3680.5545 - UESC
>>> 55(73)99966.9100 - VIVO
>>> 55(73)98817.6159 - OI
>>> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>>> 
>>> If you have software to deal with statistics, you have arms; if you
>>> have good software, you have arms and legs; if you have software like
>>> R, you have arms, legs and wings...
>>> the height of your flight depends only on you!
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dc@rl@on @ending from t@mu@edu  Mon Sep 24 22:26:51 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Mon, 24 Sep 2018 20:26:51 +0000
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <CAN+Emd9SX4eZkNVS0-NHXYguGi=Qge4-xnKh59-xri7GBBig1g@mail.gmail.com>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
 <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
 <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>
 <c266d1a09f8742ee900ee491e8c74977@tamu.edu>
 <CAN+Emd9SX4eZkNVS0-NHXYguGi=Qge4-xnKh59-xri7GBBig1g@mail.gmail.com>
Message-ID: <375b4b147ad046f1af65f83b8c2a0247@tamu.edu>

You need to know the number of decimal places reported for the data. I don't know of any straightforward way to compute that from the data. 

Given the number of decimals, you can compute "true" limit boundaries. This would be a way to compute the upper and lower boundaries and the number of intervals from the data:

> decimals <- 1
> tlimit <- (10^-decimals)/2
> bks <- pretty(c(dat, max(dat)+tlimit), nclass.Sturges(dat))
> f <- cut(dat, breaks= bks-tlimit, right=FALSE, dig.lab=10L)

You would also need to decide if you want your factor levels to reflect the true boundaries or the stated boundaries:

> levels(f)
[1] "[0.55,0.75)" "[0.75,0.95)" "[0.95,1.15)" "[1.15,1.35)" "[1.35,1.55)"
[6] "[1.55,1.75)" "[1.75,1.95)" "[1.95,2.15)"

Vs. 

> lvls <- levels(cut(dat, breaks= bks, right=FALSE, dig.lab=10L))
> levels(f) <- lvls
> levels(f)
[1] "[0.6,0.8)" "[0.8,1)"   "[1,1.2)"   "[1.2,1.4)" "[1.4,1.6)" "[1.6,1.8)"
[7] "[1.8,2)"   "[2,2.2)"  

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

From: Jose Claudio Faria <joseclaudio.faria at gmail.com> 
Sent: Monday, September 24, 2018 2:01 PM
To: David L Carlson <dcarlson at tamu.edu>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
Subject: Re: [R] cut{base}: is it a bug?

Dears,

Thank you for your contribution!

However, this function is important in a generic usage package for frequency distribution tables: fdth (https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_web_packages_fdth_index.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=wB3zkm0Z2hvc1svMqrK7BS3aQS7VlLlteA8BFZd-sQA&e=).

In this case, when I do not know in advance what the user data is, what is the best option to avoid deviations as centuados as the example?

The data used in the example was sent to me from a teacher trying to reproduce in class the table of a book.

Best,


///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at https://urldefense.proofpoint.com/v2/url?u=http-3A__gmail.com&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=3NkW6wyXOvCsrjWVqle139SjYzQ1xGL_aOQ3ec8L85Y&e=
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
55(73)98817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms;
if you have good software, you have arms and legs;
if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

2018-09-24 14:42 GMT-03:00 David L Carlson <mailto:dcarlson at tamu.edu>:
Yes, I should have included that point. The cut() function "encourages" exact comparison of values by including the right= argument without a warning that this may create unexpected results. With truly continuous data, values falling exactly on the boundary would be rare. 

Most data arrives from instruments that measure to limited precision. Introductory statistics texts deal with this by distinguishing between "true" and "stated" class limits. Or, like Lyman Ott, recommend choosing the starting point interval such that "no measurement falls on a point of division between two intervals."

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us> 
Sent: Monday, September 24, 2018 10:41 AM
To: mailto:r-help at r-project.org; David L Carlson <mailto:dcarlson at tamu.edu>; Jose Claudio Faria <mailto:joseclaudio.faria at gmail.com>; mailto:r-help at r-project.org
Subject: Re: [R] cut{base}: is it a bug?

"Subtracting a bit" only fixes the problem for the test data... it introduces a bias in any continuous data you happen to throw at it. However, if you have data with known rounding applied (e.g. published tabular data) then the subtracting trick can be useful. In general you should not expect floating point fractions to behave like exact values in your analysis.

On September 24, 2018 8:14:09 AM PDT, David L Carlson <mailto:dcarlson at tamu.edu> wrote:
>You've been bitten by FAQ 7.31: Why doesn't R think these numbers are
>equal?
>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_doc_FAQ_R-2DFAQ.html-23Why-2Ddoesn-5F0027t-2DR-2Dthink-2Dthese-2Dnumbers-2Dare-2Dequal-5F003f&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=bmSMJ_7ca1pAJtmWsC5SlqVYRV2rn75Kgco0uSbRHkE&e=
>
>Your boundaries and your data values are not what you think they are.
>This is a limitation of digital computing not R.
>
>> print(seq(from=.6, to=2.2, by=.2), digits=17)
>[1] 0.59999999999999998 0.80000000000000004 1.00000000000000000
>1.20000000000000018
>[5] 1.39999999999999991 1.60000000000000009 1.80000000000000027
>2.00000000000000000
>[9] 2.20000000000000018
>
>> print(dat, digits=17)
>[1] 0.59999999999999998 0.59999999999999998 0.59999999999999998
>0.69999999999999996
>[5] 0.69999999999999996 0.69999999999999996 0.69999999999999996
>0.69999999999999996
>[9] 0.80000000000000004 0.80000000000000004 0.80000000000000004
>0.90000000000000002
>[13] 0.90000000000000002 0.90000000000000002 0.90000000000000002
>1.00000000000000000
>[17] 1.00000000000000000 1.00000000000000000 1.00000000000000000
>1.10000000000000009
>[21] 1.10000000000000009 1.10000000000000009 1.19999999999999996
>1.19999999999999996
>[25] 1.19999999999999996 1.19999999999999996 1.30000000000000004
>1.30000000000000004
>[29] 1.30000000000000004 1.39999999999999991 1.39999999999999991
>1.39999999999999991
>[33] 1.50000000000000000 1.50000000000000000 1.50000000000000000
>1.60000000000000009
>[37] 1.60000000000000009 1.69999999999999996 1.69999999999999996
>1.69999999999999996
>[41] 1.69999999999999996 1.80000000000000004 1.80000000000000004
>1.80000000000000004
>[45] 1.89999999999999991 1.89999999999999991 2.00000000000000000
>2.00000000000000000
>[49] 2.00000000000000000 2.00000000000000000 2.00000000000000000
>2.10000000000000009
>
>The simplest solution is to subtract a bit. This also means you don't
>need the include.lowest= or right= arguments:
>
>> f <- cut(dat,
>+? ? ? ? ? ?breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
>+? ? ? ? ? ?dig.lab=10L)
>> as.matrix(tb <- table(f))
>? ? ? ? ? ? [,1]
>[0.59,0.79)? ? 8
>[0.79,0.99)? ? 7
>[0.99,1.19)? ? 7
>[1.19,1.39)? ? 7
>[1.39,1.59)? ? 6
>[1.59,1.79)? ? 6
>[1.79,1.99)? ? 5
>[1.99,2.19]? ? 6
>
>----------------------------------------
>David L Carlson
>Department of Anthropology
>Texas A&M University
>College Station, TX 77843-4352
>
>
>-----Original Message-----
>From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Jose Claudio
>Faria
>Sent: Monday, September 24, 2018 9:32 AM
>To: mailto:r-help at r-project.org
>Subject: [R] cut{base}: is it a bug?
>
>Dears members,
>
>Is the below a bug of the cut {base} function?
>
>dat <- c(
> 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
> 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,? ? ? ? #(7)
> 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,? ? ? ? #(7)
> 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,? ? ? ? #(7)
> 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,? ? ? ? ? ? ? ?#(6)
> 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,? ? ? ? ? ? ? ?#(6)
> 1.8, 1.8, 1.8, 1.9, 1.9,? ? ? ? ? ? ? ? ? ? ? #(5)
> 2.0, 2.0, 2.0, 2.0, 2.0, 2.1? ? ? ? ? ? ? ? #(6)
> )
>
># making class from function "cut"
>(f <- cut(dat,
>? ? ? ? ? breaks= seq(from=.6, to=2.2, by=.2),
>? ? ? ? ? include.lowest=TRUE,
>? ? ? ? ? dig.lab=10L,
>? ? ? ? ? right=FALSE))
>
># more easy to see the table
>as.matrix(tb <- table(f))
>
># Checking
>print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
>print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
>print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]? # !?
>print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]? # !?
>print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
>print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]? # !?
>print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]? # !?
>print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]
>
>Best,
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>Jose Claudio Faria
>UESC/DCET/Brasil
>joseclaudio.faria at https://urldefense.proofpoint.com/v2/url?u=http-3A__gmail.com&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=3NkW6wyXOvCsrjWVqle139SjYzQ1xGL_aOQ3ec8L85Y&e=
>Telefones:
>55(73)3680.5545 - UESC
>55(73)99966.9100 - VIVO
>55(73)98817.6159 - OI
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>
>If you have software to deal with statistics, you have arms; if you
>have good software, you have arms and legs; if you have software like
>R, you have arms, legs and wings...
>the height of your flight depends only on you!
>
>? ? ? ?[[alternative HTML version deleted]]
>
>______________________________________________
>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=B_9d6gWXu0q4UO6J41Ve_rNsdRdGpGychN2ABZzb3Z4&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=vyr1qxeTCBubIC7Ora6AWijq6kMLQ0yomzD31wUGgfY&e=
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=B_9d6gWXu0q4UO6J41Ve_rNsdRdGpGychN2ABZzb3Z4&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=vyr1qxeTCBubIC7Ora6AWijq6kMLQ0yomzD31wUGgfY&e=
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From g@@per@c@nk@r @ending from ric@@i  Mon Sep 24 15:25:38 2018
From: g@@per@c@nk@r @ending from ric@@i (Gasper Cankar)
Date: Mon, 24 Sep 2018 13:25:38 +0000
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <ce6d102d-0ac0-853c-2741-e08a6214381c@gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>
 <c226c952-b8f3-3c1a-6c62-5d19530afce6@gmail.com>
 <4d2400ea-28ef-875a-064e-79a0bd7325ac@yorku.ca>,
 <ce6d102d-0ac0-853c-2741-e08a6214381c@gmail.com>
Message-ID: <9AF3B98F746E140F.7db34733-20e0-4675-bf20-f454e9ff8f06@mail.outlook.com>



Get Outlook for Android<https://aka.ms/ghei36>




On Mon, Sep 24, 2018 at 3:18 PM +0200, "Andrew" <phaedrusv at gmail.com<mailto:phaedrusv at gmail.com>> wrote:


Ha! Even better - thank you. Plenty here for me to play around with.

Many thanks
Andrew


On 23/09/18 15:22, Michael Friendly wrote:
> On 9/22/2018 6:49 AM, Andrew wrote:
>> Hi Michael
>>
>> This looks like it could be really helpful in moving my project
>> forwards thank you.
>>
>> I remember many years ago using (proprietary) software from the
>> University of Liverpool which did a nice job of allowing regions to
>> be defined, and then for the space to be rotated to obtain visual
>> inspection of relative distance from different angles. I appreciate
>> that smacof will not do that, but as long as the analysis allows for
>> the graph to be plotted and analysed, that's what's important.
>
> You need not rely on the plots provided directly by a given package.
> Just roll your own using standard plotting libraries.
> Here is just the first Google hit on "R MDS 3D plot"
>
> http://omnilogia.blogspot.com/2014/05/basic-2d-3d-multi-dimensional-scaling.html
>
>
> which shows a rotating 3D plot, colored by a grouping variable. Here
> is another:
>
> http://whatzcookinlab.blogspot.com/2013/05/spinning-3d-mds-plot.html
>
> The vegan and ade4 packages also have a variety of plots and related
> methods.
>
>
> -Michael
>
>>
>> Thank you again, and to all of those who responded.
>>
>> Best wishes
>> Andrew
>>
>>
>> On 21/09/18 14:07, Michael Friendly wrote:
>>> Smallest space analysis (SSA) is just the name given to software
>>> developed by Guttman & Lingoes around the time the various versions
>>> of multidimensional scaling were being developed.  Call it Israeli MDS
>>> or Falafel MDS if you prefer. The reason you encountered it in your
>>> course is presumably that the instructor was trained in that.
>>>
>>> There are several variants of MDS-like algorithms for embedding
>>> points representing objects in a space, using data representing
>>> similarities or distances among objects -- metric (cmdscale)
>>> and non-metric (MASS::isoMDS), using only rank order information,
>>> and a variety of
>>> measures of goodness-of-fit ("stress").  I don't recall the details
>>> of the SSA programs, but that should matter little conceptually.
>>>
>>> The smacof package offers the widest array of possibilities.
>>>
>>> -Michael
>>>
>>>
>>> On 9/19/2018 7:00 AM, Andrew wrote:
>>>> Hi
>>>>
>>>> As part of my forensics psych course, we have been introduced to
>>>> Guttman's smallest space analysis (SSA). I want to explore this
>>>> approach
>>>> using R, but despite finding some queries on the web about this same
>>>> thing, have yet to find any answers. The MASS package doesn't seem
>>>> to do
>>>> the job, and the only thing I have been able to find is some
>>>> proprietary
>>>> software HUDAP  (Hebrew University Data Analysis Package) which
>>>> may/ not
>>>> be compatible with R (or GNU/Linux for that matter).
>>>>
>>>> Does anyone have information on how to do SSA using R?
>>>>
>>>> Many thanks
>>>>
>>>> Andrew
>>>>
>>>>
>>>>     [[alternative HTML version deleted]]
>>>>
>>>
>>>
>>
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@echler @ending from @t@t@m@th@ethz@ch  Tue Sep 25 10:50:49 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 25 Sep 2018 10:50:49 +0200
Subject: [R] For Loop
In-Reply-To: <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
Message-ID: <23465.63209.180983.97854@stat.math.ethz.ch>

>>>>> Wensui Liu 
>>>>>     on Sun, 23 Sep 2018 13:26:32 -0500 writes:

    > what you measures is the "elapsed" time in the default
    > setting. you might need to take a closer look at the
    > beautiful benchmark() function and see what time I am
    > talking about.

    > I just provided tentative solution for the person asking
    > for it and believe he has enough wisdom to decide what's
    > best. why bother to judge others subjectively?  

Well, because  Ista Zahn is much much much better R programmer
than you, sorry to be blunt!

Martin

    > On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com>
    > wrote:
    >> 
    >> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu
    >> <liuwensui at gmail.com> wrote:
    >> >
    >> > actually, by the parallel pvec, the user time is a lot
    >> shorter. or did > I somewhere miss your invaluable
    >> insight?
    >> >
    >> > > c1 <- 1:1000000 > > len <- length(c1) > >
    >> rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications
    >> = 100) > test replications elapsed relative user.self
    >> sys.self > 1 log(c1[-1]/c1[-len]) 100 4.617 1 4.484 0.133
    >> > user.child sys.child > 1 0 0 > >
    >> rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4,
    >> function(i) log(c1[i + 1] / c1[i])), replications = 100)
    >> > test > 1 pvec(1:(len - 1), mc.cores = 4, function(i)
    >> log(c1[i + 1]/c1[i])) > replications elapsed relative
    >> user.self sys.self user.child sys.child > 1 100 9.079 1
    >> 2.571 4.138 9.736 8.046
    >> 
    >> Your output is mangled in my email, but on my system your
    >> pvec approach takes more than twice as long:
    >> 
    >> c1 <- 1:1000000 len <- length(c1) library(parallel)
    >> library(rbenchmark)
    >> 
    >> regular <- function() log(c1[-1]/c1[-len])
    >> iterate.parallel <- function() { pvec(1:(len - 1),
    >> mc.cores = 4, function(i) log(c1[i + 1] / c1[i])) }
    >> 
    >> benchmark(regular(), iterate.parallel(), replications =
    >> 100, columns = c("test", "elapsed", "relative")) ## test
    >> elapsed relative ## 2 iterate.parallel() 7.517 2.482 ## 1
    >> regular() 3.028 1.000
    >> 
    >> Honestly, just use log(c1[-1]/c1[-len]). The code is
    >> simple and easy to understand and it runs pretty
    >> fast. There is usually no reason to make it more
    >> complicated.  --Ista
    >> 
    >> > On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn
    >> <istazahn at gmail.com> wrote:
    >> > >
    >> > > On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu
    >> <liuwensui at gmail.com> wrote:
    >> > > >
    >> > > > Why?
    >> > >
    >> > > The operations required for this algorithm are
    >> vectorized, as are most > > operations in R. There is no
    >> need to iterate through each element.  > > Using
    >> Vectorize to achieve the iteration is no better than
    >> using > > *apply or a for-loop, and betrays the same
    >> basic lack of insight into > > basic principles of
    >> programming in R.
    >> > >
    >> > > And/or, if you want a more practical reason:
    >> > >
    >> > > > c1 <- 1:1000000 > > > len <- 1000000 > > >
    >> system.time( s1 <- log(c1[-1]/c1[-len])) > > user system
    >> elapsed > > 0.031 0.004 0.035 > > > system.time(s2 <-
    >> Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len)) >
    >> > user system elapsed > > 1.258 0.022 1.282
    >> > >
    >> > > Best, > > Ista
    >> > >
    >> > > >
    >> > > > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn
    >> <istazahn at gmail.com> wrote:
    >> > > >>
    >> > > >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu
    >> <liuwensui at gmail.com> wrote:
    >> > > >> >
    >> > > >> > or this one:
    >> > > >> >
    >> > > >> > (Vectorize(function(i) log(c1[i + 1] / c1[i]))
    >> (1:len))
    >> > > >>
    >> > > >> Oh dear god no.
    >> > > >>
    >> > > >> >
    >> > > >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8
    >> <rsherry8 at comcast.net> wrote:
    >> > > >> > >
    >> > > >> > >
    >> > > >> > > It is my impression that good R programmers
    >> make very little use of the > > >> > > for
    >> statement. Please consider the following > > >> > > R
    >> statement: > > >> > > for( i in 1:(len-1) ) s[i] =
    >> log(c1[i+1]/c1[i], base = exp(1) ) > > >> > > One problem
    >> I have found with this statement is that s must exist
    >> before > > >> > > the statement is run. Can it be written
    >> without using a for > > >> > > loop? Would that be
    >> better?
    >> > > >> > >
    >> > > >> > > Thanks, > > >> > > Bob
    >> > > >> > >
    >> > > >> > > ______________________________________________
    >> > > >> > > R-help at r-project.org mailing list -- To
    >> UNSUBSCRIBE and more, see > > >> > >
    >> https://stat.ethz.ch/mailman/listinfo/r-help > > >> > >
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html > > >> > >
    >> and provide commented, minimal, self-contained,
    >> reproducible code.
    >> > > >> >
    >> > > >> > ______________________________________________ >
    >> > >> > R-help at r-project.org mailing list -- To
    >> UNSUBSCRIBE and more, see > > >> >
    >> https://stat.ethz.ch/mailman/listinfo/r-help > > >> >
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html > > >> > and
    >> provide commented, minimal, self-contained, reproducible
    >> code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From h@enlein @ending from gm@il@com  Tue Sep 25 17:15:24 2018
From: h@enlein @ending from gm@il@com (Michael Haenlein)
Date: Tue, 25 Sep 2018 17:15:24 +0200
Subject: [R] Instagram Analysis
Message-ID: <CAOyz9G50VYP7=ekm2uspoq+8U=PVwn9eFjg5_zDV9sxXKp2rDA@mail.gmail.com>

Dear all,

I'm looking for an R package that allows me to analyze Instagram.
Specifically I would like to download for a given account the list of other
accounts that either this account follows or that follow this account (the
followers and following numbers).

I know there is instaR but this package is quite old (August 2016) and
seems not to have been updated in the meantime. Is there a new package or
any other way to get this information in an easy way?

Thanks,

Michael

	[[alternative HTML version deleted]]


From h@@@n@diw@n @ending from gm@il@com  Tue Sep 25 17:24:31 2018
From: h@@@n@diw@n @ending from gm@il@com (Hasan Diwan)
Date: Tue, 25 Sep 2018 08:24:31 -0700
Subject: [R] Instagram Analysis
In-Reply-To: <CAOyz9G50VYP7=ekm2uspoq+8U=PVwn9eFjg5_zDV9sxXKp2rDA@mail.gmail.com>
References: <CAOyz9G50VYP7=ekm2uspoq+8U=PVwn9eFjg5_zDV9sxXKp2rDA@mail.gmail.com>
Message-ID: <CAP+bYWBPJVToY8qtvrYb3niMs+3ZxW78FTK+57kjDkMuPiAA4A@mail.gmail.com>

Michael,
On Tue, 25 Sep 2018 at 08:15, Michael Haenlein <haenlein at gmail.com> wrote:
> I'm looking for an R package that allows me to analyze Instagram.
> Specifically I would like to download for a given account the list of other
> accounts that either this account follows or that follow this account (the
> followers and following numbers).
> any other way to get this information in an easy way?

Send a get request to
https://api.instagram.com/v1/users/{user-id}/follows?access_token=ACCESS-TOKEN
and you'll get JSON back with (among other things) the accounts said
user follows. Hope that helps... Feel free to drop me a line off-list
should you need further help. -- H


-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable


From li@t@ @ending from dewey@myzen@co@uk  Tue Sep 25 17:29:48 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 25 Sep 2018 16:29:48 +0100
Subject: [R] About uniroot error
In-Reply-To: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>
References: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>
Message-ID: <3719d912-731a-06ad-6dfc-88295b3ce41c@dewey.myzen.co.uk>

Dear Tania

Without your dataset I am not sure but a comment below to suggest where 
to look next.

On 24/09/2018 18:37, Tania Morgado Garcia wrote:
> Thanks for your answers. I continue to learn R and now I am detained in an
> error with uniroot that I see happens to others but I can not find the
> solution. Next the code
> 
> x1 <- BAaxOrd$V1
> y1 <- BAaxOrd$V2
> x1R <- BAaxOrdRCOS$V1
> y1R <- BAaxOrdRCOS$V2
> FCOS1 <- splinefun(smooth.spline(x1,y1))
> FRCOS1 <- splinefun(smooth.spline(x1R,y1R))
> FCOS1 <- Vectorize(FCOS1)
> FRCOS1 <- Vectorize(FRCOS1)
> 
> req(input$file1)
>        tryCatch(
>        {
>          df <- read.csv(input$file1$datapath,
>                         header = input$header,
>                         sep = "\t",
>                         quote = '"')
>        },
>        error = function(e) {
>          # return a safeError if a parsing error occurs
>          stop(safeError(e))
>        }
>      )
> 
>      #if(input$disp == "head") {
>       # return(head(df))
>      #}
>      #else {
> 
>        # Determine Carbon Reserve
>        for (row in 1:nrow(df)) {
>          if(df$ts==1) {
>             prof <-
> uniroot(f=function(x){FCOS1(x1)-df$carbono},interval=c(0,20))$root
>             limsup <- prof + df$pu
>             reserva <- integrate(FRCOS1,prof,limsup)$value
>          }

Are you sure that FCOS(x1) - df$carbono returns a scalar? It looks as 
though it returns a vector to me but without your data I am not sure so 
ignore my post if it does.
> 
> The if is because there are several types of soil, but I only put one.  The
> error is
> 
> Warning in if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
>    the condition has length > 1 and only the first element will be used
> Warning in if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
>    the condition has length > 1 and only the first element will be used
> Warning: Error in uniroot: f() values at end points not of opposite sign
> 
> The file that I load with data has a single row with the values ts = 1,
> carbon = 2.04 and pu = 15 (I left only that row to be able to determine the
> origin of the error). The functions FCOS1 and FRCOS1 are monotone
> decreasing.Graphic attachment of FCOS1
> 
> I would appreciate some help in this regard
> 
> thanks a lot
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tmg1970 @ending from gm@il@com  Tue Sep 25 17:46:58 2018
From: tmg1970 @ending from gm@il@com (Tania Morgado Garcia)
Date: Tue, 25 Sep 2018 10:46:58 -0500
Subject: [R] About uniroot error
In-Reply-To: <3719d912-731a-06ad-6dfc-88295b3ce41c@dewey.myzen.co.uk>
References: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>
 <3719d912-731a-06ad-6dfc-88295b3ce41c@dewey.myzen.co.uk>
Message-ID: <CAGObTgpdas1O45x_mr4fc1e2BwEzDU2xwcF_q3+oMf+-ObJLjw@mail.gmail.com>

Thanks for your reply. You're right, return a vector. An example of the
dataset:
ts pu carbono
1 15 2.04
1 37 1.27
1 55 0.93
1 80 0.5
1 105 0.49
1 22 2.08
1 41 1.43
1 65 0.78

The data that originate the FCOS and FRCOS pattern functions are others,
which I only use to obtain the functions.

Thanks again

El mar., 25 sept. 2018 a las 10:29, Michael Dewey (<lists at dewey.myzen.co.uk>)
escribi?:

> Dear Tania
>
> Without your dataset I am not sure but a comment below to suggest where
> to look next.
>
> On 24/09/2018 18:37, Tania Morgado Garcia wrote:
> > Thanks for your answers. I continue to learn R and now I am detained in
> an
> > error with uniroot that I see happens to others but I can not find the
> > solution. Next the code
> >
> > x1 <- BAaxOrd$V1
> > y1 <- BAaxOrd$V2
> > x1R <- BAaxOrdRCOS$V1
> > y1R <- BAaxOrdRCOS$V2
> > FCOS1 <- splinefun(smooth.spline(x1,y1))
> > FRCOS1 <- splinefun(smooth.spline(x1R,y1R))
> > FCOS1 <- Vectorize(FCOS1)
> > FRCOS1 <- Vectorize(FRCOS1)
> >
> > req(input$file1)
> >        tryCatch(
> >        {
> >          df <- read.csv(input$file1$datapath,
> >                         header = input$header,
> >                         sep = "\t",
> >                         quote = '"')
> >        },
> >        error = function(e) {
> >          # return a safeError if a parsing error occurs
> >          stop(safeError(e))
> >        }
> >      )
> >
> >      #if(input$disp == "head") {
> >       # return(head(df))
> >      #}
> >      #else {
> >
> >        # Determine Carbon Reserve
> >        for (row in 1:nrow(df)) {
> >          if(df$ts==1) {
> >             prof <-
> > uniroot(f=function(x){FCOS1(x1)-df$carbono},interval=c(0,20))$root
> >             limsup <- prof + df$pu
> >             reserva <- integrate(FRCOS1,prof,limsup)$value
> >          }
>
> Are you sure that FCOS(x1) - df$carbono returns a scalar? It looks as
> though it returns a vector to me but without your data I am not sure so
> ignore my post if it does.
> >
> > The if is because there are several types of soil, but I only put one.
> The
> > error is
> >
> > Warning in if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
> >    the condition has length > 1 and only the first element will be used
> > Warning in if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
> >    the condition has length > 1 and only the first element will be used
> > Warning: Error in uniroot: f() values at end points not of opposite sign
> >
> > The file that I load with data has a single row with the values ts = 1,
> > carbon = 2.04 and pu = 15 (I left only that row to be able to determine
> the
> > origin of the error). The functions FCOS1 and FRCOS1 are monotone
> > decreasing.Graphic attachment of FCOS1
> >
> > I would appreciate some help in this regard
> >
> > thanks a lot
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From i@co@tig@n @ending from me@com  Wed Sep 26 07:10:47 2018
From: i@co@tig@n @ending from me@com (Imanuel Costigan)
Date: Wed, 26 Sep 2018 15:10:47 +1000
Subject: [R] Odd R CMD build behaviour on Windows
References: <5D9D741F94C2FC498DE8D3CE76553DBEAB41D3CB@PWMXS0032.btfin.com>
Message-ID: <B2CCA9A8-BED4-4FCB-8EC7-F4F136EFD04B@me.com>

Hi all

I am finding that on Windows 10:

* the archive file produced by R (i386) CMD build command saves the resulting archive file in the present working directory 
* ...BUT the archive produced by the R (x64) CMD build command is **not** saved in the present working directory. Instead it is saved in the file path produced by `paste0(Sys.getenv("HOMEDRIVE"), Sys.getenv("HOMEPATH"))` or `Sys.getenv("HOMESHARE")` (the former resolves to H:\ which is an alias for the latter). This path is not represented in any other environment variables returned by Sys.getenv()

This behaviour persists for R-3.5.1 (release) and R-3.4.4. It also persists after I uninstall R and Rtools and then clean reinstall R-3.4.4 and R-3.5.1.

Has anyone else had this issue? Or tips on what might be causing this?

I am running these commands in Powershell using the following commands:

Thanks.

```
& 'C:\R\R-3.5.1\bin\x64\R.exe' --no-site-file --no-environ --no-save --no-restore --quiet CMD build "C:\users\XXXX\Coding\testpackage\" --no-resave-data --no-manual

# Archive is **not** saved in present working directory, but saved to H:\

& 'C:\R\R-3.5.1\bin\i386\R.exe' --no-site-file --no-environ --no-save --no-restore --quiet CMD build "C:\users\XXXX\Coding\testpackage\" --no-resave-data --no-manual

# Archive is saved in present working directory.
```


From infojomy @ending from gm@il@com  Wed Sep 26 09:55:08 2018
From: infojomy @ending from gm@il@com (Jomy Jose)
Date: Wed, 26 Sep 2018 13:25:08 +0530
Subject: [R] Accessing files from Linux Server
Message-ID: <CADGufDE=08FQzLGLssKZyuAEu0UcYhECpPXWMRUyktaEMFb1yg@mail.gmail.com>

Hi
Which R package can be best employed to access the files in Linux server

Thanks in advance
Jose

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Wed Sep 26 11:28:53 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Wed, 26 Sep 2018 10:28:53 +0100
Subject: [R] Accessing files from Linux Server
In-Reply-To: <CADGufDE=08FQzLGLssKZyuAEu0UcYhECpPXWMRUyktaEMFb1yg@mail.gmail.com>
References: <CADGufDE=08FQzLGLssKZyuAEu0UcYhECpPXWMRUyktaEMFb1yg@mail.gmail.com>
Message-ID: <a51da657-5107-52f3-bf3d-9e44037a0e90@sapo.pt>

Hello,

There are functions in base R to access files, you will need an external 
package only for special file types (such as, for instance, .xls or JSON).

At an R prompt type

?read.table
?readLines
?file
?scan

and start from there. I suggest you start with the first, it's the most 
used of all. And tghe first of those pages have links to their companion 
'write' versions.

There are also packages to read from the web.

Hope this helps,

Rui Barradas

?s 08:55 de 26/09/2018, Jomy Jose escreveu:
> Hi
> Which R package can be best employed to access the files in Linux server
> 
> Thanks in advance
> Jose
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Anne@Ch@tton @ending from hcuge@ch  Wed Sep 26 10:42:56 2018
From: Anne@Ch@tton @ending from hcuge@ch (CHATTON Anne)
Date: Wed, 26 Sep 2018 08:42:56 +0000
Subject: [R] Problems to obtain standardized betas in multiply-imputed data
Message-ID: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>

Dear all,

I am having problems in obtaining standardized betas on a multiply-imputed data set. Here are the codes I used?:
imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
Up to here everything is fine. But when I ask for the standardized coefficients of the multiply-imputed regressions using this command?:
sdBeta <- lm.beta(FitImp)
I get the following error message: 
Error in b * sx : argument non num?rique pour un op?rateur binaire

Can anyone help me with this please?

Anne


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Wed Sep 26 16:00:08 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Wed, 26 Sep 2018 10:00:08 -0400
Subject: [R] Summarizing R script
In-Reply-To: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
Message-ID: <CAPQaxLMOTx+cOpxu+SO=k=BdiqaOjg+A8JkGQF+q-zsifN54tA@mail.gmail.com>

R users,

  Is anyone aware of the proper procedure for summarizing a script(your
complete list of functions, arguments , and error codes within your R
console for say a formal report or publication?

Many thanks,

Best wishes,

Spencer Brackett

---------- Forwarded message ---------
From: CHATTON Anne via R-help <r-help at r-project.org>
Date: Wed, Sep 26, 2018 at 6:03 AM
Subject: [R] Problems to obtain standardized betas in multiply-imputed data
To: r-help at r-project.org <r-help at r-project.org>


Dear all,

I am having problems in obtaining standardized betas on a multiply-imputed
data set. Here are the codes I used :
imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
Up to here everything is fine. But when I ask for the standardized
coefficients of the multiply-imputed regressions using this command :
sdBeta <- lm.beta(FitImp)
I get the following error message:
Error in b * sx : argument non num?rique pour un op?rateur binaire

Can anyone help me with this please?

Anne

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rkoenker @ending from illinoi@@edu  Wed Sep 26 16:06:31 2018
From: rkoenker @ending from illinoi@@edu (Roger Koenker)
Date: Wed, 26 Sep 2018 15:06:31 +0100
Subject: [R] Summarizing R script
In-Reply-To: <f3b031553cdd468a8fe5da3b148b9564@CHIHT4.ad.uillinois.edu>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
 <f3b031553cdd468a8fe5da3b148b9564@CHIHT4.ad.uillinois.edu>
Message-ID: <62534FAE-2A72-4EBE-8A54-DFD5DF2F1964@illinois.edu>

I use R CMD BATCH foo which produces a file called foo.Rout and provided the script includes
sessionInfo() constitutes a quite sufficient summary for my purposes, it isn?t exactly pretty, but it
is informative.

> On Sep 26, 2018, at 3:00 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> 
> R users,
> 
>  Is anyone aware of the proper procedure for summarizing a script(your
> complete list of functions, arguments , and error codes within your R
> console for say a formal report or publication?
> 
> Many thanks,
> 
> Best wishes,
> 
> Spencer Brackett
> 
> ---------- Forwarded message ---------
> From: CHATTON Anne via R-help <r-help at r-project.org>
> Date: Wed, Sep 26, 2018 at 6:03 AM
> Subject: [R] Problems to obtain standardized betas in multiply-imputed data
> To: r-help at r-project.org <r-help at r-project.org>
> 
> 
> Dear all,
> 
> I am having problems in obtaining standardized betas on a multiply-imputed
> data set. Here are the codes I used :
> imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
> FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
> Up to here everything is fine. But when I ask for the standardized
> coefficients of the multiply-imputed regressions using this command :
> sdBeta <- lm.beta(FitImp)
> I get the following error message:
> Error in b * sx : argument non num?rique pour un op?rateur binaire
> 
> Can anyone help me with this please?
> 
> Anne
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @pencer@gr@ve@ @ending from effectivedefen@e@org  Wed Sep 26 16:24:32 2018
From: @pencer@gr@ve@ @ending from effectivedefen@e@org (Spencer Graves)
Date: Wed, 26 Sep 2018 09:24:32 -0500
Subject: [R] Summarizing R script
In-Reply-To: <62534FAE-2A72-4EBE-8A54-DFD5DF2F1964@illinois.edu>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
 <f3b031553cdd468a8fe5da3b148b9564@CHIHT4.ad.uillinois.edu>
 <62534FAE-2A72-4EBE-8A54-DFD5DF2F1964@illinois.edu>
Message-ID: <5ec95596-5248-abf9-75fe-2cfba219874e@effectivedefense.org>



 ????? It depends on what you want, but I've found it very useful to 
create packages and submitting them to CRAN.? See "Creating R Packages" 
for how to do that.[1]? Part of this involves creating vignettes using 
Rmarkdown within RStudio.? Creating R packages and routinely running "R 
CMD check" sounds like it would take extra time.? My experience has been 
very much the opposite, because it dramatically reduces the bugs in my 
software and makes it vastly easier to find the bugs that still exist.? 
AND I have something I can just hand to others, and they can use it.? 
That would be exceedingly difficult otherwise.


 ????? And there are publications like "R Journal" that are looking for 
descriptions of what you've done.? I have a paper in "R Journal" 
describing the "sos" package;? that article is a vignette in that 
package.? This process has worked for me.[2]


 ?????? Spencer


[1] Available from help.start().? See also 
"https://cran.r-project.org/doc/manuals/r-release/R-exts.html".


[2] The "sos" package is the fastest literature search I know for 
anything statistical.? It's availability on CRAN combined with the R 
Journal article got me invited to help organize a plenary session on 
"Navigating the R Package Universe" at the useR!2017 conference in 
Brussels last year.? This is an example of how creating an R package 
with a vignette has helped me find an audience.


On 2018-09-26 09:06, Roger Koenker wrote:
> I use R CMD BATCH foo which produces a file called foo.Rout and provided the script includes
> sessionInfo() constitutes a quite sufficient summary for my purposes, it isn?t exactly pretty, but it
> is informative.
>
>> On Sep 26, 2018, at 3:00 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>>
>> R users,
>>
>>   Is anyone aware of the proper procedure for summarizing a script(your
>> complete list of functions, arguments , and error codes within your R
>> console for say a formal report or publication?
>>
>> Many thanks,
>>
>> Best wishes,
>>
>> Spencer Brackett
>>
>> ---------- Forwarded message ---------
>> From: CHATTON Anne via R-help <r-help at r-project.org>
>> Date: Wed, Sep 26, 2018 at 6:03 AM
>> Subject: [R] Problems to obtain standardized betas in multiply-imputed data
>> To: r-help at r-project.org <r-help at r-project.org>
>>
>>
>> Dear all,
>>
>> I am having problems in obtaining standardized betas on a multiply-imputed
>> data set. Here are the codes I used :
>> imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
>> FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
>> Up to here everything is fine. But when I ask for the standardized
>> coefficients of the multiply-imputed regressions using this command :
>> sdBeta <- lm.beta(FitImp)
>> I get the following error message:
>> Error in b * sx : argument non num?rique pour un op?rateur binaire
>>
>> Can anyone help me with this please?
>>
>> Anne
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @ending from gm@il@com  Wed Sep 26 17:28:50 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 26 Sep 2018 11:28:50 -0400
Subject: [R] Summarizing R script
In-Reply-To: <5ec95596-5248-abf9-75fe-2cfba219874e@effectivedefense.org>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
 <f3b031553cdd468a8fe5da3b148b9564@CHIHT4.ad.uillinois.edu>
 <62534FAE-2A72-4EBE-8A54-DFD5DF2F1964@illinois.edu>
 <5ec95596-5248-abf9-75fe-2cfba219874e@effectivedefense.org>
Message-ID: <3223af2d-e963-9607-8707-82c8d71dfc0f@gmail.com>

On 26/09/2018 10:24 AM, Spencer Graves wrote:
> 
> 
>   ????? It depends on what you want, but I've found it very useful to
> create packages and submitting them to CRAN.? See "Creating R Packages"
> for how to do that.[1]? Part of this involves creating vignettes using
> Rmarkdown within RStudio.? Creating R packages and routinely running "R
> CMD check" sounds like it would take extra time.? My experience has been
> very much the opposite, because it dramatically reduces the bugs in my
> software and makes it vastly easier to find the bugs that still exist.
> AND I have something I can just hand to others, and they can use it.
> That would be exceedingly difficult otherwise.

I think that's very good advice.  Even if the R script is something not 
suitable for publication on CRAN (containing proprietary data, or 
solving one unique problem, for example), preparing it as though for 
submission there enforces some good coding and documentation practices.

Duncan Murdoch

> 
> 
>   ????? And there are publications like "R Journal" that are looking for
> descriptions of what you've done.? I have a paper in "R Journal"
> describing the "sos" package;? that article is a vignette in that
> package.? This process has worked for me.[2]
> 
> 
>   ?????? Spencer
> 
> 
> [1] Available from help.start().? See also
> "https://cran.r-project.org/doc/manuals/r-release/R-exts.html".
> 
> 
> [2] The "sos" package is the fastest literature search I know for
> anything statistical.? It's availability on CRAN combined with the R
> Journal article got me invited to help organize a plenary session on
> "Navigating the R Package Universe" at the useR!2017 conference in
> Brussels last year.? This is an example of how creating an R package
> with a vignette has helped me find an audience.
> 
> 
> On 2018-09-26 09:06, Roger Koenker wrote:
>> I use R CMD BATCH foo which produces a file called foo.Rout and provided the script includes
>> sessionInfo() constitutes a quite sufficient summary for my purposes, it isn?t exactly pretty, but it
>> is informative.
>>
>>> On Sep 26, 2018, at 3:00 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>>>
>>> R users,
>>>
>>>    Is anyone aware of the proper procedure for summarizing a script(your
>>> complete list of functions, arguments , and error codes within your R
>>> console for say a formal report or publication?
>>>
>>> Many thanks,
>>>
>>> Best wishes,
>>>
>>> Spencer Brackett
>>>
>>> ---------- Forwarded message ---------
>>> From: CHATTON Anne via R-help <r-help at r-project.org>
>>> Date: Wed, Sep 26, 2018 at 6:03 AM
>>> Subject: [R] Problems to obtain standardized betas in multiply-imputed data
>>> To: r-help at r-project.org <r-help at r-project.org>
>>>
>>>
>>> Dear all,
>>>
>>> I am having problems in obtaining standardized betas on a multiply-imputed
>>> data set. Here are the codes I used :
>>> imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
>>> FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
>>> Up to here everything is fine. But when I ask for the standardized
>>> coefficients of the multiply-imputed regressions using this command :
>>> sdBeta <- lm.beta(FitImp)
>>> I get the following error message:
>>> Error in b * sx : argument non num?rique pour un op?rateur binaire
>>>
>>> Can anyone help me with this please?
>>>
>>> Anne
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@cqueen1 @ending from llnl@gov  Wed Sep 26 17:38:37 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Wed, 26 Sep 2018 15:38:37 +0000
Subject: [R] Summarizing R script
In-Reply-To: <CAPQaxLMOTx+cOpxu+SO=k=BdiqaOjg+A8JkGQF+q-zsifN54tA@mail.gmail.com>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
 <CAPQaxLMOTx+cOpxu+SO=k=BdiqaOjg+A8JkGQF+q-zsifN54tA@mail.gmail.com>
Message-ID: <236B8DC2-5768-47DB-880C-9645E4F8E5C0@llnl.gov>

I wonder if the lintr package might be helpful.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/26/18, 7:00 AM, "R-help on behalf of Spencer Brackett" <r-help-bounces at r-project.org on behalf of spbrackett20 at saintjosephhs.com> wrote:

    R users,
    
      Is anyone aware of the proper procedure for summarizing a script(your
    complete list of functions, arguments , and error codes within your R
    console for say a formal report or publication?
    
    Many thanks,
    
    Best wishes,
    
    Spencer Brackett
    
    ---------- Forwarded message ---------
    From: CHATTON Anne via R-help <r-help at r-project.org>
    Date: Wed, Sep 26, 2018 at 6:03 AM
    Subject: [R] Problems to obtain standardized betas in multiply-imputed data
    To: r-help at r-project.org <r-help at r-project.org>
    
    
    Dear all,
    
    I am having problems in obtaining standardized betas on a multiply-imputed
    data set. Here are the codes I used :
    imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
    FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
    Up to here everything is fine. But when I ask for the standardized
    coefficients of the multiply-imputed regressions using this command :
    sdBeta <- lm.beta(FitImp)
    I get the following error message:
    Error in b * sx : argument non num?rique pour un op?rateur binaire
    
    Can anyone help me with this please?
    
    Anne
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @ending from gm@il@com  Wed Sep 26 17:58:48 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 26 Sep 2018 08:58:48 -0700
Subject: [R] Summarizing R script
In-Reply-To: <236B8DC2-5768-47DB-880C-9645E4F8E5C0@llnl.gov>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
 <CAPQaxLMOTx+cOpxu+SO=k=BdiqaOjg+A8JkGQF+q-zsifN54tA@mail.gmail.com>
 <236B8DC2-5768-47DB-880C-9645E4F8E5C0@llnl.gov>
Message-ID: <CAGxFJbSan7ixPL_vuyxRcEPq49chPTSeVsD2AgGWZBcuyomrOQ@mail.gmail.com>

All suggestions made by others here are useful, but I would suggest that
computer scientists are probably a better -- or at least valuable
additional -- resource for this sort of knowledge than R programmers. A web
search on "self-documenting code" and/or "reproducible research" should
yield lots of relevant hits. For R specifically, the CRAN "Reproducible
Research" task view should be useful..

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 26, 2018 at 8:39 AM MacQueen, Don via R-help <
r-help at r-project.org> wrote:

> I wonder if the lintr package might be helpful.
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 9/26/18, 7:00 AM, "R-help on behalf of Spencer Brackett" <
> r-help-bounces at r-project.org on behalf of spbrackett20 at saintjosephhs.com>
> wrote:
>
>     R users,
>
>       Is anyone aware of the proper procedure for summarizing a script(your
>     complete list of functions, arguments , and error codes within your R
>     console for say a formal report or publication?
>
>     Many thanks,
>
>     Best wishes,
>
>     Spencer Brackett
>
>     ---------- Forwarded message ---------
>     From: CHATTON Anne via R-help <r-help at r-project.org>
>     Date: Wed, Sep 26, 2018 at 6:03 AM
>     Subject: [R] Problems to obtain standardized betas in multiply-imputed
> data
>     To: r-help at r-project.org <r-help at r-project.org>
>
>
>     Dear all,
>
>     I am having problems in obtaining standardized betas on a
> multiply-imputed
>     data set. Here are the codes I used :
>     imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
>     FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
>     Up to here everything is fine. But when I ask for the standardized
>     coefficients of the multiply-imputed regressions using this command :
>     sdBeta <- lm.beta(FitImp)
>     I get the following error message:
>     Error in b * sx : argument non num?rique pour un op?rateur binaire
>
>     Can anyone help me with this please?
>
>     Anne
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @ending from effectivedefen@e@org  Wed Sep 26 22:16:33 2018
From: @pencer@gr@ve@ @ending from effectivedefen@e@org (Spencer Graves)
Date: Wed, 26 Sep 2018 15:16:33 -0500
Subject: [R] using S4 objects in "with"?
Message-ID: <d943cdd7-d0ea-9d55-7831-9f89db45b66b@effectivedefense.org>

 ????? Is there anything comparable to "with" for S4 objects?


EXAMPLE:


 ????? A "Wave" object in the tuneR package has slots "left" and 
"right", plus others.? I'd like to be able to do something like the 
following:


library(tuneR)
x <- seq(0, 2*pi, length = 6)
all.equal(x, rev(x))
channel <- round(32000 * sin(440 * x))
Wobj <- Wave(left = channel, right=rev(channel))

with(Wobj, quantile(left-right))


 ????? ** This last statement throws "Error ... object 'left' not found".


 ????? Is there something comparable to "with" that can do this?


 ????? Thanks,
 ????? Spencer Graves


From murdoch@dunc@n @ending from gm@il@com  Wed Sep 26 22:34:46 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 26 Sep 2018 16:34:46 -0400
Subject: [R] using S4 objects in "with"?
In-Reply-To: <d943cdd7-d0ea-9d55-7831-9f89db45b66b@effectivedefense.org>
References: <d943cdd7-d0ea-9d55-7831-9f89db45b66b@effectivedefense.org>
Message-ID: <4d6f033e-3929-3648-a408-55c78f29a9bc@gmail.com>

On 26/09/2018 4:16 PM, Spencer Graves wrote:
>   ????? Is there anything comparable to "with" for S4 objects?
> 
> 
> EXAMPLE:
> 
> 
>   ????? A "Wave" object in the tuneR package has slots "left" and
> "right", plus others.? I'd like to be able to do something like the
> following:
> 
> 
> library(tuneR)
> x <- seq(0, 2*pi, length = 6)
> all.equal(x, rev(x))
> channel <- round(32000 * sin(440 * x))
> Wobj <- Wave(left = channel, right=rev(channel))
> 
> with(Wobj, quantile(left-right))
> 
> 
>   ????? ** This last statement throws "Error ... object 'left' not found".
> 
> 
>   ????? Is there something comparable to "with" that can do this?

I don't know of anything that is "officially sanctioned".  A couple of 
ideas:

1.  Slots in S4 are stored in attributes.  So

   with(attributes(Wobj), quantile(left - right))

works.  BUT:  as far as I recall, this is an undocumented implementation 
detail, and you aren't supposed to count on it.

2.  You could write an as.list() method for the Wave class, then

   with(as.list(Wobj),

would work.  This may be the "right" way to do this.

Duncan Murdoch


From @pencer@gr@ve@ @ending from effectivedefen@e@org  Wed Sep 26 23:23:17 2018
From: @pencer@gr@ve@ @ending from effectivedefen@e@org (Spencer Graves)
Date: Wed, 26 Sep 2018 16:23:17 -0500
Subject: [R] using S4 objects in "with"?
In-Reply-To: <4d6f033e-3929-3648-a408-55c78f29a9bc@gmail.com>
References: <d943cdd7-d0ea-9d55-7831-9f89db45b66b@effectivedefense.org>
 <4d6f033e-3929-3648-a408-55c78f29a9bc@gmail.com>
Message-ID: <243b9ca4-10f9-b331-841b-6d4c69677559@effectivedefense.org>



On 2018-09-26 15:34, Duncan Murdoch wrote:
> On 26/09/2018 4:16 PM, Spencer Graves wrote:
>> ? ????? Is there anything comparable to "with" for S4 objects?
>>
>>
>> EXAMPLE:
>>
>>
>> ? ????? A "Wave" object in the tuneR package has slots "left" and
>> "right", plus others.? I'd like to be able to do something like the
>> following:
>>
>>
>> library(tuneR)
>> x <- seq(0, 2*pi, length = 6)
>> all.equal(x, rev(x))
>> channel <- round(32000 * sin(440 * x))
>> Wobj <- Wave(left = channel, right=rev(channel))
>>
>> with(Wobj, quantile(left-right))
>>
>>
>> ? ????? ** This last statement throws "Error ... object 'left' not 
>> found".
>>
>>
>> ? ????? Is there something comparable to "with" that can do this?
>
> I don't know of anything that is "officially sanctioned".? A couple of 
> ideas:
>
> 1.? Slots in S4 are stored in attributes.? So
>
> ? with(attributes(Wobj), quantile(left - right))
>
> works.? BUT:? as far as I recall, this is an undocumented 
> implementation detail, and you aren't supposed to count on it.
>
> 2.? You could write an as.list() method for the Wave class, then
>
> ? with(as.list(Wobj),
>
> would work.? This may be the "right" way to do this.


 ????? Thanks.? I'd prefer to have as.list.default convert every S4 
object to a list.? And have with(S4_object, ...) interpret it equivalent 
to with(as.list(S4_object), ...).


 ????? I think I'll do it other ways for the time being.


 ????? Best Wishes,
 ????? Spencer

>
> Duncan Murdoch


From m@rongiu@luigi @ending from gm@il@com  Thu Sep 27 09:28:49 2018
From: m@rongiu@luigi @ending from gm@il@com (Luigi Marongiu)
Date: Thu, 27 Sep 2018 09:28:49 +0200
Subject: [R] Erase content of dataframe in a single stroke
Message-ID: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>

Dear all,
I would like to erase the content of a dataframe -- but not the
dataframe itself -- in a simple and fast way.
At the moment I do that by re-defining the dataframe itself in this way:

> df <- data.frame(A = numeric(),
+                   B = numeric(),
+                   C = character())
> # assign
> A <- 5
> B <- 0.6
> C <- 103
> # load
> R <- cbind(A, B, C)
> df <- rbind(df, R)
> df
  A   B   C
1 5 0.6 103
> # erase
> df <- data.frame(A = numeric(),
+                  B = numeric(),
+                  C = character())
> df
[1] A B C
<0 rows> (or 0-length row.names)
>

Is there a way to erase the content of the dataframe in a simplier
(acting on all the dataframe at once instead of naming each column
individually) and nicer (with a specific erasure command instead of
re-defyining the object itself) way?

Thank you.
-- 
Best regards,
Luigi


From drjimlemon @ending from gm@il@com  Thu Sep 27 09:44:52 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 27 Sep 2018 17:44:52 +1000
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
Message-ID: <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>

Hi Luigi,
Maybe this:

testdf<-data.frame(A=1,B=2,C=3)
> testdf
 A B C
1 1 2 3
toNull<-function(x) return(NULL)
testdf<-sapply(testdf,toNull)

Jim
On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I would like to erase the content of a dataframe -- but not the
> dataframe itself -- in a simple and fast way.
> At the moment I do that by re-defining the dataframe itself in this way:
>
> > df <- data.frame(A = numeric(),
> +                   B = numeric(),
> +                   C = character())
> > # assign
> > A <- 5
> > B <- 0.6
> > C <- 103
> > # load
> > R <- cbind(A, B, C)
> > df <- rbind(df, R)
> > df
>   A   B   C
> 1 5 0.6 103
> > # erase
> > df <- data.frame(A = numeric(),
> +                  B = numeric(),
> +                  C = character())
> > df
> [1] A B C
> <0 rows> (or 0-length row.names)
> >
>
> Is there a way to erase the content of the dataframe in a simplier
> (acting on all the dataframe at once instead of naming each column
> individually) and nicer (with a specific erasure command instead of
> re-defyining the object itself) way?
>
> Thank you.
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon @ending from gm@il@com  Thu Sep 27 10:12:11 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 27 Sep 2018 18:12:11 +1000
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
Message-ID: <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>

Ah, yes, try 'as.data.frame" on it.

Jim

On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Thank you Jim,
> this requires the definition of an ad hoc function; strange that R
> does not have a function for this purpose...
> Anyway, it works but it changes the structure of the data. By
> redefining the dataframe as I did, I obtain:
>
> > df
> [1] A B C
> <0 rows> (or 0-length row.names)
> > str(df)
> 'data.frame': 0 obs. of  3 variables:
>  $ A: num
>  $ B: num
>  $ C: num
>
> When applying your function, I get:
>
> > df
> $A
> NULL
>
> $B
> NULL
>
> $C
> NULL
>
> > str(df)
> List of 3
>  $ A: NULL
>  $ B: NULL
>  $ C: NULL
>
> The dataframe has become a list. Would that affect downstream applications?
>
> Thank you,
> Luigi
> On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Luigi,
> > Maybe this:
> >
> > testdf<-data.frame(A=1,B=2,C=3)
> > > testdf
> >  A B C
> > 1 1 2 3
> > toNull<-function(x) return(NULL)
> > testdf<-sapply(testdf,toNull)
> >
> > Jim
> > On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Dear all,
> > > I would like to erase the content of a dataframe -- but not the
> > > dataframe itself -- in a simple and fast way.
> > > At the moment I do that by re-defining the dataframe itself in this way:
> > >
> > > > df <- data.frame(A = numeric(),
> > > +                   B = numeric(),
> > > +                   C = character())
> > > > # assign
> > > > A <- 5
> > > > B <- 0.6
> > > > C <- 103
> > > > # load
> > > > R <- cbind(A, B, C)
> > > > df <- rbind(df, R)
> > > > df
> > >   A   B   C
> > > 1 5 0.6 103
> > > > # erase
> > > > df <- data.frame(A = numeric(),
> > > +                  B = numeric(),
> > > +                  C = character())
> > > > df
> > > [1] A B C
> > > <0 rows> (or 0-length row.names)
> > > >
> > >
> > > Is there a way to erase the content of the dataframe in a simplier
> > > (acting on all the dataframe at once instead of naming each column
> > > individually) and nicer (with a specific erasure command instead of
> > > re-defyining the object itself) way?
> > >
> > > Thank you.
> > > --
> > > Best regards,
> > > Luigi
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi


From petr@pik@l @ending from prechez@@cz  Thu Sep 27 10:32:51 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 27 Sep 2018 08:32:51 +0000
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
 <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
Message-ID: <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>

Hm

I would use

> testdf<-data.frame(A=c(1,2),B=c(2,3),C=c(3,4))
> str(testdf)
'data.frame':   2 obs. of  3 variables:
 $ A: num  1 2
 $ B: num  2 3
 $ C: num  3 4
> testdf<-testdf[-(1:nrow(testdf)),]
> str(testdf)
'data.frame':   0 obs. of  3 variables:
 $ A: num
 $ B: num
 $ C: num

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
> Sent: Thursday, September 27, 2018 10:12 AM
> To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help mailing list <r-help at r-
> project.org>
> Subject: Re: [R] Erase content of dataframe in a single stroke
>
> Ah, yes, try 'as.data.frame" on it.
>
> Jim
>
> On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >
> > Thank you Jim,
> > this requires the definition of an ad hoc function; strange that R
> > does not have a function for this purpose...
> > Anyway, it works but it changes the structure of the data. By
> > redefining the dataframe as I did, I obtain:
> >
> > > df
> > [1] A B C
> > <0 rows> (or 0-length row.names)
> > > str(df)
> > 'data.frame': 0 obs. of  3 variables:
> >  $ A: num
> >  $ B: num
> >  $ C: num
> >
> > When applying your function, I get:
> >
> > > df
> > $A
> > NULL
> >
> > $B
> > NULL
> >
> > $C
> > NULL
> >
> > > str(df)
> > List of 3
> >  $ A: NULL
> >  $ B: NULL
> >  $ C: NULL
> >
> > The dataframe has become a list. Would that affect downstream
> applications?
> >
> > Thank you,
> > Luigi
> > On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com>
> wrote:
> > >
> > > Hi Luigi,
> > > Maybe this:
> > >
> > > testdf<-data.frame(A=1,B=2,C=3)
> > > > testdf
> > >  A B C
> > > 1 1 2 3
> > > toNull<-function(x) return(NULL)
> > > testdf<-sapply(testdf,toNull)
> > >
> > > Jim
> > > On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu
> <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Dear all,
> > > > I would like to erase the content of a dataframe -- but not the
> > > > dataframe itself -- in a simple and fast way.
> > > > At the moment I do that by re-defining the dataframe itself in this way:
> > > >
> > > > > df <- data.frame(A = numeric(),
> > > > +                   B = numeric(),
> > > > +                   C = character())
> > > > > # assign
> > > > > A <- 5
> > > > > B <- 0.6
> > > > > C <- 103
> > > > > # load
> > > > > R <- cbind(A, B, C)
> > > > > df <- rbind(df, R)
> > > > > df
> > > >   A   B   C
> > > > 1 5 0.6 103
> > > > > # erase
> > > > > df <- data.frame(A = numeric(),
> > > > +                  B = numeric(),
> > > > +                  C = character())
> > > > > df
> > > > [1] A B C
> > > > <0 rows> (or 0-length row.names)
> > > > >
> > > >
> > > > Is there a way to erase the content of the dataframe in a simplier
> > > > (acting on all the dataframe at once instead of naming each column
> > > > individually) and nicer (with a specific erasure command instead
> > > > of re-defyining the object itself) way?
> > > >
> > > > Thank you.
> > > > --
> > > > Best regards,
> > > > Luigi
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From drjimlemon @ending from gm@il@com  Thu Sep 27 10:36:13 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 27 Sep 2018 18:36:13 +1000
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <CAMk+s2QCa8PTkBgzQgkVX06o8O1_jbW-bLHOJ6Bze383bhgK7A@mail.gmail.com>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
 <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
 <CAMk+s2QCa8PTkBgzQgkVX06o8O1_jbW-bLHOJ6Bze383bhgK7A@mail.gmail.com>
Message-ID: <CA+8X3fUqu6a_si7F5PZnPBE-snG0rXx_nSoAR=NgEuiekuHURA@mail.gmail.com>

You're right. Apparently one can form a list with NULL elements but
not a data frame. I just saw Petr's answer, which seems to do the
trick.

Jim
On Thu, Sep 27, 2018 at 6:19 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> I am not sure if I got it right; Now I get:
>
> >  toNull<-function(x) return(NULL)
> >  df<-as.data.frame(sapply(df,toNull))
> >  df
> data frame with 0 columns and 0 rows
> >  str(df)
> 'data.frame': 0 obs. of  0 variables
> On Thu, Sep 27, 2018 at 10:12 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Ah, yes, try 'as.data.frame" on it.
> >
> > Jim
> >
> > On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Thank you Jim,
> > > this requires the definition of an ad hoc function; strange that R
> > > does not have a function for this purpose...
> > > Anyway, it works but it changes the structure of the data. By
> > > redefining the dataframe as I did, I obtain:
> > >
> > > > df
> > > [1] A B C
> > > <0 rows> (or 0-length row.names)
> > > > str(df)
> > > 'data.frame': 0 obs. of  3 variables:
> > >  $ A: num
> > >  $ B: num
> > >  $ C: num
> > >
> > > When applying your function, I get:
> > >
> > > > df
> > > $A
> > > NULL
> > >
> > > $B
> > > NULL
> > >
> > > $C
> > > NULL
> > >
> > > > str(df)
> > > List of 3
> > >  $ A: NULL
> > >  $ B: NULL
> > >  $ C: NULL
> > >
> > > The dataframe has become a list. Would that affect downstream applications?
> > >
> > > Thank you,
> > > Luigi
> > > On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > >
> > > > Hi Luigi,
> > > > Maybe this:
> > > >
> > > > testdf<-data.frame(A=1,B=2,C=3)
> > > > > testdf
> > > >  A B C
> > > > 1 1 2 3
> > > > toNull<-function(x) return(NULL)
> > > > testdf<-sapply(testdf,toNull)
> > > >
> > > > Jim
> > > > On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > > >
> > > > > Dear all,
> > > > > I would like to erase the content of a dataframe -- but not the
> > > > > dataframe itself -- in a simple and fast way.
> > > > > At the moment I do that by re-defining the dataframe itself in this way:
> > > > >
> > > > > > df <- data.frame(A = numeric(),
> > > > > +                   B = numeric(),
> > > > > +                   C = character())
> > > > > > # assign
> > > > > > A <- 5
> > > > > > B <- 0.6
> > > > > > C <- 103
> > > > > > # load
> > > > > > R <- cbind(A, B, C)
> > > > > > df <- rbind(df, R)
> > > > > > df
> > > > >   A   B   C
> > > > > 1 5 0.6 103
> > > > > > # erase
> > > > > > df <- data.frame(A = numeric(),
> > > > > +                  B = numeric(),
> > > > > +                  C = character())
> > > > > > df
> > > > > [1] A B C
> > > > > <0 rows> (or 0-length row.names)
> > > > > >
> > > > >
> > > > > Is there a way to erase the content of the dataframe in a simplier
> > > > > (acting on all the dataframe at once instead of naming each column
> > > > > individually) and nicer (with a specific erasure command instead of
> > > > > re-defyining the object itself) way?
> > > > >
> > > > > Thank you.
> > > > > --
> > > > > Best regards,
> > > > > Luigi
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
>
>
>
> --
> Best regards,
> Luigi


From rhelp @ending from eoo@@dd@@nl  Thu Sep 27 11:11:00 2018
From: rhelp @ending from eoo@@dd@@nl (Jan van der Laan)
Date: Thu, 27 Sep 2018 11:11:00 +0200
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
 <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
 <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>
Message-ID: <5BAC9EA4.50504@eoos.dds.nl>

Or

testdf <- testdf[FALSE, ]

or

testdf <- testdf[numeric(0), ]

which seems to be slightly faster.

Best,
Jan


Op 27-9-2018 om 10:32 schreef PIKAL Petr:
> Hm
>
> I would use
>
>> testdf<-data.frame(A=c(1,2),B=c(2,3),C=c(3,4))
>> str(testdf)
> 'data.frame':   2 obs. of  3 variables:
>   $ A: num  1 2
>   $ B: num  2 3
>   $ C: num  3 4
>> testdf<-testdf[-(1:nrow(testdf)),]
>> str(testdf)
> 'data.frame':   0 obs. of  3 variables:
>   $ A: num
>   $ B: num
>   $ C: num
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
>> Sent: Thursday, September 27, 2018 10:12 AM
>> To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help mailing list <r-help at r-
>> project.org>
>> Subject: Re: [R] Erase content of dataframe in a single stroke
>>
>> Ah, yes, try 'as.data.frame" on it.
>>
>> Jim
>>
>> On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu <marongiu.luigi at gmail.com>
>> wrote:
>>> Thank you Jim,
>>> this requires the definition of an ad hoc function; strange that R
>>> does not have a function for this purpose...
>>> Anyway, it works but it changes the structure of the data. By
>>> redefining the dataframe as I did, I obtain:
>>>
>>>> df
>>> [1] A B C
>>> <0 rows> (or 0-length row.names)
>>>> str(df)
>>> 'data.frame': 0 obs. of  3 variables:
>>>   $ A: num
>>>   $ B: num
>>>   $ C: num
>>>
>>> When applying your function, I get:
>>>
>>>> df
>>> $A
>>> NULL
>>>
>>> $B
>>> NULL
>>>
>>> $C
>>> NULL
>>>
>>>> str(df)
>>> List of 3
>>>   $ A: NULL
>>>   $ B: NULL
>>>   $ C: NULL
>>>
>>> The dataframe has become a list. Would that affect downstream
>> applications?
>>> Thank you,
>>> Luigi
>>> On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>>>> Hi Luigi,
>>>> Maybe this:
>>>>
>>>> testdf<-data.frame(A=1,B=2,C=3)
>>>>> testdf
>>>>   A B C
>>>> 1 1 2 3
>>>> toNull<-function(x) return(NULL)
>>>> testdf<-sapply(testdf,toNull)
>>>>
>>>> Jim
>>>> On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu
>> <marongiu.luigi at gmail.com> wrote:
>>>>> Dear all,
>>>>> I would like to erase the content of a dataframe -- but not the
>>>>> dataframe itself -- in a simple and fast way.
>>>>> At the moment I do that by re-defining the dataframe itself in this way:
>>>>>
>>>>>> df <- data.frame(A = numeric(),
>>>>> +                   B = numeric(),
>>>>> +                   C = character())
>>>>>> # assign
>>>>>> A <- 5
>>>>>> B <- 0.6
>>>>>> C <- 103
>>>>>> # load
>>>>>> R <- cbind(A, B, C)
>>>>>> df <- rbind(df, R)
>>>>>> df
>>>>>    A   B   C
>>>>> 1 5 0.6 103
>>>>>> # erase
>>>>>> df <- data.frame(A = numeric(),
>>>>> +                  B = numeric(),
>>>>> +                  C = character())
>>>>>> df
>>>>> [1] A B C
>>>>> <0 rows> (or 0-length row.names)
>>>>> Is there a way to erase the content of the dataframe in a simplier
>>>>> (acting on all the dataframe at once instead of naming each column
>>>>> individually) and nicer (with a specific erasure command instead
>>>>> of re-defyining the object itself) way?
>>>>>
>>>>> Thank you.
>>>>> --
>>>>> Best regards,
>>>>> Luigi
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> --
>>> Best regards,
>>> Luigi
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From prof@@mit@mitt@l m@ili@g off gm@il@com  Thu Sep 27 11:46:33 2018
From: prof@@mit@mitt@l m@ili@g off gm@il@com (prof@@mit@mitt@l m@ili@g off gm@il@com)
Date: Thu, 27 Sep 2018 15:16:33 +0530
Subject: [R] Erase content of data.frame in a single stroke
Message-ID: <009301d45646$fe3b5df0$fab219d0$@gmail.com>


I never bother with the dimensions of a data frame . That way you can assign
a new var before a for and auto assign it columns inside or nullify the
whole df instead of separate columns?

BR
-----Original Message-----
From: R-help <> On Behalf Of Jim Lemon
Sent: Thursday, September 27, 2018 2:06 PM
To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help mailing list
<r-help at r-project.org>
Subject: Re: [R] Erase content of dataframe in a single stroke

You're right. Apparently one can form a list with NULL elements but not a
data frame. I just saw Petr's answer, which seems to do the trick.

Jim
On Thu, Sep 27, 2018 at 6:19 PM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:
>
> I am not sure if I got it right; Now I get:
>
> >  toNull<-function(x) return(NULL)
> >  df<-as.data.frame(sapply(df,toNull))
> >  df
> data frame with 0 columns and 0 rows
> >  str(df)
> 'data.frame': 0 obs. of  0 variables
> On Thu, Sep 27, 2018 at 10:12 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Ah, yes, try 'as.data.frame" on it.
> >
> > Jim
> >
> > On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> > >
> > > Thank you Jim,
> > > this requires the definition of an ad hoc function; strange that R 
> > > does not have a function for this purpose...
> > > Anyway, it works but it changes the structure of the data. By 
> > > redefining the dataframe as I did, I obtain:
> > >
> > > > df
> > > [1] A B C
> > > <0 rows> (or 0-length row.names)
> > > > str(df)
> > > 'data.frame': 0 obs. of  3 variables:
> > >  $ A: num
> > >  $ B: num
> > >  $ C: num
> > >
> > > When applying your function, I get:
> > >
> > > > df
> > > $A
> > > NULL
> > >
> > > $B
> > > NULL
> > >
> > > $C
> > > NULL
> > >
> > > > str(df)
> > > List of 3
> > >  $ A: NULL
> > >  $ B: NULL
> > >  $ C: NULL
> > >
> > > The dataframe has become a list. Would that affect downstream
applications?
> > >
> > > Thank you,
> > > Luigi
> > > On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com>
wrote:
> > > >
> > > > Hi Luigi,
> > > > Maybe this:
> > > >
> > > > testdf<-data.frame(A=1,B=2,C=3)
> > > > > testdf
> > > >  A B C
> > > > 1 1 2 3
> > > > toNull<-function(x) return(NULL)
> > > > testdf<-sapply(testdf,toNull)
> > > >
> > > > Jim
> > > > On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> > > > >
> > > > > Dear all,
> > > > > I would like to erase the content of a dataframe -- but not 
> > > > > the dataframe itself -- in a simple and fast way.
> > > > > At the moment I do that by re-defining the dataframe itself in
this way:
> > > > >
> > > > > > df <- data.frame(A = numeric(),
> > > > > +                   B = numeric(),
> > > > > +                   C = character())
> > > > > > # assign
> > > > > > A <- 5
> > > > > > B <- 0.6
> > > > > > C <- 103
> > > > > > # load
> > > > > > R <- cbind(A, B, C)
> > > > > > df <- rbind(df, R)
> > > > > > df
> > > > >   A   B   C
> > > > > 1 5 0.6 103
> > > > > > # erase
> > > > > > df <- data.frame(A = numeric(),
> > > > > +                  B = numeric(),
> > > > > +                  C = character())
> > > > > > df
> > > > > [1] A B C
> > > > > <0 rows> (or 0-length row.names)
> > > > > >
> > > > >
> > > > > Is there a way to erase the content of the dataframe in a 
> > > > > simplier (acting on all the dataframe at once instead of 
> > > > > naming each column
> > > > > individually) and nicer (with a specific erasure command 
> > > > > instead of re-defyining the object itself) way?
> > > > >
> > > > > Thank you.
> > > > > --
> > > > > Best regards,
> > > > > Luigi
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, 
> > > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide 
> > > > > http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
>
>
>
> --
> Best regards,
> Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From toth@dene@ @ending from kogentum@hu  Thu Sep 27 12:12:59 2018
From: toth@dene@ @ending from kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Thu, 27 Sep 2018 12:12:59 +0200
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <5BAC9EA4.50504@eoos.dds.nl>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
 <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
 <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>
 <5BAC9EA4.50504@eoos.dds.nl>
Message-ID: <8c1520f7-3ba9-9e39-aae6-9db682a9024f@kogentum.hu>

Hi Luigi,

Actually I doubt that the original problem you try to solve requires the 
initialization of an empty data.frame with a particular structure. 
However, if you think you really need this step, I would write a 
function for it and also consider edge cases.

getSkeleton <- function(x, drop_levels = FALSE) {
   out <- x[numeric(0L), , drop = FALSE]
   if (isTRUE(drop_levels)) out <- droplevels(out)
   out
}

Note that it retains or drops factor levels depending on 'drop_levels'. 
It only matters if you have factors in your data.frame.
'drop = FALSE' is required to guard against silent conversion to a 
vector if 'x' has only one column.

Regards,
Denes



On 09/27/2018 11:11 AM, Jan van der Laan wrote:
> Or
> 
> testdf <- testdf[FALSE, ]
> 
> or
> 
> testdf <- testdf[numeric(0), ]
> 
> which seems to be slightly faster.
> 
> Best,
> Jan
> 
> 
> Op 27-9-2018 om 10:32 schreef PIKAL Petr:
>> Hm
>>
>> I would use
>>
>>> testdf<-data.frame(A=c(1,2),B=c(2,3),C=c(3,4))
>>> str(testdf)
>> 'data.frame':   2 obs. of  3 variables:
>>   $ A: num  1 2
>>   $ B: num  2 3
>>   $ C: num  3 4
>>> testdf<-testdf[-(1:nrow(testdf)),]
>>> str(testdf)
>> 'data.frame':   0 obs. of  3 variables:
>>   $ A: num
>>   $ B: num
>>   $ C: num
>>
>> Cheers
>> Petr
>>
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
>>> Sent: Thursday, September 27, 2018 10:12 AM
>>> To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help mailing list 
>>> <r-help at r-
>>> project.org>
>>> Subject: Re: [R] Erase content of dataframe in a single stroke
>>>
>>> Ah, yes, try 'as.data.frame" on it.
>>>
>>> Jim
>>>
>>> On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu 
>>> <marongiu.luigi at gmail.com>
>>> wrote:
>>>> Thank you Jim,
>>>> this requires the definition of an ad hoc function; strange that R
>>>> does not have a function for this purpose...
>>>> Anyway, it works but it changes the structure of the data. By
>>>> redefining the dataframe as I did, I obtain:
>>>>
>>>>> df
>>>> [1] A B C
>>>> <0 rows> (or 0-length row.names)
>>>>> str(df)
>>>> 'data.frame': 0 obs. of  3 variables:
>>>>   $ A: num
>>>>   $ B: num
>>>>   $ C: num
>>>>
>>>> When applying your function, I get:
>>>>
>>>>> df
>>>> $A
>>>> NULL
>>>>
>>>> $B
>>>> NULL
>>>>
>>>> $C
>>>> NULL
>>>>
>>>>> str(df)
>>>> List of 3
>>>>   $ A: NULL
>>>>   $ B: NULL
>>>>   $ C: NULL
>>>>
>>>> The dataframe has become a list. Would that affect downstream
>>> applications?
>>>> Thank you,
>>>> Luigi
>>>> On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>>>> Hi Luigi,
>>>>> Maybe this:
>>>>>
>>>>> testdf<-data.frame(A=1,B=2,C=3)
>>>>>> testdf
>>>>>   A B C
>>>>> 1 1 2 3
>>>>> toNull<-function(x) return(NULL)
>>>>> testdf<-sapply(testdf,toNull)
>>>>>
>>>>> Jim
>>>>> On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu
>>> <marongiu.luigi at gmail.com> wrote:
>>>>>> Dear all,
>>>>>> I would like to erase the content of a dataframe -- but not the
>>>>>> dataframe itself -- in a simple and fast way.
>>>>>> At the moment I do that by re-defining the dataframe itself in 
>>>>>> this way:
>>>>>>
>>>>>>> df <- data.frame(A = numeric(),
>>>>>> +                   B = numeric(),
>>>>>> +                   C = character())
>>>>>>> # assign
>>>>>>> A <- 5
>>>>>>> B <- 0.6
>>>>>>> C <- 103
>>>>>>> # load
>>>>>>> R <- cbind(A, B, C)
>>>>>>> df <- rbind(df, R)
>>>>>>> df
>>>>>>    A   B   C
>>>>>> 1 5 0.6 103
>>>>>>> # erase
>>>>>>> df <- data.frame(A = numeric(),
>>>>>> +                  B = numeric(),
>>>>>> +                  C = character())
>>>>>>> df
>>>>>> [1] A B C
>>>>>> <0 rows> (or 0-length row.names)
>>>>>> Is there a way to erase the content of the dataframe in a simplier
>>>>>> (acting on all the dataframe at once instead of naming each column
>>>>>> individually) and nicer (with a specific erasure command instead
>>>>>> of re-defyining the object itself) way?
>>>>>>
>>>>>> Thank you.
>>>>>> -- 
>>>>>> Best regards,
>>>>>> Luigi
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>> -- 
>>>> Best regards,
>>>> Luigi
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? 
>> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: 
>> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information 
>> about processing and protection of business partner?s personal data 
>> are available on website: 
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou 
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? 
>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any 
>> documents attached to it may be confidential and are subject to the 
>> legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @igbert @ending from wiwi@hu-berlin@de  Thu Sep 27 12:30:39 2018
From: @igbert @ending from wiwi@hu-berlin@de (Sigbert Klinke)
Date: Thu, 27 Sep 2018 12:30:39 +0200
Subject: [R] Access function as text from package by name
Message-ID: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>

Hi,

I want to have a function, e.g. graphics::box, as text.
Currently I'am using

deparse(eval(parse(text='graphics::box')))

It is important that '::' and ':::' can be used in the name.

Is there a simpler way?

Thanks

Sigbert

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From ruipb@rr@d@@ @ending from @@po@pt  Thu Sep 27 13:55:29 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Thu, 27 Sep 2018 12:55:29 +0100
Subject: [R] Access function as text from package by name
In-Reply-To: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
Message-ID: <8514c9d8-9849-b17a-3358-343d1e616d45@sapo.pt>

Hello,

Maybe

capture.output(graphics::box)


Hope this helps,

Rui Barradas

?s 11:30 de 27/09/2018, Sigbert Klinke escreveu:
> Hi,
> 
> I want to have a function, e.g. graphics::box, as text.
> Currently I'am using
> 
> deparse(eval(parse(text='graphics::box')))
> 
> It is important that '::' and ':::' can be used in the name.
> 
> Is there a simpler way?
> 
> Thanks
> 
> Sigbert
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pd@lgd @ending from gm@il@com  Thu Sep 27 14:04:02 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Thu, 27 Sep 2018 14:04:02 +0200
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
 <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
 <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>
Message-ID: <6766997C-5387-4985-B17C-AA49CC1078FA@gmail.com>

Variations on the same theme:

> testdf<-data.frame(A=c(1,2),B=c(2,3),C=c(3,4))
> testdf[0,]
[1] A B C
<0 rows> (or 0-length row.names)
> testdf[FALSE,]
[1] A B C
<0 rows> (or 0-length row.names)
> testdf[integer(0),]
[1] A B C
<0 rows> (or 0-length row.names)
> testdf[NULL,]
[1] A B C
<0 rows> (or 0-length row.names)

-pd

> On 27 Sep 2018, at 10:32 , PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Hm
> 
> I would use
> 
>> testdf<-data.frame(A=c(1,2),B=c(2,3),C=c(3,4))
>> str(testdf)
> 'data.frame':   2 obs. of  3 variables:
> $ A: num  1 2
> $ B: num  2 3
> $ C: num  3 4
>> testdf<-testdf[-(1:nrow(testdf)),]
>> str(testdf)
> 'data.frame':   0 obs. of  3 variables:
> $ A: num
> $ B: num
> $ C: num
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
>> Sent: Thursday, September 27, 2018 10:12 AM
>> To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help mailing list <r-help at r-
>> project.org>
>> Subject: Re: [R] Erase content of dataframe in a single stroke
>> 
>> Ah, yes, try 'as.data.frame" on it.
>> 
>> Jim
>> 
>> On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu <marongiu.luigi at gmail.com>
>> wrote:
>>> 
>>> Thank you Jim,
>>> this requires the definition of an ad hoc function; strange that R
>>> does not have a function for this purpose...
>>> Anyway, it works but it changes the structure of the data. By
>>> redefining the dataframe as I did, I obtain:
>>> 
>>>> df
>>> [1] A B C
>>> <0 rows> (or 0-length row.names)
>>>> str(df)
>>> 'data.frame': 0 obs. of  3 variables:
>>> $ A: num
>>> $ B: num
>>> $ C: num
>>> 
>>> When applying your function, I get:
>>> 
>>>> df
>>> $A
>>> NULL
>>> 
>>> $B
>>> NULL
>>> 
>>> $C
>>> NULL
>>> 
>>>> str(df)
>>> List of 3
>>> $ A: NULL
>>> $ B: NULL
>>> $ C: NULL
>>> 
>>> The dataframe has become a list. Would that affect downstream
>> applications?
>>> 
>>> Thank you,
>>> Luigi
>>> On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>>>> 
>>>> Hi Luigi,
>>>> Maybe this:
>>>> 
>>>> testdf<-data.frame(A=1,B=2,C=3)
>>>>> testdf
>>>> A B C
>>>> 1 1 2 3
>>>> toNull<-function(x) return(NULL)
>>>> testdf<-sapply(testdf,toNull)
>>>> 
>>>> Jim
>>>> On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu
>> <marongiu.luigi at gmail.com> wrote:
>>>>> 
>>>>> Dear all,
>>>>> I would like to erase the content of a dataframe -- but not the
>>>>> dataframe itself -- in a simple and fast way.
>>>>> At the moment I do that by re-defining the dataframe itself in this way:
>>>>> 
>>>>>> df <- data.frame(A = numeric(),
>>>>> +                   B = numeric(),
>>>>> +                   C = character())
>>>>>> # assign
>>>>>> A <- 5
>>>>>> B <- 0.6
>>>>>> C <- 103
>>>>>> # load
>>>>>> R <- cbind(A, B, C)
>>>>>> df <- rbind(df, R)
>>>>>> df
>>>>> A   B   C
>>>>> 1 5 0.6 103
>>>>>> # erase
>>>>>> df <- data.frame(A = numeric(),
>>>>> +                  B = numeric(),
>>>>> +                  C = character())
>>>>>> df
>>>>> [1] A B C
>>>>> <0 rows> (or 0-length row.names)
>>>>>> 
>>>>> 
>>>>> Is there a way to erase the content of the dataframe in a simplier
>>>>> (acting on all the dataframe at once instead of naming each column
>>>>> individually) and nicer (with a specific erasure command instead
>>>>> of re-defyining the object itself) way?
>>>>> 
>>>>> Thank you.
>>>>> --
>>>>> Best regards,
>>>>> Luigi
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> --
>>> Best regards,
>>> Luigi
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pjb10 @ending from c@m@@c@uk  Thu Sep 27 12:56:49 2018
From: pjb10 @ending from c@m@@c@uk (Patrick Barrie)
Date: Thu, 27 Sep 2018 11:56:49 +0100
Subject: [R] Query on R-squared correlation coefficient for linear
 regression through origin
Message-ID: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>

I have a query on the R-squared correlation coefficient for linear 
regression through the origin.

The general expression for R-squared in regression (whether linear or 
non-linear) is
R-squared = 1 - sum(y-ypredicted)^2 / sum(y-ybar)^2

However, the lm function within R does not seem to use this expression 
when the intercept is constrained to be zero. It gives results different 
to Excel and other data analysis packages.

As an example (using built-in cars dataframe):
>  cars.lm=lm(dist ~ 0+speed, data=cars)???? # linear regression through 
origin
> summary(cars.lm)$r.squared # report R-squared [1] 0.8962893 > 
1-deviance(cars.lm)/sum((cars$dist-mean(cars$dist))^2) ? ? # calculates 
R-squared directly [1] 0.6018997 > # The latter corresponds to the value 
reported by Excel (and other data analysis packages) > > # Note that we 
expect R-squared to be smaller for linear regression through the origin
 > # than for linear regression without a constraint (which is 0.6511 in 
this example)

Does anyone know what R is doing in this case? Is there an option to get 
R to return what I termed the "general" expression for R-squared? The 
adjusted R-squared value is also affected. [Other parameters all seem 
correct.]

Thanks for any help on this issue,

Patrick

P.S. I believe old versions of Excel (before 2003) also had this issue.

-- 
Dr Patrick J. Barrie
Department of Chemical Engineering and Biotechnology
University of Cambridge
Philippa Fawcett Drive, Cambridge CB3 0AS
01223 331864
pjb10 at cam.ac.uk


	[[alternative HTML version deleted]]


From profjcn@@h @ending from gm@il@com  Thu Sep 27 14:43:17 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Thu, 27 Sep 2018 08:43:17 -0400
Subject: [R] Query on R-squared correlation coefficient for linear
 regression through origin
In-Reply-To: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
References: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
Message-ID: <96009784-9176-60f4-fc6b-a11726ebc1ec@gmail.com>

This issue that traces back to the very unfortunate use
of R-squared as the name of a tool to simply compare a model to the model that
is a single number (the mean). The mean can be shown to be the optimal choice
for a model that is a single number, so it makes sense to try to do better.

The OP has the correct form -- and I find no matter what the software, when
working with models that do NOT have a constant in them (i.e., nonlinear
models, regression through the origin) it pays to do the calculation
"manually". In R it is really easy to write the necessary function, so
why take a chance that a software developer has tried to expand the concept
using a personal choice that is beyond a clear definition.

I've commented elsewhere that I use this statistic even for nonlinear
models in my own software, since I think one should do better than the
mean for a model, but other workers shy away from using it for nonlinear
models because there may be false interpretation based on its use for
linear models.

JN


On 2018-09-27 06:56 AM, Patrick Barrie wrote:
> I have a query on the R-squared correlation coefficient for linear 
> regression through the origin.
> 
> The general expression for R-squared in regression (whether linear or 
> non-linear) is
> R-squared = 1 - sum(y-ypredicted)^2 / sum(y-ybar)^2
> 
> However, the lm function within R does not seem to use this expression 
> when the intercept is constrained to be zero. It gives results different 
> to Excel and other data analysis packages.
> 
> As an example (using built-in cars dataframe):
>>  cars.lm=lm(dist ~ 0+speed, data=cars)???? # linear regression through 
> origin
>> summary(cars.lm)$r.squared # report R-squared [1] 0.8962893 > 
> 1-deviance(cars.lm)/sum((cars$dist-mean(cars$dist))^2) ? ? # calculates 
> R-squared directly [1] 0.6018997 > # The latter corresponds to the value 
> reported by Excel (and other data analysis packages) > > # Note that we 
> expect R-squared to be smaller for linear regression through the origin
>  > # than for linear regression without a constraint (which is 0.6511 in 
> this example)
> 
> Does anyone know what R is doing in this case? Is there an option to get 
> R to return what I termed the "general" expression for R-squared? The 
> adjusted R-squared value is also affected. [Other parameters all seem 
> correct.]
> 
> Thanks for any help on this issue,
> 
> Patrick
> 
> P.S. I believe old versions of Excel (before 2003) also had this issue.
>


From ericjberger @ending from gm@il@com  Thu Sep 27 14:50:23 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Thu, 27 Sep 2018 15:50:23 +0300
Subject: [R] Query on R-squared correlation coefficient for linear
 regression through origin
In-Reply-To: <96009784-9176-60f4-fc6b-a11726ebc1ec@gmail.com>
References: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
 <96009784-9176-60f4-fc6b-a11726ebc1ec@gmail.com>
Message-ID: <CAGgJW75tpWw-aLtFTM8_Q24u-N=ngGqwuorVNNDwZ031giKt2Q@mail.gmail.com>

See also this thread in stats.stackexchange

https://stats.stackexchange.com/questions/26176/removal-of-statistically-significant-intercept-term-increases-r2-in-linear-mo



On Thu, Sep 27, 2018 at 3:43 PM, J C Nash <profjcnash at gmail.com> wrote:

> This issue that traces back to the very unfortunate use
> of R-squared as the name of a tool to simply compare a model to the model
> that
> is a single number (the mean). The mean can be shown to be the optimal
> choice
> for a model that is a single number, so it makes sense to try to do better.
>
> The OP has the correct form -- and I find no matter what the software, when
> working with models that do NOT have a constant in them (i.e., nonlinear
> models, regression through the origin) it pays to do the calculation
> "manually". In R it is really easy to write the necessary function, so
> why take a chance that a software developer has tried to expand the concept
> using a personal choice that is beyond a clear definition.
>
> I've commented elsewhere that I use this statistic even for nonlinear
> models in my own software, since I think one should do better than the
> mean for a model, but other workers shy away from using it for nonlinear
> models because there may be false interpretation based on its use for
> linear models.
>
> JN
>
>
> On 2018-09-27 06:56 AM, Patrick Barrie wrote:
> > I have a query on the R-squared correlation coefficient for linear
> > regression through the origin.
> >
> > The general expression for R-squared in regression (whether linear or
> > non-linear) is
> > R-squared = 1 - sum(y-ypredicted)^2 / sum(y-ybar)^2
> >
> > However, the lm function within R does not seem to use this expression
> > when the intercept is constrained to be zero. It gives results different
> > to Excel and other data analysis packages.
> >
> > As an example (using built-in cars dataframe):
> >>  cars.lm=lm(dist ~ 0+speed, data=cars)     # linear regression through
> > origin
> >> summary(cars.lm)$r.squared # report R-squared [1] 0.8962893 >
> > 1-deviance(cars.lm)/sum((cars$dist-mean(cars$dist))^2)     # calculates
> > R-squared directly [1] 0.6018997 > # The latter corresponds to the value
> > reported by Excel (and other data analysis packages) > > # Note that we
> > expect R-squared to be smaller for linear regression through the origin
> >  > # than for linear regression without a constraint (which is 0.6511 in
> > this example)
> >
> > Does anyone know what R is doing in this case? Is there an option to get
> > R to return what I termed the "general" expression for R-squared? The
> > adjusted R-squared value is also affected. [Other parameters all seem
> > correct.]
> >
> > Thanks for any help on this issue,
> >
> > Patrick
> >
> > P.S. I believe old versions of Excel (before 2003) also had this issue.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Thu Sep 27 16:22:49 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Thu, 27 Sep 2018 16:22:49 +0200
Subject: [R] Query on R-squared correlation coefficient for linear
 regression through origin
In-Reply-To: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
References: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
Message-ID: <C8D38472-F013-4E29-BD20-23E3D841C16F@gmail.com>

This is an old discussion. The thing that R is doing is to compare the model to the model without any regressors, which in the no-intercept case is the constant zero. Otherwise, you would be comparing non-nested models and the R^2 would not satisfy the property of being between 0 and 1. 

A similar issue affects anova tables, where the regression sum of squares is sum(yhat^2) rather than sum((yhat - ybar)^2).

-pd

> On 27 Sep 2018, at 12:56 , Patrick Barrie <pjb10 at cam.ac.uk> wrote:
> 
> I have a query on the R-squared correlation coefficient for linear 
> regression through the origin.
> 
> The general expression for R-squared in regression (whether linear or 
> non-linear) is
> R-squared = 1 - sum(y-ypredicted)^2 / sum(y-ybar)^2
> 
> However, the lm function within R does not seem to use this expression 
> when the intercept is constrained to be zero. It gives results different 
> to Excel and other data analysis packages.
> 
> As an example (using built-in cars dataframe):
>> cars.lm=lm(dist ~ 0+speed, data=cars)     # linear regression through 
> origin
>> summary(cars.lm)$r.squared # report R-squared [1] 0.8962893 > 
> 1-deviance(cars.lm)/sum((cars$dist-mean(cars$dist))^2)     # calculates 
> R-squared directly [1] 0.6018997 > # The latter corresponds to the value 
> reported by Excel (and other data analysis packages) > > # Note that we 
> expect R-squared to be smaller for linear regression through the origin
>> # than for linear regression without a constraint (which is 0.6511 in 
> this example)
> 
> Does anyone know what R is doing in this case? Is there an option to get 
> R to return what I termed the "general" expression for R-squared? The 
> adjusted R-squared value is also affected. [Other parameters all seem 
> correct.]
> 
> Thanks for any help on this issue,
> 
> Patrick
> 
> P.S. I believe old versions of Excel (before 2003) also had this issue.
> 
> -- 
> Dr Patrick J. Barrie
> Department of Chemical Engineering and Biotechnology
> University of Cambridge
> Philippa Fawcett Drive, Cambridge CB3 0AS
> 01223 331864
> pjb10 at cam.ac.uk
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rhelp @ending from krueger-f@mily@de  Thu Sep 27 16:48:41 2018
From: rhelp @ending from krueger-f@mily@de (Knut Krueger)
Date: Thu, 27 Sep 2018 16:48:41 +0200
Subject: [R] subset only if f.e a column is successive for more than 3 values
Message-ID: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>

Hi to all

I need a subset for values if there are f.e 3 values successive in a 
column of a Data Frame:
Example from the subset help page:

subset(airquality, Temp > 80, select = c(Ozone, Temp))
29     45   81
35     NA   84
36     NA   85
38     29   82
39     NA   87
40     71   90
41     39   87
42     NA   93
43     NA   92
44     23   82
.....

I would like to get only

...
40     71   90
41     39   87
42     NA   93
43     NA   92
44     23   82
....

because the left column is ascending more than f.e three times without gap

Any hints for a package or do I need to build a own function?

Kind Regards Knut


From ruipb@rr@d@@ @ending from @@po@pt  Thu Sep 27 16:51:24 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Thu, 27 Sep 2018 15:51:24 +0100
Subject: [R] Query on R-squared correlation coefficient for linear
 regression through origin
In-Reply-To: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
References: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
Message-ID: <c5f20120-c1de-d454-2c46-1848336428bb@sapo.pt>

Hello,

As for R^2 in Excel for models without an intercept, maybe the following 
are relevant.

https://support.microsoft.com/en-us/help/829249/you-will-receive-an-incorrect-r-squared-value-in-the-chart-tool-in-exc

https://stat.ethz.ch/pipermail/r-help/2012-July/318347.html


Hope this helps,

Rui Barradas

?s 11:56 de 27/09/2018, Patrick Barrie escreveu:
> I have a query on the R-squared correlation coefficient for linear
> regression through the origin.
> 
> The general expression for R-squared in regression (whether linear or
> non-linear) is
> R-squared = 1 - sum(y-ypredicted)^2 / sum(y-ybar)^2
> 
> However, the lm function within R does not seem to use this expression
> when the intercept is constrained to be zero. It gives results different
> to Excel and other data analysis packages.
> 
> As an example (using built-in cars dataframe):
>>   cars.lm=lm(dist ~ 0+speed, data=cars)???? # linear regression through
> origin
>> summary(cars.lm)$r.squared # report R-squared [1] 0.8962893 >
> 1-deviance(cars.lm)/sum((cars$dist-mean(cars$dist))^2) ? ? # calculates
> R-squared directly [1] 0.6018997 > # The latter corresponds to the value
> reported by Excel (and other data analysis packages) > > # Note that we
> expect R-squared to be smaller for linear regression through the origin
>   > # than for linear regression without a constraint (which is 0.6511 in
> this example)
> 
> Does anyone know what R is doing in this case? Is there an option to get
> R to return what I termed the "general" expression for R-squared? The
> adjusted R-squared value is also affected. [Other parameters all seem
> correct.]
> 
> Thanks for any help on this issue,
> 
> Patrick
> 
> P.S. I believe old versions of Excel (before 2003) also had this issue.
>


From bgunter@4567 @ending from gm@il@com  Thu Sep 27 17:09:18 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 27 Sep 2018 08:09:18 -0700
Subject: [R] subset only if f.e a column is successive for more than 3
 values
In-Reply-To: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
References: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
Message-ID: <CAGxFJbTPq7PK3vorgEiU0LcuaUKmYd3TwkbdDM11aLUB=6essA@mail.gmail.com>

1. I assume the values are integers, not floats/numerics (which woud make
it more complicated).

2. Strategy: Take differences (e.g. see ?diff) and look for >3 1's in a
row.

I don't have time to work out details, but perhaps that helps.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 27, 2018 at 7:49 AM Knut Krueger <rhelp at krueger-family.de>
wrote:

> Hi to all
>
> I need a subset for values if there are f.e 3 values successive in a
> column of a Data Frame:
> Example from the subset help page:
>
> subset(airquality, Temp > 80, select = c(Ozone, Temp))
> 29     45   81
> 35     NA   84
> 36     NA   85
> 38     29   82
> 39     NA   87
> 40     71   90
> 41     39   87
> 42     NA   93
> 43     NA   92
> 44     23   82
> .....
>
> I would like to get only
>
> ...
> 40     71   90
> 41     39   87
> 42     NA   93
> 43     NA   92
> 44     23   82
> ....
>
> because the left column is ascending more than f.e three times without gap
>
> Any hints for a package or do I need to build a own function?
>
> Kind Regards Knut
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @w@p@nkum@rtrip@thy @ending from gm@il@com  Thu Sep 27 17:02:13 2018
From: @w@p@nkum@rtrip@thy @ending from gm@il@com (Swapan Kumar Tripathy)
Date: Thu, 27 Sep 2018 20:32:13 +0530
Subject: [R] Installation of R/qtl
Message-ID: <CAKYa35hewkA-gfwE9Wmb3qSQ3LMVE4pg6G+cynw=XsqW5j0ohw@mail.gmail.com>

Sir,
I have successfully installed R, but could not install the R/qtl.
There is instruction that "To install R/qtl, the simplest approach is to
start R and type install.packages("qtl"). But, I do not find any step where
to type install.packages("qtl") during the process of installing R.
 Kindly, advice me and suggest steps to install R/qtl.
Looking forward your suggestion.

-- 
*Dr. S.K. Tripathy*
*Professor (Agril. Biotechnology)*
*Dept. of Agril. Biotechnology*
*College of Agriculture*
*Orissa University of Agriculture and Technology, BBSR*
*Odisha, India, 751003*

	[[alternative HTML version deleted]]


From L@J@Bonnett @ending from liverpool@@c@uk  Thu Sep 27 17:26:31 2018
From: L@J@Bonnett @ending from liverpool@@c@uk (Bonnett, Laura)
Date: Thu, 27 Sep 2018 15:26:31 +0000
Subject: [R] Choosing between functional forms using flexible parametric
 survival models
Message-ID: <811b8ea4f35646d2afff7c903c6b1b8c@liverpool.ac.uk>

Dear all,

I am using R 3.4.3 on Windows 10.  I am writing code to use in a forthcoming teaching session.  As part of the workshop the students are using breast cancer data made available by Patrick Royston and available from http://www.statapress.com/data/fpsaus.html (I didn't pick the dataset by the way).  I would like the students to visualise linear, fractional polynomial and spline transformations of the "node" variable using a flexible parametric model with 3 knots for the baseline hazard.  I can do this using the "predict" option within stpm2 as follows:

flex_nodes_lin <- stpm2(Surv(rfs/12,rfsi)~nodes, data=Practical_Rott_dev,df=3)
haz_lin <- predict(flex_nodes_lin,type="hazard")

flex_nodes_fp <- stpm2(Surv(rfs/12,rfsi)~log(nodes),data=Practical_Rott_dev,df=3)
haz_fp <- predict(flex_nodes_fp,type="hazard")

spline3 <- stpm2(Surv(rfs/12,rfsi)~1, data=Practical_Rott_dev,df=3)
haz_spline3 <- predict(spline3,type="hazard")

data_part9 <- data.frame(nodes,haz_lin[nodes],haz_spline3[nodes],haz_fp[nodes])
data_part9_m <- melt(data_part9,id.vars='nodes',factorsAsStrings=F)
plot_part9 <- ggplot(data_part9_m,aes(nodes,value,colour=variable))+geom_line()+scale_colour_manual(labels=c("Linear","FP1","Spline 3 knots"),values=c("green","red","blue"))+theme_bw()
plot_part9 + labs(x="Number of positive nodes",y="",color="") + theme(legend.position=c(0.8,0.8))

However, to my mind using "hazard" (or "survival") leads to a plot which do not help to understand the different functional form of "nodes".  Therefore, I would prefer to do this using the linear predictor for each model instead.  I've written the following code to do this:
lp_nodes_lin <- flex_nodes_lin at lm$fitted.values
lp_nodes_spline <- flex_nodes_spline at lm$fitted.values
lp_nodes_fp <- flex_nodes_fp at lm$fitted.values

data_part9 <- data.frame(flex_nodes_lin at lm$model$nodes,lp_nodes_lin,lp_nodes_spline,lp_nodes_fp)
colnames(data_part9)[1] <- "nodes"

data_part9_m <- melt(data_part9,id.vars='nodes')
plot_part9 <- ggplot(data_part9_m,aes(nodes,value,colour=variable))+geom_line()+scale_colour_manual(labels=c("Linear","Spline (3 knots)", "FP1"),values=c("green","red","blue"))+theme_bw()
plot_part9 + labs(x="Number of positive nodes",y="Prediction",color="") + theme(legend.position=c(0.8,0.8))

I have 2 concerns over this:

1.       The plots are still not the shape I would expect them to be i.e. a line along the 45 degree line for the linear transformation, and a curve for each of the spline and FP transformations.

2.       This code is really complicated - there must be an easier way?!

Any help gratefully received!

Kind regards,
Laura

P.S. If I was doing this in the logistic regression the code would be relatively simple:
age_mod <- glm(DAY30~AGE,family="binomial")
lp_age_lin <- predict(age_mod)

agefp1_mod <- mfp(DAY30~fp(AGE,df=2,alpha=1),family="binomial")
lp_agefp1 <- predict(agefp1_mod)

age3_mod <- glm(DAY30~age3_spline,family="binomial")
lp_age3 <- predict(age3_mod)

data_part8 <- data.frame(AGE,lp_age_lin,lp_agefp1,lp_age3)
data_part8_m <- melt(data_part8,id.vars='AGE')
plot_part8 <- ggplot(data_part8_m,aes(AGE,value,colour=variable))+geom_line()+scale_colour_manual(labels=c("Linear","FP1","Spline 3 knots"),values=c("green","blue","red"))+theme_bw()
plot_part8 + labs(x="Age (years)",y="Linear Predictor (log odds)",color="") + theme(legend.position=c(0.2,0.8))

	[[alternative HTML version deleted]]


From rhelp @ending from krueger-f@mily@de  Thu Sep 27 17:31:50 2018
From: rhelp @ending from krueger-f@mily@de (Knut Krueger)
Date: Thu, 27 Sep 2018 17:31:50 +0200
Subject: [R] Installation of R/qtl
In-Reply-To: <CAKYa35hewkA-gfwE9Wmb3qSQ3LMVE4pg6G+cynw=XsqW5j0ohw@mail.gmail.com>
References: <CAKYa35hewkA-gfwE9Wmb3qSQ3LMVE4pg6G+cynw=XsqW5j0ohw@mail.gmail.com>
Message-ID: <19b049e1-4ebe-abfe-bbbc-71422de02a54@krueger-family.de>

Am 27.09.2018 um 17:02 schrieb Swapan Kumar Tripathy:
> Sir,
> I have successfully installed R, but could not install the R/qtl.
> There is instruction that "To install R/qtl, the simplest approach is to
> start R and type install.packages("qtl"). But, I do not find any step where
> to type install.packages("qtl") during the process of installing R.
>   Kindly, advice me and suggest steps to install R/qtl.
> Looking forward your suggestion.
> 
You can install packages only after R is installed and working.

If you are not familiar with the R console  you can try the GUI Rstudio 
https://www.rstudio.com/

Kind regards Knut


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Sep 27 17:32:47 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 27 Sep 2018 08:32:47 -0700 (PDT)
Subject: [R] Installation of R/qtl
In-Reply-To: <CAKYa35hewkA-gfwE9Wmb3qSQ3LMVE4pg6G+cynw=XsqW5j0ohw@mail.gmail.com>
References: <CAKYa35hewkA-gfwE9Wmb3qSQ3LMVE4pg6G+cynw=XsqW5j0ohw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809270830260.24044@salmo.appl-ecosys.com>

On Thu, 27 Sep 2018, Swapan Kumar Tripathy wrote:

> I have successfully installed R, but could not install the R/qtl. There is
> instruction that "To install R/qtl, the simplest approach is to start R
> and type install.packages("qtl"). But, I do not find any step where to
> type install.packages("qtl") during the process of installing R. Kindly,
> advice me and suggest steps to install R/qtl. Looking forward your
> suggestion.

Swapan,

   After installing R you need to invoke the application before you can use
it. From the command line type
 	R
When it loads you'll see the prompt > and you can then type
 	install.packages("qtl")

   R will ask you to select a repository, then proceed to install the package
for you.

Regards,

Rich


From m@cqueen1 @ending from llnl@gov  Thu Sep 27 17:33:36 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 27 Sep 2018 15:33:36 +0000
Subject: [R] Access function as text from package by name
In-Reply-To: <8514c9d8-9849-b17a-3358-343d1e616d45@sapo.pt>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
 <8514c9d8-9849-b17a-3358-343d1e616d45@sapo.pt>
Message-ID: <E8E07739-0B5B-4983-A9C4-D8B334716942@llnl.gov>

Or

  sink('stuff.txt') ; graphics::box ; sink()

to have it in a text file.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/27/18, 4:55 AM, "R-help on behalf of Rui Barradas" <r-help-bounces at r-project.org on behalf of ruipbarradas at sapo.pt> wrote:

    Hello,
    
    Maybe
    
    capture.output(graphics::box)
    
    
    Hope this helps,
    
    Rui Barradas
    
    ?s 11:30 de 27/09/2018, Sigbert Klinke escreveu:
    > Hi,
    > 
    > I want to have a function, e.g. graphics::box, as text.
    > Currently I'am using
    > 
    > deparse(eval(parse(text='graphics::box')))
    > 
    > It is important that '::' and ':::' can be used in the name.
    > 
    > Is there a simpler way?
    > 
    > Thanks
    > 
    > Sigbert
    > 
    > 
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    >
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From henrik@bengt@@on @ending from gm@il@com  Thu Sep 27 18:35:29 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Thu, 27 Sep 2018 09:35:29 -0700
Subject: [R] Access function as text from package by name
In-Reply-To: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
Message-ID: <CAFDcVCQRqF25O_miA4_TV--Za628uJYhOzZMax20eSQKxBTonw@mail.gmail.com>

deparse(graphics::box)

/Henrik
On Thu, Sep 27, 2018 at 3:30 AM Sigbert Klinke
<sigbert at wiwi.hu-berlin.de> wrote:
>
> Hi,
>
> I want to have a function, e.g. graphics::box, as text.
> Currently I'am using
>
> deparse(eval(parse(text='graphics::box')))
>
> It is important that '::' and ':::' can be used in the name.
>
> Is there a simpler way?
>
> Thanks
>
> Sigbert
>
> --
> https://hu.berlin/sk
> https://hu.berlin/mmstat3
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ddi@@b01 @ending from gm@il@com  Thu Sep 27 18:35:25 2018
From: ddi@@b01 @ending from gm@il@com (David Disabato)
Date: Thu, 27 Sep 2018 12:35:25 -0400
Subject: [R] Printing standard notation and scientific notation in the same
 column of a dataframe
Message-ID: <CACg022_=Zz+B9V006q2c3NgJn_G+==GxWQ1NVzgmQC5thEGa1Q@mail.gmail.com>

Hi R-help,

I was wondering if it was possible for a column of a dataframe to print
some numbers in standard notation and some in scientific notation. Say my
column of data (i.e., dat$x) has numbers between 0 and 1 with a few numbers
very close to 0. When using the "scipen" argument in "options," R seems to
print all numbers of a column in scientific notation if one number in the
column is a decimal with a starting digit smaller than the "scipen"
argument. It is annoying that is changes ALL numbers in that column to
scientific notation though. For example, I do want .00000000000000000001 in
scientific notation, but I want .52 in standard form. Ideally, an example
dataframe column would print as something like this:

print(dat$x)
.52
.17
.03
1.0e-20

However, I cannot figure out how to do this. Any solutions people are aware
of?

-- 
David J. Disabato, M.A.
Clinical Psychology Doctoral Student
George Mason University
ddisabat at gmu.edu

Email is not a secure form of communication as information and
confidentiality cannot be guaranteed. Information provided in an email is
not intended to be a professional service. In the case of a crisis or
emergency situation, call 911.

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Thu Sep 27 20:53:22 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 27 Sep 2018 11:53:22 -0700
Subject: [R] 
 Printing standard notation and scientific notation in the same
 column of a dataframe
In-Reply-To: <CACg022_=Zz+B9V006q2c3NgJn_G+==GxWQ1NVzgmQC5thEGa1Q@mail.gmail.com>
References: <CACg022_=Zz+B9V006q2c3NgJn_G+==GxWQ1NVzgmQC5thEGa1Q@mail.gmail.com>
Message-ID: <98F2B61B-F692-4D94-8C03-55101A15F2A6@comcast.net>


> On Sep 27, 2018, at 9:35 AM, David Disabato <ddisab01 at gmail.com> wrote:
> 
> Hi R-help,
> 
> I was wondering if it was possible for a column of a dataframe to print
> some numbers in standard notation and some in scientific notation. Say my
> column of data (i.e., dat$x) has numbers between 0 and 1 with a few numbers
> very close to 0. When using the "scipen" argument in "options," R seems to
> print all numbers of a column in scientific notation if one number in the
> column is a decimal with a starting digit smaller than the "scipen"
> argument. It is annoying that is changes ALL numbers in that column to
> scientific notation though. For example, I do want .00000000000000000001 in
> scientific notation, but I want .52 in standard form. Ideally, an example
> dataframe column would print as something like this:
> 
> print(dat$x)
> .52
> .17
> .03
> 1.0e-20
> 
> However, I cannot figure out how to do this. Any solutions people are aware
> of?

Perhaps cat?

> cat(x)
0.52 0.17 0.03 1e-20

> 
> -- 
> David J. Disabato, M.A.
> Clinical Psychology Doctoral Student
> George Mason University
> ddisabat at gmu.edu
> 
> Email is not a secure form of communication as information and
> confidentiality cannot be guaranteed. Information provided in an email is
> not intended to be a professional service. In the case of a crisis or
> emergency situation, call 911.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From m@cqueen1 @ending from llnl@gov  Thu Sep 27 23:51:12 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 27 Sep 2018 21:51:12 +0000
Subject: [R] 
 Printing standard notation and scientific notation in the same
 column of a dataframe
In-Reply-To: <98F2B61B-F692-4D94-8C03-55101A15F2A6@comcast.net>
References: <CACg022_=Zz+B9V006q2c3NgJn_G+==GxWQ1NVzgmQC5thEGa1Q@mail.gmail.com>
 <98F2B61B-F692-4D94-8C03-55101A15F2A6@comcast.net>
Message-ID: <27CBEE40-B81D-4B2F-A38E-248F4EC6F809@llnl.gov>

First compare

> format(c(0.52, 0.17, 0.03, 1e-20))
[1] "5.2e-01" "1.7e-01" "3.0e-02" "1.0e-20"

> prettyNum(c(0.52, 0.17, 0.03, 1e-20))
[1] "0.52"  "0.17"  "0.03"  "1e-20"
>

If you want to print one column at a time, that will do what you ask. If you want to print the entire data frame, with numeric columns formatting this way when needed, it will take more work.

Start with ?print.data.frame, which says, in part,

     This calls 'format' which formats the data frame column-by-column,
     then converts to a character matrix and dispatches to the 'print'
     method for matrices.

Fortunately the code for print.data.frame is fairly short and simple. Looking at it, it calls format.data.frame (also fairly short and simple), which in turn uses format(). So there does not appear to be a built in option for the formatting you want.

Some possible approaches:

1) create your own version of format.data.frame which uses prettyNum on numeric columns and format on all other types. If it appears earlier in the path than base R's format.data.frame it might be used instead.
2) create your own versions of both print.data.frame and format.data.frame, again causing it to use prettyNum on numeric columns
3) manually convert your numeric columns to character columns using prettyNum, then print that. Alignment will probably change, which you may not want, but at least you'll get nicer to read numbers.


(as an aside, I'll claim that this is an example of the power of open-source software -- if you don't like the defaults, one can make one's own version to work however is desired -- but it does take some work)

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/27/18, 11:53 AM, "R-help on behalf of David Winsemius" <r-help-bounces at r-project.org on behalf of dwinsemius at comcast.net> wrote:

    
    > On Sep 27, 2018, at 9:35 AM, David Disabato <ddisab01 at gmail.com> wrote:
    > 
    > Hi R-help,
    > 
    > I was wondering if it was possible for a column of a dataframe to print
    > some numbers in standard notation and some in scientific notation. Say my
    > column of data (i.e., dat$x) has numbers between 0 and 1 with a few numbers
    > very close to 0. When using the "scipen" argument in "options," R seems to
    > print all numbers of a column in scientific notation if one number in the
    > column is a decimal with a starting digit smaller than the "scipen"
    > argument. It is annoying that is changes ALL numbers in that column to
    > scientific notation though. For example, I do want .00000000000000000001 in
    > scientific notation, but I want .52 in standard form. Ideally, an example
    > dataframe column would print as something like this:
    > 
    > print(dat$x)
    > .52
    > .17
    > .03
    > 1.0e-20
    > 
    > However, I cannot figure out how to do this. Any solutions people are aware
    > of?
    
    Perhaps cat?
    
    > cat(x)
    0.52 0.17 0.03 1e-20
    
    > 
    > -- 
    > David J. Disabato, M.A.
    > Clinical Psychology Doctoral Student
    > George Mason University
    > ddisabat at gmu.edu
    > 
    > Email is not a secure form of communication as information and
    > confidentiality cannot be guaranteed. Information provided in an email is
    > not intended to be a professional service. In the case of a crisis or
    > emergency situation, call 911.
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    David Winsemius
    Alameda, CA, USA
    
    'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From drjimlemon @ending from gm@il@com  Fri Sep 28 00:35:37 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Fri, 28 Sep 2018 08:35:37 +1000
Subject: [R] subset only if f.e a column is successive for more than 3
 values
In-Reply-To: <CAGxFJbTPq7PK3vorgEiU0LcuaUKmYd3TwkbdDM11aLUB=6essA@mail.gmail.com>
References: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
 <CAGxFJbTPq7PK3vorgEiU0LcuaUKmYd3TwkbdDM11aLUB=6essA@mail.gmail.com>
Message-ID: <CA+8X3fWRz9NU1LZoSQz3K9dzF4McS2RpUaM-KOSvyUcjOfxf3g@mail.gmail.com>

Hi Knut,
As Bert said, you can start with diff and work from there. I can
easily get the text for the subset, but despite fooling around with
"parse", "eval" and "expression", I couldn't get it to work:

# use a bigger subset to test whether multiple runs can be extracted
kkdf<-subset(airquality,Temp > 77,select=c("Ozone","Temp"))
kkdf$index<-as.numeric(rownames(kkdf))
# get the run length encoding
seqindx<-rle(diff(kkdf$index)==1)
# get a logical vector of the starts of the runs
runsel<-seqindx$lengths >= 3 & seqindx$values
# get the indices for the starts of the runs
starts<-cumsum(seqindx$lengths)[runsel[-1]]+1
# and the ends
ends<-cumsum(seqindx$lengths)[runsel]+1
# the character representation of the subset as indices is
paste0("c(",paste(starts,ends,sep=":",collapse=","),")")

I expect there will be a lightning response from someone who knows
about converting the resulting string into whatever is needed.

Jim
On Fri, Sep 28, 2018 at 1:13 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> 1. I assume the values are integers, not floats/numerics (which woud make
> it more complicated).
>
> 2. Strategy: Take differences (e.g. see ?diff) and look for >3 1's in a
> row.
>
> I don't have time to work out details, but perhaps that helps.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Sep 27, 2018 at 7:49 AM Knut Krueger <rhelp at krueger-family.de>
> wrote:
>
> > Hi to all
> >
> > I need a subset for values if there are f.e 3 values successive in a
> > column of a Data Frame:
> > Example from the subset help page:
> >
> > subset(airquality, Temp > 80, select = c(Ozone, Temp))
> > 29     45   81
> > 35     NA   84
> > 36     NA   85
> > 38     29   82
> > 39     NA   87
> > 40     71   90
> > 41     39   87
> > 42     NA   93
> > 43     NA   92
> > 44     23   82
> > .....
> >
> > I would like to get only
> >
> > ...
> > 40     71   90
> > 41     39   87
> > 42     NA   93
> > 43     NA   92
> > 44     23   82
> > ....
> >
> > because the left column is ascending more than f.e three times without gap
> >
> > Any hints for a package or do I need to build a own function?
> >
> > Kind Regards Knut
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon @ending from gm@il@com  Fri Sep 28 00:43:35 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Fri, 28 Sep 2018 08:43:35 +1000
Subject: [R] subset only if f.e a column is successive for more than 3
 values
In-Reply-To: <CA+8X3fWRz9NU1LZoSQz3K9dzF4McS2RpUaM-KOSvyUcjOfxf3g@mail.gmail.com>
References: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
 <CAGxFJbTPq7PK3vorgEiU0LcuaUKmYd3TwkbdDM11aLUB=6essA@mail.gmail.com>
 <CA+8X3fWRz9NU1LZoSQz3K9dzF4McS2RpUaM-KOSvyUcjOfxf3g@mail.gmail.com>
Message-ID: <CA+8X3fU477t2RYpVFJCYQ0R_3EoqiorOWmeS3iGXuqafXi89GQ@mail.gmail.com>

Bugger! It's

eval(parse(text=paste0("kkdf[c(",paste(starts,ends,sep=":",collapse=","),"),]")))

What a mess!

Jim
On Fri, Sep 28, 2018 at 8:35 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Knut,
> As Bert said, you can start with diff and work from there. I can
> easily get the text for the subset, but despite fooling around with
> "parse", "eval" and "expression", I couldn't get it to work:
>
> # use a bigger subset to test whether multiple runs can be extracted
> kkdf<-subset(airquality,Temp > 77,select=c("Ozone","Temp"))
> kkdf$index<-as.numeric(rownames(kkdf))
> # get the run length encoding
> seqindx<-rle(diff(kkdf$index)==1)
> # get a logical vector of the starts of the runs
> runsel<-seqindx$lengths >= 3 & seqindx$values
> # get the indices for the starts of the runs
> starts<-cumsum(seqindx$lengths)[runsel[-1]]+1
> # and the ends
> ends<-cumsum(seqindx$lengths)[runsel]+1
> # the character representation of the subset as indices is
> paste0("c(",paste(starts,ends,sep=":",collapse=","),")")
>
> I expect there will be a lightning response from someone who knows
> about converting the resulting string into whatever is needed.
>
> Jim
> On Fri, Sep 28, 2018 at 1:13 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > 1. I assume the values are integers, not floats/numerics (which woud make
> > it more complicated).
> >
> > 2. Strategy: Take differences (e.g. see ?diff) and look for >3 1's in a
> > row.
> >
> > I don't have time to work out details, but perhaps that helps.
> >
> > Cheers,
> > Bert
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Thu, Sep 27, 2018 at 7:49 AM Knut Krueger <rhelp at krueger-family.de>
> > wrote:
> >
> > > Hi to all
> > >
> > > I need a subset for values if there are f.e 3 values successive in a
> > > column of a Data Frame:
> > > Example from the subset help page:
> > >
> > > subset(airquality, Temp > 80, select = c(Ozone, Temp))
> > > 29     45   81
> > > 35     NA   84
> > > 36     NA   85
> > > 38     29   82
> > > 39     NA   87
> > > 40     71   90
> > > 41     39   87
> > > 42     NA   93
> > > 43     NA   92
> > > 44     23   82
> > > .....
> > >
> > > I would like to get only
> > >
> > > ...
> > > 40     71   90
> > > 41     39   87
> > > 42     NA   93
> > > 43     NA   92
> > > 44     23   82
> > > ....
> > >
> > > because the left column is ascending more than f.e three times without gap
> > >
> > > Any hints for a package or do I need to build a own function?
> > >
> > > Kind Regards Knut
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From dulc@lm@ @ending from bigpond@com  Fri Sep 28 07:41:48 2018
From: dulc@lm@ @ending from bigpond@com (Duncan Mackay)
Date: Fri, 28 Sep 2018 15:41:48 +1000
Subject: [R] 
 Printing standard notation and scientific notation in the same
 column of a dataframe
In-Reply-To: <98F2B61B-F692-4D94-8C03-55101A15F2A6@comcast.net>
References: <CACg022_=Zz+B9V006q2c3NgJn_G+==GxWQ1NVzgmQC5thEGa1Q@mail.gmail.com>
 <98F2B61B-F692-4D94-8C03-55101A15F2A6@comcast.net>
Message-ID: <001401d456ed$f3840360$da8c0a20$@bigpond.com>

Hi

If you do not require the zeros to the right in the scientific notation
  x
[1] 5.2e-01 1.7e-01 3.0e-02 1.0e-20
  zapsmall(x)
[1] 0.52 0.17 0.03 0.00

Then use format, formatC or  sprintf for character conversions

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350
 
-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
Winsemius
Sent: Friday, 28 September 2018 04:53
To: David Disabato
Cc: r-help at r-project.org
Subject: Re: [R] Printing standard notation and scientific notation in the
same column of a dataframe


> On Sep 27, 2018, at 9:35 AM, David Disabato <ddisab01 at gmail.com> wrote:
> 
> Hi R-help,
> 
> I was wondering if it was possible for a column of a dataframe to print
> some numbers in standard notation and some in scientific notation. Say my
> column of data (i.e., dat$x) has numbers between 0 and 1 with a few
numbers
> very close to 0. When using the "scipen" argument in "options," R seems to
> print all numbers of a column in scientific notation if one number in the
> column is a decimal with a starting digit smaller than the "scipen"
> argument. It is annoying that is changes ALL numbers in that column to
> scientific notation though. For example, I do want .00000000000000000001
in
> scientific notation, but I want .52 in standard form. Ideally, an example
> dataframe column would print as something like this:
> 
> print(dat$x)
> .52
> .17
> .03
> 1.0e-20
> 
> However, I cannot figure out how to do this. Any solutions people are
aware
> of?

Perhaps cat?

> cat(x)
0.52 0.17 0.03 1e-20

> 
> -- 
> David J. Disabato, M.A.
> Clinical Psychology Doctoral Student
> George Mason University
> ddisabat at gmu.edu
> 
> Email is not a secure form of communication as information and
> confidentiality cannot be guaranteed. Information provided in an email is
> not intended to be a professional service. In the case of a crisis or
> emergency situation, call 911.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'
-Gehm's Corollary to Clarke's Third Law

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @igbert @ending from wiwi@hu-berlin@de  Fri Sep 28 08:44:32 2018
From: @igbert @ending from wiwi@hu-berlin@de (Sigbert Klinke)
Date: Fri, 28 Sep 2018 08:44:32 +0200
Subject: [R] Access function as text from package by name
In-Reply-To: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
Message-ID: <bc84db17-44bb-5a27-18e1-dca9decede84@wiwi.hu-berlin.de>

Hi,

I guess I was not clear enough: the name of the function is stored as 
string. Solutions which use the object directly do not help unfortunately.

Thanks Sigbert

Am 27.09.2018 um 12:30 schrieb Sigbert Klinke:
> Hi,
> 
> I want to have a function, e.g. graphics::box, as text.
> Currently I'am using
> 
> deparse(eval(parse(text='graphics::box')))
> 
> It is important that '::' and ':::' can be used in the name.
> 
> Is there a simpler way?
> 
> Thanks
> 
> Sigbert
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From bgunter@4567 @ending from gm@il@com  Fri Sep 28 10:45:27 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 28 Sep 2018 01:45:27 -0700
Subject: [R] Access function as text from package by name
In-Reply-To: <bc84db17-44bb-5a27-18e1-dca9decede84@wiwi.hu-berlin.de>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
 <bc84db17-44bb-5a27-18e1-dca9decede84@wiwi.hu-berlin.de>
Message-ID: <CAGxFJbTQ3Gui2-9W+ygTTZ=2Gg1piLb0vgG4Cj+Rev69sa8BaA@mail.gmail.com>

Do you mean:
?get



On Thu, Sep 27, 2018, 11:44 PM Sigbert Klinke <sigbert at wiwi.hu-berlin.de>
wrote:

> Hi,
>
> I guess I was not clear enough: the name of the function is stored as
> string. Solutions which use the object directly do not help unfortunately.
>
> Thanks Sigbert
>
> Am 27.09.2018 um 12:30 schrieb Sigbert Klinke:
> > Hi,
> >
> > I want to have a function, e.g. graphics::box, as text.
> > Currently I'am using
> >
> > deparse(eval(parse(text='graphics::box')))
> >
> > It is important that '::' and ':::' can be used in the name.
> >
> > Is there a simpler way?
> >
> > Thanks
> >
> > Sigbert
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> https://hu.berlin/sk
> https://hu.berlin/mmstat3
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From deep@y@n@@@rk@r @ending from gm@il@com  Fri Sep 28 10:58:58 2018
From: deep@y@n@@@rk@r @ending from gm@il@com (Deepayan Sarkar)
Date: Fri, 28 Sep 2018 14:28:58 +0530
Subject: [R] Access function as text from package by name
In-Reply-To: <CAGxFJbTQ3Gui2-9W+ygTTZ=2Gg1piLb0vgG4Cj+Rev69sa8BaA@mail.gmail.com>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
 <bc84db17-44bb-5a27-18e1-dca9decede84@wiwi.hu-berlin.de>
 <CAGxFJbTQ3Gui2-9W+ygTTZ=2Gg1piLb0vgG4Cj+Rev69sa8BaA@mail.gmail.com>
Message-ID: <CADfFDC7opA8Jqj_V54VzKzHRxGJO37A-6eNuhV3uqr6+9TVxJw@mail.gmail.com>

On Fri, Sep 28, 2018 at 2:16 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Do you mean:
> ?get

Doesn't work with :: etc:

> get("graphics::box")
Error in get("graphics::box") : object 'graphics::box' not found

I think parse()+eval() is pretty much unavoidable. After that, it's a
choice between deparse() and print()+capture.output().

-Deepayan


> On Thu, Sep 27, 2018, 11:44 PM Sigbert Klinke <sigbert at wiwi.hu-berlin.de>
> wrote:
>
> > Hi,
> >
> > I guess I was not clear enough: the name of the function is stored as
> > string. Solutions which use the object directly do not help unfortunately.
> >
> > Thanks Sigbert
> >
> > Am 27.09.2018 um 12:30 schrieb Sigbert Klinke:
> > > Hi,
> > >
> > > I want to have a function, e.g. graphics::box, as text.
> > > Currently I'am using
> > >
> > > deparse(eval(parse(text='graphics::box')))
> > >
> > > It is important that '::' and ':::' can be used in the name.
> > >
> > > Is there a simpler way?
> > >
> > > Thanks
> > >
> > > Sigbert
> > >
> > >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> > --
> > https://hu.berlin/sk
> > https://hu.berlin/mmstat3
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rongiu@luigi @ending from gm@il@com  Fri Sep 28 11:50:29 2018
From: m@rongiu@luigi @ending from gm@il@com (Luigi Marongiu)
Date: Fri, 28 Sep 2018 11:50:29 +0200
Subject: [R] Boxplot: draw outliers in colours
Message-ID: <CAMk+s2TYtKpxPmyx69-hoMAZGVAr+1fPd39fL54-s__HE5F1vw@mail.gmail.com>

Dear all,
I am trying to overlap two series of boxplots on the same graph. In
order to distinguish the outliers from one series to the other, would
be possible to colour the outliers?: instead of the standard black, is
it possible to give a chosen colour?
Thank you

>>>
This is the example. I could not generate not normally distributed
random values (even with runif), so I had to create the values
manually and they are still a bit rough (in the real thing, the two
series are more distant), anyway this should better explain the case.
Note that the three outliers at the bottom right belong to the 'blue'
distribution and the upper outlier on the right belongs to the 'green'
distribution, so making them in blue and green colours would make
clearer their positions.

# generate data.frames
A = c(70, 22, 4, 21, 29, 35, 24, 20, 9, 21,
      22, 12, 20, 21, 13, 18, 15, 3, 9, 23,
      6, 5, 2, 24, 25, 21, 16, 0, 4, 1)
B = c(17, 21, 70, 6, 23, 10, 8, 5, 22, 5,
      21, 5, 19, 9, 23, 24, 11, 13, 7, 15,
      25, 9, 13, 14, 11, 9, 12, 0, 5, 9)
C = c(17, 8, 30, 22, 11, 32, 33, 8, 160, 11,
      35, 7, 36, 15, 11, 25, 16, 6, 38, 19,
      35, 30, 12, 27, 22, 32, 47, 39, 31, 26)
D = c(79, 26, 8, 33, 59, 67, 60, 65, 54, 88,
      78, 105, 59, 40, 109, 81, 28, 26, 94,
      35, 10, 38, 58, 79, 58, 10, 5, 8, 4, 50)
E = c(98, 104, 101, 102, 97, 97, 97,
      100, 97, 102, 100, 103, 104,
      104, 99, 102, 100, 97, 102, 105,
      99, 105, 100, 102, 100, 115,
      112, 113, 111, 115)
G = c(105, 130, 97, 105, 113, 123,
      149, 15,     134, 148, 98, 104,
      113, 108, 209, 145, 138, 119,
      142, 129, 298, 101, 136, 129,
      148, 295, 125, 277, 107, 642)
X = rep(c(1, 3, 5),30*3)
dfA <- data.frame(X, c(A, B, C))
dfB <- data.frame(X, c(D, E, G))
names(dfA) <- c("X", "Y")
names(dfB) <- c("X", "Y")

# plot
boxplot(dfA$Y ~ dfA$X,
        ylim=c(0, 200),
        col="green",
        ylab="Y-values",
        xlab="X-values"
)
par(new=TRUE)
boxplot(dfB$Y ~ dfB$X,
        ylim=c(0, 200),
        col="blue",
        ylab="", xlab="",
        xaxt="n", yaxt="n"
)


-- 
Best regards,
Luigi


From m@rongiu@luigi @ending from gm@il@com  Fri Sep 28 12:05:48 2018
From: m@rongiu@luigi @ending from gm@il@com (Luigi Marongiu)
Date: Fri, 28 Sep 2018 12:05:48 +0200
Subject: [R] Boxplot with linear (not categorical) x-axis
Message-ID: <CAMk+s2Qn+5KyzZYCE_1OqmCBqXn9Jg0FCGmogqGt=KkK0aTUaw@mail.gmail.com>

Dear all,
I am using boxplot to draw some data. Would be possible to have the
X-axis linear (as in a scatter plot) instead of the standard
categorical axis?
The data I have is subdivided into three groups at the numerical
values 1, 3, 5; boxplot treats these as categorical values; in fact, I
can write my own labels simply by using the values 1, 2, 3 for the
position of the labels as in the example.
Thank you,

>>>>
# generate data.frames
A = c(70, 22, 4, 21, 29, 35, 24, 20, 9, 21,
      22, 12, 20, 21, 13, 18, 15, 3, 9, 23,
      6, 5, 2, 24, 25, 21, 16, 0, 4, 1)
B = c(17, 21, 70, 6, 23, 10, 8, 5, 22, 5,
      21, 5, 19, 9, 23, 24, 11, 13, 7, 15,
      25, 9, 13, 14, 11, 9, 12, 0, 5, 9)
C = c(17, 8, 30, 22, 11, 32, 33, 8, 160, 11,
      35, 7, 36, 15, 11, 25, 16, 6, 38, 19,
      35, 30, 12, 27, 22, 32, 47, 39, 31, 26)
X = rep(c(1, 3, 5),30*3)
dfA <- data.frame(X, c(A, B, C))
names(dfA) <- c("X", "Y")
par(mfrow=c(2,1))
boxplot(dfA$Y ~ dfA$X,
        ylim=c(0, 80),
        col="green",
        ylab="Y-values",
        xlab="X-values",
        main="usual X labels"
)
boxplot(dfA$Y ~ dfA$X,
        ylim=c(0, 80),
        col="green",
        ylab="Y-values",
        xlab="X-values",
        main="custom X labels",
        xaxt="n"
)
x.lab = c("A", "B", "C")
x.pos = c(1, 2, 3)
axis(side=1, at=x.pos,
     lab=x.lab, cex.axis=1)

-- 
Best regards,
Luigi


From drjimlemon @ending from gm@il@com  Fri Sep 28 13:14:27 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Fri, 28 Sep 2018 21:14:27 +1000
Subject: [R] Boxplot: draw outliers in colours
In-Reply-To: <CAMk+s2TYtKpxPmyx69-hoMAZGVAr+1fPd39fL54-s__HE5F1vw@mail.gmail.com>
References: <CAMk+s2TYtKpxPmyx69-hoMAZGVAr+1fPd39fL54-s__HE5F1vw@mail.gmail.com>
Message-ID: <CA+8X3fX0tORXpAZm_2GVsHm6SsWZxab-j0mfVhCAQZR6jeOpww@mail.gmail.com>

Hi Luigi,
An easy way is to use "points" to overplot the outliers:

grbxp<-boxplot(dfA$Y ~ dfA$X,
         ylim=c(0, 200),
         col="green",
         ylab="Y-values",
         xlab="X-values"
 )
points(grbxp$group,grbxp$out,col="green")


On Fri, Sep 28, 2018 at 7:51 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I am trying to overlap two series of boxplots on the same graph. In
> order to distinguish the outliers from one series to the other, would
> be possible to colour the outliers?: instead of the standard black, is
> it possible to give a chosen colour?
> Thank you
>
> >>>
> This is the example. I could not generate not normally distributed
> random values (even with runif), so I had to create the values
> manually and they are still a bit rough (in the real thing, the two
> series are more distant), anyway this should better explain the case.
> Note that the three outliers at the bottom right belong to the 'blue'
> distribution and the upper outlier on the right belongs to the 'green'
> distribution, so making them in blue and green colours would make
> clearer their positions.
>
> # generate data.frames
> A = c(70, 22, 4, 21, 29, 35, 24, 20, 9, 21,
>       22, 12, 20, 21, 13, 18, 15, 3, 9, 23,
>       6, 5, 2, 24, 25, 21, 16, 0, 4, 1)
> B = c(17, 21, 70, 6, 23, 10, 8, 5, 22, 5,
>       21, 5, 19, 9, 23, 24, 11, 13, 7, 15,
>       25, 9, 13, 14, 11, 9, 12, 0, 5, 9)
> C = c(17, 8, 30, 22, 11, 32, 33, 8, 160, 11,
>       35, 7, 36, 15, 11, 25, 16, 6, 38, 19,
>       35, 30, 12, 27, 22, 32, 47, 39, 31, 26)
> D = c(79, 26, 8, 33, 59, 67, 60, 65, 54, 88,
>       78, 105, 59, 40, 109, 81, 28, 26, 94,
>       35, 10, 38, 58, 79, 58, 10, 5, 8, 4, 50)
> E = c(98, 104, 101, 102, 97, 97, 97,
>       100, 97, 102, 100, 103, 104,
>       104, 99, 102, 100, 97, 102, 105,
>       99, 105, 100, 102, 100, 115,
>       112, 113, 111, 115)
> G = c(105, 130, 97, 105, 113, 123,
>       149, 15,     134, 148, 98, 104,
>       113, 108, 209, 145, 138, 119,
>       142, 129, 298, 101, 136, 129,
>       148, 295, 125, 277, 107, 642)
> X = rep(c(1, 3, 5),30*3)
> dfA <- data.frame(X, c(A, B, C))
> dfB <- data.frame(X, c(D, E, G))
> names(dfA) <- c("X", "Y")
> names(dfB) <- c("X", "Y")
>
> # plot
> boxplot(dfA$Y ~ dfA$X,
>         ylim=c(0, 200),
>         col="green",
>         ylab="Y-values",
>         xlab="X-values"
> )
> par(new=TRUE)
> boxplot(dfB$Y ~ dfB$X,
>         ylim=c(0, 200),
>         col="blue",
>         ylab="", xlab="",
>         xaxt="n", yaxt="n"
> )
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @ending from temple@edu  Fri Sep 28 15:45:36 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Fri, 28 Sep 2018 09:45:36 -0400
Subject: [R] Boxplot with linear (not categorical) x-axis
In-Reply-To: <CAMk+s2Qn+5KyzZYCE_1OqmCBqXn9Jg0FCGmogqGt=KkK0aTUaw@mail.gmail.com>
References: <CAMk+s2Qn+5KyzZYCE_1OqmCBqXn9Jg0FCGmogqGt=KkK0aTUaw@mail.gmail.com>
Message-ID: <CAGx1TMAwFrGXzB=QmPnffuC6E-Px2Mgjx3ToU5xBjgQyqb-RgQ@mail.gmail.com>

install.packages("HH")
library(HH)
system.file("demo/bwplot.examples.r", package="HH")
demo("bwplot.examples", package="HH", ask=FALSE)

## your example
dfA <- data.frame(X, Y=c(A, B, C))
dfA$X.factor <- factor(dfA$X)
position(dfA$X.factor) <- c(1,3,5)
bwplot(Y ~ X.factor, panel=panel.bwplot.intermediate.hh, data=dfA, xlim=c(0,6))

On Fri, Sep 28, 2018 at 6:05 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> Dear all,
> I am using boxplot to draw some data. Would be possible to have the
> X-axis linear (as in a scatter plot) instead of the standard
> categorical axis?
> The data I have is subdivided into three groups at the numerical
> values 1, 3, 5; boxplot treats these as categorical values; in fact, I
> can write my own labels simply by using the values 1, 2, 3 for the
> position of the labels as in the example.
> Thank you,
>
>>>>>
> # generate data.frames
> A = c(70, 22, 4, 21, 29, 35, 24, 20, 9, 21,
>       22, 12, 20, 21, 13, 18, 15, 3, 9, 23,
>       6, 5, 2, 24, 25, 21, 16, 0, 4, 1)
> B = c(17, 21, 70, 6, 23, 10, 8, 5, 22, 5,
>       21, 5, 19, 9, 23, 24, 11, 13, 7, 15,
>       25, 9, 13, 14, 11, 9, 12, 0, 5, 9)
> C = c(17, 8, 30, 22, 11, 32, 33, 8, 160, 11,
>       35, 7, 36, 15, 11, 25, 16, 6, 38, 19,
>       35, 30, 12, 27, 22, 32, 47, 39, 31, 26)
> X = rep(c(1, 3, 5),30*3)
> dfA <- data.frame(X, c(A, B, C))
> names(dfA) <- c("X", "Y")
> par(mfrow=c(2,1))
> boxplot(dfA$Y ~ dfA$X,
>         ylim=c(0, 80),
>         col="green",
>         ylab="Y-values",
>         xlab="X-values",
>         main="usual X labels"
> )
> boxplot(dfA$Y ~ dfA$X,
>         ylim=c(0, 80),
>         col="green",
>         ylab="Y-values",
>         xlab="X-values",
>         main="custom X labels",
>         xaxt="n"
> )
> x.lab = c("A", "B", "C")
> x.pos = c(1, 2, 3)
> axis(side=1, at=x.pos,
>      lab=x.lab, cex.axis=1)
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rhelp @ending from krueger-f@mily@de  Fri Sep 28 17:08:31 2018
From: rhelp @ending from krueger-f@mily@de (Knut Krueger)
Date: Fri, 28 Sep 2018 17:08:31 +0200
Subject: [R] subset only if f.e a column is successive for more than 3
 values
In-Reply-To: <CA+8X3fU477t2RYpVFJCYQ0R_3EoqiorOWmeS3iGXuqafXi89GQ@mail.gmail.com>
References: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
 <CAGxFJbTPq7PK3vorgEiU0LcuaUKmYd3TwkbdDM11aLUB=6essA@mail.gmail.com>
 <CA+8X3fWRz9NU1LZoSQz3K9dzF4McS2RpUaM-KOSvyUcjOfxf3g@mail.gmail.com>
 <CA+8X3fU477t2RYpVFJCYQ0R_3EoqiorOWmeS3iGXuqafXi89GQ@mail.gmail.com>
Message-ID: <955b2ee9-c5b0-cb0d-363d-25642ef1c2dd@krueger-family.de>

Hi Jim,
thank's it is working with the given example,
but whats the difference when using

testdata=data.frame(TIME=c("17:11:20", "17:11:21", "17:11:22", 
"17:11:23", "17:11:24", "17:11:25", "17:11:26", "17:11:27", "17:11:28", 
"17:21:43",
                         "17:22:16", "17:22:19", "18:04:48", "18:04:49", 
"18:04:50", "18:04:51", "18:04:52", "19:50:09", "00:59:27", "00:59:28",
                         "00:59:29", "04:13:40", "04:13:43", "04:13:44"),

index=c(8960,8961,8962,8963,8964,8965,8966,8967,8968,9583,9616,9619,12168,12169,12170,12171,12172,18489
                               ,37047,37048,37049,48700,48701,48702))

seqindx<-rle(diff(testdata$index)==1)
runsel<-seqindx$lengths >= 3 & seqindx$values
# get the indices for the starts of the runs
starts<-cumsum(seqindx$lengths)[runsel[-1]]+1
# and the ends
ends<-cumsum(seqindx$lengths)[runsel]+1

eval(parse(text=paste0("testdata[c(",paste(starts,ends,sep=":",collapse=","),"),]")))

the result (index)  is 
12168,9619,9616,9583,8968,12168,12169,12170,12171,12172


maybe the gaps between .. 8967,8968,9583,9616,9619,12168,12169 ..?

Regards Knut


From wdunl@p @ending from tibco@com  Fri Sep 28 17:22:59 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 28 Sep 2018 08:22:59 -0700
Subject: [R] subset only if f.e a column is successive for more than 3
 values
In-Reply-To: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
References: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
Message-ID: <CAF8bMcaqfA=ZnJFzBh0nmV=XAY1y6GxXKD+FJ=Ek-Q+O41EsVQ@mail.gmail.com>

Do you also want lines 38 and 39 (in addition to 40:44), or do I
misunderstand your problem?

When you deal with runs of data, think of the rle (run-length encoding)
function.  E.g. here is
a barely tested function to find runs of a given minimum length and a given
difference between
successive values.  It also returns a 'runNumber' so you can split the
result into runs.

findRuns <- function(x, minRunLength=3, difference=1) {
     # for integral x, find runs of length at least 'minRunLength'
     # with 'difference' between succesive values
     d <- diff(x)
     dRle <- rle(d)
     w <- rep(dRle$lengths>=minRunLength-1 & dRle$values==difference,
dRle$lengths)
     values <- x[c(FALSE,w) | c(w,FALSE)]
     runNumber <- cumsum(c(TRUE, diff(values)!=difference))
     data.frame(values=values, runNumber=runNumber)
}

> findRuns(c(10,8,6,4,1,2,3,20,17,18,19,20))
  values runNumber
1      1         1
2      2         1
3      3         1
4     17         2
5     18         2
6     19         2
7     20         2
> findRuns(c(10,8,6,4,1,2,3,20,17,18,19,20), minRunLength=4)
  values runNumber
1     17         1
2     18         1
3     19         1
4     20         1
> findRuns(c(10,8,6,4,1,2,3,20,17,18,19,20), difference=-2)
  values runNumber
1     10         1
2      8         1
3      6         1
4      4         1


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Sep 27, 2018 at 7:48 AM, Knut Krueger <rhelp at krueger-family.de>
wrote:

> Hi to all
>
> I need a subset for values if there are f.e 3 values successive in a
> column of a Data Frame:
> Example from the subset help page:
>
> subset(airquality, Temp > 80, select = c(Ozone, Temp))
> 29     45   81
> 35     NA   84
> 36     NA   85
> 38     29   82
> 39     NA   87
> 40     71   90
> 41     39   87
> 42     NA   93
> 43     NA   92
> 44     23   82
> .....
>
> I would like to get only
>
> ...
> 40     71   90
> 41     39   87
> 42     NA   93
> 43     NA   92
> 44     23   82
> ....
>
> because the left column is ascending more than f.e three times without gap
>
> Any hints for a package or do I need to build a own function?
>
> Kind Regards Knut
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Fri Sep 28 17:33:47 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 28 Sep 2018 08:33:47 -0700
Subject: [R] Boxplot with linear (not categorical) x-axis
In-Reply-To: <CAMk+s2Qn+5KyzZYCE_1OqmCBqXn9Jg0FCGmogqGt=KkK0aTUaw@mail.gmail.com>
References: <CAMk+s2Qn+5KyzZYCE_1OqmCBqXn9Jg0FCGmogqGt=KkK0aTUaw@mail.gmail.com>
Message-ID: <CAF8bMca1M3FP5MF8hxtYH+NM7L0GMxGfZk2W9jz7DLTO6b2zyg@mail.gmail.com>

Use the 'at' argument to boxplot.  E.g.,

> x <- rep(c(2,4,8,16), c(5,10,20,30))
> y <- seq_along(x)
> par(mfrow=c(2,1))
> boxplot(y~x, at=unique(x))
> boxplot(y~x)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Sep 28, 2018 at 3:05 AM, Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Dear all,
> I am using boxplot to draw some data. Would be possible to have the
> X-axis linear (as in a scatter plot) instead of the standard
> categorical axis?
> The data I have is subdivided into three groups at the numerical
> values 1, 3, 5; boxplot treats these as categorical values; in fact, I
> can write my own labels simply by using the values 1, 2, 3 for the
> position of the labels as in the example.
> Thank you,
>
> >>>>
> # generate data.frames
> A = c(70, 22, 4, 21, 29, 35, 24, 20, 9, 21,
>       22, 12, 20, 21, 13, 18, 15, 3, 9, 23,
>       6, 5, 2, 24, 25, 21, 16, 0, 4, 1)
> B = c(17, 21, 70, 6, 23, 10, 8, 5, 22, 5,
>       21, 5, 19, 9, 23, 24, 11, 13, 7, 15,
>       25, 9, 13, 14, 11, 9, 12, 0, 5, 9)
> C = c(17, 8, 30, 22, 11, 32, 33, 8, 160, 11,
>       35, 7, 36, 15, 11, 25, 16, 6, 38, 19,
>       35, 30, 12, 27, 22, 32, 47, 39, 31, 26)
> X = rep(c(1, 3, 5),30*3)
> dfA <- data.frame(X, c(A, B, C))
> names(dfA) <- c("X", "Y")
> par(mfrow=c(2,1))
> boxplot(dfA$Y ~ dfA$X,
>         ylim=c(0, 80),
>         col="green",
>         ylab="Y-values",
>         xlab="X-values",
>         main="usual X labels"
> )
> boxplot(dfA$Y ~ dfA$X,
>         ylim=c(0, 80),
>         col="green",
>         ylab="Y-values",
>         xlab="X-values",
>         main="custom X labels",
>         xaxt="n"
> )
> x.lab = c("A", "B", "C")
> x.pos = c(1, 2, 3)
> axis(side=1, at=x.pos,
>      lab=x.lab, cex.axis=1)
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Sep  1 01:01:51 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 1 Sep 2018 11:01:51 +1200
Subject: [R] [FORGED]  Main label on Cullen and Frey
In-Reply-To: <2040384799.899784.1535715740012@mail2.virginmedia.com>
References: <2040384799.899784.1535715740012@mail2.virginmedia.com>
Message-ID: <83759f46-9307-4f79-2b96-2b83335ed221@auckland.ac.nz>


On 08/31/2018 11:42 PM, Nick Wray via R-help wrote:

> Hello   Does anyone know how to modify the main label when you plot a
> Cullen & Frey (sounds like an Oxford gentleman's outfitters -
> statistically significant waistcoats a speciality) diagram from the
> "descdist" function?  I've tried setting a variable to the
> descdist(data) but it just returns the summary statistics.

I know nothing about descdist() nor the package fitdistrplus whence it 
comes.  However I *do* know how to look at the code of R functions.
See fortune(250).

The short answer to your question is 'No.'  The main title is hard-wired in.

The long answer is:  It's easy to change:

* edit the function descdist()
* add the argument main="Cullen and Frey graph"
* change the call to plot() (about half way through the code) so
   that it says 'main=main' (rather than 'main="Cullen and Frey graph"')
* call descdist() with the syntax (something like)

     gorp <- descdist(x,discrete=TRUE,main="A Load of Dingoes' Kidneys")

And away you go.

Note: The editing process, however you go at it, will create a version 
of descdist() in your global environment.  This will over-ride (mask)
the package version.  However it will be ephemeral unless you choose to 
save your global environment when you quit from R.

You may wish to extract the code from the source package, edit that code 
in situ, and re-install the package from source.  This way you will get 
your modified version of descdist() every time you load the package.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Sep  1 01:04:28 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 1 Sep 2018 11:04:28 +1200
Subject: [R] [FORGED]  Main label on Cullen and Frey
In-Reply-To: <2040384799.899784.1535715740012@mail2.virginmedia.com>
References: <2040384799.899784.1535715740012@mail2.virginmedia.com>
Message-ID: <5f8160b5-7efa-da30-d157-0258a7550149@auckland.ac.nz>


On 08/31/2018 11:42 PM, Nick Wray via R-help wrote:

> ...  Does anyone know how to modify the main label when you plot a
> Cullen & Frey (sounds like an Oxford gentleman's outfitters -
> statistically significant waistcoats a speciality) diagram from the
> "descdist" function?

Fortune nomination.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From jwd @end|ng |rom @urewe@t@net  Sat Sep  1 02:40:09 2018
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Fri, 31 Aug 2018 17:40:09 -0700
Subject: [R] [FORGED]  Main label on Cullen and Frey
In-Reply-To: <5f8160b5-7efa-da30-d157-0258a7550149@auckland.ac.nz>
References: <2040384799.899784.1535715740012@mail2.virginmedia.com>
 <5f8160b5-7efa-da30-d157-0258a7550149@auckland.ac.nz>
Message-ID: <20180831174009.6a5f93b2@Draco.localdomain>

On Sat, 1 Sep 2018 11:04:28 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 08/31/2018 11:42 PM, Nick Wray via R-help wrote:
> 
> > ...  Does anyone know how to modify the main label when you plot a
> > Cullen & Frey (sounds like an Oxford gentleman's outfitters -
> > statistically significant waistcoats a speciality) diagram from the
> > "descdist" function?  
> 
> Fortune nomination.
> 
> cheers,
> 
> Rolf Turner
> 

Seconded.

JWDougherty



From wdun|@p @end|ng |rom t|bco@com  Sat Sep  1 03:12:25 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 31 Aug 2018 18:12:25 -0700
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPQaxLM9FzNabJ=AJPGacVbWUnRBR3HpPRgweN=2oqVitU6pyQ@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
 <CAPQaxLN4Ji3rn9EF_2mKT1Z2-UY5Tx4M+3GNY4J-Ou-hMte_bg@mail.gmail.com>
 <CAPMtxSisrfmnMM79yT_XdvJXYdHUs6nyxw-_-CJ6rPZUpVhLpA@mail.gmail.com>
 <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>
 <CAF8bMcbCFbVbdgDbqbisyKZ+fYnBmW8ybSQD4mMym8Rgaa_9qg@mail.gmail.com>
 <CAPQaxLM9FzNabJ=AJPGacVbWUnRBR3HpPRgweN=2oqVitU6pyQ@mail.gmail.com>
Message-ID: <CAF8bMcZYLq8hUBNTdeiL=5_-Mvn5xwj+WkasdjOBEuk4eo8pSg@mail.gmail.com>

It looks like it is not a UTF-16 text file, although it could be UTF-16
with a different byte order.
Look at it with a text editor or Excel or 'od' or 'file' (the latter are
Unix utilities) or ask the person
you got it from to see what the file contains.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Aug 31, 2018 at 6:01 PM, Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Thank you Mr. Dunlap for the suggestion. How would this modified read.csv
> file read? This is my attempt at what you suggested, which is obviously
> errored.
>
> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=
> TRUE,fileEncoding="UTF-16")
> Warning messages:
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   invalid input found on input connection 'GBM_clinical_drug.csv'
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   incomplete final line found by readTableHeader on 'GBM_clinical_drug.csv'
> >  the_data<-read.csv(file="GBM_clinical_drug.csv",header=
> TRUE,sep=",",fileEncoding="UTF-16")
> Warning messages:
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   invalid input found on input connection 'GBM_clinical_drug.csv'
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   incomplete final line found by readTableHeader on 'GBM_clinical_drug.csv'
>
> Many thanks,
>
> Spencer Brackett
> >
>
>
> On Fri, Aug 31, 2018 at 11:12 AM William Dunlap <wdunlap at tibco.com> wrote:
>
>> Try adding fileEncoding="UTF-16" to your read.csv() call.  Many Windows
>> programs write UTF-16 files by default.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Thu, Aug 30, 2018 at 6:05 PM, Spencer Brackett <
>> spbrackett20 at saintjosephhs.com> wrote:
>>
>>> My apologies... the following is what I received from the correction
>>>
>>>  the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep=",")
>>> Warning messages:
>>> 1: In read.table(file = file, header = header, sep = sep, quote =
>>> quote,  :
>>>   line 3 appears to contain embedded nulls
>>> 2: In read.table(file = file, header = header, sep = sep, quote =
>>> quote,  :
>>>   line 4 appears to contain embedded nulls
>>> 3: In read.table(file = file, header = header, sep = sep, quote =
>>> quote,  :
>>>   line 5 appears to contain embedded nulls
>>> 4: In scan(file = file, what = what, sep = sep, quote = quote, dec =
>>> dec,  :
>>>   embedded nul(s) found in input
>>> >
>>>
>>>
>>> On Thu, Aug 30, 2018 at 8:57 PM Patrick Barry <pdbarry at alaska.edu>
>>> wrote:
>>>
>>> > You still haven't fixed the first thing both Sarah and I pointed out.
>>> You
>>> > are lacking an = between sep and ","
>>> >
>>> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>>> >
>>> > should be
>>> >
>>> > the_data <- read.csv(file = "GBM_clinical_drug.csv", header = TRUE,
>>> *sep
>>> > = ","*)
>>> >
>>> > as Sarah pointed out, you should use spaces to help make these errors
>>> more
>>> > obvious.
>>> >
>>> > On Thu, Aug 30, 2018 at 4:53 PM, Spencer Brackett <
>>> > spbrackett20 at saintjosephhs.com> wrote:
>>> >
>>> >> Hello again,
>>> >>
>>> >> My apologies for the delayed response... computer troubles. In
>>> reference
>>> >> to
>>> >> Ms. Goslee's and Mr. Barry's query, the following is the error code
>>> >> received after I inputted my R command
>>> >>
>>> >>  the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>>> >> Error: unexpected string constant in
>>> >> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",""
>>> >>
>>> >> Given this, should I proceed with implementing the path<getwd()
>>> ,since I
>>> >> am, as he suggested trying to set the variable *path* to my working
>>> >> directory with path<-"."
>>> >>
>>> >> Mr. Mittal also recommended importing with r studio, which I shall
>>> try in
>>> >> the meantime.
>>> >>
>>> >> Many thanks,
>>> >>
>>> >> Spencer Brackett
>>> >>
>>> >>
>>> >> On Wed, Aug 29, 2018 at 10:14 PM Amit Mittal <
>>> prof.amit.mittal at gmail.com>
>>> >> wrote:
>>> >>
>>> >> > Use r studio and import from the menu. Read_csv has changed
>>> >> >
>>> >> > Also you can see any format problems
>>> >> >
>>> >> > On Thu, 30 Aug 2018 3:36 am Spencer Brackett, <
>>> >> > spbrackett20 at saintjosephhs.com> wrote:
>>> >> >
>>> >> >> Good evening R users,
>>> >> >>
>>> >> >>   I am attempting to carry out DNA methylation analysis on two
>>> separate
>>> >> >> CSV
>>> >> >> files (LGG and GBM), which I have downloaded onto my R console. To
>>> set
>>> >> the
>>> >> >> path<-"." to be indicative of one or both of the csv files, I
>>> utilized
>>> >> the
>>> >> >> following functions and received the errors shown. How do I set the
>>> >> "." so
>>> >> >> that I can begin analysis on my files?
>>> >> >>
>>> >> >> > the_data <-read.csv(file="LGG_clinical_
>>> drug.csv",header=T,sep",")
>>> >> >> Error: unexpected string constant in "the_data
>>> >> >> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
>>> >> >> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
>>> >> >> Error: unexpected string constant in
>>> >> >> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>>> >> >>
>>> >> >> This is the preliminary portion of the analysis I am trying to run,
>>> >> which
>>> >> >> I
>>> >> >> am referring to:
>>> >> >>
>>> >> >> 1 library(TCGAbiolinks)
>>> >> >> 2
>>> >> >> 3 # Download the DNA methylation data: HumanMethylation450 LGG and
>>> GBM.
>>> >> >> 4 path <? "."
>>> >> >> 5
>>> >> >> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"
>>> HumanMethylation450",
>>> >> >> level = 3)
>>> >> >> 7 TCGAdownload(query.met, path = path )
>>> >> >> 8 met <? TCGAprepare(query = query.met,dir = path,
>>> >> >> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>> >> >> 10                    summarizedExperiment = TRUE,
>>> >> >> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>> >> >> 12
>>> >> >> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and
>>> GBM.
>>> >> >> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>> >> >> "IlluminaHiSeq_
>>> >> >> RNASeqV2",level = 3)
>>> >> >> 15
>>> >> >> 16 TCGAdownload(query.exp,path = path, type =
>>> "rsem.genes.normalized_
>>> >> >> results")
>>> >> >> 17
>>> >> >> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>> >> >> 19                    summarizedExperiment = TRUE,
>>> >> >> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>> >> >> 21                    type = "rsem.genes.normalized_results",
>>> >> >> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>> >> >>
>>> >> >> Many thanks,
>>> >> >>
>>> >> >> Spencer Brackett
>>> >> >>
>>> >> >>         [[alternative HTML version deleted]]
>>> >> >>
>>> >> >> ______________________________________________
>>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> >> PLEASE do read the posting guide
>>> >> >> http://www.R-project.org/posting-guide.html
>>> >> >> and provide commented, minimal, self-contained, reproducible code.
>>> >> >>
>>> >> >
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]



From @@@h@@w@ng2017 @end|ng |rom y@ndex@com  Sat Sep  1 01:58:57 2018
From: @@@h@@w@ng2017 @end|ng |rom y@ndex@com (Jiayue Wang)
Date: Sat, 1 Sep 2018 07:58:57 +0800
Subject: [R] Specifying Java runtime path
Message-ID: <e73cc047-58e1-6edb-0e8a-ea23c0c82b09@yandex.com>

My Java interpreter etc. are not in the "standard" paths (I use Oracle 
JDK, which was installed in /opt) so I keep getting error messages when 
I tried to install packages that depend on rJava. How should Java 
runtime specs be specified?

Thanks

Sasha



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep  1 18:29:04 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 01 Sep 2018 09:29:04 -0700
Subject: [R] Specifying Java runtime path
In-Reply-To: <e73cc047-58e1-6edb-0e8a-ea23c0c82b09@yandex.com>
References: <e73cc047-58e1-6edb-0e8a-ea23c0c82b09@yandex.com>
Message-ID: <D291050E-CAD0-43B2-94CD-6E6D9C9FBF82@dcn.davis.ca.us>

Wouldn't that be the usual way... by exporting environment variables? You can cobble together the right settings using Sys.setenv(), but this kind of thing is best handled in your user-level OS configuration (~/.profile?) and this is not the right place to learn about how to muck with your OS.

On August 31, 2018 4:58:57 PM PDT, Jiayue Wang <sasha.wang2017 at yandex.com> wrote:
>My Java interpreter etc. are not in the "standard" paths (I use Oracle 
>JDK, which was installed in /opt) so I keep getting error messages when
>
>I tried to install packages that depend on rJava. How should Java 
>runtime specs be specified?
>
>Thanks
>
>Sasha
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From t@v|b@r @end|ng |rom gm@||@com  Sat Sep  1 22:32:26 2018
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Sat, 1 Sep 2018 23:32:26 +0300
Subject: [R] partialPlot within a function
Message-ID: <4e61af90-99d0-f252-213f-358330d6af3e@gmail.com>

I am running randomForest regressions in a loop, passing a different 
data.frame each time, and trying to plot importance and partial 
dependency plots for all variables in the data.frame. The commands all 
run OK when typed at the prompt, but when I wrap them into a function, 
the partialPlot function fails with:
 ?Error in eval(x.var) : object 'impvar' not found

It seems that the x.var parameter is getting the variable name 
(impvar[i] in this case) rather than the value of the variable.
What am I missing here?


The easiest way to see this is using the example right from the 
partialPlot help page, but wrapped into a function:

##--------------------------
library(randomForest)
## Looping over variables ranked by importance:
do_pdp <- function(dta) {
 ??????? dta <- na.omit(dta)
 ??????? set.seed(131)
 ??????? ozone.rf <- randomForest(Ozone ~ ., dta, importance=TRUE)
 ??????? imp <- importance(ozone.rf)
 ??????? impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
 ??????? op <- par(mfrow=c(2, 3))
 ??????? for (i in seq_along(impvar)) {
 ???????????? partialPlot(ozone.rf, dta, impvar[i], xlab=impvar[i],
 ???????????????????? main=paste("Partial Dependence on", impvar[i]),
 ???????????????????? ylim=c(30, 70))
 ??????? }
 ??????? par(op)
}
data(airquality)
do_pdp(airquality)
##--------------------------

Fails with the above message above for me. Running the commands 
directly, without the "do_pdp" function works fine, of course.


sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Linux Mint 19

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3
LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so

locale:
 ?[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
 ?[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=en_US.UTF-8
 ?[5] LC_MONETARY=en_US.UTF-8??? LC_MESSAGES=en_US.UTF-8
 ?[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
 ?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods base

other attached packages:
[1] randomForest_4.6-14

loaded via a namespace (and not attached):
[1] compiler_3.5.1 tools_3.5.1

Thanks

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918



From t@v|b@r @end|ng |rom gm@||@com  Sun Sep  2 08:38:08 2018
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Sun, 2 Sep 2018 09:38:08 +0300
Subject: [R] partialPlot within a function
In-Reply-To: <DM6PR01MB4107BCCDB66DE1D72259C678FC0D0@DM6PR01MB4107.prod.exchangelabs.com>
References: <4e61af90-99d0-f252-213f-358330d6af3e@gmail.com>
 <DM6PR01MB4107A7B5B54A9CA54D67C5E8FC0D0@DM6PR01MB4107.prod.exchangelabs.com>
 <634035f9-025c-28c4-803a-00371ef0a656@gmail.com>
 <DM6PR01MB4107BCCDB66DE1D72259C678FC0D0@DM6PR01MB4107.prod.exchangelabs.com>
Message-ID: <5504d5a5-d9a6-6d22-f58b-369820489be2@gmail.com>



On 09/02/2018 09:28 AM, Amit Mittal wrote:
>> partialPlot(ozone.rf, dta, impvar[i],
>
> Is there a close bracket here. Have you tried naming each of the 
> parameters, like data = ozone.rf etc. Dry if I am rushing this . But 
> it looks a basic syntax problem
>

It's just copy-paste from the help example. I don't think there's a 
syntax problem.
And If I just take the same commands *out* of the function, it works fine.
:-(

> ????????????
> Amit Mittal
> PhD in Finance and Accounting (tbd)
> IIM Lucknow
> http://ssrn.com/author=2665511
> *Top 10%, downloaded author since July 2017
> ????????????
> Sent from my Outlook for Android
> https://aka.ms/ghei36
>
> ------------------------------------------------------------------------
> *From:* Micha Silver <tsvibar at gmail.com>
> *Sent:* Sunday, September 2, 2018 11:54:44 AM
> *To:* Amit Mittal
> *Cc:* R-help
> *Subject:* Re: [R] partialPlot within a function
>
>
> On 09/02/2018 09:17 AM, Amit Mittal wrote:
>> Could be just the assignment of a new xlab
>>
>> `xlab=impvar[i],`
>>
>
> The error message refers to the x.var, not the axis label.
> Besides, the x axis label has a default value. x.var does not)
> ??
> Thanks
>
>> Try xlab[i]=impvar[i]
>> Or initialising it xlab <-0
>>
>> ????????????
>> Amit Mittal
>> PhD in Finance and Accounting (tbd)
>> IIM Lucknow
>> http://ssrn.com/author=2665511
>> *Top 10%, downloaded author since July 2017
>> ????????????
>> Sent from my Outlook for Android
>> https://aka.ms/ghei36
>>
>> ------------------------------------------------------------------------
>> *From:* R-help <r-help-bounces at r-project.org> on behalf of Micha 
>> Silver <tsvibar at gmail.com>
>> *Sent:* Sunday, September 2, 2018 2:02:26 AM
>> *To:* R-help at r-project.org
>> *Subject:* [R] partialPlot within a function
>> I am running randomForest regressions in a loop, passing a different
>> data.frame each time, and trying to plot importance and partial
>> dependency plots for all variables in the data.frame. The commands all
>> run OK when typed at the prompt, but when I wrap them into a function,
>> the partialPlot function fails with:
>> ??Error in eval(x.var) : object 'impvar' not found
>>
>> It seems that the x.var parameter is getting the variable name
>> (impvar[i] in this case) rather than the value of the variable.
>> What am I missing here?
>>
>>
>> The easiest way to see this is using the example right from the
>> partialPlot help page, but wrapped into a function:
>>
>> ##--------------------------
>> library(randomForest)
>> ## Looping over variables ranked by importance:
>> do_pdp <- function(dta) {
>> ???????? dta <- na.omit(dta)
>> ???????? set.seed(131)
>> ???????? ozone.rf <- randomForest(Ozone ~ ., dta, importance=TRUE)
>> ???????? imp <- importance(ozone.rf)
>> ???????? impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
>> ???????? op <- par(mfrow=c(2, 3))
>> ???????? for (i in seq_along(impvar)) {
>> ????????????? partialPlot(ozone.rf, dta, impvar[i], xlab=impvar[i],
>> ????????????????????? main=paste("Partial Dependence on", impvar[i]),
>> ????????????????????? ylim=c(30, 70))
>> ???????? }
>> ???????? par(op)
>> }
>> data(airquality)
>> do_pdp(airquality)
>> ##--------------------------
>>
>> Fails with the above message above for me. Running the commands
>> directly, without the "do_pdp" function works fine, of course.
>>
>>
>> sessionInfo()
>> R version 3.5.1 (2018-07-02)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Linux Mint 19
>>
>> Matrix products: default
>> BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3
>> LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so
>>
>> locale:
>> ??[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
>> ??[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=en_US.UTF-8
>> ??[5] LC_MONETARY=en_US.UTF-8??? LC_MESSAGES=en_US.UTF-8
>> ??[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
>> ??[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats???? graphics? grDevices utils???? datasets methods base
>>
>> other attached packages:
>> [1] randomForest_4.6-14
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.5.1 tools_3.5.1
>>
>> Thanks
>>
>> -- 
>> Micha Silver
>> Ben Gurion Univ.
>> Sde Boker, Remote Sensing Lab
>> cell: +972-523-665918
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html 
>> <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
> -- 
> Micha Silver
> Ben Gurion Univ.
> Sde Boker, Remote Sensing Lab
> cell: +972-523-665918

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918



From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Sep  2 09:57:44 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 2 Sep 2018 07:57:44 +0000
Subject: [R] RHEl Vs UBUNTU for R
Message-ID: <SL2P216MB0091E5F57C803D6D5D4638BFC80D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I am using AWS LINUX ec2 instances for running my R code.

I am in  a conundrum whether to use RHEL or Ubuntu.

Does R run faster on Red Hat as compared to Ubuntu?

What other advantages does running R have on Red Hat over Ubuntu?

Very many thanks for your time and effort...
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep  2 10:20:53 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 02 Sep 2018 01:20:53 -0700
Subject: [R] RHEl Vs UBUNTU for R
In-Reply-To: <SL2P216MB0091E5F57C803D6D5D4638BFC80D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091E5F57C803D6D5D4638BFC80D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <3A079AB4-B74C-44B7-B858-2A47106ED307@dcn.davis.ca.us>

R runs equally well on both of those distributions of the Linux kernel. The choice of which to use would be determined by your personal preferences or by those of the people you have available to help you manage the system configuration. This is not an OS support area, nor a chat room for debating personal preferences, so please don't pursue this discussion here.

On September 2, 2018 12:57:44 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>              I am using AWS LINUX ec2 instances for running my R code.
>
>I am in  a conundrum whether to use RHEL or Ubuntu.
>
>Does R run faster on Red Hat as compared to Ubuntu?
>
>What other advantages does running R have on Red Hat over Ubuntu?
>
>Very many thanks for your time and effort...
>Yours sincerely,
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From @@@h@@w@ng2017 @end|ng |rom y@ndex@com  Sun Sep  2 09:54:27 2018
From: @@@h@@w@ng2017 @end|ng |rom y@ndex@com (Jiayue Wang)
Date: Sun, 2 Sep 2018 15:54:27 +0800
Subject: [R] Specifying Java runtime path
In-Reply-To: <D291050E-CAD0-43B2-94CD-6E6D9C9FBF82@dcn.davis.ca.us>
References: <e73cc047-58e1-6edb-0e8a-ea23c0c82b09@yandex.com>
 <D291050E-CAD0-43B2-94CD-6E6D9C9FBF82@dcn.davis.ca.us>
Message-ID: <5081a6a6-7153-edfc-bd7c-40a27d7ce1fb@yandex.com>

Thanks Jeff, for the patience to answer my newbie question, now I know 
which way to look.

Sasha

On 09/02/2018 12:29 AM, Jeff Newmiller wrote:
> Wouldn't that be the usual way... by exporting environment variables? You can cobble together the right settings using Sys.setenv(), but this kind of thing is best handled in your user-level OS configuration (~/.profile?) and this is not the right place to learn about how to muck with your OS.
> 
> On August 31, 2018 4:58:57 PM PDT, Jiayue Wang <sasha.wang2017 at yandex.com> wrote:
>> My Java interpreter etc. are not in the "standard" paths (I use Oracle
>> JDK, which was installed in /opt) so I keep getting error messages when
>>
>> I tried to install packages that depend on rJava. How should Java
>> runtime specs be specified?
>>
>> Thanks
>>
>> Sasha
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>



From t@v|b@r @end|ng |rom gm@||@com  Sun Sep  2 14:56:51 2018
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Sun, 2 Sep 2018 15:56:51 +0300
Subject: [R] partialPlot within a function [Solved]
In-Reply-To: <4e61af90-99d0-f252-213f-358330d6af3e@gmail.com>
References: <4e61af90-99d0-f252-213f-358330d6af3e@gmail.com>
Message-ID: <9dd43e80-f06b-9061-4e9d-f1f8753d69d8@gmail.com>

I found a few old posts on StackOverflow that brought up the same 
problem with partialPlot. Apparently the function refers to the global 
env when looking for x.var, and if it's running within a function, there 
is no global value for that parameter.

The work around was simple: put the partialPlot function into a do.call()

 ??????? for (i in seq_along(impvar)) {
 ??? ??? ??? ?? pP_params <- list(x = ozone.rf,? pred.data = dta,
 ??? ??? ??? ??? ??? ??? ??? ??? x.var = impvar[i], xlab = impvar[i],
 ???????????????????? ??? ??? main=paste("Partial Dependence on", 
impvar[i]),
 ???????????????????? ??? ??? ylim=c(30, 70))
 ???????????? do.call("partialPlot", pP_params)
 ??????? }

Regards,

On 09/01/2018 11:32 PM, Micha Silver wrote:
> I am running randomForest regressions in a loop, passing a different 
> data.frame each time, and trying to plot importance and partial 
> dependency plots for all variables in the data.frame. The commands all 
> run OK when typed at the prompt, but when I wrap them into a function, 
> the partialPlot function fails with:
> ?Error in eval(x.var) : object 'impvar' not found
>
> It seems that the x.var parameter is getting the variable name 
> (impvar[i] in this case) rather than the value of the variable.
> What am I missing here?
>
>
> The easiest way to see this is using the example right from the 
> partialPlot help page, but wrapped into a function:
>
> ##--------------------------
> library(randomForest)
> ## Looping over variables ranked by importance:
> do_pdp <- function(dta) {
> ??????? dta <- na.omit(dta)
> ??????? set.seed(131)
> ??????? ozone.rf <- randomForest(Ozone ~ ., dta, importance=TRUE)
> ??????? imp <- importance(ozone.rf)
> ??????? impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
> ??????? op <- par(mfrow=c(2, 3))
> ??????? for (i in seq_along(impvar)) {
> ???????????? partialPlot(ozone.rf, dta, impvar[i], xlab=impvar[i],
> ???????????????????? main=paste("Partial Dependence on", impvar[i]),
> ???????????????????? ylim=c(30, 70))
> ??????? }
> ??????? par(op)
> }
> data(airquality)
> do_pdp(airquality)
> ##--------------------------
>
> Fails with the above message above for me. Running the commands 
> directly, without the "do_pdp" function works fine, of course.
>
>
> sessionInfo()
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Linux Mint 19
>
> Matrix products: default
> BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3
> LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so
>
> locale:
> ?[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=en_US.UTF-8
> ?[5] LC_MONETARY=en_US.UTF-8??? LC_MESSAGES=en_US.UTF-8
> ?[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
> ?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats???? graphics? grDevices utils???? datasets? methods base
>
> other attached packages:
> [1] randomForest_4.6-14
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.1 tools_3.5.1
>
> Thanks
>

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918



From t@@|ngh @end|ng |rom uc|@@c@uk  Mon Sep  3 10:47:53 2018
From: t@@|ngh @end|ng |rom uc|@@c@uk (Singh, Tanya)
Date: Mon, 3 Sep 2018 08:47:53 +0000
Subject: [R] pheatmap query
Message-ID: <AM4PR01MB1860BEBDAECEDF6B6BF03DE1BD0C0@AM4PR01MB1860.eurprd01.prod.exchangelabs.com>

Hi



I am plotting a pheatmap using following line in a R code

pheatmap(counts_filtered_df,scale="row",cluster_col=FALSE,cluster_row=TRUE,border_color=NA,show_rownames = T)



I want to extract the row names in the same order as shown in pheatmap and the z scores for them.



So basically a numeric matrix instead of a figure. Can someone help me how this can be done



Thanks



Tanya


	[[alternative HTML version deleted]]



From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Sep  3 16:30:22 2018
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 3 Sep 2018 09:30:22 -0500
Subject: [R] Error when using complete function for imputed data
Message-ID: <CAMOcQfN82EGX1SPQY7iet2LsMT25iKXJBFLMvLg80k3cC6t0ug@mail.gmail.com>

Dear friends,

It seems to me that there is something wrong with the complete function. I
am using R version 3.5.0 and mice package for data imputation.

I am working on a Windows 8.1 Enterprise machine with 64-bit Operating
System.

So here is my code:

Imputed_Data <- mice(dataFrame[2:5])
CompleteData <- complete(Imputed_Data)
Error in UseMethod("complete_") :
  no applicable method for 'complete_' applied to an object of class "mids"

I used the complete function before when imputing data with the mice
function, but now it is not working.

Any help will be greatly appreciated. Below is the dput() of my dataset:

> dput(dataFrame)
structure(list(TransitDate = structure(c(496990800, 499669200,
502261200, 504939600, 507618000, 510037200, 512715600, 515307600,
517986000, 520578000, 523256400, 525934800, 528526800, 531205200,
533797200, 536475600, 539154000, 541573200, 544251600, 546843600,
549522000, 552114000, 554792400, 557470800, 560062800, 562741200,
565333200, 568011600, 570690000, 573195600, 575874000, 578466000,
581144400, 583736400, 586414800, 589093200, 591685200, 594363600,
596955600, 599634000, 602312400, 604731600, 607410000, 610002000,
612680400, 615272400, 617950800, 620629200, 623221200, 625899600,
628491600, 631170000, 633848400, 636267600, 638946000, 641538000,
644216400, 646808400, 649486800, 652165200, 654757200, 657435600,
660027600, 662706000, 665384400, 667803600, 670482000, 673074000,
675752400, 678344400, 681022800, 683701200, 686293200, 688971600,
691563600, 694242000, 696920400, 699426000, 702104400, 704696400,
707371200, 709963200, 712641600, 715320000, 717912000, 720590400,
723182400, 725860800, 728539200, 730958400, 733636800, 736232400,
738910800, 741502800, 744181200, 746859600, 749451600, 752130000,
754722000, 757400400, 760078800, 762498000, 765176400, 767768400,
770446800, 773038800, 775717200, 778395600, 780987600, 783666000,
786258000, 788936400, 791614800, 794034000, 796712400, 799304400,
801982800, 804574800, 807253200, 809931600, 812523600, 815202000,
817794000, 820472400, 823150800, 825656400, 828334800, 830926800,
833605200, 836197200, 838875600, 841554000, 844146000, 846824400,
849416400, 852094800, 854773200, 857192400, 859870800, 862462800,
865141200, 867733200, 870411600, 873090000, 875682000, 878360400,
880952400, 883630800, 886309200, 888728400, 891406800, 893998800,
896677200, 899269200, 901947600, 904626000, 907218000, 909896400,
912488400, 915166800, 917845200, 920264400, 922942800, 925534800,
928213200, 930805200, 933483600, 936162000, 938754000, 941432400,
944024400, 946702800, 949381200, 951886800, 954565200, 957157200,
959835600, 962427600, 965106000, 967784400, 970376400, 973054800,
975646800, 978325200, 981003600, 983422800, 986101200, 988693200,
991371600, 993963600, 996642000, 999320400, 1001912400, 1004590800,
1007182800, 1009861200, 1012539600, 1014958800, 1017637200, 1020229200,
1022907600, 1025499600, 1028178000, 1030856400, 1033448400, 1036126800,
1038718800, 1041397200, 1044075600, 1046494800, 1049173200, 1051765200,
1054443600, 1057035600, 1059714000, 1062392400, 1064984400, 1067662800,
1070254800, 1072933200, 1075611600, 1078117200, 1080795600, 1083387600,
1086066000, 1088658000, 1091336400, 1094014800, 1096606800, 1099285200,
1101877200, 1104555600, 1107234000, 1109653200, 1112331600, 1114923600,
1117602000, 1120194000, 1122872400, 1125550800, 1128142800, 1130821200,
1133413200, 1136091600, 1138770000, 1141189200, 1143867600, 1146459600,
1149138000, 1151730000, 1154408400, 1157086800, 1159678800, 1162357200,
1164949200, 1167627600, 1170306000, 1172725200, 1175403600, 1177995600,
1180674000, 1183266000, 1185944400, 1188622800, 1191214800, 1193893200,
1196485200, 1199163600, 1201842000, 1204347600, 1207026000, 1209618000,
1212296400, 1214888400, 1217566800, 1220245200, 1222837200, 1225515600,
1228107600, 1230786000, 1233464400, 1235883600, 1238562000, 1241154000,
1243832400, 1246424400, 1249102800, 1251781200, 1254373200, 1257051600,
1259643600, 1262322000, 1265000400, 1267419600, 1270098000, 1272690000,
1275368400, 1277960400, 1280638800, 1283317200, 1285909200, 1288587600,
1291179600, 1293858000, 1296536400, 1298955600, 1301634000, 1304226000,
1306904400, 1309496400, 1312174800, 1314853200, 1317445200, 1320123600,
1322715600, 1325394000, 1328072400, 1330578000, 1333256400, 1335848400,
1338526800, 1341118800, 1343797200, 1346475600, 1349067600, 1351746000,
1354338000, 1357016400, 1359694800, 1362114000, 1364792400, 1367384400,
1370062800, 1372654800, 1375333200, 1378011600, 1380603600, 1383282000,
1385874000, 1388552400, 1391230800, 1393650000, 1396328400, 1398920400,
1401598800, 1404190800, 1406869200, 1409547600, 1412139600, 1414818000,
1417410000, 1420088400, 1422766800, 1425186000, 1427864400, 1430456400,
1433134800, 1435726800, 1438405200, 1441083600, 1443675600, 1446354000,
1448946000, 1451624400, 1454302800, 1456808400, 1459486800, 1462078800,
1464757200, 1467349200, 1470027600, 1472706000, 1475298000, 1477976400,
1480568400, 1483246800, 1485925200, 1488344400, 1491022800, 1493614800,
1496293200, 1501563600, 1504242000), class = c("POSIXct", "POSIXt"
), tzone = ""), Transits = c(14L, 14L, 13L, 10L, 11L, 14L, 14L,
14L, 16L, 6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L, 8L,
10L, 9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L,
7L, 7L, 8L, 4L, 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L, 5L,
10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L, 5L, 6L, 7L, 6L, 9L, 8L,
10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L, 14L, 15L,
14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L, 9L, 12L, 8L,
12L, 10L, 11L, 10L, 9L, 10L, 11L, 8L, 10L, 12L, 10L, 11L, 14L,
9L, 15L, 15L, 14L, 14L, 14L, 15L, 16L, 15L, 18L, 21L, 18L, 17L,
21L, 18L, 19L, 19L, 18L, 21L, 22L, 25L, 23L, 28L, 25L, 25L, 25L,
21L, 28L, 21L, 22L, 23L, 20L, 24L, 22L, 26L, 24L, 24L, 28L, 31L,
34L, 36L, 33L, 29L, 34L, 33L, 33L, 31L, 33L, 29L, 32L, 26L, 24L,
30L, 27L, 31L, 23L, 23L, 21L, 21L, 18L, 21L, 19L, 19L, 16L, 14L,
22L, 24L, 28L, 26L, 29L, 23L, 28L, 21L, 17L, 17L, 14L, 12L, 14L,
10L, 12L, 13L, 14L, 15L, 21L, 10L, 15L, 12L, 15L, 16L, 17L, 14L,
14L, 12L, 7L, 8L, 8L, 11L, 9L, 12L, 11L, 6L, 8L, 11L, 7L, 8L,
14L, 9L, 11L, 8L, 8L, 6L, 3L, 4L, 4L, 5L, 4L, 3L, 3L, 5L, 8L,
6L, 8L, 6L, 7L, 14L, 14L, 15L, 13L, 16L, 18L, 20L, 21L, 18L,
19L, 24L, 27L, 26L, 18L, 28L, 21L, 22L, 25L, 29L, 26L, 22L, 22L,
14L, 18L, 18L, 13L, 15L, 16L, 19L, 9L, 14L, 11L, 9L, 14L, 16L,
11L, 13L, 11L, 16L, 16L, 20L, 17L, 19L, 18L, 24L, 19L, 19L, 15L,
21L, 21L, 24L, 28L, 14L, 20L, 15L, 24L, 18L, 24L, 24L, 25L, 21L,
24L, 27L, 28L, 27L, 26L, 29L, 25L, 24L, 25L, 28L, 23L, 30L, 23L,
29L, 26L, 31L, 33L, 40L, 36L, 39L, 36L, 34L, 32L, 32L, 30L, 27L,
32L, 30L, 31L, 26L, 31L, 29L, 26L, 28L, 24L, 22L, 11L, 15L, 17L,
12L, 13L, 14L, 9L, 12L, 11L, 17L, 9L, 8L, 7L, 11L, 8L, 15L, 8L,
10L, 13L, 12L, 13L, 12L, 12L, 19L, 21L, 18L, 20L, 21L, 20L, 22L,
19L, 21L, 20L, 21L, 18L, 18L, 19L, 13L, 16L, 12L, 6L, 7L, 5L,
6L, 6L, 7L, 7L, 5L, 4L, 6L, 4L, 1L, 2L, 7L, 12L), CargoTons = c(154973L,
129636L, 136884L, 86348L, 109907L, 154506L, 144083L, 152794L,
124861L, 60330L, 65221L, 61718L, 53997L, 83536L, 63218L, 98222L,
54719L, 98470L, 18263L, 104255L, 62869L, 62523L, 75344L, 81476L,
92818L, 87457L, 85231L, 77897L, 57699L, 96989L, 109361L, 59799L,
91116L, 82241L, 74251L, 124361L, 68751L, 61719L, 68017L, 37760L,
32513L, 56359L, 51333L, 80859L, 75852L, 65760L, 96043L, 38820L,
63202L, 102647L, 49104L, 53482L, 121305L, 71795L, 76704L, 146097L,
73047L, 68557L, 110642L, 77616L, 97767L, 52059L, 58658L, 66350L,
69303L, 76013L, 91909L, 108445L, 94454L, 101249L, 112131L, 56290L,
118342L, 70618L, 64783L, 112839L, 120506L, 94243L, 130768L, 133643L,
146321L, 140736L, 147234L, 158953L, 189888L, 93819L, 130021L,
130124L, 55088L, 114783L, 95184L, 82205L, 80321L, 65422L, 98933L,
93713L, 98417L, 97210L, 88464L, 94659L, 92873L, 79784L, 96655L,
122266L, 100779L, 120569L, 133029L, 92889L, 160886L, 132364L,
130435L, 139653L, 152143L, 160824L, 165842L, 175679L, 210872L,
211941L, 207820L, 179857L, 212733L, 203135L, 218368L, 198343L,
195677L, 210066L, 243311L, 261965L, 240683L, 245242L, 218004L,
247640L, 209872L, 223668L, 290521L, 185161L, 210341L, 261739L,
205431L, 284114L, 251466L, 302961L, 292981L, 279329L, 309197L,
341092L, 385209L, 366958L, 330515L, 286950L, 295590L, 350901L,
341678L, 284666L, 283148L, 279108L, 284896L, 238802L, 198786L,
273465L, 256694L, 360520L, 320201L, 296881L, 264202L, 280142L,
219105L, 278606L, 254420L, 260339L, 216457L, 198077L, 249436L,
302860L, 360184L, 317105L, 391413L, 265210L, 354714L, 306031L,
266124L, 215799L, 232630L, 156590L, 203111L, 157075L, 160140L,
177874L, 219162L, 159610L, 286483L, 144631L, 216456L, 157305L,
237780L, 191617L, 223211L, 180330L, 187074L, 126043L, 62462L,
93633L, 56417L, 115036L, 74365L, 98785L, 116172L, 43421L, 73769L,
128795L, 58910L, 74282L, 115312L, 102303L, 106109L, 76940L, 82683L,
49149L, 22517L, 20731L, 24684L, 52558L, 40057L, 28981L, 46062L,
43213L, 107755L, 53404L, 56390L, 41541L, 41183L, 80161L, 110960L,
130891L, 130395L, 183351L, 242803L, 225383L, 190962L, 169432L,
186260L, 206997L, 196097L, 202942L, 175063L, 240869L, 213226L,
237754L, 208280L, 231596L, 207033L, 213294L, 250265L, 129334L,
173986L, 145188L, 98384L, 163739L, 138180L, 136521L, 86836L,
97452L, 71988L, 79293L, 124134L, 116343L, 91030L, 98457L, 77906L,
130599L, 132381L, 162992L, 142756L, 150105L, 150339L, 161097L,
112633L, 145691L, 100771L, 147805L, 123418L, 138375L, 185776L,
108842L, 145245L, 108517L, 154079L, 118999L, 184855L, 157646L,
187000L, 126190L, 181693L, 180395L, 170781L, 200521L, 140371L,
185517L, 160662L, 149601L, 164220L, 162613L, 120102L, 189868L,
131791L, 187465L, 205760L, 249684L, 219829L, 201173L, 230138L,
261196L, 258797L, 286470L, 216719L, 219241L, 221386L, 191207L,
212000L, 220639L, 237053L, 172805L, 199395L, 154402L, 152970L,
120174L, 188452L, 122797L, 88608L, 101692L, 114182L, 96193L,
111524L, 93344L, 87006L, 104160L, 88455L, 77399L, 69451L, 73572L,
54280L, 93056L, 71274L, 124714L, 65822L, 54215L, 73492L, 73178L,
104991L, 68259L, 88045L, 84797L, 47925L, 88662L, 88082L, 140498L,
116875L, 145168L, 107149L, 144324L, 119079L, 171258L, 97017L,
86082L, 110873L, 50194L, 114805L, 62368L, 32524L, 39318L, 30558L,
42822L, 45154L, 35025L, 20565L, 58236L, 35809L, 47644L, 30747L,
NA, NA, 35449L, 48808L), RcnstPCUMS = c(229914L, 214547L, 215890L,
158695L, 173125L, 222533L, 212490L, 222125L, 266913L, 94268L,
112967L, 95480L, 87654L, 108996L, 97973L, 139247L, 93817L, 133197L,
40020L, 169749L, 102590L, 112121L, 140241L, 122989L, 144592L,
144979L, 123748L, 123249L, 70081L, 155218L, 168096L, 104743L,
163384L, 142648L, 129188L, 183170L, 99299L, 99873L, 111648L,
55890L, 59183L, 95568L, 72550L, 104562L, 100478L, 92665L, 130625L,
54786L, 105900L, 135833L, 70932L, 73247L, 149632L, 94317L, 87926L,
181989L, 92778L, 107097L, 153246L, 105175L, 126393L, 81976L,
95518L, 109019L, 95370L, 140492L, 125795L, 157978L, 138424L,
138160L, 180320L, 78757L, 135860L, 85921L, 114847L, 151965L,
152561L, 132841L, 204839L, 209567L, 224436L, 210209L, 227143L,
245968L, 264969L, 158648L, 222251L, 194335L, 111618L, 189643L,
137438L, 124953L, 163155L, 107633L, 164525L, 135102L, 152072L,
126636L, 121008L, 137824L, 149673L, 106832L, 134953L, 162195L,
135259L, 151180L, 188069L, 121234L, 199609L, 206011L, 186772L,
185596L, 189869L, 189930L, 209268L, 191993L, 238722L, 281076L,
236211L, 227651L, 277805L, 248063L, 258661L, 261644L, 248401L,
292764L, 313626L, 353877L, 318685L, 385547L, 346224L, 347058L,
353098L, 290663L, 398291L, 305578L, 314469L, 325343L, 281866L,
355524L, 323626L, 393901L, 360773L, 362326L, 415317L, 464535L,
511488L, 540671L, 491824L, 426657L, 500855L, 494717L, 495668L,
455605L, 484598L, 437629L, 476437L, 383114L, 357059L, 449471L,
409024L, 479044L, 360007L, 360455L, 333982L, 342971L, 273450L,
337258L, 308626L, 302838L, 265044L, 221514L, 341869L, 371003L,
450406L, 414775L, 469590L, 360334L, 451528L, 337465L, 283627L,
278748L, 242639L, 202808L, 237041L, 174856L, 206948L, 219398L,
247023L, 253697L, 351625L, 179661L, 255214L, 205368L, 258669L,
270376L, 284729L, 231441L, 240220L, 197141L, 110459L, 124586L,
115785L, 208191L, 139493L, 195068L, 184665L, 99351L, 123562L,
186571L, 117504L, 128846L, 217616L, 128850L, 158105L, 112762L,
118091L, 91510L, 41670L, 65418L, 57038L, 74113L, 63359L, 48717L,
59326L, 79181L, 133076L, 93478L, 121455L, 100396L, 113939L, 224357L,
209899L, 237803L, 196839L, 254633L, 278283L, 302996L, 315330L,
272767L, 277027L, 357066L, 398089L, 400740L, 275789L, 429226L,
326028L, 332848L, 388062L, 434889L, 397012L, 332171L, 338845L,
209076L, 270632L, 261217L, 191663L, 222970L, 237384L, 276674L,
138649L, 203588L, 178863L, 135641L, 217348L, 239162L, 168607L,
196393L, 173731L, 256877L, 250192L, 303120L, 256045L, 278352L,
266185L, 350521L, 282258L, 281162L, 226240L, 312103L, 312547L,
369650L, 420464L, 214503L, 305474L, 232981L, 382171L, 291030L,
370213L, 368859L, 395471L, 331912L, 389084L, 433543L, 446459L,
434882L, 427397L, 482135L, 424532L, 402021L, 413143L, 460258L,
399300L, 513805L, 383895L, 485673L, 426859L, 515510L, 532852L,
640559L, 591249L, 612067L, 577562L, 546291L, 524853L, 515396L,
485261L, 442432L, 520541L, 485585L, 505058L, 424639L, 527199L,
468619L, 427842L, 457937L, 414473L, 368965L, 165326L, 228879L,
261042L, 184066L, 199600L, 213524L, 140264L, 175064L, 152734L,
252011L, 139741L, 124736L, 106170L, 165564L, 127610L, 237950L,
122876L, 151239L, 191794L, 173043L, 187453L, 171653L, 171397L,
275756L, 308794L, 264032L, 285570L, 322867L, 281804L, 311683L,
271705L, 310707L, 286221L, 302599L, 270895L, 258684L, 277845L,
191935L, 236936L, 180781L, 101623L, 112534L, 81747L, 98125L,
102205L, 111226L, 110349L, 89677L, 69492L, 97820L, 69730L, 15018L,
40889L, 97624L, 166204L), TotalToll = c(420742L, 392621L, 395078L,
290411L, 316818L, 407235L, 388856L, 406488L, 482774L, 172510L,
206729L, 174728L, 160406L, 199462L, 179290L, 254822L, 171685L,
243750L, 73236L, 310640L, 187739L, 205181L, 249438L, 225069L,
264603L, 265311L, 226458L, 225545L, 128248L, 284048L, 296023L,
184934L, 298992L, 261045L, 236414L, 335201L, 181717L, 182767L,
204315L, 102278L, 108304L, 174889L, 132766L, 191348L, 183874L,
169576L, 239043L, 100258L, 212859L, 273024L, 142573L, 147226L,
300760L, 189577L, 176731L, 365797L, 186483L, 215264L, 308024L,
211401L, 254049L, 164771L, 191991L, 219128L, 191693L, 282388L,
252847L, 317535L, 278232L, 277701L, 356022L, 158301L, 273078L,
172701L, 230842L, 305449L, 306647L, 267010L, 406202L, 421229L,
451116L, 422520L, 456557L, 494395L, 582202L, 350612L, 491174L,
429480L, 239858L, 419111L, 303737L, 276146L, 360572L, 237868L,
358627L, 298575L, 336079L, 279865L, 267427L, 304591L, 323566L,
236098L, 298246L, 358450L, 298922L, 334107L, 415632L, 267927L,
441136L, 455284L, 412766L, 410167L, 419610L, 419745L, 462482L,
424305L, 527576L, 621178L, 522026L, 503109L, 613949L, 548219L,
571641L, 578233L, 548966L, 647008L, 693113L, 782068L, 704294L,
845344L, 765155L, 766998L, 774306L, 642365L, 880223L, 730331L,
751581L, 770694L, 660018L, 849702L, 773466L, 941423L, 862247L,
865959L, 992608L, 1103240L, 1222456L, 1389524L, 1263988L, 1096508L,
1278566L, 1271423L, 1273867L, 1158103L, 1239499L, 1124707L, 1218525L,
984603L, 909630L, 1155140L, 1043122L, 1231143L, 925218L, 926369L,
850265L, 881435L, 702766L, 866753L, 793169L, 778294L, 681163L,
569291L, 871709L, 953478L, 1150022L, 1065972L, 1206846L, 926058L,
1129778L, 867285L, 728921L, 716382L, 623582L, 521217L, 609195L,
449380L, 531856L, 563853L, 634849L, 643607L, 888831L, 461729L,
655900L, 527796L, 664779L, 687175L, 731754L, 586409L, 617365L,
506652L, 276310L, 320186L, 289618L, 535051L, 389544L, 544553L,
515428L, 277302L, 336755L, 512700L, 318225L, 359684L, 607673L,
379065L, 465104L, 331810L, 347203L, 268918L, 122643L, 192034L,
159071L, 217928L, 186080L, 134668L, 173724L, 232564L, 390599L,
265947L, 348773L, 294627L, 334562L, 649731L, 607805L, 698507L,
578572L, 1059450L, 1187844L, 1246619L, 1296120L, 1140384L, 1187214L,
1432452L, 1606332L, 1728174L, 1203594L, 1822716L, 1389276L, 1728426L,
1926935L, 2125297L, 1943820L, 1623321L, 1590148L, 1049286L, 1398754L,
1320550L, 994945L, 1164583L, 1205841L, 1559682L, 769662L, 1091567L,
1000642L, 718794L, 1175818L, 1254971L, 900558L, 1033592L, 927072L,
1245348L, 1240380L, 1820813L, 1567994L, 1789477L, 1700773L, 2204080L,
1745881L, 1842826L, 1476216L, 1967969L, 1939304L, 2335284L, 2676920L,
1580544L, 2277360L, 1694016L, 2721614L, 2107008L, 2630707L, 2530555L,
2872656L, 2395440L, 2704234L, 3035837L, 3147379L, 3076661L, 2903544L,
3398155L, 2964859L, 2837506L, 2883096L, 3264696L, 2779186L, 3980670L,
2923166L, 3739659L, 3317358L, 3978904L, 4112544L, 4828331L, 4423260L,
4650546L, 4321198L, 4147356L, 3959882L, 3891892L, 3623148L, 3365086L,
3917517L, 3708696L, 3876444L, 3234706L, 3968716L, 3558025L, 3313506L,
3522721L, 3104372L, 2772710L, 1329618L, 1857286L, 2126974L, 1509160L,
1616068L, 1679704L, 1164638L, 1390846L, 1199265L, 1868727L, 1091024L,
1023810L, 837614L, 1367468L, 1056694L, 1886631L, 951129L, 1153342L,
1491752L, 1305802L, 1461332L, 1286770L, 1310026L, 1997167L, 2234964L,
1924902L, 2080596L, 2331026L, 2046594L, 2302530L, 1958478L, 2262478L,
2115387L, 2220923L, 1959669L, 1849238L, 2089172L, 1381704L, 1553856L,
1251361L, 704230L, 776554L, 592426L, 704066L, 772042L, 754649L,
797425L, 624502L, 517122L, 683626L, 507750L, 99592L, 217680L,
671070L, 1150758L)), class = "data.frame", row.names = c(NA,
383L))

	[[alternative HTML version deleted]]



From z@@v@z @end|ng |rom gm@||@com  Mon Sep  3 15:21:48 2018
From: z@@v@z @end|ng |rom gm@||@com (Pedro Vaz)
Date: Mon, 3 Sep 2018 14:21:48 +0100
Subject: [R] Account for a factor variability in a logistic GLMM in lme4
Message-ID: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>

We did a field study in which we tried to understand which factors
significantly explain the probability of a group of animals (5 species in
total) crossing through 30 wildlife road-crossing structures. The response
variable is binomial (yes=crossed; no = did not cross) and was recorded by
animal species. We did about 30 visits to each crossing structure (our
random factor) in which we recorded the binomial response by each animal
species and the values of a few predictors.

So, I have this (simplified for better understanding) mixed effects model:
library (lme4)

Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|structure.id),
  data = Mydata, family = binomial)

stream is a factor with 2 levels; width.m is continuous; grass.per is a
percentage

This is the model in which I assessed crossings by all species combined
(i.e., cross. 01 = 1 when an animal of any species crossed, cross.01 = 0
when no animal crossed). However, we did one model per species and those
species-specific models highlight that different species exhibit different
relationships between crossings and explanatory variables.

My problem: This means that my model above suffers from an additional
source of variation related to the species level without accounting for it.
However I cannot recalibrate the above model adding the species level as
random factor because, in my binomial response, the zero means no species
crossed (all zeros would have "NA" or, say, "none" for species) and so that
additional source of variation is only present when the response was 1.
Just to confirm this, I did add species as a random factor:

(1 | structure.id) + (1 | species)

As expected, the message is "Error: Response is constant"

How can I account for the species variability in my model in lme4?

A few more details:
A few more details:
- I had 5 mammal species crossing through the 30 road-crossing structures.
In 134 occasions (i.e., 134 of my records on individual
crossing-structures), no animal crossed (so, @Dimitris Rizopoulos, no, I
didn't have the species of the animals which did not cross. A "no cross"
was a "zero" for that visit to the crossing-structure). In 498 occasions,
at least one animal of a given species crossed the structure (these were my
"ones" in my logistic response)
- A side comment: This is to respond to a reviewer in a paper of mine,
i.e., I did and presented species-specific and "all combined species"
models in the draft reviewed but now the reviewer is asking me to control
for the species variability in the "combined species model". He asked me to
include a random factor but I realized that is not possible since all my
zeros would have "none" for the species that crossed. So, is it possible to
control for the species variability in my model in lme4 in another way? I
know in nlme including a fitting of variance structures it's not that
difficult...
- Every time an animal crossed, the binary response was "one" and I
recorded the animal species as well. Thus, I have variability between
species in the "ones" but not in my "zeros" of my logistic model.

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep  3 16:46:53 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 3 Sep 2018 07:46:53 -0700
Subject: [R] Account for a factor variability in a logistic GLMM in lme4
In-Reply-To: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>
References: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>
Message-ID: <CAGxFJbTwkYC11NKc+3=ZCkihGerjVa5L9G2Dv+GybnXRNbfeLA@mail.gmail.com>

You should post this on the r-sig-mixed-models list, not here.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 3, 2018 at 7:43 AM Pedro Vaz <zasvaz at gmail.com> wrote:

> We did a field study in which we tried to understand which factors
> significantly explain the probability of a group of animals (5 species in
> total) crossing through 30 wildlife road-crossing structures. The response
> variable is binomial (yes=crossed; no = did not cross) and was recorded by
> animal species. We did about 30 visits to each crossing structure (our
> random factor) in which we recorded the binomial response by each animal
> species and the values of a few predictors.
>
> So, I have this (simplified for better understanding) mixed effects model:
> library (lme4)
>
> Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|
> structure.id),
>   data = Mydata, family = binomial)
>
> stream is a factor with 2 levels; width.m is continuous; grass.per is a
> percentage
>
> This is the model in which I assessed crossings by all species combined
> (i.e., cross. 01 = 1 when an animal of any species crossed, cross.01 = 0
> when no animal crossed). However, we did one model per species and those
> species-specific models highlight that different species exhibit different
> relationships between crossings and explanatory variables.
>
> My problem: This means that my model above suffers from an additional
> source of variation related to the species level without accounting for it.
> However I cannot recalibrate the above model adding the species level as
> random factor because, in my binomial response, the zero means no species
> crossed (all zeros would have "NA" or, say, "none" for species) and so that
> additional source of variation is only present when the response was 1.
> Just to confirm this, I did add species as a random factor:
>
> (1 | structure.id) + (1 | species)
>
> As expected, the message is "Error: Response is constant"
>
> How can I account for the species variability in my model in lme4?
>
> A few more details:
> A few more details:
> - I had 5 mammal species crossing through the 30 road-crossing structures.
> In 134 occasions (i.e., 134 of my records on individual
> crossing-structures), no animal crossed (so, @Dimitris Rizopoulos, no, I
> didn't have the species of the animals which did not cross. A "no cross"
> was a "zero" for that visit to the crossing-structure). In 498 occasions,
> at least one animal of a given species crossed the structure (these were my
> "ones" in my logistic response)
> - A side comment: This is to respond to a reviewer in a paper of mine,
> i.e., I did and presented species-specific and "all combined species"
> models in the draft reviewed but now the reviewer is asking me to control
> for the species variability in the "combined species model". He asked me to
> include a random factor but I realized that is not possible since all my
> zeros would have "none" for the species that crossed. So, is it possible to
> control for the species variability in my model in lme4 in another way? I
> know in nlme including a fitting of variance structures it's not that
> difficult...
> - Every time an animal crossed, the binary response was "one" and I
> recorded the animal species as well. Thus, I have variability between
> species in the "ones" but not in my "zeros" of my logistic model.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Mon Sep  3 16:57:26 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 3 Sep 2018 14:57:26 +0000
Subject: [R] Error when using complete function for imputed data
In-Reply-To: <CAMOcQfN82EGX1SPQY7iet2LsMT25iKXJBFLMvLg80k3cC6t0ug@mail.gmail.com>
References: <CAMOcQfN82EGX1SPQY7iet2LsMT25iKXJBFLMvLg80k3cC6t0ug@mail.gmail.com>
Message-ID: <ed740a07a1ea446d9f503563895d5fa9@SRVEXCHCM1302.precheza.cz>

Hi

AFAIK it was probably answered several days ago that mice conflicts with some other loaded package.

I did not get any error.

After importing your data
str(dataFrame)
'data.frame':   383 obs. of  5 variables:
 $ TransitDate: POSIXct, format: "1985-10-01 06:00:00" "1985-11-01 06:00:00" ...
 $ Transits   : int  14 14 13 10 11 14 14 14 16 6 ...
 $ CargoTons  : int  154973 129636 136884 86348 109907 154506 144083 152794 124861 60330 ...
 $ RcnstPCUMS : int  229914 214547 215890 158695 173125 222533 212490 222125 266913 94268 ...
 $ TotalToll  : int  420742 392621 395078 290411 316818 407235 388856 406488

> colSums(apply(dataFrame,2, is.na))
TransitDate    Transits   CargoTons  RcnstPCUMS   TotalToll
          0           0           2           0           0
> library(mice)
> Imputed_Data <- mice(dataFrame[2:5])
> CompleteData <- complete(Imputed_Data)
> colSums(apply(CompleteData,2, is.na))
  Transits  CargoTons RcnstPCUMS  TotalToll
         0          0          0          0
>

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
> Sent: Monday, September 3, 2018 4:30 PM
> To: r-help at r-project.org
> Subject: [R] Error when using complete function for imputed data
>
> Dear friends,
>
> It seems to me that there is something wrong with the complete function. I
> am using R version 3.5.0 and mice package for data imputation.
>
> I am working on a Windows 8.1 Enterprise machine with 64-bit Operating
> System.
>
> So here is my code:
>
> Imputed_Data <- mice(dataFrame[2:5])
> CompleteData <- complete(Imputed_Data)
> Error in UseMethod("complete_") :
>   no applicable method for 'complete_' applied to an object of class "mids"
>
> I used the complete function before when imputing data with the mice
> function, but now it is not working.
>
> Any help will be greatly appreciated. Below is the dput() of my dataset:
>
> > dput(dataFrame)
> structure(list(TransitDate = structure(c(496990800, 499669200,
> 502261200, 504939600, 507618000, 510037200, 512715600, 515307600,
> 517986000, 520578000, 523256400, 525934800, 528526800, 531205200,
> 533797200, 536475600, 539154000, 541573200, 544251600, 546843600,
> 549522000, 552114000, 554792400, 557470800, 560062800, 562741200,
> 565333200, 568011600, 570690000, 573195600, 575874000, 578466000,
> 581144400, 583736400, 586414800, 589093200, 591685200, 594363600,
> 596955600, 599634000, 602312400, 604731600, 607410000, 610002000,
> 612680400, 615272400, 617950800, 620629200, 623221200, 625899600,
> 628491600, 631170000, 633848400, 636267600, 638946000, 641538000,
> 644216400, 646808400, 649486800, 652165200, 654757200, 657435600,
> 660027600, 662706000, 665384400, 667803600, 670482000, 673074000,
> 675752400, 678344400, 681022800, 683701200, 686293200, 688971600,
> 691563600, 694242000, 696920400, 699426000, 702104400, 704696400,
> 707371200, 709963200, 712641600, 715320000, 717912000, 720590400,
> 723182400, 725860800, 728539200, 730958400, 733636800, 736232400,
> 738910800, 741502800, 744181200, 746859600, 749451600, 752130000,
> 754722000, 757400400, 760078800, 762498000, 765176400, 767768400,
> 770446800, 773038800, 775717200, 778395600, 780987600, 783666000,
> 786258000, 788936400, 791614800, 794034000, 796712400, 799304400,
> 801982800, 804574800, 807253200, 809931600, 812523600, 815202000,
> 817794000, 820472400, 823150800, 825656400, 828334800, 830926800,
> 833605200, 836197200, 838875600, 841554000, 844146000, 846824400,
> 849416400, 852094800, 854773200, 857192400, 859870800, 862462800,
> 865141200, 867733200, 870411600, 873090000, 875682000, 878360400,
> 880952400, 883630800, 886309200, 888728400, 891406800, 893998800,
> 896677200, 899269200, 901947600, 904626000, 907218000, 909896400,
> 912488400, 915166800, 917845200, 920264400, 922942800, 925534800,
> 928213200, 930805200, 933483600, 936162000, 938754000, 941432400,
> 944024400, 946702800, 949381200, 951886800, 954565200, 957157200,
> 959835600, 962427600, 965106000, 967784400, 970376400, 973054800,
> 975646800, 978325200, 981003600, 983422800, 986101200, 988693200,
> 991371600, 993963600, 996642000, 999320400, 1001912400, 1004590800,
> 1007182800, 1009861200, 1012539600, 1014958800, 1017637200,
> 1020229200,
> 1022907600, 1025499600, 1028178000, 1030856400, 1033448400,
> 1036126800,
> 1038718800, 1041397200, 1044075600, 1046494800, 1049173200,
> 1051765200,
> 1054443600, 1057035600, 1059714000, 1062392400, 1064984400,
> 1067662800,
> 1070254800, 1072933200, 1075611600, 1078117200, 1080795600,
> 1083387600,
> 1086066000, 1088658000, 1091336400, 1094014800, 1096606800,
> 1099285200,
> 1101877200, 1104555600, 1107234000, 1109653200, 1112331600,
> 1114923600,
> 1117602000, 1120194000, 1122872400, 1125550800, 1128142800,
> 1130821200,
> 1133413200, 1136091600, 1138770000, 1141189200, 1143867600,
> 1146459600,
> 1149138000, 1151730000, 1154408400, 1157086800, 1159678800,
> 1162357200,
> 1164949200, 1167627600, 1170306000, 1172725200, 1175403600,
> 1177995600,
> 1180674000, 1183266000, 1185944400, 1188622800, 1191214800,
> 1193893200,
> 1196485200, 1199163600, 1201842000, 1204347600, 1207026000,
> 1209618000,
> 1212296400, 1214888400, 1217566800, 1220245200, 1222837200,
> 1225515600,
> 1228107600, 1230786000, 1233464400, 1235883600, 1238562000,
> 1241154000,
> 1243832400, 1246424400, 1249102800, 1251781200, 1254373200,
> 1257051600,
> 1259643600, 1262322000, 1265000400, 1267419600, 1270098000,
> 1272690000,
> 1275368400, 1277960400, 1280638800, 1283317200, 1285909200,
> 1288587600,
> 1291179600, 1293858000, 1296536400, 1298955600, 1301634000,
> 1304226000,
> 1306904400, 1309496400, 1312174800, 1314853200, 1317445200,
> 1320123600,
> 1322715600, 1325394000, 1328072400, 1330578000, 1333256400,
> 1335848400,
> 1338526800, 1341118800, 1343797200, 1346475600, 1349067600,
> 1351746000,
> 1354338000, 1357016400, 1359694800, 1362114000, 1364792400,
> 1367384400,
> 1370062800, 1372654800, 1375333200, 1378011600, 1380603600,
> 1383282000,
> 1385874000, 1388552400, 1391230800, 1393650000, 1396328400,
> 1398920400,
> 1401598800, 1404190800, 1406869200, 1409547600, 1412139600,
> 1414818000,
> 1417410000, 1420088400, 1422766800, 1425186000, 1427864400,
> 1430456400,
> 1433134800, 1435726800, 1438405200, 1441083600, 1443675600,
> 1446354000,
> 1448946000, 1451624400, 1454302800, 1456808400, 1459486800,
> 1462078800,
> 1464757200, 1467349200, 1470027600, 1472706000, 1475298000,
> 1477976400,
> 1480568400, 1483246800, 1485925200, 1488344400, 1491022800,
> 1493614800,
> 1496293200, 1501563600, 1504242000), class = c("POSIXct", "POSIXt"
> ), tzone = ""), Transits = c(14L, 14L, 13L, 10L, 11L, 14L, 14L,
> 14L, 16L, 6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L, 8L,
> 10L, 9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L,
> 7L, 7L, 8L, 4L, 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L, 5L,
> 10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L, 5L, 6L, 7L, 6L, 9L, 8L,
> 10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L, 14L, 15L,
> 14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L, 9L, 12L, 8L,
> 12L, 10L, 11L, 10L, 9L, 10L, 11L, 8L, 10L, 12L, 10L, 11L, 14L,
> 9L, 15L, 15L, 14L, 14L, 14L, 15L, 16L, 15L, 18L, 21L, 18L, 17L,
> 21L, 18L, 19L, 19L, 18L, 21L, 22L, 25L, 23L, 28L, 25L, 25L, 25L,
> 21L, 28L, 21L, 22L, 23L, 20L, 24L, 22L, 26L, 24L, 24L, 28L, 31L,
> 34L, 36L, 33L, 29L, 34L, 33L, 33L, 31L, 33L, 29L, 32L, 26L, 24L,
> 30L, 27L, 31L, 23L, 23L, 21L, 21L, 18L, 21L, 19L, 19L, 16L, 14L,
> 22L, 24L, 28L, 26L, 29L, 23L, 28L, 21L, 17L, 17L, 14L, 12L, 14L,
> 10L, 12L, 13L, 14L, 15L, 21L, 10L, 15L, 12L, 15L, 16L, 17L, 14L,
> 14L, 12L, 7L, 8L, 8L, 11L, 9L, 12L, 11L, 6L, 8L, 11L, 7L, 8L,
> 14L, 9L, 11L, 8L, 8L, 6L, 3L, 4L, 4L, 5L, 4L, 3L, 3L, 5L, 8L,
> 6L, 8L, 6L, 7L, 14L, 14L, 15L, 13L, 16L, 18L, 20L, 21L, 18L,
> 19L, 24L, 27L, 26L, 18L, 28L, 21L, 22L, 25L, 29L, 26L, 22L, 22L,
> 14L, 18L, 18L, 13L, 15L, 16L, 19L, 9L, 14L, 11L, 9L, 14L, 16L,
> 11L, 13L, 11L, 16L, 16L, 20L, 17L, 19L, 18L, 24L, 19L, 19L, 15L,
> 21L, 21L, 24L, 28L, 14L, 20L, 15L, 24L, 18L, 24L, 24L, 25L, 21L,
> 24L, 27L, 28L, 27L, 26L, 29L, 25L, 24L, 25L, 28L, 23L, 30L, 23L,
> 29L, 26L, 31L, 33L, 40L, 36L, 39L, 36L, 34L, 32L, 32L, 30L, 27L,
> 32L, 30L, 31L, 26L, 31L, 29L, 26L, 28L, 24L, 22L, 11L, 15L, 17L,
> 12L, 13L, 14L, 9L, 12L, 11L, 17L, 9L, 8L, 7L, 11L, 8L, 15L, 8L,
> 10L, 13L, 12L, 13L, 12L, 12L, 19L, 21L, 18L, 20L, 21L, 20L, 22L,
> 19L, 21L, 20L, 21L, 18L, 18L, 19L, 13L, 16L, 12L, 6L, 7L, 5L,
> 6L, 6L, 7L, 7L, 5L, 4L, 6L, 4L, 1L, 2L, 7L, 12L), CargoTons = c(154973L,
> 129636L, 136884L, 86348L, 109907L, 154506L, 144083L, 152794L,
> 124861L, 60330L, 65221L, 61718L, 53997L, 83536L, 63218L, 98222L,
> 54719L, 98470L, 18263L, 104255L, 62869L, 62523L, 75344L, 81476L,
> 92818L, 87457L, 85231L, 77897L, 57699L, 96989L, 109361L, 59799L,
> 91116L, 82241L, 74251L, 124361L, 68751L, 61719L, 68017L, 37760L,
> 32513L, 56359L, 51333L, 80859L, 75852L, 65760L, 96043L, 38820L,
> 63202L, 102647L, 49104L, 53482L, 121305L, 71795L, 76704L, 146097L,
> 73047L, 68557L, 110642L, 77616L, 97767L, 52059L, 58658L, 66350L,
> 69303L, 76013L, 91909L, 108445L, 94454L, 101249L, 112131L, 56290L,
> 118342L, 70618L, 64783L, 112839L, 120506L, 94243L, 130768L, 133643L,
> 146321L, 140736L, 147234L, 158953L, 189888L, 93819L, 130021L,
> 130124L, 55088L, 114783L, 95184L, 82205L, 80321L, 65422L, 98933L,
> 93713L, 98417L, 97210L, 88464L, 94659L, 92873L, 79784L, 96655L,
> 122266L, 100779L, 120569L, 133029L, 92889L, 160886L, 132364L,
> 130435L, 139653L, 152143L, 160824L, 165842L, 175679L, 210872L,
> 211941L, 207820L, 179857L, 212733L, 203135L, 218368L, 198343L,
> 195677L, 210066L, 243311L, 261965L, 240683L, 245242L, 218004L,
> 247640L, 209872L, 223668L, 290521L, 185161L, 210341L, 261739L,
> 205431L, 284114L, 251466L, 302961L, 292981L, 279329L, 309197L,
> 341092L, 385209L, 366958L, 330515L, 286950L, 295590L, 350901L,
> 341678L, 284666L, 283148L, 279108L, 284896L, 238802L, 198786L,
> 273465L, 256694L, 360520L, 320201L, 296881L, 264202L, 280142L,
> 219105L, 278606L, 254420L, 260339L, 216457L, 198077L, 249436L,
> 302860L, 360184L, 317105L, 391413L, 265210L, 354714L, 306031L,
> 266124L, 215799L, 232630L, 156590L, 203111L, 157075L, 160140L,
> 177874L, 219162L, 159610L, 286483L, 144631L, 216456L, 157305L,
> 237780L, 191617L, 223211L, 180330L, 187074L, 126043L, 62462L,
> 93633L, 56417L, 115036L, 74365L, 98785L, 116172L, 43421L, 73769L,
> 128795L, 58910L, 74282L, 115312L, 102303L, 106109L, 76940L, 82683L,
> 49149L, 22517L, 20731L, 24684L, 52558L, 40057L, 28981L, 46062L,
> 43213L, 107755L, 53404L, 56390L, 41541L, 41183L, 80161L, 110960L,
> 130891L, 130395L, 183351L, 242803L, 225383L, 190962L, 169432L,
> 186260L, 206997L, 196097L, 202942L, 175063L, 240869L, 213226L,
> 237754L, 208280L, 231596L, 207033L, 213294L, 250265L, 129334L,
> 173986L, 145188L, 98384L, 163739L, 138180L, 136521L, 86836L,
> 97452L, 71988L, 79293L, 124134L, 116343L, 91030L, 98457L, 77906L,
> 130599L, 132381L, 162992L, 142756L, 150105L, 150339L, 161097L,
> 112633L, 145691L, 100771L, 147805L, 123418L, 138375L, 185776L,
> 108842L, 145245L, 108517L, 154079L, 118999L, 184855L, 157646L,
> 187000L, 126190L, 181693L, 180395L, 170781L, 200521L, 140371L,
> 185517L, 160662L, 149601L, 164220L, 162613L, 120102L, 189868L,
> 131791L, 187465L, 205760L, 249684L, 219829L, 201173L, 230138L,
> 261196L, 258797L, 286470L, 216719L, 219241L, 221386L, 191207L,
> 212000L, 220639L, 237053L, 172805L, 199395L, 154402L, 152970L,
> 120174L, 188452L, 122797L, 88608L, 101692L, 114182L, 96193L,
> 111524L, 93344L, 87006L, 104160L, 88455L, 77399L, 69451L, 73572L,
> 54280L, 93056L, 71274L, 124714L, 65822L, 54215L, 73492L, 73178L,
> 104991L, 68259L, 88045L, 84797L, 47925L, 88662L, 88082L, 140498L,
> 116875L, 145168L, 107149L, 144324L, 119079L, 171258L, 97017L,
> 86082L, 110873L, 50194L, 114805L, 62368L, 32524L, 39318L, 30558L,
> 42822L, 45154L, 35025L, 20565L, 58236L, 35809L, 47644L, 30747L,
> NA, NA, 35449L, 48808L), RcnstPCUMS = c(229914L, 214547L, 215890L,
> 158695L, 173125L, 222533L, 212490L, 222125L, 266913L, 94268L,
> 112967L, 95480L, 87654L, 108996L, 97973L, 139247L, 93817L, 133197L,
> 40020L, 169749L, 102590L, 112121L, 140241L, 122989L, 144592L,
> 144979L, 123748L, 123249L, 70081L, 155218L, 168096L, 104743L,
> 163384L, 142648L, 129188L, 183170L, 99299L, 99873L, 111648L,
> 55890L, 59183L, 95568L, 72550L, 104562L, 100478L, 92665L, 130625L,
> 54786L, 105900L, 135833L, 70932L, 73247L, 149632L, 94317L, 87926L,
> 181989L, 92778L, 107097L, 153246L, 105175L, 126393L, 81976L,
> 95518L, 109019L, 95370L, 140492L, 125795L, 157978L, 138424L,
> 138160L, 180320L, 78757L, 135860L, 85921L, 114847L, 151965L,
> 152561L, 132841L, 204839L, 209567L, 224436L, 210209L, 227143L,
> 245968L, 264969L, 158648L, 222251L, 194335L, 111618L, 189643L,
> 137438L, 124953L, 163155L, 107633L, 164525L, 135102L, 152072L,
> 126636L, 121008L, 137824L, 149673L, 106832L, 134953L, 162195L,
> 135259L, 151180L, 188069L, 121234L, 199609L, 206011L, 186772L,
> 185596L, 189869L, 189930L, 209268L, 191993L, 238722L, 281076L,
> 236211L, 227651L, 277805L, 248063L, 258661L, 261644L, 248401L,
> 292764L, 313626L, 353877L, 318685L, 385547L, 346224L, 347058L,
> 353098L, 290663L, 398291L, 305578L, 314469L, 325343L, 281866L,
> 355524L, 323626L, 393901L, 360773L, 362326L, 415317L, 464535L,
> 511488L, 540671L, 491824L, 426657L, 500855L, 494717L, 495668L,
> 455605L, 484598L, 437629L, 476437L, 383114L, 357059L, 449471L,
> 409024L, 479044L, 360007L, 360455L, 333982L, 342971L, 273450L,
> 337258L, 308626L, 302838L, 265044L, 221514L, 341869L, 371003L,
> 450406L, 414775L, 469590L, 360334L, 451528L, 337465L, 283627L,
> 278748L, 242639L, 202808L, 237041L, 174856L, 206948L, 219398L,
> 247023L, 253697L, 351625L, 179661L, 255214L, 205368L, 258669L,
> 270376L, 284729L, 231441L, 240220L, 197141L, 110459L, 124586L,
> 115785L, 208191L, 139493L, 195068L, 184665L, 99351L, 123562L,
> 186571L, 117504L, 128846L, 217616L, 128850L, 158105L, 112762L,
> 118091L, 91510L, 41670L, 65418L, 57038L, 74113L, 63359L, 48717L,
> 59326L, 79181L, 133076L, 93478L, 121455L, 100396L, 113939L, 224357L,
> 209899L, 237803L, 196839L, 254633L, 278283L, 302996L, 315330L,
> 272767L, 277027L, 357066L, 398089L, 400740L, 275789L, 429226L,
> 326028L, 332848L, 388062L, 434889L, 397012L, 332171L, 338845L,
> 209076L, 270632L, 261217L, 191663L, 222970L, 237384L, 276674L,
> 138649L, 203588L, 178863L, 135641L, 217348L, 239162L, 168607L,
> 196393L, 173731L, 256877L, 250192L, 303120L, 256045L, 278352L,
> 266185L, 350521L, 282258L, 281162L, 226240L, 312103L, 312547L,
> 369650L, 420464L, 214503L, 305474L, 232981L, 382171L, 291030L,
> 370213L, 368859L, 395471L, 331912L, 389084L, 433543L, 446459L,
> 434882L, 427397L, 482135L, 424532L, 402021L, 413143L, 460258L,
> 399300L, 513805L, 383895L, 485673L, 426859L, 515510L, 532852L,
> 640559L, 591249L, 612067L, 577562L, 546291L, 524853L, 515396L,
> 485261L, 442432L, 520541L, 485585L, 505058L, 424639L, 527199L,
> 468619L, 427842L, 457937L, 414473L, 368965L, 165326L, 228879L,
> 261042L, 184066L, 199600L, 213524L, 140264L, 175064L, 152734L,
> 252011L, 139741L, 124736L, 106170L, 165564L, 127610L, 237950L,
> 122876L, 151239L, 191794L, 173043L, 187453L, 171653L, 171397L,
> 275756L, 308794L, 264032L, 285570L, 322867L, 281804L, 311683L,
> 271705L, 310707L, 286221L, 302599L, 270895L, 258684L, 277845L,
> 191935L, 236936L, 180781L, 101623L, 112534L, 81747L, 98125L,
> 102205L, 111226L, 110349L, 89677L, 69492L, 97820L, 69730L, 15018L,
> 40889L, 97624L, 166204L), TotalToll = c(420742L, 392621L, 395078L,
> 290411L, 316818L, 407235L, 388856L, 406488L, 482774L, 172510L,
> 206729L, 174728L, 160406L, 199462L, 179290L, 254822L, 171685L,
> 243750L, 73236L, 310640L, 187739L, 205181L, 249438L, 225069L,
> 264603L, 265311L, 226458L, 225545L, 128248L, 284048L, 296023L,
> 184934L, 298992L, 261045L, 236414L, 335201L, 181717L, 182767L,
> 204315L, 102278L, 108304L, 174889L, 132766L, 191348L, 183874L,
> 169576L, 239043L, 100258L, 212859L, 273024L, 142573L, 147226L,
> 300760L, 189577L, 176731L, 365797L, 186483L, 215264L, 308024L,
> 211401L, 254049L, 164771L, 191991L, 219128L, 191693L, 282388L,
> 252847L, 317535L, 278232L, 277701L, 356022L, 158301L, 273078L,
> 172701L, 230842L, 305449L, 306647L, 267010L, 406202L, 421229L,
> 451116L, 422520L, 456557L, 494395L, 582202L, 350612L, 491174L,
> 429480L, 239858L, 419111L, 303737L, 276146L, 360572L, 237868L,
> 358627L, 298575L, 336079L, 279865L, 267427L, 304591L, 323566L,
> 236098L, 298246L, 358450L, 298922L, 334107L, 415632L, 267927L,
> 441136L, 455284L, 412766L, 410167L, 419610L, 419745L, 462482L,
> 424305L, 527576L, 621178L, 522026L, 503109L, 613949L, 548219L,
> 571641L, 578233L, 548966L, 647008L, 693113L, 782068L, 704294L,
> 845344L, 765155L, 766998L, 774306L, 642365L, 880223L, 730331L,
> 751581L, 770694L, 660018L, 849702L, 773466L, 941423L, 862247L,
> 865959L, 992608L, 1103240L, 1222456L, 1389524L, 1263988L, 1096508L,
> 1278566L, 1271423L, 1273867L, 1158103L, 1239499L, 1124707L, 1218525L,
> 984603L, 909630L, 1155140L, 1043122L, 1231143L, 925218L, 926369L,
> 850265L, 881435L, 702766L, 866753L, 793169L, 778294L, 681163L,
> 569291L, 871709L, 953478L, 1150022L, 1065972L, 1206846L, 926058L,
> 1129778L, 867285L, 728921L, 716382L, 623582L, 521217L, 609195L,
> 449380L, 531856L, 563853L, 634849L, 643607L, 888831L, 461729L,
> 655900L, 527796L, 664779L, 687175L, 731754L, 586409L, 617365L,
> 506652L, 276310L, 320186L, 289618L, 535051L, 389544L, 544553L,
> 515428L, 277302L, 336755L, 512700L, 318225L, 359684L, 607673L,
> 379065L, 465104L, 331810L, 347203L, 268918L, 122643L, 192034L,
> 159071L, 217928L, 186080L, 134668L, 173724L, 232564L, 390599L,
> 265947L, 348773L, 294627L, 334562L, 649731L, 607805L, 698507L,
> 578572L, 1059450L, 1187844L, 1246619L, 1296120L, 1140384L, 1187214L,
> 1432452L, 1606332L, 1728174L, 1203594L, 1822716L, 1389276L, 1728426L,
> 1926935L, 2125297L, 1943820L, 1623321L, 1590148L, 1049286L, 1398754L,
> 1320550L, 994945L, 1164583L, 1205841L, 1559682L, 769662L, 1091567L,
> 1000642L, 718794L, 1175818L, 1254971L, 900558L, 1033592L, 927072L,
> 1245348L, 1240380L, 1820813L, 1567994L, 1789477L, 1700773L, 2204080L,
> 1745881L, 1842826L, 1476216L, 1967969L, 1939304L, 2335284L, 2676920L,
> 1580544L, 2277360L, 1694016L, 2721614L, 2107008L, 2630707L, 2530555L,
> 2872656L, 2395440L, 2704234L, 3035837L, 3147379L, 3076661L, 2903544L,
> 3398155L, 2964859L, 2837506L, 2883096L, 3264696L, 2779186L, 3980670L,
> 2923166L, 3739659L, 3317358L, 3978904L, 4112544L, 4828331L, 4423260L,
> 4650546L, 4321198L, 4147356L, 3959882L, 3891892L, 3623148L, 3365086L,
> 3917517L, 3708696L, 3876444L, 3234706L, 3968716L, 3558025L, 3313506L,
> 3522721L, 3104372L, 2772710L, 1329618L, 1857286L, 2126974L, 1509160L,
> 1616068L, 1679704L, 1164638L, 1390846L, 1199265L, 1868727L, 1091024L,
> 1023810L, 837614L, 1367468L, 1056694L, 1886631L, 951129L, 1153342L,
> 1491752L, 1305802L, 1461332L, 1286770L, 1310026L, 1997167L, 2234964L,
> 1924902L, 2080596L, 2331026L, 2046594L, 2302530L, 1958478L, 2262478L,
> 2115387L, 2220923L, 1959669L, 1849238L, 2089172L, 1381704L, 1553856L,
> 1251361L, 704230L, 776554L, 592426L, 704066L, 772042L, 754649L,
> 797425L, 624502L, 517122L, 683626L, 507750L, 99592L, 217680L,
> 671070L, 1150758L)), class = "data.frame", row.names = c(NA,
> 383L))
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From jte||er|@@rproject @end|ng |rom gm@||@com  Mon Sep  3 17:17:54 2018
From: jte||er|@@rproject @end|ng |rom gm@||@com (Juan Telleria Ruiz de Aguirre)
Date: Mon, 3 Sep 2018 17:17:54 +0200
Subject: [R] ANOVA Permutation Test
Message-ID: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>

Dear R users,

I have the following Question related to Package lmPerm:

This package uses a modified version of aov() function, which uses
Permutation Tests instead of Normal Theory Tests for fitting an Analysis of
Variance (ANOVA) Model.

However, when I run the following code for a simple linear model:

library(lmPerm)

e$t_Downtime_per_Intervention_Successful %>%
  aovp(
    formula = `Downtime per Intervention[h]` ~ `Working Hours`,
    data = .
  ) %>%
  summary()

I obtain different p-values for each run!

With a regular ANOVA Test, I obtain instead a constant F-statistic, but I
do not fulfill the required Normality Assumptions.

So my questions are:

Would it still be possible use the regular aov() by generating permutations
in advance (Obtaining therefore a Normal Distribution thanks to the Central
Limit Theorem)? And applying the aov() function afterwards? Does it have
sense?


Or maybe this issue could be due to unbalanced classes? I also tried to
weight observations based on proportions, but the function failed.


Any alternative solution for performing a One-Way ANOVA Test over
Non-Normal Data?


Thank you.

Juan

	[[alternative HTML version deleted]]



From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Sep  3 17:58:46 2018
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 3 Sep 2018 16:58:46 +0100
Subject: [R] ANOVA Permutation Test
In-Reply-To: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
References: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
Message-ID: <6d0b7771-a0fa-6b21-e248-0e28d59356a5@dewey.myzen.co.uk>

Dear Juan

I do not use the package but if it does permutation tests it presumably 
uses random numbers and since you are not setting the seed you would get 
different values for each run.

Michael

On 03/09/2018 16:17, Juan Telleria Ruiz de Aguirre wrote:
> Dear R users,
> 
> I have the following Question related to Package lmPerm:
> 
> This package uses a modified version of aov() function, which uses
> Permutation Tests instead of Normal Theory Tests for fitting an Analysis of
> Variance (ANOVA) Model.
> 
> However, when I run the following code for a simple linear model:
> 
> library(lmPerm)
> 
> e$t_Downtime_per_Intervention_Successful %>%
>    aovp(
>      formula = `Downtime per Intervention[h]` ~ `Working Hours`,
>      data = .
>    ) %>%
>    summary()
> 
> I obtain different p-values for each run!
> 
> With a regular ANOVA Test, I obtain instead a constant F-statistic, but I
> do not fulfill the required Normality Assumptions.
> 
> So my questions are:
> 
> Would it still be possible use the regular aov() by generating permutations
> in advance (Obtaining therefore a Normal Distribution thanks to the Central
> Limit Theorem)? And applying the aov() function afterwards? Does it have
> sense?
> 
> 
> Or maybe this issue could be due to unbalanced classes? I also tried to
> weight observations based on proportions, but the function failed.
> 
> 
> Any alternative solution for performing a One-Way ANOVA Test over
> Non-Normal Data?
> 
> 
> Thank you.
> 
> Juan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html



From meyner@@m @end|ng |rom pg@com  Mon Sep  3 18:06:51 2018
From: meyner@@m @end|ng |rom pg@com (Meyners, Michael)
Date: Mon, 3 Sep 2018 16:06:51 +0000
Subject: [R] ANOVA Permutation Test
In-Reply-To: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
References: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
Message-ID: <BL0PR01MB4132BBC31D231756636D7B539A0C0@BL0PR01MB4132.prod.exchangelabs.com>

Juan, 

Your question might be borderline for this list, as it ultimately rather seems a stats question coming in R disguise.

Anyway, the short answer is that you *expect* to get a different p value from a permutation test unless you are able to do all possible permutation and therefore use the so-called systematic reference set. That is rarely the case, and only for relatively small problems. 
The permutation test uses a random subset of all possible permutations. Given this randomness, you'll get a different p value. In order to get reproducible results, you may specify a seed (?set.seed), yet that is only reproducible with this environment. Someone else with a different software and/or code might come out with a different p. The higher the number of permutations used, the smaller the variation around the p values, however. For most applications, 1000 seem good enough to me, but sometimes I go higher (in particular if the p value is borderline and I really need a strict above/below alpha decision).

The permutations do not create an implicit normal distribution, but rather a null distribution that can (likely is depending on non-normality of your data) not normal. So your respective proposal does not appeal.

I don't think you need an alternative - the permutation test is just fine, and recognizing the randomness in the execution does not render the (relatively small) variability in p values a major issue.

You may want to have a look at the text book by Edgington & Onghena for details on permutation tests, and there are plenty of papers out there addressing them in various contexts, which will help to understand *why* you observe what you observe here. 

HTH, Michael



> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Juan Telleria Ruiz
> de Aguirre
> Sent: Montag, 3. September 2018 17:18
> To: R help Mailing list <r-help at r-project.org>
> Subject: [R] ANOVA Permutation Test
> 
> Dear R users,
> 
> I have the following Question related to Package lmPerm:
> 
> This package uses a modified version of aov() function, which uses
> Permutation Tests instead of Normal Theory Tests for fitting an Analysis of
> Variance (ANOVA) Model.
> 
> However, when I run the following code for a simple linear model:
> 
> library(lmPerm)
> 
> e$t_Downtime_per_Intervention_Successful %>%
>   aovp(
>     formula = `Downtime per Intervention[h]` ~ `Working Hours`,
>     data = .
>   ) %>%
>   summary()
> 
> I obtain different p-values for each run!
> 
> With a regular ANOVA Test, I obtain instead a constant F-statistic, but I do not
> fulfill the required Normality Assumptions.
> 
> So my questions are:
> 
> Would it still be possible use the regular aov() by generating permutations in
> advance (Obtaining therefore a Normal Distribution thanks to the Central
> Limit Theorem)? And applying the aov() function afterwards? Does it have
> sense?
> 
> 
> Or maybe this issue could be due to unbalanced classes? I also tried to weight
> observations based on proportions, but the function failed.
> 
> 
> Any alternative solution for performing a One-Way ANOVA Test over Non-
> Normal Data?
> 
> 
> Thank you.
> 
> Juan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From S@E|||@on @end|ng |rom LGCGroup@com  Mon Sep  3 18:20:14 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Mon, 3 Sep 2018 16:20:14 +0000
Subject: [R] ANOVA Permutation Test
In-Reply-To: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
References: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
Message-ID: <9e13f11c85144361984a29db539e83b8@GBDCVPEXC04.corp.lgc-group.com>

> This package uses a modified version of aov() function, which uses
> Permutation Tests 
> 
> I obtain different p-values for each run!

Could that be because you are defaulting to perm="Prob"?

I am not familiar with the package, but the manual is informative.
You may have missed something when reading it.

" ...The Exact method will be used by default when the number of observations is less than or equal to
maxExact, otherwise Prob will be used.
Prob:  Iterations terminate when the estimated standard error of the estimated proportion p is less
than p*Ca"

I would assume that probabilistic permutation is random and will change from run to run.
You could use set.seed() to stop that, but it's actually quite useful to see how much the results change.
If you want complete permutation, you'd need to force Exact (unless that does not mean what it sounds like for this package).
It looks like that requires you to set maxExact to at least your number of observations. But given that permutation  grows combinatorially,  that could take a _long_ time for a run; the Example in the help page does not complete in a useful time when maxExact is set to exceed the number of data points.

So I'd probably run it using Prob and simply note the range of results for a handful of runs to give you an indication of how far to trust the answers.

> Would it still be possible use the regular aov() by generating permutations
> in advance (Obtaining therefore a Normal Distribution thanks to the Central
> Limit Theorem)? And applying the aov() function afterwards? Does it have
> sense?
As a chemist, I'd guess No. And you'd be even more limited in number of permutations.

> Or maybe this issue could be due to unbalanced classes? I also tried to
> weight observations based on proportions, but the function failed.
No, it's nothing to do with balance, if the results change run to run with no change in the model. I'd guess that may exacerbate the permutaiton variability somewhat but it won't _cause_ it.

> Any alternative solution for performing a One-Way ANOVA Test over
> Non-Normal Data?
Yes; the traditional nonparametric test for one-way data (balanced) is the kruskal-wallis test - see ?kruskal.test.
Classical ANOVA on ranks can also be defended as a general 'nonparametric' approach, though I gather it can also be criticised. 



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep  3 19:45:07 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 3 Sep 2018 10:45:07 -0700 (PDT)
Subject: [R] Display time of PDF plots
Message-ID: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>

   This may be an inappropriate forum for this question. If so, please point
me in a better direction.

   A current project includes scatter plots with thousands of points. Saved
as PDF files they display slowly using a pdf viewer or when included in the
PDF output of a LaTeX document.

   Is there a process by which these plots can be 'thinned' so they show the
same overall patterns but with fewer points so they display more quickly?

   Rasterizing them to .jpg files using 'convert' allows them to load
immediately, but the bit-mapped resolution is, of course, much lower than
the vector PDF format.

Rich



From jte||er|@@rproject @end|ng |rom gm@||@com  Mon Sep  3 19:47:07 2018
From: jte||er|@@rproject @end|ng |rom gm@||@com (Juan Telleria Ruiz de Aguirre)
Date: Mon, 3 Sep 2018 19:47:07 +0200
Subject: [R] ANOVA Permutation Test
In-Reply-To: <9e13f11c85144361984a29db539e83b8@GBDCVPEXC04.corp.lgc-group.com>
References: <CAJXDcw2ahNN3wPbYwOwoDbs4qKAXa8XVbY6hVqgHVeXoV-CTig@mail.gmail.com>
 <9e13f11c85144361984a29db539e83b8@GBDCVPEXC04.corp.lgc-group.com>
Message-ID: <CAJXDcw3ZzMnCP1V4dt6qzz+8tYk9-Bz=hmWWmuhV8G9FEF7zAg@mail.gmail.com>

Thank you all for your **very good** answers:

Using aovp(..., perm="Exact") seems to be the way to go for small datasets,
and also I should definitely try ?kruskal.test.


Juan

	[[alternative HTML version deleted]]



From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Sep  3 20:18:21 2018
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 3 Sep 2018 13:18:21 -0500
Subject: [R] Error when using complete function for imputed data
In-Reply-To: <ed740a07a1ea446d9f503563895d5fa9@SRVEXCHCM1302.precheza.cz>
References: <CAMOcQfN82EGX1SPQY7iet2LsMT25iKXJBFLMvLg80k3cC6t0ug@mail.gmail.com>
 <ed740a07a1ea446d9f503563895d5fa9@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMOcQfNsFCduSQwwRDk+yzgr_f+8zt9ZdjEvhRdU5Z9hhBG+Tw@mail.gmail.com>

Thank you for the feedback Petr, I was able to run the code without any
problems.

Best regads,

Paul

El lun., 3 sept. 2018 a las 9:57, PIKAL Petr (<petr.pikal at precheza.cz>)
escribi?:

> Hi
>
> AFAIK it was probably answered several days ago that mice conflicts with
> some other loaded package.
>
> I did not get any error.
>
> After importing your data
> str(dataFrame)
> 'data.frame':   383 obs. of  5 variables:
>  $ TransitDate: POSIXct, format: "1985-10-01 06:00:00" "1985-11-01
> 06:00:00" ...
>  $ Transits   : int  14 14 13 10 11 14 14 14 16 6 ...
>  $ CargoTons  : int  154973 129636 136884 86348 109907 154506 144083
> 152794 124861 60330 ...
>  $ RcnstPCUMS : int  229914 214547 215890 158695 173125 222533 212490
> 222125 266913 94268 ...
>  $ TotalToll  : int  420742 392621 395078 290411 316818 407235 388856
> 406488
>
> > colSums(apply(dataFrame,2, is.na))
> TransitDate    Transits   CargoTons  RcnstPCUMS   TotalToll
>           0           0           2           0           0
> > library(mice)
> > Imputed_Data <- mice(dataFrame[2:5])
> > CompleteData <- complete(Imputed_Data)
> > colSums(apply(CompleteData,2, is.na))
>   Transits  CargoTons RcnstPCUMS  TotalToll
>          0          0          0          0
> >
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
> > Sent: Monday, September 3, 2018 4:30 PM
> > To: r-help at r-project.org
> > Subject: [R] Error when using complete function for imputed data
> >
> > Dear friends,
> >
> > It seems to me that there is something wrong with the complete function.
> I
> > am using R version 3.5.0 and mice package for data imputation.
> >
> > I am working on a Windows 8.1 Enterprise machine with 64-bit Operating
> > System.
> >
> > So here is my code:
> >
> > Imputed_Data <- mice(dataFrame[2:5])
> > CompleteData <- complete(Imputed_Data)
> > Error in UseMethod("complete_") :
> >   no applicable method for 'complete_' applied to an object of class
> "mids"
> >
> > I used the complete function before when imputing data with the mice
> > function, but now it is not working.
> >
> > Any help will be greatly appreciated. Below is the dput() of my dataset:
> >
> > > dput(dataFrame)
> > structure(list(TransitDate = structure(c(496990800, 499669200,
> > 502261200, 504939600, 507618000, 510037200, 512715600, 515307600,
> > 517986000, 520578000, 523256400, 525934800, 528526800, 531205200,
> > 533797200, 536475600, 539154000, 541573200, 544251600, 546843600,
> > 549522000, 552114000, 554792400, 557470800, 560062800, 562741200,
> > 565333200, 568011600, 570690000, 573195600, 575874000, 578466000,
> > 581144400, 583736400, 586414800, 589093200, 591685200, 594363600,
> > 596955600, 599634000, 602312400, 604731600, 607410000, 610002000,
> > 612680400, 615272400, 617950800, 620629200, 623221200, 625899600,
> > 628491600, 631170000, 633848400, 636267600, 638946000, 641538000,
> > 644216400, 646808400, 649486800, 652165200, 654757200, 657435600,
> > 660027600, 662706000, 665384400, 667803600, 670482000, 673074000,
> > 675752400, 678344400, 681022800, 683701200, 686293200, 688971600,
> > 691563600, 694242000, 696920400, 699426000, 702104400, 704696400,
> > 707371200, 709963200, 712641600, 715320000, 717912000, 720590400,
> > 723182400, 725860800, 728539200, 730958400, 733636800, 736232400,
> > 738910800, 741502800, 744181200, 746859600, 749451600, 752130000,
> > 754722000, 757400400, 760078800, 762498000, 765176400, 767768400,
> > 770446800, 773038800, 775717200, 778395600, 780987600, 783666000,
> > 786258000, 788936400, 791614800, 794034000, 796712400, 799304400,
> > 801982800, 804574800, 807253200, 809931600, 812523600, 815202000,
> > 817794000, 820472400, 823150800, 825656400, 828334800, 830926800,
> > 833605200, 836197200, 838875600, 841554000, 844146000, 846824400,
> > 849416400, 852094800, 854773200, 857192400, 859870800, 862462800,
> > 865141200, 867733200, 870411600, 873090000, 875682000, 878360400,
> > 880952400, 883630800, 886309200, 888728400, 891406800, 893998800,
> > 896677200, 899269200, 901947600, 904626000, 907218000, 909896400,
> > 912488400, 915166800, 917845200, 920264400, 922942800, 925534800,
> > 928213200, 930805200, 933483600, 936162000, 938754000, 941432400,
> > 944024400, 946702800, 949381200, 951886800, 954565200, 957157200,
> > 959835600, 962427600, 965106000, 967784400, 970376400, 973054800,
> > 975646800, 978325200, 981003600, 983422800, 986101200, 988693200,
> > 991371600, 993963600, 996642000, 999320400, 1001912400, 1004590800,
> > 1007182800, 1009861200, 1012539600, 1014958800, 1017637200,
> > 1020229200,
> > 1022907600, 1025499600, 1028178000, 1030856400, 1033448400,
> > 1036126800,
> > 1038718800, 1041397200, 1044075600, 1046494800, 1049173200,
> > 1051765200,
> > 1054443600, 1057035600, 1059714000, 1062392400, 1064984400,
> > 1067662800,
> > 1070254800, 1072933200, 1075611600, 1078117200, 1080795600,
> > 1083387600,
> > 1086066000, 1088658000, 1091336400, 1094014800, 1096606800,
> > 1099285200,
> > 1101877200, 1104555600, 1107234000, 1109653200, 1112331600,
> > 1114923600,
> > 1117602000, 1120194000, 1122872400, 1125550800, 1128142800,
> > 1130821200,
> > 1133413200, 1136091600, 1138770000, 1141189200, 1143867600,
> > 1146459600,
> > 1149138000, 1151730000, 1154408400, 1157086800, 1159678800,
> > 1162357200,
> > 1164949200, 1167627600, 1170306000, 1172725200, 1175403600,
> > 1177995600,
> > 1180674000, 1183266000, 1185944400, 1188622800, 1191214800,
> > 1193893200,
> > 1196485200, 1199163600, 1201842000, 1204347600, 1207026000,
> > 1209618000,
> > 1212296400, 1214888400, 1217566800, 1220245200, 1222837200,
> > 1225515600,
> > 1228107600, 1230786000, 1233464400, 1235883600, 1238562000,
> > 1241154000,
> > 1243832400, 1246424400, 1249102800, 1251781200, 1254373200,
> > 1257051600,
> > 1259643600, 1262322000, 1265000400, 1267419600, 1270098000,
> > 1272690000,
> > 1275368400, 1277960400, 1280638800, 1283317200, 1285909200,
> > 1288587600,
> > 1291179600, 1293858000, 1296536400, 1298955600, 1301634000,
> > 1304226000,
> > 1306904400, 1309496400, 1312174800, 1314853200, 1317445200,
> > 1320123600,
> > 1322715600, 1325394000, 1328072400, 1330578000, 1333256400,
> > 1335848400,
> > 1338526800, 1341118800, 1343797200, 1346475600, 1349067600,
> > 1351746000,
> > 1354338000, 1357016400, 1359694800, 1362114000, 1364792400,
> > 1367384400,
> > 1370062800, 1372654800, 1375333200, 1378011600, 1380603600,
> > 1383282000,
> > 1385874000, 1388552400, 1391230800, 1393650000, 1396328400,
> > 1398920400,
> > 1401598800, 1404190800, 1406869200, 1409547600, 1412139600,
> > 1414818000,
> > 1417410000, 1420088400, 1422766800, 1425186000, 1427864400,
> > 1430456400,
> > 1433134800, 1435726800, 1438405200, 1441083600, 1443675600,
> > 1446354000,
> > 1448946000, 1451624400, 1454302800, 1456808400, 1459486800,
> > 1462078800,
> > 1464757200, 1467349200, 1470027600, 1472706000, 1475298000,
> > 1477976400,
> > 1480568400, 1483246800, 1485925200, 1488344400, 1491022800,
> > 1493614800,
> > 1496293200, 1501563600, 1504242000), class = c("POSIXct", "POSIXt"
> > ), tzone = ""), Transits = c(14L, 14L, 13L, 10L, 11L, 14L, 14L,
> > 14L, 16L, 6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L, 8L,
> > 10L, 9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L,
> > 7L, 7L, 8L, 4L, 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L, 5L,
> > 10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L, 5L, 6L, 7L, 6L, 9L, 8L,
> > 10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L, 14L, 15L,
> > 14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L, 9L, 12L, 8L,
> > 12L, 10L, 11L, 10L, 9L, 10L, 11L, 8L, 10L, 12L, 10L, 11L, 14L,
> > 9L, 15L, 15L, 14L, 14L, 14L, 15L, 16L, 15L, 18L, 21L, 18L, 17L,
> > 21L, 18L, 19L, 19L, 18L, 21L, 22L, 25L, 23L, 28L, 25L, 25L, 25L,
> > 21L, 28L, 21L, 22L, 23L, 20L, 24L, 22L, 26L, 24L, 24L, 28L, 31L,
> > 34L, 36L, 33L, 29L, 34L, 33L, 33L, 31L, 33L, 29L, 32L, 26L, 24L,
> > 30L, 27L, 31L, 23L, 23L, 21L, 21L, 18L, 21L, 19L, 19L, 16L, 14L,
> > 22L, 24L, 28L, 26L, 29L, 23L, 28L, 21L, 17L, 17L, 14L, 12L, 14L,
> > 10L, 12L, 13L, 14L, 15L, 21L, 10L, 15L, 12L, 15L, 16L, 17L, 14L,
> > 14L, 12L, 7L, 8L, 8L, 11L, 9L, 12L, 11L, 6L, 8L, 11L, 7L, 8L,
> > 14L, 9L, 11L, 8L, 8L, 6L, 3L, 4L, 4L, 5L, 4L, 3L, 3L, 5L, 8L,
> > 6L, 8L, 6L, 7L, 14L, 14L, 15L, 13L, 16L, 18L, 20L, 21L, 18L,
> > 19L, 24L, 27L, 26L, 18L, 28L, 21L, 22L, 25L, 29L, 26L, 22L, 22L,
> > 14L, 18L, 18L, 13L, 15L, 16L, 19L, 9L, 14L, 11L, 9L, 14L, 16L,
> > 11L, 13L, 11L, 16L, 16L, 20L, 17L, 19L, 18L, 24L, 19L, 19L, 15L,
> > 21L, 21L, 24L, 28L, 14L, 20L, 15L, 24L, 18L, 24L, 24L, 25L, 21L,
> > 24L, 27L, 28L, 27L, 26L, 29L, 25L, 24L, 25L, 28L, 23L, 30L, 23L,
> > 29L, 26L, 31L, 33L, 40L, 36L, 39L, 36L, 34L, 32L, 32L, 30L, 27L,
> > 32L, 30L, 31L, 26L, 31L, 29L, 26L, 28L, 24L, 22L, 11L, 15L, 17L,
> > 12L, 13L, 14L, 9L, 12L, 11L, 17L, 9L, 8L, 7L, 11L, 8L, 15L, 8L,
> > 10L, 13L, 12L, 13L, 12L, 12L, 19L, 21L, 18L, 20L, 21L, 20L, 22L,
> > 19L, 21L, 20L, 21L, 18L, 18L, 19L, 13L, 16L, 12L, 6L, 7L, 5L,
> > 6L, 6L, 7L, 7L, 5L, 4L, 6L, 4L, 1L, 2L, 7L, 12L), CargoTons = c(154973L,
> > 129636L, 136884L, 86348L, 109907L, 154506L, 144083L, 152794L,
> > 124861L, 60330L, 65221L, 61718L, 53997L, 83536L, 63218L, 98222L,
> > 54719L, 98470L, 18263L, 104255L, 62869L, 62523L, 75344L, 81476L,
> > 92818L, 87457L, 85231L, 77897L, 57699L, 96989L, 109361L, 59799L,
> > 91116L, 82241L, 74251L, 124361L, 68751L, 61719L, 68017L, 37760L,
> > 32513L, 56359L, 51333L, 80859L, 75852L, 65760L, 96043L, 38820L,
> > 63202L, 102647L, 49104L, 53482L, 121305L, 71795L, 76704L, 146097L,
> > 73047L, 68557L, 110642L, 77616L, 97767L, 52059L, 58658L, 66350L,
> > 69303L, 76013L, 91909L, 108445L, 94454L, 101249L, 112131L, 56290L,
> > 118342L, 70618L, 64783L, 112839L, 120506L, 94243L, 130768L, 133643L,
> > 146321L, 140736L, 147234L, 158953L, 189888L, 93819L, 130021L,
> > 130124L, 55088L, 114783L, 95184L, 82205L, 80321L, 65422L, 98933L,
> > 93713L, 98417L, 97210L, 88464L, 94659L, 92873L, 79784L, 96655L,
> > 122266L, 100779L, 120569L, 133029L, 92889L, 160886L, 132364L,
> > 130435L, 139653L, 152143L, 160824L, 165842L, 175679L, 210872L,
> > 211941L, 207820L, 179857L, 212733L, 203135L, 218368L, 198343L,
> > 195677L, 210066L, 243311L, 261965L, 240683L, 245242L, 218004L,
> > 247640L, 209872L, 223668L, 290521L, 185161L, 210341L, 261739L,
> > 205431L, 284114L, 251466L, 302961L, 292981L, 279329L, 309197L,
> > 341092L, 385209L, 366958L, 330515L, 286950L, 295590L, 350901L,
> > 341678L, 284666L, 283148L, 279108L, 284896L, 238802L, 198786L,
> > 273465L, 256694L, 360520L, 320201L, 296881L, 264202L, 280142L,
> > 219105L, 278606L, 254420L, 260339L, 216457L, 198077L, 249436L,
> > 302860L, 360184L, 317105L, 391413L, 265210L, 354714L, 306031L,
> > 266124L, 215799L, 232630L, 156590L, 203111L, 157075L, 160140L,
> > 177874L, 219162L, 159610L, 286483L, 144631L, 216456L, 157305L,
> > 237780L, 191617L, 223211L, 180330L, 187074L, 126043L, 62462L,
> > 93633L, 56417L, 115036L, 74365L, 98785L, 116172L, 43421L, 73769L,
> > 128795L, 58910L, 74282L, 115312L, 102303L, 106109L, 76940L, 82683L,
> > 49149L, 22517L, 20731L, 24684L, 52558L, 40057L, 28981L, 46062L,
> > 43213L, 107755L, 53404L, 56390L, 41541L, 41183L, 80161L, 110960L,
> > 130891L, 130395L, 183351L, 242803L, 225383L, 190962L, 169432L,
> > 186260L, 206997L, 196097L, 202942L, 175063L, 240869L, 213226L,
> > 237754L, 208280L, 231596L, 207033L, 213294L, 250265L, 129334L,
> > 173986L, 145188L, 98384L, 163739L, 138180L, 136521L, 86836L,
> > 97452L, 71988L, 79293L, 124134L, 116343L, 91030L, 98457L, 77906L,
> > 130599L, 132381L, 162992L, 142756L, 150105L, 150339L, 161097L,
> > 112633L, 145691L, 100771L, 147805L, 123418L, 138375L, 185776L,
> > 108842L, 145245L, 108517L, 154079L, 118999L, 184855L, 157646L,
> > 187000L, 126190L, 181693L, 180395L, 170781L, 200521L, 140371L,
> > 185517L, 160662L, 149601L, 164220L, 162613L, 120102L, 189868L,
> > 131791L, 187465L, 205760L, 249684L, 219829L, 201173L, 230138L,
> > 261196L, 258797L, 286470L, 216719L, 219241L, 221386L, 191207L,
> > 212000L, 220639L, 237053L, 172805L, 199395L, 154402L, 152970L,
> > 120174L, 188452L, 122797L, 88608L, 101692L, 114182L, 96193L,
> > 111524L, 93344L, 87006L, 104160L, 88455L, 77399L, 69451L, 73572L,
> > 54280L, 93056L, 71274L, 124714L, 65822L, 54215L, 73492L, 73178L,
> > 104991L, 68259L, 88045L, 84797L, 47925L, 88662L, 88082L, 140498L,
> > 116875L, 145168L, 107149L, 144324L, 119079L, 171258L, 97017L,
> > 86082L, 110873L, 50194L, 114805L, 62368L, 32524L, 39318L, 30558L,
> > 42822L, 45154L, 35025L, 20565L, 58236L, 35809L, 47644L, 30747L,
> > NA, NA, 35449L, 48808L), RcnstPCUMS = c(229914L, 214547L, 215890L,
> > 158695L, 173125L, 222533L, 212490L, 222125L, 266913L, 94268L,
> > 112967L, 95480L, 87654L, 108996L, 97973L, 139247L, 93817L, 133197L,
> > 40020L, 169749L, 102590L, 112121L, 140241L, 122989L, 144592L,
> > 144979L, 123748L, 123249L, 70081L, 155218L, 168096L, 104743L,
> > 163384L, 142648L, 129188L, 183170L, 99299L, 99873L, 111648L,
> > 55890L, 59183L, 95568L, 72550L, 104562L, 100478L, 92665L, 130625L,
> > 54786L, 105900L, 135833L, 70932L, 73247L, 149632L, 94317L, 87926L,
> > 181989L, 92778L, 107097L, 153246L, 105175L, 126393L, 81976L,
> > 95518L, 109019L, 95370L, 140492L, 125795L, 157978L, 138424L,
> > 138160L, 180320L, 78757L, 135860L, 85921L, 114847L, 151965L,
> > 152561L, 132841L, 204839L, 209567L, 224436L, 210209L, 227143L,
> > 245968L, 264969L, 158648L, 222251L, 194335L, 111618L, 189643L,
> > 137438L, 124953L, 163155L, 107633L, 164525L, 135102L, 152072L,
> > 126636L, 121008L, 137824L, 149673L, 106832L, 134953L, 162195L,
> > 135259L, 151180L, 188069L, 121234L, 199609L, 206011L, 186772L,
> > 185596L, 189869L, 189930L, 209268L, 191993L, 238722L, 281076L,
> > 236211L, 227651L, 277805L, 248063L, 258661L, 261644L, 248401L,
> > 292764L, 313626L, 353877L, 318685L, 385547L, 346224L, 347058L,
> > 353098L, 290663L, 398291L, 305578L, 314469L, 325343L, 281866L,
> > 355524L, 323626L, 393901L, 360773L, 362326L, 415317L, 464535L,
> > 511488L, 540671L, 491824L, 426657L, 500855L, 494717L, 495668L,
> > 455605L, 484598L, 437629L, 476437L, 383114L, 357059L, 449471L,
> > 409024L, 479044L, 360007L, 360455L, 333982L, 342971L, 273450L,
> > 337258L, 308626L, 302838L, 265044L, 221514L, 341869L, 371003L,
> > 450406L, 414775L, 469590L, 360334L, 451528L, 337465L, 283627L,
> > 278748L, 242639L, 202808L, 237041L, 174856L, 206948L, 219398L,
> > 247023L, 253697L, 351625L, 179661L, 255214L, 205368L, 258669L,
> > 270376L, 284729L, 231441L, 240220L, 197141L, 110459L, 124586L,
> > 115785L, 208191L, 139493L, 195068L, 184665L, 99351L, 123562L,
> > 186571L, 117504L, 128846L, 217616L, 128850L, 158105L, 112762L,
> > 118091L, 91510L, 41670L, 65418L, 57038L, 74113L, 63359L, 48717L,
> > 59326L, 79181L, 133076L, 93478L, 121455L, 100396L, 113939L, 224357L,
> > 209899L, 237803L, 196839L, 254633L, 278283L, 302996L, 315330L,
> > 272767L, 277027L, 357066L, 398089L, 400740L, 275789L, 429226L,
> > 326028L, 332848L, 388062L, 434889L, 397012L, 332171L, 338845L,
> > 209076L, 270632L, 261217L, 191663L, 222970L, 237384L, 276674L,
> > 138649L, 203588L, 178863L, 135641L, 217348L, 239162L, 168607L,
> > 196393L, 173731L, 256877L, 250192L, 303120L, 256045L, 278352L,
> > 266185L, 350521L, 282258L, 281162L, 226240L, 312103L, 312547L,
> > 369650L, 420464L, 214503L, 305474L, 232981L, 382171L, 291030L,
> > 370213L, 368859L, 395471L, 331912L, 389084L, 433543L, 446459L,
> > 434882L, 427397L, 482135L, 424532L, 402021L, 413143L, 460258L,
> > 399300L, 513805L, 383895L, 485673L, 426859L, 515510L, 532852L,
> > 640559L, 591249L, 612067L, 577562L, 546291L, 524853L, 515396L,
> > 485261L, 442432L, 520541L, 485585L, 505058L, 424639L, 527199L,
> > 468619L, 427842L, 457937L, 414473L, 368965L, 165326L, 228879L,
> > 261042L, 184066L, 199600L, 213524L, 140264L, 175064L, 152734L,
> > 252011L, 139741L, 124736L, 106170L, 165564L, 127610L, 237950L,
> > 122876L, 151239L, 191794L, 173043L, 187453L, 171653L, 171397L,
> > 275756L, 308794L, 264032L, 285570L, 322867L, 281804L, 311683L,
> > 271705L, 310707L, 286221L, 302599L, 270895L, 258684L, 277845L,
> > 191935L, 236936L, 180781L, 101623L, 112534L, 81747L, 98125L,
> > 102205L, 111226L, 110349L, 89677L, 69492L, 97820L, 69730L, 15018L,
> > 40889L, 97624L, 166204L), TotalToll = c(420742L, 392621L, 395078L,
> > 290411L, 316818L, 407235L, 388856L, 406488L, 482774L, 172510L,
> > 206729L, 174728L, 160406L, 199462L, 179290L, 254822L, 171685L,
> > 243750L, 73236L, 310640L, 187739L, 205181L, 249438L, 225069L,
> > 264603L, 265311L, 226458L, 225545L, 128248L, 284048L, 296023L,
> > 184934L, 298992L, 261045L, 236414L, 335201L, 181717L, 182767L,
> > 204315L, 102278L, 108304L, 174889L, 132766L, 191348L, 183874L,
> > 169576L, 239043L, 100258L, 212859L, 273024L, 142573L, 147226L,
> > 300760L, 189577L, 176731L, 365797L, 186483L, 215264L, 308024L,
> > 211401L, 254049L, 164771L, 191991L, 219128L, 191693L, 282388L,
> > 252847L, 317535L, 278232L, 277701L, 356022L, 158301L, 273078L,
> > 172701L, 230842L, 305449L, 306647L, 267010L, 406202L, 421229L,
> > 451116L, 422520L, 456557L, 494395L, 582202L, 350612L, 491174L,
> > 429480L, 239858L, 419111L, 303737L, 276146L, 360572L, 237868L,
> > 358627L, 298575L, 336079L, 279865L, 267427L, 304591L, 323566L,
> > 236098L, 298246L, 358450L, 298922L, 334107L, 415632L, 267927L,
> > 441136L, 455284L, 412766L, 410167L, 419610L, 419745L, 462482L,
> > 424305L, 527576L, 621178L, 522026L, 503109L, 613949L, 548219L,
> > 571641L, 578233L, 548966L, 647008L, 693113L, 782068L, 704294L,
> > 845344L, 765155L, 766998L, 774306L, 642365L, 880223L, 730331L,
> > 751581L, 770694L, 660018L, 849702L, 773466L, 941423L, 862247L,
> > 865959L, 992608L, 1103240L, 1222456L, 1389524L, 1263988L, 1096508L,
> > 1278566L, 1271423L, 1273867L, 1158103L, 1239499L, 1124707L, 1218525L,
> > 984603L, 909630L, 1155140L, 1043122L, 1231143L, 925218L, 926369L,
> > 850265L, 881435L, 702766L, 866753L, 793169L, 778294L, 681163L,
> > 569291L, 871709L, 953478L, 1150022L, 1065972L, 1206846L, 926058L,
> > 1129778L, 867285L, 728921L, 716382L, 623582L, 521217L, 609195L,
> > 449380L, 531856L, 563853L, 634849L, 643607L, 888831L, 461729L,
> > 655900L, 527796L, 664779L, 687175L, 731754L, 586409L, 617365L,
> > 506652L, 276310L, 320186L, 289618L, 535051L, 389544L, 544553L,
> > 515428L, 277302L, 336755L, 512700L, 318225L, 359684L, 607673L,
> > 379065L, 465104L, 331810L, 347203L, 268918L, 122643L, 192034L,
> > 159071L, 217928L, 186080L, 134668L, 173724L, 232564L, 390599L,
> > 265947L, 348773L, 294627L, 334562L, 649731L, 607805L, 698507L,
> > 578572L, 1059450L, 1187844L, 1246619L, 1296120L, 1140384L, 1187214L,
> > 1432452L, 1606332L, 1728174L, 1203594L, 1822716L, 1389276L, 1728426L,
> > 1926935L, 2125297L, 1943820L, 1623321L, 1590148L, 1049286L, 1398754L,
> > 1320550L, 994945L, 1164583L, 1205841L, 1559682L, 769662L, 1091567L,
> > 1000642L, 718794L, 1175818L, 1254971L, 900558L, 1033592L, 927072L,
> > 1245348L, 1240380L, 1820813L, 1567994L, 1789477L, 1700773L, 2204080L,
> > 1745881L, 1842826L, 1476216L, 1967969L, 1939304L, 2335284L, 2676920L,
> > 1580544L, 2277360L, 1694016L, 2721614L, 2107008L, 2630707L, 2530555L,
> > 2872656L, 2395440L, 2704234L, 3035837L, 3147379L, 3076661L, 2903544L,
> > 3398155L, 2964859L, 2837506L, 2883096L, 3264696L, 2779186L, 3980670L,
> > 2923166L, 3739659L, 3317358L, 3978904L, 4112544L, 4828331L, 4423260L,
> > 4650546L, 4321198L, 4147356L, 3959882L, 3891892L, 3623148L, 3365086L,
> > 3917517L, 3708696L, 3876444L, 3234706L, 3968716L, 3558025L, 3313506L,
> > 3522721L, 3104372L, 2772710L, 1329618L, 1857286L, 2126974L, 1509160L,
> > 1616068L, 1679704L, 1164638L, 1390846L, 1199265L, 1868727L, 1091024L,
> > 1023810L, 837614L, 1367468L, 1056694L, 1886631L, 951129L, 1153342L,
> > 1491752L, 1305802L, 1461332L, 1286770L, 1310026L, 1997167L, 2234964L,
> > 1924902L, 2080596L, 2331026L, 2046594L, 2302530L, 1958478L, 2262478L,
> > 2115387L, 2220923L, 1959669L, 1849238L, 2089172L, 1381704L, 1553856L,
> > 1251361L, 704230L, 776554L, 592426L, 704066L, 772042L, 754649L,
> > 797425L, 624502L, 517122L, 683626L, 507750L, 99592L, 217680L,
> > 671070L, 1150758L)), class = "data.frame", row.names = c(NA,
> > 383L))
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep  3 20:20:54 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 3 Sep 2018 11:20:54 -0700
Subject: [R] Display time of PDF plots
In-Reply-To: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>

1. Plot a random sample of the points (e.g. of rows of matrix/dataframe
containing "x" and "y" columns

2. See the hexbin package

3. Check out the graphics taskview on cran:
https://cran.r-project.org/web/views/Graphics.html
(though it may be somewhat dated by now)

4. Internet search:  e.g. on "display scatterplots with thousands of
points"
typical hit:
https://stackoverflow.com/questions/7714677/scatterplot-with-too-many-points

5. Search/Post on stats.stackexchange.com instead.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 3, 2018 at 10:45 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>    This may be an inappropriate forum for this question. If so, please
> point
> me in a better direction.
>
>    A current project includes scatter plots with thousands of points. Saved
> as PDF files they display slowly using a pdf viewer or when included in the
> PDF output of a LaTeX document.
>
>    Is there a process by which these plots can be 'thinned' so they show
> the
> same overall patterns but with fewer points so they display more quickly?
>
>    Rasterizing them to .jpg files using 'convert' allows them to load
> immediately, but the bit-mapped resolution is, of course, much lower than
> the vector PDF format.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep  3 20:31:02 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 3 Sep 2018 11:31:02 -0700 (PDT)
Subject: [R] Display time of PDF plots
In-Reply-To: <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809031129550.20440@salmo.appl-ecosys.com>

On Mon, 3 Sep 2018, Bert Gunter wrote:

> 1. Plot a random sample of the points (e.g. of rows of matrix/dataframe
> containing "x" and "y" columns
>
> 2. See the hexbin package
>
> 3. Check out the graphics taskview on cran:
> https://cran.r-project.org/web/views/Graphics.html
> (though it may be somewhat dated by now)
>
> 4. Internet search:  e.g. on "display scatterplots with thousands of
> points"
> typical hit:
> https://stackoverflow.com/questions/7714677/scatterplot-with-too-many-points
>
> 5. Search/Post on stats.stackexchange.com instead.

Bert,

   I did a web search without finding useful information. Probably not the
best search terms.

   Will implement your suggestions.

Thanks,

Rich



From dc@r|@on @end|ng |rom t@mu@edu  Mon Sep  3 20:36:42 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Mon, 3 Sep 2018 18:36:42 +0000
Subject: [R] Display time of PDF plots
In-Reply-To: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
Message-ID: <2da8f15c0c824e0b846c82fd6e3049aa@tamu.edu>

If the plot is being displayed on a monitor, it is being bitmapped to the resolution of the display device regardless of how you save it. Most computer monitors are about 100dpi.

If the problem is that the points are overprinting, Bert's suggestion to use hexbin() is the way to go.

If the points are not substantially overprinting, you could just save the plot in raster format using an lzh compressed tif() or png() to the maximum likely resolution of the display device (take zooming into account by going up to 600dpi or 1200dpi, for example). Don't use jpg since it is lossy and you will get halos when you zoom in. 

You can always preserve a vector version for publication. If you have Adobe Acrobat (not Reader), you can Save As Other | Image | tiff (or png) and set the resolution before exporting.

----------------------------
David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Monday, September 3, 2018 12:45 PM
To: r-help at r-project.org
Subject: [R] Display time of PDF plots

   This may be an inappropriate forum for this question. If so, please point
me in a better direction.

   A current project includes scatter plots with thousands of points. Saved
as PDF files they display slowly using a pdf viewer or when included in the
PDF output of a LaTeX document.

   Is there a process by which these plots can be 'thinned' so they show the
same overall patterns but with fewer points so they display more quickly?

   Rasterizing them to .jpg files using 'convert' allows them to load
immediately, but the bit-mapped resolution is, of course, much lower than
the vector PDF format.

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep  3 21:10:27 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 3 Sep 2018 12:10:27 -0700 (PDT)
Subject: [R] Display time of PDF plots
In-Reply-To: <2da8f15c0c824e0b846c82fd6e3049aa@tamu.edu>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <2da8f15c0c824e0b846c82fd6e3049aa@tamu.edu>
Message-ID: <alpine.LNX.2.20.1809031207100.20440@salmo.appl-ecosys.com>

On Mon, 3 Sep 2018, David L Carlson wrote:

> If the plot is being displayed on a monitor, it is being bitmapped to the
> resolution of the display device regardless of how you save it. Most
> computer monitors are about 100dpi.

David,

   I'm looking at the report on the monitor. I suspect that most readers
will, too. But, some will print it.

> If the problem is that the points are overprinting, Bert's suggestion to
> use hexbin() is the way to go.

   Most look like overprints, but at the top there are discrete print
characters.

> If the points are not substantially overprinting, you could just save the
> plot in raster format using an lzh compressed tif() or png() to the
> maximum likely resolution of the display device (take zooming into account
> by going up to 600dpi or 1200dpi, for example). Don't use jpg since it is
> lossy and you will get halos when you zoom in.

   I used convert to produce .png images but, of course, bit-maps of plots
and text are less sharp than are vector images.

> You can always preserve a vector version for publication. If you have
> Adobe Acrobat (not Reader), you can Save As Other | Image | tiff (or png)
> and set the resolution before exporting.

   'convert', the ImageMagick tool, does this, too.

Thanks,

Rich



From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Mon Sep  3 21:32:49 2018
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Tue, 4 Sep 2018 07:32:49 +1200
Subject: [R] [FORGED] Re:  Display time of PDF plots
In-Reply-To: <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>
Message-ID: <2e6dbc25-c4e2-7722-bbee-1236574c05a6@stat.auckland.ac.nz>

Hi

Another option is to just rasterize the points (but leave the rest of 
the plot vector).  See ...

https://www.stat.auckland.ac.nz/~paul/Reports/rasterize/rasterize.html

Paul

On 04/09/18 06:20, Bert Gunter wrote:
> 1. Plot a random sample of the points (e.g. of rows of matrix/dataframe
> containing "x" and "y" columns
> 
> 2. See the hexbin package
> 
> 3. Check out the graphics taskview on cran:
> https://cran.r-project.org/web/views/Graphics.html
> (though it may be somewhat dated by now)
> 
> 4. Internet search:  e.g. on "display scatterplots with thousands of
> points"
> typical hit:
> https://stackoverflow.com/questions/7714677/scatterplot-with-too-many-points
> 
> 5. Search/Post on stats.stackexchange.com instead.
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Sep 3, 2018 at 10:45 AM Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
> 
>>     This may be an inappropriate forum for this question. If so, please
>> point
>> me in a better direction.
>>
>>     A current project includes scatter plots with thousands of points. Saved
>> as PDF files they display slowly using a pdf viewer or when included in the
>> PDF output of a LaTeX document.
>>
>>     Is there a process by which these plots can be 'thinned' so they show
>> the
>> same overall patterns but with fewer points so they display more quickly?
>>
>>     Rasterizing them to .jpg files using 'convert' allows them to load
>> immediately, but the bit-mapped resolution is, of course, much lower than
>> the vector PDF format.
>>
>> Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep  3 23:17:52 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 3 Sep 2018 14:17:52 -0700 (PDT)
Subject: [R] [FORGED] Re:  Display time of PDF plots
In-Reply-To: <2e6dbc25-c4e2-7722-bbee-1236574c05a6@stat.auckland.ac.nz>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <CAGxFJbRvJMttoMj8p5Q2gDNaVcYSpFUsJFdDJq+FYTde1E1-4A@mail.gmail.com>
 <2e6dbc25-c4e2-7722-bbee-1236574c05a6@stat.auckland.ac.nz>
Message-ID: <alpine.LNX.2.20.1809031417210.20440@salmo.appl-ecosys.com>

On Tue, 4 Sep 2018, Paul Murrell wrote:

> Another option is to just rasterize the points (but leave the rest of the
> plot vector). See ...
> https://www.stat.auckland.ac.nz/~paul/Reports/rasterize/rasterize.html

Paul,

   Thanks very much for the suggestion and URL.

Regards,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep  3 23:19:12 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 3 Sep 2018 14:19:12 -0700 (PDT)
Subject: [R] Display time of PDF plots
In-Reply-To: <0F789916-5437-4A84-8CC0-2CA9216CE45F@som.umaryland.edu>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <0F789916-5437-4A84-8CC0-2CA9216CE45F@som.umaryland.edu>
Message-ID: <alpine.LNX.2.20.1809031418130.20440@salmo.appl-ecosys.com>

On Mon, 3 Sep 2018, Sorkin, John wrote:

> Might it help to take a random subset of the data and plot the sub set? If
> the relation is linear you could include a regression line obtained from
> the entire data set

John,

   I'll definitely explore this option. Thanks for the idea.

Regards,

Rich



From drj|m|emon @end|ng |rom gm@||@com  Tue Sep  4 00:36:22 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 4 Sep 2018 08:36:22 +1000
Subject: [R] Account for a factor variability in a logistic GLMM in lme4
In-Reply-To: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>
References: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>
Message-ID: <CA+8X3fXUk2=zNkKxLojEj9pHrFfQjDMVNNohnq=irLSN236WXw@mail.gmail.com>

Hi Pedro,
I have encountered similar situations in a number of areas. Great care
is taken to record significant events of low probability, but not the
non-occurrence of those events. Sometimes this is due to a problem
with the definition of non-occurrence. To use your example, how close
does an animal have to approach the crossing to be counted as not
crossing? Perhaps it was just a failure to record the species of
animals that didn't cross. In that case you have a problem, because
the probability of crossing within species cannot be estimated from
the data you describe.

Jim
On Tue, Sep 4, 2018 at 12:43 AM Pedro Vaz <zasvaz at gmail.com> wrote:
>
> We did a field study in which we tried to understand which factors
> significantly explain the probability of a group of animals (5 species in
> total) crossing through 30 wildlife road-crossing structures. The response
> variable is binomial (yes=crossed; no = did not cross) and was recorded by
> animal species. We did about 30 visits to each crossing structure (our
> random factor) in which we recorded the binomial response by each animal
> species and the values of a few predictors.
>
> So, I have this (simplified for better understanding) mixed effects model:
> library (lme4)
>
> Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|structure.id),
>   data = Mydata, family = binomial)
>
> stream is a factor with 2 levels; width.m is continuous; grass.per is a
> percentage
>
> This is the model in which I assessed crossings by all species combined
> (i.e., cross. 01 = 1 when an animal of any species crossed, cross.01 = 0
> when no animal crossed). However, we did one model per species and those
> species-specific models highlight that different species exhibit different
> relationships between crossings and explanatory variables.
>
> My problem: This means that my model above suffers from an additional
> source of variation related to the species level without accounting for it.
> However I cannot recalibrate the above model adding the species level as
> random factor because, in my binomial response, the zero means no species
> crossed (all zeros would have "NA" or, say, "none" for species) and so that
> additional source of variation is only present when the response was 1.
> Just to confirm this, I did add species as a random factor:
>
> (1 | structure.id) + (1 | species)
>
> As expected, the message is "Error: Response is constant"
>
> How can I account for the species variability in my model in lme4?
>
> A few more details:
> A few more details:
> - I had 5 mammal species crossing through the 30 road-crossing structures.
> In 134 occasions (i.e., 134 of my records on individual
> crossing-structures), no animal crossed (so, @Dimitris Rizopoulos, no, I
> didn't have the species of the animals which did not cross. A "no cross"
> was a "zero" for that visit to the crossing-structure). In 498 occasions,
> at least one animal of a given species crossed the structure (these were my
> "ones" in my logistic response)
> - A side comment: This is to respond to a reviewer in a paper of mine,
> i.e., I did and presented species-specific and "all combined species"
> models in the draft reviewed but now the reviewer is asking me to control
> for the species variability in the "combined species model". He asked me to
> include a random factor but I realized that is not possible since all my
> zeros would have "none" for the species that crossed. So, is it possible to
> control for the species variability in my model in lme4 in another way? I
> know in nlme including a fitting of variance structures it's not that
> difficult...
> - Every time an animal crossed, the binary response was "one" and I
> recorded the animal species as well. Thus, I have variability between
> species in the "ones" but not in my "zeros" of my logistic model.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From drj|m|emon @end|ng |rom gm@||@com  Tue Sep  4 03:09:52 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 4 Sep 2018 11:09:52 +1000
Subject: [R] pheatmap query
In-Reply-To: <AM4PR01MB1860BEBDAECEDF6B6BF03DE1BD0C0@AM4PR01MB1860.eurprd01.prod.exchangelabs.com>
References: <AM4PR01MB1860BEBDAECEDF6B6BF03DE1BD0C0@AM4PR01MB1860.eurprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fXEiqn2PoVDLF0hORXqtf=RhRqaAFP6rx33ZinkbLgv5A@mail.gmail.com>

Hi Tanya,
Have you looked at the return value of pheatmap?

ret<-pheatmap(counts_filtered_df,scale="row",cluster_col=FALSE,
 cluster_row=TRUE,border_color=NA,show_rownames = TRUE)
str(ret)
names(ret$tree_row)
names(ret$tree_col)

Look at what is in "ret" to see if your numeric matrix is hidden there.

Jim
On Mon, Sep 3, 2018 at 7:25 PM Singh, Tanya <t.singh at ucl.ac.uk> wrote:
>
> Hi
>
>
>
> I am plotting a pheatmap using following line in a R code
>
> pheatmap(counts_filtered_df,scale="row",cluster_col=FALSE,cluster_row=TRUE,border_color=NA,show_rownames = T)
>
>
>
> I want to extract the row names in the same order as shown in pheatmap and the z scores for them.
>
>
>
> So basically a numeric matrix instead of a figure. Can someone help me how this can be done
>
>
>
> Thanks
>
>
>
> Tanya
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Sep  4 11:28:12 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 4 Sep 2018 11:28:12 +0200
Subject: [R] Account for a factor variability in a logistic GLMM in lme4
In-Reply-To: <CA+8X3fXUk2=zNkKxLojEj9pHrFfQjDMVNNohnq=irLSN236WXw@mail.gmail.com>
References: <CAKW-RG-nF=DbNGe5WUZ95Zz0D=ei31_zuaS2Dh0simJog_M-aQ@mail.gmail.com>
 <CA+8X3fXUk2=zNkKxLojEj9pHrFfQjDMVNNohnq=irLSN236WXw@mail.gmail.com>
Message-ID: <23438.20524.387844.394620@stat.math.ethz.ch>

>>>>> Jim Lemon 
>>>>>     on Tue, 4 Sep 2018 08:36:22 +1000 writes:

    > Hi Pedro,
    > I have encountered similar situations in a number of areas. Great care
    > is taken to record significant events of low probability, but not the
    > non-occurrence of those events. Sometimes this is due to a problem
    > with the definition of non-occurrence. To use your example, how close
    > does an animal have to approach the crossing to be counted as not
    > crossing? Perhaps it was just a failure to record the species of
    > animals that didn't cross. In that case you have a problem, because
    > the probability of crossing within species cannot be estimated from
    > the data you describe.

    > Jim

Indeed!

For those among us too young to remember:

The 1986 Space shuttle Challenger catastrophe was co-caused by
that mistake:  Only considering the '1's and not considering the
'0's in the data (visualised and shown to the decision making experts).

See, e.g.,
  https://priceonomics.com/the-space-shuttle-challenger-explosion-and-the-o/

  (couldn't easily find a more academic / reliable source which
   *does* include the graphics)

Martin Maechler
ETH Zurich

    > On Tue, Sep 4, 2018 at 12:43 AM Pedro Vaz <zasvaz at gmail.com> wrote:
    >> 
    >> We did a field study in which we tried to understand which factors
    >> significantly explain the probability of a group of animals (5 species in
    >> total) crossing through 30 wildlife road-crossing structures. The response
    >> variable is binomial (yes=crossed; no = did not cross) and was recorded by
    >> animal species. We did about 30 visits to each crossing structure (our
    >> random factor) in which we recorded the binomial response by each animal
    >> species and the values of a few predictors.
    >> 
    >> So, I have this (simplified for better understanding) mixed effects model:
    >> library (lme4)
    >> 
    >> Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|structure.id),
    >> data = Mydata, family = binomial)
    >> 
    >> stream is a factor with 2 levels; width.m is continuous; grass.per is a
    >> percentage
    >> 
    >> This is the model in which I assessed crossings by all species combined
    >> (i.e., cross. 01 = 1 when an animal of any species crossed, cross.01 = 0
    >> when no animal crossed). However, we did one model per species and those
    >> species-specific models highlight that different species exhibit different
    >> relationships between crossings and explanatory variables.
    >> 
    >> My problem: This means that my model above suffers from an additional
    >> source of variation related to the species level without accounting for it.
    >> However I cannot recalibrate the above model adding the species level as
    >> random factor because, in my binomial response, the zero means no species
    >> crossed (all zeros would have "NA" or, say, "none" for species) and so that
    >> additional source of variation is only present when the response was 1.
    >> Just to confirm this, I did add species as a random factor:
    >> 
    >> (1 | structure.id) + (1 | species)
    >> 
    >> As expected, the message is "Error: Response is constant"
    >> 
    >> How can I account for the species variability in my model in lme4?
    >> 
    >> A few more details:
    >> A few more details:
    >> - I had 5 mammal species crossing through the 30 road-crossing structures.
    >> In 134 occasions (i.e., 134 of my records on individual
    >> crossing-structures), no animal crossed (so, @Dimitris Rizopoulos, no, I
    >> didn't have the species of the animals which did not cross. A "no cross"
    >> was a "zero" for that visit to the crossing-structure). In 498 occasions,
    >> at least one animal of a given species crossed the structure (these were my
    >> "ones" in my logistic response)
    >> - A side comment: This is to respond to a reviewer in a paper of mine,
    >> i.e., I did and presented species-specific and "all combined species"
    >> models in the draft reviewed but now the reviewer is asking me to control
    >> for the species variability in the "combined species model". He asked me to
    >> include a random factor but I realized that is not possible since all my
    >> zeros would have "none" for the species that crossed. So, is it possible to
    >> control for the species variability in my model in lme4 in another way? I
    >> know in nlme including a fitting of variance structures it's not that
    >> difficult...
    >> - Every time an animal crossed, the binary response was "one" and I
    >> recorded the animal species as well. Thus, I have variability between
    >> species in the "ones" but not in my "zeros" of my logistic model.
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.



From ne||@redu @end|ng |rom hotm@||@|r  Tue Sep  4 18:32:56 2018
From: ne||@redu @end|ng |rom hotm@||@|r (Nelly Reduan)
Date: Tue, 4 Sep 2018 16:32:56 +0000
Subject: [R] Round down numeric values with decimals
Message-ID: <DM5PR05MB279324049A2520E959CB8B1B99030@DM5PR05MB2793.namprd05.prod.outlook.com>

Hello,



How can I round down numeric values with decimals? For example,



> signif(3.896037e+09, digits = 1)

[1] 4e+09



The expected result is 3e+09 (and not 4e+09).



> signif(8.68542378e-10, digits = 1)

[1] 9e-10



The expected result is 8e-10 (and not 9e-10).



Thank you very much for your time.

Have a nice day

Nell


	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep  4 18:41:03 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 4 Sep 2018 09:41:03 -0700 (PDT)
Subject: [R] Display time of PDF plots
In-Reply-To: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809040934080.8839@salmo.appl-ecosys.com>

On Mon, 3 Sep 2018, Rich Shepard wrote:

> Is there a process by which these plots can be 'thinned' so they show the
> same overall patterns but with fewer points so they display more quickly?

Bert/Paul/David/John:

   Thanks very much for the suggestions. I think an appropriate way to
illustrate the patterns is to plot the median and maximum for each month
(for all sites). That's the important information and plotting each daily
point over 13 years obscures that information.

   The dataframe is structured this way:

str(rainfall)
'data.frame':	113569 obs. of  6 variables:
  $ name    : chr  "Headworks Portland Water" "Headworks Portland Water" "Headworks Portland Water" "Headworks Portland Water" ...
  $ easting : num  2370575 2370575 2370575 2370575 2370575 ...
  $ northing: num  199338 199338 199338 199338 199338 ...
  $ elev    : num  228 228 228 228 228 228 228 228 228 228 ...
  $ sampdate: Date, format: "2005-01-01" "2005-01-02" ...
  $ prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...

   There are probably multiple ways of extracting the monthly median and
maximum 'prcp' and I don't know how to identify the appropriate one. Is
there a task view for this type of data manipulation? I've not before done
anything like this and would appreciate a pointer to where I start to learn.

Regards,

Rich



From z@@v@z @end|ng |rom gm@||@com  Tue Sep  4 18:39:51 2018
From: z@@v@z @end|ng |rom gm@||@com (Pedro Vaz)
Date: Tue, 4 Sep 2018 17:39:51 +0100
Subject: [R] leave-one-out cross validation in mixed effects logistic model
 (lme4)
Message-ID: <CAKW-RG_2b9MzYUg-zCpxTRd4xoiOPZW-bHXf4098j_Rzg3J+TA@mail.gmail.com>

 Hello,

So, I have this (simplified for better understanding) binomial mixed
effects model [library (lme4)]

Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|
structure.id),
  data = Mydata, family = binomial)

stream is a factor with 2 levels; width.m is continuous; grass.per is a
percentage

Now, a reviewer is asking me to apply "a cross-validation procedure (i.e. a
leave-one-out design coupled with predictive metrics as e.g. AUC) on this
model"

Does anyone have R-code to do this cross validation in my logistic mixed
effects model? In the reviewer words: "the model should be evaluated also
as for their predictive performance, not only for assumptions violation and
for goodness-of-fit" (which I presented already in the reviewed paper draft)

Many thanks in advance,
pedro

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep  4 20:08:07 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 4 Sep 2018 11:08:07 -0700
Subject: [R] Round down numeric values with decimals
In-Reply-To: <DM5PR05MB279324049A2520E959CB8B1B99030@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB279324049A2520E959CB8B1B99030@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <CAGxFJbQFkRuiWHZAnmmuSdn_Tr9uSYPsBGM5jP+HbUtLhWGx4g@mail.gmail.com>

This is *not* "rounding down."

But this should do it I think:
## (see ?floor)

x <- 3.896e09
k <- floor(log10(x))

> floor(x*10^(-k))*10^k
[1] 3e+09

There may be even slicker ways, but this is as slick as I can muster...

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 4, 2018 at 9:33 AM Nelly Reduan <nell.redu at hotmail.fr> wrote:

> Hello,
>
>
>
> How can I round down numeric values with decimals? For example,
>
>
>
> > signif(3.896037e+09, digits = 1)
>
> [1] 4e+09
>
>
>
> The expected result is 3e+09 (and not 4e+09).
>
>
>
> > signif(8.68542378e-10, digits = 1)
>
> [1] 9e-10
>
>
>
> The expected result is 8e-10 (and not 9e-10).
>
>
>
> Thank you very much for your time.
>
> Have a nice day
>
> Nell
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep  4 20:13:51 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 4 Sep 2018 11:13:51 -0700
Subject: [R] 
 leave-one-out cross validation in mixed effects logistic model
 (lme4)
In-Reply-To: <CAKW-RG_2b9MzYUg-zCpxTRd4xoiOPZW-bHXf4098j_Rzg3J+TA@mail.gmail.com>
References: <CAKW-RG_2b9MzYUg-zCpxTRd4xoiOPZW-bHXf4098j_Rzg3J+TA@mail.gmail.com>
Message-ID: <CAGxFJbT3j12+MVY=-R-5+eCtEMX7iu8najYneWRGrmYb8-9Vxw@mail.gmail.com>

Please post on the r-sig-mixed-models list, where you are more likely to
find the requisite expertise.

However, FWIW, I think the reviewer's request is complete nonsense (na?ve
cross validation requires iid sampling). But the mixed models experts are
the authorities on such judgments (and may tell you that my opinion is
complete nonsense!).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 4, 2018 at 10:16 AM Pedro Vaz <zasvaz at gmail.com> wrote:

>  Hello,
>
> So, I have this (simplified for better understanding) binomial mixed
> effects model [library (lme4)]
>
> Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|
> structure.id),
>   data = Mydata, family = binomial)
>
> stream is a factor with 2 levels; width.m is continuous; grass.per is a
> percentage
>
> Now, a reviewer is asking me to apply "a cross-validation procedure (i.e. a
> leave-one-out design coupled with predictive metrics as e.g. AUC) on this
> model"
>
> Does anyone have R-code to do this cross validation in my logistic mixed
> effects model? In the reviewer words: "the model should be evaluated also
> as for their predictive performance, not only for assumptions violation and
> for goodness-of-fit" (which I presented already in the reviewed paper
> draft)
>
> Many thanks in advance,
> pedro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From g||ted|||e2014 @end|ng |rom gm@||@com  Tue Sep  4 21:34:36 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Tue, 4 Sep 2018 20:34:36 +0100
Subject: [R] Equal Standard Error bar
Message-ID: <CAC8ss30AWzFAGoeg8xaNFRwXHRMs-9+NnRJcOtch1daViA_ubw@mail.gmail.com>

Dear List,

I have a dataset of high variability. I conducted epoch analysis and
attempted to plot the standard error bar alongside.

I am, however, surprised that the error bars are of equal length. I do not
think that the variability in the data is captured, except there is a kind
of averaging that smooths out the differences in daily variations. Should
that be the case, I don't know how and as such need your assistance to
explain what is going on.

The plot is attached. 71 events are represented in the plot.

The code I use to generate the plot is:
oodf<-data.frame(A,B)
library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(145000,162000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/day",main="Superposed
Epoch of all the Events")
dispersion(-5:10,oomean,oose).

The sample data is:
-5 64833
-4 95864
-3 82322
-2 95591
-1 69378
0 74281
1 103261
2 92473
3 84344
4 127415
5 123826
6 100029
7 76205
8 105162
9 119533
10 106490
-5 82322
-4 95591
-3 69378
-2 74281
-1 103261
0 92473
1 84344
2 127415
3 123826
4 100029
5 76205
6 105162
7 119533
8 106490
9 114771
10 55593
-5 85694
-4 65205
-3 80995
-2 51723
-1 62310
0 53401
1 65677
2 76094
3 64035
4 68290
5 73306
6 82176
7 75566
8 89762
9 88063
10 94395
-5 80651
-4 81291
-3 63702
-2 70297
-1 64117
0 71219
1 57354
2 62111
3 42252
4 35454
5 33469
6 38899
7 64981
8 85694
9 79452
10 85216
-5 71219
-4 57354
-3 62111
-2 42252
-1 35454
0 33469
1 38899
2 64981
3 85694
4 79452
5 85216
6 81721
7 91231
8 107074
9 108103
10 75768


You kind help will be greatly appreciated.

Many thanks

Ogbos

-------------- next part --------------
A non-text attachment was scrubbed...
Name: A8.png
Type: image/png
Size: 10229 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180904/a9a19f5a/attachment-0002.png>

From dc@r|@on @end|ng |rom t@mu@edu  Tue Sep  4 22:58:04 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Tue, 4 Sep 2018 20:58:04 +0000
Subject: [R] Equal Standard Error bar
In-Reply-To: <CAC8ss30AWzFAGoeg8xaNFRwXHRMs-9+NnRJcOtch1daViA_ubw@mail.gmail.com>
References: <CAC8ss30AWzFAGoeg8xaNFRwXHRMs-9+NnRJcOtch1daViA_ubw@mail.gmail.com>
Message-ID: <044a56c442cf4573870f5fe24bfabfab@tamu.edu>

Thank you for the reproducible data, but it is not the data used in the plot you attached and does not plot anything with the code you included. The ylim= argument must be modified:

plot(-5:10, oomean, type="b", ylim=c(40000, 120000),
  xlab="days (epoch is the day of Fd)", ylab="strikes/day",
  main="Superposed Epoch of all the Events")
dispersion(-5:10, oomean, oose, arrow.cap=.01)

On the plot of these data it is clear that the error bars are different sizes:

range(oose)
[1] 1728.234 6890.916

What was the range of oose values for the data in the plot you included with your message?

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Ogbos Okike
Sent: Tuesday, September 4, 2018 2:35 PM
To: r-help <r-help at r-project.org>
Subject: [R] Equal Standard Error bar

Dear List,

I have a dataset of high variability. I conducted epoch analysis and attempted to plot the standard error bar alongside.

I am, however, surprised that the error bars are of equal length. I do not think that the variability in the data is captured, except there is a kind of averaging that smooths out the differences in daily variations. Should that be the case, I don't know how and as such need your assistance to explain what is going on.

The plot is attached. 71 events are represented in the plot.

The code I use to generate the plot is:
oodf<-data.frame(A,B)
library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(145000,162000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/day",main="Superposed
Epoch of all the Events")
dispersion(-5:10,oomean,oose).

The sample data is:
-5 64833
-4 95864
-3 82322
-2 95591
-1 69378
0 74281
1 103261
2 92473
3 84344
4 127415
5 123826
6 100029
7 76205
8 105162
9 119533
10 106490
-5 82322
-4 95591
-3 69378
-2 74281
-1 103261
0 92473
1 84344
2 127415
3 123826
4 100029
5 76205
6 105162
7 119533
8 106490
9 114771
10 55593
-5 85694
-4 65205
-3 80995
-2 51723
-1 62310
0 53401
1 65677
2 76094
3 64035
4 68290
5 73306
6 82176
7 75566
8 89762
9 88063
10 94395
-5 80651
-4 81291
-3 63702
-2 70297
-1 64117
0 71219
1 57354
2 62111
3 42252
4 35454
5 33469
6 38899
7 64981
8 85694
9 79452
10 85216
-5 71219
-4 57354
-3 62111
-2 42252
-1 35454
0 33469
1 38899
2 64981
3 85694
4 79452
5 85216
6 81721
7 91231
8 107074
9 108103
10 75768


You kind help will be greatly appreciated.

Many thanks

Ogbos

-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot.png
Type: image/png
Size: 7334 bytes
Desc: plot.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180904/8f32584f/attachment-0002.png>

From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep  5 00:12:20 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 4 Sep 2018 15:12:20 -0700
Subject: [R] Round down numeric values with decimals
In-Reply-To: <CAGxFJbQFkRuiWHZAnmmuSdn_Tr9uSYPsBGM5jP+HbUtLhWGx4g@mail.gmail.com>
References: <DM5PR05MB279324049A2520E959CB8B1B99030@DM5PR05MB2793.namprd05.prod.outlook.com>
 <CAGxFJbQFkRuiWHZAnmmuSdn_Tr9uSYPsBGM5jP+HbUtLhWGx4g@mail.gmail.com>
Message-ID: <CAGxFJbQ0P+BgMFYbD_NnxtOyMzBDPA-+i=f6V9S=tnfTJ645Ew@mail.gmail.com>

Note also that if you wish to include 0 and negative numbers, and your
intent is to truncate to 1 digit towards 0, then you must of course check
for 0 separately and modify what I suggested for x != 0 to:

k <- floor(log10(abs(x)))
ifelse(x <0, ceiling(x*10^(-k)), floor(x*10^(-k))) *10^k

Note that this is all vectorized, so, e.g. ,

> x<- c(-101.8, 101.8)
> k <- floor(log10(abs(x)))
> ifelse(x <0, ceiling(x*10^(-k)), floor(x*10^(-k))) *10^k
[1] -100  100

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 4, 2018 at 11:08 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> This is *not* "rounding down."
>
> But this should do it I think:
> ## (see ?floor)
>
> x <- 3.896e09
> k <- floor(log10(x))
>
> > floor(x*10^(-k))*10^k
> [1] 3e+09
>
> There may be even slicker ways, but this is as slick as I can muster...
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Sep 4, 2018 at 9:33 AM Nelly Reduan <nell.redu at hotmail.fr> wrote:
>
>> Hello,
>>
>>
>>
>> How can I round down numeric values with decimals? For example,
>>
>>
>>
>> > signif(3.896037e+09, digits = 1)
>>
>> [1] 4e+09
>>
>>
>>
>> The expected result is 3e+09 (and not 4e+09).
>>
>>
>>
>> > signif(8.68542378e-10, digits = 1)
>>
>> [1] 9e-10
>>
>>
>>
>> The expected result is 8e-10 (and not 9e-10).
>>
>>
>>
>> Thank you very much for your time.
>>
>> Have a nice day
>>
>> Nell
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Sep  5 04:06:25 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 5 Sep 2018 03:06:25 +0100
Subject: [R] Equal Standard Error bar
In-Reply-To: <044a56c442cf4573870f5fe24bfabfab@tamu.edu>
References: <CAC8ss30AWzFAGoeg8xaNFRwXHRMs-9+NnRJcOtch1daViA_ubw@mail.gmail.com>
 <044a56c442cf4573870f5fe24bfabfab@tamu.edu>
Message-ID: <CAC8ss33wBpVc4jketJuhjkkRhL2_9W0YKnFX+vQRLeNaeVELwA@mail.gmail.com>

Hi David,

You are right. Thanks for your time.

The problem is certainly with the data. Plotting part of it gives different
results, usually quite different from the output when the total data is
used. In fact, just as you mentioned, it will look as if it is not the same
code that is used to plot it.

The range is  33469-281856.

Instead of taking time to explain how I fiddled with the range before
getting the plot I attached, let me just attach the whole data. I really
had issues with the range when plotting the whole data (see attached
please).

Many thanks again.

Ogbos



On Tue, Sep 4, 2018 at 9:58 PM David L Carlson <dcarlson at tamu.edu> wrote:

> Thank you for the reproducible data, but it is not the data used in the
> plot you attached and does not plot anything with the code you included.
> The ylim= argument must be modified:
>
> plot(-5:10, oomean, type="b", ylim=c(40000, 120000),
>   xlab="days (epoch is the day of Fd)", ylab="strikes/day",
>   main="Superposed Epoch of all the Events")
> dispersion(-5:10, oomean, oose, arrow.cap=.01)
>
> On the plot of these data it is clear that the error bars are different
> sizes:
>
> range(oose)
> [1] 1728.234 6890.916
>
> What was the range of oose values for the data in the plot you included
> with your message?
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ogbos Okike
> Sent: Tuesday, September 4, 2018 2:35 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] Equal Standard Error bar
>
> Dear List,
>
> I have a dataset of high variability. I conducted epoch analysis and
> attempted to plot the standard error bar alongside.
>
> I am, however, surprised that the error bars are of equal length. I do not
> think that the variability in the data is captured, except there is a kind
> of averaging that smooths out the differences in daily variations. Should
> that be the case, I don't know how and as such need your assistance to
> explain what is going on.
>
> The plot is attached. 71 events are represented in the plot.
>
> The code I use to generate the plot is:
> oodf<-data.frame(A,B)
> library(plotrix)
> std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> oomean<-as.vector(by(oodf$B,oodf$A,mean))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(145000,162000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/day",main="Superposed
> Epoch of all the Events")
> dispersion(-5:10,oomean,oose).
>
> The sample data is:
> -5 64833
> -4 95864
> -3 82322
> -2 95591
> -1 69378
> 0 74281
> 1 103261
> 2 92473
> 3 84344
> 4 127415
> 5 123826
> 6 100029
> 7 76205
> 8 105162
> 9 119533
> 10 106490
> -5 82322
> -4 95591
> -3 69378
> -2 74281
> -1 103261
> 0 92473
> 1 84344
> 2 127415
> 3 123826
> 4 100029
> 5 76205
> 6 105162
> 7 119533
> 8 106490
> 9 114771
> 10 55593
> -5 85694
> -4 65205
> -3 80995
> -2 51723
> -1 62310
> 0 53401
> 1 65677
> 2 76094
> 3 64035
> 4 68290
> 5 73306
> 6 82176
> 7 75566
> 8 89762
> 9 88063
> 10 94395
> -5 80651
> -4 81291
> -3 63702
> -2 70297
> -1 64117
> 0 71219
> 1 57354
> 2 62111
> 3 42252
> 4 35454
> 5 33469
> 6 38899
> 7 64981
> 8 85694
> 9 79452
> 10 85216
> -5 71219
> -4 57354
> -3 62111
> -2 42252
> -1 35454
> 0 33469
> 1 38899
> 2 64981
> 3 85694
> 4 79452
> 5 85216
> 6 81721
> 7 91231
> 8 107074
> 9 108103
> 10 75768
>
>
> You kind help will be greatly appreciated.
>
> Many thanks
>
> Ogbos
>


From @rchhbpn@tejenn @end|ng |rom utex@@@edu  Wed Sep  5 01:30:57 2018
From: @rchhbpn@tejenn @end|ng |rom utex@@@edu (Nathan D Jennings)
Date: Tue, 4 Sep 2018 18:30:57 -0500
Subject: [R] Help with r script
Message-ID: <663d1062-1801-40db-98a3-699b8c8e6ea4@Spark>

?To the R Project:

I am using R Studio and I need help sum product exponents with R Script. ?Every time I type at the very start in the R Script window like 25* 30 nothing happens. ?Where can I go to find the complete commands for basic functions in the r script window?


Sincerely,


Nathan Jennings

	[[alternative HTML version deleted]]



From phiiipsm m@iii@g oii cp@@ei1@stormweb@@et  Wed Sep  5 04:08:59 2018
From: phiiipsm m@iii@g oii cp@@ei1@stormweb@@et (phiiipsm m@iii@g oii cp@@ei1@stormweb@@et)
Date: Tue, 04 Sep 2018 22:08:59 -0400
Subject: [R] Multi-word column names in a data frame
Message-ID: <20180904220859.Horde._UUjvliZZ6zi537vypqQ-93@webmail.philipsmith.ca>

I am having trouble working with column names in a data frame. My  
column names are multi-word text strings and I like it that way. I  
want to loop through the columns, plotting graphs for each one, and I  
want to use the column names in the chart labels and in the file names  
when I save the charts. Here is a simple reproducible example that  
does not work.

library(dplyr)
`RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
`Number of vegetables` <- c(14,23,45)
`Number of people` <- c(20,30,40)
MyData <- data.frame(RefDate,`Number of vegetables`,`Number of  
people`,check.names=FALSE)
MyVars <- c("Number of vegetables","Number of people")
for (A in MyVars) {
   g2 <- ggplot(MyData,aes(RefDate,eval(parse(text=A)))) + geom_line() +
     labs(title = paste(A," adjusted",sep=""))
   g2
   ggsave(paste(A,".jpg",sep=""),g2,height=5,width=8,dpi=300)
}

Philip



From drj|m|emon @end|ng |rom gm@||@com  Wed Sep  5 06:22:44 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 5 Sep 2018 14:22:44 +1000
Subject: [R] Multi-word column names in a data frame
In-Reply-To: <20180904220859.Horde._UUjvliZZ6zi537vypqQ-93@webmail.philipsmith.ca>
References: <20180904220859.Horde._UUjvliZZ6zi537vypqQ-93@webmail.philipsmith.ca>
Message-ID: <CA+8X3fXe6=QZB=a2OJM6xGiHoLpjQYDSVxOd96jwt7L07GJKLg@mail.gmail.com>

Hi Philip,
This may work:

library(dplyr)
`RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
`Number of vegetables` <- c(14,23,45)
`Number of people` <- c(20,30,40)
MyData <- data.frame(RefDate,`Number_of_vegetables`,
 `Number_of_people`,check.names=FALSE)
MyVars <- c("Number of vegetables","Number of people")
My_Vars <- c("Number_of_vegetables","Number_of_people")
nnames<-length(MyVars)
for (i in 1:nnames) {
   g2 <- ggplot(MyData,aes(RefDate,eval(parse(text=My_Vars[i])))) +
geom_line() +
     labs(title = paste(MyVars[i]," adjusted",sep=""))
   g2
   ggsave(paste(A,".jpg",sep=""),g2,height=5,width=8,dpi=300)
}

Jim
On Wed, Sep 5, 2018 at 1:22 PM <philipsm at cpanel1.stormweb.net> wrote:
>
> I am having trouble working with column names in a data frame. My
> column names are multi-word text strings and I like it that way. I
> want to loop through the columns, plotting graphs for each one, and I
> want to use the column names in the chart labels and in the file names
> when I save the charts. Here is a simple reproducible example that
> does not work.
>
> library(dplyr)
> `RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
> `Number of vegetables` <- c(14,23,45)
> `Number of people` <- c(20,30,40)
> MyData <- data.frame(RefDate,`Number of vegetables`,`Number of
> people`,check.names=FALSE)
> MyVars <- c("Number of vegetables","Number of people")
> for (A in MyVars) {
>    g2 <- ggplot(MyData,aes(RefDate,eval(parse(text=A)))) + geom_line() +
>      labs(title = paste(A," adjusted",sep=""))
>    g2
>    ggsave(paste(A,".jpg",sep=""),g2,height=5,width=8,dpi=300)
> }
>
> Philip
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep  5 06:55:01 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 4 Sep 2018 21:55:01 -0700 (PDT)
Subject: [R] Multi-word column names in a data frame
In-Reply-To: <20180904220859.Horde._UUjvliZZ6zi537vypqQ-93@webmail.philipsmith.ca>
References: <20180904220859.Horde._UUjvliZZ6zi537vypqQ-93@webmail.philipsmith.ca>
Message-ID: <alpine.BSF.2.00.1809042150090.27516@pedal.dcn.davis.ca.us>

a) missing ggplot2 library
b) cannot word wrap in the middle of a string in R without introducing 
newlines
c) aes is not recommended for working with string variables as names... 
use aes_string
d) Because aes_string will parse the string, you need to add the backticks
e) paste0() is a shorter version of paste( sep="" )

##############################
library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(ggplot2)
`RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
`Number of vegetables` <- c(14,23,45)
`Number of people` <- c(20,30,40)
MyData <- data.frame( RefDate
                     , `Number of vegetables`
                     , `Number of people`
                     , check.names = FALSE
                     )
MyVars <- c( "Number of vegetables", "Number of people" )
for ( A in MyVars ) {
   g2 <- ggplot( MyData
               , aes_string( x = RefDate
                           , y = paste0( "`", A, "`" )
                           )
               ) +
     geom_line() +
     labs( title = paste0( A, " adjusted" ) )
   g2
   ggsave( paste0( A, ".jpg" )
         , g2
         , height=5
         , width=8
         , dpi=300
         )
}

#' Created on 2018-09-05 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
###################################33

On Tue, 4 Sep 2018, philipsm at cpanel1.stormweb.net wrote:

> I am having trouble working with column names in a data frame. My column 
> names are multi-word text strings and I like it that way. I want to loop 
> through the columns, plotting graphs for each one, and I want to use the 
> column names in the chart labels and in the file names when I save the 
> charts. Here is a simple reproducible example that does not work.
>
> library(dplyr)
> `RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
> `Number of vegetables` <- c(14,23,45)
> `Number of people` <- c(20,30,40)
> MyData <- data.frame(RefDate,`Number of vegetables`,`Number of 
> people`,check.names=FALSE)
> MyVars <- c("Number of vegetables","Number of people")
> for (A in MyVars) {
> g2 <- ggplot(MyData,aes(RefDate,eval(parse(text=A)))) + geom_line() +
>   labs(title = paste(A," adjusted",sep=""))
> g2
> ggsave(paste(A,".jpg",sep=""),g2,height=5,width=8,dpi=300)
> }
>
> Philip
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep  5 07:36:15 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 4 Sep 2018 22:36:15 -0700 (PDT)
Subject: [R] Help with r script
In-Reply-To: <663d1062-1801-40db-98a3-699b8c8e6ea4@Spark>
References: <663d1062-1801-40db-98a3-699b8c8e6ea4@Spark>
Message-ID: <alpine.BSF.2.00.1809042155180.27516@pedal.dcn.davis.ca.us>

On Tue, 4 Sep 2018, Nathan D Jennings wrote:

> ?To the R Project:

This is the R-help mailing list, populated by various people who use R 
including the occasional R-core developer.

> I am using R Studio and I need help sum product exponents with R Script.

a) This is the R-help mailing list, not the RStudio-help mailing list. 
RStudio is only one of numerous user interfaces that can be used to 
interact with R. This mailing list is about the language, not the user 
interface. They do have a forum [1].

> ?Every time I type at the very start in the R Script window like 25* 30 
> nothing happens.

b) I think the window you are describing as the "R Script" window is 
actually a text editor window. All interaction with R occurs in the R 
Console, and the text editor window is a place to keep organized in a file 
the commands you write that seem to do what you want when executed in the 
Console. Usually you will need a number of commands executed in sequence 
to accomplish whatever analysis goal you have, so a text file is a good 
place to keep those commands organized. You can position the cursor on an 
R command in the editor and hold down the control key and press Enter, and 
RStudio will type it into the console window for you. Once you are 
confident those commands work you can use the source() function to have R 
execute the entire file of commands at once. You would look for the 
response/result/output in the Console and/or the Plot windows depending 
which commands you used.

> ?Where can I go to find the complete commands for basic functions in the 
> r script window?

c) I don't think that there is any comprehensive list of commands you can 
give to R. There are many introductory R books, and there is an 
Introduction to R document provided with R [2]. You might find the 
cheatsheets listed under the Help/Cheatsheets menu in RStudio helpful to 
give you some clues. If you want a thorough discussion of the structure of 
the R language you can refer to the R Language Definition [3], but that is 
really rather dense going if you are just starting out... an introductory 
book or the r-intro document would probably be most useful to you at this 
point.

Finally, per the Posting Guide mentioned below this mailing list is not 
appropriate for students doing homework... from your email address I think 
you should have local resources who can boost you up the learning curve 
much more efficiently than we can through a plain text mailing list (or 
even the RStudio forum). In this mailing list, you need to understand 
enough R to be able to post R code that illustrates what isn't working for 
you, along with a clear specification of what you wanted to get.

[1] https://community.rstudio.com/
[2] https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf
[3] https://cran.r-project.org/manuals.html

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep  5 09:17:28 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (ruipbarradas)
Date: Wed, 05 Sep 2018 08:17:28 +0100
Subject: [R] Help with r script
Message-ID: <mojlpj5t8w4cnbi7h7byle6q.1536131848861@email.android.com>

Hello,
25*30 <Ctrl><Enter>
This is the most basic possible, please google an intro text and run its examples.
Hope this helps,
Rui Barradas?


Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: Nathan D Jennings <archhbpnatejenn at utexas.edu> Data: 05/09/2018  00:30  (GMT+00:00) Para: r-help at r-project.org Assunto: [R] Help with r script 
?To the R Project:

I am using R Studio and I need help sum product exponents with R Script. ?Every time I type at the very start in the R Script window like 25* 30 nothing happens. ?Where can I go to find the complete commands for basic functions in the r script window?


Sincerely,


Nathan Jennings

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ce||ne_jou@n|n @end|ng |rom y@hoo@|r  Wed Sep  5 15:34:11 2018
From: ce||ne_jou@n|n @end|ng |rom y@hoo@|r (Jouanin Celine)
Date: Wed, 5 Sep 2018 13:34:11 +0000 (UTC)
Subject: [R] Convention de stage
References: <1220985191.3018295.1536154451818.ref@mail.yahoo.com>
Message-ID: <1220985191.3018295.1536154451818@mail.yahoo.com>

Bonjour,
Suite ? votre appel la semaine derni?re, je reviens vers vous concernant ma convention de stage et mon entr?e ? Open le 10 septembre.
Avez vous eu des retours pour la signature de celle ci ? Je peux passer demain ou vendredi la chercher afin de la transmettre ? mon organisme de formation.Je vous remercie pour votre retour.

Bien cordialement,C?line Jouanin


	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep  5 21:26:36 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (ruipbarradas)
Date: Wed, 05 Sep 2018 20:26:36 +0100
Subject: [R] Convention de stage
Message-ID: <8s8wu3j6nvtg49ae711bvp3x.1536175596895@email.android.com>

Bonjour,
Vous ?tes en erreur, cette liste est la liste R-Help pour aider ceux qui ont des doutes sur le langage de programmation R, un langage pour statistique, analyse de donn?s et graphiques scientifiques.
Cordialement,
Rui Barradas


Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: Jouanin Celine via R-help <r-help at r-project.org> Data: 05/09/2018  14:34  (GMT+00:00) Para: emmanuel.jouan at open-groupe.com, "R." <r-help at r-project.org> Assunto: [R] Convention de stage 
Bonjour,
Suite ? votre appel la semaine derni?re, je reviens vers vous concernant ma convention de stage et mon entr?e ? Open le 10 septembre.
Avez vous eu des retours pour la signature de celle ci ? Je peux passer demain ou vendredi la chercher afin de la transmettre ? mon organisme de formation.Je vous remercie pour votre retour.

Bien cordialement,C?line Jouanin


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From m@cqueen1 @end|ng |rom ||n|@gov  Wed Sep  5 22:05:02 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Wed, 5 Sep 2018 20:05:02 +0000
Subject: [R] Display time of PDF plots
In-Reply-To: <alpine.LNX.2.20.1809040934080.8839@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809031043290.4056@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1809040934080.8839@salmo.appl-ecosys.com>
Message-ID: <1AAA6D75-B182-48AE-ACE3-F263EDED2DD4@llnl.gov>

(this is somewhat a change of subject from the original question)

Rich, there functions such as aggregate() in base R. There are also many options in CRAN packages.

But I tend to have difficulty getting them to do exactly what I want, and usually end up rolling my own.

The idea is to split the data into groups by station and month, then calculate summary stats for each group, then recombine into a new data frame.

## untested with your data, but this kind of approach works well for me
## note that this code assumes easting, northing, and elevation are in fact unique within each group
## if they are not, you will get an ERROR

## add a 'month' variable
raindf <- rainfall
raindf$mon <- format(raindf$sampdate,'%Y-%m')
  
  mysum <- function(df) {
    data.frame( name=unique(df$name),
               easting=unique(df$easting),
               northing=unique(df$northing),
               elev=unique(df$elev),
               mon=unique(df$mon),
               pr.med=median(df$prcp),
               pr.max=max(df$prcp) )
  }

tmpdf <- split(raindf, paste(raindf$name, raindf$mon) )

## at this point, you can check your summary stats function with, for example,
mysum(tmpdf[[1]])
mysum(tmpdf[[2]])

## when satisfied with mysum(), do this
tmpsum <- lapply(tmpdf, mysum)

## recombine
rain.by.mon <- do.call(rbind, tmpsum)

## might still want to create a numeric month to facilitate plotting
## or maybe assign each month to the first of the month, or the 15th, or end or whatever makes sense
rain.by.mon$mondt <- as.Date(paste0(rain.by.mon$mon,'-1'))




--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/4/18, 9:41 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

    On Mon, 3 Sep 2018, Rich Shepard wrote:
    
    > Is there a process by which these plots can be 'thinned' so they show the
    > same overall patterns but with fewer points so they display more quickly?
    
    Bert/Paul/David/John:
    
       Thanks very much for the suggestions. I think an appropriate way to
    illustrate the patterns is to plot the median and maximum for each month
    (for all sites). That's the important information and plotting each daily
    point over 13 years obscures that information.
    
       The dataframe is structured this way:
    
    str(rainfall)
    'data.frame':	113569 obs. of  6 variables:
      $ name    : chr  "Headworks Portland Water" "Headworks Portland Water" "Headworks Portland Water" "Headworks Portland Water" ...
      $ easting : num  2370575 2370575 2370575 2370575 2370575 ...
      $ northing: num  199338 199338 199338 199338 199338 ...
      $ elev    : num  228 228 228 228 228 228 228 228 228 228 ...
      $ sampdate: Date, format: "2005-01-01" "2005-01-02" ...
      $ prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
    
       There are probably multiple ways of extracting the monthly median and
    maximum 'prcp' and I don't know how to identify the appropriate one. Is
    there a task view for this type of data manipulation? I've not before done
    anything like this and would appreciate a pointer to where I start to learn.
    
    Regards,
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep  5 22:17:54 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 5 Sep 2018 13:17:54 -0700 (PDT)
Subject: [R] Casting Date to char
Message-ID: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>

   I've read the help for as.Date: "Date Conversion Functions to and from
Character" but the method as.character(x ...) isn't working for me:

> str(dp)
'data.frame':	113569 obs. of  2 variables:
  $ rainfall.sampdate: Date, format: "2005-01-01" "2005-01-02" ...
  $ rainfall.prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
> dp$sampdate <- as.Character(dp$sampdate)
Error in `$<-.data.frame`(`*tmp*`, sampdata, value = character(0)) :
   replacement has 0 rows, data has 113569

   I don't understand the error message and want to learn what I've done
incorrectly.

Regards,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep  5 22:32:56 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 5 Sep 2018 13:32:56 -0700 (PDT)
Subject: [R] Casting Date to char
In-Reply-To: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809051332020.20257@salmo.appl-ecosys.com>

On Wed, 5 Sep 2018, Rich Shepard wrote:

>> dp$sampdate <- as.Character(dp$sampdate)

   This from a failed attempt: as.Character not found. The reported error was
generated by using as.character.

Rich



From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep  5 22:30:26 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 5 Sep 2018 16:30:26 -0400
Subject: [R] Casting Date to char
In-Reply-To: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
Message-ID: <f88669eb-80c1-68ba-9bf5-26df3f23f2a0@gmail.com>

On 05/09/2018 4:17 PM, Rich Shepard wrote:
>     I've read the help for as.Date: "Date Conversion Functions to and from
> Character" but the method as.character(x ...) isn't working for me:
> 
>> str(dp)
> 'data.frame':	113569 obs. of  2 variables:
>    $ rainfall.sampdate: Date, format: "2005-01-01" "2005-01-02" ...
>    $ rainfall.prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
>> dp$sampdate <- as.Character(dp$sampdate)
> Error in `$<-.data.frame`(`*tmp*`, sampdata, value = character(0)) :
>     replacement has 0 rows, data has 113569

This might just be a typo in your message, but as.character() is the 
function you want, not as.Character().

The other typo or error above is that you are trying to convert 
dp$sampdate, but the dataframe has no column with that name according to 
the lines above.

Duncan Murdoch

> 
>     I don't understand the error message and want to learn what I've done
> incorrectly.
> 
> Regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep  5 22:42:35 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 5 Sep 2018 13:42:35 -0700 (PDT)
Subject: [R] Casting Date to char
In-Reply-To: <f88669eb-80c1-68ba-9bf5-26df3f23f2a0@gmail.com>
References: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
 <f88669eb-80c1-68ba-9bf5-26df3f23f2a0@gmail.com>
Message-ID: <alpine.LNX.2.20.1809051341520.20257@salmo.appl-ecosys.com>

On Wed, 5 Sep 2018, Duncan Murdoch wrote:

> This might just be a typo in your message, but as.character() is the function 
> you want, not as.Character().

Duncan,

   Yes, it is a typo.

> The other typo or error above is that you are trying to convert
> dp$sampdate, but the dataframe has no column with that name according to
> the lines above.

   I now see this.

Many thanks,

Rich



From btupper @end|ng |rom b|ge|ow@org  Wed Sep  5 22:51:50 2018
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Wed, 5 Sep 2018 16:51:50 -0400
Subject: [R] Casting Date to char
In-Reply-To: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
Message-ID: <B1606BF8-A7ED-4771-8A4D-DF35355530FA@bigelow.org>

Hi,

Perhaps you wanted to convert dp$rainfall.sampdate and not dp$sampdate like this...

dp$sampdate <- as.character(dp$rainfall.sampdate)

... or even better, take charge of the conversion with format() ...

dp$sampdate <- format(dp$rainfall.sampdate, format = '%Y-%m-%d')

Cheers,
Ben

> On Sep 5, 2018, at 4:17 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I've read the help for as.Date: "Date Conversion Functions to and from
> Character" but the method as.character(x ...) isn't working for me:
> 
>> str(dp)
> 'data.frame':	113569 obs. of  2 variables:
> $ rainfall.sampdate: Date, format: "2005-01-01" "2005-01-02" ...
> $ rainfall.prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
>> dp$sampdate <- as.Character(dp$sampdate)
> Error in `$<-.data.frame`(`*tmp*`, sampdata, value = character(0)) :
>  replacement has 0 rows, data has 113569
> 
>  I don't understand the error message and want to learn what I've done
> incorrectly.
> 
> Regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep  5 22:54:50 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 5 Sep 2018 13:54:50 -0700 (PDT)
Subject: [R] Casting Date to char
In-Reply-To: <B1606BF8-A7ED-4771-8A4D-DF35355530FA@bigelow.org>
References: <alpine.LNX.2.20.1809051059180.20257@salmo.appl-ecosys.com>
 <B1606BF8-A7ED-4771-8A4D-DF35355530FA@bigelow.org>
Message-ID: <alpine.LNX.2.20.1809051353360.20257@salmo.appl-ecosys.com>

On Wed, 5 Sep 2018, Ben Tupper wrote:

> Perhaps you wanted to convert dp$rainfall.sampdate and not dp$sampdate like this...
>
> dp$sampdate <- as.character(dp$rainfall.sampdate)
>
> ... or even better, take charge of the conversion with format() ...
>
> dp$sampdate <- format(dp$rainfall.sampdate, format = '%Y-%m-%d')

Ben,

   Yep. That's what I want and didn't know how to do. The first conversion I
missed seeing and the second reflects my infamiliarity with format().

Many thanks,

Rich



From d@v|d@m| @end|ng |rom m|cro@o|t@com  Thu Sep  6 00:08:21 2018
From: d@v|d@m| @end|ng |rom m|cro@o|t@com (David Smith (CDA))
Date: Wed, 5 Sep 2018 22:08:21 +0000
Subject: [R] Revolutions blog: August 2018 roundup
Message-ID: <DM5PR2101MB10488ACF9F11FB6D7B40294AC8020@DM5PR2101MB1048.namprd21.prod.outlook.com>

Since 2008, Microsoft staff and guests have written about R at the Revolutions
blog (http://blog.revolutionanalytics.com) and every month I post a summary of
articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of August:

A guide to installing R and RStudio with packages and multithreaded BLAS on
various platforms:
http://blog.revolutionanalytics.com/2018/08/installation-guide.html

Some tips for Excel users migrating to R for data analysis:
http://blog.revolutionanalytics.com/2018/08/how-to-use-r-with-excel.html 

Videos of presentations from the New York R Conference:
http://blog.revolutionanalytics.com/2018/08/videos-from-nyc-r-conference.html

The Chartmaker Directory compares and provides examples of data visualizations
for dozens of tools, including R:
http://blog.revolutionanalytics.com/2018/08/chartmaker-directory.html

Siraj Raval's video overview of Azure machine learning services:
http://blog.revolutionanalytics.com/2018/08/aml-video.html

A simple script based on the gganimate package illustrates the luminance
illusion: http://blog.revolutionanalytics.com/2018/08/luminance-illusion.html

Roundup of AI, Machine Learning and Data Science news from August 2018:
http://blog.revolutionanalytics.com/2018/08/ai-roundup-august-2018.html

A package to make R play text as speech:
http://blog.revolutionanalytics.com/2018/08/make-r-speak.html

Microsoft R Open 3.5.1 is now available:
http://blog.revolutionanalytics.com/2018/08/mro-351-now-available.html

R ranks #14 in the June 2018 Redmonk Language Rankings:
http://blog.revolutionanalytics.com/2018/08/redmonk-language-rankings-june-2018.html

R drops one place to #7 in the 2018 IEEE Language Rankings:
http://blog.revolutionanalytics.com/2018/08/ieee-language-rankings-2018.html

A video tutorial on running R and Python in SQL Server from a Jupyter Notebook:
http://blog.revolutionanalytics.com/2018/08/r-python-in-sql-server.html

The cover story for Significance Magazine celebrates 25 years of the R project:
http://blog.revolutionanalytics.com/2018/08/r-generation.html

And some general interest stories (not necessarily related to R):

* The Curiosity Show, the 80's Australian science program for kids:
  http://blog.revolutionanalytics.com/2018/08/because-its-friday-the-curiosity-show.html

* A visualization of the prime factors of the first million integers shows
  surprising structure:
  http://blog.revolutionanalytics.com/2018/08/one-million-integers.html

* Brexit as the Titanic disaster:
  http://blog.revolutionanalytics.com/2018/08/because-its-friday-a-titanic-brexit.html

* An experimental underwater data center gets a fishcam:
  http://blog.revolutionanalytics.com/2018/08/because-its-friday-a-turbine-under-the-sea.html

* A parody commercial for Australia tourism focuses on the "dangers":
  http://blog.revolutionanalytics.com/2018/08/undangerous-australia.html

As always, thanks for the comments and please keep sending suggestions to me at
davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com



From m||uj|@b @end|ng |rom gm@||@com  Thu Sep  6 00:30:09 2018
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Thu, 6 Sep 2018 00:30:09 +0200
Subject: [R] Marginal effects with plm
Message-ID: <CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>

Dear all,

I am running the following panel regression;

plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt, data =
df, index=c("region","year"))

where 'df' is a pdata.frame. I would like to obtain marginal effects of 'y'
for the variable 'x1'. I have tried the packages 'prediction' and 'margins'
without luck.

Is it possible to obtain marginal effects with 'plm'? Any help will be
highly appreciated. Thank you.

Error in UseMethod("predict") :
  no applicable method for 'predict' applied to an object of class
"c('plm', 'panelmodel')"

Sincerely,

Milu

	[[alternative HTML version deleted]]



From j|ox @end|ng |rom mcm@@ter@c@  Thu Sep  6 01:12:30 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Wed, 5 Sep 2018 23:12:30 +0000
Subject: [R] Marginal effects with plm
In-Reply-To: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
References: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>

Dear Milu,

Depending upon what you mean by "marginal effects," you might try the effects package. For example, for your model, try 

	(Ef.hd <- Effect(c("heat", "debt_dummy"), plm1))
	plot(Ef.hd)

A couple of comments about the model: I'd prefer to specify the formula as log(y) ~ poly(x1, 2) + heat*debt + tt or log(y) ~ poly(x1, 2, raw=TRUE) + heat*debt + tt (assuming that debt_dummy is a precoded dummy regressor for a factor debt).

I hope this helps,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Miluji
> Sb
> Sent: Wednesday, September 5, 2018 6:30 PM
> To: r-help mailing list <r-help at r-project.org>
> Subject: [R] Marginal effects with plm
> 
> Dear all,
> 
> I am running the following panel regression;
> 
> plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt, data
> = df, index=c("region","year"))
> 
> where 'df' is a pdata.frame. I would like to obtain marginal effects of
> 'y'	
> for the variable 'x1'. I have tried the packages 'prediction' and
> 'margins'
> without luck.
> 
> Is it possible to obtain marginal effects with 'plm'? Any help will be
> highly appreciated. Thank you.
> 
> Error in UseMethod("predict") :
>   no applicable method for 'predict' applied to an object of class
> "c('plm', 'panelmodel')"
> 
> Sincerely,
> 
> Milu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep  6 04:28:31 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 5 Sep 2018 19:28:31 -0700
Subject: [R] A small thing that amused my small mind
In-Reply-To: <CAGxFJbQ0P+BgMFYbD_NnxtOyMzBDPA-+i=f6V9S=tnfTJ645Ew@mail.gmail.com>
References: <DM5PR05MB279324049A2520E959CB8B1B99030@DM5PR05MB2793.namprd05.prod.outlook.com>
 <CAGxFJbQFkRuiWHZAnmmuSdn_Tr9uSYPsBGM5jP+HbUtLhWGx4g@mail.gmail.com>
 <CAGxFJbQ0P+BgMFYbD_NnxtOyMzBDPA-+i=f6V9S=tnfTJ645Ew@mail.gmail.com>
Message-ID: <CAGxFJbS7p9=nD+TB2TB3JvQ7p-XphakVH8qvw95g2F_URY+kTQ@mail.gmail.com>

A few days ago, someone asked how to truncate arbitrary numerics to 1
digit towards 0. e.g. -189 should become -100 and 254 should become
200; and all values in magniude < 1 should become 0.

I proposed a somewhat clumsy solution using floor() and ceiling(), but
in fooling with it a bit more, I realized that a better way to do it
is to use R's trunc() function. It is simpler and works for all cases
AFAICS. Here's a litte function to do it -- maybe someone else might
find it amusing/instructive:

poof <- function(x){
   ## truncating to 0
## x is a numeric vector
k <- 10^trunc(log10(abs(x)))
ifelse(k, trunc(x/k)*k, k)
}

## test it
> x <- c(0,-.036578, .4876, -189, 254)
> poof(x)
[1]    0    0    0 -100  200

Cheers,
Bert



From Scott@W@|ch|er @end|ng |rom pnn|@gov  Thu Sep  6 07:00:52 2018
From: Scott@W@|ch|er @end|ng |rom pnn|@gov (Waichler, Scott R)
Date: Thu, 6 Sep 2018 05:00:52 +0000
Subject: [R] seq() problem with chron
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881BB21182@EX10MBOX03.pnnl.gov>

Hi, 

I encountered the problem below where the last value in the chron vector created with seq() should have a time of 15:30, but instead has 15:15.  What causes this and how can I make sure that the last value in the chron vector is the same as the "to" value in seq()?

library(chron)
dt1 <- chron("02/20/13", "00:00:00")
dt2 <- chron("07/03/18", "15:30:00")
dt <- seq(from=dt1, to=dt2, by=1/(24*4))
dt[length(dt)]
#[1] (07/03/18 15:15:00)

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
scott.waichler at pnnl.gov



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep  6 09:04:10 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 6 Sep 2018 00:04:10 -0700 (PDT)
Subject: [R] Multi-word column names in a data frame
In-Reply-To: <20180905195744.Horde.PwCsZ1Pu2AdI-VDJpD-CJ9-@webmail.philipsmith.ca>
References: <20180905195744.Horde.PwCsZ1Pu2AdI-VDJpD-CJ9-@webmail.philipsmith.ca>
Message-ID: <alpine.BSF.2.00.1809052338150.85393@pedal.dcn.davis.ca.us>

You forgot to reply-all ... I don't do private consulting, so please keep 
the conversation on the mailing list.

Here are some ideas for extending your example. However, whether you WANT 
to or not, you really need to learn to manipulate your data BEFORE you 
give it to ggplot.

#########################################
library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(tidyr)
library(ggplot2)
library(rlang)
`RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
`Number of vegetables` <- c(14,23,45)
`Number of people` <- c(20,30,40)
MyData <- data.frame( RefDate
                     , `Number of vegetables`
                     , `Number of people`
                     , check.names=FALSE
                     )
MyVars <- c("Number of vegetables","Number of people")

# simple approach... notice "RefDate" is a string

for (A in MyVars) {
  g2 <- ggplot( MyData
              , aes_string( x = "RefDate"
                          , y = paste0( "`", A, "`")
                          )
              ) +
    geom_line() +
    labs( title = paste( A, "adjusted" ) )
    print( g2 )
  # ggsave( paste0( A,".jpg" )
  #       ,g2
  #       ,height=5
  #       ,width=8
  #       ,dpi=300
  #       )
}


# Using function FQPC here - works, but an inferior use of ggplot
# because ggplot does not build legends with wide data

FQPC <- function(x) {100*x/lag(x,1)-100} # % change
for (A in MyVars) {
  g2 <- ggplot( MyData
              , aes( x = RefDate
                   , y = FQPC( !!sym( A ) )
                   )
              ) +
    geom_line() +
    labs(title = paste( A,"adjusted" ) )
  print( g2 )
  # ggsave( paste0( A,".jpg" )
  #         ,g2
  #         ,height=5
  #         ,width=8
  #         ,dpi=300
  # )
}
#> Warning: Removed 1 rows containing missing values (geom_path).
#'
#> Warning: Removed 1 rows containing missing values (geom_path).

# superior approach is to do the computations first

for ( A in MyVars ) {
   DF <- MyData[ , c( "RefDate", A ) ]
   DF[[ 2 ]] <- FQPC( DF[[ 2 ]] )
   g2 <- ( ggplot( DF, aes( x = RefDate, y = !!sym( A ) ) )
         + geom_line()
         + labs( title = paste( A,"adjusted" ) )
         )
   print( g2 )
}
#> Warning: Removed 1 rows containing missing values (geom_path).
#'
#> Warning: Removed 1 rows containing missing values (geom_path).

# Another way to do the computations first
resultDF <- data_frame( variable = MyVars
                       , data = lapply( MyVars
                                      , function( A ) {
                                           DF <- setNames( MyData[ , c( "RefDate", A ) ]
                                                         , c( "RefDate", "value" )
                                                         )
                                           DF[[ 2 ]] <- FQPC( DF[[ 2 ]] )
                                           DF
                                        }
                                      )
                       )
for ( i in seq.int( nrow( resultDF ) ) ) {
   A <- resultDF$variable[ i ]
   g2 <- ( ggplot( resultDF$data[[ i ]], aes( x = RefDate, y = value ) )
         + geom_line()
         + ylab( A )
         + labs( title = paste( A, "adjusted" ) )
         )
   print( g2 )
}
#> Warning: Removed 1 rows containing missing values (geom_path).

#'     #> Warning: Removed 1 rows containing missing values (geom_path).

# or put them together in order determined by MyVars:

resultDF %>%
mutate( variable = factor( variable, levels = MyVars ) ) %>%
unnest %>% # flattens separate data frames in data column into one long 
data frame
ggplot( aes( x = RefDate, y = value ) ) +
   geom_line() +
   facet_grid( variable ~ ., scales = "free_y" )
#> Warning: Removed 1 rows containing missing values (geom_path).

#' Created on 2018-09-05 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
#####################################33

On Wed, 5 Sep 2018, philipsm at cpanel1.stormweb.net wrote:

> Thanks again for your help. Your suggested solution using aes_string(), which 
> I was not familiar with, worked perfectly when I plotted the column 
> variables. However, I also want to plot transformations of those variables 
> and the aes_string() approach does not work in that case. I implement the 
> transformations with a function and the function is expecting a numeric 
> rather than a string.
>
> For example, when I use the function:
>
> library(dplyr)
> library(ggplot2)
> `RefDate` <- as.Date(c("2010-11-1","2010-12-01","2011-01-01"))
> `Number of vegetables` <- c(14,23,45)
> `Number of people` <- c(20,30,40)
> MyData <- data.frame(RefDate
>                    ,`Number of vegetables`
>                    ,`Number of people`
>                    ,check.names=FALSE
>                    )
> MyVars <- c("Number of vegetables","Number of people")
>
> # No function here - it works
>
> for (A in MyVars) {
> g2 <- ggplot(MyData
>              ,aes_string( x = RefDate
>                         , y = paste0( "`", A, "`")
>                         )
>              ) +
>   geom_line() +
>   labs(title = paste( A,"adjusted" ) )
> g2
> ggsave( paste0( A,".jpg" )
>       ,g2
>       ,height=5
>       ,width=8
>       ,dpi=300
>       )
> }
>
> # Using function FQPC here - it does not work
>
> FQPC <- function(x) {100*x/lag(x,1)-100} # % change
> for (A in MyVars) {
> g2 <- ggplot(MyData
>              ,aes_string( x = RefDate
>                           , y = FQPC(paste0( "`", A, "`"))
>              )
> ) +
>   geom_line() +
>   labs(title = paste( A,"adjusted" ) )
> g2
> ggsave( paste0( A,".jpg" )
>         ,g2
>         ,height=5
>         ,width=8
>         ,dpi=300
> )
> }
>
>
> # I get the error: "Error in 100*x : non-numeric argument to binary 
> operator".
>
> I need some way to convert the string representation of the variable, 'A', 
> back to a column name representation and, presumably, use aes() instead of 
> aes_string(). Any further thoughts about this?
>
> Philip
>
>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From djnord|und @end|ng |rom gm@||@com  Thu Sep  6 09:07:02 2018
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Thu, 6 Sep 2018 00:07:02 -0700
Subject: [R] seq() problem with chron
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB8881BB21182@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB8881BB21182@EX10MBOX03.pnnl.gov>
Message-ID: <c10972e0-c6a0-ceb9-f830-3d4c8fe45327@gmail.com>

On 9/5/2018 10:00 PM, Waichler, Scott R wrote:
> Hi,
> 
> I encountered the problem below where the last value in the chron vector created with seq() should have a time of 15:30, but instead has 15:15.  What causes this and how can I make sure that the last value in the chron vector is the same as the "to" value in seq()?
> 
> library(chron)
> dt1 <- chron("02/20/13", "00:00:00")
> dt2 <- chron("07/03/18", "15:30:00")
> dt <- seq(from=dt1, to=dt2, by=1/(24*4))
> dt[length(dt)]
> #[1] (07/03/18 15:15:00)
> 
> Thanks,
> Scott Waichler
> Pacific Northwest National Laboratory
> scott.waichler at pnnl.gov
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

This is not a chron problem, it is a floating-point arithmetic problem 
(basically, FAQ 7.31).  You are adding incrementing by 1/96, which can't 
be represent exactly in binary representation.  So, when you expected 
that you should get a time of 15:30, it is slightly larger and the 
sequence is stopped at 15:15.

You could change dt2 to be chron("07/03/18", "15:31:00").  Or or you 
could use POSIX datetimes with something like the following, where the 
increment 900 is the number of seconds in 15 minutes.

dt1 <- strptime("02/20/13 00:00:00", "%m/%d/%y %H:%M:%S")
dt2 <- strptime("07/03/18 15:30:00", "%m/%d/%y %H:%M:%S")
dt <- seq(from=dt1, to=dt2, by=900)
dt[length(dt)]

There might also be some useful functions in the lubridate package.


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep  6 09:54:25 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 6 Sep 2018 00:54:25 -0700 (PDT)
Subject: [R] seq() problem with chron
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB8881BB21182@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB8881BB21182@EX10MBOX03.pnnl.gov>
Message-ID: <alpine.BSF.2.00.1809060008540.85393@pedal.dcn.davis.ca.us>

See FAQ 7.31... chron uses floating point representation, and there is 
some error accumulating. I also think there may be at least one bug in 
chron::seq.dates(), but I think POSIXct is significantly better than chron 
anywway so I don't intend to debug chron.

#############################
# with chron, avoiding repeated addition of fractional days
library(chron)
dt1 <- chron("02/20/13", "00:00:00")
dt2 <- chron("07/03/18", "15:30:00")
n <- round( 24*4*as.numeric( dt2 - dt1 ) )
length(dt)
#> [1] 1
dt <- dt1 + seq( 0, n ) / 24 / 4
dt[length(dt)]
#> [1] (07/03/18 15:30:00)
# with POSIXct
Sys.setenv( TZ = "GMT" )
DT1 <- as.POSIXct( "02/20/2013 00:00:00", format = "%m/%d/%Y %H:%M:%S" )
DT2 <- as.POSIXct( "07/03/2018 15:30:00", format = "%m/%d/%Y %H:%M:%S" )
# POSIXct is represented as seconds, so no fractions are used
DT <- seq( DT1, DT2, by = as.difftime( 15, units="mins" ) )
DT[length(DT)]
#> [1] "2018-07-03 15:30:00 GMT"

#' Created on 2018-09-06 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
#############################


On Thu, 6 Sep 2018, Waichler, Scott R wrote:

> Hi,
>
> I encountered the problem below where the last value in the chron vector created with seq() should have a time of 15:30, but instead has 15:15.  What causes this and how can I make sure that the last value in the chron vector is the same as the "to" value in seq()?
>
> library(chron)
> dt1 <- chron("02/20/13", "00:00:00")
> dt2 <- chron("07/03/18", "15:30:00")
> dt <- seq(from=dt1, to=dt2, by=1/(24*4))
> dt[length(dt)]
> #[1] (07/03/18 15:15:00)
>
> Thanks,
> Scott Waichler
> Pacific Northwest National Laboratory
> scott.waichler at pnnl.gov
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From m||uj|@b @end|ng |rom gm@||@com  Thu Sep  6 11:37:10 2018
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Thu, 6 Sep 2018 11:37:10 +0200
Subject: [R] Marginal effects with plm
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>
References: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAMLwc7OGY2cfy0ruwPNwCD-QnAJ0ePqf+6H0UBjAF4PeR3NcuQ@mail.gmail.com>

Dear John,

Thank you very much for the solution and the suggestion. I have tried the
following;

plm1 <- plm(formula = log(gva_ind) ~  poly(x1, 2, raw=TRUE) +
heat*debt_dummy + tt, data = df, index=c("region","year"))

Ef.hd <- Effect(c("heat", "debt_dummy"), plm1)

But get the following error;  - Error in UseMethod("droplevels") : no
applicable method for 'droplevels' applied to an object of class "NULL"

Is this something to do with the way the plm object? Thanks again!

Sincerely,

Milu

On Thu, Sep 6, 2018 at 1:12 AM Fox, John <jfox at mcmaster.ca> wrote:

> Dear Milu,
>
> Depending upon what you mean by "marginal effects," you might try the
> effects package. For example, for your model, try
>
>         (Ef.hd <- Effect(c("heat", "debt_dummy"), plm1))
>         plot(Ef.hd)
>
> A couple of comments about the model: I'd prefer to specify the formula as
> log(y) ~ poly(x1, 2) + heat*debt + tt or log(y) ~ poly(x1, 2, raw=TRUE) +
> heat*debt + tt (assuming that debt_dummy is a precoded dummy regressor for
> a factor debt).
>
> I hope this helps,
>  John
>
> --------------------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Miluji
> > Sb
> > Sent: Wednesday, September 5, 2018 6:30 PM
> > To: r-help mailing list <r-help at r-project.org>
> > Subject: [R] Marginal effects with plm
> >
> > Dear all,
> >
> > I am running the following panel regression;
> >
> > plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt, data
> > = df, index=c("region","year"))
> >
> > where 'df' is a pdata.frame. I would like to obtain marginal effects of
> > 'y'
> > for the variable 'x1'. I have tried the packages 'prediction' and
> > 'margins'
> > without luck.
> >
> > Is it possible to obtain marginal effects with 'plm'? Any help will be
> > highly appreciated. Thank you.
> >
> > Error in UseMethod("predict") :
> >   no applicable method for 'predict' applied to an object of class
> > "c('plm', 'panelmodel')"
> >
> > Sincerely,
> >
> > Milu
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @@@@k@@h @end|ng |rom gm@||@com  Thu Sep  6 12:43:05 2018
From: @@@@k@@h @end|ng |rom gm@||@com (Aakash Kumar)
Date: Thu, 6 Sep 2018 16:13:05 +0530
Subject: [R] Query on read.xls function in gdata
In-Reply-To: <CAEd2DY+3ShFOqeVaxMCwZnkvW5zTdqQJMsjA6ywBVpbMqdO7Cg@mail.gmail.com>
References: <CAEd2DYJkz1n7ozF9qOqNen01dfo7+MUhpLj3RfU8WUN8+pAHmA@mail.gmail.com>
 <CAEd2DYL6BLMC8jMr-Pst6Q-PXH0r2LApoL2adJxmhNfE84sw6g@mail.gmail.com>
 <CAEd2DYKb0QmkxLUF0_LGnu46Gjbpz+2aKUj7JvhFCzFcV_Hdsw@mail.gmail.com>
 <CAEd2DYLT+AHmpO0+uESQ4ygVMPeJySrxh20xvxw=9TH1PB0wfA@mail.gmail.com>
 <CAEd2DYKO7HoTtMLP_t=RGBC4B9AjKrfThHBZXRajnrC=OPw2dA@mail.gmail.com>
 <CAEd2DY+cundHG_EhfFWx9qvRRdFNEdA6z-vSd0=2P5X1gwVizw@mail.gmail.com>
 <CAEd2DY+3ShFOqeVaxMCwZnkvW5zTdqQJMsjA6ywBVpbMqdO7Cg@mail.gmail.com>
Message-ID: <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>

Hi Team,

I am trying to read in .xls files in R using read.xls function present in
gdata package. I have installed the required perl dependencies as well.
Yet, I am facing the following error.

"*Error in xls2sep : Intermediate file is missing*"

Could someone please help me out understanding the cause and if possible, a
fix for the same?

Thanks in advance!

Regards,
Aakash

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep  6 13:30:26 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 6 Sep 2018 11:30:26 +0000
Subject: [R] Query on read.xls function in gdata
In-Reply-To: <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>
References: <CAEd2DYJkz1n7ozF9qOqNen01dfo7+MUhpLj3RfU8WUN8+pAHmA@mail.gmail.com>
 <CAEd2DYL6BLMC8jMr-Pst6Q-PXH0r2LApoL2adJxmhNfE84sw6g@mail.gmail.com>
 <CAEd2DYKb0QmkxLUF0_LGnu46Gjbpz+2aKUj7JvhFCzFcV_Hdsw@mail.gmail.com>
 <CAEd2DYLT+AHmpO0+uESQ4ygVMPeJySrxh20xvxw=9TH1PB0wfA@mail.gmail.com>
 <CAEd2DYKO7HoTtMLP_t=RGBC4B9AjKrfThHBZXRajnrC=OPw2dA@mail.gmail.com>
 <CAEd2DY+cundHG_EhfFWx9qvRRdFNEdA6z-vSd0=2P5X1gwVizw@mail.gmail.com>
 <CAEd2DY+3ShFOqeVaxMCwZnkvW5zTdqQJMsjA6ywBVpbMqdO7Cg@mail.gmail.com>
 <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>
Message-ID: <1a746e7561a24a12ab986159a88273ed@SRVEXCHCM1302.precheza.cz>

Hi

If you do not need to stick with gdata you could try package readxl, it does not need any further packages.

https://cran.r-project.org/web/packages/readxl/readxl.pdf

It results in tibble data but change to data.frame is easy.

Cheers
Petr
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Aakash Kumar
> Sent: Thursday, September 6, 2018 12:43 PM
> To: r-help at r-project.org
> Subject: [R] Query on read.xls function in gdata
>
> Hi Team,
>
> I am trying to read in .xls files in R using read.xls function present in gdata
> package. I have installed the required perl dependencies as well.
> Yet, I am facing the following error.
>
> "*Error in xls2sep : Intermediate file is missing*"
>
> Could someone please help me out understanding the cause and if possible, a
> fix for the same?
>
> Thanks in advance!
>
> Regards,
> Aakash
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From j|ox @end|ng |rom mcm@@ter@c@  Thu Sep  6 14:16:01 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 6 Sep 2018 12:16:01 +0000
Subject: [R] Marginal effects with plm
In-Reply-To: <CAMLwc7OGY2cfy0ruwPNwCD-QnAJ0ePqf+6H0UBjAF4PeR3NcuQ@mail.gmail.com>
References: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>
 <CAMLwc7OGY2cfy0ruwPNwCD-QnAJ0ePqf+6H0UBjAF4PeR3NcuQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368A7D2B@FHSDB2D11-2.csu.mcmaster.ca>

Dear Milu,

Effect() doesn't have a specific plm method so the default method is invoked. Before responding to your initial question. I tried Effect() with an example from ?plm and it worked.

Without a reproducible example that produces the error that you encountered, there's no way to answer your question.

Best,
 John

> -----Original Message-----
> From: Miluji Sb [mailto:milujisb at gmail.com]
> Sent: Thursday, September 6, 2018 5:37 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Marginal effects with plm
> 
> Dear John,
> 
> Thank you very much for the solution and the suggestion. I have tried the
> following;
> 
> plm1 <- plm(formula = log(gva_ind) ~  poly(x1, 2, raw=TRUE) +
> heat*debt_dummy + tt, data = df, index=c("region","year"))
> 
> Ef.hd <- Effect(c("heat", "debt_dummy"), plm1)
> 
> 
> But get the following error;  - Error in UseMethod("droplevels") : no applicable
> method for 'droplevels' applied to an object of class "NULL"
> 
> Is this something to do with the way the plm object? Thanks again!
> 
> Sincerely,
> 
> Milu
> 
> On Thu, Sep 6, 2018 at 1:12 AM Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Milu,
> 
> 	Depending upon what you mean by "marginal effects," you might try
> the effects package. For example, for your model, try
> 
> 	        (Ef.hd <- Effect(c("heat", "debt_dummy"), plm1))
> 	        plot(Ef.hd)
> 
> 	A couple of comments about the model: I'd prefer to specify the
> formula as log(y) ~ poly(x1, 2) + heat*debt + tt or log(y) ~ poly(x1, 2,
> raw=TRUE) + heat*debt + tt (assuming that debt_dummy is a precoded
> dummy regressor for a factor debt).
> 
> 	I hope this helps,
> 	 John
> 
> 	--------------------------------------
> 	John Fox, Professor Emeritus
> 	McMaster University
> 	Hamilton, Ontario, Canada
> 	Web: socialsciences.mcmaster.ca/jfox/
> <http://socialsciences.mcmaster.ca/jfox/>
> 
> 
> 
> 	> -----Original Message-----
> 	> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org> ] On Behalf Of Miluji
> 	> Sb
> 	> Sent: Wednesday, September 5, 2018 6:30 PM
> 	> To: r-help mailing list <r-help at r-project.org <mailto:r-help at r-
> project.org> >
> 	> Subject: [R] Marginal effects with plm
> 	>
> 	> Dear all,
> 	>
> 	> I am running the following panel regression;
> 	>
> 	> plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt,
> data
> 	> = df, index=c("region","year"))
> 	>
> 	> where 'df' is a pdata.frame. I would like to obtain marginal effects of
> 	> 'y'
> 	> for the variable 'x1'. I have tried the packages 'prediction' and
> 	> 'margins'
> 	> without luck.
> 	>
> 	> Is it possible to obtain marginal effects with 'plm'? Any help will be
> 	> highly appreciated. Thank you.
> 	>
> 	> Error in UseMethod("predict") :
> 	>   no applicable method for 'predict' applied to an object of class
> 	> "c('plm', 'panelmodel')"
> 	>
> 	> Sincerely,
> 	>
> 	> Milu
> 	>
> 	>       [[alternative HTML version deleted]]
> 	>
> 	> ______________________________________________
> 	> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list --
> To UNSUBSCRIBE and more, see
> 	> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> PLEASE do read the posting guide http://www.R-project.org/posting-
> 	> guide.html
> 	> and provide commented, minimal, self-contained, reproducible
> code.
> 


From m||uj|@b @end|ng |rom gm@||@com  Thu Sep  6 14:51:48 2018
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Thu, 6 Sep 2018 14:51:48 +0200
Subject: [R] Marginal effects with plm
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8368A7D2B@FHSDB2D11-2.csu.mcmaster.ca>
References: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>
 <CAMLwc7OGY2cfy0ruwPNwCD-QnAJ0ePqf+6H0UBjAF4PeR3NcuQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7D2B@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAMLwc7N9HL7z53vFUxvPweKHnJ9oVMf0sFVF2Wqtfz3T=rx=mQ@mail.gmail.com>

Dear John,

Apologies for not providing reproducible example. I just tried with a plm
example but ran into the same issue;

library(plm)
data("Produc", package = "plm")
zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc,
index = c("state","year"))

Ef.hd <- Effect(c("pc", "emp", "unemp"), zz)

Error in UseMethod("droplevels") :
  no applicable method for 'droplevels' applied to an object of class "NULL"

What am I doing wrong? Thanks again.

Sincerely,

Milu

	[[alternative HTML version deleted]]



From |@t@z@hn @end|ng |rom gm@||@com  Thu Sep  6 15:03:47 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Thu, 6 Sep 2018 09:03:47 -0400
Subject: [R] Marginal effects with plm
In-Reply-To: <CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
References: <CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
Message-ID: <CA+vqiLGH5Ybr43mnVkEzt4cn6HworjLy=rf6ZkhYCmiJV9VDMQ@mail.gmail.com>

You might be interested in the "prediction" and "margins" packages.

--Ista

On Wed, Sep 5, 2018 at 6:30 PM Miluji Sb <milujisb at gmail.com> wrote:
>
> Dear all,
>
> I am running the following panel regression;
>
> plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt, data =
> df, index=c("region","year"))
>
> where 'df' is a pdata.frame. I would like to obtain marginal effects of 'y'
> for the variable 'x1'. I have tried the packages 'prediction' and 'margins'
> without luck.
>
> Is it possible to obtain marginal effects with 'plm'? Any help will be
> highly appreciated. Thank you.
>
> Error in UseMethod("predict") :
>   no applicable method for 'predict' applied to an object of class
> "c('plm', 'panelmodel')"
>
> Sincerely,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep  6 15:14:52 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 06 Sep 2018 06:14:52 -0700
Subject: [R] Query on read.xls function in gdata
In-Reply-To: <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>
References: <CAEd2DYJkz1n7ozF9qOqNen01dfo7+MUhpLj3RfU8WUN8+pAHmA@mail.gmail.com>
 <CAEd2DYL6BLMC8jMr-Pst6Q-PXH0r2LApoL2adJxmhNfE84sw6g@mail.gmail.com>
 <CAEd2DYKb0QmkxLUF0_LGnu46Gjbpz+2aKUj7JvhFCzFcV_Hdsw@mail.gmail.com>
 <CAEd2DYLT+AHmpO0+uESQ4ygVMPeJySrxh20xvxw=9TH1PB0wfA@mail.gmail.com>
 <CAEd2DYKO7HoTtMLP_t=RGBC4B9AjKrfThHBZXRajnrC=OPw2dA@mail.gmail.com>
 <CAEd2DY+cundHG_EhfFWx9qvRRdFNEdA6z-vSd0=2P5X1gwVizw@mail.gmail.com>
 <CAEd2DY+3ShFOqeVaxMCwZnkvW5zTdqQJMsjA6ywBVpbMqdO7Cg@mail.gmail.com>
 <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>
Message-ID: <30116570-C704-4E8E-BD2B-897FE79370D2@dcn.davis.ca.us>

Without a reproducible example that is highly unlikely to happen.

However, you might just want to try the openxlsx or readxl packages instead.

On September 6, 2018 3:43:05 AM PDT, Aakash Kumar <ssaakash at gmail.com> wrote:
>Hi Team,
>
>I am trying to read in .xls files in R using read.xls function present
>in
>gdata package. I have installed the required perl dependencies as well.
>Yet, I am facing the following error.
>
>"*Error in xls2sep : Intermediate file is missing*"
>
>Could someone please help me out understanding the cause and if
>possible, a
>fix for the same?
>
>Thanks in advance!
>
>Regards,
>Aakash
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From m||uj|@b @end|ng |rom gm@||@com  Thu Sep  6 15:12:51 2018
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Thu, 6 Sep 2018 15:12:51 +0200
Subject: [R] Marginal effects with plm
In-Reply-To: <CA+vqiLGH5Ybr43mnVkEzt4cn6HworjLy=rf6ZkhYCmiJV9VDMQ@mail.gmail.com>
References: <CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
 <CA+vqiLGH5Ybr43mnVkEzt4cn6HworjLy=rf6ZkhYCmiJV9VDMQ@mail.gmail.com>
Message-ID: <CAMLwc7MbzuJ9dtbjrh+ud8CX_hGPm6zLyGUb6QGFH1Ukan4t=w@mail.gmail.com>

Dear Ista,

Thanks for your reply. I tried both "prediction" and "margins" but neither
of them seem to work  with plm.

Sincerely,

Milu

On Thu, Sep 6, 2018 at 3:04 PM Ista Zahn <istazahn at gmail.com> wrote:

> You might be interested in the "prediction" and "margins" packages.
>
> --Ista
>
> On Wed, Sep 5, 2018 at 6:30 PM Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Dear all,
> >
> > I am running the following panel regression;
> >
> > plm1 <- plm(formula = log(y) ~ x1 + I(x1^2) + heat*debt_dummy + tt, data
> =
> > df, index=c("region","year"))
> >
> > where 'df' is a pdata.frame. I would like to obtain marginal effects of
> 'y'
> > for the variable 'x1'. I have tried the packages 'prediction' and
> 'margins'
> > without luck.
> >
> > Is it possible to obtain marginal effects with 'plm'? Any help will be
> > highly appreciated. Thank you.
> >
> > Error in UseMethod("predict") :
> >   no applicable method for 'predict' applied to an object of class
> > "c('plm', 'panelmodel')"
> >
> > Sincerely,
> >
> > Milu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep  6 15:24:14 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 6 Sep 2018 13:24:14 +0000
Subject: [R] Query on read.xls function in gdata
In-Reply-To: <CAEd2DYJHBR9h_jGhurWUECMxntRrWepfa28Gfir=vn6R+kuf_A@mail.gmail.com>
References: <CAEd2DYJkz1n7ozF9qOqNen01dfo7+MUhpLj3RfU8WUN8+pAHmA@mail.gmail.com>
 <CAEd2DYL6BLMC8jMr-Pst6Q-PXH0r2LApoL2adJxmhNfE84sw6g@mail.gmail.com>
 <CAEd2DYKb0QmkxLUF0_LGnu46Gjbpz+2aKUj7JvhFCzFcV_Hdsw@mail.gmail.com>
 <CAEd2DYLT+AHmpO0+uESQ4ygVMPeJySrxh20xvxw=9TH1PB0wfA@mail.gmail.com>
 <CAEd2DYKO7HoTtMLP_t=RGBC4B9AjKrfThHBZXRajnrC=OPw2dA@mail.gmail.com>
 <CAEd2DY+cundHG_EhfFWx9qvRRdFNEdA6z-vSd0=2P5X1gwVizw@mail.gmail.com>
 <CAEd2DY+3ShFOqeVaxMCwZnkvW5zTdqQJMsjA6ywBVpbMqdO7Cg@mail.gmail.com>
 <CAEd2DYL5wpPEC_te=mF+1CV34Mo7N+G_YQ5H=xdNED97ifynkA@mail.gmail.com>
 <1a746e7561a24a12ab986159a88273ed@SRVEXCHCM1302.precheza.cz>
 <CAEd2DYJHBR9h_jGhurWUECMxntRrWepfa28Gfir=vn6R+kuf_A@mail.gmail.com>
Message-ID: <6e7e9ef233524d33afec1689ba8ce106@SRVEXCHCM1302.precheza.cz>

Hi

You need to help yourself. My guess is that you did not tell to read_excel function where is your excel file.

When the file is in working directory it works seamlessly.

> library(readxl)
> read_excel("ebc.xlsx")
# A tibble: 8 x 16
  material   Rok osoby    `8oh` `8ohg` `5ohm`  otyr `3tyr`   mda   hhe   hne
  <chr>    <dbl> <chr>    <dbl>  <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>
1 tio2     2012. vyroba     25.    35.    25.   38.    42.   40.   40.   40.
2 tio2     2013. vyroba     38.    46.    35.   45.    48.   45.   55.   45.
3 tio2     2012. kontrola   10.    12.    12.   28.    14.   20.   15.   15.
4 tio2     2013. kontrola   17.    15.    17.   18.    20.   20.   15.   20.
5 fe2o3    2013. vyroba     28.    32.    25.   28.    29.   32.   30.   32.
6 fe2o3    2013. kontrola   17.    15.    17.   18.    20.   20.   17.   19.
7 kompozit 2016. vyroba     28.    37.    28.   32.    32.   25.   25.   25.
8 kompozit 2016. kontrola   20.    20.    20.   22.    22.   18.   20.   20.
# ... with 5 more variables: `8iso` <dbl>, ltb4 <dbl>, ltc4 <dbl>, ltd4 <dbl>,
#   lte4 <dbl>
>

You should either to disclose to read function where is your excel file or change working directory or copy excel file to your working directory, whatever is easiest and most convenient to you.

Cheers
Petr


From: Aakash Kumar <ssaakash at gmail.com>
Sent: Thursday, September 6, 2018 2:48 PM
To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
Subject: RE: [R] Query on read.xls function in gdata

Thanks for the suggestion, Petr.

I did try using read_xls and read_excel functions, but I got an error :

"Error in read_fun : Failed to open .xls file"

The file can be manually opened though.

It would be very helpful if you could help me out with this.

Thanks.

Regards,
Aakash


On 06-Sep-2018 17:00, "PIKAL Petr" <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

If you do not need to stick with gdata you could try package readxl, it does not need any further packages.

https://cran.r-project.org/web/packages/readxl/readxl.pdf

It results in tibble data but change to data.frame is easy.

Cheers
Petr
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Aakash Kumar
> Sent: Thursday, September 6, 2018 12:43 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Query on read.xls function in gdata
>
> Hi Team,
>
> I am trying to read in .xls files in R using read.xls function present in gdata
> package. I have installed the required perl dependencies as well.
> Yet, I am facing the following error.
>
> "*Error in xls2sep : Intermediate file is missing*"
>
> Could someone please help me out understanding the cause and if possible, a
> fix for the same?
>
> Thanks in advance!
>
> Regards,
> Aakash
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Thu Sep  6 16:03:07 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 6 Sep 2018 14:03:07 +0000
Subject: [R] Marginal effects with plm
In-Reply-To: <CAMLwc7N9HL7z53vFUxvPweKHnJ9oVMf0sFVF2Wqtfz3T=rx=mQ@mail.gmail.com>
References: <8173_1536186629_w85MUShS008624_CAMLwc7MvPWW-JM9bGi4SpLD4E-caPy4O+nTzxHPvm6=jtNYGyQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7B26@FHSDB2D11-2.csu.mcmaster.ca>
 <CAMLwc7OGY2cfy0ruwPNwCD-QnAJ0ePqf+6H0UBjAF4PeR3NcuQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368A7D2B@FHSDB2D11-2.csu.mcmaster.ca>
 <CAMLwc7N9HL7z53vFUxvPweKHnJ9oVMf0sFVF2Wqtfz3T=rx=mQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368A7EA5@FHSDB2D11-2.csu.mcmaster.ca>

Dear Milu,

I get the same error as you with this example -- I tried a different plm model -- which of course is why a reproducible example is a good idea.

Here's where the error is:

----------- snip -----------

> Ef.hd <- Effect(c("pc", "emp", "unemp"), zz)
Error in UseMethod("droplevels") : 
  no applicable method for 'droplevels' applied to an object of class "NULL"
> traceback()
10: droplevels(index)
9: model.frame.pFormula(formula = log(gsp) ~ log(pcap) + log(pc) + 
       log(emp) + unemp, data = Produc, drop.unused.levels = TRUE)
8: stats::model.frame(formula = log(gsp) ~ log(pcap) + log(pc) + 
       log(emp) + unemp, data = Produc, drop.unused.levels = TRUE)
7: eval(mf, parent.frame())
6: eval(mf, parent.frame())
5: glm(formula = log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, 
       data = Produc, control = list(epsilon = 1, maxit = 1, trace = FALSE))
4: eval(cl)
3: eval(cl)
2: Effect.default(c("pc", "emp", "unemp"), zz)
1: Effect(c("pc", "emp", "unemp"), zz)

----------- snip -----------

So the error is in model.frame.pFormula(), which is from the plm package. It would probably require substantial effort to get this to work.

Best,
 John


> -----Original Message-----
> From: Miluji Sb [mailto:milujisb at gmail.com]
> Sent: Thursday, September 6, 2018 8:52 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Marginal effects with plm
> 
> Dear John,
> 
> Apologies for not providing reproducible example. I just tried with a
> plm example but ran into the same issue;
> 
> library(plm)
> data("Produc", package = "plm")
> zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data =
> Produc, index = c("state","year"))
> 
> Ef.hd <- Effect(c("pc", "emp", "unemp"), zz)
> 
> Error in UseMethod("droplevels") :
>   no applicable method for 'droplevels' applied to an object of class
> "NULL"
> 
> What am I doing wrong? Thanks again.
> 
> Sincerely,
> 
> Milu

From @k@h@y_e4 @end|ng |rom hotm@||@com  Fri Sep  7 10:26:22 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Fri, 7 Sep 2018 08:26:22 +0000
Subject: [R] histogram in GNU R....
Message-ID: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I am running R on Linux AWS ec2 instance.
When I try to create a histogram in it, I am running into problems:

> xht <- c(1,2,3,4,5,6,7,8,9,10)
>  hist(xht)
>

when I type hist(xht), it goes to the next prompt. More importantly, there is no error message. So, the most probable conclusion is that the command gets executed. But there is no pop up screen with a histogram, and nothing else...

whats going on?

How can I circumvent the help of histogram(which is not available in GNU R)? summary(xht) would help, but not much. Any other function that can give information, in LINUX R, that a histogram gives, in LINUX CLI?

Very many thanks for your time and effort...
Yours sincerely,
AKSHAYM KULKARNI

	[[alternative HTML version deleted]]



From kry|ov@r00t @end|ng |rom gm@||@com  Fri Sep  7 10:56:07 2018
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 7 Sep 2018 11:56:07 +0300
Subject: [R] histogram in GNU R....
In-Reply-To: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <20180907115607.46c7857b@Tarkus>

On Fri, 7 Sep 2018 08:26:22 +0000
akshay kulkarni <akshay_e4 at hotmail.com> wrote:

> when I type hist(xht), it goes to the next prompt. More importantly,
> there is no error message. So, the most probable conclusion is that
> the command gets executed

Yes, hist() returns its value invisibly (try typing "? invisible" in
the R prompt without the quotes), which means that you don't see it, but
you can assign it to a variable and then view as usual:

> xht <- c(1,2,3,4,5,6,7,8,9,10)
> hxt <- hist(xht)
> hxt

You can also use the following trick:

> (hist(xht))

to see the invisible returned value without assigning it to a temporary
variable.

> But there is no pop up screen with a histogram, and nothing else...

As to why you cannot see a plot, it depends a lot on your setup. For
example, how exactly do you connect to the R instance running at AWS?
If you use plain SSH from your own Linux machine, try `ssh -X` to allow
the remote server to connect to the X graphics system on your machine
and display windows (alas, it gets very slow). What does `dev.cur()`
show after you run `hist(xht)`? On my machine, when I start R with no
available X connection, it automatically switches to the
non-interactive `pdf` graphics device; all plots get redirected to the
`Rplots.pdf` file in the current directory. Perhaps you can download
that file from the EC2 instance and view it locally?

-- 
Best regards,
Ivan



From pd@|gd @end|ng |rom gm@||@com  Fri Sep  7 11:08:03 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 7 Sep 2018 11:08:03 +0200
Subject: [R] histogram in GNU R....
In-Reply-To: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <C627B316-B767-42A1-B936-B5D64F35EEFD@gmail.com>

You are most likely plotting to a non-screen device. Check dev.list() after the hist(), and then the documentation for that device. It's probably pdf, and after quitting R, you should find that a file Rplots.pdf has been created.

-pd

> On 7 Sep 2018, at 10:26 , akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> 
> dear members,
>                             I am running R on Linux AWS ec2 instance.
> When I try to create a histogram in it, I am running into problems:
> 
>> xht <- c(1,2,3,4,5,6,7,8,9,10)
>> hist(xht)
>> 
> 
> when I type hist(xht), it goes to the next prompt. More importantly, there is no error message. So, the most probable conclusion is that the command gets executed. But there is no pop up screen with a histogram, and nothing else...
> 
> whats going on?
> 
> How can I circumvent the help of histogram(which is not available in GNU R)? summary(xht) would help, but not much. Any other function that can give information, in LINUX R, that a histogram gives, in LINUX CLI?
> 
> Very many thanks for your time and effort...
> Yours sincerely,
> AKSHAYM KULKARNI
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From deep@m@hm@||@c @end|ng |rom gm@||@com  Fri Sep  7 12:08:20 2018
From: deep@m@hm@||@c @end|ng |rom gm@||@com (Deepa)
Date: Fri, 7 Sep 2018 15:38:20 +0530
Subject: [R] Efficient way of loading files in R
Message-ID: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>

Hello,

I am using a bioconductor package in R.
The command that I use reads the contents of a file downloaded from a
database and creates an expression object.

The syntax works perfectly fine when the input size is of 10 MB. Whereas,
when the file size is around 40MB the object isn't created.

Is there an efficient way of loading a large input file to create the
expression object?

This is my code,


library(gcrma)
library(limma)
library(biomaRt)
library(GEOquery)
library(Biobase)
require(GEOquery)
require(Biobase)
gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB

##gseEset2 doesn't load and isn't created

Many thanks

	[[alternative HTML version deleted]]



From deep@m@hm@||@c @end|ng |rom gm@||@com  Fri Sep  7 12:10:30 2018
From: deep@m@hm@||@c @end|ng |rom gm@||@com (Deepa)
Date: Fri, 7 Sep 2018 15:40:30 +0530
Subject: [R] Efficient way of loading files in R
In-Reply-To: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
Message-ID: <CAGchuN5Hq0Zf4SvqaSudFXqED_ESoFWMpqDnouD53h7rB1bV9Q@mail.gmail.com>

The following is the system configuration:
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                4
On-line CPU(s) list:   0-3
Thread(s) per core:    2
Core(s) per socket:    2
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 142
Model name:            Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz
Stepping:              9
CPU MHz:               2844.008
CPU max MHz:           3500.0000
CPU min MHz:           400.0000
BogoMIPS:              5808.00
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              4096K
NUMA node0 CPU(s):     0-3


On Fri, Sep 7, 2018 at 3:38 PM Deepa <deepamahm.iisc at gmail.com> wrote:

> Hello,
>
> I am using a bioconductor package in R.
> The command that I use reads the contents of a file downloaded from a
> database and creates an expression object.
>
> The syntax works perfectly fine when the input size is of 10 MB. Whereas,
> when the file size is around 40MB the object isn't created.
>
> Is there an efficient way of loading a large input file to create the
> expression object?
>
> This is my code,
>
>
> library(gcrma)
> library(limma)
> library(biomaRt)
> library(GEOquery)
> library(Biobase)
> require(GEOquery)
> require(Biobase)
> gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
> gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
>
> ##gseEset2 doesn't load and isn't created
>
> Many thanks
>
>
>

	[[alternative HTML version deleted]]



From pro|@@m|t@m|tt@| @end|ng |rom gm@||@com  Fri Sep  7 12:11:58 2018
From: pro|@@m|t@m|tt@| @end|ng |rom gm@||@com (Amit Mittal)
Date: Fri, 7 Sep 2018 15:41:58 +0530
Subject: [R] Efficient way of loading files in R
In-Reply-To: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
Message-ID: <CAP8zaQCaC49nMfgGJqWMYDjLL+gg8weM4h5V-87bnr+KQoBafQ@mail.gmail.com>

getgeo() seems to be a custom routine. Import the file in reader and
confirm that's a CSV file from Excel. If this is a non standard input,
custom subroutine is creating new constraints. Usually R has no problem
till workspace is 1 gb

On Fri 7 Sep, 2018, 15:38 Deepa, <deepamahm.iisc at gmail.com> wrote:

> Hello,
>
> I am using a bioconductor package in R.
> The command that I use reads the contents of a file downloaded from a
> database and creates an expression object.
>
> The syntax works perfectly fine when the input size is of 10 MB. Whereas,
> when the file size is around 40MB the object isn't created.
>
> Is there an efficient way of loading a large input file to create the
> expression object?
>
> This is my code,
>
>
> library(gcrma)
> library(limma)
> library(biomaRt)
> library(GEOquery)
> library(Biobase)
> require(GEOquery)
> require(Biobase)
> gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
> gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
>
> ##gseEset2 doesn't load and isn't created
>
> Many thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 

______________________________

Amit Mittal
Pursuing Ph.D. in Finance and Accounting
Indian Institute of Management, Lucknow
Visit my SSRN author page:
http://ssrn.com/author=2665511
* Top 10% Downloaded Author on SSRN
Mob: +91 7525023664

This message has been sent from a mobile device. I may contact you again.

_________________

	[[alternative HTML version deleted]]



From mtmorg@n@b|oc @end|ng |rom gm@||@com  Fri Sep  7 12:14:58 2018
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Fri, 7 Sep 2018 06:14:58 -0400
Subject: [R] Efficient way of loading files in R
In-Reply-To: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
Message-ID: <0b51bc32-4a72-7907-fcb3-8701bf5b4da1@gmail.com>

Ask on the Bioconductor support site https://support.bioconductor.org

Provide (on the support site) the output of the R commands

   library(GEOquery)
   sessionInfo()

Also include (copy and paste) the output of the command that fails. I have

 > gseEset2 <- getGEO('GSE76896')[[1]]
Found 1 file(s)
GSE76896_series_matrix.txt.gz
trying URL 
'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE76nnn/GSE76896/matrix/GSE76896_series_matrix.txt.gz'
Content type 'application/x-gzip' length 40561936 bytes (38.7 MB)
==================================================
downloaded 38.7 MB

Parsed with column specification:
cols(
   .default = col_double(),
   ID_REF = col_character()
)
See spec(...) for full column specifications.
|=================================================================| 100% 
   84 MB
File stored at:
/tmp/Rtmpe4NWji/GPL570.soft
|=================================================================| 100% 
   75 MB
 > sessionInfo()
R version 3.5.1 Patched (2018-08-22 r75177)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.5 LTS

Matrix products: default
BLAS: /home/mtmorgan/bin/R-3-5-branch/lib/libRblas.so
LAPACK: /home/mtmorgan/bin/R-3-5-branch/lib/libRlapack.so

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] bindrcpp_0.2.2      GEOquery_2.49.1     Biobase_2.41.2
[4] BiocGenerics_0.27.1 BiocManager_1.30.2

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.18     tidyr_0.8.1      crayon_1.3.4     dplyr_0.7.6
  [5] assertthat_0.2.0 R6_2.2.2         magrittr_1.5     pillar_1.3.0
  [9] stringi_1.2.4    rlang_0.2.2      curl_3.2         limma_3.37.4
[13] xml2_1.2.0       tools_3.5.1      readr_1.1.1      glue_1.3.0
[17] purrr_0.2.5      hms_0.4.2        compiler_3.5.1   pkgconfig_2.0.2
[21] tidyselect_0.2.4 bindr_0.1.1      tibble_1.4.2

On 09/07/2018 06:08 AM, Deepa wrote:
> Hello,
> 
> I am using a bioconductor package in R.
> The command that I use reads the contents of a file downloaded from a
> database and creates an expression object.
> 
> The syntax works perfectly fine when the input size is of 10 MB. Whereas,
> when the file size is around 40MB the object isn't created.
> 
> Is there an efficient way of loading a large input file to create the
> expression object?
> 
> This is my code,
> 
> 
> library(gcrma)
> library(limma)
> library(biomaRt)
> library(GEOquery)
> library(Biobase)
> require(GEOquery)
> require(Biobase)
> gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
> gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
> 
> ##gseEset2 doesn't load and isn't created
> 
> Many thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From deep@m@hm@||@c @end|ng |rom gm@||@com  Fri Sep  7 12:35:24 2018
From: deep@m@hm@||@c @end|ng |rom gm@||@com (Deepa)
Date: Fri, 7 Sep 2018 16:05:24 +0530
Subject: [R] Efficient way of loading files in R
In-Reply-To: <0b51bc32-4a72-7907-fcb3-8701bf5b4da1@gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
 <0b51bc32-4a72-7907-fcb3-8701bf5b4da1@gmail.com>
Message-ID: <CAGchuN4hOFCW0S4so7hCjwM1kBTxAWbygWp2jgJgMKjFRZ4pnA@mail.gmail.com>

I already posted a similar issue on bioconductor.
https://support.bioconductor.org/p/112607/#112634
Couldn't find a solution.


On Fri, Sep 7, 2018 at 3:45 PM Martin Morgan <mtmorgan.bioc at gmail.com>
wrote:

> Ask on the Bioconductor support site https://support.bioconductor.org
>
> Provide (on the support site) the output of the R commands
>
>    library(GEOquery)
>    sessionInfo()
>
> Also include (copy and paste) the output of the command that fails. I have
>
>  > gseEset2 <- getGEO('GSE76896')[[1]]
> Found 1 file(s)
> GSE76896_series_matrix.txt.gz
> trying URL
> '
> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE76nnn/GSE76896/matrix/GSE76896_series_matrix.txt.gz
> '
> Content type 'application/x-gzip' length 40561936 bytes (38.7 MB)
> ==================================================
> downloaded 38.7 MB
>
> Parsed with column specification:
> cols(
>    .default = col_double(),
>    ID_REF = col_character()
> )
> See spec(...) for full column specifications.
> |=================================================================| 100%
>    84 MB
> File stored at:
> /tmp/Rtmpe4NWji/GPL570.soft
> |=================================================================| 100%
>    75 MB
>  > sessionInfo()
> R version 3.5.1 Patched (2018-08-22 r75177)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.5 LTS
>
> Matrix products: default
> BLAS: /home/mtmorgan/bin/R-3-5-branch/lib/libRblas.so
> LAPACK: /home/mtmorgan/bin/R-3-5-branch/lib/libRlapack.so
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] parallel  stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> other attached packages:
> [1] bindrcpp_0.2.2      GEOquery_2.49.1     Biobase_2.41.2
> [4] BiocGenerics_0.27.1 BiocManager_1.30.2
>
> loaded via a namespace (and not attached):
>   [1] Rcpp_0.12.18     tidyr_0.8.1      crayon_1.3.4     dplyr_0.7.6
>   [5] assertthat_0.2.0 R6_2.2.2         magrittr_1.5     pillar_1.3.0
>   [9] stringi_1.2.4    rlang_0.2.2      curl_3.2         limma_3.37.4
> [13] xml2_1.2.0       tools_3.5.1      readr_1.1.1      glue_1.3.0
> [17] purrr_0.2.5      hms_0.4.2        compiler_3.5.1   pkgconfig_2.0.2
> [21] tidyselect_0.2.4 bindr_0.1.1      tibble_1.4.2
>
> On 09/07/2018 06:08 AM, Deepa wrote:
> > Hello,
> >
> > I am using a bioconductor package in R.
> > The command that I use reads the contents of a file downloaded from a
> > database and creates an expression object.
> >
> > The syntax works perfectly fine when the input size is of 10 MB. Whereas,
> > when the file size is around 40MB the object isn't created.
> >
> > Is there an efficient way of loading a large input file to create the
> > expression object?
> >
> > This is my code,
> >
> >
> > library(gcrma)
> > library(limma)
> > library(biomaRt)
> > library(GEOquery)
> > library(Biobase)
> > require(GEOquery)
> > require(Biobase)
> > gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
> > gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
> >
> > ##gseEset2 doesn't load and isn't created
> >
> > Many thanks
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]



From deep@m@hm@||@c @end|ng |rom gm@||@com  Fri Sep  7 12:38:08 2018
From: deep@m@hm@||@c @end|ng |rom gm@||@com (Deepa)
Date: Fri, 7 Sep 2018 16:08:08 +0530
Subject: [R] Efficient way of loading files in R
In-Reply-To: <CAGchuN4hOFCW0S4so7hCjwM1kBTxAWbygWp2jgJgMKjFRZ4pnA@mail.gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
 <0b51bc32-4a72-7907-fcb3-8701bf5b4da1@gmail.com>
 <CAGchuN4hOFCW0S4so7hCjwM1kBTxAWbygWp2jgJgMKjFRZ4pnA@mail.gmail.com>
Message-ID: <CAGchuN62A_OeOzhd65Wo6gP_ZQiZ-RXb91ocjQwXzQVA3ZFtHA@mail.gmail.com>

I am also providing the output that I obtain for your kind reference,

gseEset2 <- getGEO('GSE76896', destdir = "data/")[[1]]
Found 1 file(s)
GSE76896_series_matrix.txt.gz
Using locally cached version: /data//GSE76896_series_matrix.txt.gz
Parsed with column specification:
cols(
  .default = col_double(),
  ID_REF = col_character()
)
See spec(...) for full column specifications.
Using locally cached version of GPL570 found here:
/data//GPL570.soft

After this I don't see any output. I had to forcefully stop the execution.

On Fri, Sep 7, 2018 at 4:05 PM Deepa <deepamahm.iisc at gmail.com> wrote:

> I already posted a similar issue on bioconductor.
> https://support.bioconductor.org/p/112607/#112634
> Couldn't find a solution.
>
>
> On Fri, Sep 7, 2018 at 3:45 PM Martin Morgan <mtmorgan.bioc at gmail.com>
> wrote:
>
>> Ask on the Bioconductor support site https://support.bioconductor.org
>>
>> Provide (on the support site) the output of the R commands
>>
>>    library(GEOquery)
>>    sessionInfo()
>>
>> Also include (copy and paste) the output of the command that fails. I have
>>
>>  > gseEset2 <- getGEO('GSE76896')[[1]]
>> Found 1 file(s)
>> GSE76896_series_matrix.txt.gz
>> trying URL
>> '
>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE76nnn/GSE76896/matrix/GSE76896_series_matrix.txt.gz
>> '
>> Content type 'application/x-gzip' length 40561936 bytes (38.7 MB)
>> ==================================================
>> downloaded 38.7 MB
>>
>> Parsed with column specification:
>> cols(
>>    .default = col_double(),
>>    ID_REF = col_character()
>> )
>> See spec(...) for full column specifications.
>> |=================================================================| 100%
>>    84 MB
>> File stored at:
>> /tmp/Rtmpe4NWji/GPL570.soft
>> |=================================================================| 100%
>>    75 MB
>>  > sessionInfo()
>> R version 3.5.1 Patched (2018-08-22 r75177)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 16.04.5 LTS
>>
>> Matrix products: default
>> BLAS: /home/mtmorgan/bin/R-3-5-branch/lib/libRblas.so
>> LAPACK: /home/mtmorgan/bin/R-3-5-branch/lib/libRlapack.so
>>
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] parallel  stats     graphics  grDevices utils     datasets  methods
>> [8] base
>>
>> other attached packages:
>> [1] bindrcpp_0.2.2      GEOquery_2.49.1     Biobase_2.41.2
>> [4] BiocGenerics_0.27.1 BiocManager_1.30.2
>>
>> loaded via a namespace (and not attached):
>>   [1] Rcpp_0.12.18     tidyr_0.8.1      crayon_1.3.4     dplyr_0.7.6
>>   [5] assertthat_0.2.0 R6_2.2.2         magrittr_1.5     pillar_1.3.0
>>   [9] stringi_1.2.4    rlang_0.2.2      curl_3.2         limma_3.37.4
>> [13] xml2_1.2.0       tools_3.5.1      readr_1.1.1      glue_1.3.0
>> [17] purrr_0.2.5      hms_0.4.2        compiler_3.5.1   pkgconfig_2.0.2
>> [21] tidyselect_0.2.4 bindr_0.1.1      tibble_1.4.2
>>
>> On 09/07/2018 06:08 AM, Deepa wrote:
>> > Hello,
>> >
>> > I am using a bioconductor package in R.
>> > The command that I use reads the contents of a file downloaded from a
>> > database and creates an expression object.
>> >
>> > The syntax works perfectly fine when the input size is of 10 MB.
>> Whereas,
>> > when the file size is around 40MB the object isn't created.
>> >
>> > Is there an efficient way of loading a large input file to create the
>> > expression object?
>> >
>> > This is my code,
>> >
>> >
>> > library(gcrma)
>> > library(limma)
>> > library(biomaRt)
>> > library(GEOquery)
>> > library(Biobase)
>> > require(GEOquery)
>> > require(Biobase)
>> > gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
>> > gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
>> >
>> > ##gseEset2 doesn't load and isn't created
>> >
>> > Many thanks
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>

	[[alternative HTML version deleted]]



From deep@m@hm@||@c @end|ng |rom gm@||@com  Fri Sep  7 12:49:48 2018
From: deep@m@hm@||@c @end|ng |rom gm@||@com (Deepa)
Date: Fri, 7 Sep 2018 16:19:48 +0530
Subject: [R] Efficient way of loading files in R
In-Reply-To: <CAGchuN62A_OeOzhd65Wo6gP_ZQiZ-RXb91ocjQwXzQVA3ZFtHA@mail.gmail.com>
References: <CAGchuN4cZ47rWiMpz0e5C6kRc3X8AetuJH_KQhgi3gq9uHaepQ@mail.gmail.com>
 <0b51bc32-4a72-7907-fcb3-8701bf5b4da1@gmail.com>
 <CAGchuN4hOFCW0S4so7hCjwM1kBTxAWbygWp2jgJgMKjFRZ4pnA@mail.gmail.com>
 <CAGchuN62A_OeOzhd65Wo6gP_ZQiZ-RXb91ocjQwXzQVA3ZFtHA@mail.gmail.com>
Message-ID: <CAGchuN5noOvYohRj=EsXdvg44si8VrsE3Ds8UtH0Tcc36MhyWw@mail.gmail.com>

Martin,

I forgot to mention.

The same command works fine when I try,gseEset2 <- getGEO('GSE76896') ,
without saving the file to a destination folder .




Output:

Found 1 file(s)
GSE76896_series_matrix.txt.gz
trying URL '
https://ftp.ncbi.nlm.nih.gov/geo/series/GSE76nnn/GSE76896/matrix/GSE76896_series_matrix.txt.gz
'
Content type 'application/x-gzip' length 40561936 bytes (38.7 MB)
==================================================
downloaded 38.7 MB

Parsed with column specification:
cols(
  .default = col_double(),
  ID_REF = col_character()
)
See spec(...) for full column specifications.
|=================================================================| 100%
 84 MB
File stored at:
/tmp/RtmprygqGb/GPL570.soft
|=================================================================| 100%
 80 MB
|=================================================================| 100%
 75 MB

The problem occurs when I fetch the file from destination folder using
gseEset2 <- getGEO('GSE76896', destdir = "/data/")[[1]]

Found 1 file(s)
GSE76896_series_matrix.txt.gz
Using locally cached version: /data//GSE76896_series_matrix.txt.gz
Parsed with column specification:
cols(
  .default = col_double(),
  ID_REF = col_character()
)
See spec(...) for full column specifications.
|=================================================================| 100%
 84 MB
Using locally cached version of GPL570 found here:
/data//GPL570.soft
^C


On Fri, Sep 7, 2018 at 4:08 PM Deepa <deepamahm.iisc at gmail.com> wrote:

> I am also providing the output that I obtain for your kind reference,
>
> gseEset2 <- getGEO('GSE76896', destdir = "data/")[[1]]
> Found 1 file(s)
> GSE76896_series_matrix.txt.gz
> Using locally cached version: /data//GSE76896_series_matrix.txt.gz
> Parsed with column specification:
> cols(
>   .default = col_double(),
>   ID_REF = col_character()
> )
> See spec(...) for full column specifications.
> Using locally cached version of GPL570 found here:
> /data//GPL570.soft
>
> After this I don't see any output. I had to forcefully stop the execution.
>
> On Fri, Sep 7, 2018 at 4:05 PM Deepa <deepamahm.iisc at gmail.com> wrote:
>
>> I already posted a similar issue on bioconductor.
>> https://support.bioconductor.org/p/112607/#112634
>> Couldn't find a solution.
>>
>>
>> On Fri, Sep 7, 2018 at 3:45 PM Martin Morgan <mtmorgan.bioc at gmail.com>
>> wrote:
>>
>>> Ask on the Bioconductor support site https://support.bioconductor.org
>>>
>>> Provide (on the support site) the output of the R commands
>>>
>>>    library(GEOquery)
>>>    sessionInfo()
>>>
>>> Also include (copy and paste) the output of the command that fails. I
>>> have
>>>
>>>  > gseEset2 <- getGEO('GSE76896')[[1]]
>>> Found 1 file(s)
>>> GSE76896_series_matrix.txt.gz
>>> trying URL
>>> '
>>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE76nnn/GSE76896/matrix/GSE76896_series_matrix.txt.gz
>>> '
>>> Content type 'application/x-gzip' length 40561936 bytes (38.7 MB)
>>> ==================================================
>>> downloaded 38.7 MB
>>>
>>> Parsed with column specification:
>>> cols(
>>>    .default = col_double(),
>>>    ID_REF = col_character()
>>> )
>>> See spec(...) for full column specifications.
>>> |=================================================================| 100%
>>>    84 MB
>>> File stored at:
>>> /tmp/Rtmpe4NWji/GPL570.soft
>>> |=================================================================| 100%
>>>    75 MB
>>>  > sessionInfo()
>>> R version 3.5.1 Patched (2018-08-22 r75177)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 16.04.5 LTS
>>>
>>> Matrix products: default
>>> BLAS: /home/mtmorgan/bin/R-3-5-branch/lib/libRblas.so
>>> LAPACK: /home/mtmorgan/bin/R-3-5-branch/lib/libRlapack.so
>>>
>>> locale:
>>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] parallel  stats     graphics  grDevices utils     datasets  methods
>>> [8] base
>>>
>>> other attached packages:
>>> [1] bindrcpp_0.2.2      GEOquery_2.49.1     Biobase_2.41.2
>>> [4] BiocGenerics_0.27.1 BiocManager_1.30.2
>>>
>>> loaded via a namespace (and not attached):
>>>   [1] Rcpp_0.12.18     tidyr_0.8.1      crayon_1.3.4     dplyr_0.7.6
>>>   [5] assertthat_0.2.0 R6_2.2.2         magrittr_1.5     pillar_1.3.0
>>>   [9] stringi_1.2.4    rlang_0.2.2      curl_3.2         limma_3.37.4
>>> [13] xml2_1.2.0       tools_3.5.1      readr_1.1.1      glue_1.3.0
>>> [17] purrr_0.2.5      hms_0.4.2        compiler_3.5.1   pkgconfig_2.0.2
>>> [21] tidyselect_0.2.4 bindr_0.1.1      tibble_1.4.2
>>>
>>> On 09/07/2018 06:08 AM, Deepa wrote:
>>> > Hello,
>>> >
>>> > I am using a bioconductor package in R.
>>> > The command that I use reads the contents of a file downloaded from a
>>> > database and creates an expression object.
>>> >
>>> > The syntax works perfectly fine when the input size is of 10 MB.
>>> Whereas,
>>> > when the file size is around 40MB the object isn't created.
>>> >
>>> > Is there an efficient way of loading a large input file to create the
>>> > expression object?
>>> >
>>> > This is my code,
>>> >
>>> >
>>> > library(gcrma)
>>> > library(limma)
>>> > library(biomaRt)
>>> > library(GEOquery)
>>> > library(Biobase)
>>> > require(GEOquery)
>>> > require(Biobase)
>>> > gseEset1 <- getGEO('GSE53454')[[1]] #filesize 10MB
>>> > gseEset2 <- getGEO('GSE76896')[[1]] #file size 40MB
>>> >
>>> > ##gseEset2 doesn't load and isn't created
>>> >
>>> > Many thanks
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Sep  7 18:17:56 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 7 Sep 2018 16:17:56 +0000
Subject: [R] histogram in GNU R....
Message-ID: <09BA3BF7-FE7E-49E7-BA91-974E1BCD672B@llnl.gov>

In addition to the other suggestions, try typing

  x11()

before using hist().

That *should* start a graphics window. If it does not, then type

  capabilities()

and see if "X11" is TRUE.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/7/18, 1:26 AM, "R-help on behalf of akshay kulkarni" <r-help-bounces at r-project.org on behalf of akshay_e4 at hotmail.com> wrote:

    dear members,
                                 I am running R on Linux AWS ec2 instance.
    When I try to create a histogram in it, I am running into problems:
    
    > xht <- c(1,2,3,4,5,6,7,8,9,10)
    >  hist(xht)
    >
    
    when I type hist(xht), it goes to the next prompt. More importantly, there is no error message. So, the most probable conclusion is that the command gets executed. But there is no pop up screen with a histogram, and nothing else...
    
    whats going on?
    
    How can I circumvent the help of histogram(which is not available in GNU R)? summary(xht) would help, but not much. Any other function that can give information, in LINUX R, that a histogram gives, in LINUX CLI?
    
    Very many thanks for your time and effort...
    Yours sincerely,
    AKSHAYM KULKARNI
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From wdun|@p @end|ng |rom t|bco@com  Fri Sep  7 19:30:31 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 7 Sep 2018 10:30:31 -0700
Subject: [R] histogram in GNU R....
In-Reply-To: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcYqj0hnC1HymcoNSYnJzAABe4Gh3c8huQ412bW7Stp6yw@mail.gmail.com>

You may have to install X11 stuff to your ec2 instance.  E.g., googling for
"ec2 X11 forwarding" showed things like the following:

Re: X11 forwarding to access AWS EC2 Linux instance
Posted by: wilderfield
<https://forums.aws.amazon.com/profile.jspa?userID=433982>
Posted on: Apr 5, 2018 11:31 AM
[image: in response to: LE M.]
<https://forums.aws.amazon.com/message.jspa?messageID=574740#574740> in
response to: LE M.
<https://forums.aws.amazon.com/message.jspa?messageID=574740#574740>
  [image: Click to reply to this thread]
<https://forums.aws.amazon.com/post!reply.jspa?messageID=841377> Reply
<https://forums.aws.amazon.com/post!reply.jspa?messageID=841377>
x11 <https://forums.aws.amazon.com/tags/x11>
sudo yum install xorg-x11-xauth

The above is all I needed to get X11 forwarding working over ssh

When ssh-ing to the instance, use the -X flag


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Sep 7, 2018 at 1:26 AM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                              I am running R on Linux AWS ec2 instance.
> When I try to create a histogram in it, I am running into problems:
>
> > xht <- c(1,2,3,4,5,6,7,8,9,10)
> >  hist(xht)
> >
>
> when I type hist(xht), it goes to the next prompt. More importantly, there
> is no error message. So, the most probable conclusion is that the command
> gets executed. But there is no pop up screen with a histogram, and nothing
> else...
>
> whats going on?
>
> How can I circumvent the help of histogram(which is not available in GNU
> R)? summary(xht) would help, but not much. Any other function that can give
> information, in LINUX R, that a histogram gives, in LINUX CLI?
>
> Very many thanks for your time and effort...
> Yours sincerely,
> AKSHAYM KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From peter@|@ng|e|der @end|ng |rom gm@||@com  Fri Sep  7 20:07:57 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Fri, 7 Sep 2018 11:07:57 -0700
Subject: [R] histogram in GNU R....
In-Reply-To: <CAF8bMcYqj0hnC1HymcoNSYnJzAABe4Gh3c8huQ412bW7Stp6yw@mail.gmail.com>
References: <SL2P216MB0091340B4F8D81F23013F49BC8000@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <CAF8bMcYqj0hnC1HymcoNSYnJzAABe4Gh3c8huQ412bW7Stp6yw@mail.gmail.com>
Message-ID: <CA+hbrhXb2ShM5vF+JvuUzGtoDYK-_a6kYa0aG9t6au6YGMJQGw@mail.gmail.com>

A simpler short term solution is to execute dev.off() and look for the plot
in file Rplots.pdf in the current directory. Depending on the OS of the
local computer, you should be able to point a file browser at the EC
instance and simply click the file to open in in a pdf viewer on the local
machine.

Peter

On Fri, Sep 7, 2018 at 10:31 AM William Dunlap via R-help <
r-help at r-project.org> wrote:

> You may have to install X11 stuff to your ec2 instance.  E.g., googling for
> "ec2 X11 forwarding" showed things like the following:
>
> Re: X11 forwarding to access AWS EC2 Linux instance
> Posted by: wilderfield
> <https://forums.aws.amazon.com/profile.jspa?userID=433982>
> Posted on: Apr 5, 2018 11:31 AM
> [image: in response to: LE M.]
> <https://forums.aws.amazon.com/message.jspa?messageID=574740#574740> in
> response to: LE M.
> <https://forums.aws.amazon.com/message.jspa?messageID=574740#574740>
>   [image: Click to reply to this thread]
> <https://forums.aws.amazon.com/post!reply.jspa?messageID=841377> Reply
> <https://forums.aws.amazon.com/post!reply.jspa?messageID=841377>
> x11 <https://forums.aws.amazon.com/tags/x11>
> sudo yum install xorg-x11-xauth
>
> The above is all I needed to get X11 forwarding working over ssh
>
> When ssh-ing to the instance, use the -X flag
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Sep 7, 2018 at 1:26 AM, akshay kulkarni <akshay_e4 at hotmail.com>
> wrote:
>
> > dear members,
> >                              I am running R on Linux AWS ec2 instance.
> > When I try to create a histogram in it, I am running into problems:
> >
> > > xht <- c(1,2,3,4,5,6,7,8,9,10)
> > >  hist(xht)
> > >
> >
> > when I type hist(xht), it goes to the next prompt. More importantly,
> there
> > is no error message. So, the most probable conclusion is that the command
> > gets executed. But there is no pop up screen with a histogram, and
> nothing
> > else...
> >
> > whats going on?
> >
> > How can I circumvent the help of histogram(which is not available in GNU
> > R)? summary(xht) would help, but not much. Any other function that can
> give
> > information, in LINUX R, that a histogram gives, in LINUX CLI?
> >
> > Very many thanks for your time and effort...
> > Yours sincerely,
> > AKSHAYM KULKARNI
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From D@v|d@Joubert @end|ng |rom uott@w@@c@  Fri Sep  7 19:40:58 2018
From: D@v|d@Joubert @end|ng |rom uott@w@@c@ (David Joubert)
Date: Fri, 7 Sep 2018 17:40:58 +0000
Subject: [R] Selecting random subset by ID
Message-ID: <YTOPR0101MB1531E8CDC94CA74A63B097D79A000@YTOPR0101MB1531.CANPRD01.PROD.OUTLOOK.COM>

Hello R users,

I am working with a large dataset, including roughly 50 000 sequential observations (variable "count") for 8000 individuals (variable "id"). The dataset is very unbalanced, meaning that some individuals have few observations and others have many. Because I plan on running Generalized Linear Models for panel data using pglm and the package has file size restrictions, I want to create 4 randomly selected subsets of 2500 individuals from the main dataset. What functions and code would I use to do this?

Thanks in advance,

David Joubert



	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep  7 21:00:07 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 7 Sep 2018 12:00:07 -0700
Subject: [R] Selecting random subset by ID
In-Reply-To: <YTOPR0101MB1531E8CDC94CA74A63B097D79A000@YTOPR0101MB1531.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1531E8CDC94CA74A63B097D79A000@YTOPR0101MB1531.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbR=pb71zL8D6Bz=hD7Ex7i4-sY==y5x7Eo_xXhhMhmbOQ@mail.gmail.com>

?sample

Should get you started

We expect you to first make an effort to learn about and write your
own code, rather than asking us to write it for you.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 7, 2018 at 11:38 AM David Joubert <David.Joubert at uottawa.ca> wrote:
>
> Hello R users,
>
> I am working with a large dataset, including roughly 50 000 sequential observations (variable "count") for 8000 individuals (variable "id"). The dataset is very unbalanced, meaning that some individuals have few observations and others have many. Because I plan on running Generalized Linear Models for panel data using pglm and the package has file size restrictions, I want to create 4 randomly selected subsets of 2500 individuals from the main dataset. What functions and code would I use to do this?
>
> Thanks in advance,
>
> David Joubert
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep  7 22:06:07 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 07 Sep 2018 13:06:07 -0700
Subject: [R] Selecting random subset by ID
In-Reply-To: <CAGxFJbR=pb71zL8D6Bz=hD7Ex7i4-sY==y5x7Eo_xXhhMhmbOQ@mail.gmail.com>
References: <YTOPR0101MB1531E8CDC94CA74A63B097D79A000@YTOPR0101MB1531.CANPRD01.PROD.OUTLOOK.COM>
 <CAGxFJbR=pb71zL8D6Bz=hD7Ex7i4-sY==y5x7Eo_xXhhMhmbOQ@mail.gmail.com>
Message-ID: <9CC23B91-1A1F-408F-8B7C-422CF2C1A10A@dcn.davis.ca.us>

IMO it is worth pointing out that you don't have to write code that solves your problem (else why have this list?) but this whole communication thing works best when you write code that creates a mock set of data that illustrates what you are starting from and some mock output.

The mock input can sometimes be the output of the dput function on a subset of your data, but in your case would probably be something more like

set.seed(42)
ids <- data.frame( id=1:8000, a1=rnorm(8000,0,1),n=sample(2:15,8000,replace=TRUE))
dta <- ids[rep(ids$id,ids$n),]
dta$a0 <- rnorm(nrow(dta),1,2)
dta$value <- with( dta, a0 + a1 )

where the exact way I approach making the data may not be exactly how your data is structured, but clarifying and avoiding that misunderstanding is exactly what you should try to address by learning how to do this when you ask your question.

You may find that reading the above helps you answer your own question, or you can confirm that this data set is close enough and show what code you tried starting with this data.

Oh, and by the way, sending your emails to this list formatted with html is a good way to corrupt your code examples because this list only forwards the plain text part of your email. Start with the plain text setting in your email program and avoid further miscommunication.

More on reproducible examples [1][2][3].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

On September 7, 2018 12:00:07 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>?sample
>
>Should get you started
>
>We expect you to first make an effort to learn about and write your
>own code, rather than asking us to write it for you.
>
>-- Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Fri, Sep 7, 2018 at 11:38 AM David Joubert
><David.Joubert at uottawa.ca> wrote:
>>
>> Hello R users,
>>
>> I am working with a large dataset, including roughly 50 000
>sequential observations (variable "count") for 8000 individuals
>(variable "id"). The dataset is very unbalanced, meaning that some
>individuals have few observations and others have many. Because I plan
>on running Generalized Linear Models for panel data using pglm and the
>package has file size restrictions, I want to create 4 randomly
>selected subsets of 2500 individuals from the main dataset. What
>functions and code would I use to do this?
>>
>> Thanks in advance,
>>
>> David Joubert
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep  7 23:19:18 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 7 Sep 2018 14:19:18 -0700 (PDT)
Subject: [R] Correctly applying aggregate.ts()
Message-ID: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>

   I've read ?aggregate and several blog posts on using aggregate() yet I
still haven't applied it correctly to my dataframe. The sample data are:

structure(list(sampdate = c("2005-01-01", "2005-01-02", "2005-01-03", 
"2005-01-04", "2005-01-05", "2005-01-06", "2005-01-07", "2005-01-08", 
"2005-01-09", "2005-01-10", "2005-01-11", "2005-01-12", "2005-01-13", 
"2005-01-14", "2005-01-15", "2005-01-16", "2005-01-17", "2005-01-18", 
"2005-01-19", "2005-01-20", "2005-01-21", "2005-01-22", "2005-01-23", 
"2005-01-24", "2005-01-25", "2005-01-26", "2005-01-27", "2005-01-28", 
"2005-01-29", "2005-01-30", "2005-01-31", "2005-02-01", "2005-02-02", 
"2005-02-03", "2005-02-04", "2005-02-05", "2005-02-06", "2005-02-07", 
"2005-02-08", "2005-02-09", "2005-02-10", "2005-02-11", "2005-02-12", 
"2005-02-13", "2005-02-14", "2005-02-15", "2005-02-16", "2005-02-17", 
"2005-02-18", "2005-02-19", "2005-02-20", "2005-02-21", "2005-02-22", 
"2005-02-23", "2005-02-24", "2005-02-25", "2005-02-26", "2005-02-27", 
"2005-02-28", "2005-03-01", "2005-03-02", "2005-03-03"), prcp = c(0.59, 
0.08, 0.1, 0, 0, 0.02, 0.05, 0.1, 0, 0.02, 0, 0.05, 0.2, 0, 0, 
0.5, 0.41, 0.84, 0.01, 0.1, 0.01, 0, 0, 0, 0, 0.21, 0.24, 0.13, 
1.12, 0.01, 0.09, 0, 0, 0, 0.35, 0.18, 0.65, 0.16, 0, 0, 0, 0, 
0.55, 0.21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.05, 
0.01, 0)), row.names = c(NA, 62L), class = "data.frame")

   What I need to learn how to do is to calculate monthly sum, median, and
maximum rainfall amounts from the full data set which has daily rainfall
amounts. My most current effort to calculate monthly sums uses this syntax:

monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)

(entered on a single line) which produces this result:

head(monthly.rain)
[1] NA

   The sample data has 62 of the 113K rows in the dataframe. A larger set can
be provided if needed.

   An explanation of what I've missed is needed.

Regards,

Rich



From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep  8 00:25:53 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 7 Sep 2018 15:25:53 -0700
Subject: [R] Correctly applying aggregate.ts()
In-Reply-To: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTm=6dULSuKmofcmzy=CwmGn54OPROyQNBM4Nt2RkjBSA@mail.gmail.com>

Well, let's see:
"monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)"

1. x is a data frame, so why are you using the time series method?
Perhaps you need to study S3 method usage in R.

2. You have improperly subscripted the data frame: it should be dp[,
c('sampdate','prcp')] . Perhaps you need to read about how
subscripting in R. However, in this case, no subscripting is needed
(see 3.)

3. As you should be using the data frame method, and the month is
obtained as a substring of sampdate, you should use dp[,'prcp'] as
your data frame so that sum() is not applied to the sampdate column.

4. I assume the "\" indicates <Return> ?

Anyway, once you have corrected all that, here's the call:

> monthly.rain <- aggregate(dp[, 'prcp'],
+                           list(substr(dp$sampdate,1,7)),
+                           FUN = sum, na.rm = TRUE)
> ## yielding
> monthly.rain
  Group.1    x
1 2005-01 4.88
2 2005-02 2.27
3 2005-03 0.06

It's perhaps also worth noting that the formula method (for data
frames) is somewhat more convenient, especially with several grouping
factors in the list:

> monthly.rain <- aggregate(prcp ~ substr(sampdate,1,7), data = dp, FUN = sum, na.rm = TRUE)
> ##yielding
> monthly.rain
  substr(sampdate, 1, 7) prcp
1                2005-01 4.88
2                2005-02 2.27
3                2005-03 0.06

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Fri, Sep 7, 2018 at 2:19 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
>    I've read ?aggregate and several blog posts on using aggregate() yet I
> still haven't applied it correctly to my dataframe. The sample data are:
>
> structure(list(sampdate = c("2005-01-01", "2005-01-02", "2005-01-03",
> "2005-01-04", "2005-01-05", "2005-01-06", "2005-01-07", "2005-01-08",
> "2005-01-09", "2005-01-10", "2005-01-11", "2005-01-12", "2005-01-13",
> "2005-01-14", "2005-01-15", "2005-01-16", "2005-01-17", "2005-01-18",
> "2005-01-19", "2005-01-20", "2005-01-21", "2005-01-22", "2005-01-23",
> "2005-01-24", "2005-01-25", "2005-01-26", "2005-01-27", "2005-01-28",
> "2005-01-29", "2005-01-30", "2005-01-31", "2005-02-01", "2005-02-02",
> "2005-02-03", "2005-02-04", "2005-02-05", "2005-02-06", "2005-02-07",
> "2005-02-08", "2005-02-09", "2005-02-10", "2005-02-11", "2005-02-12",
> "2005-02-13", "2005-02-14", "2005-02-15", "2005-02-16", "2005-02-17",
> "2005-02-18", "2005-02-19", "2005-02-20", "2005-02-21", "2005-02-22",
> "2005-02-23", "2005-02-24", "2005-02-25", "2005-02-26", "2005-02-27",
> "2005-02-28", "2005-03-01", "2005-03-02", "2005-03-03"), prcp = c(0.59,
> 0.08, 0.1, 0, 0, 0.02, 0.05, 0.1, 0, 0.02, 0, 0.05, 0.2, 0, 0,
> 0.5, 0.41, 0.84, 0.01, 0.1, 0.01, 0, 0, 0, 0, 0.21, 0.24, 0.13,
> 1.12, 0.01, 0.09, 0, 0, 0, 0.35, 0.18, 0.65, 0.16, 0, 0, 0, 0,
> 0.55, 0.21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.05,
> 0.01, 0)), row.names = c(NA, 62L), class = "data.frame")
>
>    What I need to learn how to do is to calculate monthly sum, median, and
> maximum rainfall amounts from the full data set which has daily rainfall
> amounts. My most current effort to calculate monthly sums uses this syntax:
>
> monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
> substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)
>
> (entered on a single line) which produces this result:
>
> head(monthly.rain)
> [1] NA
>
>    The sample data has 62 of the 113K rows in the dataframe. A larger set can
> be provided if needed.
>
>    An explanation of what I've missed is needed.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep  8 00:34:30 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 7 Sep 2018 15:34:30 -0700
Subject: [R] Correctly applying aggregate.ts()
In-Reply-To: <CAGxFJbTm=6dULSuKmofcmzy=CwmGn54OPROyQNBM4Nt2RkjBSA@mail.gmail.com>
References: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
 <CAGxFJbTm=6dULSuKmofcmzy=CwmGn54OPROyQNBM4Nt2RkjBSA@mail.gmail.com>
Message-ID: <CAGxFJbT42=CF=nvksVpf1PeJ=jJqkq7HOyhiJ6vkf=Q5aE90_Q@mail.gmail.com>

Clarification: When using the formula interface, no subscripting is needed.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 7, 2018 at 3:25 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Well, let's see:
> "monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
> substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)"
>
> 1. x is a data frame, so why are you using the time series method?
> Perhaps you need to study S3 method usage in R.
>
> 2. You have improperly subscripted the data frame: it should be dp[,
> c('sampdate','prcp')] . Perhaps you need to read about how
> subscripting in R. However, in this case, no subscripting is needed
> (see 3.)
>
> 3. As you should be using the data frame method, and the month is
> obtained as a substring of sampdate, you should use dp[,'prcp'] as
> your data frame so that sum() is not applied to the sampdate column.
>
> 4. I assume the "\" indicates <Return> ?
>
> Anyway, once you have corrected all that, here's the call:
>
> > monthly.rain <- aggregate(dp[, 'prcp'],
> +                           list(substr(dp$sampdate,1,7)),
> +                           FUN = sum, na.rm = TRUE)
> > ## yielding
> > monthly.rain
>   Group.1    x
> 1 2005-01 4.88
> 2 2005-02 2.27
> 3 2005-03 0.06
>
> It's perhaps also worth noting that the formula method (for data
> frames) is somewhat more convenient, especially with several grouping
> factors in the list:
>
> > monthly.rain <- aggregate(prcp ~ substr(sampdate,1,7), data = dp, FUN = sum, na.rm = TRUE)
> > ##yielding
> > monthly.rain
>   substr(sampdate, 1, 7) prcp
> 1                2005-01 4.88
> 2                2005-02 2.27
> 3                2005-03 0.06
>
> Cheers,
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> On Fri, Sep 7, 2018 at 2:19 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
> >
> >    I've read ?aggregate and several blog posts on using aggregate() yet I
> > still haven't applied it correctly to my dataframe. The sample data are:
> >
> > structure(list(sampdate = c("2005-01-01", "2005-01-02", "2005-01-03",
> > "2005-01-04", "2005-01-05", "2005-01-06", "2005-01-07", "2005-01-08",
> > "2005-01-09", "2005-01-10", "2005-01-11", "2005-01-12", "2005-01-13",
> > "2005-01-14", "2005-01-15", "2005-01-16", "2005-01-17", "2005-01-18",
> > "2005-01-19", "2005-01-20", "2005-01-21", "2005-01-22", "2005-01-23",
> > "2005-01-24", "2005-01-25", "2005-01-26", "2005-01-27", "2005-01-28",
> > "2005-01-29", "2005-01-30", "2005-01-31", "2005-02-01", "2005-02-02",
> > "2005-02-03", "2005-02-04", "2005-02-05", "2005-02-06", "2005-02-07",
> > "2005-02-08", "2005-02-09", "2005-02-10", "2005-02-11", "2005-02-12",
> > "2005-02-13", "2005-02-14", "2005-02-15", "2005-02-16", "2005-02-17",
> > "2005-02-18", "2005-02-19", "2005-02-20", "2005-02-21", "2005-02-22",
> > "2005-02-23", "2005-02-24", "2005-02-25", "2005-02-26", "2005-02-27",
> > "2005-02-28", "2005-03-01", "2005-03-02", "2005-03-03"), prcp = c(0.59,
> > 0.08, 0.1, 0, 0, 0.02, 0.05, 0.1, 0, 0.02, 0, 0.05, 0.2, 0, 0,
> > 0.5, 0.41, 0.84, 0.01, 0.1, 0.01, 0, 0, 0, 0, 0.21, 0.24, 0.13,
> > 1.12, 0.01, 0.09, 0, 0, 0, 0.35, 0.18, 0.65, 0.16, 0, 0, 0, 0,
> > 0.55, 0.21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.05,
> > 0.01, 0)), row.names = c(NA, 62L), class = "data.frame")
> >
> >    What I need to learn how to do is to calculate monthly sum, median, and
> > maximum rainfall amounts from the full data set which has daily rainfall
> > amounts. My most current effort to calculate monthly sums uses this syntax:
> >
> > monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
> > substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)
> >
> > (entered on a single line) which produces this result:
> >
> > head(monthly.rain)
> > [1] NA
> >
> >    The sample data has 62 of the 113K rows in the dataframe. A larger set can
> > be provided if needed.
> >
> >    An explanation of what I've missed is needed.
> >
> > Regards,
> >
> > Rich
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Sep  8 00:39:36 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 7 Sep 2018 15:39:36 -0700 (PDT)
Subject: [R] Correctly applying aggregate.ts() [RESOLVED]
In-Reply-To: <CAGxFJbTm=6dULSuKmofcmzy=CwmGn54OPROyQNBM4Nt2RkjBSA@mail.gmail.com>
References: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
 <CAGxFJbTm=6dULSuKmofcmzy=CwmGn54OPROyQNBM4Nt2RkjBSA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809071532090.11940@salmo.appl-ecosys.com>

On Fri, 7 Sep 2018, Bert Gunter wrote:

> Well, let's see:
> "monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
> substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)"
>
> 1. x is a data frame, so why are you using the time series method?
> Perhaps you need to study S3 method usage in R.

Bert,

   I saw the four varieties of aggregate and thought the time series
appropriate for the data frame of sequential dates. As I wrote, I had
difficulties understanding which flavor to use.

> 2. You have improperly subscripted the data frame: it should be dp[,
> c('sampdate','prcp')] . Perhaps you need to read about how
> subscripting in R. However, in this case, no subscripting is needed
> (see 3.)

   Ah so. All the examples I saw used single column data frames.

> 3. As you should be using the data frame method, and the month is
> obtained as a substring of sampdate, you should use dp[,'prcp'] as
> your data frame so that sum() is not applied to the sampdate column.
>
> 4. I assume the "\" indicates <Return> ?

   Yes. Alpine broke the line so I added a newline to the first part.

> Anyway, once you have corrected all that, here's the call:
>
>> monthly.rain <- aggregate(dp[, 'prcp'],
> +                           list(substr(dp$sampdate,1,7)),
> +                           FUN = sum, na.rm = TRUE)

   Thanks for making the syntax so clear.

> It's perhaps also worth noting that the formula method (for data
> frames) is somewhat more convenient, especially with several grouping
> factors in the list:
>
>> monthly.rain <- aggregate(prcp ~ substr(sampdate,1,7), data = dp, FUN = sum, na.rm = TRUE)
>> ##yielding
>> monthly.rain
>  substr(sampdate, 1, 7) prcp
> 1                2005-01 4.88
> 2                2005-02 2.27
> 3                2005-03 0.06

   I looked at the formula method without appreciating how to apply it.

   Now I can work with the multiple of daily data sets I have and properly
condense them for presentation to readers of the report. And I'm much better
armed to understand how to apply aggregate() to various data sets.

Very much appreciated,

Rich
a



From @k@h@y_e4 @end|ng |rom hotm@||@com  Sat Sep  8 12:25:57 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sat, 8 Sep 2018 10:25:57 +0000
Subject: [R] frequency distribution in figures....
Message-ID: <SL2P216MB009168C061B4FBC8D97AE478C8070@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I am facing difficulties in plotting histograms in R in Linux CLI.

Is there a function in R which produces a table of frequency distribution in figures rather than plot that distribution?

Something like this:

xht <- c(1,2,3,4,5,6,7,8,9,10)

required table:
                              bins:                   1-2     3-4    5-6     7-8     9-10
                              frequency:          2          2       2         2        2

Also is this possible:

xhth <- hist(xht)
summary(xhth)

very many thanks for your time and effort....
yours sincerely,
AKSHAYM KULKARNI


	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Sep  8 12:43:42 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 8 Sep 2018 06:43:42 -0400
Subject: [R] frequency distribution in figures....
In-Reply-To: <SL2P216MB009168C061B4FBC8D97AE478C8070@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009168C061B4FBC8D97AE478C8070@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <22f4b1ed-84f1-1cc4-5675-bcfc7d54d084@gmail.com>

On 08/09/2018 6:25 AM, akshay kulkarni wrote:
> dear members,
>                               I am facing difficulties in plotting histograms in R in Linux CLI.
> 
> Is there a function in R which produces a table of frequency distribution in figures rather than plot that distribution?
> 
> Something like this:
> 
> xht <- c(1,2,3,4,5,6,7,8,9,10)
> 
> required table:
>                                bins:                   1-2     3-4    5-6     7-8     9-10
>                                frequency:          2          2       2         2        2
> 
> Also is this possible:
> 
> xhth <- hist(xht)
> summary(xhth)
> 

You could use

table(cut(xht, breaks=2*(0:5)))

which produces


  (0,2]  (2,4]  (4,6]  (6,8] (8,10]
      2      2      2      2      2

for your dataset.

Duncan Murdoch



From drj|m|emon @end|ng |rom gm@||@com  Sat Sep  8 12:45:57 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 8 Sep 2018 20:45:57 +1000
Subject: [R] frequency distribution in figures....
In-Reply-To: <SL2P216MB009168C061B4FBC8D97AE478C8070@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009168C061B4FBC8D97AE478C8070@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fVLAsL96=U=uY7ijr1JQKTq27ysmtjkU1EHxpQdbvaB=w@mail.gmail.com>

Hi Akshay,
Try this:

table(cut(xht,breaks=seq(0,10,by=2)))

Jim

On Sat, Sep 8, 2018 at 8:26 PM akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>
> dear members,
>                              I am facing difficulties in plotting histograms in R in Linux CLI.
>
> Is there a function in R which produces a table of frequency distribution in figures rather than plot that distribution?
>
> Something like this:
>
> xht <- c(1,2,3,4,5,6,7,8,9,10)
>
> required table:
>                               bins:                   1-2     3-4    5-6     7-8     9-10
>                               frequency:          2          2       2         2        2
>
> Also is this possible:
>
> xhth <- hist(xht)
> summary(xhth)
>
> very many thanks for your time and effort....
> yours sincerely,
> AKSHAYM KULKARNI
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Sep  8 12:51:19 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 8 Sep 2018 11:51:19 +0100
Subject: [R] Correctly applying aggregate.ts()
In-Reply-To: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
Message-ID: <508c4296-5165-564d-4dcc-d1e880fc75f7@sapo.pt>

Hello,

Like Bert said, your data is a data.frame so there is no need to call 
aggregate.ts. Besides, R will call the right method so unless you want 
to change the standard behaviour, it would be enough to call aggregate 
and let the methods dispatch code to its job.

As for the problem, first an example of the formula interface, which I 
almost always prefer.


aggregate(prcp ~ substr(sampdate, 1, 7), data = dp, FUN = sum, na.rm = TRUE)
#  substr(sampdate, 1, 7) prcp
#1                2005-01 4.88
#2                2005-02 2.27
#3                2005-03 0.06


Now, you would have to change the name of the Month column, but it 
worked as expected, there was no NA issues.
And there is no need to subset the data.frame, R will find the columns 
where they are, by their names, as long as you pass the argument data = 
dp to aggregate.


If you want several statistics at the same time, it's a bit trickier, 
but with practice it becomes intuitive. (So to speak.)

Define a custom summary function. I haven't changed the default na.rm 
setting but it would make the rest of the code simpler to set na.rm = 
TRUE right now.

customSmry <- function(x, na.rm = FALSE){
   c(Sum = sum(x, na.rm = na.rm),
     Median = median(x, na.rm = na.rm),
     Max = max(x, na.rm = na.rm)
   )
}


#Now call aggregate:

agg <- aggregate(prcp ~ substr(sampdate, 1, 7), dp, FUN = customSmry, 
na.rm = TRUE)


But be VERY carefull, the result is not a df with 4 columns, it's a df 
with only two columns, the second being a matrix as you can see in the 
output of str.


str(agg)
#'data.frame':	3 obs. of  2 variables:
# $ substr(sampdate, 1, 7): chr  "2005-01" "2005-02" "2005-03"
# $ prcp                  : num [1:3, 1:3] 4.88 2.27 0.06 0.05 0 0.01 
1.12 0.65 0.05
# ..- attr(*, "dimnames")=List of 2
# .. ..$ : NULL
# .. ..$ : chr  "Sum" "Median" "Max"


So the final steps will be to cbind those two "columns" into a df.
"columns" is between quotes because I am not cbinding the first column, 
I'm cbinding the sub-df agg[1]. Like this the method of cbind that is 
called is cbind.data.frame and the result is a df.
Also, since df's are lists, the second column is an actual column but 
not a vector, an object of class matrix. This column is a list member, 
like all df columns and I will subset the df 'agg' as a list, agg[[2]].

As a bonus, the colnames of the matrix are immediately right, no prcp 
prefix. The first column's name comes from the function substr, and is 
not part of this story, just rename it when it's all done.


agg <- cbind(agg[1], agg[[2]])
str(agg)
#'data.frame':	3 obs. of  4 variables:
# $ substr(sampdate, 1, 7): chr  "2005-01" "2005-02" "2005-03"
# $ Sum                   : num  4.88 2.27 0.06
# $ Median                : num  0.05 0 0.01
# $ Max                   : num  1.12 0.65 0.05

names(agg)[1] <- "Month"
agg
#    Month  Sum Median  Max
#1 2005-01 4.88   0.05 1.12
#2 2005-02 2.27   0.00 0.65
#3 2005-03 0.06   0.01 0.05


Finally, try to get some practice with the formula interface, you will 
see that it pays in code simplicity and readability.


Hope this helps,

Rui Barradas

?s 22:19 de 07/09/2018, Rich Shepard escreveu:
>  ? I've read ?aggregate and several blog posts on using aggregate() yet I
> still haven't applied it correctly to my dataframe. The sample data are:
> 
> structure(list(sampdate = c("2005-01-01", "2005-01-02", "2005-01-03", 
> "2005-01-04", "2005-01-05", "2005-01-06", "2005-01-07", "2005-01-08", 
> "2005-01-09", "2005-01-10", "2005-01-11", "2005-01-12", "2005-01-13", 
> "2005-01-14", "2005-01-15", "2005-01-16", "2005-01-17", "2005-01-18", 
> "2005-01-19", "2005-01-20", "2005-01-21", "2005-01-22", "2005-01-23", 
> "2005-01-24", "2005-01-25", "2005-01-26", "2005-01-27", "2005-01-28", 
> "2005-01-29", "2005-01-30", "2005-01-31", "2005-02-01", "2005-02-02", 
> "2005-02-03", "2005-02-04", "2005-02-05", "2005-02-06", "2005-02-07", 
> "2005-02-08", "2005-02-09", "2005-02-10", "2005-02-11", "2005-02-12", 
> "2005-02-13", "2005-02-14", "2005-02-15", "2005-02-16", "2005-02-17", 
> "2005-02-18", "2005-02-19", "2005-02-20", "2005-02-21", "2005-02-22", 
> "2005-02-23", "2005-02-24", "2005-02-25", "2005-02-26", "2005-02-27", 
> "2005-02-28", "2005-03-01", "2005-03-02", "2005-03-03"), prcp = c(0.59, 
> 0.08, 0.1, 0, 0, 0.02, 0.05, 0.1, 0, 0.02, 0, 0.05, 0.2, 0, 0, 0.5, 
> 0.41, 0.84, 0.01, 0.1, 0.01, 0, 0, 0, 0, 0.21, 0.24, 0.13, 1.12, 0.01, 
> 0.09, 0, 0, 0, 0.35, 0.18, 0.65, 0.16, 0, 0, 0, 0, 0.55, 0.21, 0, 0, 0, 
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.05, 0.01, 0)), row.names = 
> c(NA, 62L), class = "data.frame")
> 
>  ? What I need to learn how to do is to calculate monthly sum, median, and
> maximum rainfall amounts from the full data set which has daily rainfall
> amounts. My most current effort to calculate monthly sums uses this syntax:
> 
> monthly.rain <- aggregate.ts(x = dp['sampdate','prcp'], by = list(month = \
> substr(dp$sampdate, 1, 7)), FUN = sum, na.rm = TRUE)
> 
> (entered on a single line) which produces this result:
> 
> head(monthly.rain)
> [1] NA
> 
>  ? The sample data has 62 of the 113K rows in the dataframe. A larger 
> set can
> be provided if needed.
> 
>  ? An explanation of what I've missed is needed.
> 
> Regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @h|v|pmp82 @end|ng |rom gm@||@com  Sat Sep  8 15:12:47 2018
From: @h|v|pmp82 @end|ng |rom gm@||@com (Shivi Bhatia)
Date: Sat, 8 Sep 2018 18:42:47 +0530
Subject: [R] argument "string" is missing, with no default
Message-ID: <CAB=p7Sr3CXuWJwcKXhXSy4pyB7ewqcQi7wb40EO+8_F3SLSTbw@mail.gmail.com>

Hi All,

I am trying to fetch data from a pdf file with the below code but getting
the error message:
Error in stri_split_regex(string, pattern, n = n, simplify = simplify,  :
  argument "string" is missing, with no default

library(readr)library(stringr)library(magrittr)library(dplyr)
table_data <- nvsr65_05[ [ 14 ] ] %>%
  str_split(pattern = "\n") %>%
  unlist() %>%
  str_subset(pattern = "^[^?].*(\\. ){5}") %>%
  str_c(collapse = "\n") %>%
  read_table(col_names = FALSE) %>%
  mutate(X2 = str_replace_all(X2, "(\\. )*", ""),
	 X5 = rep(c("Neonatal", "Postnatal"), each = 10)) %>%
  set_names(value = c("rank", "cause_of_death", "deaths", "percent", "group"))

Please advice. Thank you.

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Sep  8 16:13:32 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 8 Sep 2018 10:13:32 -0400
Subject: [R] argument "string" is missing, with no default
In-Reply-To: <CAB=p7Sr3CXuWJwcKXhXSy4pyB7ewqcQi7wb40EO+8_F3SLSTbw@mail.gmail.com>
References: <CAB=p7Sr3CXuWJwcKXhXSy4pyB7ewqcQi7wb40EO+8_F3SLSTbw@mail.gmail.com>
Message-ID: <0cc0f425-bd85-45e2-5a24-73ce9fc2cf71@gmail.com>

On 08/09/2018 9:12 AM, Shivi Bhatia wrote:
> Hi All,
> 
> I am trying to fetch data from a pdf file with the below code but getting
> the error message:
> Error in stri_split_regex(string, pattern, n = n, simplify = simplify,  :
>    argument "string" is missing, with no default
> 
> library(readr)library(stringr)library(magrittr)library(dplyr)
> table_data <- nvsr65_05[ [ 14 ] ] %>%
>    str_split(pattern = "\n") %>%
>    unlist() %>%
>    str_subset(pattern = "^[^?].*(\\. ){5}") %>%
>    str_c(collapse = "\n") %>%
>    read_table(col_names = FALSE) %>%
>    mutate(X2 = str_replace_all(X2, "(\\. )*", ""),
> 	 X5 = rep(c("Neonatal", "Postnatal"), each = 10)) %>%
>    set_names(value = c("rank", "cause_of_death", "deaths", "percent", "group"))
> 
> Please advice. Thank you.

Use traceback() to see which function called stri_split_regex.

Break up the long pipeline into smaller parts so you can see where the 
error is comming from.

Don't post in HTML.

Duncan Murdoch



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Sep  8 16:43:27 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sat, 8 Sep 2018 07:43:27 -0700 (PDT)
Subject: [R] Correctly applying aggregate.ts()
In-Reply-To: <508c4296-5165-564d-4dcc-d1e880fc75f7@sapo.pt>
References: <alpine.LNX.2.20.1809071410400.11940@salmo.appl-ecosys.com>
 <508c4296-5165-564d-4dcc-d1e880fc75f7@sapo.pt>
Message-ID: <alpine.LNX.2.20.1809080739370.21814@salmo.appl-ecosys.com>

On Sat, 8 Sep 2018, Rui Barradas wrote:

> Like Bert said, your data is a data.frame so there is no need to call 
> aggregate.ts. Besides, R will call the right method so unless you want to 
> change the standard behaviour, it would be enough to call aggregate and let 
> the methods dispatch code to its job.

Rui,

   I have no excuse (and certainly no valid reason) for not calling aggregate
itself.

   <Exceptionlly well written tutorial deleted.>

> Hope this helps,

   Very much so. It has also strengthed my abilities to learn how to use
other functions new to me.

Best regards,

Rich



From @h|_pe|j|@n @end|ng |rom 163@com  Sat Sep  8 14:33:54 2018
From: @h|_pe|j|@n @end|ng |rom 163@com (shi_peijian)
Date: Sat, 8 Sep 2018 20:33:54 +0800 (CST)
Subject: [R] How can I know the Hausdorff dimensions of fractals in the
 'fractalcurve' function of package 'pracma'?
Message-ID: <153827cd.526d.165b92ca112.Coremail.shi_peijian@163.com>

Dear Dr. Hans W. Borchers,




I'm using your 'pracma' package. It is very useful. May I have a small question for the 'fractalcurve' function? How can I know the Hausdorff dimension for every option below?


c("hilbert", "sierpinski", "snowflake", "dragon", "triangle", "arrowhead", "flowsnake", "molecule")


For the "dragon" option, its Hausdorff dimension is log(4)/log(2) = 2. For the others, what are the Hausdorff dimensions?


I have found the list of some fractals by Hausforff dimensions. I don't know which in the above option corresponds to which in Wikepedia.


Thanks a lot!


Best wishes,


Peijian Shi







--


Peijian (Joe)  Shi, Ph.D.

Research interests: forest ecology; theoretical ecology; thermal biology

Bamboo Research Institute, Nanjing Forestry University, P.R. China

159 Longpan Road, Nanjing City, Jiangsu Province 210037

Office:  60817  Biotechnology Building
	[[alternative HTML version deleted]]


From dd|@@b01 @end|ng |rom gm@||@com  Mon Sep 10 00:49:45 2018
From: dd|@@b01 @end|ng |rom gm@||@com (David Disabato)
Date: Sun, 9 Sep 2018 18:49:45 -0400
Subject: [R] For loop with multiple iteration indexes
Message-ID: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>

Hi R-help,

I am trying to create a for loop with multiple iteration indexes. I don't
want to use two different for loops nested together because I don't need
the full matrix of the two indexes, just the diagonal elements (e.g., i[1]
& j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to specify
both i and j in a single for loop? Here is a simplified example of
pseudo-code where x and y are equally sized character vectors with column
names and dat is their dataframe (obviously this code doesn't run in R, but
hopefully you perceive my goal):

r <- list()
n <- 0
for (i in x; j in y) {
   n <- n + 1
   r[[n]] <- cor(x = dat[, i], y = dat[, j])
}
print(r)

I realize there are other solutions to this particular correlation example,
but my actual problem is much more complicated, so I am hoping for a
solution that generalizes across any code within the for loop.

-- 
David J. Disabato, M.A.
Clinical Psychology Doctoral Student
George Mason University
ddisabat at gmu.edu

Email is not a secure form of communication as information and
confidentiality cannot be guaranteed. Information provided in an email is
not intended to be a professional service. In the case of a crisis or
emergency situation, call 911.

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Mon Sep 10 07:16:00 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 10 Sep 2018 15:16:00 +1000
Subject: [R] For loop with multiple iteration indexes
In-Reply-To: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
References: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
Message-ID: <CA+8X3fXVJoCQG0HWguMUFc8BfMxisQ+o4=XB1qJgv3Ddw4es5g@mail.gmail.com>

Hi David,
If you mean that you have two data frames named x and y and want the
correlations between the columns that would be on the diagonal of a
correlation matrix:

r<-list()
for(i in 1:n) r[[i]]<-cor(x[,i],y[,i])

If I'm wrong, let me know.

Jim

On Mon, Sep 10, 2018 at 3:06 PM David Disabato <ddisab01 at gmail.com> wrote:
>
> Hi R-help,
>
> I am trying to create a for loop with multiple iteration indexes. I don't
> want to use two different for loops nested together because I don't need
> the full matrix of the two indexes, just the diagonal elements (e.g., i[1]
> & j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to specify
> both i and j in a single for loop? Here is a simplified example of
> pseudo-code where x and y are equally sized character vectors with column
> names and dat is their dataframe (obviously this code doesn't run in R, but
> hopefully you perceive my goal):
>
> r <- list()
> n <- 0
> for (i in x; j in y) {
>    n <- n + 1
>    r[[n]] <- cor(x = dat[, i], y = dat[, j])
> }
> print(r)
>
> I realize there are other solutions to this particular correlation example,
> but my actual problem is much more complicated, so I am hoping for a
> solution that generalizes across any code within the for loop.
>
> --
> David J. Disabato, M.A.
> Clinical Psychology Doctoral Student
> George Mason University
> ddisabat at gmu.edu
>
> Email is not a secure form of communication as information and
> confidentiality cannot be guaranteed. Information provided in an email is
> not intended to be a professional service. In the case of a crisis or
> emergency situation, call 911.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @|k@u||m @end|ng |rom |@@tm@||@|m  Mon Sep 10 08:34:36 2018
From: @|k@u||m @end|ng |rom |@@tm@||@|m (Albrecht Kauffmann)
Date: Mon, 10 Sep 2018 08:34:36 +0200
Subject: [R] For loop with multiple iteration indexes
In-Reply-To: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
References: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
Message-ID: <1536561276.175268.1502469920.41D712F8@webmail.messagingengine.com>

Hi,

this simple example is very similarly, and it works in R:

r <- list()
n <- 0
x <- c("a","b","c")#x,y: Data from a dataframe
y <- c("A","B","C")
for (k in 1:3) {
    n <- n+1
    r[[n]] <- paste0(x[k],y[k])#or any other function using x[k] and y[k] as arguments
}
print(r)

Is it this what you meant?

Best,
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mo, 10. Sep 2018, um 00:49, schrieb David Disabato:
> Hi R-help,
> 
> I am trying to create a for loop with multiple iteration indexes. I don't
> want to use two different for loops nested together because I don't need
> the full matrix of the two indexes, just the diagonal elements (e.g., i[1]
> & j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to specify
> both i and j in a single for loop? Here is a simplified example of
> pseudo-code where x and y are equally sized character vectors with column
> names and dat is their dataframe (obviously this code doesn't run in R, but
> hopefully you perceive my goal):
> 
> r <- list()
> n <- 0
> for (i in x; j in y) {
>    n <- n + 1
>    r[[n]] <- cor(x = dat[, i], y = dat[, j])
> }
> print(r)
> 
> I realize there are other solutions to this particular correlation example,
> but my actual problem is much more complicated, so I am hoping for a
> solution that generalizes across any code within the for loop.
> 
> -- 
> David J. Disabato, M.A.
> Clinical Psychology Doctoral Student
> George Mason University
> ddisabat at gmu.edu
> 
> Email is not a secure form of communication as information and
> confidentiality cannot be guaranteed. Information provided in an email is
> not intended to be a professional service. In the case of a crisis or
> emergency situation, call 911.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Mon Sep 10 10:09:22 2018
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Mon, 10 Sep 2018 03:09:22 -0500
Subject: [R] real time monitoring of streaming audio with R?
Message-ID: <17ec99d3-d956-9195-a4fc-1b90a3101089@effectivedefense.org>

Hello, All:


 ????? Is it feasible to do real time monitoring of streaming audio with 
R, writing a compressed copy of what's read to 1-hour long MP3 files?


 ????? I'm a volunteer with a community radio station (kkfi.org).? My 
minimum requirements at the moment are to create MP3 files from what we 
broadcast.? I have a tuner hooked to the audio input of a computer.? I 
can listen to it in real time using the computer audio output jack, and 
I can record it manually using Audacity.? If I have MP3 versions of both 
what we send to the tower and what is actually broadcasted, I can read 
the two into R, compare them, identify substantive differences, write 
appropriate descriptions to files, send emails, etc.? I don't know how 
to sample the live stream.


 ?????? I know it can be done in Python, but I don't know how, and I'd 
prefer to use R.? I suspect it can be done with ffplay, part of ffmpeg, 
but again I don't know how.


 ????? Thanks,
 ????? Spencer Graves



From p_conno||y @end|ng |rom @||ng@hot@co@nz  Mon Sep 10 10:54:38 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Mon, 10 Sep 2018 20:54:38 +1200
Subject: [R] Why can't I make use of tcltk in this installation?
Message-ID: <20180910085438.GA5433@slingshot.co.nz>

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
 [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
 [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] utils     stats     grDevices graphics  methods   base     

other attached packages:
[1] lattice_0.20-35

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.17     dplyr_0.7.6      assertthat_0.2.0 grid_3.5.0      
 [5] R6_2.2.2         magrittr_1.5     pillar_1.2.3     rlang_0.2.1     
 [9] bindrcpp_0.2.2   tools_3.5.0      glue_1.2.0       purrr_0.2.5     
[13] compiler_3.5.0   pkgconfig_2.0.1  bindr_0.1.1      tidyselect_0.2.4
[17] tibble_1.4.2    
> capabilities()
       jpeg         png        tiff       tcltk         X11        aqua 
       TRUE        TRUE        TRUE       FALSE        TRUE       FALSE 
   http/ftp     sockets      libxml        fifo      cledit       iconv 
       TRUE        TRUE        TRUE        TRUE       FALSE        TRUE 
        NLS     profmem       cairo         ICU long.double     libcurl 
       TRUE       FALSE        TRUE        TRUE        TRUE        TRUE 
> 

If I try to load tcltk, no surprise...

> require(tcltk)
Loading required package: tcltk
Error: package or namespace load failed for ?tcltk?:
 .onLoad failed in loadNamespace() for 'tcltk', details:
  call: fun(libname, pkgname)
  error: Tcl/Tk support is not available on this system
Warning message:
S3 methods ?as.character.tclObj?, ?as.character.tclVar?, ?as.double.tclObj?, ?as.integer.tclObj?, ?as.logical.tclObj?, ?as.raw.tclObj?, ?print.tclObj?, ?[[.tclArray?, ?[[<-.tclArray?, ?$.tclArray?, ?$<-.tclArray?, ?names.tclArray?, ?names<-.tclArray?, ?length.tclArray?, ?length<-.tclArray?, ?tclObj.tclVar?, ?tclObj<-.tclVar?, ?tclvalue.default?, ?tclvalue.tclObj?, ?tclvalue.tclVar?, ?tclvalue<-.default?, ?tclvalue<-.tclVar?, ?close.tkProgressBar? were declared in NAMESPACE but not found 
> 

The question is:  What do I have to do to get Tcl/Tk support?
>From the bash prompt:
 > aptitude search tcltk
p   hfsutils-tcltk             - Tcl/Tk interfaces for reading and writing Macintosh volumes 
p   hfsutils-tcltk:i386        - Tcl/Tk interfaces for reading and writing Macintosh volumes 
p   libtcltk-ruby              - Tcl/Tk interface for Ruby           
p   libtcltk-ruby1.9.1         - Tcl/Tk interface for Ruby 1.9.1
p   libtcltk-ruby1.9.1:i386    - Tcl/Tk interface for Ruby 1.9.1
p   r-cran-tcltk2              - GNU R package for Tcl/Tk additions 
p   ruby2.0-tcltk              - Ruby/Tk for Ruby 2.0
p   ruby2.0-tcltk:i386         - Ruby/Tk for Ruby 2.0  

That's the same as what I get on another computer on which tcktl is
available, so it didn't surprise me when installing the r-cran-tcktl
package didn't help.

Where else should I be looking for a difference?

TIA


-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.



From @|k@u||m @end|ng |rom |@@tm@||@|m  Mon Sep 10 12:37:58 2018
From: @|k@u||m @end|ng |rom |@@tm@||@|m (Albrecht Kauffmann)
Date: Mon, 10 Sep 2018 12:37:58 +0200
Subject: [R] Why can't I make use of tcltk in this installation?
In-Reply-To: <20180910085438.GA5433@slingshot.co.nz>
References: <20180910085438.GA5433@slingshot.co.nz>
Message-ID: <1536575878.229467.1502681072.67196379@webmail.messagingengine.com>

Hi Patrick,

did you give the compiler path instructions to tclConfig.sh and tkConfig.sh , as

../R-3.5.1/configure  --with-tcl-config=/usr/lib64/tclConfig.sh --with-tk-config=/usr/lib64/tkConfig.sh

?

Best,
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mo, 10. Sep 2018, um 10:54, schrieb Patrick Connolly:
> > sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.5 LTS
> 
> Matrix products: default
> BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
> LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so
> 
> locale:
>  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
>  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
>  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
>  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       
> 
> attached base packages:
> [1] utils     stats     grDevices graphics  methods   base     
> 
> other attached packages:
> [1] lattice_0.20-35
> 
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.17     dplyr_0.7.6      assertthat_0.2.0 grid_3.5.0      
>  [5] R6_2.2.2         magrittr_1.5     pillar_1.2.3     rlang_0.2.1     
>  [9] bindrcpp_0.2.2   tools_3.5.0      glue_1.2.0       purrr_0.2.5     
> [13] compiler_3.5.0   pkgconfig_2.0.1  bindr_0.1.1      tidyselect_0.2.4
> [17] tibble_1.4.2    
> > capabilities()
>        jpeg         png        tiff       tcltk         X11        aqua 
>        TRUE        TRUE        TRUE       FALSE        TRUE       FALSE 
>    http/ftp     sockets      libxml        fifo      cledit       iconv 
>        TRUE        TRUE        TRUE        TRUE       FALSE        TRUE 
>         NLS     profmem       cairo         ICU long.double     libcurl 
>        TRUE       FALSE        TRUE        TRUE        TRUE        TRUE 
> > 
> 
> If I try to load tcltk, no surprise...
> 
> > require(tcltk)
> Loading required package: tcltk
> Error: package or namespace load failed for ?tcltk?:
>  .onLoad failed in loadNamespace() for 'tcltk', details:
>   call: fun(libname, pkgname)
>   error: Tcl/Tk support is not available on this system
> Warning message:
> S3 methods ?as.character.tclObj?, ?as.character.tclVar?, 
> ?as.double.tclObj?, ?as.integer.tclObj?, ?as.logical.tclObj?, 
> ?as.raw.tclObj?, ?print.tclObj?, ?[[.tclArray?, ?[[<-.tclArray?, 
> ?$.tclArray?, ?$<-.tclArray?, ?names.tclArray?, ?names<-.tclArray?, 
> ?length.tclArray?, ?length<-.tclArray?, ?tclObj.tclVar?, 
> ?tclObj<-.tclVar?, ?tclvalue.default?, ?tclvalue.tclObj?, 
> ?tclvalue.tclVar?, ?tclvalue<-.default?, ?tclvalue<-.tclVar?, 
> ?close.tkProgressBar? were declared in NAMESPACE but not found 
> > 
> 
> The question is:  What do I have to do to get Tcl/Tk support?
> From the bash prompt:
>  > aptitude search tcltk
> p   hfsutils-tcltk             - Tcl/Tk interfaces for reading and 
> writing Macintosh volumes 
> p   hfsutils-tcltk:i386        - Tcl/Tk interfaces for reading and 
> writing Macintosh volumes 
> p   libtcltk-ruby              - Tcl/Tk interface for Ruby           
> p   libtcltk-ruby1.9.1         - Tcl/Tk interface for Ruby 1.9.1
> p   libtcltk-ruby1.9.1:i386    - Tcl/Tk interface for Ruby 1.9.1
> p   r-cran-tcltk2              - GNU R package for Tcl/Tk additions 
> p   ruby2.0-tcltk              - Ruby/Tk for Ruby 2.0
> p   ruby2.0-tcltk:i386         - Ruby/Tk for Ruby 2.0  
> 
> That's the same as what I get on another computer on which tcktl is
> available, so it didn't surprise me when installing the r-cran-tcktl
> package didn't help.
> 
> Where else should I be looking for a difference?
> 
> TIA
> 
> 
> -- 
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
>    ___    Patrick Connolly   
>  {~._.~}                   Great minds discuss ideas    
>  _( Y )_  	         Average minds discuss events 
> (:_~*~_:)                  Small minds discuss people  
>  (_)-(_)  	                      ..... Eleanor Roosevelt
> 	  
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From pd@|gd @end|ng |rom gm@||@com  Mon Sep 10 13:06:59 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 10 Sep 2018 13:06:59 +0200
Subject: [R] Why can't I make use of tcltk in this installation?
In-Reply-To: <1536575878.229467.1502681072.67196379@webmail.messagingengine.com>
References: <20180910085438.GA5433@slingshot.co.nz>
 <1536575878.229467.1502681072.67196379@webmail.messagingengine.com>
Message-ID: <BE7C6055-211C-4FD4-ACBC-95BA7B1DCCFC@gmail.com>

You may need to consult the R-sig-debian list, rather than R-help.

Offhand, I would expect that you need Tcl libraries, Tk libraries and the associated -devel or -dev packages. Notice that although they are designed to work together, Tcl and Tk are two separate entities, so searching for tcltk may not suffice.

-pd

> On 10 Sep 2018, at 12:37 , Albrecht Kauffmann <alkauffm at fastmail.fm> wrote:
> 
> Hi Patrick,
> 
> did you give the compiler path instructions to tclConfig.sh and tkConfig.sh , as
> 
> ../R-3.5.1/configure  --with-tcl-config=/usr/lib64/tclConfig.sh --with-tk-config=/usr/lib64/tkConfig.sh
> 
> ?
> 
> Best,
> Albrecht
> 
> -- 
>  Albrecht Kauffmann
>  alkauffm at fastmail.fm
> 
> Am Mo, 10. Sep 2018, um 10:54, schrieb Patrick Connolly:
>>> sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.5 LTS
>> 
>> Matrix products: default
>> BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
>> LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so
>> 
>> locale:
>> [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
>> [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
>> [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
>> [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       
>> 
>> attached base packages:
>> [1] utils     stats     grDevices graphics  methods   base     
>> 
>> other attached packages:
>> [1] lattice_0.20-35
>> 
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.12.17     dplyr_0.7.6      assertthat_0.2.0 grid_3.5.0      
>> [5] R6_2.2.2         magrittr_1.5     pillar_1.2.3     rlang_0.2.1     
>> [9] bindrcpp_0.2.2   tools_3.5.0      glue_1.2.0       purrr_0.2.5     
>> [13] compiler_3.5.0   pkgconfig_2.0.1  bindr_0.1.1      tidyselect_0.2.4
>> [17] tibble_1.4.2    
>>> capabilities()
>>       jpeg         png        tiff       tcltk         X11        aqua 
>>       TRUE        TRUE        TRUE       FALSE        TRUE       FALSE 
>>   http/ftp     sockets      libxml        fifo      cledit       iconv 
>>       TRUE        TRUE        TRUE        TRUE       FALSE        TRUE 
>>        NLS     profmem       cairo         ICU long.double     libcurl 
>>       TRUE       FALSE        TRUE        TRUE        TRUE        TRUE 
>>> 
>> 
>> If I try to load tcltk, no surprise...
>> 
>>> require(tcltk)
>> Loading required package: tcltk
>> Error: package or namespace load failed for ?tcltk?:
>> .onLoad failed in loadNamespace() for 'tcltk', details:
>>  call: fun(libname, pkgname)
>>  error: Tcl/Tk support is not available on this system
>> Warning message:
>> S3 methods ?as.character.tclObj?, ?as.character.tclVar?, 
>> ?as.double.tclObj?, ?as.integer.tclObj?, ?as.logical.tclObj?, 
>> ?as.raw.tclObj?, ?print.tclObj?, ?[[.tclArray?, ?[[<-.tclArray?, 
>> ?$.tclArray?, ?$<-.tclArray?, ?names.tclArray?, ?names<-.tclArray?, 
>> ?length.tclArray?, ?length<-.tclArray?, ?tclObj.tclVar?, 
>> ?tclObj<-.tclVar?, ?tclvalue.default?, ?tclvalue.tclObj?, 
>> ?tclvalue.tclVar?, ?tclvalue<-.default?, ?tclvalue<-.tclVar?, 
>> ?close.tkProgressBar? were declared in NAMESPACE but not found 
>>> 
>> 
>> The question is:  What do I have to do to get Tcl/Tk support?
>> From the bash prompt:
>>> aptitude search tcltk
>> p   hfsutils-tcltk             - Tcl/Tk interfaces for reading and 
>> writing Macintosh volumes 
>> p   hfsutils-tcltk:i386        - Tcl/Tk interfaces for reading and 
>> writing Macintosh volumes 
>> p   libtcltk-ruby              - Tcl/Tk interface for Ruby           
>> p   libtcltk-ruby1.9.1         - Tcl/Tk interface for Ruby 1.9.1
>> p   libtcltk-ruby1.9.1:i386    - Tcl/Tk interface for Ruby 1.9.1
>> p   r-cran-tcltk2              - GNU R package for Tcl/Tk additions 
>> p   ruby2.0-tcltk              - Ruby/Tk for Ruby 2.0
>> p   ruby2.0-tcltk:i386         - Ruby/Tk for Ruby 2.0  
>> 
>> That's the same as what I get on another computer on which tcktl is
>> available, so it didn't surprise me when installing the r-cran-tcktl
>> package didn't help.
>> 
>> Where else should I be looking for a difference?
>> 
>> TIA
>> 
>> 
>> -- 
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
>>   ___    Patrick Connolly   
>> {~._.~}                   Great minds discuss ideas    
>> _( Y )_  	         Average minds discuss events 
>> (:_~*~_:)                  Small minds discuss people  
>> (_)-(_)  	                      ..... Eleanor Roosevelt
>> 	  
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From ccberry @end|ng |rom uc@d@edu  Mon Sep 10 17:29:50 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Mon, 10 Sep 2018 15:29:50 +0000
Subject: [R] For loop with multiple iteration indexes
In-Reply-To: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
References: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
Message-ID: <F226B06A-9457-47DF-A9F0-9B995D999475@ucsd.edu>

I have a sense of deja vu:

https://www.mail-archive.com/r-help at r-project.org/msg250494.html

There is some good advice there.

> On Sep 9, 2018, at 3:49 PM, David Disabato <ddisab01 at gmail.com> wrote:
> 
> Hi R-help,
> 
> I am trying to create a for loop with multiple iteration indexes. I don't
> want to use two different for loops nested together because I don't need
> the full matrix of the two indexes, just the diagonal elements (e.g., i[1]
> & j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to specify
> both i and j in a single for loop? Here is a simplified example of
> pseudo-code where x and y are equally sized character vectors with column
> names and dat is their dataframe (obviously this code doesn't run in R, but
> hopefully you perceive my goal):
> 
> r <- list()
> n <- 0
> for (i in x; j in y) {
>   n <- n + 1
>   r[[n]] <- cor(x = dat[, i], y = dat[, j])
> }
> print(r)
> 
> I realize there are other solutions to this particular correlation example,
> but my actual problem is much more complicated, so I am hoping for a
> solution that generalizes across any code within the for loop.

A more aRtful way (than a for loop) to approach this is with mapply:

	
i <- head(colnames(mtcars))
j <- tail(colnames(mtcars))

r <- mapply(function(i, j, dat) cor( x = dat[, i], y = dat[, j]),
       i=i , j=j , MoreArgs = list( dat = mtcars), 
       SIMPLIFY = FALSE, USE.NAMES = FALSE)


and if you want, maybe USE.NAMES = paste(i, j, sep="_")

Chuck



From k@kow|t@k| @end|ng |rom |c|oud@com  Mon Sep 10 17:54:27 2018
From: k@kow|t@k| @end|ng |rom |c|oud@com (Kevin Kowitski)
Date: Mon, 10 Sep 2018 15:54:27 +0000 (GMT)
Subject: [R] Packaged exe and Shiny
Message-ID: <d71e9b46-7a37-4e1c-b6ca-8142baaadbcd@me.com>

Hey Everyone,?

? I do not know if this topic has been covered, I'm sure it must have, but is there a good environment for packaging R code into a distributed exe. (which includes all of the required libraries, etc.)?? I have seen that Shiny is a good GUI / Web library for sharing R programs, but I have never used it.?

What is the groups input on this???

My goal is to create some basic tools (with interfaces) at work for analyzing .csv files and generating basic graphs and output csv files. These tools would be distributed to team members to have on their desktops.? ?I considered doing this in Java, but I am more well versed in R so it would be quicker for me to whip up the varying tools in R than re-learning Java.?

Thank you!

-Kevin

From drj|m|emon @end|ng |rom gm@||@com  Tue Sep 11 00:17:02 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 11 Sep 2018 08:17:02 +1000
Subject: [R] Packaged exe and Shiny
In-Reply-To: <d71e9b46-7a37-4e1c-b6ca-8142baaadbcd@me.com>
References: <d71e9b46-7a37-4e1c-b6ca-8142baaadbcd@me.com>
Message-ID: <CA+8X3fUQYVu2zhrd6DDu-a3wP2OVuF0DUBcFvwd5iG-US0x=ZQ@mail.gmail.com>

Hi Kevin,
It might be just as easy to write R scripts that would do basic
analyses. Users could "source" these scripts in an R session or from
the command line. The scripts would be much more compact than the .exe
files that you describe.

Jim

On Tue, Sep 11, 2018 at 8:06 AM Kevin Kowitski via R-help
<r-help at r-project.org> wrote:
>
> Hey Everyone,
>
>   I do not know if this topic has been covered, I'm sure it must have, but is there a good environment for packaging R code into a distributed exe. (which includes all of the required libraries, etc.)?  I have seen that Shiny is a good GUI / Web library for sharing R programs, but I have never used it.
>
> What is the groups input on this?
>
> My goal is to create some basic tools (with interfaces) at work for analyzing .csv files and generating basic graphs and output csv files. These tools would be distributed to team members to have on their desktops.   I considered doing this in Java, but I am more well versed in R so it would be quicker for me to whip up the varying tools in R than re-learning Java.
>
> Thank you!
>
> -Kevin
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep 11 00:58:47 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 10 Sep 2018 15:58:47 -0700
Subject: [R] Packaged exe and Shiny
In-Reply-To: <CA+8X3fUQYVu2zhrd6DDu-a3wP2OVuF0DUBcFvwd5iG-US0x=ZQ@mail.gmail.com>
References: <d71e9b46-7a37-4e1c-b6ca-8142baaadbcd@me.com>
 <CA+8X3fUQYVu2zhrd6DDu-a3wP2OVuF0DUBcFvwd5iG-US0x=ZQ@mail.gmail.com>
Message-ID: <4C65246C-FDF7-4D4C-9F40-E510D50F9206@dcn.davis.ca.us>

IMO the best short answer is don't target making an install package or msi at all... the obstacles are quite significant. Aim for building most of your capabilities in packages and having people install them. You can setup an in-house package repo to simplify this and give them a startup script that configures their R environment.

There is also the option to use R-Portable [1] but this leads to massive deployment files that don't upgrade easily.

I also think that when the time crunch happens many people will go to the internet and copy-paste solutions that you would be unlikely to have anticipated. Closing off that scary console completely will keep you in the hot seat indefinitely, whereas giving them the option to go around your UI lets more resources be allocated later.

[1] https://www.r-bloggers.com/deploying-desktop-apps-with-r/amp/

On September 10, 2018 3:17:02 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Kevin,
>It might be just as easy to write R scripts that would do basic
>analyses. Users could "source" these scripts in an R session or from
>the command line. The scripts would be much more compact than the .exe
>files that you describe.
>
>Jim
>
>On Tue, Sep 11, 2018 at 8:06 AM Kevin Kowitski via R-help
><r-help at r-project.org> wrote:
>>
>> Hey Everyone,
>>
>>   I do not know if this topic has been covered, I'm sure it must
>have, but is there a good environment for packaging R code into a
>distributed exe. (which includes all of the required libraries, etc.)? 
>I have seen that Shiny is a good GUI / Web library for sharing R
>programs, but I have never used it.
>>
>> What is the groups input on this?
>>
>> My goal is to create some basic tools (with interfaces) at work for
>analyzing .csv files and generating basic graphs and output csv files.
>These tools would be distributed to team members to have on their
>desktops.   I considered doing this in Java, but I am more well versed
>in R so it would be quicker for me to whip up the varying tools in R
>than re-learning Java.
>>
>> Thank you!
>>
>> -Kevin
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From p_conno||y @end|ng |rom @||ng@hot@co@nz  Tue Sep 11 01:52:33 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (p_connolly)
Date: Tue, 11 Sep 2018 11:52:33 +1200
Subject: [R] Why can't I make use of tcltk in this installation?
In-Reply-To: <1536575878.229467.1502681072.67196379@webmail.messagingengine.com>
References: <20180910085438.GA5433@slingshot.co.nz>
 <1536575878.229467.1502681072.67196379@webmail.messagingengine.com>
Message-ID: <fcb88bfc7392f86af31accdbe6a28d4f@slingshot.co.nz>

Hello Albrecht.

I didn't specify those paths on the 3 machines that have tcltk 
available.  It appears that those files are not on the machine in 
question and that is the reason for my problem.  But if they are, 
./configure finds them itself.

I'm not at the machine that has the issue, but I assume that since I get 
this on a machine that does work:

> dpkg -S tkConfig.sh
tk8.6-dev:amd64: /usr/lib/x86_64-linux-gnu/tk8.6/tkConfig.sh
tk8.6-dev:amd64: /usr/lib/tk8.6/tkConfig.sh
tk-dev:amd64: /usr/lib/x86_64-linux-gnu/tkConfig.sh
tk-dev:amd64: /usr/lib/tkConfig.sh

I need to install those two packages (and the corresponding ones for 
tcl) and reinstall R.

Thanks for the pointer, and thank you pd for drawing my attention to the 
fact that Tcl and Tk need to be done separately.




On 2018-09-10 22:37, Albrecht Kauffmann wrote:
> Hi Patrick,
> 
> did you give the compiler path instructions to tclConfig.sh and 
> tkConfig.sh , as
> 
> ../R-3.5.1/configure  --with-tcl-config=/usr/lib64/tclConfig.sh
> --with-tk-config=/usr/lib64/tkConfig.sh
> 
> ?
> 
> Best,
> Albrecht
> 
> --
>   Albrecht Kauffmann
>   alkauffm at fastmail.fm
> 
> Am Mo, 10. Sep 2018, um 10:54, schrieb Patrick Connolly:
>> > sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.5 LTS
>> 
>> Matrix products: default
>> BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
>> LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so
>> 
>> locale:
>>  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
>>  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
>>  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] utils     stats     grDevices graphics  methods   base
>> 
>> other attached packages:
>> [1] lattice_0.20-35
>> 
>> loaded via a namespace (and not attached):
>>  [1] Rcpp_0.12.17     dplyr_0.7.6      assertthat_0.2.0 grid_3.5.0
>>  [5] R6_2.2.2         magrittr_1.5     pillar_1.2.3     rlang_0.2.1
>>  [9] bindrcpp_0.2.2   tools_3.5.0      glue_1.2.0       purrr_0.2.5
>> [13] compiler_3.5.0   pkgconfig_2.0.1  bindr_0.1.1      
>> tidyselect_0.2.4
>> [17] tibble_1.4.2
>> > capabilities()
>>        jpeg         png        tiff       tcltk         X11        
>> aqua
>>        TRUE        TRUE        TRUE       FALSE        TRUE       
>> FALSE
>>    http/ftp     sockets      libxml        fifo      cledit       
>> iconv
>>        TRUE        TRUE        TRUE        TRUE       FALSE        
>> TRUE
>>         NLS     profmem       cairo         ICU long.double     
>> libcurl
>>        TRUE       FALSE        TRUE        TRUE        TRUE        
>> TRUE
>> >
>> 
>> If I try to load tcltk, no surprise...
>> 
>> > require(tcltk)
>> Loading required package: tcltk
>> Error: package or namespace load failed for ?tcltk?:
>>  .onLoad failed in loadNamespace() for 'tcltk', details:
>>   call: fun(libname, pkgname)
>>   error: Tcl/Tk support is not available on this system
>> Warning message:
>> S3 methods ?as.character.tclObj?, ?as.character.tclVar?,
>> ?as.double.tclObj?, ?as.integer.tclObj?, ?as.logical.tclObj?,
>> ?as.raw.tclObj?, ?print.tclObj?, ?[[.tclArray?, ?[[<-.tclArray?,
>> ?$.tclArray?, ?$<-.tclArray?, ?names.tclArray?, ?names<-.tclArray?,
>> ?length.tclArray?, ?length<-.tclArray?, ?tclObj.tclVar?,
>> ?tclObj<-.tclVar?, ?tclvalue.default?, ?tclvalue.tclObj?,
>> ?tclvalue.tclVar?, ?tclvalue<-.default?, ?tclvalue<-.tclVar?,
>> ?close.tkProgressBar? were declared in NAMESPACE but not found
>> >
>> 
>> The question is:  What do I have to do to get Tcl/Tk support?
>> From the bash prompt:
>>  > aptitude search tcltk
>> p   hfsutils-tcltk             - Tcl/Tk interfaces for reading and
>> writing Macintosh volumes
>> p   hfsutils-tcltk:i386        - Tcl/Tk interfaces for reading and
>> writing Macintosh volumes
>> p   libtcltk-ruby              - Tcl/Tk interface for Ruby
>> p   libtcltk-ruby1.9.1         - Tcl/Tk interface for Ruby 1.9.1
>> p   libtcltk-ruby1.9.1:i386    - Tcl/Tk interface for Ruby 1.9.1
>> p   r-cran-tcltk2              - GNU R package for Tcl/Tk additions
>> p   ruby2.0-tcltk              - Ruby/Tk for Ruby 2.0
>> p   ruby2.0-tcltk:i386         - Ruby/Tk for Ruby 2.0
>> 
>> That's the same as what I get on another computer on which tcktl is
>> available, so it didn't surprise me when installing the r-cran-tcktl
>> package didn't help.
>> 
>> Where else should I be looking for a difference?
>> 
>> TIA
>> 
>> 
>> --
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>>    ___    Patrick Connolly
>>  {~._.~}                   Great minds discuss ideas
>>  _( Y )_  	         Average minds discuss events
>> (:_~*~_:)                  Small minds discuss people
>>  (_)-(_)  	                      ..... Eleanor Roosevelt
>> 
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dd|@@b01 @end|ng |rom gm@||@com  Tue Sep 11 03:32:57 2018
From: dd|@@b01 @end|ng |rom gm@||@com (David Disabato)
Date: Mon, 10 Sep 2018 21:32:57 -0400
Subject: [R] For loop with multiple iteration indexes
In-Reply-To: <F226B06A-9457-47DF-A9F0-9B995D999475@ucsd.edu>
References: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
 <F226B06A-9457-47DF-A9F0-9B995D999475@ucsd.edu>
Message-ID: <CACg0228eV_KsSyHpT6iBVhSyQ1hfFv2Nazj7a1JJrpMOfVQDLg@mail.gmail.com>

Thank you everyone. After thinking about each response, I realized a fairly
simple solution is available (obviously, other suggested approaches work as
well):

stopifnot(length(x) == length(y); stopifnot(length(x) > 0)
r <- list()
for (i in 1:length(x) ) {
   r[[i]] <- cor(x = dat[, x[i] ], y = dat[, y[i] ])
}
print(r)

On Mon, Sep 10, 2018 at 11:30 AM Berry, Charles <ccberry at ucsd.edu> wrote:

> I have a sense of deja vu:
>
> https://www.mail-archive.com/r-help at r-project.org/msg250494.html
>
> There is some good advice there.
>
> > On Sep 9, 2018, at 3:49 PM, David Disabato <ddisab01 at gmail.com> wrote:
> >
> > Hi R-help,
> >
> > I am trying to create a for loop with multiple iteration indexes. I don't
> > want to use two different for loops nested together because I don't need
> > the full matrix of the two indexes, just the diagonal elements (e.g.,
> i[1]
> > & j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to specify
> > both i and j in a single for loop? Here is a simplified example of
> > pseudo-code where x and y are equally sized character vectors with column
> > names and dat is their dataframe (obviously this code doesn't run in R,
> but
> > hopefully you perceive my goal):
> >
> > r <- list()
> > n <- 0
> > for (i in x; j in y) {
> >   n <- n + 1
> >   r[[n]] <- cor(x = dat[, i], y = dat[, j])
> > }
> > print(r)
> >
> > I realize there are other solutions to this particular correlation
> example,
> > but my actual problem is much more complicated, so I am hoping for a
> > solution that generalizes across any code within the for loop.
>
> A more aRtful way (than a for loop) to approach this is with mapply:
>
>
> i <- head(colnames(mtcars))
> j <- tail(colnames(mtcars))
>
> r <- mapply(function(i, j, dat) cor( x = dat[, i], y = dat[, j]),
>        i=i , j=j , MoreArgs = list( dat = mtcars),
>        SIMPLIFY = FALSE, USE.NAMES = FALSE)
>
>
> and if you want, maybe USE.NAMES = paste(i, j, sep="_")
>
> Chuck
>
>

-- 
David J. Disabato, M.A.
Clinical Psychology Doctoral Student
George Mason University
ddisabat at gmu.edu

Email is not a secure form of communication as information and
confidentiality cannot be guaranteed. Information provided in an email is
not intended to be a professional service. In the case of a crisis or
emergency situation, call 911.

	[[alternative HTML version deleted]]



From kr|@t|@g|over @end|ng |rom hotm@||@com  Tue Sep 11 08:52:06 2018
From: kr|@t|@g|over @end|ng |rom hotm@||@com (Kristi Glover)
Date: Tue, 11 Sep 2018 06:52:06 +0000
Subject: [R] loop for comparing two or more groups using bootstrapping
Message-ID: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>

Hi R users,

I was trying to test a null hypothesis of difference between two groups was 0. I have many years data, such as year1, year2,, year3, year4 and I was trying to compare between year1 and year2, year1 and year3, year2 and year3 and so on and have used following code with an example data.


I tried to make a loop but did not work to compare between many years, and also want to obtain the exact p value. Would you mind to help me to make a loop?

Thanks for your help.


KG


daT<-structure(list(year1 = c(0.417, 0.538, 0.69, 0.688, 0.688, 0.606,

0.667, 0.7, 0.545, 0.462, 0.711, 0.642, 0.744, 0.604, 0.612,

0.667, 0.533, 0.556, 0.444, 0.526, 0.323, 0.308, 0.195, 0.333,

0.323, 0.256, 0.345, 0.205, 0.286, 0.706, 0.7, 0.6, 0.571, 0.364,

0.429, 0.326, 0.571, 0.424, 0.341, 0.387, 0.341, 0.324, 0.696,

0.696, 0.583, 0.556, 0.645, 0.435, 0.471, 0.556), year2 = c(0.385,

0.552, 0.645, 0.516, 0.629, 0.595, 0.72, 0.638, 0.557, 0.588,

0.63, 0.744, 0.773, 0.571, 0.723, 0.769, 0.667, 0.667, 0.526,

0.476, 0.294, 0.323, 0.222, 0.556, 0.263, 0.37, 0.357, 0.25,

0.323, 0.778, 0.667, 0.636, 0.583, 0.432, 0.412, 0.333, 0.571,

0.39, 0.4, 0.452, 0.326, 0.471, 0.7, 0.75, 0.615, 0.462, 0.556,

0.4, 0.696, 0.465), year3 = c(0.435, 0.759, 0.759, 0.759, 0.714,

0.593, 0.651, 0.683, 0.513, 0.643, 0.652, 0.757, 0.791, 0.649,

0.78, 0.5, 0.5, 0.5, 0.533, 0.429, 0.333, 0.286, 0.231, 0.533,

0.303, 0.417, 0.333, 0.333, 0.357, 0.909, 1, 0.952, 0.8, 0.556,

0.529, 0.562, 0.762, 0.513, 0.733, 0.611, 0.733, 0.647, 0.909,

0.857, 0.8, 0.556, 0.588, 0.562, 0.857, 0.513), year4 = c(0.333,

0.533, 0.6, 0.483, 0.743, 0.5, 0.691, 0.619, 0.583, 0.385, 0.653,

0.762, 0.844, 0.64, 0.667, 0.571, 0.571, 0.615, 0.421, 0.5, 0.205,

0.308, 0.25, 0.6, 0.242, 0.308, 0.276, 0.235, 0.211, 0.9, 0.632,

0.72, 0.727, 0.356, 0.5, 0.368, 0.5, 0.41, 0.562, 0.514, 0.4,

0.409, 0.632, 0.72, 0.727, 0.4, 0.5, 0.421, 0.5, 0.462)), .Names = c("year1",

"year2", "year3", "year4"), row.names = c(NA, -50L), class = "data.frame")

head(daT)

# null hypothesis; difference is equal to zero

dif1.2<-daT$year2-daT$year1

k=10000

mysamples1.2=replicate(k, sample(dif1.2, replace=T))

mymeans1.2=apply(mysamples1.2, 2, mean)

quantile(mymeans1.2, c(0.025, 0.975))

hist(mysamples1.2)

mean(mymeans1.2)

#what is p value?


#similarly Now I want to compare between year 1 and year3,

dif1.3<-daT$year3-daT$year1

mysamples1.3=replicate(k, sample(dif1.3, replace=T))

mymeans1.3=apply(mysamples1.3, 2, mean)

quantile(mymeans1.3, c(0.025, 0.975))


	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Tue Sep 11 09:44:46 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 11 Sep 2018 17:44:46 +1000
Subject: [R] loop for comparing two or more groups using bootstrapping
In-Reply-To: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
References: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
Message-ID: <CA+8X3fX6f6zT3VGbprbaOFMspKFijOncD0jiwodQ=cXShcnX_g@mail.gmail.com>

Hi Kristy,
Try this:

colname.mat<-combn(paste0("year",1:4),2)
samplenames<-apply(colname.mat,2,paste,collapse="")
k<-10000
for(column in 1:ncol(colname.mat)) {
 assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,column]]),3,TRUE)))
}

Then use get(samplenames[1]) and so on to access the values.

Jim
On Tue, Sep 11, 2018 at 4:52 PM Kristi Glover <kristi.glover at hotmail.com> wrote:
>
> Hi R users,
>
> I was trying to test a null hypothesis of difference between two groups was 0. I have many years data, such as year1, year2,, year3, year4 and I was trying to compare between year1 and year2, year1 and year3, year2 and year3 and so on and have used following code with an example data.
>
>
> I tried to make a loop but did not work to compare between many years, and also want to obtain the exact p value. Would you mind to help me to make a loop?
>
> Thanks for your help.
>
>
> KG
>
>
> daT<-structure(list(year1 = c(0.417, 0.538, 0.69, 0.688, 0.688, 0.606,
>
> 0.667, 0.7, 0.545, 0.462, 0.711, 0.642, 0.744, 0.604, 0.612,
>
> 0.667, 0.533, 0.556, 0.444, 0.526, 0.323, 0.308, 0.195, 0.333,
>
> 0.323, 0.256, 0.345, 0.205, 0.286, 0.706, 0.7, 0.6, 0.571, 0.364,
>
> 0.429, 0.326, 0.571, 0.424, 0.341, 0.387, 0.341, 0.324, 0.696,
>
> 0.696, 0.583, 0.556, 0.645, 0.435, 0.471, 0.556), year2 = c(0.385,
>
> 0.552, 0.645, 0.516, 0.629, 0.595, 0.72, 0.638, 0.557, 0.588,
>
> 0.63, 0.744, 0.773, 0.571, 0.723, 0.769, 0.667, 0.667, 0.526,
>
> 0.476, 0.294, 0.323, 0.222, 0.556, 0.263, 0.37, 0.357, 0.25,
>
> 0.323, 0.778, 0.667, 0.636, 0.583, 0.432, 0.412, 0.333, 0.571,
>
> 0.39, 0.4, 0.452, 0.326, 0.471, 0.7, 0.75, 0.615, 0.462, 0.556,
>
> 0.4, 0.696, 0.465), year3 = c(0.435, 0.759, 0.759, 0.759, 0.714,
>
> 0.593, 0.651, 0.683, 0.513, 0.643, 0.652, 0.757, 0.791, 0.649,
>
> 0.78, 0.5, 0.5, 0.5, 0.533, 0.429, 0.333, 0.286, 0.231, 0.533,
>
> 0.303, 0.417, 0.333, 0.333, 0.357, 0.909, 1, 0.952, 0.8, 0.556,
>
> 0.529, 0.562, 0.762, 0.513, 0.733, 0.611, 0.733, 0.647, 0.909,
>
> 0.857, 0.8, 0.556, 0.588, 0.562, 0.857, 0.513), year4 = c(0.333,
>
> 0.533, 0.6, 0.483, 0.743, 0.5, 0.691, 0.619, 0.583, 0.385, 0.653,
>
> 0.762, 0.844, 0.64, 0.667, 0.571, 0.571, 0.615, 0.421, 0.5, 0.205,
>
> 0.308, 0.25, 0.6, 0.242, 0.308, 0.276, 0.235, 0.211, 0.9, 0.632,
>
> 0.72, 0.727, 0.356, 0.5, 0.368, 0.5, 0.41, 0.562, 0.514, 0.4,
>
> 0.409, 0.632, 0.72, 0.727, 0.4, 0.5, 0.421, 0.5, 0.462)), .Names = c("year1",
>
> "year2", "year3", "year4"), row.names = c(NA, -50L), class = "data.frame")
>
> head(daT)
>
> # null hypothesis; difference is equal to zero
>
> dif1.2<-daT$year2-daT$year1
>
> k=10000
>
> mysamples1.2=replicate(k, sample(dif1.2, replace=T))
>
> mymeans1.2=apply(mysamples1.2, 2, mean)
>
> quantile(mymeans1.2, c(0.025, 0.975))
>
> hist(mysamples1.2)
>
> mean(mymeans1.2)
>
> #what is p value?
>
>
> #similarly Now I want to compare between year 1 and year3,
>
> dif1.3<-daT$year3-daT$year1
>
> mysamples1.3=replicate(k, sample(dif1.3, replace=T))
>
> mymeans1.3=apply(mysamples1.3, 2, mean)
>
> quantile(mymeans1.3, c(0.025, 0.975))
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From |eder|co@c@|bo|| @end|ng |rom ku|euven@be  Tue Sep 11 09:34:51 2018
From: |eder|co@c@|bo|| @end|ng |rom ku|euven@be (Federico Calboli)
Date: Tue, 11 Sep 2018 07:34:51 +0000
Subject: [R] getting 21 very different colours
Message-ID: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>

Hi All,

I am plotting a scatterplot of 21 populations, and I am using rainbow(21)[pops.col] to generate 21 colours for the plot (which works).  Maybe it is because I can really process few colours at a time, but the differences between the colours are not as strong as I?d like.  I can specify start and end for rainbow(), but if anything that looks worse if I do not just stick to 0 and 1.  

Is there a way of getting a set of 21 colours that maximises the differences between them?  

I could pick them by hand, but that is about 15 colours more than I know (I have a detailed colourchart, but the visual differences between ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).

Cheers

F
--
Federico Calboli
LBEG - Laboratory of Biodiversity and Evolutionary Genomics
Charles Deberiotstraat 32 box 2439
3000 Leuven
+32 16 32 87 67






From S@E|||@on @end|ng |rom LGCGroup@com  Tue Sep 11 12:08:25 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Tue, 11 Sep 2018 10:08:25 +0000
Subject: [R] getting 21 very different colours
In-Reply-To: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
References: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
Message-ID: <cb3c3ea557ea4a2d85d1dba4077992ba@GBDCVPEXC08.corp.lgc-group.com>

You could look at combning a number of palettes from the RColorBrewer package to get the palette length you want.

S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Federico
> Calboli
> Sent: 11 September 2018 08:35
> To: r-help at r-project.org
> Subject: [R] getting 21 very different colours
> 
> Hi All,
> 
> I am plotting a scatterplot of 21 populations, and I am using
> rainbow(21)[pops.col] to generate 21 colours for the plot (which works).
> Maybe it is because I can really process few colours at a time, but the
> differences between the colours are not as strong as I?d like.  I can specify
> start and end for rainbow(), but if anything that looks worse if I do not just
> stick to 0 and 1.
> 
> Is there a way of getting a set of 21 colours that maximises the differences
> between them?
> 
> I could pick them by hand, but that is about 15 colours more than I know (I
> have a detailed colourchart, but the visual differences between ?skyblue? and
> ?slategrey? elude me when plotted as dots on a plot).
> 
> Cheers
> 
> F
> --
> Federico Calboli
> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
> Charles Deberiotstraat 32 box 2439
> 3000 Leuven
> +32 16 32 87 67
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From kry|ov@r00t @end|ng |rom gm@||@com  Tue Sep 11 12:31:28 2018
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 11 Sep 2018 13:31:28 +0300
Subject: [R] getting 21 very different colours
In-Reply-To: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
References: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
Message-ID: <20180911133128.6b30960f@Tarkus>

On Tue, 11 Sep 2018 07:34:51 +0000
Federico Calboli <federico.calboli at kuleuven.be> wrote:

> Is there a way of getting a set of 21 colours that maximises the
> differences between them?  

In my limited experience, getting even 10 colours to look different
enough is a serious undertaking. Take a look at RColorBrewer:
display.brewer.all(n, "qual") stops offering palettes for n>12.

When I needed a 10-colour categorical/qualitative palette, I opted for
brute force approach of maximising the minimal distance between points
in HCL colourspace, although later my colleague told me that I just
needed an existing algorithm to place the points uniformly. It has to
be HCL and not RGB because HCL signifies the way people perceive
different colours while RGB is only a good representation hardware-wise.

Here is my code; the usual disclaimers about stuff written between 1 and
3 AM apply:

# -------------------------8<---------------------------

require(nloptr)

h <- c(0,360)
c <- c(0,137) # see the warning about fixup in `?hcl`: not all HCL points are representable in RGB

# NOTE: depending on your plot background, you may have to change at least luminance range
l <- c(30,90)

npoints <- 24 # I had only 10 here

pts <- matrix(ncol=3, nrow=npoints, dimnames=list(NULL, c("h","c","l")))
pts[,"h"] <- runif(npoints, min=h[1], max=h[2])
pts[,"c"] <- runif(npoints, min=c[1], max=c[2])
pts[,"l"] <- runif(npoints, min=l[1], max=l[2])

lb <- cbind(h=rep(h[1],npoints), c=rep(c[1],npoints), l=rep(l[1],npoints))
ub <- cbind(h=rep(h[2],npoints), c=rep(c[2],npoints), l=rep(l[2],npoints))

obj <- function(x) {
        pts[,c("h","c","l")] <- x
	# somehow the best results were achieved by calculating Euclidean distance from cylindrical coordinates
        pts <- cbind(pts[,"c"]*sin(pts[,'h']/360*2*pi), pts[,'c']*cos(pts[,'h']/360*2*pi), pts[,'l'])
        d <- as.matrix(dist(pts))
        diag(d) <- NA
	# maximise minimal distance <=> minimize negative of minimal distance
        -min(d, na.rm=T)
}

# the stopping criterion is a bit lame, but the objective function here is very hard to minimize
# 1e6 iterations take a few minutes on a relatively modern desktop
sol <- nloptr(as.vector(pts), obj, lb=as.vector(lb), ub=as.vector(ub), opts=list(algorithm="NLOPT_GN_CRS2_LM", maxeval=1e6))

pts[,c("h","c",'l')] <- sol$solution

plot(pts[,"c"] * sin(pts[,"h"]/360*2*pi), pts[,"c"] * cos(pts[,"h"]/360*2*pi), col=hcl(pts[,"h"], pts[,"c"], l), pch=19, cex=2)

# -------------------------8<---------------------------

I couldn't get my code to produce 24 acceptably different colours, but
maybe you will succeed with a similar approach.

-- 
Best regards,
Ivan



From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Sep 11 12:43:57 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 11 Sep 2018 06:43:57 -0400
Subject: [R] getting 21 very different colours
In-Reply-To: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
References: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
Message-ID: <8924791d-15e5-08f0-e3e3-c91e623bb4a7@gmail.com>

On 11/09/2018 3:34 AM, Federico Calboli wrote:
> Hi All,
> 
> I am plotting a scatterplot of 21 populations, and I am using rainbow(21)[pops.col] to generate 21 colours for the plot (which works).  Maybe it is because I can really process few colours at a time, but the differences between the colours are not as strong as I?d like.  I can specify start and end for rainbow(), but if anything that looks worse if I do not just stick to 0 and 1.
> 
> Is there a way of getting a set of 21 colours that maximises the differences between them?

The LAB and LUV color spaces (in the colorspace package) attempt to map 
perceptual differences to equal distances.  You could try using a grid 
of points in one of those spaces, but not all triples are valid.

However, 21 colours is probably too many for your purpose.  If you 
really want to distinguish 21 groups, you're likely going to have to use 
other characteristics as well, such as the symbol.  You could plot 21 
different letters in 5 different colours and it might work, but it's not 
going to be easy for viewers.

Duncan Murdoch

> 
> I could pick them by hand, but that is about 15 colours more than I know (I have a detailed colourchart, but the visual differences between ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).
> 
> Cheers
> 
> F
> --
> Federico Calboli
> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
> Charles Deberiotstraat 32 box 2439
> 3000 Leuven
> +32 16 32 87 67
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From h@medh@@e|| @end|ng |rom gm@||@com  Tue Sep 11 14:38:38 2018
From: h@medh@@e|| @end|ng |rom gm@||@com (Hamed Ha)
Date: Tue, 11 Sep 2018 13:38:38 +0100
Subject: [R] Problem with lm.resid() when weights are provided
In-Reply-To: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
References: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
Message-ID: <CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>

Dear R Help Team.

I get some weird results when I use the lm function with weight. The issue
can be reproduced by the example below:


The input data is (weights are intentionally designed to reflect some
structures in the data)


> df
y x weight
 1.51156139  0.55209240 2.117337e-34
-0.63653132 -0.12599316 2.117337e-34
 0.37782776  0.42095384 4.934135e-31
 3.03792318  1.40315446 2.679495e-24
 1.53646523  0.46076858 2.679495e-24
-2.37727874 -0.73963576 6.244160e-21
 0.37183065  0.20407468 1.455107e-17
-1.53917553 -0.95519361 1.455107e-17
 1.10926675  0.03897129 3.390908e-14
-0.37786333 -0.17523593 3.390908e-14
 2.43973603  0.97970095 7.902000e-11
-0.35432394 -0.03742559 7.902000e-11
 2.19296613  1.00355263 4.289362e-04
 0.49845532  0.34816207 4.289362e-04
 1.25005260  0.76306225 5.000000e-01
 0.84360691  0.45152356 5.000000e-01
 0.29565993  0.53880068 5.000000e-01
-0.54081334 -0.28104525 5.000000e-01
 0.83612836 -0.12885659 9.995711e-01
-1.42526769 -0.87107631 9.999998e-01
 0.10204789 -0.11649899 1.000000e+00
 1.14292898  0.37249631 1.000000e+00
-3.02942081 -1.28966997 1.000000e+00
-1.37549764 -0.74676145 1.000000e+00
-2.00118016 -0.55182759 1.000000e+00
-4.24441674 -1.94603608 1.000000e+00
 1.17168144  1.00868008 1.000000e+00
 2.64007761  1.26333069 1.000000e+00
 1.98550114  1.18509599 1.000000e+00
-0.58941683 -0.61972416 9.999998e-01
-4.57559611 -2.30914920 9.995711e-01
-0.82610544 -0.39347576 9.995711e-01
-0.02768220  0.20076910 9.995711e-01
 0.78186399  0.25690215 9.995711e-01
-0.88314153 -0.20200148 5.000000e-01
-4.17076452 -2.03547588 5.000000e-01
 0.93373070  0.54190626 4.289362e-04
-0.08517734  0.17692491 4.289362e-04
-4.47546619 -2.14876688 4.289362e-04
-1.65509103 -0.76898087 4.289362e-04
-0.39403030 -0.12689705 4.289362e-04
 0.01203300 -0.18689898 1.841442e-07
-4.82762639 -2.31391121 1.841442e-07
-0.72658380 -0.39751171 3.397282e-14
-2.35886866 -1.01082109 0.000000e+00
-2.03762707 -0.96439902 0.000000e+00
 0.90115123  0.60172286 0.000000e+00
 1.55999194  0.83433953 0.000000e+00
 3.07994058  1.30942776 0.000000e+00
 1.78871462  1.10605530 0.000000e+00



Running simple linear model returns:

> lm(y~x,data=df)

Call:
lm(formula = y ~ x, data = df)

Coefficients:
(Intercept)            x
   -0.04173      2.03790

and
> max(resid(lm(y~x,data=df)))
[1] 1.14046


*HOWEVER if I use the weighted model then:*

lm(formula = y ~ x, data = df, weights = df$weights)

Coefficients:
(Intercept)            x
   -0.05786      1.96087

and
> max(resid(lm(y~x,data=df,weights=df$weights)))
[1] 60.91888


as you see, the estimation of the coefficients are nearly the same but the
resid() function returns a giant residual (I have some cases where the
value is much much higher). Further, if I calculate the residuals by
simply predict(lm(y~x,data=df,weights=df$weights))-df$y then I get the true
value for the residuals.


Thanks.

Please do not hesitate to contact me for more details.
Regards,
Hamed.

	[[alternative HTML version deleted]]



From kr|@t|@g|over @end|ng |rom hotm@||@com  Tue Sep 11 15:55:18 2018
From: kr|@t|@g|over @end|ng |rom hotm@||@com (Kristi Glover)
Date: Tue, 11 Sep 2018 13:55:18 +0000
Subject: [R] loop for comparing two or more groups using bootstrapping
In-Reply-To: <CA+8X3fX6f6zT3VGbprbaOFMspKFijOncD0jiwodQ=cXShcnX_g@mail.gmail.com>
References: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>,
 <CA+8X3fX6f6zT3VGbprbaOFMspKFijOncD0jiwodQ=cXShcnX_g@mail.gmail.com>
Message-ID: <CY4PR1301MB21673838F1F43BB962933542FA040@CY4PR1301MB2167.namprd13.prod.outlook.com>

Dear Jim,

Thank you very much for the code. I run it but it gave me row names like "year224", "year142".

are these the difference between columns? If we want to get bootstrapping means of difference between years (year2-year1; year3-year1), its CI and exact p value, how can we get it?

thanks

KG

----

head(daT)

colname.mat<-combn(paste0("year",1:4),2)

samplenames<-apply(colname.mat,2,paste,collapse="")

k<-10

for(column in 1:ncol(colname.mat)) {

 assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,column]]),3,TRUE)))

}


> get(samplenames[1])
         [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
year224 0.556 0.667 0.571 0.526 0.629 0.696 0.323 0.526 0.256 0.667
year142 0.324 0.324 0.706 0.638 0.600 0.294 0.612 0.688 0.432 0.387
year237 0.571 0.696 0.629 0.471 0.462 0.471 0.452 0.595 0.333 0.435




________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: September 11, 2018 1:44 AM
To: Kristi Glover
Cc: r-help mailing list
Subject: Re: [R] loop for comparing two or more groups using bootstrapping

Hi Kristy,
Try this:

colname.mat<-combn(paste0("year",1:4),2)
samplenames<-apply(colname.mat,2,paste,collapse="")
k<-10000
for(column in 1:ncol(colname.mat)) {
 assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,column]]),3,TRUE)))
}

Then use get(samplenames[1]) and so on to access the values.

Jim
On Tue, Sep 11, 2018 at 4:52 PM Kristi Glover <kristi.glover at hotmail.com> wrote:
>
> Hi R users,
>
> I was trying to test a null hypothesis of difference between two groups was 0. I have many years data, such as year1, year2,, year3, year4 and I was trying to compare between year1 and year2, year1 and year3, year2 and year3 and so on and have used following code with an example data.
>
>
> I tried to make a loop but did not work to compare between many years, and also want to obtain the exact p value. Would you mind to help me to make a loop?
>
> Thanks for your help.
>
>
> KG
>
>
> daT<-structure(list(year1 = c(0.417, 0.538, 0.69, 0.688, 0.688, 0.606,
> 0.667, 0.7, 0.545, 0.462, 0.711, 0.642, 0.744, 0.604, 0.612,
> 0.667, 0.533, 0.556, 0.444, 0.526, 0.323, 0.308, 0.195, 0.333,
> 0.323, 0.256, 0.345, 0.205, 0.286, 0.706, 0.7, 0.6, 0.571, 0.364,
> 0.429, 0.326, 0.571, 0.424, 0.341, 0.387, 0.341, 0.324, 0.696,
> 0.696, 0.583, 0.556, 0.645, 0.435, 0.471, 0.556), year2 = c(0.385,
> 0.552, 0.645, 0.516, 0.629, 0.595, 0.72, 0.638, 0.557, 0.588,
> 0.63, 0.744, 0.773, 0.571, 0.723, 0.769, 0.667, 0.667, 0.526,
> 0.476, 0.294, 0.323, 0.222, 0.556, 0.263, 0.37, 0.357, 0.25,
> 0.323, 0.778, 0.667, 0.636, 0.583, 0.432, 0.412, 0.333, 0.571,
> 0.39, 0.4, 0.452, 0.326, 0.471, 0.7, 0.75, 0.615, 0.462, 0.556,
> 0.4, 0.696, 0.465), year3 = c(0.435, 0.759, 0.759, 0.759, 0.714,
> 0.593, 0.651, 0.683, 0.513, 0.643, 0.652, 0.757, 0.791, 0.649,
> 0.78, 0.5, 0.5, 0.5, 0.533, 0.429, 0.333, 0.286, 0.231, 0.533,
> 0.303, 0.417, 0.333, 0.333, 0.357, 0.909, 1, 0.952, 0.8, 0.556,
> 0.529, 0.562, 0.762, 0.513, 0.733, 0.611, 0.733, 0.647, 0.909,
> 0.857, 0.8, 0.556, 0.588, 0.562, 0.857, 0.513), year4 = c(0.333,
> 0.533, 0.6, 0.483, 0.743, 0.5, 0.691, 0.619, 0.583, 0.385, 0.653,
> 0.762, 0.844, 0.64, 0.667, 0.571, 0.571, 0.615, 0.421, 0.5, 0.205,
> 0.308, 0.25, 0.6, 0.242, 0.308, 0.276, 0.235, 0.211, 0.9, 0.632,
> 0.72, 0.727, 0.356, 0.5, 0.368, 0.5, 0.41, 0.562, 0.514, 0.4,
> 0.409, 0.632, 0.72, 0.727, 0.4, 0.5, 0.421, 0.5, 0.462)), .Names = c("year1",
> "year2", "year3", "year4"), row.names = c(NA, -50L), class = "data.frame")
>
> head(daT)
>
> # null hypothesis; difference is equal to zero
>
> dif1.2<-daT$year2-daT$year1
>
> k=10000
>
> mysamples1.2=replicate(k, sample(dif1.2, replace=T))
>
> mymeans1.2=apply(mysamples1.2, 2, mean)
>
> quantile(mymeans1.2, c(0.025, 0.975))
>
> hist(mysamples1.2)
>
> mean(mymeans1.2)
>
> #what is p value?
>
>
> #similarly Now I want to compare between year 1 and year3,
>
> dif1.3<-daT$year3-daT$year1
>
> mysamples1.3=replicate(k, sample(dif1.3, replace=T))
>
> mymeans1.3=apply(mysamples1.3, 2, mean)
>
> quantile(mymeans1.3, c(0.025, 0.975))
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help

thz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R, enhancements and patches to the source code and documentation of R, comparison and compatibility with S and S-plus, and for the posting of nice examples and benchmarks.



> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From dc@r|@on @end|ng |rom t@mu@edu  Tue Sep 11 16:50:07 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Tue, 11 Sep 2018 14:50:07 +0000
Subject: [R] For loop with multiple iteration indexes
In-Reply-To: <CACg0228eV_KsSyHpT6iBVhSyQ1hfFv2Nazj7a1JJrpMOfVQDLg@mail.gmail.com>
References: <CACg02295magQZts6jWS4rBJCuN=2-vHSfFLpcZkLcwP5cNpaAw@mail.gmail.com>
 <F226B06A-9457-47DF-A9F0-9B995D999475@ucsd.edu>
 <CACg0228eV_KsSyHpT6iBVhSyQ1hfFv2Nazj7a1JJrpMOfVQDLg@mail.gmail.com>
Message-ID: <062ad885a87b40cba826833940de1eff@tamu.edu>

Just for fun, there are ways to do this in R without an explicit loop:

> set.seed(42)
> dat <- matrix(rnorm(10*5), 10, 5)
> x <- sample(1:5)
> y <- sample(1:5)
> diag(cor(dat[, x], dat[, y]))
[1] -0.69156568 -0.06002371 -0.37492894  0.46477742 -0.37972866

You can use as.list() to convert the vector to a list.

> i <- seq_len(length(x))
> sapply(i, function(j) cor(dat[, x[j]], dat[, y[j]]))
[1] -0.69156568 -0.06002371 -0.37492894  0.46477742 -0.37972866
> xy <- cbind(x, y)
> sapply(i, function(j) cor(dat[, xy[j, ]])[1, 2])
[1] -0.69156568 -0.06002371 -0.37492894  0.46477742 -0.37972866

Change sapply() to lapply() to get list output.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of David Disabato
Sent: Monday, September 10, 2018 8:33 PM
To: r-help at r-project.org
Subject: Re: [R] For loop with multiple iteration indexes

Thank you everyone. After thinking about each response, I realized a fairly simple solution is available (obviously, other suggested approaches work as
well):

stopifnot(length(x) == length(y); stopifnot(length(x) > 0) r <- list() for (i in 1:length(x) ) {
   r[[i]] <- cor(x = dat[, x[i] ], y = dat[, y[i] ]) }
print(r)

On Mon, Sep 10, 2018 at 11:30 AM Berry, Charles <ccberry at ucsd.edu> wrote:

> I have a sense of deja vu:
>
> https://www.mail-archive.com/r-help at r-project.org/msg250494.html
>
> There is some good advice there.
>
> > On Sep 9, 2018, at 3:49 PM, David Disabato <ddisab01 at gmail.com> wrote:
> >
> > Hi R-help,
> >
> > I am trying to create a for loop with multiple iteration indexes. I 
> > don't want to use two different for loops nested together because I 
> > don't need the full matrix of the two indexes, just the diagonal 
> > elements (e.g.,
> i[1]
> > & j[1] and i[2] & j[2], but not i[1] & j[2]). Is there a way to 
> > specify both i and j in a single for loop? Here is a simplified 
> > example of pseudo-code where x and y are equally sized character 
> > vectors with column names and dat is their dataframe (obviously this 
> > code doesn't run in R,
> but
> > hopefully you perceive my goal):
> >
> > r <- list()
> > n <- 0
> > for (i in x; j in y) {
> >   n <- n + 1
> >   r[[n]] <- cor(x = dat[, i], y = dat[, j]) }
> > print(r)
> >
> > I realize there are other solutions to this particular correlation
> example,
> > but my actual problem is much more complicated, so I am hoping for a 
> > solution that generalizes across any code within the for loop.
>
> A more aRtful way (than a for loop) to approach this is with mapply:
>
>
> i <- head(colnames(mtcars))
> j <- tail(colnames(mtcars))
>
> r <- mapply(function(i, j, dat) cor( x = dat[, i], y = dat[, j]),
>        i=i , j=j , MoreArgs = list( dat = mtcars),
>        SIMPLIFY = FALSE, USE.NAMES = FALSE)
>
>
> and if you want, maybe USE.NAMES = paste(i, j, sep="_")
>
> Chuck
>
>

--
David J. Disabato, M.A.
Clinical Psychology Doctoral Student
George Mason University
ddisabat at gmu.edu

Email is not a secure form of communication as information and confidentiality cannot be guaranteed. Information provided in an email is not intended to be a professional service. In the case of a crisis or emergency situation, call 911.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk  Tue Sep 11 17:36:31 2018
From: b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk (Barry Rowlingson)
Date: Tue, 11 Sep 2018 16:36:31 +0100
Subject: [R] getting 21 very different colours
In-Reply-To: <048d1aa7d3f246d386bdae5812f94c9a@LNXP265MB1290.GBRP265.PROD.OUTLOOK.COM>
References: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
 <048d1aa7d3f246d386bdae5812f94c9a@LNXP265MB1290.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CANVKczNSEwrmkoFq8jNksC3N=SUacaWUB0Oho_REVUeRBBqZTw@mail.gmail.com>

On Tue, Sep 11, 2018 at 11:43 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 11/09/2018 3:34 AM, Federico Calboli wrote:
> > Hi All,
> >
> > I am plotting a scatterplot of 21 populations, and I am using
> rainbow(21)[pops.col] to generate 21 colours for the plot (which works).
> Maybe it is because I can really process few colours at a time, but the
> differences between the colours are not as strong as I?d like.  I can
> specify start and end for rainbow(), but if anything that looks worse if I
> do not just stick to 0 and 1.
> >
> > Is there a way of getting a set of 21 colours that maximises the
> differences between them?
>
> The LAB and LUV color spaces (in the colorspace package) attempt to map
> perceptual differences to equal distances.  You could try using a grid
> of points in one of those spaces, but not all triples are valid.
>
> However, 21 colours is probably too many for your purpose.  If you
> really want to distinguish 21 groups, you're likely going to have to use
> other characteristics as well, such as the symbol.  You could plot 21
> different letters in 5 different colours and it might work, but it's not
> going to be easy for viewers.
>
>
The `alphabet` and `alphabet2` palettes from the `pals` package claim 26
"distinguishable" colours:

Details:

     The ?alphabet? palette has 26 distinguishable colors that have
     logical names starting with the English alphabet letters A, B, ...
     Z. This palette is based on the work by Green-Armytage (2010), but
     uses the names 'orange' instead of 'orpiment', and 'magenta'
     instead of 'mallow'.

There are some other palettes in that help page (?alphabet) that might also
work. But 21 colours is pushing it.

Barry






> Duncan Murdoch
>
> >
> > I could pick them by hand, but that is about 15 colours more than I know
> (I have a detailed colourchart, but the visual differences between
> ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).
> >
> > Cheers
> >
> > F
> > --
> > Federico Calboli
> > LBEG - Laboratory of Biodiversity and Evolutionary Genomics
> > Charles Deberiotstraat 32 box 2439
> > 3000 Leuven
> > +32 16 32 87 67
> >
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Tue Sep 11 20:02:00 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Tue, 11 Sep 2018 14:02:00 -0400
Subject: [R] Bar Graph
Message-ID: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>

Dear All:


I do need your help on how to add frequency to bar plot on the top of each
bar.


here is the R code.


*Number.of.Death <- c(432, 217,93, 34, 224)    ##### Number of Death*

*Cause.of.Death <- c("Heart disease", "Cancer", "Stroke", "Accidents",
"Other")  *

*barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Grapg for
Death Data", ylab="Number of Death", xlab="Cause of Death") *



Thank you very much for your help in advance.


with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep 11 20:24:13 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 11 Sep 2018 19:24:13 +0100
Subject: [R] Bar Graph
In-Reply-To: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
References: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
Message-ID: <00e960fd-71d4-453e-5c80-e3571f6ec76d@sapo.pt>

Hello,

Use function text() with the return of barplot() as x value and 
Number.of.Death as y.
Note that the limits of the y axis are not the automatic ones.



bp <- barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Graph for
Death Data", ylab="Number of Death", xlab="Cause of Death", ylim = c(0, 
500))

text(x = bp, y = Number.of.Death, labels = Number.of.Death, pos = 3)


Hope this helps,

Rui Barradas

On 11-09-2018 19:02, AbouEl-Makarim Aboueissa wrote:
> Dear All:
> 
> 
> I do need your help on how to add frequency to bar plot on the top of each
> bar.
> 
> 
> here is the R code.
> 
> 
> *Number.of.Death <- c(432, 217,93, 34, 224)    ##### Number of Death*
> 
> *Cause.of.Death <- c("Heart disease", "Cancer", "Stroke", "Accidents",
> "Other")  *
> 
> *barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Grapg for
> Death Data", ylab="Number of Death", xlab="Cause of Death") *
> 
> 
> 
> Thank you very much for your help in advance.
> 
> 
> with many thanks
> abou
> ______________________
> 
> 
> *AbouEl-Makarim Aboueissa, PhD*
> 
> *Professor of Statistics*
> *Graduate Coordinator*
> 
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 11 20:47:36 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Sep 2018 11:47:36 -0700
Subject: [R] Bar Graph
In-Reply-To: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
References: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
Message-ID: <CAGxFJbQCpLoqKxTuvtz3RMSKexYqNVSR_Z8=4WKVYG-pzVa0tw@mail.gmail.com>

Not quite -- he wanted the frequencies not the counts. So something
like this (using the adj argument to center the frequencies above each
bar:

bp <-barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar
Graph for Death Data", ylab="Number of Deaths", xlab="Cause of Death",
ylim = c(0,500) )

text(bp, y = Number.of.Death + 30, adj = .5,
     lab = round(Number.of.Death/sum(Number.of.Death),2))

Cheers,
Bert

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Sep 11, 2018 at 11:02 AM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear All:
>
>
> I do need your help on how to add frequency to bar plot on the top of each
> bar.
>
>
> here is the R code.
>
>
> *Number.of.Death <- c(432, 217,93, 34, 224)    ##### Number of Death*
>
> *Cause.of.Death <- c("Heart disease", "Cancer", "Stroke", "Accidents",
> "Other")  *
>
> *barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Grapg for
> Death Data", ylab="Number of Death", xlab="Cause of Death") *
>
>
>
> Thank you very much for your help in advance.
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Tue Sep 11 21:23:36 2018
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Wed, 12 Sep 2018 07:23:36 +1200
Subject: [R] [FORGED] Re:  getting 21 very different colours
In-Reply-To: <CANVKczNSEwrmkoFq8jNksC3N=SUacaWUB0Oho_REVUeRBBqZTw@mail.gmail.com>
References: <08A6397B-4D67-4195-A53A-1FD394F72B6C@kuleuven.be>
 <048d1aa7d3f246d386bdae5812f94c9a@LNXP265MB1290.GBRP265.PROD.OUTLOOK.COM>
 <CANVKczNSEwrmkoFq8jNksC3N=SUacaWUB0Oho_REVUeRBBqZTw@mail.gmail.com>
Message-ID: <d3a5aaf0-81b6-2d33-6f93-72523639e290@stat.auckland.ac.nz>


You could also take a look at the 'Polychrome' package

Paul

On 12/09/18 03:36, Barry Rowlingson wrote:
> On Tue, Sep 11, 2018 at 11:43 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> 
>> On 11/09/2018 3:34 AM, Federico Calboli wrote:
>>> Hi All,
>>>
>>> I am plotting a scatterplot of 21 populations, and I am using
>> rainbow(21)[pops.col] to generate 21 colours for the plot (which works).
>> Maybe it is because I can really process few colours at a time, but the
>> differences between the colours are not as strong as I?d like.  I can
>> specify start and end for rainbow(), but if anything that looks worse if I
>> do not just stick to 0 and 1.
>>>
>>> Is there a way of getting a set of 21 colours that maximises the
>> differences between them?
>>
>> The LAB and LUV color spaces (in the colorspace package) attempt to map
>> perceptual differences to equal distances.  You could try using a grid
>> of points in one of those spaces, but not all triples are valid.
>>
>> However, 21 colours is probably too many for your purpose.  If you
>> really want to distinguish 21 groups, you're likely going to have to use
>> other characteristics as well, such as the symbol.  You could plot 21
>> different letters in 5 different colours and it might work, but it's not
>> going to be easy for viewers.
>>
>>
> The `alphabet` and `alphabet2` palettes from the `pals` package claim 26
> "distinguishable" colours:
> 
> Details:
> 
>       The ?alphabet? palette has 26 distinguishable colors that have
>       logical names starting with the English alphabet letters A, B, ...
>       Z. This palette is based on the work by Green-Armytage (2010), but
>       uses the names 'orange' instead of 'orpiment', and 'magenta'
>       instead of 'mallow'.
> 
> There are some other palettes in that help page (?alphabet) that might also
> work. But 21 colours is pushing it.
> 
> Barry
> 
> 
> 
> 
> 
> 
>> Duncan Murdoch
>>
>>>
>>> I could pick them by hand, but that is about 15 colours more than I know
>> (I have a detailed colourchart, but the visual differences between
>> ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).
>>>
>>> Cheers
>>>
>>> F
>>> --
>>> Federico Calboli
>>> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
>>> Charles Deberiotstraat 32 box 2439
>>> 3000 Leuven
>>> +32 16 32 87 67
>>>
>>>
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Tue Sep 11 21:28:12 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Tue, 11 Sep 2018 15:28:12 -0400
Subject: [R] Bar Graph
In-Reply-To: <CAGxFJbQCpLoqKxTuvtz3RMSKexYqNVSR_Z8=4WKVYG-pzVa0tw@mail.gmail.com>
References: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
 <CAGxFJbQCpLoqKxTuvtz3RMSKexYqNVSR_Z8=4WKVYG-pzVa0tw@mail.gmail.com>
Message-ID: <CAE9stmfafQJ9mT_w_sX65GRjsQKdQhR9qKSYzw6wn9wk7UzETA@mail.gmail.com>

Dear Bert:

thank you very much

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Tue, Sep 11, 2018 at 2:47 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Not quite -- he wanted the frequencies not the counts. So something
> like this (using the adj argument to center the frequencies above each
> bar:
>
> bp <-barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar
> Graph for Death Data", ylab="Number of Deaths", xlab="Cause of Death",
> ylim = c(0,500) )
>
> text(bp, y = Number.of.Death + 30, adj = .5,
>      lab = round(Number.of.Death/sum(Number.of.Death),2))
>
> Cheers,
> Bert
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Sep 11, 2018 at 11:02 AM AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> >
> > Dear All:
> >
> >
> > I do need your help on how to add frequency to bar plot on the top of
> each
> > bar.
> >
> >
> > here is the R code.
> >
> >
> > *Number.of.Death <- c(432, 217,93, 34, 224)    ##### Number of Death*
> >
> > *Cause.of.Death <- c("Heart disease", "Cancer", "Stroke", "Accidents",
> > "Other")  *
> >
> > *barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Grapg for
> > Death Data", ylab="Number of Death", xlab="Cause of Death") *
> >
> >
> >
> > Thank you very much for your help in advance.
> >
> >
> > with many thanks
> > abou
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor of Statistics*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Tue Sep 11 21:28:57 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Tue, 11 Sep 2018 15:28:57 -0400
Subject: [R] Bar Graph
In-Reply-To: <00e960fd-71d4-453e-5c80-e3571f6ec76d@sapo.pt>
References: <CAE9stmd8UXk5-UoQFT42x9AdykzoWdeTHbPnp6-znVVbTfff5w@mail.gmail.com>
 <00e960fd-71d4-453e-5c80-e3571f6ec76d@sapo.pt>
Message-ID: <CAE9stmdOdTzRuMCUZPmSLLpmWZ99Z8axx+i_AcF+NBoW1-h-Hg@mail.gmail.com>

Dear  Rui:

thank you very much

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Tue, Sep 11, 2018 at 2:24 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Use function text() with the return of barplot() as x value and
> Number.of.Death as y.
> Note that the limits of the y axis are not the automatic ones.
>
>
>
> bp <- barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Graph
> for
> Death Data", ylab="Number of Death", xlab="Cause of Death", ylim = c(0,
> 500))
>
> text(x = bp, y = Number.of.Death, labels = Number.of.Death, pos = 3)
>
>
> Hope this helps,
>
> Rui Barradas
>
> On 11-09-2018 19:02, AbouEl-Makarim Aboueissa wrote:
> > Dear All:
> >
> >
> > I do need your help on how to add frequency to bar plot on the top of
> each
> > bar.
> >
> >
> > here is the R code.
> >
> >
> > *Number.of.Death <- c(432, 217,93, 34, 224)    ##### Number of Death*
> >
> > *Cause.of.Death <- c("Heart disease", "Cancer", "Stroke", "Accidents",
> > "Other")  *
> >
> > *barplot(Number.of.Death, names.arg=Cause.of.Death, main="Bar Grapg for
> > Death Data", ylab="Number of Death", xlab="Cause of Death") *
> >
> >
> >
> > Thank you very much for your help in advance.
> >
> >
> > with many thanks
> > abou
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor of Statistics*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]



From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Tue Sep 11 21:43:13 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Tue, 11 Sep 2018 15:43:13 -0400
Subject: [R] Remove plot axis values in dotplot graph
Message-ID: <CAE9stmdidxkAMbA-6+cFRPZMVppQt+rj6WYPJ-1AhHiqcPBpaA@mail.gmail.com>

Dear All:

One more thing. I want to Remove the plot x-axis values in dotplot graph. I
am trying to use xaxt = "n", but it seems NOT working. Also after removing
the x-axis values, I want to use the command axis(1, at=0:16, cex.axis=1)
to add x-axis values from 0 to 16, but it seems not working as expect.



Honey.Dosage<-c(12,11,15,11,10,13,10,4,15,16,9,14,10,6,10,8,11,12,12,8,12,9,11,15,10,15,9,13,8,12,10,8,9,5,12)

DM.Dosage<-c(4,6,9,4,7,7,7,9,12,10,11,6,3,4,9,12,7,6,8,12,12,4,12,13,7,10,13,9,4,4,10,15,9)

No.Dosage<-c(5,8,6,1,0,8,12,8,7,7,1,6,7,7,12,7,9,7,9,5,11,9,5,6,8,8,6,7,10,9,4,8,7,3,1,4,3)

scores<-c(Honey.Dosage,DM.Dosage,No.Dosage)

min(scores)
max(scores)

dotchart(scores,cex=1.5, pch = 18, col=c(1:3), xaxt = "n", main="Dot Plot
child?s cough data", xlab="cough Scores")

axis(1, at=0:16, cex.axis=1.5)




with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 11 23:46:24 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 14:46:24 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes
Message-ID: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>

   Every lattice xyplot() I've created before this one has tick marks on only
the left and bottom axes. The current plot has sprouted tick marks on the
top and right side, too, and I want to remove them. I've not found an answer
to this issue in Deepayan's book or on the web. I would appreciate also
learning why the extra tick marks appeared. The dput() data are included.

   The plotting command;

rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'h',
                        main = 'Monthly Total Precipitation\n2005-2018',
                        xlab = 'Year and Month', ylab = 'Precipitation (in)',
                        scales = list(x = list(at = seq(1,162,by=6), cex = 0.7, rot = 90)))

plot(rain.all.sum)

   The data:

structure(list(Month = structure(1:162, .Label = c("2005-01", 
"2005-02", "2005-03", "2005-04", "2005-05", "2005-06", "2005-07", 
"2005-08", "2005-09", "2005-10", "2005-11", "2005-12", "2006-01", 
"2006-02", "2006-03", "2006-04", "2006-05", "2006-06", "2006-07", 
"2006-08", "2006-09", "2006-10", "2006-11", "2006-12", "2007-01", 
"2007-02", "2007-03", "2007-04", "2007-05", "2007-06", "2007-07", 
"2007-08", "2007-09", "2007-10", "2007-11", "2007-12", "2008-01", 
"2008-02", "2008-03", "2008-04", "2008-05", "2008-06", "2008-07", 
"2008-08", "2008-09", "2008-10", "2008-11", "2008-12", "2009-01", 
"2009-02", "2009-03", "2009-04", "2009-05", "2009-06", "2009-07", 
"2009-08", "2009-09", "2009-10", "2009-11", "2009-12", "2010-01", 
"2010-02", "2010-03", "2010-04", "2010-05", "2010-06", "2010-07", 
"2010-08", "2010-09", "2010-10", "2010-11", "2010-12", "2011-01", 
"2011-02", "2011-03", "2011-04", "2011-05", "2011-06", "2011-07", 
"2011-08", "2011-09", "2011-10", "2011-11", "2011-12", "2012-01", 
"2012-02", "2012-03", "2012-04", "2012-05", "2012-06", "2012-07", 
"2012-08", "2012-09", "2012-10", "2012-11", "2012-12", "2013-01", 
"2013-02", "2013-03", "2013-04", "2013-05", "2013-06", "2013-07", 
"2013-08", "2013-09", "2013-10", "2013-11", "2013-12", "2014-01", 
"2014-02", "2014-03", "2014-04", "2014-05", "2014-06", "2014-07", 
"2014-08", "2014-09", "2014-10", "2014-11", "2014-12", "2015-01", 
"2015-02", "2015-03", "2015-04", "2015-05", "2015-06", "2015-07", 
"2015-08", "2015-09", "2015-10", "2015-11", "2015-12", "2016-01", 
"2016-02", "2016-03", "2016-04", "2016-05", "2016-06", "2016-07", 
"2016-08", "2016-09", "2016-10", "2016-11", "2016-12", "2017-01", 
"2017-02", "2017-03", "2017-04", "2017-05", "2017-06", "2017-07", 
"2017-08", "2017-09", "2017-10", "2017-11", "2017-12", "2018-01", 
"2018-02", "2018-03", "2018-04", "2018-05", "2018-06"), class = "factor"),
     Sum = c(53.51, 24.2, 88.54, 72.85, 77.3, 49.19, 8.77, 5.75,
     27.83, 79.75, 123.89, 168.29, 229.69, 70.91, 74.15, 62.3,
     43.56, 35.08, 3.6, 2.76, 26.83, 47.72, 293.23, 139.84, 103.48,
     120.91, 85.96, 55.91, 26.56, 29.44, 9.9, 15.38, 33.47, 93.6,
     105.61, 277.41, 279.38, 144.26, 220.88, 149.75, 82.28, 55.87,
     5.29, 52.27, 21.1, 64.76, 182.31, 207.13, 196.29, 89.27,
     187.72, 111.67, 111.72, 38.19, 6.07, 15.25, 52.46, 127.75,
     208.43, 146.62, 169.34, 94.54, 154.21, 131.39, 151.27, 135.46,
     9.98, 8.72, 86.67, 142.04, 225.61, 274.93, 196.68, 153.24,
     263.54, 231.49, 122.23, 58.26, 34.65, 2.96, 28.21, 103.92,
     217.52, 166.16, 305.27, 168.73, 333.28, 145.68, 101.2, 127.77,
     15.41, 1.85, 3.49, 245.99, 272.35, 297.05, 177.17, 105.71,
     118.44, 136.34, 161.01, 53.31, 1.15, 23.43, 200.97, 69.12,
     158.51, 131.67, 156.95, 266.38, 291.7, 147.15, 101.49, 78.89,
     26.99, 24.35, 35.76, 210.2, 225.55, 282.85, 153.91, 148.13,
     187.03, 133.99, 62.28, 17.58, 13.41, 35.58, 47.04, 154.92,
     317.77, 604.04, 288.91, 210.86, 266.04, 121.62, 78.17, 85.96,
     29.84, 7.02, 72.13, 404.33, 247.71, 255.5, 138.22, 339.5,
     368.99, 209.41, 110.08, 63.9, 0.62, 6.97, 133.75, 227.1,
     312.99, 178.58, 255.8, 155.05, 135.27, 225.55, 15.23, 1.58
     ), Median = c(0.01, 0, 0, 0.1, 0.1, 0, 0, 0, 0, 0.02, 0.1,
     0.04, 0.5, 0, 0.1, 0.07, 0, 0, 0, 0, 0, 0, 0.57, 0.03, 0,
     0.2, 0.055, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0.21, 0.02, 0.2,
     0.11, 0.02, 0, 0, 0, 0, 0, 0.1, 0.165, 0.01, 0.01, 0.15,
     0.01, 0, 0, 0, 0, 0, 0.02, 0.125, 0, 0.1, 0.08, 0.055, 0.1,
     0.13, 0.01, 0, 0, 0, 0, 0.2, 0.17, 0.02, 0.07, 0.23, 0.15,
     0.06, 0, 0, 0, 0, 0.03, 0.1, 0, 0.1, 0.1, 0.2, 0.07, 0, 0.02,
     0, 0, 0, 0.04, 0.115, 0.24, 0.02, 0.03, 0.01, 0.01, 0.02,
     0, 0, 0, 0, 0, 0.02, 0, 0, 0.2, 0.18, 0.05, 0, 0, 0, 0, 0,
     0.08, 0.07, 0.1, 0, 0.01, 0, 0.02, 0, 0, 0, 0, 0, 0, 0.09,
     0.4, 0.18, 0.1, 0.2, 0, 0, 0, 0, 0, 0, 0.29, 0.09, 0.09,
     0, 0.26, 0.3, 0.16, 0, 0, 0, 0, 0, 0, 0.25, 0, 0.16, 0.03,
     0.02, 0.08, 0, 0), Max = c(3, 1.1, 3.2, 1.2, 1.6, 1.48, 0.8,
     0.6, 3.2, 4.9, 3.1, 3.63, 3.4, 2.6, 2, 3.25, 1.6, 2.1, 0.4,
     0.5, 1.1, 2, 6.6, 3.2, 3.6, 5.8, 2.3, 1.7, 1.3, 1.2, 1, 2.1,
     2, 3, 3, 5.9, 3.3, 2.9, 5.2, 1.8, 1.4, 2.2, 0.6, 2.5, 1.02,
     2, 4.4, 3.6, 5.3, 2.2, 2.7, 2.5, 1.5, 1.4, 0.8, 1.4, 1.4,
     2.11, 2.1, 3.3, 3.12, 1.3, 2.4, 1.5, 2.4, 3.5, 0.9, 1.3,
     2.77, 2, 3.2, 2.6, 5.4, 3.4, 2.87, 2.6, 1.6, 1.4, 1.2, 0.2,
     0.91, 2.1, 2.2, 5.2, 4.75, 2.3, 3.4, 2.67, 1.8, 1.9, 0.61,
     0.2, 0.2, 3.4, 3.65, 3.1, 3.15, 2.2, 2, 2.7, 2.3, 1.18, 0.2,
     2.1, 3.3, 1.7, 2.47, 8.8, 2.8, 3.27, 3.29, 2.4, 2.1, 1.73,
     1.03, 1.4, 1.1, 2.9, 3.1, 5.7, 2.69, 2.7, 3.1, 1.3, 1.85,
     0.6, 1.5, 1.1, 1.5, 4.2, 3.8, 4.4, 2.5, 3.2, 2.61, 1.94,
     2.1, 2.1, 1, 0.57, 2.2, 5, 3.02, 2.8, 1.7, 3.08, 5, 2.54,
     2.7, 1.6, 0.1, 0.5, 2.6, 5.35, 3.5, 2.9, 2.3, 2.9, 1.2, 2.47,
     0.6, 0.25)), row.names = c(NA, -162L), class = "data.frame")

Rich



From bry@nm@c@24 @end|ng |rom gm@||@com  Tue Sep 11 21:28:57 2018
From: bry@nm@c@24 @end|ng |rom gm@||@com (Bryan Mac)
Date: Tue, 11 Sep 2018 12:28:57 -0700
Subject: [R] Hierarchical Cluster Analysis
Message-ID: <D8AD1348-0091-4BC5-BD7E-395CE465BEB7@gmail.com>


Bryan Mac
Data Scientist
Research Analytics
Ipsos Insight LLC





	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 12 00:13:53 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Sep 2018 15:13:53 -0700
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>

Well, you might try ?xyplot -- in particular the "scales" list section
and in particular there the "tck" parameter. Adding
tck = c(1, 0)
to the "scales ="  list will probably solve your problem.

-- Bert


On Tue, Sep 11, 2018 at 2:46 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
>    Every lattice xyplot() I've created before this one has tick marks on only
> the left and bottom axes. The current plot has sprouted tick marks on the
> top and right side, too, and I want to remove them. I've not found an answer
> to this issue in Deepayan's book or on the web. I would appreciate also
> learning why the extra tick marks appeared. The dput() data are included.
>
>    The plotting command;
>
> rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'h',
>                         main = 'Monthly Total Precipitation\n2005-2018',
>                         xlab = 'Year and Month', ylab = 'Precipitation (in)',
>                         scales = list(x = list(at = seq(1,162,by=6), cex = 0.7, rot = 90)))
>
> plot(rain.all.sum)
>
>    The data:
>
> structure(list(Month = structure(1:162, .Label = c("2005-01",
> "2005-02", "2005-03", "2005-04", "2005-05", "2005-06", "2005-07",
> "2005-08", "2005-09", "2005-10", "2005-11", "2005-12", "2006-01",
> "2006-02", "2006-03", "2006-04", "2006-05", "2006-06", "2006-07",
> "2006-08", "2006-09", "2006-10", "2006-11", "2006-12", "2007-01",
> "2007-02", "2007-03", "2007-04", "2007-05", "2007-06", "2007-07",
> "2007-08", "2007-09", "2007-10", "2007-11", "2007-12", "2008-01",
> "2008-02", "2008-03", "2008-04", "2008-05", "2008-06", "2008-07",
> "2008-08", "2008-09", "2008-10", "2008-11", "2008-12", "2009-01",
> "2009-02", "2009-03", "2009-04", "2009-05", "2009-06", "2009-07",
> "2009-08", "2009-09", "2009-10", "2009-11", "2009-12", "2010-01",
> "2010-02", "2010-03", "2010-04", "2010-05", "2010-06", "2010-07",
> "2010-08", "2010-09", "2010-10", "2010-11", "2010-12", "2011-01",
> "2011-02", "2011-03", "2011-04", "2011-05", "2011-06", "2011-07",
> "2011-08", "2011-09", "2011-10", "2011-11", "2011-12", "2012-01",
> "2012-02", "2012-03", "2012-04", "2012-05", "2012-06", "2012-07",
> "2012-08", "2012-09", "2012-10", "2012-11", "2012-12", "2013-01",
> "2013-02", "2013-03", "2013-04", "2013-05", "2013-06", "2013-07",
> "2013-08", "2013-09", "2013-10", "2013-11", "2013-12", "2014-01",
> "2014-02", "2014-03", "2014-04", "2014-05", "2014-06", "2014-07",
> "2014-08", "2014-09", "2014-10", "2014-11", "2014-12", "2015-01",
> "2015-02", "2015-03", "2015-04", "2015-05", "2015-06", "2015-07",
> "2015-08", "2015-09", "2015-10", "2015-11", "2015-12", "2016-01",
> "2016-02", "2016-03", "2016-04", "2016-05", "2016-06", "2016-07",
> "2016-08", "2016-09", "2016-10", "2016-11", "2016-12", "2017-01",
> "2017-02", "2017-03", "2017-04", "2017-05", "2017-06", "2017-07",
> "2017-08", "2017-09", "2017-10", "2017-11", "2017-12", "2018-01",
> "2018-02", "2018-03", "2018-04", "2018-05", "2018-06"), class = "factor"),
>      Sum = c(53.51, 24.2, 88.54, 72.85, 77.3, 49.19, 8.77, 5.75,
>      27.83, 79.75, 123.89, 168.29, 229.69, 70.91, 74.15, 62.3,
>      43.56, 35.08, 3.6, 2.76, 26.83, 47.72, 293.23, 139.84, 103.48,
>      120.91, 85.96, 55.91, 26.56, 29.44, 9.9, 15.38, 33.47, 93.6,
>      105.61, 277.41, 279.38, 144.26, 220.88, 149.75, 82.28, 55.87,
>      5.29, 52.27, 21.1, 64.76, 182.31, 207.13, 196.29, 89.27,
>      187.72, 111.67, 111.72, 38.19, 6.07, 15.25, 52.46, 127.75,
>      208.43, 146.62, 169.34, 94.54, 154.21, 131.39, 151.27, 135.46,
>      9.98, 8.72, 86.67, 142.04, 225.61, 274.93, 196.68, 153.24,
>      263.54, 231.49, 122.23, 58.26, 34.65, 2.96, 28.21, 103.92,
>      217.52, 166.16, 305.27, 168.73, 333.28, 145.68, 101.2, 127.77,
>      15.41, 1.85, 3.49, 245.99, 272.35, 297.05, 177.17, 105.71,
>      118.44, 136.34, 161.01, 53.31, 1.15, 23.43, 200.97, 69.12,
>      158.51, 131.67, 156.95, 266.38, 291.7, 147.15, 101.49, 78.89,
>      26.99, 24.35, 35.76, 210.2, 225.55, 282.85, 153.91, 148.13,
>      187.03, 133.99, 62.28, 17.58, 13.41, 35.58, 47.04, 154.92,
>      317.77, 604.04, 288.91, 210.86, 266.04, 121.62, 78.17, 85.96,
>      29.84, 7.02, 72.13, 404.33, 247.71, 255.5, 138.22, 339.5,
>      368.99, 209.41, 110.08, 63.9, 0.62, 6.97, 133.75, 227.1,
>      312.99, 178.58, 255.8, 155.05, 135.27, 225.55, 15.23, 1.58
>      ), Median = c(0.01, 0, 0, 0.1, 0.1, 0, 0, 0, 0, 0.02, 0.1,
>      0.04, 0.5, 0, 0.1, 0.07, 0, 0, 0, 0, 0, 0, 0.57, 0.03, 0,
>      0.2, 0.055, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0.21, 0.02, 0.2,
>      0.11, 0.02, 0, 0, 0, 0, 0, 0.1, 0.165, 0.01, 0.01, 0.15,
>      0.01, 0, 0, 0, 0, 0, 0.02, 0.125, 0, 0.1, 0.08, 0.055, 0.1,
>      0.13, 0.01, 0, 0, 0, 0, 0.2, 0.17, 0.02, 0.07, 0.23, 0.15,
>      0.06, 0, 0, 0, 0, 0.03, 0.1, 0, 0.1, 0.1, 0.2, 0.07, 0, 0.02,
>      0, 0, 0, 0.04, 0.115, 0.24, 0.02, 0.03, 0.01, 0.01, 0.02,
>      0, 0, 0, 0, 0, 0.02, 0, 0, 0.2, 0.18, 0.05, 0, 0, 0, 0, 0,
>      0.08, 0.07, 0.1, 0, 0.01, 0, 0.02, 0, 0, 0, 0, 0, 0, 0.09,
>      0.4, 0.18, 0.1, 0.2, 0, 0, 0, 0, 0, 0, 0.29, 0.09, 0.09,
>      0, 0.26, 0.3, 0.16, 0, 0, 0, 0, 0, 0, 0.25, 0, 0.16, 0.03,
>      0.02, 0.08, 0, 0), Max = c(3, 1.1, 3.2, 1.2, 1.6, 1.48, 0.8,
>      0.6, 3.2, 4.9, 3.1, 3.63, 3.4, 2.6, 2, 3.25, 1.6, 2.1, 0.4,
>      0.5, 1.1, 2, 6.6, 3.2, 3.6, 5.8, 2.3, 1.7, 1.3, 1.2, 1, 2.1,
>      2, 3, 3, 5.9, 3.3, 2.9, 5.2, 1.8, 1.4, 2.2, 0.6, 2.5, 1.02,
>      2, 4.4, 3.6, 5.3, 2.2, 2.7, 2.5, 1.5, 1.4, 0.8, 1.4, 1.4,
>      2.11, 2.1, 3.3, 3.12, 1.3, 2.4, 1.5, 2.4, 3.5, 0.9, 1.3,
>      2.77, 2, 3.2, 2.6, 5.4, 3.4, 2.87, 2.6, 1.6, 1.4, 1.2, 0.2,
>      0.91, 2.1, 2.2, 5.2, 4.75, 2.3, 3.4, 2.67, 1.8, 1.9, 0.61,
>      0.2, 0.2, 3.4, 3.65, 3.1, 3.15, 2.2, 2, 2.7, 2.3, 1.18, 0.2,
>      2.1, 3.3, 1.7, 2.47, 8.8, 2.8, 3.27, 3.29, 2.4, 2.1, 1.73,
>      1.03, 1.4, 1.1, 2.9, 3.1, 5.7, 2.69, 2.7, 3.1, 1.3, 1.85,
>      0.6, 1.5, 1.1, 1.5, 4.2, 3.8, 4.4, 2.5, 3.2, 2.61, 1.94,
>      2.1, 2.1, 1, 0.57, 2.2, 5, 3.02, 2.8, 1.7, 3.08, 5, 2.54,
>      2.7, 1.6, 0.1, 0.5, 2.6, 5.35, 3.5, 2.9, 2.3, 2.9, 1.2, 2.47,
>      0.6, 0.25)), row.names = c(NA, -162L), class = "data.frame")
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From zp@|mp@o @end|ng |rom gm@||@com  Wed Sep 12 00:30:20 2018
From: zp@|mp@o @end|ng |rom gm@||@com (Zach Simpson)
Date: Wed, 12 Sep 2018 10:30:20 +1200
Subject: [R] getting 21 very different colours
Message-ID: <CAJByKzq-2aES1GoaPhesLKL_6r9G5c53m6-u1PUaeOD+geGvkw@mail.gmail.com>

Hi Federico

For a possible alternative, the scico package provides a nice
collection of color palettes that are designed to be both color-blind
friendly and differentiable:

https://www.data-imaginist.com/2018/scico-and-the-colour-conundrum/

You could generate a vector of 21 colors (spaced as far apart as
possible on the palette) to pass to your plot arguments with something
like:

library(scico)
scico(21, palette = 'oleron')

Not sure if this works for your case though. But maybe another feature
(shape?) could help differentiate the 21 points.

Hope this helps,
Zach Simpson

> Message: 11
> Date: Tue, 11 Sep 2018 07:34:51 +0000
> From: Federico Calboli <federico.calboli at kuleuven.be>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] getting 21 very different colours
> Message-ID: <08A6397B-4D67-4195-A53A-1FD394F72B6C at kuleuven.be>
> Content-Type: text/plain; charset="utf-8"
>
> Hi All,
>
> I am plotting a scatterplot of 21 populations, and I am using rainbow(21)[pops.col] to generate 21 colours for the plot (which works).  Maybe it is because I can really process few colours at a time, but the differences between the colours are not as strong as I?d like.  I can specify start and end for rainbow(), but if anything that looks worse if I do not just stick to 0 and 1.
>
> Is there a way of getting a set of 21 colours that maximises the differences between them?
>
> I could pick them by hand, but that is about 15 colours more than I know (I have a detailed colourchart, but the visual differences between ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).
>
> Cheers
>
> F
> --
> Federico Calboli
> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
> Charles Deberiotstraat 32 box 2439
> 3000 Leuven
> +32 16 32 87 67



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep 12 00:36:02 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 15:36:02 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes
Message-ID: <alpine.LNX.2.20.1809111535030.11930@salmo.appl-ecosys.com>

On Tue, 11 Sep 2018, Bert Gunter wrote:

> Well, you might try ?xyplot -- in particular the "scales" list section
> and in particular there the "tck" parameter. Adding
> tck = c(1, 0)
> to the "scales ="  list will probably solve your problem.

Bert,

   I missed the end of the tck description in the book (the same text as the
help file but with more information) where it mentions that tck can be a
vector of length 2 where the first element affects the left/bottom axes and
the second element affects the right/top axes. I also did not grok turning
the first element on and the second element off.

   Now I wonder why this wasn't an issue before now in the xyplots I created.

Thanks much,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep 12 00:41:19 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 15:41:19 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>

On Tue, 11 Sep 2018, Bert Gunter wrote:

> Adding
> tck = c(1, 0)
> to the "scales ="  list will probably solve your problem.

Bert,

   How interesting. This removed the tick marks on top but left them on the
right axes. Will think more about this.

Regards,

Rich



From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 12 00:43:36 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 12 Sep 2018 08:43:36 +1000
Subject: [R] loop for comparing two or more groups using bootstrapping
In-Reply-To: <CY4PR1301MB21673838F1F43BB962933542FA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
References: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
 <CA+8X3fX6f6zT3VGbprbaOFMspKFijOncD0jiwodQ=cXShcnX_g@mail.gmail.com>
 <CY4PR1301MB21673838F1F43BB962933542FA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
Message-ID: <CA+8X3fXs5+4EWqpm7cbTjZy0Eg=PK1bewy7GBnRjgSXSkS4-uw@mail.gmail.com>

Hi Kristi,
My fault, I only worked out how to assign the values to the names and pick
out the columns of daT for the calculations. I think this does what you
want, but I can't guarantee the result.

daT<-structure(list(year1=c(0.417,0.538,0.69,0.688,0.688,0.606,
0.667,0.7,0.545,0.462,0.711,0.642,0.744,0.604,0.612,
0.667,0.533,0.556,0.444,0.526,0.323,0.308,0.195,0.333,
0.323,0.256,0.345,0.205,0.286,0.706,0.7,0.6,0.571,0.364,
0.429,0.326,0.571,0.424,0.341,0.387,0.341,0.324,0.696,
0.696,0.583,0.556,0.645,0.435,0.471,0.556),year2=c(0.385,
0.552,0.645,0.516,0.629,0.595,0.72,0.638,0.557,0.588,
0.63,0.744,0.773,0.571,0.723,0.769,0.667,0.667,0.526,
0.476,0.294,0.323,0.222,0.556,0.263,0.37,0.357,0.25,
0.323,0.778,0.667,0.636,0.583,0.432,0.412,0.333,0.571,
0.39,0.4,0.452,0.326,0.471,0.7,0.75,0.615,0.462,0.556,
0.4,0.696,0.465),year3=c(0.435,0.759,0.759,0.759,0.714,
0.593,0.651,0.683,0.513,0.643,0.652,0.757,0.791,0.649,
0.78,0.5,0.5,0.5,0.533,0.429,0.333,0.286,0.231,0.533,
0.303,0.417,0.333,0.333,0.357,0.909,1,0.952,0.8,0.556,
0.529,0.562,0.762,0.513,0.733,0.611,0.733,0.647,0.909,
0.857,0.8,0.556,0.588,0.562,0.857,0.513),year4=c(0.333,
0.533,0.6,0.483,0.743,0.5,0.691,0.619,0.583,0.385,0.653,
0.762,0.844,0.64,0.667,0.571,0.571,0.615,0.421,0.5,0.205,
0.308,0.25,0.6,0.242,0.308,0.276,0.235,0.211,0.9,0.632,
0.72,0.727,0.356,0.5,0.368,0.5,0.41,0.562,0.514,0.4,
0.409,0.632,0.72,0.727,0.4,0.5,0.421,0.5,0.462)),.Names=c("year1",
"year2","year3","year4"),row.names=c(NA,-50L),class="data.frame")
colname.mat<-combn(paste0("year",1:4),2)
samplenames<-apply(colname.mat,2,paste,collapse="")
k<-10000
meandiff<-function(x) return(mean(x[[1]])-mean(x[[2]]))
for(column in 1:ncol(colname.mat)) {
 assign(samplenames[column],
  replicate(k,data.frame(sample(daT[,colname.mat[1,column]],3,TRUE),
   sample(daT[,colname.mat[2,column]],3,TRUE))))
 meandiffs<-unlist(apply(get(samplenames[column]),2,meandiff))
 cat(samplenames[column],"\n")
 cat("mean diff =",mean(meandiffs),"95% CI =",
  quantile(meandiffs,c(0.025,0.975)),"\n")
 png(paste0(samplenames[column],".png")
 hist(meandiffs)
 dev.off()
}

You should get a printout of the means and CIs and  bunch of PNG files with
the histograms.

Jim


On Tue, Sep 11, 2018 at 11:55 PM Kristi Glover <kristi.glover at hotmail.com>
wrote:

> Dear Jim,
>
> Thank you very much for the code. I run it but it gave me row names
> like "year224", "year142".
>
> are these the difference between columns? If we want to get bootstrapping
> means of difference between years (year2-year1; year3-year1), its CI and
> exact p value, how can we get it?
>
> thanks
>
> KG
>
> ----
>
> head(daT)
>
> colname.mat<-combn(paste0("year",1:4),2)
>
> samplenames<-apply(colname.mat,2,paste,collapse="")
>
> k<-10
>
> for(column in 1:ncol(colname.mat)) {
>
>  assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,
> column]]),3,TRUE)))
>
> }
>
> > get(samplenames[1])
>          [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
> year224 0.556 0.667 0.571 0.526 0.629 0.696 0.323 0.526 0.256 0.667
> year142 0.324 0.324 0.706 0.638 0.600 0.294 0.612 0.688 0.432 0.387
> year237 0.571 0.696 0.629 0.471 0.462 0.471 0.452 0.595 0.333 0.435
>
>
>
>
> ------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *Sent:* September 11, 2018 1:44 AM
> *To:* Kristi Glover
> *Cc:* r-help mailing list
> *Subject:* Re: [R] loop for comparing two or more groups using
> bootstrapping
>
> Hi Kristy,
> Try this:
>
> colname.mat<-combn(paste0("year",1:4),2)
> samplenames<-apply(colname.mat,2,paste,collapse="")
> k<-10000
> for(column in 1:ncol(colname.mat)) {
>
>  assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,column]]),3,TRUE)))
> }
>
> Then use get(samplenames[1]) and so on to access the values.
>
> Jim
> On Tue, Sep 11, 2018 at 4:52 PM Kristi Glover <kristi.glover at hotmail.com>
> wrote:
> >
> > Hi R users,
> >
> > I was trying to test a null hypothesis of difference between two groups
> was 0. I have many years data, such as year1, year2,, year3, year4 and I
> was trying to compare between year1 and year2, year1 and year3, year2 and
> year3 and so on and have used following code with an example data.
> >
> >
> > I tried to make a loop but did not work to compare between many years,
> and also want to obtain the exact p value. Would you mind to help me to
> make a loop?
> >
> > Thanks for your help.
> >
> >
> > KG
> >
> >
> > daT<-structure(list(year1 = c(0.417, 0.538, 0.69, 0.688, 0.688, 0.606,
> > 0.667, 0.7, 0.545, 0.462, 0.711, 0.642, 0.744, 0.604, 0.612,
> > 0.667, 0.533, 0.556, 0.444, 0.526, 0.323, 0.308, 0.195, 0.333,
> > 0.323, 0.256, 0.345, 0.205, 0.286, 0.706, 0.7, 0.6, 0.571, 0.364,
> > 0.429, 0.326, 0.571, 0.424, 0.341, 0.387, 0.341, 0.324, 0.696,
> > 0.696, 0.583, 0.556, 0.645, 0.435, 0.471, 0.556), year2 = c(0.385,
> > 0.552, 0.645, 0.516, 0.629, 0.595, 0.72, 0.638, 0.557, 0.588,
> > 0.63, 0.744, 0.773, 0.571, 0.723, 0.769, 0.667, 0.667, 0.526,
> > 0.476, 0.294, 0.323, 0.222, 0.556, 0.263, 0.37, 0.357, 0.25,
> > 0.323, 0.778, 0.667, 0.636, 0.583, 0.432, 0.412, 0.333, 0.571,
> > 0.39, 0.4, 0.452, 0.326, 0.471, 0.7, 0.75, 0.615, 0.462, 0.556,
> > 0.4, 0.696, 0.465), year3 = c(0.435, 0.759, 0.759, 0.759, 0.714,
> > 0.593, 0.651, 0.683, 0.513, 0.643, 0.652, 0.757, 0.791, 0.649,
> > 0.78, 0.5, 0.5, 0.5, 0.533, 0.429, 0.333, 0.286, 0.231, 0.533,
> > 0.303, 0.417, 0.333, 0.333, 0.357, 0.909, 1, 0.952, 0.8, 0.556,
> > 0.529, 0.562, 0.762, 0.513, 0.733, 0.611, 0.733, 0.647, 0.909,
> > 0.857, 0.8, 0.556, 0.588, 0.562, 0.857, 0.513), year4 = c(0.333,
> > 0.533, 0.6, 0.483, 0.743, 0.5, 0.691, 0.619, 0.583, 0.385, 0.653,
> > 0.762, 0.844, 0.64, 0.667, 0.571, 0.571, 0.615, 0.421, 0.5, 0.205,
> > 0.308, 0.25, 0.6, 0.242, 0.308, 0.276, 0.235, 0.211, 0.9, 0.632,
> > 0.72, 0.727, 0.356, 0.5, 0.368, 0.5, 0.41, 0.562, 0.514, 0.4,
> > 0.409, 0.632, 0.72, 0.727, 0.4, 0.5, 0.421, 0.5, 0.462)), .Names =
> c("year1",
> > "year2", "year3", "year4"), row.names = c(NA, -50L), class =
> "data.frame")
> >
> > head(daT)
> >
> > # null hypothesis; difference is equal to zero
> >
> > dif1.2<-daT$year2-daT$year1
> >
> > k=10000
> >
> > mysamples1.2=replicate(k, sample(dif1.2, replace=T))
> >
> > mymeans1.2=apply(mysamples1.2, 2, mean)
> >
> > quantile(mymeans1.2, c(0.025, 0.975))
> >
> > hist(mysamples1.2)
> >
> > mean(mymeans1.2)
> >
> > #what is p value?
> >
> >
> > #similarly Now I want to compare between year 1 and year3,
> >
> > dif1.3<-daT$year3-daT$year1
> >
> > mysamples1.3=replicate(k, sample(dif1.3, replace=T))
> >
> > mymeans1.3=apply(mysamples1.3, 2, mean)
> >
> > quantile(mymeans1.3, c(0.025, 0.975))
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> R-help -- Main R Mailing List: Primary help - Homepage - SfS
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> stat.ethz.ch
> The main R mailing list, for announcements about the development of R and
> the availability of new code, questions and answers about problems and
> solutions using R, enhancements and patches to the source code and
> documentation of R, comparison and compatibility with S and S-plus, and for
> the posting of nice examples and benchmarks.
>
>
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Wed Sep 12 00:47:51 2018
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Wed, 12 Sep 2018 00:47:51 +0200 (CEST)
Subject: [R] getting 21 very different colours
In-Reply-To: <CAJByKzq-2aES1GoaPhesLKL_6r9G5c53m6-u1PUaeOD+geGvkw@mail.gmail.com>
References: <CAJByKzq-2aES1GoaPhesLKL_6r9G5c53m6-u1PUaeOD+geGvkw@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.1809120044520.2287@paninaro>

Have a look at the Polychrome package by Kevin Coombes and Guy Brock:
https://CRAN.R-project.org/package=Polychrome

This employs the LUV space (with HCL = polar LUV) to get many distinct 
distinguishable colors. For a few first steps, see:
https://CRAN.R-project.org/web/packages/Polychrome/vignettes/polychrome.html

On Wed, 12 Sep 2018, Zach Simpson wrote:

> Hi Federico
>
> For a possible alternative, the scico package provides a nice
> collection of color palettes that are designed to be both color-blind
> friendly and differentiable:
>
> https://www.data-imaginist.com/2018/scico-and-the-colour-conundrum/
>
> You could generate a vector of 21 colors (spaced as far apart as
> possible on the palette) to pass to your plot arguments with something
> like:
>
> library(scico)
> scico(21, palette = 'oleron')
>
> Not sure if this works for your case though. But maybe another feature
> (shape?) could help differentiate the 21 points.
>
> Hope this helps,
> Zach Simpson
>
>> Message: 11
>> Date: Tue, 11 Sep 2018 07:34:51 +0000
>> From: Federico Calboli <federico.calboli at kuleuven.be>
>> To: "r-help at r-project.org" <r-help at r-project.org>
>> Subject: [R] getting 21 very different colours
>> Message-ID: <08A6397B-4D67-4195-A53A-1FD394F72B6C at kuleuven.be>
>> Content-Type: text/plain; charset="utf-8"
>>
>> Hi All,
>>
>> I am plotting a scatterplot of 21 populations, and I am using rainbow(21)[pops.col] to generate 21 colours for the plot (which works).  Maybe it is because I can really process few colours at a time, but the differences between the colours are not as strong as I?d like.  I can specify start and end for rainbow(), but if anything that looks worse if I do not just stick to 0 and 1.
>>
>> Is there a way of getting a set of 21 colours that maximises the differences between them?
>>
>> I could pick them by hand, but that is about 15 colours more than I know (I have a detailed colourchart, but the visual differences between ?skyblue? and ?slategrey? elude me when plotted as dots on a plot).
>>
>> Cheers
>>
>> F
>> --
>> Federico Calboli
>> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
>> Charles Deberiotstraat 32 box 2439
>> 3000 Leuven
>> +32 16 32 87 67
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 12 00:52:34 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 12 Sep 2018 08:52:34 +1000
Subject: [R] Increasing size of label in Taylor plot of Plotrix package
In-Reply-To: <20180911083700.29178.qmail@f5mail-224-158.rediffmail.com>
References: <20180911083700.29178.qmail@f5mail-224-158.rediffmail.com>
Message-ID: <CA+8X3fUVp+R-QzRaiZq_D+yejchGxPqQYhbpvMjRPgXOky0LsA@mail.gmail.com>

Hi Sonam,
You're right. Although the cex.axis argument is present, it doesn't
seem to be used. I will have to debug this, which may take a day or
two.

Jim

On Tue, Sep 11, 2018 at 6:37 PM Sonam Sandeep Dash
<ssdash_swce at rediffmail.com> wrote:
>
> Respected Sir,
> I have created a Taylor plot using the plotrix package. However, I am unable to increase the size of labels of axis. I have tried so many ways but all are in vein. There is no change to size of label of either axis. Kindly tell me the procedure to do the same.
> Thank you,
>
> Regards:
> Sonam Sandeep Dash
> Research scholar
> School of Water Resources
> Indian Institute of Technology, Kharagpur
> West Bengal-721302



From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 12 00:55:21 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Sep 2018 15:55:21 -0700
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>

??

Not when I run your code with the tck specification added. Show us
your xyplot invocation. It should be
scales = list(tck = c(1,0), x= etc.)

Bert

On Tue, Sep 11, 2018 at 3:51 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 11 Sep 2018, Bert Gunter wrote:
>
> > Adding
> > tck = c(1, 0)
> > to the "scales ="  list will probably solve your problem.
>
> Bert,
>
>    How interesting. This removed the tick marks on top but left them on the
> right axes. Will think more about this.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 12 01:14:14 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 12 Sep 2018 09:14:14 +1000
Subject: [R] Remove plot axis values in dotplot graph
In-Reply-To: <CAE9stmdidxkAMbA-6+cFRPZMVppQt+rj6WYPJ-1AhHiqcPBpaA@mail.gmail.com>
References: <CAE9stmdidxkAMbA-6+cFRPZMVppQt+rj6WYPJ-1AhHiqcPBpaA@mail.gmail.com>
Message-ID: <CA+8X3fVqRQABehfH48QMc5_BzTVqO3qaJOTxzyCmC+ovw7OXug@mail.gmail.com>

Hi Abou,
Surprisingly you can't omit the x axis in dotchart. This hack will work:

sink("dotchar_noax.R")
sink()

Edit the resulting file by joining the first two lines with the
assignment symbol (<-), delete the two lines at the bottom and comment
out the line "axis(1)".

source("dotchart.noax.R")
dotchart.noax(scores,cex=1.5, pch = 18, col=c(1:3), xaxt = "n", main="Dot Plot
 child?s cough data", xlab="cough Scores")
library(plotrix)
staxlab(1,0:16)

I used "staxlab" so that you could have all of the labels 0:16.

Jim


On Wed, Sep 12, 2018 at 5:57 AM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear All:
>
> One more thing. I want to Remove the plot x-axis values in dotplot graph. I
> am trying to use xaxt = "n", but it seems NOT working. Also after removing
> the x-axis values, I want to use the command axis(1, at=0:16, cex.axis=1)
> to add x-axis values from 0 to 16, but it seems not working as expect.
>
>
>
> Honey.Dosage<-c(12,11,15,11,10,13,10,4,15,16,9,14,10,6,10,8,11,12,12,8,12,9,11,15,10,15,9,13,8,12,10,8,9,5,12)
>
> DM.Dosage<-c(4,6,9,4,7,7,7,9,12,10,11,6,3,4,9,12,7,6,8,12,12,4,12,13,7,10,13,9,4,4,10,15,9)
>
> No.Dosage<-c(5,8,6,1,0,8,12,8,7,7,1,6,7,7,12,7,9,7,9,5,11,9,5,6,8,8,6,7,10,9,4,8,7,3,1,4,3)
>
> scores<-c(Honey.Dosage,DM.Dosage,No.Dosage)
>
> min(scores)
> max(scores)
>
> dotchart(scores,cex=1.5, pch = 18, col=c(1:3), xaxt = "n", main="Dot Plot
> child?s cough data", xlab="cough Scores")
>
> axis(1, at=0:16, cex.axis=1.5)
>
>
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 12 01:16:54 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 12 Sep 2018 09:16:54 +1000
Subject: [R] Hierarchical Cluster Analysis
In-Reply-To: <D8AD1348-0091-4BC5-BD7E-395CE465BEB7@gmail.com>
References: <D8AD1348-0091-4BC5-BD7E-395CE465BEB7@gmail.com>
Message-ID: <CA+8X3fX-GRh5F3OQiwotOLtKhG8tdSU7bDR1aUs7XqoBM+ncrg@mail.gmail.com>

agnes (cluster)

Jim
On Wed, Sep 12, 2018 at 8:10 AM Bryan Mac <bryanmac.24 at gmail.com> wrote:
>
>
> Bryan Mac
> Data Scientist
> Research Analytics
> Ipsos Insight LLC
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep 12 01:02:47 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 16:02:47 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
 <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>

On Tue, 11 Sep 2018, Bert Gunter wrote:

> Not when I run your code with the tck specification added. Show us
> your xyplot invocation. It should be
> scales = list(tck = c(1,0), x= etc.)

Bert,

   Command:

rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'h',
                        main = 'Monthly Total Precipitation\n2005-2018',
                        xlab = 'Year and Month', ylab = 'Precipitation (in)',
                        scales = list(x = list(tck = c(1, 0), at = seq(1,162,by=6),
                                               cex = 0.7, rot = 90)))

rain.all.sum.pdf attached.

Regards,

Rich

-------------- next part --------------
A non-text attachment was scrubbed...
Name: rain.all.sum.pdf
Type: application/pdf
Size: 6640 bytes
Desc: 
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180911/bc738398/attachment-0002.pdf>

From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 12 02:21:38 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Sep 2018 17:21:38 -0700
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
 <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
 <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTwayvLnE7aAtFO69pEQMABa5sC4YR+5tLzGPy=ZUPFJg@mail.gmail.com>

As I thought, you did not do what I told you to.

Look *carefully* at the two to see your error.

-- Bert


On Tue, Sep 11, 2018 at 5:01 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 11 Sep 2018, Bert Gunter wrote:
>
> > Not when I run your code with the tck specification added. Show us
> > your xyplot invocation. It should be
> > scales = list(tck = c(1,0), x= etc.)
>
> Bert,
>
>    Command:
>
> rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'h',
>                         main = 'Monthly Total Precipitation\n2005-2018',
>                         xlab = 'Year and Month', ylab = 'Precipitation (in)',
>                         scales = list(x = list(tck = c(1, 0), at = seq(1,162,by=6),
>                                                cex = 0.7, rot = 90)))
>
> rain.all.sum.pdf attached.
>
> Regards,
>
> Rich
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep 12 02:39:13 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 17:39:13 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <CAGxFJbTwayvLnE7aAtFO69pEQMABa5sC4YR+5tLzGPy=ZUPFJg@mail.gmail.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
 <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
 <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>
 <CAGxFJbTwayvLnE7aAtFO69pEQMABa5sC4YR+5tLzGPy=ZUPFJg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809111733320.21101@salmo.appl-ecosys.com>

On Tue, 11 Sep 2018, Bert Gunter wrote:

> As I thought, you did not do what I told you to.
> Look *carefully* at the two to see your error.

Bert,

   You're correct, of course. After moving the tck parameter in front of the
x list the right-side ticks are gone. Unfortunately, so are the data: the
panel is empty.

   Corrected command:

rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'p, h',
                        main = 'Monthly Total Precipitation\n2005-2018',
                        xlab = 'Year and Month', ylab = 'Precipitation (in)',
                        scales = list(tck = c(1,0), x = list(at = seq(1,162,by=6),
                                               cex = 0.7, rot = 90)))

   Tomorrow I'll work on why the panel display disappeared along with the
right axes tick marks. Parentheses all match according to emacs.

Thanks,

Rich



From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 12 03:02:30 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Sep 2018 18:02:30 -0700
Subject: [R] Undesired tick marks on top, right axes
In-Reply-To: <alpine.LNX.2.20.1809111733320.21101@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
 <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
 <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>
 <CAGxFJbTwayvLnE7aAtFO69pEQMABa5sC4YR+5tLzGPy=ZUPFJg@mail.gmail.com>
 <alpine.LNX.2.20.1809111733320.21101@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTW6YaVGpcdw4j1ZpFWdHr+A_CxFGXu+UQaLE+2+aL=nQ@mail.gmail.com>

You do that. Your error is obvious.
-- Bert


On Tue, Sep 11, 2018 at 5:39 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 11 Sep 2018, Bert Gunter wrote:
>
> > As I thought, you did not do what I told you to.
> > Look *carefully* at the two to see your error.
>
> Bert,
>
>    You're correct, of course. After moving the tck parameter in front of the
> x list the right-side ticks are gone. Unfortunately, so are the data: the
> panel is empty.
>
>    Corrected command:
>
> rain.all.sum <- xyplot(Sum ~ Month, data=agg.all, col = 'black', type = 'p, h',
>                         main = 'Monthly Total Precipitation\n2005-2018',
>                         xlab = 'Year and Month', ylab = 'Precipitation (in)',
>                         scales = list(tck = c(1,0), x = list(at = seq(1,162,by=6),
>                                                cex = 0.7, rot = 90)))
>
>    Tomorrow I'll work on why the panel display disappeared along with the
> right axes tick marks. Parentheses all match according to emacs.
>
> Thanks,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep 12 03:28:04 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 11 Sep 2018 18:28:04 -0700 (PDT)
Subject: [R] Undesired tick marks on top, right axes [RESOLVED]
In-Reply-To: <CAGxFJbTW6YaVGpcdw4j1ZpFWdHr+A_CxFGXu+UQaLE+2+aL=nQ@mail.gmail.com>
References: <alpine.LNX.2.20.1809111428380.11930@salmo.appl-ecosys.com>
 <CAGxFJbR62+tEm+pwVRmJPBxEocaBJMxKHwOzmL1iMTnm_bFscg@mail.gmail.com>
 <alpine.LNX.2.20.1809111539170.11930@salmo.appl-ecosys.com>
 <CAGxFJbQpr5=PKeoRC5GJr9XZey+hZp2QM3Ve6Xf_eAPWQR+kRg@mail.gmail.com>
 <alpine.LNX.2.20.1809111557220.11930@salmo.appl-ecosys.com>
 <CAGxFJbTwayvLnE7aAtFO69pEQMABa5sC4YR+5tLzGPy=ZUPFJg@mail.gmail.com>
 <alpine.LNX.2.20.1809111733320.21101@salmo.appl-ecosys.com>
 <CAGxFJbTW6YaVGpcdw4j1ZpFWdHr+A_CxFGXu+UQaLE+2+aL=nQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809111827150.22624@salmo.appl-ecosys.com>

On Tue, 11 Sep 2018, Bert Gunter wrote:

> You do that. Your error is obvious.

Bert,

   Yep. Forgot to remove the 'p' from the type attribute.

Mea culpa!

Rich



From ncecch|no @end|ng |rom gm@||@com  Wed Sep 12 03:49:36 2018
From: ncecch|no @end|ng |rom gm@||@com (Nicola Cecchino)
Date: Tue, 11 Sep 2018 21:49:36 -0400
Subject: [R] Correcting dates in research / medical record using R
Message-ID: <e8b5a2bf-4403-2353-1d50-27665c60b7a7@gmail.com>

Hi,

I'm not that well versed with R - I'm trying to correct the dates of 
service in a de-identified research medical record of several subjects.? 
The correct dates come from a csv file, in the VisitDate column,? that 
looks like this in Excel.? The empty cells have other data in them that 
I don't need and the? file name is DateR.csv:


Id1 	Id2 	
	
	
	
	
	VisitDate
12345 	12345 	
	
	
	
	
	4/3/2018


The research medical record is a text file and the "DATE OF SERVICE" in 
the top matter is in error in all of the subjects and needs to be 
replaced with the "VisitDate" in the csv file.? The file name for the 
medical records is test3.NEW.? Here is a screen grab of the top matter 
of the research medical record; below this data excerpt is other 
gathered data for that subject:


================================================================================

PATIENT NAME: CONFIDENTIAL,#12345
PATIENT ID #: 12345
DATE OF SERVICE: 04/10/2018
ACCESSION NUMBER: RR1234567

TEST PROCEDURE??????? HIGH/LOW? TEST RESULTS?????? UNITS NORMAL VALUES


As described above, I need to update the text file DATE OF SERVICE:? 
date with the VisitDate in the csv file.

I made several attempts at this to failure and so now I turn to you.? 
Here is the code that exhibits my attempts:


clinicVdate <- read.csv("DateR.csv")

rownames(clinicVdate) <- as.character(clinicVdate[,'Id2'])

Id2 <- NA

input_data <- readLines("D:/test/test3.NEW")
output_data <- c()

for(input_line in input_data){
 ? output_line = input_line
 ? if(length(grep('PATIENT ID #:', input_line))>0)? {
 ??? Id2 = as.character(strsplit(input_line, ':')[[1]][2])
 ? }

 ? if (length(grep( 'DATE OF SERVICE: ', input_line))){

 ??? output_line = paste('DATE OF SERVICE', clinicVdate[Id2, 
'VisitDate'], sep=':')

 ? }
 ? output_data = paste(output_data, output_line, sep='\n')
}

cat(output_data)


The results of the above remove the erroneous date and replace it with 
NA.? Here is an example of the results:


================================================================================

PATIENT NAME: CONFIDENTIAL,#12345
PATIENT ID #: 12345
DATE OF SERVICE: NA
ACCESSION NUMBER: RR1234567

TEST PROCEDURE??????? HIGH/LOW? TEST RESULTS?????? UNITS NORMAL VALUES


Where am I going wrong?? If I didn't pose my question appropriately, 
please let me know too!!? Any help with this would be greatly appreciated!!

Kind regards,

Nic Cecchino




	[[alternative HTML version deleted]]



From m@rn@@w@g|ey @end|ng |rom gm@||@com  Wed Sep 12 04:57:30 2018
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Tue, 11 Sep 2018 19:57:30 -0700
Subject: [R] loop for comparing two or more groups using bootstrapping
In-Reply-To: <CA+8X3fXs5+4EWqpm7cbTjZy0Eg=PK1bewy7GBnRjgSXSkS4-uw@mail.gmail.com>
References: <CY4PR1301MB216743F42565E6131471893AFA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
 <CA+8X3fX6f6zT3VGbprbaOFMspKFijOncD0jiwodQ=cXShcnX_g@mail.gmail.com>
 <CY4PR1301MB21673838F1F43BB962933542FA040@CY4PR1301MB2167.namprd13.prod.outlook.com>
 <CA+8X3fXs5+4EWqpm7cbTjZy0Eg=PK1bewy7GBnRjgSXSkS4-uw@mail.gmail.com>
Message-ID: <CAMwU6B0JpJ_=_5GL8LYyOSxUA29DX+oZ9Gj-4UsbDjBDeYesBA@mail.gmail.com>

Thank you Jim, it worked. I am very grateful for your help.
Thanks
KG

On Tue, Sep 11, 2018 at 3:51 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Kristi,
> My fault, I only worked out how to assign the values to the names and pick
> out the columns of daT for the calculations. I think this does what you
> want, but I can't guarantee the result.
>
> daT<-structure(list(year1=c(0.417,0.538,0.69,0.688,0.688,0.606,
> 0.667,0.7,0.545,0.462,0.711,0.642,0.744,0.604,0.612,
> 0.667,0.533,0.556,0.444,0.526,0.323,0.308,0.195,0.333,
> 0.323,0.256,0.345,0.205,0.286,0.706,0.7,0.6,0.571,0.364,
> 0.429,0.326,0.571,0.424,0.341,0.387,0.341,0.324,0.696,
> 0.696,0.583,0.556,0.645,0.435,0.471,0.556),year2=c(0.385,
> 0.552,0.645,0.516,0.629,0.595,0.72,0.638,0.557,0.588,
> 0.63,0.744,0.773,0.571,0.723,0.769,0.667,0.667,0.526,
> 0.476,0.294,0.323,0.222,0.556,0.263,0.37,0.357,0.25,
> 0.323,0.778,0.667,0.636,0.583,0.432,0.412,0.333,0.571,
> 0.39,0.4,0.452,0.326,0.471,0.7,0.75,0.615,0.462,0.556,
> 0.4,0.696,0.465),year3=c(0.435,0.759,0.759,0.759,0.714,
> 0.593,0.651,0.683,0.513,0.643,0.652,0.757,0.791,0.649,
> 0.78,0.5,0.5,0.5,0.533,0.429,0.333,0.286,0.231,0.533,
> 0.303,0.417,0.333,0.333,0.357,0.909,1,0.952,0.8,0.556,
> 0.529,0.562,0.762,0.513,0.733,0.611,0.733,0.647,0.909,
> 0.857,0.8,0.556,0.588,0.562,0.857,0.513),year4=c(0.333,
> 0.533,0.6,0.483,0.743,0.5,0.691,0.619,0.583,0.385,0.653,
> 0.762,0.844,0.64,0.667,0.571,0.571,0.615,0.421,0.5,0.205,
> 0.308,0.25,0.6,0.242,0.308,0.276,0.235,0.211,0.9,0.632,
> 0.72,0.727,0.356,0.5,0.368,0.5,0.41,0.562,0.514,0.4,
> 0.409,0.632,0.72,0.727,0.4,0.5,0.421,0.5,0.462)),.Names=c("year1",
> "year2","year3","year4"),row.names=c(NA,-50L),class="data.frame")
> colname.mat<-combn(paste0("year",1:4),2)
> samplenames<-apply(colname.mat,2,paste,collapse="")
> k<-10000
> meandiff<-function(x) return(mean(x[[1]])-mean(x[[2]]))
> for(column in 1:ncol(colname.mat)) {
>  assign(samplenames[column],
>   replicate(k,data.frame(sample(daT[,colname.mat[1,column]],3,TRUE),
>    sample(daT[,colname.mat[2,column]],3,TRUE))))
>  meandiffs<-unlist(apply(get(samplenames[column]),2,meandiff))
>  cat(samplenames[column],"\n")
>  cat("mean diff =",mean(meandiffs),"95% CI =",
>   quantile(meandiffs,c(0.025,0.975)),"\n")
>  png(paste0(samplenames[column],".png")
>  hist(meandiffs)
>  dev.off()
> }
>
> You should get a printout of the means and CIs and  bunch of PNG files with
> the histograms.
>
> Jim
>
>
> On Tue, Sep 11, 2018 at 11:55 PM Kristi Glover <kristi.glover at hotmail.com>
> wrote:
>
> > Dear Jim,
> >
> > Thank you very much for the code. I run it but it gave me row names
> > like "year224", "year142".
> >
> > are these the difference between columns? If we want to get bootstrapping
> > means of difference between years (year2-year1; year3-year1), its CI and
> > exact p value, how can we get it?
> >
> > thanks
> >
> > KG
> >
> > ----
> >
> > head(daT)
> >
> > colname.mat<-combn(paste0("year",1:4),2)
> >
> > samplenames<-apply(colname.mat,2,paste,collapse="")
> >
> > k<-10
> >
> > for(column in 1:ncol(colname.mat)) {
> >
> >  assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,
> > column]]),3,TRUE)))
> >
> > }
> >
> > > get(samplenames[1])
> >          [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
> > year224 0.556 0.667 0.571 0.526 0.629 0.696 0.323 0.526 0.256 0.667
> > year142 0.324 0.324 0.706 0.638 0.600 0.294 0.612 0.688 0.432 0.387
> > year237 0.571 0.696 0.629 0.471 0.462 0.471 0.452 0.595 0.333 0.435
> >
> >
> >
> >
> > ------------------------------
> > *From:* Jim Lemon <drjimlemon at gmail.com>
> > *Sent:* September 11, 2018 1:44 AM
> > *To:* Kristi Glover
> > *Cc:* r-help mailing list
> > *Subject:* Re: [R] loop for comparing two or more groups using
> > bootstrapping
> >
> > Hi Kristy,
> > Try this:
> >
> > colname.mat<-combn(paste0("year",1:4),2)
> > samplenames<-apply(colname.mat,2,paste,collapse="")
> > k<-10000
> > for(column in 1:ncol(colname.mat)) {
> >
> >
> assign(samplenames[column],replicate(k,sample(unlist(daT[,colname.mat[,column]]),3,TRUE)))
> > }
> >
> > Then use get(samplenames[1]) and so on to access the values.
> >
> > Jim
> > On Tue, Sep 11, 2018 at 4:52 PM Kristi Glover <kristi.glover at hotmail.com
> >
> > wrote:
> > >
> > > Hi R users,
> > >
> > > I was trying to test a null hypothesis of difference between two groups
> > was 0. I have many years data, such as year1, year2,, year3, year4 and I
> > was trying to compare between year1 and year2, year1 and year3, year2 and
> > year3 and so on and have used following code with an example data.
> > >
> > >
> > > I tried to make a loop but did not work to compare between many years,
> > and also want to obtain the exact p value. Would you mind to help me to
> > make a loop?
> > >
> > > Thanks for your help.
> > >
> > >
> > > KG
> > >
> > >
> > > daT<-structure(list(year1 = c(0.417, 0.538, 0.69, 0.688, 0.688, 0.606,
> > > 0.667, 0.7, 0.545, 0.462, 0.711, 0.642, 0.744, 0.604, 0.612,
> > > 0.667, 0.533, 0.556, 0.444, 0.526, 0.323, 0.308, 0.195, 0.333,
> > > 0.323, 0.256, 0.345, 0.205, 0.286, 0.706, 0.7, 0.6, 0.571, 0.364,
> > > 0.429, 0.326, 0.571, 0.424, 0.341, 0.387, 0.341, 0.324, 0.696,
> > > 0.696, 0.583, 0.556, 0.645, 0.435, 0.471, 0.556), year2 = c(0.385,
> > > 0.552, 0.645, 0.516, 0.629, 0.595, 0.72, 0.638, 0.557, 0.588,
> > > 0.63, 0.744, 0.773, 0.571, 0.723, 0.769, 0.667, 0.667, 0.526,
> > > 0.476, 0.294, 0.323, 0.222, 0.556, 0.263, 0.37, 0.357, 0.25,
> > > 0.323, 0.778, 0.667, 0.636, 0.583, 0.432, 0.412, 0.333, 0.571,
> > > 0.39, 0.4, 0.452, 0.326, 0.471, 0.7, 0.75, 0.615, 0.462, 0.556,
> > > 0.4, 0.696, 0.465), year3 = c(0.435, 0.759, 0.759, 0.759, 0.714,
> > > 0.593, 0.651, 0.683, 0.513, 0.643, 0.652, 0.757, 0.791, 0.649,
> > > 0.78, 0.5, 0.5, 0.5, 0.533, 0.429, 0.333, 0.286, 0.231, 0.533,
> > > 0.303, 0.417, 0.333, 0.333, 0.357, 0.909, 1, 0.952, 0.8, 0.556,
> > > 0.529, 0.562, 0.762, 0.513, 0.733, 0.611, 0.733, 0.647, 0.909,
> > > 0.857, 0.8, 0.556, 0.588, 0.562, 0.857, 0.513), year4 = c(0.333,
> > > 0.533, 0.6, 0.483, 0.743, 0.5, 0.691, 0.619, 0.583, 0.385, 0.653,
> > > 0.762, 0.844, 0.64, 0.667, 0.571, 0.571, 0.615, 0.421, 0.5, 0.205,
> > > 0.308, 0.25, 0.6, 0.242, 0.308, 0.276, 0.235, 0.211, 0.9, 0.632,
> > > 0.72, 0.727, 0.356, 0.5, 0.368, 0.5, 0.41, 0.562, 0.514, 0.4,
> > > 0.409, 0.632, 0.72, 0.727, 0.4, 0.5, 0.421, 0.5, 0.462)), .Names =
> > c("year1",
> > > "year2", "year3", "year4"), row.names = c(NA, -50L), class =
> > "data.frame")
> > >
> > > head(daT)
> > >
> > > # null hypothesis; difference is equal to zero
> > >
> > > dif1.2<-daT$year2-daT$year1
> > >
> > > k=10000
> > >
> > > mysamples1.2=replicate(k, sample(dif1.2, replace=T))
> > >
> > > mymeans1.2=apply(mysamples1.2, 2, mean)
> > >
> > > quantile(mymeans1.2, c(0.025, 0.975))
> > >
> > > hist(mysamples1.2)
> > >
> > > mean(mymeans1.2)
> > >
> > > #what is p value?
> > >
> > >
> > > #similarly Now I want to compare between year 1 and year3,
> > >
> > > dif1.3<-daT$year3-daT$year1
> > >
> > > mysamples1.3=replicate(k, sample(dif1.3, replace=T))
> > >
> > > mymeans1.3=apply(mysamples1.3, 2, mean)
> > >
> > > quantile(mymeans1.3, c(0.025, 0.975))
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > R-help -- Main R Mailing List: Primary help - Homepage - SfS
> > <https://stat.ethz.ch/mailman/listinfo/r-help>
> > stat.ethz.ch
> > The main R mailing list, for announcements about the development of R and
> > the availability of new code, questions and answers about problems and
> > solutions using R, enhancements and patches to the source code and
> > documentation of R, comparison and compatibility with S and S-plus, and
> for
> > the posting of nice examples and benchmarks.
> >
> >
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From ro@||n@ump @end|ng |rom gm@||@com  Wed Sep 12 08:20:40 2018
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Wed, 12 Sep 2018 14:20:40 +0800
Subject: [R] customise tick marks
Message-ID: <CANTvJZLMtZWX3BwUgagTMdxj0-gsz1z8SDP95-JLmM9Bvyp5Kg@mail.gmail.com>

Dear r-users,

I want to draw dotplot for mtcars data according to cyl. There are three
types of cylinder 4,6,8. However when we draw it does not use 4,6,8 instead
label it as 1,2,3.

I have this code and would like to customise the tick mark according to cyl
groups:


dotplot(cyl ~ mpg, data = mtcars, groups = cyl, cex=1.2,axes=FALSE,
  main="Gas Milage for Car Models",  xlab="Miles Per Gallon")
ticks = c(1,2,3)
axis(2, at = ticks, labels=c(4,6,8))

I got this message:

axis(2, at = ticks, labels=c(4,6,8))
Error in axis(2, at = ticks, labels = c(4, 6, 8)) :
  plot.new has not been called yet

Thank you so much for any help given.
-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Wed Sep 12 08:26:30 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 12 Sep 2018 06:26:30 +0000
Subject: [R] Correcting dates in research / medical record using R
In-Reply-To: <e8b5a2bf-4403-2353-1d50-27665c60b7a7@gmail.com>
References: <e8b5a2bf-4403-2353-1d50-27665c60b7a7@gmail.com>
Message-ID: <cfc5e11caf914d18aad819587de342d6@SRVEXCHCM1302.precheza.cz>

Hi

First of all you should not use HTML formated posts, it is big chance that it gets scrambled.

You should compare your ld2 after for cycle and result of

clinicVdate[Id2, 'VisitDate'], sep=':')

Most probably ld2 after for cycle does not conform to row names of clinicVdate.

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Nicola Cecchino
> Sent: Wednesday, September 12, 2018 3:50 AM
> To: R-help at r-project.org
> Subject: [R] Correcting dates in research / medical record using R
>
> Hi,
>
> I'm not that well versed with R - I'm trying to correct the dates of
> service in a de-identified research medical record of several subjects.
> The correct dates come from a csv file, in the VisitDate column,  that
> looks like this in Excel.  The empty cells have other data in them that
> I don't need and the  file name is DateR.csv:
>
>
> Id1 Id2
>
>
>
>
> VisitDate
> 12345 12345
>
>
>
>
> 4/3/2018
>
>
> The research medical record is a text file and the "DATE OF SERVICE" in
> the top matter is in error in all of the subjects and needs to be
> replaced with the "VisitDate" in the csv file.  The file name for the
> medical records is test3.NEW.  Here is a screen grab of the top matter
> of the research medical record; below this data excerpt is other
> gathered data for that subject:
>
>
> ===================================================================
> =============
>
> PATIENT NAME: CONFIDENTIAL,#12345
> PATIENT ID #: 12345
> DATE OF SERVICE: 04/10/2018
> ACCESSION NUMBER: RR1234567
>
> TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS NORMAL VALUES
>
>
> As described above, I need to update the text file DATE OF SERVICE:
> date with the VisitDate in the csv file.
>
> I made several attempts at this to failure and so now I turn to you.
> Here is the code that exhibits my attempts:
>
>
> clinicVdate <- read.csv("DateR.csv")
>
> rownames(clinicVdate) <- as.character(clinicVdate[,'Id2'])
>
> Id2 <- NA
>
> input_data <- readLines("D:/test/test3.NEW")
> output_data <- c()
>
> for(input_line in input_data){
>    output_line = input_line
>    if(length(grep('PATIENT ID #:', input_line))>0)  {
>      Id2 = as.character(strsplit(input_line, ':')[[1]][2])
>    }
>
>    if (length(grep( 'DATE OF SERVICE: ', input_line))){
>
>      output_line = paste('DATE OF SERVICE', clinicVdate[Id2,
> 'VisitDate'], sep=':')
>
>    }
>    output_data = paste(output_data, output_line, sep='\n')
> }
>
> cat(output_data)
>
>
> The results of the above remove the erroneous date and replace it with
> NA.  Here is an example of the results:
>
>
> ===================================================================
> =============
>
> PATIENT NAME: CONFIDENTIAL,#12345
> PATIENT ID #: 12345
> DATE OF SERVICE: NA
> ACCESSION NUMBER: RR1234567
>
> TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS NORMAL VALUES
>
>
> Where am I going wrong?  If I didn't pose my question appropriately,
> please let me know too!!  Any help with this would be greatly appreciated!!
>
> Kind regards,
>
> Nic Cecchino
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From choco|d12 @end|ng |rom gm@||@com  Wed Sep 12 08:55:26 2018
From: choco|d12 @end|ng |rom gm@||@com (lily li)
Date: Wed, 12 Sep 2018 14:55:26 +0800
Subject: [R] how to plot gridded data
Message-ID: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>

Hi R users,

I have a question about plotting gridded data. I have the files separately,
but do not know how to combine them. For example, each txt file has daily
precipitation data at a specific grid cell, named pr_lat_lon.txt. How to
plot all txt files for one surface (which is rectangular in this case), or
how to combine the txt files together? Thanks.

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Wed Sep 12 09:22:18 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 12 Sep 2018 07:22:18 +0000
Subject: [R] how to plot gridded data
In-Reply-To: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
References: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
Message-ID: <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>

Hi

1. Read files/lines into R ?read.table, ?read.lines
2. Merge files according to your specification ?merge, ?rbind
3. Plot values by suitable command(s) ?plot, ?ggplot
4. If you want more specific answer, please post more specific question, preferably with concise and clear example.
5. Avoid posting in HTML

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of lily li
> Sent: Wednesday, September 12, 2018 8:55 AM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] how to plot gridded data
>
> Hi R users,
>
> I have a question about plotting gridded data. I have the files separately, but do
> not know how to combine them. For example, each txt file has daily
> precipitation data at a specific grid cell, named pr_lat_lon.txt. How to plot all
> txt files for one surface (which is rectangular in this case), or how to combine
> the txt files together? Thanks.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 12 11:58:27 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 12 Sep 2018 19:58:27 +1000
Subject: [R] customise tick marks
In-Reply-To: <CANTvJZLMtZWX3BwUgagTMdxj0-gsz1z8SDP95-JLmM9Bvyp5Kg@mail.gmail.com>
References: <CANTvJZLMtZWX3BwUgagTMdxj0-gsz1z8SDP95-JLmM9Bvyp5Kg@mail.gmail.com>
Message-ID: <CA+8X3fUD1Txb6cfUwMvHzhvg=w6oUy+iRCqmv26WgQ+TAE6gzA@mail.gmail.com>

Hi Roslinazairimah,
You seem to be using the dotplot function from the lattice package. If so:

dotplot(cyl ~ mpg, data = mtcars, groups = cyl, cex=1.2,
 scales=list(y=list(labels=sort(unique(mtcars$cyl)))),
 main="Gas Milage for Car Models",  xlab="Miles Per Gallon")

Jim
On Wed, Sep 12, 2018 at 4:21 PM roslinazairimah zakaria
<roslinaump at gmail.com> wrote:
>
> Dear r-users,
>
> I want to draw dotplot for mtcars data according to cyl. There are three
> types of cylinder 4,6,8. However when we draw it does not use 4,6,8 instead
> label it as 1,2,3.
>
> I have this code and would like to customise the tick mark according to cyl
> groups:
>
>
> dotplot(cyl ~ mpg, data = mtcars, groups = cyl, cex=1.2,axes=FALSE,
>   main="Gas Milage for Car Models",  xlab="Miles Per Gallon")
> ticks = c(1,2,3)
> axis(2, at = ticks, labels=c(4,6,8))
>
> I got this message:
>
> axis(2, at = ticks, labels=c(4,6,8))
> Error in axis(2, at = ticks, labels = c(4, 6, 8)) :
>   plot.new has not been called yet
>
> Thank you so much for any help given.
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Wed Sep 12 13:53:09 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Wed, 12 Sep 2018 17:23:09 +0530
Subject: [R] Obtaining exact pattern in list.files()
Message-ID: <CA+dpOJk=DBPfJ_SqT=K7feGOV8twPFAfw2dFVRHgt5hOHj1c9g@mail.gmail.com>

Hi,

In the list.files() function, there is an argument 'pattern' to locate the
desired files. However I failed to see if I can manage to fetch those files
that having an exact match.

For example, if there are 2 files that contain the expression 'File' and
'Second_File', then I should get the 1st one. However R is returning both
the files.

Any pointer on how to achieve that would be helpful. Thanks,

	[[alternative HTML version deleted]]



From |@t@z@hn @end|ng |rom gm@||@com  Wed Sep 12 15:07:44 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Wed, 12 Sep 2018 09:07:44 -0400
Subject: [R] Obtaining exact pattern in list.files()
In-Reply-To: <CA+dpOJk=DBPfJ_SqT=K7feGOV8twPFAfw2dFVRHgt5hOHj1c9g@mail.gmail.com>
References: <CA+dpOJk=DBPfJ_SqT=K7feGOV8twPFAfw2dFVRHgt5hOHj1c9g@mail.gmail.com>
Message-ID: <CA+vqiLGfS2Z6gpxEgfhSN_Pt6YYUEhMnrRedm0Zcei4m+t6tJQ@mail.gmail.com>

pattern = "^File$"

Best,
Ista
On Wed, Sep 12, 2018 at 7:53 AM Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
>
> Hi,
>
> In the list.files() function, there is an argument 'pattern' to locate the
> desired files. However I failed to see if I can manage to fetch those files
> that having an exact match.
>
> For example, if there are 2 files that contain the expression 'File' and
> 'Second_File', then I should get the 1st one. However R is returning both
> the files.
>
> Any pointer on how to achieve that would be helpful. Thanks,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep 12 15:20:53 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 12 Sep 2018 06:20:53 -0700
Subject: [R] Obtaining exact pattern in list.files()
In-Reply-To: <CA+dpOJk=DBPfJ_SqT=K7feGOV8twPFAfw2dFVRHgt5hOHj1c9g@mail.gmail.com>
References: <CA+dpOJk=DBPfJ_SqT=K7feGOV8twPFAfw2dFVRHgt5hOHj1c9g@mail.gmail.com>
Message-ID: <9D5CBBF2-D5CC-4073-B0E4-106C005221C0@dcn.davis.ca.us>

Study regular expressions via ?regex or any of the many websites you can find with a search engine. With no special characters, your search pattern matches anywhere in the string. Start your study by learning about the ^ and $ characters.

On September 12, 2018 4:53:09 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi,
>
>In the list.files() function, there is an argument 'pattern' to locate
>the
>desired files. However I failed to see if I can manage to fetch those
>files
>that having an exact match.
>
>For example, if there are 2 files that contain the expression 'File'
>and
>'Second_File', then I should get the 1st one. However R is returning
>both
>the files.
>
>Any pointer on how to achieve that would be helpful. Thanks,
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Wed Sep 12 18:09:16 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Wed, 12 Sep 2018 12:09:16 -0400
Subject: [R] Install R into mac
Message-ID: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>

Dear All:

One of my students has  mac software  OS X Yosemite, Version 10.10.5. He
could not install R into his mac laptop. I am not familiar with mac at all.
Any help will be appreciated.

with thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep 12 18:21:15 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 12 Sep 2018 09:21:15 -0700 (PDT)
Subject: [R] Save printed/plotted output to different directory
Message-ID: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>

   I run analyses in one directory and keep images and textual output in
other directories. My test involving a pdf output specifying an output
directory relative to the cwd produced a blank image. The command was like
this:
pdf('../images/filename.pdf')

   Will R accept an absolute path to an output directory or none at all?

TIA,

Rich



From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 12 18:25:11 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 12 Sep 2018 09:25:11 -0700
Subject: [R] Install R into mac
In-Reply-To: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>
References: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>
Message-ID: <CAGxFJbRoKoxOFfj_krrwV3Kgn=x752P=D2ccMburFX6zMHdN=A@mail.gmail.com>

You have given insufficient information for useful help. R installs
(from the Mac binary) without difficulty on my Mac.

Have your student post with sufficient details to the r-sig-mac list.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Sep 12, 2018 at 9:10 AM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear All:
>
> One of my students has  mac software  OS X Yosemite, Version 10.10.5. He
> could not install R into his mac laptop. I am not familiar with mac at all.
> Any help will be appreciated.
>
> with thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 12 18:26:41 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 12 Sep 2018 09:26:41 -0700
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>

Don't post. Try it and see.

-- Bert


On Wed, Sep 12, 2018 at 9:21 AM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
>    I run analyses in one directory and keep images and textual output in
> other directories. My test involving a pdf output specifying an output
> directory relative to the cwd produced a blank image. The command was like
> this:
> pdf('../images/filename.pdf')
>
>    Will R accept an absolute path to an output directory or none at all?
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep 12 18:38:35 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 12 Sep 2018 09:38:35 -0700 (PDT)
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
 <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809120937270.27645@salmo.appl-ecosys.com>

On Wed, 12 Sep 2018, Bert Gunter wrote:

> Don't post. Try it and see.

Bert,

   Tried using both $HOME and the full path without success and wondered if
there was a way to direct output to a different directory that hadn't
occurred to me.

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep 12 18:43:07 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 12 Sep 2018 09:43:07 -0700 (PDT)
Subject: [R] 
 Save printed/plotted output to different directory [ANSWERED]
In-Reply-To: <alpine.LNX.2.20.1809120937270.27645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
 <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
 <alpine.LNX.2.20.1809120937270.27645@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809120942250.27645@salmo.appl-ecosys.com>

On Wed, 12 Sep 2018, Rich Shepard wrote:

> Tried using both $HOME and the full path without success and wondered if
> there was a way to direct output to a different directory that hadn't
> occurred to me.

   Found the glitch. Now it works using relative paths.

Rich



From B|||@Po||ng @end|ng |rom ze||@@com  Wed Sep 12 19:10:18 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 12 Sep 2018 17:10:18 +0000
Subject: [R] Help with simple Map of US states to predefined regions
Message-ID: <SN6PR02MB508800BA681A2BE4FE6C59DCEA1B0@SN6PR02MB5088.namprd02.prod.outlook.com>

Hi I have this df with three columns ProviderState, ProviderStateCode, ProviderRegion

I have reviewed fiftystater pkg and map pkg but not sure how to simply take these three columns and plot a simple 5 color map based on the Region the state is in?

Do I need all the longitude and latitude data or can this be done with what I have?

https://cran.r-project.org/web/packages/fiftystater/vignettes/fiftystater.html
https://cran.r-project.org/web/packages/maps/maps.pdf


str(Map1)
Classes 'tbl_df', 'tbl' and 'data.frame':    54 obs. of  3 variables:
$ ProviderState    : chr  "ALASKA" "ALABAMA" "ARKANSAS" "ARIZONA" ...
$ ProviderStateCode: chr  "AK" "AL" "AR" "AZ" ...
$ ProviderRegion   : chr  "Pacific" "South" "South" "Pacific" ...
- attr(*, "spec")=List of 2
  ..$ cols   :List of 3
  .. ..$ ProviderState    : list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  .. ..$ ProviderStateCode: list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  .. ..$ ProviderRegion   : list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  ..$ default: list()
  .. ..- attr(*, "class")= chr  "collector_guess" "collector"
  ..- attr(*, "class")= chr "col_spec"

dput(Map1)
structure(list(ProviderState = c("ALASKA", "ALABAMA", "ARKANSAS",
"ARIZONA", "CALIFORNIA", "COLORADO", "CONNECTICUT", "DISTRICT OF COLUMBIA",
"DELAWARE", "FLORIDA", "GEORGIA", "GUAM", "HAWAII", "IOWA", "IDAHO",
"ILLINOIS", "INDIANA", "KANSAS", "KENTUCKY", "LOUISIANA", "MASSACHUSETTS",
"MARYLAND", "MAINE", "MICHIGAN", "MINNESOTA", "MISSOURI", "MISSISSIPPI",
"MONTANA", "NORTH CAROLINA", "NORTH DAKOTA", "NEBRASKA", "NEW HAMPSHIRE",
"NEW JERSEY", "NEW MEXICO", "NEVADA", "NEW YORK", "OHIO", "OKLAHOMA",
"OREGON", "PENNSYLVANIA", "PUERTO RICO", "RHODE ISLAND", "SOUTH CAROLINA",
"SOUTH DAKOTA", "TENNESSEE", "TEXAS", "UTAH", "VIRGINIA", "VIRGIN ISLANDS",
"VERMONT", "WASHINGTON", "WISCONSIN", "WEST VIRGINIA", "WYOMING"
), ProviderStateCode = c("AK", "AL", "AR", "AZ", "CA", "CO",
"CT", "DC", "DE", "FL", "GA", "GU", "HI", "IA", "ID", "IL", "IN",
"KS", "KY", "LA", "MA", "MD", "ME", "MI", "MN", "MO", "MS", "MT",
"NC", "ND", "NE", "NH", "NJ", "NM", "NV", "NY", "OH", "OK", "OR",
"PA", "PR", "RI", "SC", "SD", "TN", "TX", "UT", "VA", "VI", "VT",
"WA", "WI", "WV", "WY"), ProviderRegion = c("Pacific", "South",
"South", "Pacific", "Pacific", "Frontier", "Northeast", "Northeast",
"Northeast", "South", "South", "Pacific", "Pacific", "Midwest",
"Frontier", "Midwest", "Midwest", "Frontier", "South", "South",
"Northeast", "Northeast", "Northeast", "Midwest", "Midwest",
"Midwest", "South", "Frontier", "South", "Midwest", "Midwest",
"Northeast", "Northeast", "Frontier", "Pacific", "Northeast",
"Midwest", "Frontier", "Pacific", "Northeast", "Northeast", "Northeast",
"South", "Midwest", "South", "Frontier", "Frontier", "South",
"Northeast", "Northeast", "Pacific", "Midwest", "South", "Frontier"
)), row.names = c(NA, -54L), class = c("tbl_df", "tbl", "data.frame"
), spec = structure(list(cols = list(ProviderState = structure(list(), class = c("collector_character",
"collector")), ProviderStateCode = structure(list(), class = c("collector_character",
"collector")), ProviderRegion = structure(list(), class = c("collector_character",
"collector"))), default = structure(list(), class = c("collector_guess",
"collector"))), class = "col_spec"))

Thank you for any suggestions.

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 12 19:10:32 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 12 Sep 2018 10:10:32 -0700
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <alpine.LNX.2.20.1809120937270.27645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
 <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
 <alpine.LNX.2.20.1809120937270.27645@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbR0-HgTTeorqX6QS9y2jdgkfAo2L+H7Y-Rkf1Ldn5D8hQ@mail.gmail.com>

Insufficient info to diagnose. No code for what you did.

-- Bert


On Wed, Sep 12, 2018 at 9:43 AM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Wed, 12 Sep 2018, Bert Gunter wrote:
>
> > Don't post. Try it and see.
>
> Bert,
>
>    Tried using both $HOME and the full path without success and wondered if
> there was a way to direct output to a different directory that hadn't
> occurred to me.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep 12 21:33:34 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 12 Sep 2018 12:33:34 -0700
Subject: [R] Install R into mac
In-Reply-To: <CAGxFJbRoKoxOFfj_krrwV3Kgn=x752P=D2ccMburFX6zMHdN=A@mail.gmail.com>
References: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>
 <CAGxFJbRoKoxOFfj_krrwV3Kgn=x752P=D2ccMburFX6zMHdN=A@mail.gmail.com>
Message-ID: <6DE6E333-95E9-437B-9E38-00FB3C5D6DD8@dcn.davis.ca.us>

Also read the CRAN download web page which says 10.10.5 is too old for current supported versions of R. Could try an archived version or, better yet, upgrade the OS.

On September 12, 2018 9:25:11 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>You have given insufficient information for useful help. R installs
>(from the Mac binary) without difficulty on my Mac.
>
>Have your student post with sufficient details to the r-sig-mac list.
>
>-- Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Wed, Sep 12, 2018 at 9:10 AM AbouEl-Makarim Aboueissa
><abouelmakarim1962 at gmail.com> wrote:
>>
>> Dear All:
>>
>> One of my students has  mac software  OS X Yosemite, Version 10.10.5.
>He
>> could not install R into his mac laptop. I am not familiar with mac
>at all.
>> Any help will be appreciated.
>>
>> with thanks
>> abou
>> ______________________
>>
>>
>> *AbouEl-Makarim Aboueissa, PhD*
>>
>> *Professor of Statistics*
>> *Graduate Coordinator*
>>
>> *Department of Mathematics and Statistics*
>> *University of Southern Maine*
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep 12 21:43:11 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 12 Sep 2018 12:43:11 -0700
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
 <CAGxFJbTZ=2wEbsr6pxhdiOZBNnXPpWNpAjgzK1KArOF8wzJoyQ@mail.gmail.com>
Message-ID: <1D816046-DC82-48A0-BA0D-C95BF464F352@dcn.davis.ca.us>

Yes. I do it all the time.

On September 12, 2018 9:26:41 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Don't post. Try it and see.
>
>-- Bert
>
>
>On Wed, Sep 12, 2018 at 9:21 AM Rich Shepard <rshepard at appl-ecosys.com>
>wrote:
>>
>>    I run analyses in one directory and keep images and textual output
>in
>> other directories. My test involving a pdf output specifying an
>output
>> directory relative to the cwd produced a blank image. The command was
>like
>> this:
>> pdf('../images/filename.pdf')
>>
>>    Will R accept an absolute path to an output directory or none at
>all?
>>
>> TIA,
>>
>> Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From ncecch|no @end|ng |rom gm@||@com  Wed Sep 12 21:43:22 2018
From: ncecch|no @end|ng |rom gm@||@com (Nicola Cecchino)
Date: Wed, 12 Sep 2018 15:43:22 -0400
Subject: [R] Correcting dates in research records using R - 2 attempt
Message-ID: <CAO4oC1n=pa+jKpFpHHEiB29c6iYL=yxxS+wjE9y8bLgaaD5u+g@mail.gmail.com>

Hi,

I apologize - sent the first time around accidentally as HTML and not
text.  Thanks to the responder for pointing this out and providing
some feed back too.

I'm not that well versed with R - I'm trying to correct the dates of
service in a de-identified research medical record of several
subjects.  The correct dates come from a csv file, in the VisitDate
column,  that looks like this in Excel.  The empty cells have other
data in them that I don't need and the  file name is DateR.csv:


Id1       Id2                         VisitDate
12345 12345                       4/3/2018


The research medical record is a text file and the "DATE OF SERVICE"
in the top matter is in error in all of the subjects and needs to be
replaced with the "VisitDate" in the csv file.  The file name for the
medical records is test3.NEW.  Here is a screen grab of the top matter
of the research medical record; below this data excerpt is other
gathered data for that subject:


================================================================================

PATIENT NAME: CONFIDENTIAL,#12345
PATIENT ID #: 12345
DATE OF SERVICE: 04/10/2018
ACCESSION NUMBER: RR1234567

TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS       NORMAL VALUES


As described above, I need to update the text file DATE OF SERVICE:
date with the VisitDate in the csv file.

I made several attempts at this to failure and so now I turn to you.
Here is the code that exhibits my attempts:


clinicVdate <- read.csv("DateR.csv")

rownames(clinicVdate) <- as.character(clinicVdate[,'Id2'])

Id2 <- NA

input_data <- readLines("D:/test/test3.NEW")
output_data <- c()

for(input_line in input_data){
  output_line = input_line
  if(length(grep('PATIENT ID #:', input_line))>0)  {
    Id2 = as.character(strsplit(input_line, ':')[[1]][2])
  }

  if (length(grep( 'DATE OF SERVICE: ', input_line))){

    output_line = paste('DATE OF SERVICE', clinicVdate[Id2,
'VisitDate'], sep=':')

  }
  output_data = paste(output_data, output_line, sep='\n')
}

cat(output_data)


The results of the above remove the erroneous date and replace it with
NA.  Here is an example of the results:


================================================================================

PATIENT NAME: CONFIDENTIAL,#12345
PATIENT ID #: 12345
DATE OF SERVICE: NA
ACCESSION NUMBER: RR1234567

TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS       NORMAL VALUES


Where am I going wrong?  If I didn't pose my question appropriately,
please let me know too!!  Any help with this would be greatly
appreciated!!

Kind regards,

Nic Cecchino



From v@|kremk @end|ng |rom gm@||@com  Wed Sep 12 22:38:40 2018
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Wed, 12 Sep 2018 15:38:40 -0500
Subject: [R] select and hold missing
Message-ID: <CAJOiR6YZGiEZvpbjgfJQuDg+Z1urq7gkwc5iEHN3GAo=JcmS5w@mail.gmail.com>

I have a data
dfc <- read.table( text= 'week v1 v2
  w1  11  11
  w1  .    42
  w1  31  32
  w2  31  52
  w2  41  .
  w3  51  82
  w2  11  22
  w3  11  12
  w4  21  202
  w1  31  72
  w2  71  52', header = TRUE, as.is = TRUE, na.strings=c("",".","NA") )

I want to create this new variable diff = v2-v1  and remove rows based
on this "diff" value as shown below.
dfc$diff <-  dfc$v2 - dfc$v1
I want to   remove row values  <=0  and any value greater than  >=
100   and keep all values including NAs
dfca      <- dfc[((dfc$diff) > 0) & ((dfc$diff) < 100), ]

 However, the result is not what I wanted. I want the output as follow,
  week v1 v2 diff
  w1 NA  42  NA
  w1 31 32    1
  w2 31 52   21
  w2 41  NA  NA
  w3 51 82   31
  w2 11 22   11
  w3 11 12    1
  w1 31 72   41

However, I got this,l. Why it is setting all row values  NA?
   week v1 v2 diff
  <NA> NA NA   NA
  w1 31 32    1
 w2 31 52   21
 <NA> NA NA   NA
  w3 51 82   31
  w2 11 22   11
  w3 11 12    1
  w1 31 72   41

Any help ?
Thank you.



From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 12 23:04:52 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 12 Sep 2018 14:04:52 -0700
Subject: [R] select and hold missing
In-Reply-To: <CAJOiR6YZGiEZvpbjgfJQuDg+Z1urq7gkwc5iEHN3GAo=JcmS5w@mail.gmail.com>
References: <CAJOiR6YZGiEZvpbjgfJQuDg+Z1urq7gkwc5iEHN3GAo=JcmS5w@mail.gmail.com>
Message-ID: <CAGxFJbTL1iQAtg6jRPRPGjxud3wBhpLdZbjALoXHiBf_U2U-_w@mail.gmail.com>

"Why it is setting all row values  NA?"

Because the row index is NA. e.g.

> z <- data.frame(a=letters[1:3],b = 1:3); x <- c(TRUE,NA,FALSE)
> z[x,]
      a  b
1     a  1
NA <NA> NA

Change your logical comparison to (using with() to simplify entry):

> dfc[with(dfc, diff > 0 & diff < 100 | is.na(diff)), ]
   week v1 v2 diff
2    w1 NA 42   NA
3    w1 31 32    1
4    w2 31 52   21
5    w2 41 NA   NA
6    w3 51 82   31
7    w2 11 22   11
8    w3 11 12    1
10   w1 31 72   41

Cheers,
Bert


On Wed, Sep 12, 2018 at 1:39 PM Val <valkremk at gmail.com> wrote:
>
> I have a data
> dfc <- read.table( text= 'week v1 v2
>   w1  11  11
>   w1  .    42
>   w1  31  32
>   w2  31  52
>   w2  41  .
>   w3  51  82
>   w2  11  22
>   w3  11  12
>   w4  21  202
>   w1  31  72
>   w2  71  52', header = TRUE, as.is = TRUE, na.strings=c("",".","NA") )
>
> I want to create this new variable diff = v2-v1  and remove rows based
> on this "diff" value as shown below.
> dfc$diff <-  dfc$v2 - dfc$v1
> I want to   remove row values  <=0  and any value greater than  >=
> 100   and keep all values including NAs
> dfca      <- dfc[((dfc$diff) > 0) & ((dfc$diff) < 100), ]
>
>  However, the result is not what I wanted. I want the output as follow,
>   week v1 v2 diff
>   w1 NA  42  NA
>   w1 31 32    1
>   w2 31 52   21
>   w2 41  NA  NA
>   w3 51 82   31
>   w2 11 22   11
>   w3 11 12    1
>   w1 31 72   41
>
> However, I got this,l. Why it is setting all row values  NA?
>    week v1 v2 diff
>   <NA> NA NA   NA
>   w1 31 32    1
>  w2 31 52   21
>  <NA> NA NA   NA
>   w3 51 82   31
>   w2 11 22   11
>   w3 11 12    1
>   w1 31 72   41
>
> Any help ?
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From g|u@epp@ce|@|u @end|ng |rom gm@||@com  Wed Sep 12 23:06:44 2018
From: g|u@epp@ce|@|u @end|ng |rom gm@||@com (Giuseppa Cefalu)
Date: Wed, 12 Sep 2018 17:06:44 -0400
Subject: [R] How to insert a name from a list into a double loop
Message-ID: <CACGY-iReet=3eKPZWM-sGvmxqmok=tR5O=97ow8tLkGAT7xr3g@mail.gmail.com>

Hello,

The script below works well when I define the elementname <- list("name1",
"name2", "name3") .  Please see program below.
SCRIPT
```
glyCount1 <- function(answer = NULL, fileChoice = NULL, combination = NULL,
enteredValue = NULL, nameList) {

lc <- enteredValue
choseDataFiles = TRUE

first_path <- NULL
new_path <- NULL

new_dataFns <- list()

new_dataFns <- as.list(unlist(strsplit(as.character(nameList), ",")))

file_content <- NULL

elementname <- list("name1", "name2", "name3")

  for(i in 1:length(lc)){
     for(j in 1:length(lc[[i]])){
       first_path[j]<- paste(getwd(), "/", lc[[i]][j], sep = "")
       print(first_path[j])
      #  file_content[[j]] <- read.csv(file = first_path[[i]], header =
TRUE, sep = ",")
       for(k in 1:length(elementname)){
         if(k == i){
           new_path[j] <- paste(getwd(),"/", i, elementname[k], ".csv", sep
= "")
           print (new_path[j])
        }
      }
     }
  }
}

```
SCRIPT OUTPUT:

[1] "/home/giuseppa/Development/glycoPipeApp/1name1.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/1name1.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/1name1.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/1name1.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/2name2.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/2name2.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/2name2.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/3name3.csv"
[1] "/home/giuseppa/Development/glycoPipeApp/3name3.csv"


However, If instead of using the list "elementname" I call the script
through an app and I enter the list of names through a textbox, which then
is passed to the glycoPipe1 function.  Please see below.  The same script
does not return the expected output.

'new_dataFns <- list()
new_dataFns <- as.list(unlist(strsplit(as.character(nameList), ","))) is
used in the script when the value passed to the function by the app's
textinput (nameList) is used, in which case I would substitute the
elementname list buythe new_dataFns list, please see block code below.

BLOCK OF CODE
```
  for(i in 1:length(lc)){
     for(j in 1:length(lc[[i]])){
       first_path[j]<- paste(getwd(), "/", lc[[i]][j], sep = "")
       print(first_path[j])
      #  file_content[[j]] <- read.csv(file = first_path[[i]], header =
TRUE, sep = ",")
       for(k in 1:length(elementname)){
         if(k == i){
           new_path[j] <- paste(getwd(),"/", i, elementname[k], ".csv", sep
= "")
           print (new_path[j])
        }
      }
         }
```

I am sending the app below just in case you need it.  but I wonder if it
has to do with the list:
new_dataFns <- as.list(unlist(strsplit(as.character(nameList), ","))) .  It
seams that elementname a new_dataFns do not work in the same way in the
script.

Am I am building the new_dataFns list incorrectly?.  It seems as if the
values could not be accessed.

Thank you for your help


APP PROGRAM
```
library(shiny)
library(shinyjs)

ui <- fluidPage(
  selectInput("combinefiles", label = h5(strong("Do you wish to combine any
data files, and compare the combined data sets? (Y/N) ")),
              choices = c("", "Y", "N"),selected = NULL),
  verbatimTextOutput("combiningFiles"),
  verbatimTextOutput("combineChosen"),
  #verbatimTextOutput("filesToCombine"),
  useShinyjs(),
  conditionalPanel(
    condition = "output.toCombine > '0'",
    selectInput(inputId = "select",label = h5(strong("Please select from
the list")), choices = c(Chose = "",
list.files("~/Development/glycoPipeApp")), multiple = TRUE, selectize =
TRUE)
  ),
  conditionalPanel(
    condition = "output.displayAddButton > '0'",
    actionButton('add','Add')
  ),
  verbatimTextOutput("samelist"),
  conditionalPanel(
    condition = "output.displayAddButton == 1",
    actionButton("sBtn", "Press the save button to end")
  ),

  conditionalPanel(
    condition = "output.displayTheSaveButton  > '0'",
    textInput("textbox", h5(strong("Please enter name/s to designate
combined set/s separated by comma")))),
  strong(verbatimTextOutput("list")),
  verbatimTextOutput("caption")


)

#selections = NULL,

glycoPipe <- function(response = NULL, fOfData = NULL, combineResult =
NULL, listContents = NULL, vals = NULL){

enteredValue = NULL
nameList = NULL
answer = NULL
fileChoice = NULL
combination = NULL
combinations = NULL
comb = NULL
nameListSize = NULL
choseDataFiles = NULL

if(!is.null(response)){
  answer = response
}
if(!is.null(fOfData)){
  fileChoice = fOfData
}

if(!is.null(combineResult)){
  combination = combineResult
}

if(!is.null(listContents)){
  enteredValue = listContents
}

if(!is.null(vals)){
  nameList <- vals
}

glyCount1(answer, fileChoice, combination, enteredValue, nameList)

}

  server <- function(input, output, session){
    listContents = NULL

    source("Utilities/utilities.R")
    source("glycoPipeFunctions/glycoPipe_fcns.R")
    source("glyCount1.R")

    output$toCombine <- reactive({
      req(input$combinefiles)
      return(length(input$combinefiles))
    })

    outputOptions(output, "toCombine", suspendWhenHidden = FALSE)

        output$displayAddButton <- reactive({
        req(input$combinefiles)
        return(length(input$combinefiles))
     })

    outputOptions(output, "displayAddButton", suspendWhenHidden = FALSE)

    output$displayTheSaveButton <- reactive({
       req(input$sBtn)
       return(input$sBtn)
     })

    outputOptions(output, "displayTheSaveButton", suspendWhenHidden = FALSE)

      myValues <- reactiveValues()
      observe({
      if(input$add > 0){
         myValues$dList <- c(isolate(myValues$dList),
isolate(list(input$select)))
       }
    })

    # #unlist(input$filescombine)
    output$samelist<-renderPrint({
       #listContents  <- list()

       listContents <- append(listContents, myValues$dList)
       print(listContents)
      if(input$sBtn > 0){
        numberOfSelectedSets <- glycoPipe(response = NULL, fOfData = NULL,
combineResult = NULL , listContents)
        paste("Please enter", numberOfSelectedSets$nameListSize, "names to
designate your", numberOfSelectedSets$nameListSize, "sets")
       }
     })

    VALUES <- list()
     observe({
       isolate({
         req(input$textbox)
         VALUES <- input$textbox
         VALUES <- append(VALUES, list(input$textbox))
         updateTextInput(session, inputId = "textbox", value = VALUES)

      })
     })

     output$caption <- renderPrint({
       vals <- list()
       vals <- append(vals, input$textbox)
       if(input$sBtn > 0){
         result <- glycoPipe(response = NULL, fOfData = NULL, combineResult
= NULL, listContents = NULL, vals)
         #unlist(input$filescombine)
      }
     })

    session$allowReconnect(TRUE)

  }
  shinyApp(ui = ui, server = server)
```

	[[alternative HTML version deleted]]



From ch@r||e @end|ng |rom @t@t@umn@edu  Wed Sep 12 23:14:16 2018
From: ch@r||e @end|ng |rom @t@t@umn@edu (Charles Geyer)
Date: Wed, 12 Sep 2018 16:14:16 -0500
Subject: [R] YAML for bookdown
Message-ID: <CAKctRd1azRoDE3T+CERNA-Ys=FBRSZhvxKeTEM5QLiMAa-2=QQ@mail.gmail.com>

Does anyone know where I can look up all the possible things that can be
set in the YAML for bookdown?  Is this documented anywhere?  The bookdown
book (https://bookdown.org/yihui/bookdown/) just provides a few example
things.  Is the only thing to do RTFS?  Really customizing this seems hard.

-- 
Charles Geyer
Professor, School of Statistics
Resident Fellow, Minnesota Center for Philosophy of Science
University of Minnesota
charlie at stat.umn.edu

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep 12 23:27:42 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 12 Sep 2018 17:27:42 -0400
Subject: [R] YAML for bookdown
In-Reply-To: <CAKctRd1azRoDE3T+CERNA-Ys=FBRSZhvxKeTEM5QLiMAa-2=QQ@mail.gmail.com>
References: <CAKctRd1azRoDE3T+CERNA-Ys=FBRSZhvxKeTEM5QLiMAa-2=QQ@mail.gmail.com>
Message-ID: <a78448a5-fcdd-904d-b370-211729af404b@gmail.com>

On 12/09/2018 5:14 PM, Charles Geyer wrote:
> Does anyone know where I can look up all the possible things that can be
> set in the YAML for bookdown?  Is this documented anywhere?  The bookdown
> book (https://bookdown.org/yihui/bookdown/) just provides a few example
> things.  Is the only thing to do RTFS?  Really customizing this seems hard.

I think there is nothing special about bookdown except for options 
contained in the output declaration.  (I.e. other top level YAML is the 
same as for any other RMarkdown output.)

The possible entries within "output: bookdown::gitbook" are exactly the 
arguments to the bookdown::gitbook function.  It passes ... to 
rmarkdown::html_document, so those arguments are available too.

If you're using a different bookdown output format, the allowed entries 
will be the arguments to whatever function you use.

Duncan Murdoch



From jhunter @end|ng |rom |deve|opment@|n|o  Wed Sep 12 18:13:58 2018
From: jhunter @end|ng |rom |deve|opment@|n|o (Jeffrey Hunter)
Date: Wed, 12 Sep 2018 12:13:58 -0400
Subject: [R] Install R into mac
In-Reply-To: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>
References: <CAE9stmdnrkKH0sZoBYGccQ-eQSJitXfVsbjsG85CfmEX_X0JYg@mail.gmail.com>
Message-ID: <D6F21D69-AE9E-4754-91D4-BDA3FAB91EBE@idevelopment.info>

Hi,

What type of issues is your student running into?

Please review the following video install.

https://medium.com/@GalarnykMichael/install-r-and-rstudio-on-mac-e911606ce4f4 <https://medium.com/@GalarnykMichael/install-r-and-rstudio-on-mac-e911606ce4f4>

Thanks,
Jeff

Jeffrey M. Hunter
Senior DBA, Mathematical Programmer, Author
jhunter at idevelopment.info
www.idevelopment.info

A computer without a Microsoft operating system is like a dog without bricks tied to its head.

God rot Windows and all its ugly, clunky, badly-designed horror.
Stephen Fry


> On Sep 12, 2018, at 12:09 PM, AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com> wrote:
> 
> Dear All:
> 
> One of my students has  mac software  OS X Yosemite, Version 10.10.5. He
> could not install R into his mac laptop. I am not familiar with mac at all.
> Any help will be appreciated.
> 
> with thanks
> abou
> ______________________
> 
> 
> *AbouEl-Makarim Aboueissa, PhD*
> 
> *Professor of Statistics*
> *Graduate Coordinator*
> 
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 13 02:29:37 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 13 Sep 2018 10:29:37 +1000
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
Message-ID: <CA+8X3fWKBSt4WVjcmXi++0pJJA7rTpdhW6tPxNJqQN5r_uZKNA@mail.gmail.com>

Hi Rich,
Sometimes an empty image is due to not closing the image file. If you
forgot to put:

dev.off()

after the plotting commands, or there was an error in the plotting
commands, the file may be left open. Try manually entering "dev.off()"
after you have run the code. If you don't get an error:

Error in dev.off() : cannot shut down device 1 (the null device)

it means that you had an open device.

Jim

On Thu, Sep 13, 2018 at 2:21 AM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
>    I run analyses in one directory and keep images and textual output in
> other directories. My test involving a pdf output specifying an output
> directory relative to the cwd produced a blank image. The command was like
> this:
> pdf('../images/filename.pdf')
>
>    Will R accept an absolute path to an output directory or none at all?
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep 13 03:33:15 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 12 Sep 2018 18:33:15 -0700 (PDT)
Subject: [R] Save printed/plotted output to different directory
In-Reply-To: <CA+8X3fWKBSt4WVjcmXi++0pJJA7rTpdhW6tPxNJqQN5r_uZKNA@mail.gmail.com>
References: <alpine.LNX.2.20.1809120918040.27645@salmo.appl-ecosys.com>
 <CA+8X3fWKBSt4WVjcmXi++0pJJA7rTpdhW6tPxNJqQN5r_uZKNA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809121829550.6031@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Jim Lemon wrote:

> Sometimes an empty image is due to not closing the image file. If you
> forgot to put:
>
> dev.off()
>
> after the plotting commands, or there was an error in the plotting
> commands, the file may be left open. Try manually entering "dev.off()"
> after you have run the code. If you don't get an error:

Jim,

   I thought of this and entered dev.off() a couple of times, to no avail.
Then I quit R and restarted it. That cleared the problem.

   A typo slipped in the script elsewhere when I modified the path for the
output PDF file. That probably jammed the device. Fixing the typo did not
address the constipation it caused, but killing the process and starting it
again did the job.

   Thanks for the information!

Best regards,

Rich



From ro@||n@ump @end|ng |rom gm@||@com  Thu Sep 13 09:00:39 2018
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Thu, 13 Sep 2018 15:00:39 +0800
Subject: [R] customise tick marks
In-Reply-To: <CA+8X3fUD1Txb6cfUwMvHzhvg=w6oUy+iRCqmv26WgQ+TAE6gzA@mail.gmail.com>
References: <CANTvJZLMtZWX3BwUgagTMdxj0-gsz1z8SDP95-JLmM9Bvyp5Kg@mail.gmail.com>
 <CA+8X3fUD1Txb6cfUwMvHzhvg=w6oUy+iRCqmv26WgQ+TAE6gzA@mail.gmail.com>
Message-ID: <CANTvJZLXjg_ti8DA1YNuSBcg3tmPbOe2DZCG14BA1cx4sZZdZQ@mail.gmail.com>

Hi Jim,
It works beautifully.

Thank you very much for your help.


On Wed, Sep 12, 2018 at 5:58 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Roslinazairimah,
> You seem to be using the dotplot function from the lattice package. If so:
>
> dotplot(cyl ~ mpg, data = mtcars, groups = cyl, cex=1.2,
>  scales=list(y=list(labels=sort(unique(mtcars$cyl)))),
>  main="Gas Milage for Car Models",  xlab="Miles Per Gallon")
>
> Jim
> On Wed, Sep 12, 2018 at 4:21 PM roslinazairimah zakaria
> <roslinaump at gmail.com> wrote:
> >
> > Dear r-users,
> >
> > I want to draw dotplot for mtcars data according to cyl. There are three
> > types of cylinder 4,6,8. However when we draw it does not use 4,6,8
> instead
> > label it as 1,2,3.
> >
> > I have this code and would like to customise the tick mark according to
> cyl
> > groups:
> >
> >
> > dotplot(cyl ~ mpg, data = mtcars, groups = cyl, cex=1.2,axes=FALSE,
> >   main="Gas Milage for Car Models",  xlab="Miles Per Gallon")
> > ticks = c(1,2,3)
> > axis(2, at = ticks, labels=c(4,6,8))
> >
> > I got this message:
> >
> > axis(2, at = ticks, labels=c(4,6,8))
> > Error in axis(2, at = ticks, labels = c(4, 6, 8)) :
> >   plot.new has not been called yet
> >
> > Thank you so much for any help given.
> > --
> > *Roslinazairimah Zakaria*
> > *Tel: +609-5492370; Fax. No.+609-5492766*
> >
> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> > roslinaump at gmail.com <roslinaump at gmail.com>*
> > Faculty of Industrial Sciences & Technology
> > University Malaysia Pahang
> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep 13 09:53:48 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 13 Sep 2018 07:53:48 +0000
Subject: [R] Correcting dates in research / medical record using R
In-Reply-To: <415bccb8-71df-aff5-2d22-887a3f743629@gmail.com>
References: <e8b5a2bf-4403-2353-1d50-27665c60b7a7@gmail.com>
 <cfc5e11caf914d18aad819587de342d6@SRVEXCHCM1302.precheza.cz>
 <415bccb8-71df-aff5-2d22-887a3f743629@gmail.com>
Message-ID: <e2d74478a32e447a91a3dbe84c986e1b@SRVEXCHCM1302.precheza.cz>

Hi

You should send your responses to R helplist, others could offer better/different solutions.

I myself am not an expert for regex so if all your files are formated in the same way I would use strsplit.

# I read header to test object
test<-readLines("clipboard")
str(test)
 chr [1:4] "PATIENT NAME: CONFIDENTIAL,#12345" "PATIENT ID #: 12345" ...

# here is something similar to your csv file
test2<-read.table("clipboard")
test2
    Id1   Id2 VisitDate
1 12345 12345  4/3/2018
2 11111 11111  5/4/2018

# here I split second line of patient record, select 4th item and compare with Id2 value from csv file.

sel<-which(test2$Id2 == as.numeric(unlist(strsplit(test[2], " "))[4]))

# I take third line of patient record and split it
out<-unlist(strsplit(test[3], split=" "))

# and change 4th item with selected value from csv VisitDate
out[4] <- as.character(test2$VisitDate[sel])

# here you should be aware of difference between factors and characters
# and finally make collapsed line, which could be used to change third line in patient record
paste(out, collapse=" ")
[1] "DATE OF SERVICE: 4/3/2018"

But what you want to do with it? It actually manipulates objects in your R session and not original files. I believe that there are other tools more suitable for such tasks.

Cheers
Petr

> -----Original Message-----
> From: Nicola Cecchino <ncecchino at gmail.com>
> Sent: Thursday, September 13, 2018 5:04 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Subject: Re: [R] Correcting dates in research / medical record using R
>
> Hi Petr,
>
> Thank you for your help but I'm not sure what that code is supposed to do?  I'm
> really new to regular expressions and am having difficulties with this whole
> thing.
>
> Nic
>
>
>
>
> On 9/12/2018 2:26 AM, PIKAL Petr wrote:
> > Hi
> >
> > First of all you should not use HTML formated posts, it is big chance that it
> gets scrambled.
> >
> > You should compare your ld2 after for cycle and result of
> >
> > clinicVdate[Id2, 'VisitDate'], sep=':')
> >
> > Most probably ld2 after for cycle does not conform to row names of
> clinicVdate.
> >
> > Cheers
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Nicola
> >> Cecchino
> >> Sent: Wednesday, September 12, 2018 3:50 AM
> >> To: R-help at r-project.org
> >> Subject: [R] Correcting dates in research / medical record using R
> >>
> >> Hi,
> >>
> >> I'm not that well versed with R - I'm trying to correct the dates of
> >> service in a de-identified research medical record of several subjects.
> >> The correct dates come from a csv file, in the VisitDate column,
> >> that looks like this in Excel.  The empty cells have other data in
> >> them that I don't need and the  file name is DateR.csv:
> >>
> >>
> >> Id1 Id2
> >>
> >>
> >>
> >>
> >> VisitDate
> >> 12345 12345
> >>
> >>
> >>
> >>
> >> 4/3/2018
> >>
> >>
> >> The research medical record is a text file and the "DATE OF SERVICE"
> >> in the top matter is in error in all of the subjects and needs to be
> >> replaced with the "VisitDate" in the csv file.  The file name for the
> >> medical records is test3.NEW.  Here is a screen grab of the top
> >> matter of the research medical record; below this data excerpt is
> >> other gathered data for that subject:
> >>
> >>
> >>
> ===================================================================
> >> =============
> >>
> >> PATIENT NAME: CONFIDENTIAL,#12345
> >> PATIENT ID #: 12345
> >> DATE OF SERVICE: 04/10/2018
> >> ACCESSION NUMBER: RR1234567
> >>
> >> TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS NORMAL VALUES
> >>
> >>
> >> As described above, I need to update the text file DATE OF SERVICE:
> >> date with the VisitDate in the csv file.
> >>
> >> I made several attempts at this to failure and so now I turn to you.
> >> Here is the code that exhibits my attempts:
> >>
> >>
> >> clinicVdate <- read.csv("DateR.csv")
> >>
> >> rownames(clinicVdate) <- as.character(clinicVdate[,'Id2'])
> >>
> >> Id2 <- NA
> >>
> >> input_data <- readLines("D:/test/test3.NEW") output_data <- c()
> >>
> >> for(input_line in input_data){
> >>     output_line = input_line
> >>     if(length(grep('PATIENT ID #:', input_line))>0)  {
> >>       Id2 = as.character(strsplit(input_line, ':')[[1]][2])
> >>     }
> >>
> >>     if (length(grep( 'DATE OF SERVICE: ', input_line))){
> >>
> >>       output_line = paste('DATE OF SERVICE', clinicVdate[Id2,
> >> 'VisitDate'], sep=':')
> >>
> >>     }
> >>     output_data = paste(output_data, output_line, sep='\n') }
> >>
> >> cat(output_data)
> >>
> >>
> >> The results of the above remove the erroneous date and replace it
> >> with NA.  Here is an example of the results:
> >>
> >>
> >>
> ===================================================================
> >> =============
> >>
> >> PATIENT NAME: CONFIDENTIAL,#12345
> >> PATIENT ID #: 12345
> >> DATE OF SERVICE: NA
> >> ACCESSION NUMBER: RR1234567
> >>
> >> TEST PROCEDURE        HIGH/LOW  TEST RESULTS       UNITS NORMAL VALUES
> >>
> >>
> >> Where am I going wrong?  If I didn't pose my question appropriately,
> >> please let me know too!!  Any help with this would be greatly appreciated!!
> >>
> >> Kind regards,
> >>
> >> Nic Cecchino
> >>
> >>
> >>
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> > obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> > about processing and protection of business partner?s personal data
> > are available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the
> > legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From B|||@Po||ng @end|ng |rom ze||@@com  Thu Sep 13 14:14:33 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 13 Sep 2018 12:14:33 +0000
Subject: [R] Help with simple Map of US states with predefined regions
 Version 2
Message-ID: <SN6PR02MB5088847E2A3E48B54FAB2C82EA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>

Hi,

I hope someone can help me finalize this please.

I am coming close to what I need using variations from two ggplot2 tutorials.

This first gives me the map of the US with AK & HI but I cannot figure out how to get my 5 regions colored

#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1


library(ggplot2)
install.packages("ggalt")
library(ggalt)     # coord_proj
library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
install.packages("ggthemes")
library(ggthemes)  # theme_map
install.packages("rgeos")
library(rgeos)     # centroids
library(dplyr)

# composite map with AK & HI
usa_map <- usa_composite()

# calculate the centroids for each state
gCentroid(usa_map, byid=TRUE) %>%
  as.data.frame() %>%
  mutate(state=usa_map at data$iso_3166_2) -> centroids

# make it usable in ggplot2
usa_map <- fortify(usa_map)

View(usa_map)
t1 <- head(usa_map,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))

#

  # |long      |lat      | group| order|  region|subregion |
  # |:---------|:--------|-----:|-----:|-------:|:---------|
  # |-87.46201 |30.38968 |     1|     1| alabama|NA        |
  # |-87.48493 |30.37249 |     1|     2| alabama|NA        |
  # |-87.52503 |30.37249 |     1|     3| alabama|NA        |
  # |-87.53076 |30.33239 |     1|     4| alabama|NA        |
  # |-87.57087 |30.32665 |     1|     5| alabama|NA        |

usa_map <- fortify(usa_map)
gg <- ggplot()
gg <- gg + geom_map(data=usa_map, map=usa_map,
                    aes(long, lat, map_id=id),
                    color="#2b2b2b", size=0.1, fill=NA)

gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
gg <- gg + coord_proj(us_laea_proj)
gg <- gg + theme_map()
gg




#************************************************************************************************************************************************************************************/

This second is an alternative (however not liking AK&HI, not coming into the map like scenario one above) but also ignoring new Mexico (because recognizing a seventh field value) and I suspect it will do the same for new York and new jersey etc.. when I add them to the list.

Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :  line 12 did not have 6 elements

When I use newmexico (all one word) it appears white in the map like the other states not in the table statement

#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors

library(ggplot2)

read.table(text="State.Code   region            St_Abbr   Num_Estab  colors
                      1          1   alaska       Ak        13123    #f7931e
                      3          1   arizona      AZ        18053    #f7931e
                      5          1   california   CA       143937    #f7931e
                      2          1   hawaii       HI       123456    #f7931e
                      4          1   nevada       NV       654321    #f7931e
                      6          1   oregon       OR       321456    #f7931e
                      7          1   washington   WA       456123    #f7931e
                      8          2   colorado     CO       987654    #787878
                      9          2   idaho        ID       13549     #787878
                     10          2   kansas       KS       94531     #787878
                     11          2   montana      MT       456321    #787878
                     12          2   new mexico   NM     582310            #787878 <---Not liking new mexico, saying not 6
                     13          2   oklahoma     OK       214567    #787878
                     14          2   texas        TX       675421    #787878
                     15          2   utah         UT       754321    #787878
                     16          2   wyoming      WY       543124    #787878 ",
stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df

usa_map1 <- map_data("state")
t1 <- head(usa_map1,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
View(usa_map1)
#
#   |long      |lat      | group| order|  region|subregion |
#   |:---------|:--------|-----:|-----:|-------:|:---------|
#   |-87.46201 |30.38968 |     1|     1| alabama|NA        |
#   |-87.48493 |30.37249 |     1|     2| alabama|NA        |
#   |-87.52503 |30.37249 |     1|     3| alabama|NA        |
#   |-87.53076 |30.33239 |     1|     4| alabama|NA        |
#   |-87.57087 |30.32665 |     1|     5| alabama|NA        |



gg <- ggplot()
#View(gg)
gg <- gg + geom_map(data=usa_map1, map=usa_map1,
                    aes(long, lat, map_id=region),
                    color="#2b2b2b", size=0.15, fill=NA)

gg <- gg + geom_map(data=df, map=usa_map1,
                    aes(fill=colors, map_id=region),
                    color="#2b2b2b", size=0.15)


gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
gg <- gg + coord_proj(us_laea_proj)
gg <- gg + theme_map()
gg


gg <- gg + scale_color_identity()
gg <- gg + coord_map("polyconic")
gg <- gg + ggthemes::theme_map()
gg

#c( "colorado", "idaho", "kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") )
#c("alaska", "arizona", "california", "hawaii", "nevada", "oregon","washington"))



William H. Poling, Ph.D., MPH




Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 13 16:28:59 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 13 Sep 2018 07:28:59 -0700
Subject: [R] Help with simple Map of US states with predefined regions
 Version 2
In-Reply-To: <SN6PR02MB5088847E2A3E48B54FAB2C82EA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>
References: <SN6PR02MB5088847E2A3E48B54FAB2C82EA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>
Message-ID: <E7C8ACD6-49FC-4ECC-9CED-1249F3301A26@dcn.davis.ca.us>

Your data appear to be in fixed format, not  space-delimited (or delimited by any other special character), so you should use read.fwf to read it in rather that read.table.

?read.fwf

In the future you should try to identify where your errors are or your data don't look right and ask focused questions about that (reproducible) problem rather than spilling your whole script into an email. That is, your error occurred in the single read.table command and the rest of it was working fine.

On September 13, 2018 5:14:33 AM PDT, Bill Poling <Bill.Poling at zelis.com> wrote:
>Hi,
>
>I hope someone can help me finalize this please.
>
>I am coming close to what I need using variations from two ggplot2
>tutorials.
>
>This first gives me the map of the US with AK & HI but I cannot figure
>out how to get my 5 regions colored
>
>#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1
>
>
>library(ggplot2)
>install.packages("ggalt")
>library(ggalt)     # coord_proj
>library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
>install.packages("ggthemes")
>library(ggthemes)  # theme_map
>install.packages("rgeos")
>library(rgeos)     # centroids
>library(dplyr)
>
># composite map with AK & HI
>usa_map <- usa_composite()
>
># calculate the centroids for each state
>gCentroid(usa_map, byid=TRUE) %>%
>  as.data.frame() %>%
>  mutate(state=usa_map at data$iso_3166_2) -> centroids
>
># make it usable in ggplot2
>usa_map <- fortify(usa_map)
>
>View(usa_map)
>t1 <- head(usa_map,n=5)
>knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
>
>#
>
>  # |long      |lat      | group| order|  region|subregion |
>  # |:---------|:--------|-----:|-----:|-------:|:---------|
>  # |-87.46201 |30.38968 |     1|     1| alabama|NA        |
>  # |-87.48493 |30.37249 |     1|     2| alabama|NA        |
>  # |-87.52503 |30.37249 |     1|     3| alabama|NA        |
>  # |-87.53076 |30.33239 |     1|     4| alabama|NA        |
>  # |-87.57087 |30.32665 |     1|     5| alabama|NA        |
>
>usa_map <- fortify(usa_map)
>gg <- ggplot()
>gg <- gg + geom_map(data=usa_map, map=usa_map,
>                    aes(long, lat, map_id=id),
>                    color="#2b2b2b", size=0.1, fill=NA)
>
>gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
>gg <- gg + coord_proj(us_laea_proj)
>gg <- gg + theme_map()
>gg
>
>
>
>
>#************************************************************************************************************************************************************************************/
>
>This second is an alternative (however not liking AK&HI, not coming
>into the map like scenario one above) but also ignoring new Mexico
>(because recognizing a seventh field value) and I suspect it will do
>the same for new York and new jersey etc.. when I add them to the list.
>
>Error in scan(file = file, what = what, sep = sep, quote = quote, dec =
>dec,  :  line 12 did not have 6 elements
>
>When I use newmexico (all one word) it appears white in the map like
>the other states not in the table statement
>
>#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors
>
>library(ggplot2)
>
>read.table(text="State.Code   region            St_Abbr   Num_Estab
>colors
>                 1          1   alaska       Ak        13123    #f7931e
>                 3          1   arizona      AZ        18053    #f7931e
>                 5          1   california   CA       143937    #f7931e
>                 2          1   hawaii       HI       123456    #f7931e
>                 4          1   nevada       NV       654321    #f7931e
>                 6          1   oregon       OR       321456    #f7931e
>                 7          1   washington   WA       456123    #f7931e
>                 8          2   colorado     CO       987654    #787878
>                 9          2   idaho        ID       13549     #787878
>                10          2   kansas       KS       94531     #787878
>                11          2   montana      MT       456321    #787878
>12          2   new mexico   NM     582310            #787878 <---Not
>liking new mexico, saying not 6
>                13          2   oklahoma     OK       214567    #787878
>                14          2   texas        TX       675421    #787878
>                15          2   utah         UT       754321    #787878
>             16          2   wyoming      WY       543124    #787878 ",
>stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df
>
>usa_map1 <- map_data("state")
>t1 <- head(usa_map1,n=5)
>knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
>View(usa_map1)
>#
>#   |long      |lat      | group| order|  region|subregion |
>#   |:---------|:--------|-----:|-----:|-------:|:---------|
>#   |-87.46201 |30.38968 |     1|     1| alabama|NA        |
>#   |-87.48493 |30.37249 |     1|     2| alabama|NA        |
>#   |-87.52503 |30.37249 |     1|     3| alabama|NA        |
>#   |-87.53076 |30.33239 |     1|     4| alabama|NA        |
>#   |-87.57087 |30.32665 |     1|     5| alabama|NA        |
>
>
>
>gg <- ggplot()
>#View(gg)
>gg <- gg + geom_map(data=usa_map1, map=usa_map1,
>                    aes(long, lat, map_id=region),
>                    color="#2b2b2b", size=0.15, fill=NA)
>
>gg <- gg + geom_map(data=df, map=usa_map1,
>                    aes(fill=colors, map_id=region),
>                    color="#2b2b2b", size=0.15)
>
>
>gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
>gg <- gg + coord_proj(us_laea_proj)
>gg <- gg + theme_map()
>gg
>
>
>gg <- gg + scale_color_identity()
>gg <- gg + coord_map("polyconic")
>gg <- gg + ggthemes::theme_map()
>gg
>
>#c( "colorado", "idaho", "kansas", "montana", "new mexico",
>"oklahoma","texas", "utah", "wyoming") )
>#c("alaska", "arizona", "california", "hawaii", "nevada",
>"oregon","washington"))
>
>
>
>William H. Poling, Ph.D., MPH
>
>
>
>
>Confidentiality Notice This message is sent from Zelis.
>...{{dropped:13}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From B|||@Po||ng @end|ng |rom ze||@@com  Thu Sep 13 20:31:55 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 13 Sep 2018 18:31:55 +0000
Subject: [R] Help with simple Map of US states with predefined regions
 Version 2
In-Reply-To: <E7C8ACD6-49FC-4ECC-9CED-1249F3301A26@dcn.davis.ca.us>
References: <SN6PR02MB5088847E2A3E48B54FAB2C82EA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>
 <E7C8ACD6-49FC-4ECC-9CED-1249F3301A26@dcn.davis.ca.us>
Message-ID: <SN6PR02MB50885E53405A2781213DC21FEA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>

Thank you Jeff.

Cannot seem to get this to work in the fashion I want it to appear no matter how many websites and packages I investigate.

Letting it go for the moment.

Always appreciate your advice Sir!

WHP
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Thursday, September 13, 2018 10:29 AM
To: r-help at r-project.org; Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with simple Map of US states with predefined regions Version 2

Your data appear to be in fixed format, not space-delimited (or delimited by any other special character), so you should use read.fwf to read it in rather that read.table.

?read.fwf

In the future you should try to identify where your errors are or your data don't look right and ask focused questions about that (reproducible) problem rather than spilling your whole script into an email. That is, your error occurred in the single read.table command and the rest of it was working fine.

On September 13, 2018 5:14:33 AM PDT, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>Hi,
>
>I hope someone can help me finalize this please.
>
>I am coming close to what I need using variations from two ggplot2
>tutorials.
>
>This first gives me the map of the US with AK & HI but I cannot figure
>out how to get my 5 regions colored
>
>#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1<https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1>
>
>
>library(ggplot2)
>install.packages("ggalt")
>library(ggalt) # coord_proj
>library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
>install.packages("ggthemes")
>library(ggthemes) # theme_map
>install.packages("rgeos")
>library(rgeos) # centroids
>library(dplyr)
>
># composite map with AK & HI
>usa_map <- usa_composite()
>
># calculate the centroids for each state
>gCentroid(usa_map, byid=TRUE) %>%
> as.data.frame() %>%
> mutate(state=usa_map at data$iso_3166_2) -> centroids
>
># make it usable in ggplot2
>usa_map <- fortify(usa_map)
>
>View(usa_map)
>t1 <- head(usa_map,n=5)
>knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
>
>#
>
> # |long |lat | group| order| region|subregion |
> # |:---------|:--------|-----:|-----:|-------:|:---------|
> # |-87.46201 |30.38968 | 1| 1| alabama|NA |
> # |-87.48493 |30.37249 | 1| 2| alabama|NA |
> # |-87.52503 |30.37249 | 1| 3| alabama|NA |
> # |-87.53076 |30.33239 | 1| 4| alabama|NA |
> # |-87.57087 |30.32665 | 1| 5| alabama|NA |
>
>usa_map <- fortify(usa_map)
>gg <- ggplot()
>gg <- gg + geom_map(data=usa_map, map=usa_map,
> aes(long, lat, map_id=id),
> color="#2b2b2b", size=0.1, fill=NA)
>
>gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
>gg <- gg + coord_proj(us_laea_proj)
>gg <- gg + theme_map()
>gg
>
>
>
>
>#************************************************************************************************************************************************************************************/
>
>This second is an alternative (however not liking AK&HI, not coming
>into the map like scenario one above) but also ignoring new Mexico
>(because recognizing a seventh field value) and I suspect it will do
>the same for new York and new jersey etc.. when I add them to the list.
>
>Error in scan(file = file, what = what, sep = sep, quote = quote, dec =
>dec, : line 12 did not have 6 elements
>
>When I use newmexico (all one word) it appears white in the map like
>the other states not in the table statement
>
>#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors<https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors>
>
>library(ggplot2)
>
>read.table(text="State.Code region St_Abbr Num_Estab
>colors
> 1 1 alaska Ak 13123 #f7931e
> 3 1 arizona AZ 18053 #f7931e
> 5 1 california CA 143937 #f7931e
> 2 1 hawaii HI 123456 #f7931e
> 4 1 nevada NV 654321 #f7931e
> 6 1 oregon OR 321456 #f7931e
> 7 1 washington WA 456123 #f7931e
> 8 2 colorado CO 987654 #787878
> 9 2 idaho ID 13549 #787878
> 10 2 kansas KS 94531 #787878
> 11 2 montana MT 456321 #787878
>12 2 new mexico NM 582310 #787878 <---Not
>liking new mexico, saying not 6
> 13 2 oklahoma OK 214567 #787878
> 14 2 texas TX 675421 #787878
> 15 2 utah UT 754321 #787878
> 16 2 wyoming WY 543124 #787878 ",
>stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df
>
>usa_map1 <- map_data("state")
>t1 <- head(usa_map1,n=5)
>knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
>View(usa_map1)
>#
># |long |lat | group| order| region|subregion |
># |:---------|:--------|-----:|-----:|-------:|:---------|
># |-87.46201 |30.38968 | 1| 1| alabama|NA |
># |-87.48493 |30.37249 | 1| 2| alabama|NA |
># |-87.52503 |30.37249 | 1| 3| alabama|NA |
># |-87.53076 |30.33239 | 1| 4| alabama|NA |
># |-87.57087 |30.32665 | 1| 5| alabama|NA |
>
>
>
>gg <- ggplot()
>#View(gg)
>gg <- gg + geom_map(data=usa_map1, map=usa_map1,
> aes(long, lat, map_id=region),
> color="#2b2b2b", size=0.15, fill=NA)
>
>gg <- gg + geom_map(data=df, map=usa_map1,
> aes(fill=colors, map_id=region),
> color="#2b2b2b", size=0.15)
>
>
>gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
>gg <- gg + coord_proj(us_laea_proj)
>gg <- gg + theme_map()
>gg
>
>
>gg <- gg + scale_color_identity()
>gg <- gg + coord_map("polyconic")
>gg <- gg + ggthemes::theme_map()
>gg
>
>#c( "colorado", "idaho", "kansas", "montana", "new mexico",
>"oklahoma","texas", "utah", "wyoming") )
>#c("alaska", "arizona", "california", "hawaii", "nevada",
>"oregon","washington"))
>
>
>
>William H. Poling, Ph.D., MPH
>
>
>
>
>Confidentiality Notice This message is sent from Zelis.
>...{{dropped:13}}
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From motyoc@k@ @end|ng |rom y@hoo@com  Thu Sep 13 21:11:21 2018
From: motyoc@k@ @end|ng |rom y@hoo@com (Andras Farkas)
Date: Thu, 13 Sep 2018 19:11:21 +0000 (UTC)
Subject: [R] ddply (or other suitable solution) question
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
Message-ID: <1075990829.2369338.1536865881254@mail.yahoo.com>

Dear All,

I have data frame:
set.seed(123.456)
df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
? ? ? ? ? ? ? ? read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
? ? ? ? ? ? ? ? int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
? ? ? ? ? ? ? ? z=rnorm(13,1,5),
? ? ? ? ? ? ? ? y=rnorm(13,1,5))

what I would like to achieve (as best as I see it now) is to create multiple lists (and lists within lists using the data in df) that would be based on the groups in the ID column ("top level of list") and "join together" each line item within the group followed by the next line item ("bottom level list"), so would look like this for?

[[ID=1]]
[[1]][[1]]
? ID read int? ? ? ? z? ? ? ? y
? 1? ? 1? ?1 5.188935 5.107905
? 1? ? 1? ?1 1.766866 4.443201
[[ID=2]]
[[2]][[1]]? ID read int? ? ? ? ?z? ? ? ? ?y
? 2? ? 0? ?0 -4.690685 3.7695883
? 2? ? 1? ?0? 7.269075 0.6904414[[ID=2]]
[[2]][[2]]? ID read int? ? ? ? z? ? ? ? ? y
? 2? ? 1? ?0 7.269075? 0.6904414
? 2? ? 1? ?0 3.132321 -0.5298133[[ID=3]]
[[3]][[1]]? ID read int? ? ? ? ? z? ? ? ? ?y
? 3? ? 1? ?1 -0.4753574 -0.902355
? 3? ? 0? ?1? 5.4756283 -2.473535
[[ID=3]]
[[3]][[2]]
? 3? ? 0? ?1 5.475628 -2.47353489
? 3? ? 0? ?0 5.390667 -0.03958639


hoping example clear enough... all our help is appreciated,

thanks,



Andras?



From jerem|eju@te @end|ng |rom gm@||@com  Thu Sep 13 22:11:32 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Thu, 13 Sep 2018 22:11:32 +0200
Subject: [R] ddply (or other suitable solution) question
In-Reply-To: <1075990829.2369338.1536865881254@mail.yahoo.com> (Andras Farkas
 via's message of "Thu, 13 Sep 2018 19:11:21 +0000 (UTC)")
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
 <1075990829.2369338.1536865881254@mail.yahoo.com>
Message-ID: <87d0thp37v.fsf@gmail.com>

Andras Farkas via R-help <r-help at r-project.org> writes:

Hello,

 set.seed(123.456)
 
 df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
 read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
 int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
 z=rnorm(13,1,5),
 y=rnorm(13,1,5))

May this will suffice?

lapply(unique(df$ID),function(x) df[df$ID==x,])



HTH,

Jeremie



From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 13 22:40:39 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Sep 2018 13:40:39 -0700
Subject: [R] ddply (or other suitable solution) question
In-Reply-To: <1075990829.2369338.1536865881254@mail.yahoo.com>
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
 <1075990829.2369338.1536865881254@mail.yahoo.com>
Message-ID: <CAGxFJbSxu7KKy2hzYKUtq54fp+farc4S0fdzFWw5BwkTb+3ULQ@mail.gmail.com>

What if there is only one read in the id?


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 13, 2018 at 12:11 PM Andras Farkas via R-help
<r-help at r-project.org> wrote:
>
> Dear All,
>
> I have data frame:
> set.seed(123.456)
> df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
>                 read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
>                 int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
>                 z=rnorm(13,1,5),
>                 y=rnorm(13,1,5))
>
> what I would like to achieve (as best as I see it now) is to create multiple lists (and lists within lists using the data in df) that would be based on the groups in the ID column ("top level of list") and "join together" each line item within the group followed by the next line item ("bottom level list"), so would look like this for
>
> [[ID=1]]
> [[1]][[1]]
>   ID read int        z        y
>   1    1   1 5.188935 5.107905
>   1    1   1 1.766866 4.443201
> [[ID=2]]
> [[2]][[1]]  ID read int         z         y
>   2    0   0 -4.690685 3.7695883
>   2    1   0  7.269075 0.6904414[[ID=2]]
> [[2]][[2]]  ID read int        z          y
>   2    1   0 7.269075  0.6904414
>   2    1   0 3.132321 -0.5298133[[ID=3]]
> [[3]][[1]]  ID read int          z         y
>   3    1   1 -0.4753574 -0.902355
>   3    0   1  5.4756283 -2.473535
> [[ID=3]]
> [[3]][[2]]
>   3    0   1 5.475628 -2.47353489
>   3    0   0 5.390667 -0.03958639
>
>
> hoping example clear enough... all our help is appreciated,
>
> thanks,
>
>
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 13 23:16:40 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Sep 2018 14:16:40 -0700
Subject: [R] ddply (or other suitable solution) question
In-Reply-To: <CAGxFJbSxu7KKy2hzYKUtq54fp+farc4S0fdzFWw5BwkTb+3ULQ@mail.gmail.com>
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
 <1075990829.2369338.1536865881254@mail.yahoo.com>
 <CAGxFJbSxu7KKy2hzYKUtq54fp+farc4S0fdzFWw5BwkTb+3ULQ@mail.gmail.com>
Message-ID: <CAGxFJbQYwJwdarhdrgs=Gs28n6E84GysZGcs3ny3hweLE=cj-g@mail.gmail.com>

Mod my earlier question, it seems that you just want to replicate all
rows within an id if there more than 2 rows. If this is incorrect,
ignore the rest of this post.

Otherwise...

(I assume the data frame is listed in ID order, whatever that is)

set.seed(123.456)
df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
                read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
                int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
                z=rnorm(13,1,5),
                y=rnorm(13,1,5))

yielded on my Mac and R version 3.5.1

> df
   ID read int          z           y
1   1    1   1 -1.8023782  1.55341358
2   1    1   1 -0.1508874 -1.77920567
3   2    0   0  8.7935416  9.93456568
4   2    1   0  1.3525420  3.48925239
5   2    1   0  1.6464387 -8.83308578
6   3    1   1  9.5753249  4.50677951
7   3    0   1  3.3045810 -1.36395704
8   3    0   0 -5.3253062 -4.33911853
9   3    0   0 -2.4342643 -0.08987457
10  4    1   1 -1.2283099 -4.13002224
11  4    0   1  7.1204090 -2.64445615
12  5    0   1  2.7990691 -2.12519634
13  5    0   1  3.0038573 -7.43346655

## The following doubles up the rows by ID
> ix <- tapply(seq_len(nrow(df)),df$ID,
+              function(x){
+                 lenx <- length(x)
+                 if(lenx > 2)
+                    c(x[1],rep(x[2]:x[lenx-1],e=2),x[lenx])
+                 else x
+              }
+    )
> ix
$`1`
[1] 1 2

$`2`
[1] 3 4 4 5

$`3`
[1] 6 7 7 8 8 9

$`4`
[1] 10 11

$`5`
[1] 12 13

## now use the ix list to break up df:

> lapply(ix, function(i)df[i,])
$`1`
  ID read int          z         y
1  1    1   1 -1.8023782  1.553414
2  1    1   1 -0.1508874 -1.779206

$`2`
    ID read int        z         y
3    2    0   0 8.793542  9.934566
4    2    1   0 1.352542  3.489252
4.1  2    1   0 1.352542  3.489252
5    2    1   0 1.646439 -8.833086

$`3`
    ID read int         z           y
6    3    1   1  9.575325  4.50677951
7    3    0   1  3.304581 -1.36395704
7.1  3    0   1  3.304581 -1.36395704
8    3    0   0 -5.325306 -4.33911853
8.1  3    0   0 -5.325306 -4.33911853
9    3    0   0 -2.434264 -0.08987457

$`4`
   ID read int         z         y
10  4    1   1 -1.228310 -4.130022
11  4    0   1  7.120409 -2.644456

$`5`
   ID read int        z         y
12  5    0   1 2.799069 -2.125196
13  5    0   1 3.003857 -7.433467

I leave it to you to modify the lapply() function to break up each id
data frame into sublists of pairs if that is what you wish to do.
Assuming again that this is actually what you want.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Thu, Sep 13, 2018 at 1:40 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> What if there is only one read in the id?
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 13, 2018 at 12:11 PM Andras Farkas via R-help
> <r-help at r-project.org> wrote:
> >
> > Dear All,
> >
> > I have data frame:
> > set.seed(123.456)
> > df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
> >                 read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
> >                 int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
> >                 z=rnorm(13,1,5),
> >                 y=rnorm(13,1,5))
> >
> > what I would like to achieve (as best as I see it now) is to create multiple lists (and lists within lists using the data in df) that would be based on the groups in the ID column ("top level of list") and "join together" each line item within the group followed by the next line item ("bottom level list"), so would look like this for
> >
> > [[ID=1]]
> > [[1]][[1]]
> >   ID read int        z        y
> >   1    1   1 5.188935 5.107905
> >   1    1   1 1.766866 4.443201
> > [[ID=2]]
> > [[2]][[1]]  ID read int         z         y
> >   2    0   0 -4.690685 3.7695883
> >   2    1   0  7.269075 0.6904414[[ID=2]]
> > [[2]][[2]]  ID read int        z          y
> >   2    1   0 7.269075  0.6904414
> >   2    1   0 3.132321 -0.5298133[[ID=3]]
> > [[3]][[1]]  ID read int          z         y
> >   3    1   1 -0.4753574 -0.902355
> >   3    0   1  5.4756283 -2.473535
> > [[ID=3]]
> > [[3]][[2]]
> >   3    0   1 5.475628 -2.47353489
> >   3    0   0 5.390667 -0.03958639
> >
> >
> > hoping example clear enough... all our help is appreciated,
> >
> > thanks,
> >
> >
> >
> > Andras
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 14 00:32:46 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 15:32:46 -0700 (PDT)
Subject: [R] sink() output to another directory
Message-ID: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>

   Neither ?sink nor ?capture.output indicates how the output file can be
specified to be in a directory other than the cwd.

   When the cwd is ../analyses/ and I want the output to be in
../analyses/stat-summaries/ how do I write this?

   sink('example-output.txt')
   print(summary(df))
   sink()

writes output to the current directory. My attempts to prefix the file name
with ./ or just / don't sit well with R. What is the proper syntax?

TIA,

Rich



From henr|k@bengt@@on @end|ng |rom gm@||@com  Fri Sep 14 00:42:26 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 13 Sep 2018 15:42:26 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
Message-ID: <CAFDcVCS2a7hWu716CCtmX3BduMXqvppu4kuxmQNm79pEyyTb9w@mail.gmail.com>

On Thu, Sep 13, 2018 at 3:33 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
>    Neither ?sink nor ?capture.output indicates how the output file can be
> specified to be in a directory other than the cwd.
>
>    When the cwd is ../analyses/ and I want the output to be in
> ../analyses/stat-summaries/ how do I write this?
>
>    sink('example-output.txt')
>    print(summary(df))
>    sink()
>
> writes output to the current directory. My attempts to prefix the file name
> with ./ or just / don't sit well with R.

Hi welcome to R-help. Please help the helper(s) to help you by being
as explicit as possible what you've tried (i.e. cut'n'paste your
code), provide error messages (cut'n'paste) you get, if any, and/or
what you mean by "don't sit well with R" (that can mean many different
things).

/Henrik

> What is the proper syntax?
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 14 00:49:52 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 15:49:52 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
Message-ID: <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Duncan Murdoch wrote:

> What did you try?  Prefixing with either ./ or / doesn't make any sense.

Duncan,

   Using linux (and perhaps other unices) ./ and / refer to the current
directory. My code, to print to the sub-directory
(../analyses/stat-summaries/) when the script is being run in ../analyses:

sink('stat-summaries/estacada-wnw-precip.txt')
print(/summary(estacada_wnw_wx))
sink()

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 14 00:58:16 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 15:58:16 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Rich Shepard wrote:

>  sink('example-output.txt')
>  print(summary(df))
>  sink()

   Let me expand on this. When the script contains

# Open PDF device to save plot
pdf('../images/rainfall-estacada-se.pdf')
...
plot(rain_est_se)
dev.off()

the file, rainfall-estacada-se.pdf is placed in the images directory, which
is on the same directory level as the one in which the script is being run.
I thought the equivalent syntax with sink() would work, but the print
command rejects the forward slash that plot() accepts:

Error in source("rainfall-dubois-crk-all.r") :
   rainfall-dubois-crk-all.r:25:7: unexpected '/'

   Is this more clear?

Thanks,

Rich



From peter@|@ng|e|der @end|ng |rom gm@||@com  Fri Sep 14 01:04:41 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 13 Sep 2018 16:04:41 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>
Message-ID: <CA+hbrhU6S9-pofo4A1WZehxEVjPdiJazkWKE1D2nc0vEb-oZHQ@mail.gmail.com>

Remove the / from the print command, it does not belong there.

sink("../directory/file.txt");
print(summary(foo))
sink(NULL)


On Thu, Sep 13, 2018 at 4:03 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 13 Sep 2018, Rich Shepard wrote:
>
> >  sink('example-output.txt')
> >  print(summary(df))
> >  sink()
>
>    Let me expand on this. When the script contains
>
> # Open PDF device to save plot
> pdf('../images/rainfall-estacada-se.pdf')
> ...
> plot(rain_est_se)
> dev.off()
>
> the file, rainfall-estacada-se.pdf is placed in the images directory, which
> is on the same directory level as the one in which the script is being run.
> I thought the equivalent syntax with sink() would work, but the print
> command rejects the forward slash that plot() accepts:
>
> Error in source("rainfall-dubois-crk-all.r") :
>    rainfall-dubois-crk-all.r:25:7: unexpected '/'
>
>    Is this more clear?
>
> Thanks,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Sep 14 01:25:28 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 14 Sep 2018 11:25:28 +1200
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
Message-ID: <4d557f8b-20af-cfa5-a400-f850ebcdde31@auckland.ac.nz>


On 09/14/2018 10:49 AM, Rich Shepard wrote:

> On Thu, 13 Sep 2018, Duncan Murdoch wrote:
> 
>> What did you try?? Prefixing with either ./ or / doesn't make any sense.
> 
> Duncan,
> 
>  ? Using linux (and perhaps other unices) ./ and / refer to the current
> directory.

This is simply incorrect; "./" refers to the current directory but "/" 
refers to the root directory.

Note that sink("./mung.txt") gives the same result as sink("mung.txt"). 
I.e. the "./" is redundant.

If you have a directory "gorp" in your current directory, then

     sink("gorp/mung.txt")

will put the sink() output into the file "mung.txt" in the directory "gorp".

<SNIP>

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 14 01:28:09 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 16:28:09 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <CA+hbrhU6S9-pofo4A1WZehxEVjPdiJazkWKE1D2nc0vEb-oZHQ@mail.gmail.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>
 <CA+hbrhU6S9-pofo4A1WZehxEVjPdiJazkWKE1D2nc0vEb-oZHQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809131625560.10298@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Peter Langfelder wrote:

> Remove the / from the print command, it does not belong there.

Peter,

   So the print() function cannot accept a relative path to a different
directory for its output? This does seem to be the case:

source('rainfall-dubois-crk-all.r')
Error in source("rainfall-dubois-crk-all.r") :
   rainfall-dubois-crk-all.r:25:7: unexpected '/'
24: sink('stat-summaries/estacada-wnw-precip.txt')
25: print(/
           ^

   Then I'll print to the cwd and move the files manually afterwards.

Thanks,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 14 01:32:04 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 16:32:04 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <4d557f8b-20af-cfa5-a400-f850ebcdde31@auckland.ac.nz>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <4d557f8b-20af-cfa5-a400-f850ebcdde31@auckland.ac.nz>
Message-ID: <alpine.LNX.2.20.1809131628440.10298@salmo.appl-ecosys.com>

On Fri, 14 Sep 2018, Rolf Turner wrote:

> This is simply incorrect; "./" refers to the current directory but "/" refers 
> to the root directory.

Rolf,

   I was not sufficientl clear.

> Note that sink("./mung.txt") gives the same result as sink("mung.txt"). I.e. 
> the "./" is redundant.
>
> If you have a directory "gorp" in your current directory, then
>
>    sink("gorp/mung.txt")
>
> will put the sink() output into the file "mung.txt" in the directory "gorp".

sink('stat-summaries/estacada-wnw-precip.txt')
print(summary(estacada_se_wx))
sink()

results in

24: sink('stat-summaries/estacada-wnw-precip.txt')
25: print(/
           ^
   Does not matter if I use single or double quotes.

Regards,

Rich



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Sep 14 01:51:16 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 13 Sep 2018 23:51:16 +0000
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
Message-ID: <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>

In my experience, any path that can be used at the shell prompt in a unix-alike can be used anywhere that R wants a file name.

[that is, when running R on a unix-alike system, and when pwd at the shell prompt returns the same value as getwd() in R]

Hopefully, that helps...


-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/13/18, 3:49 PM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

    On Thu, 13 Sep 2018, Duncan Murdoch wrote:
    
    > What did you try?  Prefixing with either ./ or / doesn't make any sense.
    
    Duncan,
    
       Using linux (and perhaps other unices) ./ and / refer to the current
    directory. My code, to print to the sub-directory
    (../analyses/stat-summaries/) when the script is being run in ../analyses:
    
    sink('stat-summaries/estacada-wnw-precip.txt')
    print(/summary(estacada_wnw_wx))
    sink()
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 14 02:50:33 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 13 Sep 2018 17:50:33 -0700
Subject: [R] ddply (or other suitable solution) question
In-Reply-To: <1075990829.2369338.1536865881254@mail.yahoo.com>
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
 <1075990829.2369338.1536865881254@mail.yahoo.com>
Message-ID: <174D482F-C120-4503-B948-FEB0DC75C171@dcn.davis.ca.us>

The input example seems explicit enough, but I get confused understanding your desired output. Can you create an example data structure in your global environment "by hand" and use dput to give it to us?

On September 13, 2018 12:11:21 PM PDT, Andras Farkas via R-help <r-help at r-project.org> wrote:
>Dear All,
>
>I have data frame:
>set.seed(123.456)
>df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
>? ? ? ? ? ? ? ? read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
>? ? ? ? ? ? ? ? int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
>? ? ? ? ? ? ? ? z=rnorm(13,1,5),
>? ? ? ? ? ? ? ? y=rnorm(13,1,5))
>
>what I would like to achieve (as best as I see it now) is to create
>multiple lists (and lists within lists using the data in df) that would
>be based on the groups in the ID column ("top level of list") and "join
>together" each line item within the group followed by the next line
>item ("bottom level list"), so would look like this for?
>
>[[ID=1]]
>[[1]][[1]]
>? ID read int? ? ? ? z? ? ? ? y
>? 1? ? 1? ?1 5.188935 5.107905
>? 1? ? 1? ?1 1.766866 4.443201
>[[ID=2]]
>[[2]][[1]]? ID read int? ? ? ? ?z? ? ? ? ?y
>? 2? ? 0? ?0 -4.690685 3.7695883
>? 2? ? 1? ?0? 7.269075 0.6904414[[ID=2]]
>[[2]][[2]]? ID read int? ? ? ? z? ? ? ? ? y
>? 2? ? 1? ?0 7.269075? 0.6904414
>? 2? ? 1? ?0 3.132321 -0.5298133[[ID=3]]
>[[3]][[1]]? ID read int? ? ? ? ? z? ? ? ? ?y
>? 3? ? 1? ?1 -0.4753574 -0.902355
>? 3? ? 0? ?1? 5.4756283 -2.473535
>[[ID=3]]
>[[3]][[2]]
>? 3? ? 0? ?1 5.475628 -2.47353489
>? 3? ? 0? ?0 5.390667 -0.03958639
>
>
>hoping example clear enough... all our help is appreciated,
>
>thanks,
>
>
>
>Andras?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 14 03:05:15 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 18:05:15 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
Message-ID: <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, MacQueen, Don wrote:

> In my experience, any path that can be used at the shell prompt in a
> unix-alike can be used anywhere that R wants a file name.

Don,

   That's been my experiences, too.

> Hopefully, that helps...

   That's why I don't understand why the plot() function accepts the
different directory while the sink() function (here) doesn't.

   I showed R rejecting:

sink('stat-summaries/estacada-se-precip.txt')
print(summary(estacada_se_wx))
sink()

while accepting:

pdf('../images/rainfall-estacada-se.pdf')
  <snip xyplot() function>
plot(rain_est_se)
dev.off()

   Changing the sink() file to
'./stat-summaries/estacada-se-precip.txt'

generates the same error while I regularly use this syntax to copy files or
specify the relative path to an executable file.

Regards,

Rich



From henr|k@bengt@@on @end|ng |rom gm@||@com  Fri Sep 14 03:15:38 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 13 Sep 2018 18:15:38 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
Message-ID: <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>

On Thu, Sep 13, 2018 at 6:05 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Thu, 13 Sep 2018, MacQueen, Don wrote:
>
> > In my experience, any path that can be used at the shell prompt in a
> > unix-alike can be used anywhere that R wants a file name.
>
> Don,
>
>    That's been my experiences, too.
>
> > Hopefully, that helps...
>
>    That's why I don't understand why the plot() function accepts the
> different directory while the sink() function (here) doesn't.
>
>    I showed R rejecting:
>
> sink('stat-summaries/estacada-se-precip.txt')
> print(summary(estacada_se_wx))
> sink()
>
> while accepting:
>
> pdf('../images/rainfall-estacada-se.pdf')
>   <snip xyplot() function>
> plot(rain_est_se)
> dev.off()
>
>    Changing the sink() file to
> './stat-summaries/estacada-se-precip.txt'
>
> generates the same error

"same error" as what? (ambiguity is the reason for not being able to
help you - all the replies in this thread this far are correct and on
the spot)

BTW, not that it should matter, what is your operating system and version of R?

/Henrik

> while I regularly use this syntax to copy files or
> specify the relative path to an executable file.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From FAGuo @end|ng |rom corner@tone@com  Thu Sep 13 22:15:01 2018
From: FAGuo @end|ng |rom corner@tone@com (Guo, Fang (Associate))
Date: Thu, 13 Sep 2018 20:15:01 +0000
Subject: [R] Question on Binom.Confint
Message-ID: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>

Hi,

I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!


Fang Guo
Associate

CORNERSTONE RESEARCH
699 Boylston Street, 5th Floor
Boston, MA 02116-2836
617.927.3042 direct
faguo at cornerstone.com<mailto:faguo at cornerstone.com>

www.cornerstone.com<http://www.cornerstone.com/>


***********************************************************
Warning: This email may contain confidential or privileged information
intended only for the use of the individual or entity to whom it is
addressed. If you are not the intended recipient, please understand 
that any disclosure, copying, distribution, or use of the contents 
of this email is strictly prohibited.
***********************************************************

	[[alternative HTML version deleted]]



From @|m|n@@t@work @end|ng |rom gm@||@com  Thu Sep 13 23:31:50 2018
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Thu, 13 Sep 2018 17:31:50 -0400
Subject: [R] Change the position of label when using R package eulerr
Message-ID: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>

I am using eulerr to get venn.
My code is like:

fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
"LAD&nonXL_MEF" = 541,
                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")

plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
= 1),alpha=0.7)

After I get the figure, I find the position of some  labels need to be
adjusted.

Does anyone has some idea about how to process this?


Thank you,

Aimin

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Sep 14 03:56:58 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 13 Sep 2018 18:56:58 -0700
Subject: [R] Change the position of label when using R package eulerr
In-Reply-To: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
Message-ID: <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>


> On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> 
> I am using eulerr to get venn.
> My code is like:
> 
> fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
>                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> "LAD&nonXL_MEF" = 541,
>                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> 
> plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
> = 1),alpha=0.7)
> 
> After I get the figure, I find the position of some  labels need to be
> adjusted.
> 
> Does anyone has some idea about how to process this?

Looking at the code of plot.euler we see that the plotting paradigm is grid. So you could assign the output to a data.object name, search for list items that match the names of the labels you want to reposition, and modify the position values. You would need to be more specific, if you want a worked example.

As far as I can see the lables and postions are fairly deep inside a list structure:

 $ children     :List of 1
  ..$ GRID.gTree.12:List of 5
  .. ..$ children
         $ diagram.grob.1     
            $children
.. .. .. .. ..$ labels.grob    :List of 11
  .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
  .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native 69.2native 11.9native
  .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
  .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
  .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native 5.24native 27.86native
  .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
  .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"

-- 
David.
> 
> 
> Thank you,
> 
> Aimin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Sep 14 03:58:33 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 13 Sep 2018 18:58:33 -0700
Subject: [R] Question on Binom.Confint
In-Reply-To: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
Message-ID: <DF7D1D63-B3F3-491F-AAE2-98F89C240FC0@comcast.net>


> On Sep 13, 2018, at 1:15 PM, Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
> 
> Hi,
> 
> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!

First you need to tell use where you are getting Binom.Confint.

Error: object 'Binom.Confint' not found

-- 
David,
> 
> 
> Fang Guo
> Associate
> 
> CORNERSTONE RESEARCH
> 699 Boylston Street, 5th Floor
> Boston, MA 02116-2836
> 617.927.3042 direct
> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
> 
> www.cornerstone.com<http://www.cornerstone.com/>
> 
> 
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand 
> that any disclosure, copying, distribution, or use of the contents 
> of this email is strictly prohibited.
> ***********************************************************
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Sep 14 04:01:52 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 14 Sep 2018 14:01:52 +1200
Subject: [R] [FORGED]  Question on Binom.Confint
In-Reply-To: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
Message-ID: <b1545005-4871-177d-ac0d-6aed93a5a3f8@auckland.ac.nz>


On 09/14/2018 08:15 AM, Guo, Fang (Associate) wrote:

> Hi,
> 
> I have a question with the function Binom.Confint(x,n,"method"=lrt).
> For likelihood ratio test, I'd like to ask how you define the upper
> limit when the frequency of successes is zero. Thanks!

Point 1:  This question is inappropriate for this list, since it is 
about statistical theory and not about R syntax and programming.

Point 2: Where did you find the function Binom.Confint()?  I can find no 
such function anywhere.  I did manage to locate a function 
binom.confint() (note the lower case "b" and "c") but it does not have
an argument "method".  Please do not expect those whom you are 
addressing to be telepathic.

Point 3:  Having "method"=lrt in the call is decidedly weird.  Perhaps 
you meant method="lrt"; this is entirely different.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From choco|d12 @end|ng |rom gm@||@com  Fri Sep 14 04:02:53 2018
From: choco|d12 @end|ng |rom gm@||@com (lily li)
Date: Fri, 14 Sep 2018 10:02:53 +0800
Subject: [R] how to plot gridded data
In-Reply-To: <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>
References: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
 <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>

Hi Petr,

I have merged the data using cbind. The dataset is like this:
DF
lat1_lon1  lat1_lon2  lat1_lon3  ...  lat2_lon1
  1.20           1.30          2.11      ...     1.28
  1.50           1.81          3.12      ...     2.34
  2.41           2.22          1.56      ...     2.50
  3.11           4.21          2.12      ...     3.21

The other file is a shapfile, which I can open using readOGR. Then it shows
a polygon according to geographical latitude and longitude in degrees. How
to overlay the values in DF onto the polygon? note that DF has the
coordinates for a rectangular box that includes the shapefile, but is
larger. I don't know how to do this. Thanks for your help.

On Wed, Sep 12, 2018 at 3:22 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> 1. Read files/lines into R ?read.table, ?read.lines
> 2. Merge files according to your specification ?merge, ?rbind
> 3. Plot values by suitable command(s) ?plot, ?ggplot
> 4. If you want more specific answer, please post more specific question,
> preferably with concise and clear example.
> 5. Avoid posting in HTML
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of lily li
> > Sent: Wednesday, September 12, 2018 8:55 AM
> > To: R mailing list <r-help at r-project.org>
> > Subject: [R] how to plot gridded data
> >
> > Hi R users,
> >
> > I have a question about plotting gridded data. I have the files
> separately, but do
> > not know how to combine them. For example, each txt file has daily
> > precipitation data at a specific grid cell, named pr_lat_lon.txt. How to
> plot all
> > txt files for one surface (which is rectangular in this case), or how to
> combine
> > the txt files together? Thanks.
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> zasady-ochrany-osobnich-udaju/ | Information about processing and
> protection of business partner?s personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 14 04:04:14 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Sep 2018 19:04:14 -0700
Subject: [R] Question on Binom.Confint
In-Reply-To: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
Message-ID: <CAGxFJbQGbPhj0sRSqVjGOkPXoM_NoAHeE6n1WsMbxUFJpaTu9w@mail.gmail.com>

In what package?
Binomial confidence interval functions are in several.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 13, 2018 at 6:38 PM Guo, Fang (Associate)
<FAGuo at cornerstone.com> wrote:
>
> Hi,
>
> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
>
>
> Fang Guo
> Associate
>
> CORNERSTONE RESEARCH
> 699 Boylston Street, 5th Floor
> Boston, MA 02116-2836
> 617.927.3042 direct
> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
>
> www.cornerstone.com<http://www.cornerstone.com/>
>
>
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand
> that any disclosure, copying, distribution, or use of the contents
> of this email is strictly prohibited.
> ***********************************************************
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 14 04:12:00 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 13 Sep 2018 19:12:00 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Henrik Bengtsson wrote:

>> sink('stat-summaries/estacada-se-precip.txt')
>> print(summary(estacada_se_wx))
>> sink()
>>
>> while accepting:
>>
>> pdf('../images/rainfall-estacada-se.pdf')
>>   <snip xyplot() function>
>> plot(rain_est_se)
>> dev.off()
>>
>>    Changing the sink() file to
>> './stat-summaries/estacada-se-precip.txt'
>>
>> generates the same error
>
> "same error" as what? (ambiguity is the reason for not being able to
> help you - all the replies in this thread this far are correct and on
> the spot)
>
> BTW, not that it should matter, what is your operating system and version of R?

Henrik,

   As I wrote in earlier messages:

sink('stat-summaries/estacada-wnw-precip.txt')
print(summary(estacada_se_wx))
sink()

results in

24: sink('stat-summaries/estacada-wnw-precip.txt')
25: print(/
            ^
    Does not matter if I use single or double quotes.

   The message that print() doesn't like the forward slash results when I
specify 'stat-summaries/estacada-wnw-precip.txt' or
'./stat-summaries/estacada-wnw-precip.txt'.

   Running R-3.5.1 on Slackware-14.2.

Rich



From roy@mende|@@ohn @end|ng |rom no@@@gov  Fri Sep 14 04:15:12 2018
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 13 Sep 2018 19:15:12 -0700
Subject: [R] how to plot gridded data
In-Reply-To: <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
References: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
 <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>
 <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
Message-ID: <BB3A0BB1-E552-4098-B060-DC70C3DF6938@noaa.gov>

Hi Lily:

I haven't used it to any extent to give you specifics,  but I strongly suggest you look at the package sf,  it is designed to do these sorts of things.  sf can read in the shapefile,  and it has features to covert the dataframe you describe to one of its objects,  and to combine objects.  There are even plotting functions I believe,  or if not there is a ggplot2::geom_sf()

HTH,

-Roy


> On Sep 13, 2018, at 7:02 PM, lily li <chocold12 at gmail.com> wrote:
> 
> Hi Petr,
> 
> I have merged the data using cbind. The dataset is like this:
> DF
> lat1_lon1  lat1_lon2  lat1_lon3  ...  lat2_lon1
>  1.20           1.30          2.11      ...     1.28
>  1.50           1.81          3.12      ...     2.34
>  2.41           2.22          1.56      ...     2.50
>  3.11           4.21          2.12      ...     3.21
> 
> The other file is a shapfile, which I can open using readOGR. Then it shows
> a polygon according to geographical latitude and longitude in degrees. How
> to overlay the values in DF onto the polygon? note that DF has the
> coordinates for a rectangular box that includes the shapefile, but is
> larger. I don't know how to do this. Thanks for your help.
> 
> On Wed, Sep 12, 2018 at 3:22 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
>> Hi
>> 
>> 1. Read files/lines into R ?read.table, ?read.lines
>> 2. Merge files according to your specification ?merge, ?rbind
>> 3. Plot values by suitable command(s) ?plot, ?ggplot
>> 4. If you want more specific answer, please post more specific question,
>> preferably with concise and clear example.
>> 5. Avoid posting in HTML
>> 
>> Cheers
>> Petr
>> 
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of lily li
>>> Sent: Wednesday, September 12, 2018 8:55 AM
>>> To: R mailing list <r-help at r-project.org>
>>> Subject: [R] how to plot gridded data
>>> 
>>> Hi R users,
>>> 
>>> I have a question about plotting gridded data. I have the files
>> separately, but do
>>> not know how to combine them. For example, each txt file has daily
>>> precipitation data at a specific grid cell, named pr_lat_lon.txt. How to
>> plot all
>>> txt files for one surface (which is rectangular in this case), or how to
>> combine
>>> the txt files together? Thanks.
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
>> zasady-ochrany-osobnich-udaju/ | Information about processing and
>> protection of business partner?s personal data are available on website:
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>> documents attached to it may be confidential and are subject to the legally
>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.



From peter@|@ng|e|der @end|ng |rom gm@||@com  Fri Sep 14 05:11:49 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 13 Sep 2018 20:11:49 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
Message-ID: <CA+hbrhUXYExhDCo9M5Cj6qjCdyJ3Xk=dP2R=Vh6eptB+7VQkzw@mail.gmail.com>

For the second time: Rich, there should be no slash in the print() command.

Use the form

sink("../directory/file")
print(summary(foo)) ### no slashes here
sink(NULL)

Peter

On Thu, Sep 13, 2018 at 7:12 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 13 Sep 2018, Henrik Bengtsson wrote:
>
> >> sink('stat-summaries/estacada-se-precip.txt')
> >> print(summary(estacada_se_wx))
> >> sink()
> >>
> >> while accepting:
> >>
> >> pdf('../images/rainfall-estacada-se.pdf')
> >>   <snip xyplot() function>
> >> plot(rain_est_se)
> >> dev.off()
> >>
> >>    Changing the sink() file to
> >> './stat-summaries/estacada-se-precip.txt'
> >>
> >> generates the same error
> >
> > "same error" as what? (ambiguity is the reason for not being able to
> > help you - all the replies in this thread this far are correct and on
> > the spot)
> >
> > BTW, not that it should matter, what is your operating system and
> version of R?
>
> Henrik,
>
>    As I wrote in earlier messages:
>
> sink('stat-summaries/estacada-wnw-precip.txt')
> print(summary(estacada_se_wx))
> sink()
>
> results in
>
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>             ^
>     Does not matter if I use single or double quotes.
>
>    The message that print() doesn't like the forward slash results when I
> specify 'stat-summaries/estacada-wnw-precip.txt' or
> './stat-summaries/estacada-wnw-precip.txt'.
>
>    Running R-3.5.1 on Slackware-14.2.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From choco|d12 @end|ng |rom gm@||@com  Fri Sep 14 04:11:14 2018
From: choco|d12 @end|ng |rom gm@||@com (lily li)
Date: Fri, 14 Sep 2018 10:11:14 +0800
Subject: [R] how to plot gridded data
In-Reply-To: <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
References: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
 <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>
 <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
Message-ID: <CAN5afy-6=LaYF=3q2EM9=mYQCAAv0TBwB2Sh7OUkNSiE6tuRNw@mail.gmail.com>

I think it may be feasible to transform the dataset DF, so that the column
names lat_lon can be a surface, where the values locate at each surface.
But I don't know how to transform DF.

On Fri, Sep 14, 2018 at 10:02 AM, lily li <chocold12 at gmail.com> wrote:

> Hi Petr,
>
> I have merged the data using cbind. The dataset is like this:
> DF
> lat1_lon1  lat1_lon2  lat1_lon3  ...  lat2_lon1
>   1.20           1.30          2.11      ...     1.28
>   1.50           1.81          3.12      ...     2.34
>   2.41           2.22          1.56      ...     2.50
>   3.11           4.21          2.12      ...     3.21
>
> The other file is a shapfile, which I can open using readOGR. Then it
> shows a polygon according to geographical latitude and longitude in
> degrees. How to overlay the values in DF onto the polygon? note that DF has
> the coordinates for a rectangular box that includes the shapefile, but is
> larger. I don't know how to do this. Thanks for your help.
>
> On Wed, Sep 12, 2018 at 3:22 PM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
>> Hi
>>
>> 1. Read files/lines into R ?read.table, ?read.lines
>> 2. Merge files according to your specification ?merge, ?rbind
>> 3. Plot values by suitable command(s) ?plot, ?ggplot
>> 4. If you want more specific answer, please post more specific question,
>> preferably with concise and clear example.
>> 5. Avoid posting in HTML
>>
>> Cheers
>> Petr
>>
>> > -----Original Message-----
>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of lily li
>> > Sent: Wednesday, September 12, 2018 8:55 AM
>> > To: R mailing list <r-help at r-project.org>
>> > Subject: [R] how to plot gridded data
>> >
>> > Hi R users,
>> >
>> > I have a question about plotting gridded data. I have the files
>> separately, but do
>> > not know how to combine them. For example, each txt file has daily
>> > precipitation data at a specific grid cell, named pr_lat_lon.txt. How
>> to plot all
>> > txt files for one surface (which is rectangular in this case), or how
>> to combine
>> > the txt files together? Thanks.
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady
>> -ochrany-osobnich-udaju/ | Information about processing and protection
>> of business partner?s personal data are available on website:
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>> documents attached to it may be confidential and are subject to the legally
>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>
>>
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 14 04:30:27 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Sep 2018 19:30:27 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSbXoqL6df3qFqu5uyEsYLze2EvDj=Qv-BEYzQdWqviGw@mail.gmail.com>

I find your "explanation" confusing. You appear to be misusing
print(). Please read ?print carefully. You print objects in R, not
files. Objects in R do not have "/" in their names (without some
trickery). See ?make.names .

-- Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 13, 2018 at 7:12 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Thu, 13 Sep 2018, Henrik Bengtsson wrote:
>
> >> sink('stat-summaries/estacada-se-precip.txt')
> >> print(summary(estacada_se_wx))
> >> sink()
> >>
> >> while accepting:
> >>
> >> pdf('../images/rainfall-estacada-se.pdf')
> >>   <snip xyplot() function>
> >> plot(rain_est_se)
> >> dev.off()
> >>
> >>    Changing the sink() file to
> >> './stat-summaries/estacada-se-precip.txt'
> >>
> >> generates the same error
> >
> > "same error" as what? (ambiguity is the reason for not being able to
> > help you - all the replies in this thread this far are correct and on
> > the spot)
> >
> > BTW, not that it should matter, what is your operating system and version of R?
>
> Henrik,
>
>    As I wrote in earlier messages:
>
> sink('stat-summaries/estacada-wnw-precip.txt')
> print(summary(estacada_se_wx))
> sink()
>
> results in
>
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>             ^
>     Does not matter if I use single or double quotes.
>
>    The message that print() doesn't like the forward slash results when I
> specify 'stat-summaries/estacada-wnw-precip.txt' or
> './stat-summaries/estacada-wnw-precip.txt'.
>
>    Running R-3.5.1 on Slackware-14.2.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 14 04:33:52 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Sep 2018 19:33:52 -0700
Subject: [R] how to plot gridded data
In-Reply-To: <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
References: <CAN5afy85a=QMj-sA0amT6_EYhVQcCuEAT+wDLwEyskQxM5RCtw@mail.gmail.com>
 <b0315465189845f9a45775baa9bcbbdc@SRVEXCHCM1302.precheza.cz>
 <CAN5afy8Ap=YkekmjmuCwcLocw1wVi-PmUXZ_Gz5XRjdrW+xAzA@mail.gmail.com>
Message-ID: <CAGxFJbSi5Xg7CvZyF+jLH1faNEqxjQWZbML8ywVQq5i4trrgvg@mail.gmail.com>

You may wish to consider posting on r-sig-geo, where you may be more
likely to find expertise for this sort of thing.
-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 13, 2018 at 7:08 PM lily li <chocold12 at gmail.com> wrote:
>
> Hi Petr,
>
> I have merged the data using cbind. The dataset is like this:
> DF
> lat1_lon1  lat1_lon2  lat1_lon3  ...  lat2_lon1
>   1.20           1.30          2.11      ...     1.28
>   1.50           1.81          3.12      ...     2.34
>   2.41           2.22          1.56      ...     2.50
>   3.11           4.21          2.12      ...     3.21
>
> The other file is a shapfile, which I can open using readOGR. Then it shows
> a polygon according to geographical latitude and longitude in degrees. How
> to overlay the values in DF onto the polygon? note that DF has the
> coordinates for a rectangular box that includes the shapefile, but is
> larger. I don't know how to do this. Thanks for your help.
>
> On Wed, Sep 12, 2018 at 3:22 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > Hi
> >
> > 1. Read files/lines into R ?read.table, ?read.lines
> > 2. Merge files according to your specification ?merge, ?rbind
> > 3. Plot values by suitable command(s) ?plot, ?ggplot
> > 4. If you want more specific answer, please post more specific question,
> > preferably with concise and clear example.
> > 5. Avoid posting in HTML
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: R-help <r-help-bounces at r-project.org> On Behalf Of lily li
> > > Sent: Wednesday, September 12, 2018 8:55 AM
> > > To: R mailing list <r-help at r-project.org>
> > > Subject: [R] how to plot gridded data
> > >
> > > Hi R users,
> > >
> > > I have a question about plotting gridded data. I have the files
> > separately, but do
> > > not know how to combine them. For example, each txt file has daily
> > > precipitation data at a specific grid cell, named pr_lat_lon.txt. How to
> > plot all
> > > txt files for one surface (which is rectangular in this case), or how to
> > combine
> > > the txt files together? Thanks.
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> > partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> > zasady-ochrany-osobnich-udaju/ | Information about processing and
> > protection of business partner?s personal data are available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the legally
> > binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Sep 14 04:51:41 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 14 Sep 2018 14:51:41 +1200
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
Message-ID: <bd31e734-4c84-c3c7-4420-e58746976377@auckland.ac.nz>

On 09/14/2018 02:12 PM, Rich Shepard wrote:
> On Thu, 13 Sep 2018, Henrik Bengtsson wrote:
> 
>>> sink('stat-summaries/estacada-se-precip.txt')
>>> print(summary(estacada_se_wx))
>>> sink()
>>>
>>> while accepting:
>>>
>>> pdf('../images/rainfall-estacada-se.pdf')
>>> ? <snip xyplot() function>
>>> plot(rain_est_se)
>>> dev.off()
>>>
>>> ?? Changing the sink() file to
>>> './stat-summaries/estacada-se-precip.txt'
>>>
>>> generates the same error
>>
>> "same error" as what? (ambiguity is the reason for not being able to
>> help you - all the replies in this thread this far are correct and on
>> the spot)
>>
>> BTW, not that it should matter, what is your operating system and 
>> version of R?
> 
> Henrik,
> 
>  ? As I wrote in earlier messages:
> 
> sink('stat-summaries/estacada-wnw-precip.txt')
> print(summary(estacada_se_wx))
> sink()
> 
> results in
> 
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>  ?????????? ^
>  ?? Does not matter if I use single or double quotes.
> 
>  ? The message that print() doesn't like the forward slash results when I
> specify 'stat-summaries/estacada-wnw-precip.txt' or
> './stat-summaries/estacada-wnw-precip.txt'.
> 
>  ? Running R-3.5.1 on Slackware-14.2.

This would appear to have nothing to do with sink().  There is something
weird about your data set estacada_se_wx or the summary thereof that 
print() doesn't like.

If I do:

> system("mkdir stat-summaries")
> estacada_se_wx <- rnorm(10)
> sink('stat-summaries/estacada-se-precip.txt')
> print(summary(estacada_se_wx))
> sink()
> system("cat stat-summaries/estacada-se-precip.txt")

I get:

>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
> -1.7292 -0.7621  0.5428  0.2808  1.2603  1.7702 

OMMMMMMM!!!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Fri Sep 14 05:12:38 2018
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Thu, 13 Sep 2018 22:12:38 -0500
Subject: [R] Question on Binom.Confint
In-Reply-To: <DF7D1D63-B3F3-491F-AAE2-98F89C240FC0@comcast.net>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <DF7D1D63-B3F3-491F-AAE2-98F89C240FC0@comcast.net>
Message-ID: <d9effcbb-069b-237e-c31d-2415eb8aba3d@effectivedefense.org>



On 2018-09-13 20:58, David Winsemius wrote:
>> On Sep 13, 2018, at 1:15 PM, Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
>>
>> Hi,
>>
>> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
> First you need to tell use where you are getting Binom.Confint.
>
> Error: object 'Binom.Confint' not found
>

 ????? sos::findFn('Binom.Confint') found NO function named 
"Binom.Confint", but it did find two named "binom.confint", one in the 
"binom" package and the other in the "NNTbiomarker" package. The same 
search in "rdocumentation.org" returned the same results. The indicated 
command would not work in either.


 ????? Spencer



From peter@|@ng|e|der @end|ng |rom gm@||@com  Fri Sep 14 05:12:48 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 13 Sep 2018 20:12:48 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131625560.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>
 <CA+hbrhU6S9-pofo4A1WZehxEVjPdiJazkWKE1D2nc0vEb-oZHQ@mail.gmail.com>
 <alpine.LNX.2.20.1809131625560.10298@salmo.appl-ecosys.com>
Message-ID: <CA+hbrhWjtnbJ0iSAVwS8XwjnBGFc8+TZ8HFFQwm+7ziYjGnoyw@mail.gmail.com>

There is no path in print. The path (file) is set in sink().

Peter

On Thu, Sep 13, 2018 at 4:35 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 13 Sep 2018, Peter Langfelder wrote:
>
> > Remove the / from the print command, it does not belong there.
>
> Peter,
>
>    So the print() function cannot accept a relative path to a different
> directory for its output? This does seem to be the case:
>
> source('rainfall-dubois-crk-all.r')
> Error in source("rainfall-dubois-crk-all.r") :
>    rainfall-dubois-crk-all.r:25:7: unexpected '/'
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>            ^
>
>    Then I'll print to the cwd and move the files manually afterwards.
>
> Thanks,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 14 05:50:18 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 14 Sep 2018 13:50:18 +1000
Subject: [R] Question on Binom.Confint
In-Reply-To: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
Message-ID: <CA+8X3fUbws98+JWq5YOeEbTVjO-00TN7UKcdccMxHAzxi8H=fw@mail.gmail.com>

Hi Fang,
Let's assume that you are using the "binom.confint" function in the
"binom" package and you have made a spelling mistake or two. This
function employs nine methods for estimating the binomial confidence
interval. Sadly, none of these is "lrt". The zero condition is
discussed in the help page for four of these methods. Assuming you
want to use another method, you will have to look up the method. A
good start is:

https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval

Jim

On Fri, Sep 14, 2018 at 11:38 AM Guo, Fang (Associate)
<FAGuo at cornerstone.com> wrote:
>
> Hi,
>
> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
>
>
> Fang Guo
> Associate
>
> CORNERSTONE RESEARCH
> 699 Boylston Street, 5th Floor
> Boston, MA 02116-2836
> 617.927.3042 direct
> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
>
> www.cornerstone.com<http://www.cornerstone.com/>
>
>
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand
> that any disclosure, copying, distribution, or use of the contents
> of this email is strictly prohibited.
> ***********************************************************
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 14 06:59:17 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 13 Sep 2018 21:59:17 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <CAFDcVCS2a7hWu716CCtmX3BduMXqvppu4kuxmQNm79pEyyTb9w@mail.gmail.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <CAFDcVCS2a7hWu716CCtmX3BduMXqvppu4kuxmQNm79pEyyTb9w@mail.gmail.com>
Message-ID: <B21FCD80-771D-4D9D-82B6-EE5328C749BD@dcn.davis.ca.us>

It is not possible for the current working directory to begin with "../". That is like saying n=n-1, because once follow the two dots up to the next directory the two dots refer to the next directory up.

I don't think anyone in this list understands what is going on for you, so I recommend using the reprex package to create a confirmed-reproducible example and send that along so we can identify the bug or user error that is puzzling you.

On September 13, 2018 3:42:26 PM PDT, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>On Thu, Sep 13, 2018 at 3:33 PM Rich Shepard <rshepard at appl-ecosys.com>
>wrote:
>>
>>    Neither ?sink nor ?capture.output indicates how the output file
>can be
>> specified to be in a directory other than the cwd.
>>
>>    When the cwd is ../analyses/ and I want the output to be in
>> ../analyses/stat-summaries/ how do I write this?
>>
>>    sink('example-output.txt')
>>    print(summary(df))
>>    sink()
>>
>> writes output to the current directory. My attempts to prefix the
>file name
>> with ./ or just / don't sit well with R.
>
>Hi welcome to R-help. Please help the helper(s) to help you by being
>as explicit as possible what you've tried (i.e. cut'n'paste your
>code), provide error messages (cut'n'paste) you get, if any, and/or
>what you mean by "don't sit well with R" (that can mean many different
>things).
>
>/Henrik
>
>> What is the proper syntax?
>>
>> TIA,
>>
>> Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From henr|k@bengt@@on @end|ng |rom gm@||@com  Fri Sep 14 07:01:44 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 13 Sep 2018 22:01:44 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
Message-ID: <CAFDcVCSfz02e2QRppOpek01MOnPBo2Uv=vUmi+4bztxdNOphxQ@mail.gmail.com>

On Thu, Sep 13, 2018 at 7:12 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Thu, 13 Sep 2018, Henrik Bengtsson wrote:
>
> >> sink('stat-summaries/estacada-se-precip.txt')
> >> print(summary(estacada_se_wx))
> >> sink()
> >>
> >> while accepting:
> >>
> >> pdf('../images/rainfall-estacada-se.pdf')
> >>   <snip xyplot() function>
> >> plot(rain_est_se)
> >> dev.off()
> >>
> >>    Changing the sink() file to
> >> './stat-summaries/estacada-se-precip.txt'
> >>
> >> generates the same error
> >
> > "same error" as what? (ambiguity is the reason for not being able to
> > help you - all the replies in this thread this far are correct and on
> > the spot)
> >
> > BTW, not that it should matter, what is your operating system and version of R?
>
> Henrik,
>
>    As I wrote in earlier messages:
>
> sink('stat-summaries/estacada-wnw-precip.txt')
> print(summary(estacada_se_wx))
> sink()
>
> results in
>
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>             ^
>     Does not matter if I use single or double quotes.
>
>    The message that print() doesn't like the forward slash results when I
> specify 'stat-summaries/estacada-wnw-precip.txt' or
> './stat-summaries/estacada-wnw-precip.txt'.

Since it is impossible to get that error message (which is a syntax
error, i.e. the R parser does not accept the code as written and it
never gets to the point where the R engine even runs your code) for
the code you are showing, I strongly suspect that you didn't source()
the same file that you were editing (the one that contains the
three-line code you are displaying above).

I see from one of your later message that you've got it to work now.

/Henrik

>
>    Running R-3.5.1 on Slackware-14.2.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From peter@|@ng|e|der @end|ng |rom gm@||@com  Fri Sep 14 07:00:13 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 13 Sep 2018 22:00:13 -0700
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131625560.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1809131552250.10298@salmo.appl-ecosys.com>
 <CA+hbrhU6S9-pofo4A1WZehxEVjPdiJazkWKE1D2nc0vEb-oZHQ@mail.gmail.com>
 <alpine.LNX.2.20.1809131625560.10298@salmo.appl-ecosys.com>
Message-ID: <CA+hbrhVP7MDWf9zEmR_mwzwsfgweQb+TrdppM32+FdAa3jUfEA@mail.gmail.com>

Apologies if my advice wasn't clear: the file you want to write to goes in
the sink() function/command. You can put the file anywhere on your file
system, no need to write into current directory and then move the file.

The print command is completely unaware of the file you point to in sink().
Technically, print() sends output to a device called "standard output"
which is usually screen, but it can be changed to a file (_any_ writable
file) using the sink() command.

Hope this helps,

Peter

On Thu, Sep 13, 2018 at 4:35 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 13 Sep 2018, Peter Langfelder wrote:
>
> > Remove the / from the print command, it does not belong there.
>
> Peter,
>
>    So the print() function cannot accept a relative path to a different
> directory for its output? This does seem to be the case:
>
> source('rainfall-dubois-crk-all.r')
> Error in source("rainfall-dubois-crk-all.r") :
>    rainfall-dubois-crk-all.r:25:7: unexpected '/'
> 24: sink('stat-summaries/estacada-wnw-precip.txt')
> 25: print(/
>            ^
>
>    Then I'll print to the cwd and move the files manually afterwards.
>
> Thanks,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @|m|n @end|ng |rom j|mmy@h@rv@rd@edu  Thu Sep 13 23:13:04 2018
From: @|m|n @end|ng |rom j|mmy@h@rv@rd@edu (Aimin Yan)
Date: Thu, 13 Sep 2018 17:13:04 -0400
Subject: [R] Change the position of label when using R package eulerr
Message-ID: <CAPz5e0rhBfCW9mkS6bpo9f6L-9VAaFZ24CuKvDs0LduWvKDdBw@mail.gmail.com>

I am using eulerr to get venn.
My code is like:

fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
"LAD&nonXL_MEF" = 541,
                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")

plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
= 1),alpha=0.7)

After I get the figure, I find the position of some  labels need to be
adjusted.

Does anyone has some idea about how to process this?


Thank you,

Aimin

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Fri Sep 14 09:57:33 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Fri, 14 Sep 2018 07:57:33 +0000
Subject: [R] [R-sig-Geo] Help with simple Map of US states with predefined
 regions Version 2 (Solved)
Message-ID: <SN6PR02MB50887A3625E768243B557564EA190@SN6PR02MB5088.namprd02.prod.outlook.com>

Good morning Don, I cannot thank you enough for your support and the trouble you went to.
I am novice useR and the only analyst in the shop asked to learn R and the demands are growing faster than my knowledge intake, lots of laughs!

Best regards

WHP

From: MacQueen, Don <macqueen1 at llnl.gov>
Sent: Thursday, September 13, 2018 4:41 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Help with simple Map of US states with predefined regions Version 2

I know this is not a complete solution -- and it's a very different approach -- but it should at least show you a way to reliably get states colored by region.
(I also left out Alaska and Hawaii, since the point here is how to color the regions)

require(sp)
require(rgdal)

## US Census Bureau Tiger file -- polygons of each US State
## try this URL for download
## https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2017&layergroup=States+%28and+equivalent%29<https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2017&layergroup=States+%28and+equivalent%29>

## unzip to working directory ( '.' )
ustf <- readOGR('.', 'tl_2017_us_state', stringsAsFactors=FALSE)

## note, the Tiger file includes 6 additional territories
dim(ustf)
## [1] 56 14

## get rid of the extra six territories (state.name<http://state.name> comes with R)
cus <- subset(ustf, NAME %in% state.name<http://state.name>)

## cheap rename
cus$state <- cus$NAME
cus$abb <- cus$STUSPS

## invent ridiculous groupings of states
cus$grp <- 'a'
cus$grp[11:20] <- 'b'
cus$grp[21:30] <- 'c'
cus$grp[31:40] <- 'd'
cus$grp[41:50] <- 'e'

## assign colors to the groups
cus$color <- 'red'
cus$color[cus$grp=='b'] <- 'green'
cus$color[cus$grp=='c'] <- 'blue'
cus$color[cus$grp=='d'] <- 'brown'
cus$color[cus$grp=='e'] <- 'cyan'

## exclude Alaska, Hawaii
cus <- subset(cus, !(state %in% c('Alaska','Hawaii')))

## get rid of extraneous variables (optional)
cus <- cus[ , c('state','REGION','abb', 'grp') ]

## plot colored by regions as defined in the Census Bureau Tiger file
plot(cus, col=cus$REGION, usePolypath=FALSE)

## color "1" is black, looks bad, do this instead
plot(cus, col=as.numeric(cus$REGION)+1, usePolypath=FALSE)
text(coordinates(cus), cus$abb, col='white', cex=0.75)

## colors specified by a color variable in the data
plot(cus, col=cus$color, usePolypath=FALSE)
text(coordinates(cus), cus$abb, col='white', cex=0.75)

(my preferred graphics device does not support Polypath, but probably most others do, so one can omit usePolypath=FALSE)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



?On 9/13/18, 5:17 AM, "R-sig-Geo on behalf of Bill Poling" <r-sig-geo-bounces at r-project.org on behalf of Bill.Poling at zelis.com<mailto:r-sig-geo-bounces at r-project.org%20on%20behalf%20of%20Bill.Poling at zelis.com>> wrote:

Hi,

I hope someone can help me finalize this please.

I am coming close to what I need using variations from two ggplot2 tutorials.

This first gives me the map of the US with AK & HI but I cannot figure out how to get my 5 regions colored

#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1<https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1>


library(ggplot2)
install.packages("ggalt")
library(ggalt) # coord_proj
library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
install.packages("ggthemes")
library(ggthemes) # theme_map
install.packages("rgeos")
library(rgeos) # centroids
library(dplyr)

# composite map with AK & HI
usa_map <- usa_composite()

# calculate the centroids for each state gCentroid(usa_map, byid=TRUE) %>%
as.data.frame() %>%
mutate(state=usa_map at data$iso_3166_2) -> centroids

# make it usable in ggplot2
usa_map <- fortify(usa_map)

View(usa_map)
t1 <- head(usa_map,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))

#

# |long |lat | group| order| region|subregion |
# |:---------|:--------|-----:|-----:|-------:|:---------|
# |-87.46201 |30.38968 | 1| 1| alabama|NA |
# |-87.48493 |30.37249 | 1| 2| alabama|NA |
# |-87.52503 |30.37249 | 1| 3| alabama|NA |
# |-87.53076 |30.33239 | 1| 4| alabama|NA |
# |-87.57087 |30.32665 | 1| 5| alabama|NA |

usa_map <- fortify(usa_map)
gg <- ggplot()
gg <- gg + geom_map(data=usa_map, map=usa_map,
aes(long, lat, map_id=id),
color="#2b2b2b", size=0.1, fill=NA)

gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2) gg <- gg + coord_proj(us_laea_proj) gg <- gg + theme_map() gg




#************************************************************************************************************************************************************************************/

This second is an alternative (however not liking AK&HI, not coming into the map like scenario one above) but also ignoring new Mexico (because recognizing a seventh field value) and I suspect it will do the same for new York and new jersey etc.. when I add them to the list.

Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec, : line 12 did not have 6 elements

When I use newmexico (all one word) it appears white in the map like the other states not in the table statement

#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors<https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors>

library(ggplot2)

read.table(text="State.Code region St_Abbr Num_Estab colors
1 1 alaska Ak 13123 #f7931e
3 1 arizona AZ 18053 #f7931e
5 1 california CA 143937 #f7931e
2 1 hawaii HI 123456 #f7931e
4 1 nevada NV 654321 #f7931e
6 1 oregon OR 321456 #f7931e
7 1 washington WA 456123 #f7931e
8 2 colorado CO 987654 #787878
9 2 idaho ID 13549 #787878
10 2 kansas KS 94531 #787878
11 2 montana MT 456321 #787878
12 2 new mexico NM 582310 #787878 <---Not liking new mexico, saying not 6
13 2 oklahoma OK 214567 #787878
14 2 texas TX 675421 #787878
15 2 utah UT 754321 #787878
16 2 wyoming WY 543124 #787878 ",
stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df

usa_map1 <- map_data("state")
t1 <- head(usa_map1,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
View(usa_map1)
#
# |long |lat | group| order| region|subregion |
# |:---------|:--------|-----:|-----:|-------:|:---------|
# |-87.46201 |30.38968 | 1| 1| alabama|NA |
# |-87.48493 |30.37249 | 1| 2| alabama|NA |
# |-87.52503 |30.37249 | 1| 3| alabama|NA |
# |-87.53076 |30.33239 | 1| 4| alabama|NA |
# |-87.57087 |30.32665 | 1| 5| alabama|NA |



gg <- ggplot()
#View(gg)
gg <- gg + geom_map(data=usa_map1, map=usa_map1,
aes(long, lat, map_id=region),
color="#2b2b2b", size=0.15, fill=NA)

gg <- gg + geom_map(data=df, map=usa_map1,
aes(fill=colors, map_id=region),
color="#2b2b2b", size=0.15)


gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2) gg <- gg + coord_proj(us_laea_proj) gg <- gg + theme_map() gg


gg <- gg + scale_color_identity()
gg <- gg + coord_map("polyconic")
gg <- gg + ggthemes::theme_map()
gg

#c( "colorado", "idaho", "kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") ) #c("alaska", "arizona", "california", "hawaii", "nevada", "oregon","washington"))



William H. Poling, Ph.D., MPH




Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>


Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From jerem|eju@te @end|ng |rom gm@||@com  Fri Sep 14 10:33:53 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Fri, 14 Sep 2018 10:33:53 +0200
Subject: [R] modify the supposed return value of a function during
 evaluation?
Message-ID: <871s9wpjf2.fsf@gmail.com>


Hello,

I'm wondering it is possible and if yes would it be desirable to modify
the return value of functions during evaluation.

I supposed this would be very useful during debugging

myfun <- function(x) {res <- x+3 ; browser()  ; res}

let say I run the following function myfun(3)  and drop in the browser. I then happened to notice that I should 
multiply <x> by 3 instead of adding. I was thinking to do return(x*3)
but the return value is still 6.

> myfun(3)
Called from: myfun(3)
Browse[1]> 
debug at #1: res
Browse[2]> return(3*3)
[1] 6
> 


This feature could be valuable if the following setting

function(){
        tmp_res <- time_consuming_function_with_browser(param)

         some_other_function(tmp_res)
                
}

Best regards,

Jeremie



From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Sep 14 10:56:40 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 14 Sep 2018 20:56:40 +1200
Subject: [R] 
 [FORGED] modify the supposed return value of a function during
 evaluation?
In-Reply-To: <871s9wpjf2.fsf@gmail.com>
References: <871s9wpjf2.fsf@gmail.com>
Message-ID: <81071a7b-5feb-8eed-1657-cc5bbbab9ee3@auckland.ac.nz>

On 09/14/2018 08:33 PM, Jeremie Juste wrote:
> 
> Hello,
> 
> I'm wondering it is possible and if yes would it be desirable to modify
> the return value of functions during evaluation.
> 
> I supposed this would be very useful during debugging
> 
> myfun <- function(x) {res <- x+3 ; browser()  ; res}
> 
> let say I run the following function myfun(3)  and drop in the browser. I then happened to notice that I should
> multiply <x> by 3 instead of adding. I was thinking to do return(x*3)
> but the return value is still 6.
> 
>> myfun(3)
> Called from: myfun(3)
> Browse[1]>
> debug at #1: res
> Browse[2]> return(3*3)
> [1] 6

Don't use return().  Change the value of "res" and then "continue".
Browse[1]> res <- x*3
Browse[1]> c

You will get the value 9 returned by "myfun(3)".  (God how I hate this 
stupid egocentric sounding "mythis" and "mythat" syntax that Micro$oft 
has inflicted upon the world. But never mind.)

I am however very sure that your proposed approach is Not A Good Idea.

If you want an interactive structure for your function, make it 
interactive. In a well thought out and well organised manner.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From kt|tcombe02 @end|ng |rom gm@||@com  Fri Sep 14 10:02:01 2018
From: kt|tcombe02 @end|ng |rom gm@||@com (Kim Titcombe)
Date: Fri, 14 Sep 2018 10:02:01 +0200
Subject: [R] Help with setting locale
Message-ID: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>

*Query or Set Aspects of the Locale*

 I have an issue with setting LOCALE in installation (new  installation on
new computer but have installed and used R before).

I am based in Switzerland but work in English (Windows in English), hence
want English as default.

Console contains following message:

# During startup - Warning message:

# Setting LC_CTYPE= failed

-------------------------------------------------

Solutions I tried found on ?help? and in R manual as follows?.

# Sys.getlocale(category = ?LC_ALL?)

1]
"LC_COLLATE=English_Switzerland.65001;LC_CTYPE=C;LC_MONETARY=English_Switzerland.65001;LC_NUMERIC=C;LC_TIME=English_Switzerland.65001"

# Sys.setlocale(category=?LC_ALL?, locale = ? ?)

or

# Sys.setlocale(category=?LC_ALL?, local=?Switzerland.65001?)

Output

# OS reports request to set locale to "Switzerland.65001" cannot be honoured

Tried various commands specific for 'LC_CTYPE' (as this is where
installation failed) for language string such as

# Sys.setlocale("LC_CTYPE","en-GB")

Output:

In Sys.setlocale("LC_CTYPE", "en-GB") :

  OS reports request to set locale to "en-GB" cannot be honoured

Would anyone have any further suggestions for correct command.

With thanks

	[[alternative HTML version deleted]]



From j|ox @end|ng |rom mcm@@ter@c@  Fri Sep 14 14:35:42 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 14 Sep 2018 12:35:42 +0000
Subject: [R] Problem with lm.resid() when weights are provided
In-Reply-To: <22333_1536669565_w8BCdOUV005487_CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>
References: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
 <22333_1536669565_w8BCdOUV005487_CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368B0E61@FHSDB2D11-2.csu.mcmaster.ca>

Dear Hamed,

I don't think that anyone has picked up on this problem.

What's peculiar about your weights is that several are 0 within rounding error but not exactly 0:

> head(df)
           y          x       weight
1  1.5115614  0.5520924 2.117337e-34
2 -0.6365313 -0.1259932 2.117337e-34
3  0.3778278  0.4209538 4.934135e-31
4  3.0379232  1.4031545 2.679495e-24
5  1.5364652  0.4607686 2.679495e-24
6 -2.3772787 -0.7396358 6.244160e-21

I can reproduce the results that you report:

> (mod.1 <- lm(y ~ x, data=df))

Call:
lm(formula = y ~ x, data = df)

Coefficients:
(Intercept)            x  
   -0.04173      2.03790  

> max(resid(mod.1))
[1] 1.14046
> (mod.2 <- lm(y ~ x, data=df, weights=weight))

Call:
lm(formula = y ~ x, data = df, weights = weight)

Coefficients:
(Intercept)            x  
   -0.05786      1.96087  

> max(resid(mod.2))
[1] 36.84939

But the problem disappears when the tiny nonzero weight are set to 0:

> df2 <- df
> df2$weight <- zapsmall(df2$weight)
> head(df2)
           y          x weight
1  1.5115614  0.5520924      0
2 -0.6365313 -0.1259932      0
3  0.3778278  0.4209538      0
4  3.0379232  1.4031545      0
5  1.5364652  0.4607686      0
6 -2.3772787 -0.7396358      0
> (mod.3 <- update(mod.2, data=df2))

Call:
lm(formula = y ~ x, data = df2, weights = weight)

Coefficients:
(Intercept)            x  
   -0.05786      1.96087  

> max(resid(mod.3))
[1] 1.146663

I don't know exactly why this happens, but suspect numerical instability produced by the near-zero weights, which are smaller than the machine double-epsilon

> .Machine$double.neg.eps
[1] 1.110223e-16

The problem also disappears, e.g., if the tiny weight are set to 1e-15 rather than 0.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Hamed Ha
> Sent: Tuesday, September 11, 2018 8:39 AM
> To: r-help at r-project.org
> Subject: [R] Problem with lm.resid() when weights are provided
> 
> Dear R Help Team.
> 
> I get some weird results when I use the lm function with weight. The issue can
> be reproduced by the example below:
> 
> 
> The input data is (weights are intentionally designed to reflect some
> structures in the data)
> 
> 
> > df
> y x weight
>  1.51156139  0.55209240 2.117337e-34
> -0.63653132 -0.12599316 2.117337e-34
>  0.37782776  0.42095384 4.934135e-31
>  3.03792318  1.40315446 2.679495e-24
>  1.53646523  0.46076858 2.679495e-24
> -2.37727874 -0.73963576 6.244160e-21
>  0.37183065  0.20407468 1.455107e-17
> -1.53917553 -0.95519361 1.455107e-17
>  1.10926675  0.03897129 3.390908e-14
> -0.37786333 -0.17523593 3.390908e-14
>  2.43973603  0.97970095 7.902000e-11
> -0.35432394 -0.03742559 7.902000e-11
>  2.19296613  1.00355263 4.289362e-04
>  0.49845532  0.34816207 4.289362e-04
>  1.25005260  0.76306225 5.000000e-01
>  0.84360691  0.45152356 5.000000e-01
>  0.29565993  0.53880068 5.000000e-01
> -0.54081334 -0.28104525 5.000000e-01
>  0.83612836 -0.12885659 9.995711e-01
> -1.42526769 -0.87107631 9.999998e-01
>  0.10204789 -0.11649899 1.000000e+00
>  1.14292898  0.37249631 1.000000e+00
> -3.02942081 -1.28966997 1.000000e+00
> -1.37549764 -0.74676145 1.000000e+00
> -2.00118016 -0.55182759 1.000000e+00
> -4.24441674 -1.94603608 1.000000e+00
>  1.17168144  1.00868008 1.000000e+00
>  2.64007761  1.26333069 1.000000e+00
>  1.98550114  1.18509599 1.000000e+00
> -0.58941683 -0.61972416 9.999998e-01
> -4.57559611 -2.30914920 9.995711e-01
> -0.82610544 -0.39347576 9.995711e-01
> -0.02768220  0.20076910 9.995711e-01
>  0.78186399  0.25690215 9.995711e-01
> -0.88314153 -0.20200148 5.000000e-01
> -4.17076452 -2.03547588 5.000000e-01
>  0.93373070  0.54190626 4.289362e-04
> -0.08517734  0.17692491 4.289362e-04
> -4.47546619 -2.14876688 4.289362e-04
> -1.65509103 -0.76898087 4.289362e-04
> -0.39403030 -0.12689705 4.289362e-04
>  0.01203300 -0.18689898 1.841442e-07
> -4.82762639 -2.31391121 1.841442e-07
> -0.72658380 -0.39751171 3.397282e-14
> -2.35886866 -1.01082109 0.000000e+00
> -2.03762707 -0.96439902 0.000000e+00
>  0.90115123  0.60172286 0.000000e+00
>  1.55999194  0.83433953 0.000000e+00
>  3.07994058  1.30942776 0.000000e+00
>  1.78871462  1.10605530 0.000000e+00
> 
> 
> 
> Running simple linear model returns:
> 
> > lm(y~x,data=df)
> 
> Call:
> lm(formula = y ~ x, data = df)
> 
> Coefficients:
> (Intercept)            x
>    -0.04173      2.03790
> 
> and
> > max(resid(lm(y~x,data=df)))
> [1] 1.14046
> 
> 
> *HOWEVER if I use the weighted model then:*
> 
> lm(formula = y ~ x, data = df, weights = df$weights)
> 
> Coefficients:
> (Intercept)            x
>    -0.05786      1.96087
> 
> and
> > max(resid(lm(y~x,data=df,weights=df$weights)))
> [1] 60.91888
> 
> 
> as you see, the estimation of the coefficients are nearly the same but the
> resid() function returns a giant residual (I have some cases where the value is
> much much higher). Further, if I calculate the residuals by simply
> predict(lm(y~x,data=df,weights=df$weights))-df$y then I get the true value for
> the residuals.
> 
> 
> Thanks.
> 
> Please do not hesitate to contact me for more details.
> Regards,
> Hamed.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 14 14:38:34 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 05:38:34 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <CAGxFJbSbXoqL6df3qFqu5uyEsYLze2EvDj=Qv-BEYzQdWqviGw@mail.gmail.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
 <CAGxFJbSbXoqL6df3qFqu5uyEsYLze2EvDj=Qv-BEYzQdWqviGw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809140532490.27826@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Bert Gunter wrote:

> I find your "explanation" confusing. You appear to be misusing print().
> Please read ?print carefully. You print objects in R, not files. Objects
> in R do not have "/" in their names (without some trickery). See
> ?make.names .

Bert,

   I had read both ?print and ?print.default looking for information about
placing the printed object in another directory, and found nothing.

   My initial assumption was that print() worked similar to plot(). I use
plot() after specifying a pdf file as output and thought that sink() (which
?sink tells me diverts R output to a connection (and stops it as dev.off
stops writing to the pdf file). That sink() apparently does not work the
same way is why I posted my question.

Regards,

Rich



From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Fri Sep 14 16:01:24 2018
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Fri, 14 Sep 2018 14:01:24 +0000
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809140532490.27826@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <E985CF94-AD5D-4D22-A18B-FA95E9B7C2B0@llnl.gov>
 <alpine.LNX.2.20.1809131757310.10298@salmo.appl-ecosys.com>
 <CAFDcVCS+OnYRAnEXUcJEwyvSkD=RDDk+rCiYVu7sGZ_UbNaXvw@mail.gmail.com>
 <alpine.LNX.2.20.1809131909180.23465@salmo.appl-ecosys.com>
 <CAGxFJbSbXoqL6df3qFqu5uyEsYLze2EvDj=Qv-BEYzQdWqviGw@mail.gmail.com>,
 <alpine.LNX.2.20.1809140532490.27826@salmo.appl-ecosys.com>
Message-ID: <CO2PR03MB22326B3617E42ACA09200BAFE2190@CO2PR03MB2232.namprd03.prod.outlook.com>

As has been pointed out, the correct way to direct printing to a given location is using sink( . . . put path here . . . ) then print() and then sink() without any argument to turn off print direction. A helpful addition to this strategy is to use the file.path function to define a variable that specifies the path, i.e.


path <- file.path( . . . specify path here, see documentation of file.path . . .)

sink(path)

print(. . . an R object . . .)

sink()

The nice feature about using file.path is that it by default it formats the path correctly for the OS on which you are running R; paths are specified differently (i.e. use of slashes vs. back slashes) when using Linux vs. windows systems. Note that when specifying the path using file.path rather than having to format the path according to the dictates of your OS, all you need to do is to specify the elements of the path

path <- file.path("data",''FIPSstudy","exercisetests"). The result will be a character string that is formatted properly for your OS.


John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Rich Shepard <rshepard at appl-ecosys.com>
Sent: Friday, September 14, 2018 8:38 AM
To: R-help
Subject: Re: [R] sink() output to another directory

CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.



On Thu, 13 Sep 2018, Bert Gunter wrote:

> I find your "explanation" confusing. You appear to be misusing print().
> Please read ?print carefully. You print objects in R, not files. Objects
> in R do not have "/" in their names (without some trickery). See
> ?make.names .

Bert,

   I had read both ?print and ?print.default looking for information about
placing the printed object in another directory, and found nothing.

   My initial assumption was that print() worked similar to plot(). I use
plot() after specifying a pdf file as output and thought that sink() (which
?sink tells me diverts R output to a connection (and stops it as dev.off
stops writing to the pdf file). That sink() apparently does not work the
same way is why I posted my question.

Regards,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 14 16:05:21 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 07:05:21 -0700 (PDT)
Subject: [R] sink() output to another directory [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809140659210.27826@salmo.appl-ecosys.com>

On Thu, 13 Sep 2018, Rich Shepard wrote:

>  sink('stat-summary/example-output.txt')
>  print(summary(df))
>  sink()

   My apologies to everyone for not seeing a typo further in the script.

   I had the path to the appropriate directory in the sink() function and the
print() function had only the command as above. Except for one dataframe. In
that one I had stuck a '/' in front of the summary() function and that
caused the problem.

   I just found an R equivalent to lint to find such syntactical errors before I
embarrass myself again. Has anyone used lintr from github? I will definitely
start using this on my scripts.

Mea culpa,

Rich



From kry|ov@r00t @end|ng |rom gm@||@com  Fri Sep 14 16:11:10 2018
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 14 Sep 2018 17:11:10 +0300
Subject: [R] sink() output to another directory
In-Reply-To: <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
Message-ID: <20180914171110.464d61d3@trisector>

? Thu, 13 Sep 2018 15:49:52 -0700 (PDT)
Rich Shepard <rshepard at appl-ecosys.com> ?????:

> sink('stat-summaries/estacada-wnw-precip.txt')
> print(/summary(estacada_wnw_wx))
> sink()

Just remove the slash from your print command (line 25 of
rainfall-dubois-crk-all.r) because it's a syntax error (must be a typo).
I.e. the above should be print(summary(estacada_wnw_wx)), not
print(/summary(estacada_wnw_wx)) (do you notice the difference?). The
rest of your sequence of commands is fine.

-- 
Best regards,
Ivan



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 14 16:19:16 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 07:19:16 -0700 (PDT)
Subject: [R] sink() output to another directory
In-Reply-To: <20180914171110.464d61d3@trisector>
References: <alpine.LNX.2.20.1809131524560.10298@salmo.appl-ecosys.com>
 <05b08084-29a8-b3e5-a0a8-880b9ef60499@gmail.com>
 <alpine.LNX.2.20.1809131546070.10298@salmo.appl-ecosys.com>
 <20180914171110.464d61d3@trisector>
Message-ID: <alpine.LNX.2.20.1809140717360.27826@salmo.appl-ecosys.com>

On Fri, 14 Sep 2018, Ivan Krylov wrote:

> Just remove the slash from your print command (line 25 of
> rainfall-dubois-crk-all.r) because it's a syntax error (must be a typo).
> I.e. the above should be print(summary(estacada_wnw_wx)), not
> print(/summary(estacada_wnw_wx)) (do you notice the difference?). The rest
> of your sequence of commands is fine.

Ivan,

   Yes, it was and I did not see it each time I looked at the code, ignoring
the error message point me to it.

   I've now installed lintr and will use that on all my scripts before I run
them.

Regards,

Rich



From motyoc@k@ @end|ng |rom y@hoo@com  Fri Sep 14 16:19:53 2018
From: motyoc@k@ @end|ng |rom y@hoo@com (Andras Farkas)
Date: Fri, 14 Sep 2018 14:19:53 +0000 (UTC)
Subject: [R] ddply (or other suitable solution) question
In-Reply-To: <CAGxFJbQYwJwdarhdrgs=Gs28n6E84GysZGcs3ny3hweLE=cj-g@mail.gmail.com>
References: <1075990829.2369338.1536865881254.ref@mail.yahoo.com>
 <1075990829.2369338.1536865881254@mail.yahoo.com>
 <CAGxFJbSxu7KKy2hzYKUtq54fp+farc4S0fdzFWw5BwkTb+3ULQ@mail.gmail.com>
 <CAGxFJbQYwJwdarhdrgs=Gs28n6E84GysZGcs3ny3hweLE=cj-g@mail.gmail.com>
Message-ID: <955022905.4938494.1536934793945@mail.yahoo.com>

thank you all, Bert's idea will get it done... good question also re what if 1 row: have a separate plan for that... Anyhow, finishing up Bert's lines with?
z<-lapply(ix, function(i)? ?df[i,])
lapply(z, function(x) split(x, rep(1:ceiling(nrow(x)/2), each=2)[1:nrow(x)]))


seems to do what I need,
thanks again...

Andras? 

    On Thursday, September 13, 2018, 5:16:54 PM EDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:  
 
 Mod my earlier question, it seems that you just want to replicate all
rows within an id if there more than 2 rows. If this is incorrect,
ignore the rest of this post.

Otherwise...

(I assume the data frame is listed in ID order, whatever that is)

set.seed(123.456)
df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
? ? ? ? ? ? ? ? read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
? ? ? ? ? ? ? ? int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
? ? ? ? ? ? ? ? z=rnorm(13,1,5),
? ? ? ? ? ? ? ? y=rnorm(13,1,5))

yielded on my Mac and R version 3.5.1

> df
? ID read int? ? ? ? ? z? ? ? ? ? y
1? 1? ? 1? 1 -1.8023782? 1.55341358
2? 1? ? 1? 1 -0.1508874 -1.77920567
3? 2? ? 0? 0? 8.7935416? 9.93456568
4? 2? ? 1? 0? 1.3525420? 3.48925239
5? 2? ? 1? 0? 1.6464387 -8.83308578
6? 3? ? 1? 1? 9.5753249? 4.50677951
7? 3? ? 0? 1? 3.3045810 -1.36395704
8? 3? ? 0? 0 -5.3253062 -4.33911853
9? 3? ? 0? 0 -2.4342643 -0.08987457
10? 4? ? 1? 1 -1.2283099 -4.13002224
11? 4? ? 0? 1? 7.1204090 -2.64445615
12? 5? ? 0? 1? 2.7990691 -2.12519634
13? 5? ? 0? 1? 3.0038573 -7.43346655

## The following doubles up the rows by ID
> ix <- tapply(seq_len(nrow(df)),df$ID,
+? ? ? ? ? ? ? function(x){
+? ? ? ? ? ? ? ? lenx <- length(x)
+? ? ? ? ? ? ? ? if(lenx > 2)
+? ? ? ? ? ? ? ? ? ? c(x[1],rep(x[2]:x[lenx-1],e=2),x[lenx])
+? ? ? ? ? ? ? ? else x
+? ? ? ? ? ? ? }
+? ? )
> ix
$`1`
[1] 1 2

$`2`
[1] 3 4 4 5

$`3`
[1] 6 7 7 8 8 9

$`4`
[1] 10 11

$`5`
[1] 12 13

## now use the ix list to break up df:

> lapply(ix, function(i)df[i,])
$`1`
? ID read int? ? ? ? ? z? ? ? ? y
1? 1? ? 1? 1 -1.8023782? 1.553414
2? 1? ? 1? 1 -0.1508874 -1.779206

$`2`
? ? ID read int? ? ? ? z? ? ? ? y
3? ? 2? ? 0? 0 8.793542? 9.934566
4? ? 2? ? 1? 0 1.352542? 3.489252
4.1? 2? ? 1? 0 1.352542? 3.489252
5? ? 2? ? 1? 0 1.646439 -8.833086

$`3`
? ? ID read int? ? ? ? z? ? ? ? ? y
6? ? 3? ? 1? 1? 9.575325? 4.50677951
7? ? 3? ? 0? 1? 3.304581 -1.36395704
7.1? 3? ? 0? 1? 3.304581 -1.36395704
8? ? 3? ? 0? 0 -5.325306 -4.33911853
8.1? 3? ? 0? 0 -5.325306 -4.33911853
9? ? 3? ? 0? 0 -2.434264 -0.08987457

$`4`
? ID read int? ? ? ? z? ? ? ? y
10? 4? ? 1? 1 -1.228310 -4.130022
11? 4? ? 0? 1? 7.120409 -2.644456

$`5`
? ID read int? ? ? ? z? ? ? ? y
12? 5? ? 0? 1 2.799069 -2.125196
13? 5? ? 0? 1 3.003857 -7.433467

I leave it to you to modify the lapply() function to break up each id
data frame into sublists of pairs if that is what you wish to do.
Assuming again that this is actually what you want.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Thu, Sep 13, 2018 at 1:40 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> What if there is only one read in the id?
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 13, 2018 at 12:11 PM Andras Farkas via R-help
> <r-help at r-project.org> wrote:
> >
> > Dear All,
> >
> > I have data frame:
> > set.seed(123.456)
> > df <-data.frame(ID=c(1,1,2,2,2,3,3,3,3,4,4,5,5),
> >? ? ? ? ? ? ? ? read=c(1,1,0,1,1,1,0,0,0,1,0,0,0),
> >? ? ? ? ? ? ? ? int=c(1,1,0,0,0,1,1,0,0,1,1,1,1),
> >? ? ? ? ? ? ? ? z=rnorm(13,1,5),
> >? ? ? ? ? ? ? ? y=rnorm(13,1,5))
> >
> > what I would like to achieve (as best as I see it now) is to create multiple lists (and lists within lists using the data in df) that would be based on the groups in the ID column ("top level of list") and "join together" each line item within the group followed by the next line item ("bottom level list"), so would look like this for
> >
> > [[ID=1]]
> > [[1]][[1]]
> >? ID read int? ? ? ? z? ? ? ? y
> >? 1? ? 1? 1 5.188935 5.107905
> >? 1? ? 1? 1 1.766866 4.443201
> > [[ID=2]]
> > [[2]][[1]]? ID read int? ? ? ? z? ? ? ? y
> >? 2? ? 0? 0 -4.690685 3.7695883
> >? 2? ? 1? 0? 7.269075 0.6904414[[ID=2]]
> > [[2]][[2]]? ID read int? ? ? ? z? ? ? ? ? y
> >? 2? ? 1? 0 7.269075? 0.6904414
> >? 2? ? 1? 0 3.132321 -0.5298133[[ID=3]]
> > [[3]][[1]]? ID read int? ? ? ? ? z? ? ? ? y
> >? 3? ? 1? 1 -0.4753574 -0.902355
> >? 3? ? 0? 1? 5.4756283 -2.473535
> > [[ID=3]]
> > [[3]][[2]]
> >? 3? ? 0? 1 5.475628 -2.47353489
> >? 3? ? 0? 0 5.390667 -0.03958639
> >
> >
> > hoping example clear enough... all our help is appreciated,
> >
> > thanks,
> >
> >
> >
> > Andras
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 14 16:36:17 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 14 Sep 2018 07:36:17 -0700
Subject: [R] Question on Binom.Confint
In-Reply-To: <25d985786e3c428ab38f1e4fbb977b86@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <CAGxFJbQGbPhj0sRSqVjGOkPXoM_NoAHeE6n1WsMbxUFJpaTu9w@mail.gmail.com>
 <25d985786e3c428ab38f1e4fbb977b86@CRCOEXCH2.cornerstone.com>
Message-ID: <CAGxFJbTrkQNjouUFEZ9FJm++XO27t9ghEifhQcq87tbMv2++kg@mail.gmail.com>

Then it's binom.confint (case matters in R -- PLEASE DO A TUTORIAL OR
TWO!) and there is no "lrt"  option. So no idea what you're referring
to.

-- Bert


On Fri, Sep 14, 2018 at 6:53 AM Guo, Fang (Associate)
<FAGuo at cornerstone.com> wrote:
>
> I used library(binom).
>
> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Thursday, September 13, 2018 10:04 PM
> To: Guo, Fang (Associate) <FAGuo at cornerstone.com>
> Cc: r-help-request at r-project.org; R-help <r-help at r-project.org>
> Subject: Re: [R] Question on Binom.Confint
>
> In what package?
> Binomial confidence interval functions are in several.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 13, 2018 at 6:38 PM Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
> >
> > Hi,
> >
> > I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
> >
> >
> > Fang Guo
> > Associate
> >
> > CORNERSTONE RESEARCH
> > 699 Boylston Street, 5th Floor
> > Boston, MA 02116-2836
> > 617.927.3042 direct
> > faguo at cornerstone.com<mailto:faguo at cornerstone.com>
> >
> > www.cornerstone.com<http://www.cornerstone.com/>
> >
> >
> > ***********************************************************
> > Warning: This email may contain confidential or privileged information
> > intended only for the use of the individual or entity to whom it is
> > addressed. If you are not the intended recipient, please understand
> > that any disclosure, copying, distribution, or use of the contents of
> > this email is strictly prohibited.
> > ***********************************************************
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand
> that any disclosure, copying, distribution, or use of the contents
> of this email is strictly prohibited.
> ***********************************************************



From FAGuo @end|ng |rom corner@tone@com  Fri Sep 14 15:52:15 2018
From: FAGuo @end|ng |rom corner@tone@com (Guo, Fang (Associate))
Date: Fri, 14 Sep 2018 13:52:15 +0000
Subject: [R] [FORGED]  Question on Binom.Confint
In-Reply-To: <b1545005-4871-177d-ac0d-6aed93a5a3f8@auckland.ac.nz>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <b1545005-4871-177d-ac0d-6aed93a5a3f8@auckland.ac.nz>
Message-ID: <d8ee54b0b44d43e6915750bef37ef2bc@CRCOEXCH2.cornerstone.com>

It's method="lrt" and I used the "binom" package.

-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz] 
Sent: Thursday, September 13, 2018 10:02 PM
To: Guo, Fang (Associate) <FAGuo at cornerstone.com>
Cc: r-help at R-project.org
Subject: Re: [FORGED] [R] Question on Binom.Confint


On 09/14/2018 08:15 AM, Guo, Fang (Associate) wrote:

> Hi,
> 
> I have a question with the function Binom.Confint(x,n,"method"=lrt).
> For likelihood ratio test, I'd like to ask how you define the upper 
> limit when the frequency of successes is zero. Thanks!

Point 1:  This question is inappropriate for this list, since it is about statistical theory and not about R syntax and programming.

Point 2: Where did you find the function Binom.Confint()?  I can find no such function anywhere.  I did manage to locate a function
binom.confint() (note the lower case "b" and "c") but it does not have an argument "method".  Please do not expect those whom you are addressing to be telepathic.

Point 3:  Having "method"=lrt in the call is decidedly weird.  Perhaps you meant method="lrt"; this is entirely different.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
***********************************************************
Warning: This email may contain confidential or privileged information
intended only for the use of the individual or entity to whom it is
addressed. If you are not the intended recipient, please understand 
that any disclosure, copying, distribution, or use of the contents 
of this email is strictly prohibited.
***********************************************************

From FAGuo @end|ng |rom corner@tone@com  Fri Sep 14 15:53:05 2018
From: FAGuo @end|ng |rom corner@tone@com (Guo, Fang (Associate))
Date: Fri, 14 Sep 2018 13:53:05 +0000
Subject: [R] Question on Binom.Confint
In-Reply-To: <CAGxFJbQGbPhj0sRSqVjGOkPXoM_NoAHeE6n1WsMbxUFJpaTu9w@mail.gmail.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <CAGxFJbQGbPhj0sRSqVjGOkPXoM_NoAHeE6n1WsMbxUFJpaTu9w@mail.gmail.com>
Message-ID: <25d985786e3c428ab38f1e4fbb977b86@CRCOEXCH2.cornerstone.com>

I used library(binom). 

-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Thursday, September 13, 2018 10:04 PM
To: Guo, Fang (Associate) <FAGuo at cornerstone.com>
Cc: r-help-request at r-project.org; R-help <r-help at r-project.org>
Subject: Re: [R] Question on Binom.Confint

In what package?
Binomial confidence interval functions are in several.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 13, 2018 at 6:38 PM Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
>
> Hi,
>
> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
>
>
> Fang Guo
> Associate
>
> CORNERSTONE RESEARCH
> 699 Boylston Street, 5th Floor
> Boston, MA 02116-2836
> 617.927.3042 direct
> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
>
> www.cornerstone.com<http://www.cornerstone.com/>
>
>
> ***********************************************************
> Warning: This email may contain confidential or privileged information 
> intended only for the use of the individual or entity to whom it is 
> addressed. If you are not the intended recipient, please understand 
> that any disclosure, copying, distribution, or use of the contents of 
> this email is strictly prohibited.
> ***********************************************************
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
***********************************************************
Warning: This email may contain confidential or privileged information
intended only for the use of the individual or entity to whom it is
addressed. If you are not the intended recipient, please understand 
that any disclosure, copying, distribution, or use of the contents 
of this email is strictly prohibited.
***********************************************************

From FAGuo @end|ng |rom corner@tone@com  Fri Sep 14 17:04:21 2018
From: FAGuo @end|ng |rom corner@tone@com (Guo, Fang (Associate))
Date: Fri, 14 Sep 2018 15:04:21 +0000
Subject: [R] Question on Binom.Confint
In-Reply-To: <CA+8X3fUbws98+JWq5YOeEbTVjO-00TN7UKcdccMxHAzxi8H=fw@mail.gmail.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <CA+8X3fUbws98+JWq5YOeEbTVjO-00TN7UKcdccMxHAzxi8H=fw@mail.gmail.com>
Message-ID: <8e5f599f81dd4754a8bf03707fe8331f@CRCOEXCH2.cornerstone.com>

I did use library(binom). However, I was able to use the method "lrt" which is short for likelihood ratio test. 
-----Original Message-----
From: Jim Lemon [mailto:drjimlemon at gmail.com] 
Sent: Thursday, September 13, 2018 11:50 PM
To: Guo, Fang (Associate) <FAGuo at cornerstone.com>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Question on Binom.Confint

Hi Fang,
Let's assume that you are using the "binom.confint" function in the "binom" package and you have made a spelling mistake or two. This function employs nine methods for estimating the binomial confidence interval. Sadly, none of these is "lrt". The zero condition is discussed in the help page for four of these methods. Assuming you want to use another method, you will have to look up the method. A good start is:

https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval

Jim

On Fri, Sep 14, 2018 at 11:38 AM Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
>
> Hi,
>
> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
>
>
> Fang Guo
> Associate
>
> CORNERSTONE RESEARCH
> 699 Boylston Street, 5th Floor
> Boston, MA 02116-2836
> 617.927.3042 direct
> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
>
> www.cornerstone.com<http://www.cornerstone.com/>
>
>
> ***********************************************************
> Warning: This email may contain confidential or privileged information 
> intended only for the use of the individual or entity to whom it is 
> addressed. If you are not the intended recipient, please understand 
> that any disclosure, copying, distribution, or use of the contents of 
> this email is strictly prohibited.
> ***********************************************************
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
***********************************************************
Warning: This email may contain confidential or privileged information
intended only for the use of the individual or entity to whom it is
addressed. If you are not the intended recipient, please understand 
that any disclosure, copying, distribution, or use of the contents 
of this email is strictly prohibited.
***********************************************************

From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Sep 14 17:44:56 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 14 Sep 2018 08:44:56 -0700
Subject: [R] Help with setting locale
In-Reply-To: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
References: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
Message-ID: <B5922BF1-1A5F-4748-A049-CFA87574FE65@comcast.net>


> On Sep 14, 2018, at 1:02 AM, Kim Titcombe <ktitcombe02 at gmail.com> wrote:
> 
> *Query or Set Aspects of the Locale*
> 
> I have an issue with setting LOCALE in installation (new  installation on
> new computer but have installed and used R before).
> 
> I am based in Switzerland but work in English (Windows in English), hence
> want English as default.
> 
> Console contains following message:
> 
> # During startup - Warning message:
> 
> # Setting LC_CTYPE= failed
> 
> -------------------------------------------------
> 
> Solutions I tried found on ?help? and in R manual as follows?.
> 
> # Sys.getlocale(category = ?LC_ALL?)
> 
> 1]
> "LC_COLLATE=English_Switzerland.65001;LC_CTYPE=C;LC_MONETARY=English_Switzerland.65001;LC_NUMERIC=C;LC_TIME=English_Switzerland.65001"
> 
> # Sys.setlocale(category=?LC_ALL?, locale = ? ?)
> 
> or
> 
> # Sys.setlocale(category=?LC_ALL?, local=?Switzerland.65001?)
> 
> Output
> 
> # OS reports request to set locale to "Switzerland.65001" cannot be honoured
> 
> Tried various commands specific for 'LC_CTYPE' (as this is where
> installation failed) for language string such as
> 
> # Sys.setlocale("LC_CTYPE","en-GB")

You may get better results with an underscore rather than a dash.

Try: 

Sys.setlocale("LC_CTYPE","en_GB")



On my machine you can get the acceptable locale strings with:

locales <- system("locale -a", intern = TRUE)
locales[ grep("GB",locales) ]  # Just the GB strings
[1] "en_GB"            "en_GB.ISO8859-1"  "en_GB.ISO8859-15" "en_GB.US-ASCII"   "en_GB.UTF-8"      "zh_CN.GB18030"    "zh_CN.GB2312"    
[8] "zh_CN.GBK"       



> 
> Output:
> 
> In Sys.setlocale("LC_CTYPE", "en-GB") :
> 
>  OS reports request to set locale to "en-GB" cannot be honoured
> 
> Would anyone have any further suggestions for correct command.
> 
> With thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Sep 14 17:51:19 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 14 Sep 2018 08:51:19 -0700
Subject: [R] Help with setting locale
In-Reply-To: <B5922BF1-1A5F-4748-A049-CFA87574FE65@comcast.net>
References: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
 <B5922BF1-1A5F-4748-A049-CFA87574FE65@comcast.net>
Message-ID: <402B2D9C-F4FD-42A1-88C0-81A001B9E4A4@comcast.net>


> On Sep 14, 2018, at 8:44 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Sep 14, 2018, at 1:02 AM, Kim Titcombe <ktitcombe02 at gmail.com> wrote:
>> 
>> *Query or Set Aspects of the Locale*
>> 
>> I have an issue with setting LOCALE in installation (new  installation on
>> new computer but have installed and used R before).
>> 
>> I am based in Switzerland but work in English (Windows in English), hence
>> want English as default.
>> 
>> Console contains following message:
>> 
>> # During startup - Warning message:
>> 
>> # Setting LC_CTYPE= failed
>> 
>> -------------------------------------------------
>> 
>> Solutions I tried found on ?help? and in R manual as follows?.
>> 
>> # Sys.getlocale(category = ?LC_ALL?)
>> 
>> 1]
>> "LC_COLLATE=English_Switzerland.65001;LC_CTYPE=C;LC_MONETARY=English_Switzerland.65001;LC_NUMERIC=C;LC_TIME=English_Switzerland.65001"
>> 
>> # Sys.setlocale(category=?LC_ALL?, locale = ? ?)
>> 
>> or
>> 
>> # Sys.setlocale(category=?LC_ALL?, local=?Switzerland.65001?)
>> 
>> Output
>> 
>> # OS reports request to set locale to "Switzerland.65001" cannot be honoured
>> 
>> Tried various commands specific for 'LC_CTYPE' (as this is where
>> installation failed) for language string such as
>> 
>> # Sys.setlocale("LC_CTYPE","en-GB")
> 
> You may get better results with an underscore rather than a dash.
> 
> Try: 
> 
> Sys.setlocale("LC_CTYPE","en_GB")
> 
> 
> 
> On my machine you can get the acceptable locale strings with:
> 
> locales <- system("locale -a", intern = TRUE)
> locales[ grep("GB",locales) ]  # Just the GB strings
> [1] "en_GB"            "en_GB.ISO8859-1"  "en_GB.ISO8859-15" "en_GB.US-ASCII"   "en_GB.UTF-8"      "zh_CN.GB18030"    "zh_CN.GB2312"    
> [8] "zh_CN.GBK"       

I should have admitted that I use a Mac. If you use Windoze, then consult the MS authorities for naming. Perhaps this page: https://docs.microsoft.com/en-us/windows/desktop/Intl/language-identifier-constants-and-strings , which suggests to me using 'UK' rather than 'GB' might be needed and 'ENGLISH' rather than 'en'.


> 
> 
> 
>> 
>> Output:
>> 
>> In Sys.setlocale("LC_CTYPE", "en-GB") :
>> 
>> OS reports request to set locale to "en-GB" cannot be honoured
>> 
>> Would anyone have any further suggestions for correct command.
>> 
>> With thanks
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From gor@n@bro@trom @end|ng |rom umu@@e  Fri Sep 14 17:52:49 2018
From: gor@n@bro@trom @end|ng |rom umu@@e (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Fri, 14 Sep 2018 17:52:49 +0200
Subject: [R] Question on Binom.Confint
In-Reply-To: <8e5f599f81dd4754a8bf03707fe8331f@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <CA+8X3fUbws98+JWq5YOeEbTVjO-00TN7UKcdccMxHAzxi8H=fw@mail.gmail.com>
 <8e5f599f81dd4754a8bf03707fe8331f@CRCOEXCH2.cornerstone.com>
Message-ID: <d92a8aba-0035-55ba-89b0-f78de3c15de6@umu.se>



On 2018-09-14 17:04, Guo, Fang (Associate) wrote:
> I did use library(binom). However, I was able to use the method "lrt" which is short for likelihood ratio test.

You are right, there is a method "lrt", but it is not mentioned in the 
documentation. (Look at the code.)

G?ran

> -----Original Message-----
> From: Jim Lemon [mailto:drjimlemon at gmail.com]
> Sent: Thursday, September 13, 2018 11:50 PM
> To: Guo, Fang (Associate) <FAGuo at cornerstone.com>; r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Question on Binom.Confint
> 
> Hi Fang,
> Let's assume that you are using the "binom.confint" function in the "binom" package and you have made a spelling mistake or two. This function employs nine methods for estimating the binomial confidence interval. Sadly, none of these is "lrt". The zero condition is discussed in the help page for four of these methods. Assuming you want to use another method, you will have to look up the method. A good start is:
> 
> https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval
> 
> Jim
> 
> On Fri, Sep 14, 2018 at 11:38 AM Guo, Fang (Associate) <FAGuo at cornerstone.com> wrote:
>>
>> Hi,
>>
>> I have a question with the function Binom.Confint(x,n,"method"=lrt). For likelihood ratio test, I'd like to ask how you define the upper limit when the frequency of successes is zero. Thanks!
>>
>>
>> Fang Guo
>> Associate
>>
>> CORNERSTONE RESEARCH
>> 699 Boylston Street, 5th Floor
>> Boston, MA 02116-2836
>> 617.927.3042 direct
>> faguo at cornerstone.com<mailto:faguo at cornerstone.com>
>>
>> www.cornerstone.com<http://www.cornerstone.com/>
>>
>>
>> ***********************************************************
>> Warning: This email may contain confidential or privileged information
>> intended only for the use of the individual or entity to whom it is
>> addressed. If you are not the intended recipient, please understand
>> that any disclosure, copying, distribution, or use of the contents of
>> this email is strictly prohibited.
>> ***********************************************************
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand
> that any disclosure, copying, distribution, or use of the contents
> of this email is strictly prohibited.
> ***********************************************************
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From kt|tcombe02 @end|ng |rom gm@||@com  Fri Sep 14 18:01:30 2018
From: kt|tcombe02 @end|ng |rom gm@||@com (Kim Titcombe)
Date: Fri, 14 Sep 2018 18:01:30 +0200
Subject: [R] Help with setting locale
In-Reply-To: <402B2D9C-F4FD-42A1-88C0-81A001B9E4A4@comcast.net>
References: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
 <B5922BF1-1A5F-4748-A049-CFA87574FE65@comcast.net>
 <402B2D9C-F4FD-42A1-88C0-81A001B9E4A4@comcast.net>
Message-ID: <CAE9q8v=Hjx8e9NWjxrscHXci6S2eSTWnxy1e8HdRxmYtyNge0Q@mail.gmail.com>

Thanks for the tip!
Kim

On Fri, 14 Sep 2018, 17:51 David Winsemius, <dwinsemius at comcast.net> wrote:

>
> > On Sep 14, 2018, at 8:44 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >
> >> On Sep 14, 2018, at 1:02 AM, Kim Titcombe <ktitcombe02 at gmail.com>
> wrote:
> >>
> >> *Query or Set Aspects of the Locale*
> >>
> >> I have an issue with setting LOCALE in installation (new  installation
> on
> >> new computer but have installed and used R before).
> >>
> >> I am based in Switzerland but work in English (Windows in English),
> hence
> >> want English as default.
> >>
> >> Console contains following message:
> >>
> >> # During startup - Warning message:
> >>
> >> # Setting LC_CTYPE= failed
> >>
> >> -------------------------------------------------
> >>
> >> Solutions I tried found on ?help? and in R manual as follows?.
> >>
> >> # Sys.getlocale(category = ?LC_ALL?)
> >>
> >> 1]
> >>
> "LC_COLLATE=English_Switzerland.65001;LC_CTYPE=C;LC_MONETARY=English_Switzerland.65001;LC_NUMERIC=C;LC_TIME=English_Switzerland.65001"
> >>
> >> # Sys.setlocale(category=?LC_ALL?, locale = ? ?)
> >>
> >> or
> >>
> >> # Sys.setlocale(category=?LC_ALL?, local=?Switzerland.65001?)
> >>
> >> Output
> >>
> >> # OS reports request to set locale to "Switzerland.65001" cannot be
> honoured
> >>
> >> Tried various commands specific for 'LC_CTYPE' (as this is where
> >> installation failed) for language string such as
> >>
> >> # Sys.setlocale("LC_CTYPE","en-GB")
> >
> > You may get better results with an underscore rather than a dash.
> >
> > Try:
> >
> > Sys.setlocale("LC_CTYPE","en_GB")
> >
> >
> >
> > On my machine you can get the acceptable locale strings with:
> >
> > locales <- system("locale -a", intern = TRUE)
> > locales[ grep("GB",locales) ]  # Just the GB strings
> > [1] "en_GB"            "en_GB.ISO8859-1"  "en_GB.ISO8859-15"
> "en_GB.US-ASCII"   "en_GB.UTF-8"      "zh_CN.GB18030"    "zh_CN.GB2312"
> > [8] "zh_CN.GBK"
>
> I should have admitted that I use a Mac. If you use Windoze, then consult
> the MS authorities for naming. Perhaps this page:
> https://docs.microsoft.com/en-us/windows/desktop/Intl/language-identifier-constants-and-strings
> , which suggests to me using 'UK' rather than 'GB' might be needed and
> 'ENGLISH' rather than 'en'.
>
>
> >
> >
> >
> >>
> >> Output:
> >>
> >> In Sys.setlocale("LC_CTYPE", "en-GB") :
> >>
> >> OS reports request to set locale to "en-GB" cannot be honoured
> >>
> >> Would anyone have any further suggestions for correct command.
> >>
> >> With thanks
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]



From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Fri Sep 14 18:34:04 2018
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Fri, 14 Sep 2018 11:34:04 -0500
Subject: [R] [FORGED] Question on Binom.Confint
In-Reply-To: <d8ee54b0b44d43e6915750bef37ef2bc@CRCOEXCH2.cornerstone.com>
References: <3146e6e2bb114736ab54b1af2d0ccfc9@CRCOEXCH2.cornerstone.com>
 <b1545005-4871-177d-ac0d-6aed93a5a3f8@auckland.ac.nz>
 <d8ee54b0b44d43e6915750bef37ef2bc@CRCOEXCH2.cornerstone.com>
Message-ID: <999f81bd-2066-7b1b-04d7-c986eae7b83a@effectivedefense.org>



On 2018-09-14 08:52, Guo, Fang (Associate) wrote:
> It's method="lrt" and I used the "binom" package.


 ????? The ultimate answer can be obtained as follows:


 > debug(binom.confint)
 > binom.confint(x = 0, n = 100, tol = 1e-8, method='lrt')


 ????? Then walk through the code line by line.


 ????? Reading the code, I find the following:


 ? if (any(method == "lrt") || all.methods) {
 ??????? res.lrt <- binom.lrt(x, n, conf.level = conf.level, ...)
 ??????? res <- if (is.null(res))
 ??????????? res.lrt
 ??????? else rbind(res, res.lrt)
 ??? }


 ????? Then check the help page for "binom.lrt".? That includes the 
following:


Confidence intervals are based on profiling the binomial deviance in the 
neighbourhood of the MLE. If x == 0 or x == n and bayes is TRUE, then a 
Bayesian adjustment is made to move the log-likelihood function away 
from Inf. Specifically, these values are replaced by (x + 0.5)/(n + 1), 
which is the posterier mode of f(p|x) using Jeffrey's prior on p. 
Furthermore, if conf.adj is TRUE, then the upper (or lower) bound uses a 
1 - alpha confidence level. Typically, the observed mean will not be 
inside the estimated confidence interval. If bayes is FALSE, then the 
Clopper-Pearson exact method is used on the endpoints. This tends to 
make confidence intervals at the end too conservative, though the 
observed mean is guaranteed to be within the estimated confidence limits.


 ????? Spencer
>
> -----Original Message-----
> From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
> Sent: Thursday, September 13, 2018 10:02 PM
> To: Guo, Fang (Associate) <FAGuo at cornerstone.com>
> Cc: r-help at R-project.org
> Subject: Re: [FORGED] [R] Question on Binom.Confint
>
>
> On 09/14/2018 08:15 AM, Guo, Fang (Associate) wrote:
>
>> Hi,
>>
>> I have a question with the function Binom.Confint(x,n,"method"=lrt).
>> For likelihood ratio test, I'd like to ask how you define the upper
>> limit when the frequency of successes is zero. Thanks!
> Point 1:  This question is inappropriate for this list, since it is about statistical theory and not about R syntax and programming.
>
> Point 2: Where did you find the function Binom.Confint()?  I can find no such function anywhere.  I did manage to locate a function
> binom.confint() (note the lower case "b" and "c") but it does not have an argument "method".  Please do not expect those whom you are addressing to be telepathic.
>
> Point 3:  Having "method"=lrt in the call is decidedly weird.  Perhaps you meant method="lrt"; this is entirely different.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> ***********************************************************
> Warning: This email may contain confidential or privileged information
> intended only for the use of the individual or entity to whom it is
> addressed. If you are not the intended recipient, please understand
> that any disclosure, copying, distribution, or use of the contents
> of this email is strictly prohibited.
> ***********************************************************
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@k@hho||y @end|ng |rom gm@||@com  Fri Sep 14 19:13:02 2018
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Fri, 14 Sep 2018 12:13:02 -0500
Subject: [R] label and font problems in Vennerable
Message-ID: <CAM9Qe4jbR7JZBOHjgke19tWoz-kytysZScHrnV2dqjHt80jtWw@mail.gmail.com>

Hi everyone;

I am running Vennerable with 7 sets of variables. The labels are not very
clear and the font size is not very visible. Does anyone know how I can
change the label colors and font sizes?

Regards,

Greg

	[[alternative HTML version deleted]]



From out|ook_5DC74CB3034CB0A2 @end|ng |rom out|ook@com  Fri Sep 14 20:00:05 2018
From: out|ook_5DC74CB3034CB0A2 @end|ng |rom out|ook@com (Jim Blackburn)
Date: Fri, 14 Sep 2018 18:00:05 +0000
Subject: [R] New to R
Message-ID: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>

I am newly subscribed to r-project.


I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)



I am attempting to download tickers as a time series.  I can successfully create RDA files but I want to convert them to CVS.  Following is the code I have created so far.



if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')

library(BatchGetSymbols)

tickers <- c('SPY','VCR', 'RPG')

first.date <- Sys.Date()-365

last.date <- Sys.Date

l.out <- BatchGetSymbols(tickers = tickers,

       first.date = first.date,

       last.date = last.date,

cache.folder = file.path("c://Users/Owner/Documents/R",

+    'BGS_Cache') )

print(l.out$df.control)

print(l.out$df.tickers)







I can print(l.out) and see that it contains all the data, but it is not a data.frame



Can anyone help with creating a data.frame and then converting to CSV?



Any help is GREATLY appreciated!



Thanks



Jim


Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


	[[alternative HTML version deleted]]



From @|m|n@@t@work @end|ng |rom gm@||@com  Fri Sep 14 23:03:53 2018
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Fri, 14 Sep 2018 17:03:53 -0400
Subject: [R] Change the position of label when using R package eulerr
In-Reply-To: <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
Message-ID: <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>

Thank you,

I figure out a way like this:

fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
"LAD&nonXL_MEF" = 541,
                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")

plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
= 1),alpha=0.7)

grid.ls()
t <- grid.get("quantities.grob")
names(t)

# Change these value will change the location of label.

grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
                                         unit(-14.883684319653, "native"),
                                         unit(13.9805892820006, "native"),
                                         unit(-12.8808987356981, "native"),
                                         unit(-11.488226371243, "native"),
                                         unit(-9.51474016085318, "native"),
                                         unit(-1.00436055190216, "native")))

grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
                                         unit(4.78718651828883, "native"),
                                         unit(0.25941593099694, "native"),
                                         unit(-4.32200781461293, "native"),
                                         unit(25.7349463488991, "native"),
                                         unit(-22.7610031110325, "native"),
                                         unit(14.5001560838519, "native")))

However, here I just want to change the x and y  value of 4th label, does
anyone know how to set it?

Aimin

On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> >
> > I am using eulerr to get venn.
> > My code is like:
> >
> > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> > "LAD&nonXL_MEF" = 541,
> >                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> >
> > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
> list(font
> > = 1),alpha=0.7)
> >
> > After I get the figure, I find the position of some  labels need to be
> > adjusted.
> >
> > Does anyone has some idea about how to process this?
>
> Looking at the code of plot.euler we see that the plotting paradigm is
> grid. So you could assign the output to a data.object name, search for list
> items that match the names of the labels you want to reposition, and modify
> the position values. You would need to be more specific, if you want a
> worked example.
>
> As far as I can see the lables and postions are fairly deep inside a list
> structure:
>
>  $ children     :List of 1
>   ..$ GRID.gTree.12:List of 5
>   .. ..$ children
>          $ diagram.grob.1
>             $children
> .. .. .. .. ..$ labels.grob    :List of 11
>   .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
>   .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native
> 69.2native 11.9native
>   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
>   .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native
> 5.24native 27.86native
>   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
>
> --
> David.
> >
> >
> > Thank you,
> >
> > Aimin
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 14 23:08:09 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 14 Sep 2018 14:08:09 -0700
Subject: [R] New to R
In-Reply-To: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
References: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
Message-ID: <CAGxFJbQx_vKKqj0PooGf86P54yjmchF9pjx3C_ViZireKDQ3ZQ@mail.gmail.com>

Others may help, but I suggest first going through an R tutorial or
two to learn about R's basic data structures, i/o, etc. This list can
help, but cannot substitute for such homework. Some tutorial
recommendations can be found here:
https://www.rstudio.com/online-learning/#r-programming

There are many more, of course.

See also:
?read.table (etc. in the Help page)
?write.table

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Fri, Sep 14, 2018 at 1:56 PM Jim Blackburn
<outlook_5DC74CB3034CB0A2 at outlook.com> wrote:
>
> I am newly subscribed to r-project.
>
>
> I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)
>
>
>
> I am attempting to download tickers as a time series.  I can successfully create RDA files but I want to convert them to CVS.  Following is the code I have created so far.
>
>
>
> if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')
>
> library(BatchGetSymbols)
>
> tickers <- c('SPY','VCR', 'RPG')
>
> first.date <- Sys.Date()-365
>
> last.date <- Sys.Date
>
> l.out <- BatchGetSymbols(tickers = tickers,
>
>        first.date = first.date,
>
>        last.date = last.date,
>
> cache.folder = file.path("c://Users/Owner/Documents/R",
>
> +    'BGS_Cache') )
>
> print(l.out$df.control)
>
> print(l.out$df.tickers)
>
>
>
>
>
>
>
> I can print(l.out) and see that it contains all the data, but it is not a data.frame
>
>
>
> Can anyone help with creating a data.frame and then converting to CSV?
>
>
>
> Any help is GREATLY appreciated!
>
>
>
> Thanks
>
>
>
> Jim
>
>
> Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Sep 14 23:15:50 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 14 Sep 2018 21:15:50 +0000
Subject: [R] New to R
Message-ID: <D9BFDB97-7AFD-41AC-81AC-3AA3EA7ED26C@llnl.gov>

If l.out is not a data frame, what is it? A list? A matrix? Some other structure? Try

  str(l.out)
  class(l.out)

and see what you get.

Can't help you convert it to a data frame without knowing what it is.

After you have a data frame, then write.table(), write.csv(), or write.csv2() will "convert" it to a CSV (assuming that's what you meant by "CVS".

-Don

p.s. use reply-all if you want to add that extra information .

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/14/18, 11:00 AM, "R-help on behalf of Jim Blackburn" <r-help-bounces at r-project.org on behalf of outlook_5DC74CB3034CB0A2 at outlook.com> wrote:

    I am newly subscribed to r-project.
    
    
    I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)
    
    
    
    I am attempting to download tickers as a time series.  I can successfully create RDA files but I want to convert them to CVS.  Following is the code I have created so far.
    
    
    
    if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')
    
    library(BatchGetSymbols)
    
    tickers <- c('SPY','VCR', 'RPG')
    
    first.date <- Sys.Date()-365
    
    last.date <- Sys.Date
    
    l.out <- BatchGetSymbols(tickers = tickers,
    
           first.date = first.date,
    
           last.date = last.date,
    
    cache.folder = file.path("c://Users/Owner/Documents/R",
    
    +    'BGS_Cache') )
    
    print(l.out$df.control)
    
    print(l.out$df.tickers)
    
    
    
    
    
    
    
    I can print(l.out) and see that it contains all the data, but it is not a data.frame
    
    
    
    Can anyone help with creating a data.frame and then converting to CSV?
    
    
    
    Any help is GREATLY appreciated!
    
    
    
    Thanks
    
    
    
    Jim
    
    
    Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10
    
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From j|ox @end|ng |rom mcm@@ter@c@  Fri Sep 14 23:46:09 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 14 Sep 2018 21:46:09 +0000
Subject: [R] Problem with lm.resid() when weights are provided
In-Reply-To: <CAAC89xexc0tHnC8n_n0Z+=3xtPDFmB394=U75V3KLe9RQ6OWdA@mail.gmail.com>
References: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
 <22333_1536669565_w8BCdOUV005487_CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368B0E61@FHSDB2D11-2.csu.mcmaster.ca>
 <CAAC89xexc0tHnC8n_n0Z+=3xtPDFmB394=U75V3KLe9RQ6OWdA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368B12FB@FHSDB2D11-2.csu.mcmaster.ca>

Dear Hamed,

When you post a question to r-help, generally you should cc subsequent messages there as well, as I've done to this response.

The algorithm that lm() uses is much more numerically stable than inverting the weighted sum-of-squares-and-product matrix. If you want to see how the computations are done, look at lm.wfit(), in which the residuals and fits are computed as 

    z$residuals <- z$residuals/wts
    z$fitted.values <- y - z$residuals

Zero weights are handled specially, and your tiny weights are thus the source of the problem. When you divide by a number less than the machine double-epsilon, you can't expect numerically stable results. I suppose that lm.wfit() could check for 0 weights to a tolerance rather than exactly.

John

> -----Original Message-----
> From: Hamed Ha [mailto:hamedhaseli at gmail.com]
> Sent: Friday, September 14, 2018 5:34 PM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: Re: [R] Problem with lm.resid() when weights are provided
> 
> Hi John,
> 
> Thank you for your reply.
> 
> I agree that the small weights are the potential source of the instability in the
> result. I also suspected that there are some failure/bugs in the actual
> algorithm that R uses for fitting the model. I remember that at some points I
> checked the theoretical estimation of the parameters, solve(t(x) %*% w %*%
> x) %*% t(x) %*% w %*% y, (besides the point that I had to set tol parameter in
> solve() to a super small value) and realised  that lm() and the theoretical
> results match together. That is the parameter estimation is right in R.
> Moreover, I checked the predictions, predict(lm.fit), and it was right. Then the
> only source of error remained was resid() function. I further checked this
> function and it is nothing more than calling a sub-element from and lm() fit.
> Putting all together, I think that there is something wrong/bug/miss-
> configuration in the lm() algorithm and I highly recommend the R core team to
> fix that.
> 
> Please feel free to contact me for more details if required.
> 
> Warm regards,
> Hamed.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On Fri, 14 Sep 2018 at 13:35, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Hamed,
> 
> 	I don't think that anyone has picked up on this problem.
> 
> 	What's peculiar about your weights is that several are 0 within
> rounding error but not exactly 0:
> 
> 	> head(df)
> 	           y          x       weight
> 	1  1.5115614  0.5520924 2.117337e-34
> 	2 -0.6365313 -0.1259932 2.117337e-34
> 	3  0.3778278  0.4209538 4.934135e-31
> 	4  3.0379232  1.4031545 2.679495e-24
> 	5  1.5364652  0.4607686 2.679495e-24
> 	6 -2.3772787 -0.7396358 6.244160e-21
> 
> 	I can reproduce the results that you report:
> 
> 	> (mod.1 <- lm(y ~ x, data=df))
> 
> 	Call:
> 	lm(formula = y ~ x, data = df)
> 
> 	Coefficients:
> 	(Intercept)            x
> 	   -0.04173      2.03790
> 
> 	> max(resid(mod.1))
> 	[1] 1.14046
> 	> (mod.2 <- lm(y ~ x, data=df, weights=weight))
> 
> 	Call:
> 	lm(formula = y ~ x, data = df, weights = weight)
> 
> 	Coefficients:
> 	(Intercept)            x
> 	   -0.05786      1.96087
> 
> 	> max(resid(mod.2))
> 	[1] 36.84939
> 
> 	But the problem disappears when the tiny nonzero weight are set to 0:
> 
> 	> df2 <- df
> 	> df2$weight <- zapsmall(df2$weight)
> 	> head(df2)
> 	           y          x weight
> 	1  1.5115614  0.5520924      0
> 	2 -0.6365313 -0.1259932      0
> 	3  0.3778278  0.4209538      0
> 	4  3.0379232  1.4031545      0
> 	5  1.5364652  0.4607686      0
> 	6 -2.3772787 -0.7396358      0
> 	> (mod.3 <- update(mod.2, data=df2))
> 
> 	Call:
> 	lm(formula = y ~ x, data = df2, weights = weight)
> 
> 	Coefficients:
> 	(Intercept)            x
> 	   -0.05786      1.96087
> 
> 	> max(resid(mod.3))
> 	[1] 1.146663
> 
> 	I don't know exactly why this happens, but suspect numerical
> instability produced by the near-zero weights, which are smaller than the
> machine double-epsilon
> 
> 	> .Machine$double.neg.eps
> 	[1] 1.110223e-16
> 
> 	The problem also disappears, e.g., if the tiny weight are set to 1e-15
> rather than 0.
> 
> 	I hope this helps,
> 	 John
> 
> 	-----------------------------------------------------------------
> 	John Fox
> 	Professor Emeritus
> 	McMaster University
> 	Hamilton, Ontario, Canada
> 	Web: https://socialsciences.mcmaster.ca/jfox/
> 
> 
> 
> 	> -----Original Message-----
> 	> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org> ] On Behalf Of Hamed Ha
> 	> Sent: Tuesday, September 11, 2018 8:39 AM
> 	> To: r-help at r-project.org <mailto:r-help at r-project.org>
> 	> Subject: [R] Problem with lm.resid() when weights are provided
> 	>
> 	> Dear R Help Team.
> 	>
> 	> I get some weird results when I use the lm function with weight. The
> issue can
> 	> be reproduced by the example below:
> 	>
> 	>
> 	> The input data is (weights are intentionally designed to reflect some
> 	> structures in the data)
> 	>
> 	>
> 	> > df
> 	> y x weight
> 	>  1.51156139  0.55209240 2.117337e-34
> 	> -0.63653132 -0.12599316 2.117337e-34
> 	>  0.37782776  0.42095384 4.934135e-31
> 	>  3.03792318  1.40315446 2.679495e-24
> 	>  1.53646523  0.46076858 2.679495e-24
> 	> -2.37727874 -0.73963576 6.244160e-21
> 	>  0.37183065  0.20407468 1.455107e-17
> 	> -1.53917553 -0.95519361 1.455107e-17
> 	>  1.10926675  0.03897129 3.390908e-14
> 	> -0.37786333 -0.17523593 3.390908e-14
> 	>  2.43973603  0.97970095 7.902000e-11
> 	> -0.35432394 -0.03742559 7.902000e-11
> 	>  2.19296613  1.00355263 4.289362e-04
> 	>  0.49845532  0.34816207 4.289362e-04
> 	>  1.25005260  0.76306225 5.000000e-01
> 	>  0.84360691  0.45152356 5.000000e-01
> 	>  0.29565993  0.53880068 5.000000e-01
> 	> -0.54081334 -0.28104525 5.000000e-01
> 	>  0.83612836 -0.12885659 9.995711e-01
> 	> -1.42526769 -0.87107631 9.999998e-01
> 	>  0.10204789 -0.11649899 1.000000e+00
> 	>  1.14292898  0.37249631 1.000000e+00
> 	> -3.02942081 -1.28966997 1.000000e+00
> 	> -1.37549764 -0.74676145 1.000000e+00
> 	> -2.00118016 -0.55182759 1.000000e+00
> 	> -4.24441674 -1.94603608 1.000000e+00
> 	>  1.17168144  1.00868008 1.000000e+00
> 	>  2.64007761  1.26333069 1.000000e+00
> 	>  1.98550114  1.18509599 1.000000e+00
> 	> -0.58941683 -0.61972416 9.999998e-01
> 	> -4.57559611 -2.30914920 9.995711e-01
> 	> -0.82610544 -0.39347576 9.995711e-01
> 	> -0.02768220  0.20076910 9.995711e-01
> 	>  0.78186399  0.25690215 9.995711e-01
> 	> -0.88314153 -0.20200148 5.000000e-01
> 	> -4.17076452 -2.03547588 5.000000e-01
> 	>  0.93373070  0.54190626 4.289362e-04
> 	> -0.08517734  0.17692491 4.289362e-04
> 	> -4.47546619 -2.14876688 4.289362e-04
> 	> -1.65509103 -0.76898087 4.289362e-04
> 	> -0.39403030 -0.12689705 4.289362e-04
> 	>  0.01203300 -0.18689898 1.841442e-07
> 	> -4.82762639 -2.31391121 1.841442e-07
> 	> -0.72658380 -0.39751171 3.397282e-14
> 	> -2.35886866 -1.01082109 0.000000e+00
> 	> -2.03762707 -0.96439902 0.000000e+00
> 	>  0.90115123  0.60172286 0.000000e+00
> 	>  1.55999194  0.83433953 0.000000e+00
> 	>  3.07994058  1.30942776 0.000000e+00
> 	>  1.78871462  1.10605530 0.000000e+00
> 	>
> 	>
> 	>
> 	> Running simple linear model returns:
> 	>
> 	> > lm(y~x,data=df)
> 	>
> 	> Call:
> 	> lm(formula = y ~ x, data = df)
> 	>
> 	> Coefficients:
> 	> (Intercept)            x
> 	>    -0.04173      2.03790
> 	>
> 	> and
> 	> > max(resid(lm(y~x,data=df)))
> 	> [1] 1.14046
> 	>
> 	>
> 	> *HOWEVER if I use the weighted model then:*
> 	>
> 	> lm(formula = y ~ x, data = df, weights = df$weights)
> 	>
> 	> Coefficients:
> 	> (Intercept)            x
> 	>    -0.05786      1.96087
> 	>
> 	> and
> 	> > max(resid(lm(y~x,data=df,weights=df$weights)))
> 	> [1] 60.91888
> 	>
> 	>
> 	> as you see, the estimation of the coefficients are nearly the same
> but the
> 	> resid() function returns a giant residual (I have some cases where
> the value is
> 	> much much higher). Further, if I calculate the residuals by simply
> 	> predict(lm(y~x,data=df,weights=df$weights))-df$y then I get the true
> value for
> 	> the residuals.
> 	>
> 	>
> 	> Thanks.
> 	>
> 	> Please do not hesitate to contact me for more details.
> 	> Regards,
> 	> Hamed.
> 	>
> 	>       [[alternative HTML version deleted]]
> 	>
> 	> ______________________________________________
> 	> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list --
> To UNSUBSCRIBE and more, see
> 	> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> PLEASE do read the posting guide http://www.R-project.org/posting-
> 	> guide.html
> 	> and provide commented, minimal, self-contained, reproducible
> code.
> 


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Sep 15 00:18:02 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 14 Sep 2018 15:18:02 -0700
Subject: [R] New to R
In-Reply-To: <D9BFDB97-7AFD-41AC-81AC-3AA3EA7ED26C@llnl.gov>
References: <D9BFDB97-7AFD-41AC-81AC-3AA3EA7ED26C@llnl.gov>
Message-ID: <1387982A-D691-4DD2-BFE9-849A6FBF1DD1@comcast.net>


> On Sep 14, 2018, at 2:15 PM, MacQueen, Don via R-help <r-help at r-project.org> wrote:
> 
> If l.out is not a data frame, what is it? A list? A matrix? Some other structure? Try

I thought it would be one of those variants of a zoo object. Matrix structure with specialized row.names that can handle time-date range operators.

Bert's advice to learn some basic R certainly makes sense. After fixing the two errors in the code and substituting a proper path I get:

str(l.out)
List of 2
 $ df.control:'data.frame':	3 obs. of  6 variables:
  ..$ ticker              : Factor w/ 3 levels "SPY","VCR","RPG": 1 2 3
  ..$ src                 : Factor w/ 1 level "yahoo": 1 1 1
  ..$ download.status     : Factor w/ 1 level "OK": 1 1 1
  ..$ total.obs           : int [1:3] 252 252 252
  ..$ perc.benchmark.dates: num [1:3] 1 1 1
  ..$ threshold.decision  : Factor w/ 1 level "KEEP": 1 1 1
 $ df.tickers:'data.frame':	756 obs. of  10 variables:
  ..$ price.open         : num [1:756] 250 249 250 250 250 ...
  ..$ price.high         : num [1:756] 250 249 250 250 250 ...
  ..$ price.low          : num [1:756] 250 249 249 250 249 ...
  ..$ price.close        : num [1:756] 250 249 250 250 250 ...
  ..$ volume             : num [1:756] 95446300 95432400 46235200 47108100 59574100 ...
  ..$ price.adjusted     : num [1:756] 245 246 246 247 247 ...
  ..$ ref.date           : Date[1:756], format: "2017-09-14" "2017-09-15" "2017-09-18" "2017-09-19" ...
  ..$ ticker             : chr [1:756] "SPY" "SPY" "SPY" "SPY" ...
  ..$ ret.adjusted.prices: num [1:756] NA 0.00135 0.00213 0.001 0.00036 ...
  ..$ ret.closing.prices : num [1:756] NA -0.0036 0.00213 0.001 0.00036 ...


So the data.frame would be:  l.out$df.tickers


It's got the data in a long-format arrangement:

table( l.out$df.tickers$ticker)

RPG SPY VCR 
252 252 252 
-- 
David.
> 
>  str(l.out)
>  class(l.out)
> 
> and see what you get.
> 
> Can't help you convert it to a data frame without knowing what it is.
> 
> After you have a data frame, then write.table(), write.csv(), or write.csv2() will "convert" it to a CSV (assuming that's what you meant by "CVS".
> 
> -Don
> 
> p.s. use reply-all if you want to add that extra information .
> 
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
> 
> 
> 
> ?On 9/14/18, 11:00 AM, "R-help on behalf of Jim Blackburn" <r-help-bounces at r-project.org on behalf of outlook_5DC74CB3034CB0A2 at outlook.com> wrote:
> 
>    I am newly subscribed to r-project.
> 
> 
>    I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)
> 
> 
> 
>    I am attempting to download tickers as a time series.  I can successfully create RDA files but I want to convert them to CVS.  Following is the code I have created so far.
> 
> 
> 
>    if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')
> 
>    library(BatchGetSymbols)
> 
>    tickers <- c('SPY','VCR', 'RPG')
> 
>    first.date <- Sys.Date()-365
> 
>    last.date <- Sys.Date
> 
>    l.out <- BatchGetSymbols(tickers = tickers,
> 
>           first.date = first.date,
> 
>           last.date = last.date,
> 
>    cache.folder = file.path("c://Users/Owner/Documents/R",
> 
>    +    'BGS_Cache') )
> 
>    print(l.out$df.control)
> 
>    print(l.out$df.tickers)
> 
> 
> 
> 
> 
> 
> 
>    I can print(l.out) and see that it contains all the data, but it is not a data.frame
> 
> 
> 
>    Can anyone help with creating a data.frame and then converting to CSV?
> 
> 
> 
>    Any help is GREATLY appreciated!
> 
> 
> 
>    Thanks
> 
> 
> 
>    Jim
> 
> 
>    Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10
> 
> 
>    	[[alternative HTML version deleted]]
> 
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Sep 15 00:46:59 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 14 Sep 2018 15:46:59 -0700
Subject: [R] Change the position of label when using R package eulerr
In-Reply-To: <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
 <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
Message-ID: <72EA8C05-D7CB-4949-B483-98EDBDB40934@comcast.net>


> On Sep 14, 2018, at 2:03 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> 
> Thank you,
> 
> I figure out a way like this:
> 
> fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
>                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101, "LAD&nonXL_MEF" = 541,
>                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
>     
> plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font = 1),alpha=0.7)
>    
> grid.ls()
> t <- grid.get("quantities.grob")
> names(t)
> 
> # Change these value will change the location of label.
>  
> grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
>                                          unit(-14.883684319653, "native"),
>                                          unit(13.9805892820006, "native"),
>                                          unit(-12.8808987356981, "native"),
>                                          unit(-11.488226371243, "native"),
>                                          unit(-9.51474016085318, "native"),
>                                          unit(-1.00436055190216, "native")))
>                 
> grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
>                                          unit(4.78718651828883, "native"),
>                                          unit(0.25941593099694, "native"),
>                                          unit(-4.32200781461293, "native"),
>                                          unit(25.7349463488991, "native"),
>                                          unit(-22.7610031110325, "native"),
>                                          unit(14.5001560838519, "native")))
> 
> However, here I just want to change the x and y  value of 4th label, does anyone know how to set it?

If the t object were a complete grid object, it might have been:

grid.edit("quantities.grob", x[[4]]= unit(-12.8808987356981, "native")
           )               
grid.edit("quantities.grob", y[[4]]= unit(-4.32200781461293, "native"),
           )


But I don't think that will succeed since you never assigned the value of the plot operation to a name. Instead you pulled out part of the grid object that was sitting "free" and unassigned to a name. If you assign that value of plot(....) to `my.plot` you get:

 grid.ls(my.plot)
euler.diagram
  GRID.gTree.11
    diagram.grob.1
      fills.grob.1
      fills.grob.2
      fills.grob.3
      fills.grob.4
      fills.grob.5
      fills.grob.6
      fills.grob.7
      edges.grob
      labels.grob
      quantities.grob

I think you need to work with the tutorials in the grid package.

Look at:

help("grid-package")

-- 
David.

> 
> Aimin
> 
> On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> > 
> > I am using eulerr to get venn.
> > My code is like:
> > 
> > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> > "LAD&nonXL_MEF" = 541,
> >                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> > 
> > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
> > = 1),alpha=0.7)
> > 
> > After I get the figure, I find the position of some  labels need to be
> > adjusted.
> > 
> > Does anyone has some idea about how to process this?
> 
> Looking at the code of plot.euler we see that the plotting paradigm is grid. So you could assign the output to a data.object name, search for list items that match the names of the labels you want to reposition, and modify the position values. You would need to be more specific, if you want a worked example.
> 
> As far as I can see the lables and postions are fairly deep inside a list structure:
> 
>  $ children     :List of 1
>   ..$ GRID.gTree.12:List of 5
>   .. ..$ children
>          $ diagram.grob.1     
>             $children
> .. .. .. .. ..$ labels.grob    :List of 11
>   .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
>   .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native 69.2native 11.9native
>   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
>   .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native 5.24native 27.86native
>   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> 
> -- 
> David.
> > 
> > 
> > Thank you,
> > 
> > Aimin
> > 
> >       [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From ||@t@ @end|ng |rom dewey@myzen@co@uk  Sat Sep 15 14:23:52 2018
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Sat, 15 Sep 2018 13:23:52 +0100
Subject: [R] New to R
In-Reply-To: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
References: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
Message-ID: <0fdeabf7-dcc3-575a-a0a6-ee5de67b00e0@dewey.myzen.co.uk>

Dear Jim

Without knowing what l.out is this might be tricky. What does str(l.out) 
tell you it is. And is CVS a typo for csv?

Michael

On 14/09/2018 19:00, Jim Blackburn wrote:
> I am newly subscribed to r-project.
> 
> 
> I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)
> 
> 
> 
> I am attempting to download tickers as a time series.  I can successfully create RDA files but I want to convert them to CVS.  Following is the code I have created so far.
> 
> 
> 
> if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')
> 
> library(BatchGetSymbols)
> 
> tickers <- c('SPY','VCR', 'RPG')
> 
> first.date <- Sys.Date()-365
> 
> last.date <- Sys.Date
> 
> l.out <- BatchGetSymbols(tickers = tickers,
> 
>         first.date = first.date,
> 
>         last.date = last.date,
> 
> cache.folder = file.path("c://Users/Owner/Documents/R",
> 
> +    'BGS_Cache') )
> 
> print(l.out$df.control)
> 
> print(l.out$df.tickers)
> 
> 
> 
> 
> 
> 
> 
> I can print(l.out) and see that it contains all the data, but it is not a data.frame
> 
> 
> 
> Can anyone help with creating a data.frame and then converting to CSV?
> 
> 
> 
> Any help is GREATLY appreciated!
> 
> 
> 
> Thanks
> 
> 
> 
> Jim
> 
> 
> Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html



From hwborcher@ @end|ng |rom gm@||@com  Sat Sep 15 21:38:22 2018
From: hwborcher@ @end|ng |rom gm@||@com (Hans W Borchers)
Date: Sat, 15 Sep 2018 21:38:22 +0200
Subject: [R] How can I know the Hausdorff dimensions of fractals in the
 'fractalcurve' function of package 'pracma'?
Message-ID: <CAML4n3OZwpBSG+VVe6wpHrVSt6CYmfT+3hffLO7PoE-ECeWQHw@mail.gmail.com>

> Dear Dr. Hans W. Borchers,

This is a public mailing list; do not address specific people here,
everyone can read and (possibly) answer your questions. And please send
e-mail in plain text format, not as HTML.

> I'm using your 'pracma' package. It is very useful. May I have a small
> question for the 'fractalcurve' function? How can I know the Hausdorff
> dimension for every option below?
> c("hilbert", "sierpinski", "snowflake", "dragon", "triangle",
>    "arrowhead", "flowsnake", "molecule")
> For the "dragon" option, its Hausdorff dimension is log(4)/log(2) = 2.
> For the others, what are the Hausdorff dimensions?

I don't know. Have you tried the *fractaldim* package to find at least a
plausible numerical value for the Hausdorff dimension?

> I have found the list of some fractals by Hausforff dimensions.
> I don't know which in the above option corresponds to which in Wikepedia.

Guess you mean the "List of fractals by Hausdorff dimension". Well, "hilbert"
is obviously the Hilbert curve and has a Hausdorff dimension of 2 -- because
it is a 'space-filling' curve.[^1]

Otherwise, use `fractalcurve()` to generate plots of the fractal curves and
compare with the pictures shown on the Wikipedia page. Not all the
curves may be present on this list, though.

> Thanks a lot!
> Best wishes,
> Peijian Shi

---
[1] By the way, I doubt your estimation that the dragon curve has Hausdorff
    dimension 2; it looks more like 1.5236.



From @|m|n@@t@work @end|ng |rom gm@||@com  Sat Sep 15 22:27:37 2018
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Sat, 15 Sep 2018 16:27:37 -0400
Subject: [R] Change the position of label when using R package eulerr
In-Reply-To: <72EA8C05-D7CB-4949-B483-98EDBDB40934@comcast.net>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
 <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
 <72EA8C05-D7CB-4949-B483-98EDBDB40934@comcast.net>
Message-ID: <CALn2QVjDVUXEg3UBz6dy5-qLPKpPwVafGNcn4qe7BYy1jrkcyA@mail.gmail.com>

Thank you, I tried your code, but I still got error:

  fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
"LAD&nonXL_MEF" = 541,
                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")

    fit1.plot <- plot(fit1,quantities = TRUE,fill = rainbow(7),lty =
1:2,labels = list(font = 1),alpha=0.7)
    fit1.plot
    grid.ls(fit1.plot)
    t <- grid.get("quantities.grob")
    names(t)
    t$label
    t$x
    t$y

    # Try to change the x and y value of the 4th label "2"
    grid.edit("quantities.grob",x[[4]]=unit(-11.8262244206465, "native"))
    grid.edit("quantities.grob",y[[4]]=unit(-5.19720701058398, "native"))

Error: unexpected '=' in "grid.edit("quantities.grob",x[[4]]="

Aimin

On Fri, Sep 14, 2018 at 6:47 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 14, 2018, at 2:03 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> >
> > Thank you,
> >
> > I figure out a way like this:
> >
> > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> "LAD&nonXL_MEF" = 541,
> >                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> >
> > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
> list(font = 1),alpha=0.7)
> >
> > grid.ls()
> > t <- grid.get("quantities.grob")
> > names(t)
> >
> > # Change these value will change the location of label.
> >
> > grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
> >                                          unit(-14.883684319653,
> "native"),
> >                                          unit(13.9805892820006,
> "native"),
> >                                          unit(-12.8808987356981,
> "native"),
> >                                          unit(-11.488226371243,
> "native"),
> >                                          unit(-9.51474016085318,
> "native"),
> >                                          unit(-1.00436055190216,
> "native")))
> >
> > grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
> >                                          unit(4.78718651828883,
> "native"),
> >                                          unit(0.25941593099694,
> "native"),
> >                                          unit(-4.32200781461293,
> "native"),
> >                                          unit(25.7349463488991,
> "native"),
> >                                          unit(-22.7610031110325,
> "native"),
> >                                          unit(14.5001560838519,
> "native")))
> >
> > However, here I just want to change the x and y  value of 4th label,
> does anyone know how to set it?
>
> If the t object were a complete grid object, it might have been:
>
> grid.edit("quantities.grob", x[[4]]= unit(-12.8808987356981, "native")
>            )
> grid.edit("quantities.grob", y[[4]]= unit(-4.32200781461293, "native"),
>            )
>
>
> But I don't think that will succeed since you never assigned the value of
> the plot operation to a name. Instead you pulled out part of the grid
> object that was sitting "free" and unassigned to a name. If you assign that
> value of plot(....) to `my.plot` you get:
>
>  grid.ls(my.plot)
> euler.diagram
>   GRID.gTree.11
>     diagram.grob.1
>       fills.grob.1
>       fills.grob.2
>       fills.grob.3
>       fills.grob.4
>       fills.grob.5
>       fills.grob.6
>       fills.grob.7
>       edges.grob
>       labels.grob
>       quantities.grob
>
> I think you need to work with the tutorials in the grid package.
>
> Look at:
>
> help("grid-package")
>
> --
> David.
>
> >
> > Aimin
> >
> > On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com>
> wrote:
> > >
> > > I am using eulerr to get venn.
> > > My code is like:
> > >
> > > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> > >                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> > > "LAD&nonXL_MEF" = 541,
> > >                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> > >
> > > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
> list(font
> > > = 1),alpha=0.7)
> > >
> > > After I get the figure, I find the position of some  labels need to be
> > > adjusted.
> > >
> > > Does anyone has some idea about how to process this?
> >
> > Looking at the code of plot.euler we see that the plotting paradigm is
> grid. So you could assign the output to a data.object name, search for list
> items that match the names of the labels you want to reposition, and modify
> the position values. You would need to be more specific, if you want a
> worked example.
> >
> > As far as I can see the lables and postions are fairly deep inside a
> list structure:
> >
> >  $ children     :List of 1
> >   ..$ GRID.gTree.12:List of 5
> >   .. ..$ children
> >          $ diagram.grob.1
> >             $children
> > .. .. .. .. ..$ labels.grob    :List of 11
> >   .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
> >   .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native
> 69.2native 11.9native
> >   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> >   .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native
> 5.24native 27.86native
> >   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> >
> > --
> > David.
> > >
> > >
> > > Thank you,
> > >
> > > Aimin
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Sep 16 00:25:16 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 15 Sep 2018 15:25:16 -0700
Subject: [R] Change the position of label when using R package eulerr
In-Reply-To: <CALn2QVjDVUXEg3UBz6dy5-qLPKpPwVafGNcn4qe7BYy1jrkcyA@mail.gmail.com>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
 <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
 <72EA8C05-D7CB-4949-B483-98EDBDB40934@comcast.net>
 <CALn2QVjDVUXEg3UBz6dy5-qLPKpPwVafGNcn4qe7BYy1jrkcyA@mail.gmail.com>
Message-ID: <08E2A6F0-F2C9-4C02-A9E7-CF053D6FB739@comcast.net>


> On Sep 15, 2018, at 1:27 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> 
> Thank you, I tried your code, but I still got error:
> 
>   fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
>                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101, "LAD&nonXL_MEF" = 541,
>                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
>     
>     fit1.plot <- plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font = 1),alpha=0.7)
>     fit1.plot
>     grid.ls(fit1.plot)

I don't think you are editing the right object (and I don't think you have honored my prior efforts to get you to read the documentation for the grid package):

names(fit1.plot)
#[1] "name"          "gp"            "vp"            "children"      "childrenOrder"
names(fit1.plot$children)
#[1] "GRID.gTree.12"
 names(fit1.plot$children$GRID.gTree.12)
#[1] "name"          "gp"            "vp"            "children"      "childrenOrder"
 names(fit1.plot$children$GRID.gTree.12$children)
#[1] "diagram.grob.1"
 names(fit1.plot$children$GRID.gTree.12$children$diagram.grob.1)
#[1] "name"          "gp"            "vp"            "children"      "childrenOrder"

 names()
 #[1] "fills.grob.1"    "fills.grob.2"    "fills.grob.3"    "fills.grob.4"    "fills.grob.5"    "fills.grob.6"    "fills.grob.7"   
 #[8] "edges.grob"      "labels.grob"     "quantities.grob"

My suggested target for editing, in place, would be:

fit1.plot$children$GRID.gTree.12$children$diagram.grob.1$children$quantities.grob

str( fit1.plot$children$GRID.gTree.12$children$diagram.grob.1$children$quantities.grob )
#----------------------
List of 11
 $ label        : chr [1:7] "3" "101" "541" "2" ...
 $ x            : 'unit' num [1:7] -4.35native -11.01native 16.5native -4.01native -28.09native ...
  ..- attr(*, "valid.unit")= int 4
  ..- attr(*, "unit")= chr "native"
 $ y            : 'unit' num [1:7] -2.569native 15.889native 4.732native -0.788native -7.157native ...
  ..- attr(*, "valid.unit")= int 4
  ..- attr(*, "unit")= chr "native"
 $ just         : chr "centre"
 $ hjust        : NULL
 $ vjust        : num [1:7] 0.5 0.5 0.5 0.5 1 1 1
 $ rot          : num [1:7] 0 0 0 0 0 0 0
 $ check.overlap: logi FALSE
 $ name         : chr "quantities.grob"
 $ gp           :List of 7
  ..$ col       : int [1:7] 1 1 1 1 1 1 1
  ..$ alpha     : num [1:7] 1 1 1 1 1 1 1
  ..$ fontsize  : num [1:7] 12 12 12 12 12 12 12
  ..$ cex       : num [1:7] 1 1 1 1 1 1 1
  ..$ fontfamily: chr [1:7] "" "" "" "" ...
  ..$ lineheight: num [1:7] 1.2 1.2 1.2 1.2 1.2 1.2 1.2
  ..$ font      : int [1:7] 1 1 1 1 1 1 1
  ..- attr(*, "class")= chr "gpar"
 $ vp           : NULL
 - attr(*, "class")= chr [1:3] "text" "grob" "gDesc"

 str( fit1.plot$children$GRID.gTree.12$children$diagram.grob.1$children$quantities.grob$x )
#----------
 'unit' num [1:7] -4.35native -11.01native 16.5native -4.01native -28.09native ...
 - attr(*, "valid.unit")= int 4
 - attr(*, "unit")= chr "native"
#-------
 str( fit1.plot$children$GRID.gTree.12$children$diagram.grob.1$children$quantities.grob$y )
#________
 'unit' num [1:7] -2.569native 15.889native 4.732native -0.788native -7.157native ...
 - attr(*, "valid.unit")= int 4
 - attr(*, "unit")= chr "native"

-- 
David




>     t <- grid.get("quantities.grob")
>     names(t)
>     t$label
>     t$x
>     t$y
> 
>     # Try to change the x and y value of the 4th label "2"
>     grid.edit("quantities.grob",x[[4]]=unit(-11.8262244206465, "native"))
>     grid.edit("quantities.grob",y[[4]]=unit(-5.19720701058398, "native"))
> 
> Error: unexpected '=' in "grid.edit("quantities.grob",x[[4]]="
> 
> Aimin
> 
> On Fri, Sep 14, 2018 at 6:47 PM David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Sep 14, 2018, at 2:03 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> > 
> > Thank you,
> > 
> > I figure out a way like this:
> > 
> > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101, "LAD&nonXL_MEF" = 541,
> >                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> >     
> > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font = 1),alpha=0.7)
> >    
> > grid.ls()
> > t <- grid.get("quantities.grob")
> > names(t)
> > 
> > # Change these value will change the location of label.
> >  
> > grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
> >                                          unit(-14.883684319653, "native"),
> >                                          unit(13.9805892820006, "native"),
> >                                          unit(-12.8808987356981, "native"),
> >                                          unit(-11.488226371243, "native"),
> >                                          unit(-9.51474016085318, "native"),
> >                                          unit(-1.00436055190216, "native")))
> >                 
> > grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
> >                                          unit(4.78718651828883, "native"),
> >                                          unit(0.25941593099694, "native"),
> >                                          unit(-4.32200781461293, "native"),
> >                                          unit(25.7349463488991, "native"),
> >                                          unit(-22.7610031110325, "native"),
> >                                          unit(14.5001560838519, "native")))
> > 
> > However, here I just want to change the x and y  value of 4th label, does anyone know how to set it?
> 
> If the t object were a complete grid object, it might have been:
> 
> grid.edit("quantities.grob", x[[4]]= unit(-12.8808987356981, "native")
>            )               
> grid.edit("quantities.grob", y[[4]]= unit(-4.32200781461293, "native"),
>            )
> 
> 
> But I don't think that will succeed since you never assigned the value of the plot operation to a name. Instead you pulled out part of the grid object that was sitting "free" and unassigned to a name. If you assign that value of plot(....) to `my.plot` you get:
> 
>  grid.ls(my.plot)
> euler.diagram
>   GRID.gTree.11
>     diagram.grob.1
>       fills.grob.1
>       fills.grob.2
>       fills.grob.3
>       fills.grob.4
>       fills.grob.5
>       fills.grob.6
>       fills.grob.7
>       edges.grob
>       labels.grob
>       quantities.grob
> 
> I think you need to work with the tutorials in the grid package.
> 
> Look at:
> 
> help("grid-package")
> 
> -- 
> David.
> 
> > 
> > Aimin
> > 
> > On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net> wrote:
> > 
> > > On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
> > > 
> > > I am using eulerr to get venn.
> > > My code is like:
> > > 
> > > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> > >                    "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> > > "LAD&nonXL_MEF" = 541,
> > >                    "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> > > 
> > > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
> > > = 1),alpha=0.7)
> > > 
> > > After I get the figure, I find the position of some  labels need to be
> > > adjusted.
> > > 
> > > Does anyone has some idea about how to process this?
> > 
> > Looking at the code of plot.euler we see that the plotting paradigm is grid. So you could assign the output to a data.object name, search for list items that match the names of the labels you want to reposition, and modify the position values. You would need to be more specific, if you want a worked example.
> > 
> > As far as I can see the lables and postions are fairly deep inside a list structure:
> > 
> >  $ children     :List of 1
> >   ..$ GRID.gTree.12:List of 5
> >   .. ..$ children
> >          $ diagram.grob.1     
> >             $children
> > .. .. .. .. ..$ labels.grob    :List of 11
> >   .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
> >   .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native 69.2native 11.9native
> >   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> >   .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native 5.24native 27.86native
> >   .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >   .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> > 
> > -- 
> > David.
> > > 
> > > 
> > > Thank you,
> > > 
> > > Aimin
> > > 
> > >       [[alternative HTML version deleted]]
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> > David Winsemius
> > Alameda, CA, USA
> > 
> > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> > 
> > 
> > 
> > 
> > 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From kry|ov@r00t @end|ng |rom gm@||@com  Sun Sep 16 18:21:58 2018
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sun, 16 Sep 2018 19:21:58 +0300
Subject: [R] Help with setting locale
In-Reply-To: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
References: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
Message-ID: <20180916192158.2a45b3fb@Tarkus>

On Fri, 14 Sep 2018 10:02:01 +0200
Kim Titcombe <ktitcombe02 at gmail.com> wrote:

> I am based in Switzerland but work in English (Windows in English),
> hence want English as default.

Which Windows version do you use? Which languages/language packs do you
have installed?

-- 
Best regards,
Ivan



From |e|@||u @end|ng |rom wu@t|@edu  Sun Sep 16 19:39:41 2018
From: |e|@||u @end|ng |rom wu@t|@edu (Liu, Lei)
Date: Sun, 16 Sep 2018 17:39:41 +0000
Subject: [R] bootstrap sample for clustered data
Message-ID: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>

Hi there,

I tried to generate bootstrap samples for clustered data. Here is some code I found in the web to do the work:

id=c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2)
x=c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1 )

xx=data.frame(id, x, y)

boot.cluster <- function(x, id){

  boot.id <- sample(unique(id), replace=T)
  out <- lapply(boot.id, function(i) x[id%in%i,])

  return( do.call("rbind",out) )

}

boot.pro=boot.cluster(xx, xx$id)

Now I have the output

   id x   y
5   3 0 0.4
6   3 0 1.0
51  3 0 0.4
61  3 0 1.0
9   5 1 0.5
10  5 1 2.0
52  3 0 0.4
62  3 0 1.0
3   2 1 0.4
4   2 1 0.3

However, the id variable is the original id, while I want to take the new id as (1, 1, 2, 2, 3, 3, 4, 4, 5, 5) for later analysis. Can anyone show me how to do it? Of note, the same original id may have duplicates since the bootstrap sample is drawn with replacement. Thanks a lot!

Lei


	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep 16 21:20:45 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 16 Sep 2018 12:20:45 -0700
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
References: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbQ51K8m6YgsRPHdKjWNX2GmcxEzE-kQDJ3XzdZT8Hm_0g@mail.gmail.com>

I can't make any sense of your post. Id 3 occurs 6 times, and 2 and 5 occur
twice each in your example.. How do you get (1,1,2,2,3,3,4,4,5,5) out of
that? In other words, specify the mapping of old id's to new.

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 16, 2018 at 11:51 AM Liu, Lei <lei.liu at wustl.edu> wrote:

> Hi there,
>
> I tried to generate bootstrap samples for clustered data. Here is some
> code I found in the web to do the work:
>
> id=c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
> y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2)
> x=c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1 )
>
> xx=data.frame(id, x, y)
>
> boot.cluster <- function(x, id){
>
>   boot.id <- sample(unique(id), replace=T)
>   out <- lapply(boot.id, function(i) x[id%in%i,])
>
>   return( do.call("rbind",out) )
>
> }
>
> boot.pro=boot.cluster(xx, xx$id)
>
> Now I have the output
>
>    id x   y
> 5   3 0 0.4
> 6   3 0 1.0
> 51  3 0 0.4
> 61  3 0 1.0
> 9   5 1 0.5
> 10  5 1 2.0
> 52  3 0 0.4
> 62  3 0 1.0
> 3   2 1 0.4
> 4   2 1 0.3
>
> However, the id variable is the original id, while I want to take the new
> id as (1, 1, 2, 2, 3, 3, 4, 4, 5, 5) for later analysis. Can anyone show me
> how to do it? Of note, the same original id may have duplicates since the
> bootstrap sample is drawn with replacement. Thanks a lot!
>
> Lei
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep 16 22:39:24 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 16 Sep 2018 13:39:24 -0700
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <CAGxFJbTOQCLNnK_Ewn50udoMjg8kW5UBGZzheBWm7WUYMjYCEA@mail.gmail.com>
References: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <CAGxFJbQ51K8m6YgsRPHdKjWNX2GmcxEzE-kQDJ3XzdZT8Hm_0g@mail.gmail.com>
 <SN4PR0201MB3405D3F4FDD6DB4863D3C037F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <CAGxFJbTOQCLNnK_Ewn50udoMjg8kW5UBGZzheBWm7WUYMjYCEA@mail.gmail.com>
Message-ID: <CAGxFJbTcQK_eeSe+q1j+SST-oKZg3nvQGyLFveioqDG+rLPwJg@mail.gmail.com>

(I neglected to cc this to the list -- Bert)


On Sun, Sep 16, 2018 at 1:36 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> You can do a mixed effects model using the existing id's without recoding.
>
> But if you insist, is this the sort of thing you want?
>
> set.seed(-12345) # for reprodicibility
>
> id <- factor(sample(2:5, 10, rep=TRUE))
> id
> new.id <- factor(id,labels = seq_along(levels(id)))
> new.id
>
> Note: There's a slightly slicker way to do this, but it bypasses the
> factor() API, and I prefer not to do that.
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Sep 16, 2018 at 12:52 PM Liu, Lei <lei.liu at wustl.edu> wrote:
>
>> Sorry for the confusion. I just want to recode the id variable to 1 to 5
>> in the bootstrapped sample. This way I can do e.g., a mixed effects model
>> using the new id as the cluster. Thanks!
>>
>> Lei
>>
>>
>>
>> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> *Sent:* Sunday, September 16, 2018 2:21 PM
>> *To:* Liu, Lei <lei.liu at wustl.edu>
>> *Cc:* R-help <r-help at r-project.org>
>> *Subject:* Re: [R] bootstrap sample for clustered data
>>
>>
>>
>> I can't make any sense of your post. Id 3 occurs 6 times, and 2 and 5
>> occur twice each in your example.. How do you get (1,1,2,2,3,3,4,4,5,5) out
>> of that? In other words, specify the mapping of old id's to new.
>>
>>
>>
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>
>>
>>
>> On Sun, Sep 16, 2018 at 11:51 AM Liu, Lei <lei.liu at wustl.edu> wrote:
>>
>> Hi there,
>>
>> I tried to generate bootstrap samples for clustered data. Here is some
>> code I found in the web to do the work:
>>
>> id=c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
>> y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2)
>> x=c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1 )
>>
>> xx=data.frame(id, x, y)
>>
>> boot.cluster <- function(x, id){
>>
>>   boot.id <- sample(unique(id), replace=T)
>>   out <- lapply(boot.id, function(i) x[id%in%i,])
>>
>>   return( do.call("rbind",out) )
>>
>> }
>>
>> boot.pro=boot.cluster(xx, xx$id)
>>
>> Now I have the output
>>
>>    id x   y
>> 5   3 0 0.4
>> 6   3 0 1.0
>> 51  3 0 0.4
>> 61  3 0 1.0
>> 9   5 1 0.5
>> 10  5 1 2.0
>> 52  3 0 0.4
>> 62  3 0 1.0
>> 3   2 1 0.4
>> 4   2 1 0.3
>>
>> However, the id variable is the original id, while I want to take the new
>> id as (1, 1, 2, 2, 3, 3, 4, 4, 5, 5) for later analysis. Can anyone show me
>> how to do it? Of note, the same original id may have duplicates since the
>> bootstrap sample is drawn with replacement. Thanks a lot!
>>
>> Lei
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]



From |e|@||u @end|ng |rom wu@t|@edu  Sun Sep 16 21:52:52 2018
From: |e|@||u @end|ng |rom wu@t|@edu (Liu, Lei)
Date: Sun, 16 Sep 2018 19:52:52 +0000
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <CAGxFJbQ51K8m6YgsRPHdKjWNX2GmcxEzE-kQDJ3XzdZT8Hm_0g@mail.gmail.com>
References: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <CAGxFJbQ51K8m6YgsRPHdKjWNX2GmcxEzE-kQDJ3XzdZT8Hm_0g@mail.gmail.com>
Message-ID: <SN4PR0201MB3405D3F4FDD6DB4863D3C037F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>

Sorry for the confusion. I just want to recode the id variable to 1 to 5 in the bootstrapped sample. This way I can do e.g., a mixed effects model using the new id as the cluster. Thanks!

Lei

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Sunday, September 16, 2018 2:21 PM
To: Liu, Lei <lei.liu at wustl.edu>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] bootstrap sample for clustered data

I can't make any sense of your post. Id 3 occurs 6 times, and 2 and 5 occur twice each in your example.. How do you get (1,1,2,2,3,3,4,4,5,5) out of that? In other words, specify the mapping of old id's to new.

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 16, 2018 at 11:51 AM Liu, Lei <lei.liu at wustl.edu<mailto:lei.liu at wustl.edu>> wrote:
Hi there,

I tried to generate bootstrap samples for clustered data. Here is some code I found in the web to do the work:

id=c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2)
x=c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1 )

xx=data.frame(id, x, y)

boot.cluster <- function(x, id){

  boot.id<http://boot.id> <- sample(unique(id), replace=T)
  out <- lapply(boot.id<http://boot.id>, function(i) x[id%in%i,])

  return( do.call("rbind",out) )

}

boot.pro<http://boot.pro>=boot.cluster(xx, xx$id)

Now I have the output

   id x   y
5   3 0 0.4
6   3 0 1.0
51  3 0 0.4
61  3 0 1.0
9   5 1 0.5
10  5 1 2.0
52  3 0 0.4
62  3 0 1.0
3   2 1 0.4
4   2 1 0.3

However, the id variable is the original id, while I want to take the new id as (1, 1, 2, 2, 3, 3, 4, 4, 5, 5) for later analysis. Can anyone show me how to do it? Of note, the same original id may have duplicates since the bootstrap sample is drawn with replacement. Thanks a lot!

Lei


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From zhhhw@ng @end|ng |rom um|ch@edu  Mon Sep 17 00:23:09 2018
From: zhhhw@ng @end|ng |rom um|ch@edu (Zhihao Huang)
Date: Sun, 16 Sep 2018 18:23:09 -0400
Subject: [R] makeCluster() hangs infinitely
Message-ID: <CADBpgp0PsJ7M5MATA8jkMQA1DnJ-HmQRXzGLcq=TyKe8UWG7Ag@mail.gmail.com>

Hi all,

The function makeCluster() of parallel does not work on my laptop. It hangs
infinitely.

*1. Problem Summary:*

> # Loading parallel packages

> library(parallel)

> cl <- makeCluster(2) # It hangs at this line of code.
It hangs at the second line of the code.

*2. Potential Reason*
I also tried to see the details of what it does internally by using the
following code.

> library(future)

> cl <- future::makeClusterPSOCK(1L, verbose = TRUE) # It hangs at this
line of code.
And it returns the following descriptions and hangs.

*Workers: [n = 1] ?localhost?*

*Base port: 11214*

*Creating node 1 of 1 ...*

*- setting up node*

*Starting worker #1 on ?localhost?:
'/Library/Frameworks/R.framework/Resources/bin/Rscript'
--default-packages=datasets,utils,grDevices,graphics,stats,methods -e
'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT=/dev/null
TIMEOUT=2592000 XDR=TRUE*

*Waiting for worker #1 on ?localhost? to connect back*
So the problem is that the "worker #1 on 'local host'" never connects back,
and that's why it hangs forever. I have no idea what causes this.

*3. my sessionInfo():*

R version 3.5.1 (2018-07-02)

Platform: x86_64-apple-darwin15.6.0 (64-bit)

Running under: macOS High Sierra 10.13.6


Matrix products: default

BLAS:
/Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib

LAPACK:
/Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib


locale:

[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_3.5.1

I spent hours searching for the solutions but failed. It looks like some
other people met similar problem here
<http://r.789695.n4.nabble.com/makeCluster-hangs-td4748238.html>. Also, I
posted this question online here
<https://stackoverflow.com/questions/52264460/r-parallel-makecluster-hangs-infinitely-on-mac/52284709#52284709>
a
week ago.

Any suggestion would be appreciated. Thanks a lot!

Thanks,
Zhihao
--
Zhihao (Daniel) Huang
Graduate Student
Department of Statistics,
University of Michigan, Ann Arbor
Email: zhhhwang at umich.edu

-- 
? ??
Zhihao Huang

Graduate Student
Department of Statistics,
University of Michigan, Ann Arbor
Email: zhhhwang at umich.edu

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 17 03:05:09 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 16 Sep 2018 18:05:09 -0700
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <SN4PR0201MB3405F2A5E3D547295238C395F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
References: <SN4PR0201MB34053AAD2AE0033E39ABE316F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <CAGxFJbQ51K8m6YgsRPHdKjWNX2GmcxEzE-kQDJ3XzdZT8Hm_0g@mail.gmail.com>
 <SN4PR0201MB3405D3F4FDD6DB4863D3C037F71F0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <CAGxFJbTOQCLNnK_Ewn50udoMjg8kW5UBGZzheBWm7WUYMjYCEA@mail.gmail.com>
 <SN4PR0201MB3405F2A5E3D547295238C395F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbSAr=UJhNsqYZCkpP5htbNaJSdBiTndWiP7WKReZELUrw@mail.gmail.com>

Unless there is good reason not to -- which is not the case here --
**always" cc the list. I have done that here.

"Can you help me with it?"
Nope. I'm not a private consultant, and I already made an attempt to do so,
which you seem to have completely ignored. So I'm done.
By the way, "Unfortunately it couldn?t work for my case" is a completely
meaningless comment. You need to explicitly show what you did and what
error messages you received. Read the posting guide below for how to post
an intelligible question.
FInally, if you think this is a mixed model issue -- which I believe you
are confused about, but as I can't penetrate your comments, maybe I'm wrong
-- post on the r-sig-mixed-models list,not here. Same comments go for
posting an intelligible question apply there.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 16, 2018 at 5:34 PM Liu, Lei <lei.liu at wustl.edu> wrote:

> Hi Bert,
>
>
>
> Thanks for your help. Unfortunately it couldn?t work for my case. Please
> see my code below. Here id is the cluster. Note different clusters have
> different number of subjects, some have 2, some have 3.
>
>
>
> id=c(1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5)
>
> y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2, 2.2, 3)
>
> x=c(0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1 )
>
>
>
> xx=data.frame(id, x, y)
>
>
>
> boot.cluster <- function(x, id){
>
>
>
>   boot.id <- sample(unique(id), replace=T)
>
>   out <- lapply(boot.id, function(i) x[id%in%i,])
>
>
>
>   return( do.call("rbind",out) )
>
>
>
> }
>
>
>
> boot.xx=boot.cluster(xx, xx$id)
>
>
>
> Here is the boot.xx dataset:
>
>
>
>    id x   y
>
> 5   3 0 0.4
>
> 6   3 0 1.0
>
> 7   3 0 0.9
>
> 1   1 0 0.5
>
> 2   1 0 0.6
>
> 11  5 1 2.2
>
> 12  5 1 3.0
>
> 3   2 1 0.4
>
> 4   2 1 0.3
>
> 13  1 0 0.5
>
> 21  1 0 0.6
>
>
>
> You can see that some clusters (ids) appears multiple times (e.g., id 1
> appears in two places ? 4 rows), since bootstrap does a sample *with
> replacement*, we could have the same cluster multiple times. Thus, we
> cannot do a mixed effects model using this data, as we should assume all
> the clusters are different in this new data. Instead, I will reorganize the
> data as below. This is the step I need help:
>
>
>
> new.id x   y
>
> 5   1 0 0.4
>
> 6   1 0 1.0
>
> 7   1 0 0.9
>
> 1   2 0 0.5
>
> 2   2 0 0.6
>
> 11  3 1 2.2
>
> 12  3 1 3.0
>
> 3   4 1 0.4
>
> 4   4 1 0.3
>
> 13  5 0 0.5
>
> 21  5 0 0.6
>
>
>
> Can you help me with it? Thanks a lot!
>
>
>
> Lei
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Sunday, September 16, 2018 3:36 PM
> *To:* Liu, Lei <lei.liu at wustl.edu>
> *Subject:* Re: [R] bootstrap sample for clustered data
>
>
>
> You can do a mixed effects model using the existing id's without recoding.
>
>
>
> But if you insist, is this the sort of thing you want?
>
>
>
> set.seed(-12345) # for reprodicibility
>
> id <- factor(sample(2:5, 10, rep=TRUE))
> id
> new.id <- factor(id,labels = seq_along(levels(id)))
> new.id
>
>
>
> Note: There's a slightly slicker way to do this, but it bypasses the
> factor() API, and I prefer not to do that.
>
>
>
> Cheers,
>
> Bert
>
>
>
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
>
>
> On Sun, Sep 16, 2018 at 12:52 PM Liu, Lei <lei.liu at wustl.edu> wrote:
>
> Sorry for the confusion. I just want to recode the id variable to 1 to 5
> in the bootstrapped sample. This way I can do e.g., a mixed effects model
> using the new id as the cluster. Thanks!
>
> Lei
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Sunday, September 16, 2018 2:21 PM
> *To:* Liu, Lei <lei.liu at wustl.edu>
> *Cc:* R-help <r-help at r-project.org>
> *Subject:* Re: [R] bootstrap sample for clustered data
>
>
>
> I can't make any sense of your post. Id 3 occurs 6 times, and 2 and 5
> occur twice each in your example.. How do you get (1,1,2,2,3,3,4,4,5,5) out
> of that? In other words, specify the mapping of old id's to new.
>
>
>
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
>
>
> On Sun, Sep 16, 2018 at 11:51 AM Liu, Lei <lei.liu at wustl.edu> wrote:
>
> Hi there,
>
> I tried to generate bootstrap samples for clustered data. Here is some
> code I found in the web to do the work:
>
> id=c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
> y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2)
> x=c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1 )
>
> xx=data.frame(id, x, y)
>
> boot.cluster <- function(x, id){
>
>   boot.id <- sample(unique(id), replace=T)
>   out <- lapply(boot.id, function(i) x[id%in%i,])
>
>   return( do.call("rbind",out) )
>
> }
>
> boot.pro=boot.cluster(xx, xx$id)
>
> Now I have the output
>
>    id x   y
> 5   3 0 0.4
> 6   3 0 1.0
> 51  3 0 0.4
> 61  3 0 1.0
> 9   5 1 0.5
> 10  5 1 2.0
> 52  3 0 0.4
> 62  3 0 1.0
> 3   2 1 0.4
> 4   2 1 0.3
>
> However, the id variable is the original id, while I want to take the new
> id as (1, 1, 2, 2, 3, 3, 4, 4, 5, 5) for later analysis. Can anyone show me
> how to do it? Of note, the same original id may have duplicates since the
> bootstrap sample is drawn with replacement. Thanks a lot!
>
> Lei
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]



From j@ck@onmrodr|gue@ @end|ng |rom gm@||@com  Mon Sep 17 05:03:20 2018
From: j@ck@onmrodr|gue@ @end|ng |rom gm@||@com (Jackson Rodrigues)
Date: Mon, 17 Sep 2018 00:03:20 -0300
Subject: [R] Set the same colour range for 2 != rasters
Message-ID: <CAPL76w89=D1YRax-gN_ZRoeJfwspHcS5duMe8zxqsoc5S1rnrQ@mail.gmail.com>

Dear all,

My name is Jackson.
I am trying to set the same colour range for 2 rasters (max and min
temperatures). Both rasters have different numerical ranges but the same
dimensions
dimensions  : 4346, 4365, 18970290, 1  (nrow, ncol, ncell, nlayers)

The lowest value is 3 and the highest is 31. So my colour palette should
range from 3 to 31 and be useful for both temperatures

However I got a message saying that S4 and vector cannot be coerced.
So far I understand why it is not working but how to fix it?

A few lines from my code.

####
cols<-colorRampPalette(c("royalblue","springgreen","yellow","orange","red"))(29)

Temp.interval = seq(from=3, to=31)

# creating colour vectors
col1 <- cols[findInterval(TMin_masked$prj, vec =  Temp.interval  )]

Error in as.double(x) :
  cannot coerce type 'S4' to vector of type 'double'
####

Thank you all!

Best regards.

Jackson

	[[alternative HTML version deleted]]



From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Mon Sep 17 05:00:01 2018
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Mon, 17 Sep 2018 15:00:01 +1200
Subject: [R] 
 [FORGED] Re: Change the position of label when using R package
 eulerr
In-Reply-To: <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
 <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
Message-ID: <6de0953e-2ba4-70d9-e24c-a9025362c030@stat.auckland.ac.nz>

Hi

The 'x' component of the 't' grob that you get back from grid.get() is a 
unit object, which you can subset and assign to a subset, for example 
this code nudges the fourth label up and to the right 1mm in each 
direction ...


x <- t$x
y <- t$y

x[4] <- t$x[4] + unit(1, "mm")
y[4] <- t$y[4] + unit(1, "mm")

grid.edit("quantities.grob", x=x, y=y)


... is that the sort of thing you were looking for ?

Paul

On 15/09/18 09:03, Aimin Yan wrote:
> Thank you,
> 
> I figure out a way like this:
> 
> fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
>                      "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> "LAD&nonXL_MEF" = 541,
>                      "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> 
> plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels = list(font
> = 1),alpha=0.7)
> 
> grid.ls()
> t <- grid.get("quantities.grob")
> names(t)
> 
> # Change these value will change the location of label.
> 
> grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
>                                           unit(-14.883684319653, "native"),
>                                           unit(13.9805892820006, "native"),
>                                           unit(-12.8808987356981, "native"),
>                                           unit(-11.488226371243, "native"),
>                                           unit(-9.51474016085318, "native"),
>                                           unit(-1.00436055190216, "native")))
> 
> grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
>                                           unit(4.78718651828883, "native"),
>                                           unit(0.25941593099694, "native"),
>                                           unit(-4.32200781461293, "native"),
>                                           unit(25.7349463488991, "native"),
>                                           unit(-22.7610031110325, "native"),
>                                           unit(14.5001560838519, "native")))
> 
> However, here I just want to change the x and y  value of 4th label, does
> anyone know how to set it?
> 
> Aimin
> 
> On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net>
> wrote:
> 
>>
>>> On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com> wrote:
>>>
>>> I am using eulerr to get venn.
>>> My code is like:
>>>
>>> fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
>>>                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
>>> "LAD&nonXL_MEF" = 541,
>>>                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
>>>
>>> plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
>> list(font
>>> = 1),alpha=0.7)
>>>
>>> After I get the figure, I find the position of some  labels need to be
>>> adjusted.
>>>
>>> Does anyone has some idea about how to process this?
>>
>> Looking at the code of plot.euler we see that the plotting paradigm is
>> grid. So you could assign the output to a data.object name, search for list
>> items that match the names of the labels you want to reposition, and modify
>> the position values. You would need to be more specific, if you want a
>> worked example.
>>
>> As far as I can see the lables and postions are fairly deep inside a list
>> structure:
>>
>>   $ children     :List of 1
>>    ..$ GRID.gTree.12:List of 5
>>    .. ..$ children
>>           $ diagram.grob.1
>>              $children
>> .. .. .. .. ..$ labels.grob    :List of 11
>>    .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
>>    .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native
>> 69.2native 11.9native
>>    .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>>    .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
>>    .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native
>> 5.24native 27.86native
>>    .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
>>    .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
>>
>> --
>> David.
>>>
>>>
>>> Thank you,
>>>
>>> Aimin
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'
>>   -Gehm's Corollary to Clarke's Third Law
>>
>>
>>
>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From |e|@||u @end|ng |rom wu@t|@edu  Mon Sep 17 05:22:44 2018
From: |e|@||u @end|ng |rom wu@t|@edu (Liu, Lei)
Date: Mon, 17 Sep 2018 03:22:44 +0000
Subject: [R] bootstrap sample for clustered data
Message-ID: <SN4PR0201MB340568ED119F5665F16A9386F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>

Hi there,

I posted this message before but there may be some confusion in my previous post. So here is a clearer version:

I'd like to do a bootstrap sampling for clustered data. Then I will run some complicated models (say mixed effects models) on the bootstrapped sample. Here id is the cluster. Note different clusters have different number of subjects, e.g., id 2 has 2 observations, id 3 has 3 observations.

id=c(1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5)
y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2, 2.2, 3)
x=c(0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1 )

xx=data.frame(id, x, y)

boot.cluster <- function(x, id){

  boot.id <- sample(unique(id), replace=T)
  out <- lapply(boot.id, function(i) x[id%in%i,])

  return( do.call("rbind",out) )

}

boot.xx=boot.cluster(xx, xx$id)

Here is the generated boot.xx dataset:

   id x y
   3 0 0.4
   3 0 1.0
   3 0 0.9
   1 0 0.5
   1 0 0.6
   5 1 2.2
   5 1 3.0
   2 1 0.4
   2 1 0.3
   1 0 0.5
   1 0 0.6

You can see that some clusters (ids) appears multiple times (e.g., id 1 appears in two places - 4 rows), since bootstrap does a sample with replacement, we could have the same cluster multiple times. Thus, we cannot do a mixed effects model using this data, as we should assume all the clusters are different in this new data. Instead, I will reorganize the data as below (id is reordered from the above boot.xx data). This is the step I need help:

  id x  y
   1 0 0.4
   1 0 1.0
   1 0 0.9
   2 0 0.5
   2 0 0.6
   3 1 2.2
   3 1 3.0
   4 1 0.4
   4 1 0.3
   5 0 0.5
   5 0 0.6

Can someone help me with it? Thanks!

Lei Liu
Professor of Biostatistics
Washington University in St. Louis


	[[alternative HTML version deleted]]



From henr|k@bengt@@on @end|ng |rom gm@||@com  Mon Sep 17 06:37:39 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Sun, 16 Sep 2018 21:37:39 -0700
Subject: [R] makeCluster() hangs infinitely
In-Reply-To: <CADBpgp0PsJ7M5MATA8jkMQA1DnJ-HmQRXzGLcq=TyKe8UWG7Ag@mail.gmail.com>
References: <CADBpgp0PsJ7M5MATA8jkMQA1DnJ-HmQRXzGLcq=TyKe8UWG7Ag@mail.gmail.com>
Message-ID: <CAFDcVCSvR_=-EEqkkq-yfNpFZ8TGLxa3M4teko935ZMCKMzsAw@mail.gmail.com>

Hi,

did you see my answer on StackOverflow? Specifically, if you set
argument 'outfile = NULL' to either of those two functions, you'll get
a little bit more information that *might* provide some clues.

/Henrik


On Sun, Sep 16, 2018 at 5:38 PM Zhihao Huang <zhhhwang at umich.edu> wrote:
>
> Hi all,
>
> The function makeCluster() of parallel does not work on my laptop. It hangs
> infinitely.
>
> *1. Problem Summary:*
>
> > # Loading parallel packages
>
> > library(parallel)
>
> > cl <- makeCluster(2) # It hangs at this line of code.
> It hangs at the second line of the code.
>
> *2. Potential Reason*
> I also tried to see the details of what it does internally by using the
> following code.
>
> > library(future)
>
> > cl <- future::makeClusterPSOCK(1L, verbose = TRUE) # It hangs at this
> line of code.
> And it returns the following descriptions and hangs.
>
> *Workers: [n = 1] ?localhost?*
>
> *Base port: 11214*
>
> *Creating node 1 of 1 ...*
>
> *- setting up node*
>
> *Starting worker #1 on ?localhost?:
> '/Library/Frameworks/R.framework/Resources/bin/Rscript'
> --default-packages=datasets,utils,grDevices,graphics,stats,methods -e
> 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT=/dev/null
> TIMEOUT=2592000 XDR=TRUE*
>
> *Waiting for worker #1 on ?localhost? to connect back*
> So the problem is that the "worker #1 on 'local host'" never connects back,
> and that's why it hangs forever. I have no idea what causes this.
>
> *3. my sessionInfo():*
>
> R version 3.5.1 (2018-07-02)
>
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>
> Running under: macOS High Sierra 10.13.6
>
>
> Matrix products: default
>
> BLAS:
> /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
>
> LAPACK:
> /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
>
>
> locale:
>
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> loaded via a namespace (and not attached):
>
> [1] compiler_3.5.1
>
> I spent hours searching for the solutions but failed. It looks like some
> other people met similar problem here
> <http://r.789695.n4.nabble.com/makeCluster-hangs-td4748238.html>. Also, I
> posted this question online here
> <https://stackoverflow.com/questions/52264460/r-parallel-makecluster-hangs-infinitely-on-mac/52284709#52284709>
> a
> week ago.
>
> Any suggestion would be appreciated. Thanks a lot!
>
> Thanks,
> Zhihao
> --
> Zhihao (Daniel) Huang
> Graduate Student
> Department of Statistics,
> University of Michigan, Ann Arbor
> Email: zhhhwang at umich.edu
>
> --
> ? ??
> Zhihao Huang
>
> Graduate Student
> Department of Statistics,
> University of Michigan, Ann Arbor
> Email: zhhhwang at umich.edu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From g||ted|||e2014 @end|ng |rom gm@||@com  Mon Sep 17 09:17:03 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Mon, 17 Sep 2018 08:17:03 +0100
Subject: [R] Data.frame of Different Length
Message-ID: <CAC8ss33yoTC1R03t=eHLLBGQO7B5y=rqoQ12nbqsq+Ktd_J2gQ@mail.gmail.com>

Dear Contributors,

I have two data frame of different column lengths. I am trying to have them
in one data frame.
Using
A<-d1$date
B<-d2$date
a<-data.table(A )[ , I := .I][data.table(B )[ , I := .I], on = "I"]
I got
1: 2005-01-04  1 2005-01-04
 2: 2005-01-19  2 2005-01-19
 3: 2005-01-22  3 2005-01-22
 4: 2005-02-24  4 2005-02-19
 5: 2005-05-09  5 2005-02-24
 6: 2005-05-16  6 2005-05-09
 7: 2005-06-17  7 2005-05-11
 8: 2005-07-17  8 2005-05-16
 9: 2005-08-07  9 2005-06-13
10: 2005-09-11 10 2005-06-17
11: 2005-09-13 11 2005-06-22
12: 2005-09-15 12 2005-07-18
13:         NA 13 2005-08-03
14:         NA 14 2005-08-07
15:         NA 15 2005-08-10
16:         NA 16 2005-08-25
17:         NA 17 2005-09-13
18:         NA 18 2005-09-15
19:         NA 19 2005-10-13
20:         NA 20 2005-12-15
which is fine.

I have two more problems:
1) how to remove the nos 1 to 20 inserted at the middle of the dates.

2) how to include more columns.

I have about 5 columns of different lengths which I wish to have in one
data frame.

I will remain grateful if assisted.

Best regards
Ogbos

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep 17 09:32:12 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 17 Sep 2018 00:32:12 -0700
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <SN4PR0201MB340568ED119F5665F16A9386F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
References: <SN4PR0201MB340568ED119F5665F16A9386F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
Message-ID: <894A4868-409A-44DA-A8D8-2C6CE7F252A6@dcn.davis.ca.us>

You are telling us that the ID values in your data set indicate clusters. However you went about making that determination in the first place might be an obvious(?) way to do it again with your bootstrapped sample, ignoring the cluster assignments you have in place. This is the wrong place to have a discussion about which theoretical method for cluster identification you should use, and if you do know that then searching the web or using the sos package would be the appropriate way to find implementations of a specific clustering algorithm.

I am not an ME expert, but AFAIK "complicated" analyses such as mixed effects models tend to have rather hefty appetites for data completeness, so you may have to design a special sampling plan in order to avoid generating data sets for which those analyses won't break, and you will probably need a very large data set to start with in order to have sufficient data in each cluster. That is, you may be better off keeping the original cluster identification and just restructuring your bootstrap sampling to sample within clusters.

The R-sig-me mailing list is probably a better venue for your questions. 

On September 16, 2018 8:22:44 PM PDT, "Liu, Lei" <lei.liu at wustl.edu> wrote:
>Hi there,
>
>I posted this message before but there may be some confusion in my
>previous post. So here is a clearer version:
>
>I'd like to do a bootstrap sampling for clustered data. Then I will run
>some complicated models (say mixed effects models) on the bootstrapped
>sample. Here id is the cluster. Note different clusters have different
>number of subjects, e.g., id 2 has 2 observations, id 3 has 3
>observations.
>
>id=c(1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5)
>y=c(.5, .6, .4, .3, .4, 1, .9, 1, .5, 2, 2.2, 3)
>x=c(0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1 )
>
>xx=data.frame(id, x, y)
>
>boot.cluster <- function(x, id){
>
>  boot.id <- sample(unique(id), replace=T)
>  out <- lapply(boot.id, function(i) x[id%in%i,])
>
>  return( do.call("rbind",out) )
>
>}
>
>boot.xx=boot.cluster(xx, xx$id)
>
>Here is the generated boot.xx dataset:
>
>   id x y
>   3 0 0.4
>   3 0 1.0
>   3 0 0.9
>   1 0 0.5
>   1 0 0.6
>   5 1 2.2
>   5 1 3.0
>   2 1 0.4
>   2 1 0.3
>   1 0 0.5
>   1 0 0.6
>
>You can see that some clusters (ids) appears multiple times (e.g., id 1
>appears in two places - 4 rows), since bootstrap does a sample with
>replacement, we could have the same cluster multiple times. Thus, we
>cannot do a mixed effects model using this data, as we should assume
>all the clusters are different in this new data. Instead, I will
>reorganize the data as below (id is reordered from the above boot.xx
>data). This is the step I need help:
>
>  id x  y
>   1 0 0.4
>   1 0 1.0
>   1 0 0.9
>   2 0 0.5
>   2 0 0.6
>   3 1 2.2
>   3 1 3.0
>   4 1 0.4
>   4 1 0.3
>   5 0 0.5
>   5 0 0.6
>
>Can someone help me with it? Thanks!
>
>Lei Liu
>Professor of Biostatistics
>Washington University in St. Louis
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From h@medh@@e|| @end|ng |rom gm@||@com  Mon Sep 17 09:55:59 2018
From: h@medh@@e|| @end|ng |rom gm@||@com (Hamed Ha)
Date: Mon, 17 Sep 2018 08:55:59 +0100
Subject: [R] Problem with lm.resid() when weights are provided
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8368B12FB@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
 <22333_1536669565_w8BCdOUV005487_CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368B0E61@FHSDB2D11-2.csu.mcmaster.ca>
 <CAAC89xexc0tHnC8n_n0Z+=3xtPDFmB394=U75V3KLe9RQ6OWdA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368B12FB@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAAC89xdt93_tGBsLrHQqMjjAA9uEJ2eRH4ptiVz0gWJ2CJa8VA@mail.gmail.com>

H i John,

Thank you for your reply.

I see your point, thanks. I checked lm.wfit() and realised that there is a
tol parameter that is already set to 10^-7. This is not even the half
decimal to the machine precision. Furthermore, plying with tol parameter
does not solve the problem, as far as I checked.

I still see this issue as critical and we should report it to the R core
team to be investigated more. What do you think?


Regards,
Hamed.


On Fri, 14 Sep 2018 at 22:46, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Hamed,
>
> When you post a question to r-help, generally you should cc subsequent
> messages there as well, as I've done to this response.
>
> The algorithm that lm() uses is much more numerically stable than
> inverting the weighted sum-of-squares-and-product matrix. If you want to
> see how the computations are done, look at lm.wfit(), in which the
> residuals and fits are computed as
>
>     z$residuals <- z$residuals/wts
>     z$fitted.values <- y - z$residuals
>
> Zero weights are handled specially, and your tiny weights are thus the
> source of the problem. When you divide by a number less than the machine
> double-epsilon, you can't expect numerically stable results. I suppose that
> lm.wfit() could check for 0 weights to a tolerance rather than exactly.
>
> John
>
> > -----Original Message-----
> > From: Hamed Ha [mailto:hamedhaseli at gmail.com]
> > Sent: Friday, September 14, 2018 5:34 PM
> > To: Fox, John <jfox at mcmaster.ca>
> > Subject: Re: [R] Problem with lm.resid() when weights are provided
> >
> > Hi John,
> >
> > Thank you for your reply.
> >
> > I agree that the small weights are the potential source of the
> instability in the
> > result. I also suspected that there are some failure/bugs in the actual
> > algorithm that R uses for fitting the model. I remember that at some
> points I
> > checked the theoretical estimation of the parameters, solve(t(x) %*% w
> %*%
> > x) %*% t(x) %*% w %*% y, (besides the point that I had to set tol
> parameter in
> > solve() to a super small value) and realised  that lm() and the
> theoretical
> > results match together. That is the parameter estimation is right in R.
> > Moreover, I checked the predictions, predict(lm.fit), and it was right.
> Then the
> > only source of error remained was resid() function. I further checked
> this
> > function and it is nothing more than calling a sub-element from and lm()
> fit.
> > Putting all together, I think that there is something wrong/bug/miss-
> > configuration in the lm() algorithm and I highly recommend the R core
> team to
> > fix that.
> >
> > Please feel free to contact me for more details if required.
> >
> > Warm regards,
> > Hamed.
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > On Fri, 14 Sep 2018 at 13:35, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca> > wrote:
> >
> >
> >       Dear Hamed,
> >
> >       I don't think that anyone has picked up on this problem.
> >
> >       What's peculiar about your weights is that several are 0 within
> > rounding error but not exactly 0:
> >
> >       > head(df)
> >                  y          x       weight
> >       1  1.5115614  0.5520924 2.117337e-34
> >       2 -0.6365313 -0.1259932 2.117337e-34
> >       3  0.3778278  0.4209538 4.934135e-31
> >       4  3.0379232  1.4031545 2.679495e-24
> >       5  1.5364652  0.4607686 2.679495e-24
> >       6 -2.3772787 -0.7396358 6.244160e-21
> >
> >       I can reproduce the results that you report:
> >
> >       > (mod.1 <- lm(y ~ x, data=df))
> >
> >       Call:
> >       lm(formula = y ~ x, data = df)
> >
> >       Coefficients:
> >       (Intercept)            x
> >          -0.04173      2.03790
> >
> >       > max(resid(mod.1))
> >       [1] 1.14046
> >       > (mod.2 <- lm(y ~ x, data=df, weights=weight))
> >
> >       Call:
> >       lm(formula = y ~ x, data = df, weights = weight)
> >
> >       Coefficients:
> >       (Intercept)            x
> >          -0.05786      1.96087
> >
> >       > max(resid(mod.2))
> >       [1] 36.84939
> >
> >       But the problem disappears when the tiny nonzero weight are set to
> 0:
> >
> >       > df2 <- df
> >       > df2$weight <- zapsmall(df2$weight)
> >       > head(df2)
> >                  y          x weight
> >       1  1.5115614  0.5520924      0
> >       2 -0.6365313 -0.1259932      0
> >       3  0.3778278  0.4209538      0
> >       4  3.0379232  1.4031545      0
> >       5  1.5364652  0.4607686      0
> >       6 -2.3772787 -0.7396358      0
> >       > (mod.3 <- update(mod.2, data=df2))
> >
> >       Call:
> >       lm(formula = y ~ x, data = df2, weights = weight)
> >
> >       Coefficients:
> >       (Intercept)            x
> >          -0.05786      1.96087
> >
> >       > max(resid(mod.3))
> >       [1] 1.146663
> >
> >       I don't know exactly why this happens, but suspect numerical
> > instability produced by the near-zero weights, which are smaller than the
> > machine double-epsilon
> >
> >       > .Machine$double.neg.eps
> >       [1] 1.110223e-16
> >
> >       The problem also disappears, e.g., if the tiny weight are set to
> 1e-15
> > rather than 0.
> >
> >       I hope this helps,
> >        John
> >
> >       -----------------------------------------------------------------
> >       John Fox
> >       Professor Emeritus
> >       McMaster University
> >       Hamilton, Ontario, Canada
> >       Web: https://socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >       > -----Original Message-----
> >       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:
> r-help-
> > bounces at r-project.org> ] On Behalf Of Hamed Ha
> >       > Sent: Tuesday, September 11, 2018 8:39 AM
> >       > To: r-help at r-project.org <mailto:r-help at r-project.org>
> >       > Subject: [R] Problem with lm.resid() when weights are provided
> >       >
> >       > Dear R Help Team.
> >       >
> >       > I get some weird results when I use the lm function with weight.
> The
> > issue can
> >       > be reproduced by the example below:
> >       >
> >       >
> >       > The input data is (weights are intentionally designed to reflect
> some
> >       > structures in the data)
> >       >
> >       >
> >       > > df
> >       > y x weight
> >       >  1.51156139  0.55209240 2.117337e-34
> >       > -0.63653132 -0.12599316 2.117337e-34
> >       >  0.37782776  0.42095384 4.934135e-31
> >       >  3.03792318  1.40315446 2.679495e-24
> >       >  1.53646523  0.46076858 2.679495e-24
> >       > -2.37727874 -0.73963576 6.244160e-21
> >       >  0.37183065  0.20407468 1.455107e-17
> >       > -1.53917553 -0.95519361 1.455107e-17
> >       >  1.10926675  0.03897129 3.390908e-14
> >       > -0.37786333 -0.17523593 3.390908e-14
> >       >  2.43973603  0.97970095 7.902000e-11
> >       > -0.35432394 -0.03742559 7.902000e-11
> >       >  2.19296613  1.00355263 4.289362e-04
> >       >  0.49845532  0.34816207 4.289362e-04
> >       >  1.25005260  0.76306225 5.000000e-01
> >       >  0.84360691  0.45152356 5.000000e-01
> >       >  0.29565993  0.53880068 5.000000e-01
> >       > -0.54081334 -0.28104525 5.000000e-01
> >       >  0.83612836 -0.12885659 9.995711e-01
> >       > -1.42526769 -0.87107631 9.999998e-01
> >       >  0.10204789 -0.11649899 1.000000e+00
> >       >  1.14292898  0.37249631 1.000000e+00
> >       > -3.02942081 -1.28966997 1.000000e+00
> >       > -1.37549764 -0.74676145 1.000000e+00
> >       > -2.00118016 -0.55182759 1.000000e+00
> >       > -4.24441674 -1.94603608 1.000000e+00
> >       >  1.17168144  1.00868008 1.000000e+00
> >       >  2.64007761  1.26333069 1.000000e+00
> >       >  1.98550114  1.18509599 1.000000e+00
> >       > -0.58941683 -0.61972416 9.999998e-01
> >       > -4.57559611 -2.30914920 9.995711e-01
> >       > -0.82610544 -0.39347576 9.995711e-01
> >       > -0.02768220  0.20076910 9.995711e-01
> >       >  0.78186399  0.25690215 9.995711e-01
> >       > -0.88314153 -0.20200148 5.000000e-01
> >       > -4.17076452 -2.03547588 5.000000e-01
> >       >  0.93373070  0.54190626 4.289362e-04
> >       > -0.08517734  0.17692491 4.289362e-04
> >       > -4.47546619 -2.14876688 4.289362e-04
> >       > -1.65509103 -0.76898087 4.289362e-04
> >       > -0.39403030 -0.12689705 4.289362e-04
> >       >  0.01203300 -0.18689898 1.841442e-07
> >       > -4.82762639 -2.31391121 1.841442e-07
> >       > -0.72658380 -0.39751171 3.397282e-14
> >       > -2.35886866 -1.01082109 0.000000e+00
> >       > -2.03762707 -0.96439902 0.000000e+00
> >       >  0.90115123  0.60172286 0.000000e+00
> >       >  1.55999194  0.83433953 0.000000e+00
> >       >  3.07994058  1.30942776 0.000000e+00
> >       >  1.78871462  1.10605530 0.000000e+00
> >       >
> >       >
> >       >
> >       > Running simple linear model returns:
> >       >
> >       > > lm(y~x,data=df)
> >       >
> >       > Call:
> >       > lm(formula = y ~ x, data = df)
> >       >
> >       > Coefficients:
> >       > (Intercept)            x
> >       >    -0.04173      2.03790
> >       >
> >       > and
> >       > > max(resid(lm(y~x,data=df)))
> >       > [1] 1.14046
> >       >
> >       >
> >       > *HOWEVER if I use the weighted model then:*
> >       >
> >       > lm(formula = y ~ x, data = df, weights = df$weights)
> >       >
> >       > Coefficients:
> >       > (Intercept)            x
> >       >    -0.05786      1.96087
> >       >
> >       > and
> >       > > max(resid(lm(y~x,data=df,weights=df$weights)))
> >       > [1] 60.91888
> >       >
> >       >
> >       > as you see, the estimation of the coefficients are nearly the
> same
> > but the
> >       > resid() function returns a giant residual (I have some cases
> where
> > the value is
> >       > much much higher). Further, if I calculate the residuals by
> simply
> >       > predict(lm(y~x,data=df,weights=df$weights))-df$y then I get the
> true
> > value for
> >       > the residuals.
> >       >
> >       >
> >       > Thanks.
> >       >
> >       > Please do not hesitate to contact me for more details.
> >       > Regards,
> >       > Hamed.
> >       >
> >       >       [[alternative HTML version deleted]]
> >       >
> >       > ______________________________________________
> >       > R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list --
> > To UNSUBSCRIBE and more, see
> >       > https://stat.ethz.ch/mailman/listinfo/r-help
> >       > PLEASE do read the posting guide
> http://www.R-project.org/posting-
> >       > guide.html
> >       > and provide commented, minimal, self-contained, reproducible
> > code.
> >
>
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep 17 10:07:46 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 17 Sep 2018 01:07:46 -0700
Subject: [R] Data.frame of Different Length
In-Reply-To: <CAC8ss33yoTC1R03t=eHLLBGQO7B5y=rqoQ12nbqsq+Ktd_J2gQ@mail.gmail.com>
References: <CAC8ss33yoTC1R03t=eHLLBGQO7B5y=rqoQ12nbqsq+Ktd_J2gQ@mail.gmail.com>
Message-ID: <1B8E640A-0123-4A3F-B6B3-C7492858E938@dcn.davis.ca.us>

There are many ways to combine data frames, but the method you have chosen is extremely rare because you do not appear to be creating sensible relationships in the rows of the data frame, so your final result seems unlikely to be understandable by normal interpretation of tabular data. See ?merge for more normal ways to combine data frames.

However, with respect to your questions:

1) The usual way to remove a column is to use negative integer indexing:
a <- a[ , -2 ]

2) To add more columns, just do it again with the answer you have. I do think you are taking an over-complicated approach:

n <- max( nrow(d1), nrow(d2), nrow(d3))
ix <- seq.int( n )
a <- data.frame( d1_date=d1$date[ix], d2_date=d2$date[ix], d3_date=d3$date[ix] )

On September 17, 2018 12:17:03 AM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Contributors,
>
>I have two data frame of different column lengths. I am trying to have
>them
>in one data frame.
>Using
>A<-d1$date
>B<-d2$date
>a<-data.table(A )[ , I := .I][data.table(B )[ , I := .I], on = "I"]
>I got
>1: 2005-01-04  1 2005-01-04
> 2: 2005-01-19  2 2005-01-19
> 3: 2005-01-22  3 2005-01-22
> 4: 2005-02-24  4 2005-02-19
> 5: 2005-05-09  5 2005-02-24
> 6: 2005-05-16  6 2005-05-09
> 7: 2005-06-17  7 2005-05-11
> 8: 2005-07-17  8 2005-05-16
> 9: 2005-08-07  9 2005-06-13
>10: 2005-09-11 10 2005-06-17
>11: 2005-09-13 11 2005-06-22
>12: 2005-09-15 12 2005-07-18
>13:         NA 13 2005-08-03
>14:         NA 14 2005-08-07
>15:         NA 15 2005-08-10
>16:         NA 16 2005-08-25
>17:         NA 17 2005-09-13
>18:         NA 18 2005-09-15
>19:         NA 19 2005-10-13
>20:         NA 20 2005-12-15
>which is fine.
>
>I have two more problems:
>1) how to remove the nos 1 to 20 inserted at the middle of the dates.
>
>2) how to include more columns.
>
>I have about 5 columns of different lengths which I wish to have in one
>data frame.
>
>I will remain grateful if assisted.
>
>Best regards
>Ogbos
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From g||ted|||e2014 @end|ng |rom gm@||@com  Mon Sep 17 10:35:54 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Mon, 17 Sep 2018 09:35:54 +0100
Subject: [R] Data.frame of Different Length
In-Reply-To: <1B8E640A-0123-4A3F-B6B3-C7492858E938@dcn.davis.ca.us>
References: <CAC8ss33yoTC1R03t=eHLLBGQO7B5y=rqoQ12nbqsq+Ktd_J2gQ@mail.gmail.com>
 <1B8E640A-0123-4A3F-B6B3-C7492858E938@dcn.davis.ca.us>
Message-ID: <CAC8ss32_cCkcEW_nYeX5Jz30kEHEWY2vqjqqNeSZhjVWFtMx=w@mail.gmail.com>

Dear Jeff,

Yours is like reciting A, B,C or 1, 2, 3 ...

I am greatly relieved.

Many thanks.
Ogbos

On Mon, Sep 17, 2018 at 9:07 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> There are many ways to combine data frames, but the method you have chosen
> is extremely rare because you do not appear to be creating sensible
> relationships in the rows of the data frame, so your final result seems
> unlikely to be understandable by normal interpretation of tabular data. See
> ?merge for more normal ways to combine data frames.
>
> However, with respect to your questions:
>
> 1) The usual way to remove a column is to use negative integer indexing:
> a <- a[ , -2 ]
>
> 2) To add more columns, just do it again with the answer you have. I do
> think you are taking an over-complicated approach:
>
> n <- max( nrow(d1), nrow(d2), nrow(d3))
> ix <- seq.int( n )
> a <- data.frame( d1_date=d1$date[ix], d2_date=d2$date[ix],
> d3_date=d3$date[ix] )
>
> On September 17, 2018 12:17:03 AM PDT, Ogbos Okike <
> giftedlife2014 at gmail.com> wrote:
> >Dear Contributors,
> >
> >I have two data frame of different column lengths. I am trying to have
> >them
> >in one data frame.
> >Using
> >A<-d1$date
> >B<-d2$date
> >a<-data.table(A )[ , I := .I][data.table(B )[ , I := .I], on = "I"]
> >I got
> >1: 2005-01-04  1 2005-01-04
> > 2: 2005-01-19  2 2005-01-19
> > 3: 2005-01-22  3 2005-01-22
> > 4: 2005-02-24  4 2005-02-19
> > 5: 2005-05-09  5 2005-02-24
> > 6: 2005-05-16  6 2005-05-09
> > 7: 2005-06-17  7 2005-05-11
> > 8: 2005-07-17  8 2005-05-16
> > 9: 2005-08-07  9 2005-06-13
> >10: 2005-09-11 10 2005-06-17
> >11: 2005-09-13 11 2005-06-22
> >12: 2005-09-15 12 2005-07-18
> >13:         NA 13 2005-08-03
> >14:         NA 14 2005-08-07
> >15:         NA 15 2005-08-10
> >16:         NA 16 2005-08-25
> >17:         NA 17 2005-09-13
> >18:         NA 18 2005-09-15
> >19:         NA 19 2005-10-13
> >20:         NA 20 2005-12-15
> >which is fine.
> >
> >I have two more problems:
> >1) how to remove the nos 1 to 20 inserted at the middle of the dates.
> >
> >2) how to include more columns.
> >
> >I have about 5 columns of different lengths which I wish to have in one
> >data frame.
> >
> >I will remain grateful if assisted.
> >
> >Best regards
> >Ogbos
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From kry|ov@r00t @end|ng |rom gm@||@com  Mon Sep 17 10:42:08 2018
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 17 Sep 2018 11:42:08 +0300
Subject: [R] Help with setting locale
In-Reply-To: <CAE9q8vk7huCkPSp3yQcSOWRGbODxB0t20Urqd-UssrRVsciK5w@mail.gmail.com>
References: <CAE9q8vnMUZnP-Pm2+P9puUezdq5CSPLfVs8bFZQomRhC7PA9vw@mail.gmail.com>
 <20180916192158.2a45b3fb@Tarkus>
 <CAE9q8vk7huCkPSp3yQcSOWRGbODxB0t20Urqd-UssrRVsciK5w@mail.gmail.com>
Message-ID: <20180917114208.3821dd0d@Tarkus>

On Sun, 16 Sep 2018 21:18:45 +0200
Kim Titcombe <ktitcombe02 at gmail.com> wrote:

> I have Windows 10. English version.

Do you have any other problems, besides the warning message at startup?

According to MSDN[1], the combination of English language
and Swiss cultural rules should be supported in Windows 10 >=
v1607 with a call like Sys.setlocale(locale="English_Switzerland"). If
that doesn't work, Sys.setlocale(locale="English") seemed to work even
on my Windows 2008 machine[2]. However, for some reason, when I call
setlocale() with two-letter arguments exactly as described on that page
("en-US", "en-CH", etc) the call fails.

-- 
Best regards,
Ivan

[1]: https://msdn.microsoft.com/library/cc233982.aspx

[2]: Also worked:

> Sys.setlocale(locale="English_United States")
[1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> Sys.setlocale(locale="English_United Kingdom")
[1] "LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252"



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Mon Sep 17 11:41:17 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Mon, 17 Sep 2018 12:41:17 +0300
Subject: [R] constraints are inconsistent, no solution!
Message-ID: <CAJxz9NaP8WoVhMP6sCOE=ea72omJ+-nZGVFKo09-yW9aTLZiew@mail.gmail.com>

Hi!

I'm solving a quadratic programming problem with some constraints. The
problem is the second set of Amat conditions, which seem to be
inconsistent, but I cannot see why. Do you have any idea, what could be the
problem?

Thanks in advance for your help!
Maija


for(j in 1:J){
  hs[j] <-(-(gEst$KernelRegPartLin..Phi[j]^(-1.2)))
}
hs

Dmat <- matrix(0,nrow= J, ncol=J)
diag(Dmat) <- 1
dvec <- -hs
Aeq <- 0
beq <- 0
Amat <- matrix(0,J,2*J-3)
bvec <- matrix(0,2*J-3,1)

for(j in 2:nrow(Amat)){
  Amat[j-1,j-1] = -1
  Amat[j,j] = 1
}

for(j in 3:nrow(Amat)){
  Amat[j,J-1+j-2] = -1/(Q[j]-Q[j-1])
  Amat[j-1,J-1+j-2] = 1/(Q[j]-Q[j-1])
  Amat[j-2,J-1+j-2] = -1/(Q[j-1]-Q[j-2])
}

for(j in 2:ncol(bvec)) {
  bvec[j-1] = Delta1
}

for(j in 3:ncol(bvec)) {
  bvec[J-1+j-2] = Delta2
}

solution <- solve.QP(Dmat,dvec,Amat,bvec=bvec)
solution

	[[alternative HTML version deleted]]



From @|m|n@@t@work @end|ng |rom gm@||@com  Mon Sep 17 16:22:36 2018
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Mon, 17 Sep 2018 10:22:36 -0400
Subject: [R] 
 [FORGED] Re: Change the position of label when using R package
 eulerr
In-Reply-To: <6de0953e-2ba4-70d9-e24c-a9025362c030@stat.auckland.ac.nz>
References: <CALn2QVj=LSufTygGLVbqWRCj_2i+BJb8bpCWWpBE-6YisxPL5g@mail.gmail.com>
 <CFAF276F-2B34-4CF9-8A00-59B3B7DE9E16@comcast.net>
 <CALn2QVit6=Dc3TwWRdsiMjWNEEAzmwEt7ypO08Y80j6DM-fuQQ@mail.gmail.com>
 <6de0953e-2ba4-70d9-e24c-a9025362c030@stat.auckland.ac.nz>
Message-ID: <CALn2QVj1PZsp-MRJR-W9uEfVxruU7bMJ-_Tt8MWYBpWdA_K=xw@mail.gmail.com>

Yes, it does. Thank you.

Aimin

On Sun, Sep 16, 2018 at 11:00 PM Paul Murrell <paul at stat.auckland.ac.nz>
wrote:

> Hi
>
> The 'x' component of the 't' grob that you get back from grid.get() is a
> unit object, which you can subset and assign to a subset, for example
> this code nudges the fourth label up and to the right 1mm in each
> direction ...
>
>
> x <- t$x
> y <- t$y
>
> x[4] <- t$x[4] + unit(1, "mm")
> y[4] <- t$y[4] + unit(1, "mm")
>
> grid.edit("quantities.grob", x=x, y=y)
>
>
> ... is that the sort of thing you were looking for ?
>
> Paul
>
> On 15/09/18 09:03, Aimin Yan wrote:
> > Thank you,
> >
> > I figure out a way like this:
> >
> > fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >                      "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> > "LAD&nonXL_MEF" = 541,
> >                      "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> >
> > plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
> list(font
> > = 1),alpha=0.7)
> >
> > grid.ls()
> > t <- grid.get("quantities.grob")
> > names(t)
> >
> > # Change these value will change the location of label.
> >
> > grid.edit("quantities.grob",x=unit.c(unit(-14.9884684724791, "native"),
> >                                           unit(-14.883684319653,
> "native"),
> >                                           unit(13.9805892820006,
> "native"),
> >                                           unit(-12.8808987356981,
> "native"),
> >                                           unit(-11.488226371243,
> "native"),
> >                                           unit(-9.51474016085318,
> "native"),
> >                                           unit(-1.00436055190216,
> "native")))
> >
> > grid.edit("quantities.grob",y=unit.c(unit(-8.07672595120493, "native"),
> >                                           unit(4.78718651828883,
> "native"),
> >                                           unit(0.25941593099694,
> "native"),
> >                                           unit(-4.32200781461293,
> "native"),
> >                                           unit(25.7349463488991,
> "native"),
> >                                           unit(-22.7610031110325,
> "native"),
> >                                           unit(14.5001560838519,
> "native")))
> >
> > However, here I just want to change the x and y  value of 4th label, does
> > anyone know how to set it?
> >
> > Aimin
> >
> > On Thu, Sep 13, 2018 at 9:56 PM David Winsemius <dwinsemius at comcast.net>
> > wrote:
> >
> >>
> >>> On Sep 13, 2018, at 2:31 PM, Aimin Yan <aimin.at.work at gmail.com>
> wrote:
> >>>
> >>> I am using eulerr to get venn.
> >>> My code is like:
> >>>
> >>> fit1 <- euler(c("ciLAD" = 785, "LAD" = 565, "nonXL_MEF" = 167,
> >>>                     "ciLAD&LAD" = 3, "ciLAD&nonXL_MEF" = 101,
> >>> "LAD&nonXL_MEF" = 541,
> >>>                     "ciLAD&LAD&nonXL_MEF" = 2),shape = "ellipse")
> >>>
> >>> plot(fit1,quantities = TRUE,fill = rainbow(7),lty = 1:2,labels =
> >> list(font
> >>> = 1),alpha=0.7)
> >>>
> >>> After I get the figure, I find the position of some  labels need to be
> >>> adjusted.
> >>>
> >>> Does anyone has some idea about how to process this?
> >>
> >> Looking at the code of plot.euler we see that the plotting paradigm is
> >> grid. So you could assign the output to a data.object name, search for
> list
> >> items that match the names of the labels you want to reposition, and
> modify
> >> the position values. You would need to be more specific, if you want a
> >> worked example.
> >>
> >> As far as I can see the lables and postions are fairly deep inside a
> list
> >> structure:
> >>
> >>   $ children     :List of 1
> >>    ..$ GRID.gTree.12:List of 5
> >>    .. ..$ children
> >>           $ diagram.grob.1
> >>              $children
> >> .. .. .. .. ..$ labels.grob    :List of 11
> >>    .. .. .. .. .. ..$ label        : chr [1:3] "ciLAD" "LAD" "nonXL_MEF"
> >>    .. .. .. .. .. ..$ x            : 'unit' num [1:3] -18.1native
> >> 69.2native 11.9native
> >>    .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >>    .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> >>    .. .. .. .. .. ..$ y            : 'unit' num [1:3] -17.86native
> >> 5.24native 27.86native
> >>    .. .. .. .. .. .. ..- attr(*, "valid.unit")= int 4
> >>    .. .. .. .. .. .. ..- attr(*, "unit")= chr "native"
> >>
> >> --
> >> David.
> >>>
> >>>
> >>> Thank you,
> >>>
> >>> Aimin
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >> 'Any technology distinguishable from magic is insufficiently advanced.'
> >>   -Gehm's Corollary to Clarke's Third Law
> >>
> >>
> >>
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>

	[[alternative HTML version deleted]]



From |e|@||u @end|ng |rom wu@t|@edu  Mon Sep 17 17:29:48 2018
From: |e|@||u @end|ng |rom wu@t|@edu (Liu, Lei)
Date: Mon, 17 Sep 2018 15:29:48 +0000
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <894A4868-409A-44DA-A8D8-2C6CE7F252A6@dcn.davis.ca.us>
References: <SN4PR0201MB340568ED119F5665F16A9386F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <894A4868-409A-44DA-A8D8-2C6CE7F252A6@dcn.davis.ca.us>
Message-ID: <SN4PR0201MB340523E42114316FC94E7837F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>

Thanks for the help. My friend helped me and here is the solution:

boot.cluster <- function(x, id){
  boot.id <- sample(unique(id), replace=T)
  out <- lapply(1:length(boot.id), function(newid){cbind(x[id%in%boot.id[newid],],newid)})
  return( do.call("rbind",out) )
}

Lei

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Monday, September 17, 2018 2:32 AM
To: r-help at r-project.org; Liu, Lei <lei.liu at wustl.edu>; r-help at R-project.org
Subject: Re: [R] bootstrap sample for clustered data

You are telling us that the ID values in your data set indicate clusters. However you went about making that determination in the first place might be an obvious(?) way to do it again with your bootstrapped sample, ignoring the cluster assignments you have in place. This is the wrong place to have a discussion about which theoretical method for cluster identification you should use, and if you do know that then searching the web or using the sos package would be the appropriate way to find implementations of a specific clustering algorithm.

I am not an ME expert, but AFAIK "complicated" analyses such as mixed effects models tend to have rather hefty appetites for data completeness, so you may have to design a special sampling plan in order to avoid generating data sets for which those analyses won't break, and you will probably need a very large data set to start with in order to have sufficient data in each cluster. That is, you may be better off keeping the original cluster identification and just restructuring your bootstrap sampling to sample within clusters.

The R-sig-me mailing list is probably a better venue for your questions. 

On September 16, 2018 8:22:44 PM PDT, "Liu, Lei" <lei.liu at wustl.edu> wrote:
>Hi there,
>
>I posted this message before but there may be some confusion in my 
>previous post. So here is a clearer version:
>
>I'd like to do a bootstrap sampling for clustered data. Then I will run 
>some complicated models (say mixed effects models) on the bootstrapped 
>sample. Here id is the cluster. Note different clusters have different 
>number of subjects, e.g., id 2 has 2 observations, id 3 has 3 
>observations.
>
>id=c(1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5) y=c(.5, .6, .4, .3, .4, 1, .9, 
>1, .5, 2, 2.2, 3) x=c(0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1 )
>
>xx=data.frame(id, x, y)
>
>boot.cluster <- function(x, id){
>
>  boot.id <- sample(unique(id), replace=T)  out <- lapply(boot.id, 
> function(i) x[id%in%i,])
>
>  return( do.call("rbind",out) )
>
>}
>
>boot.xx=boot.cluster(xx, xx$id)
>
>Here is the generated boot.xx dataset:
>
>   id x y
>   3 0 0.4
>   3 0 1.0
>   3 0 0.9
>   1 0 0.5
>   1 0 0.6
>   5 1 2.2
>   5 1 3.0
>   2 1 0.4
>   2 1 0.3
>   1 0 0.5
>   1 0 0.6
>
>You can see that some clusters (ids) appears multiple times (e.g., id 1 
>appears in two places - 4 rows), since bootstrap does a sample with 
>replacement, we could have the same cluster multiple times. Thus, we 
>cannot do a mixed effects model using this data, as we should assume 
>all the clusters are different in this new data. Instead, I will 
>reorganize the data as below (id is reordered from the above boot.xx 
>data). This is the step I need help:
>
>  id x  y
>   1 0 0.4
>   1 0 1.0
>   1 0 0.9
>   2 0 0.5
>   2 0 0.6
>   3 1 2.2
>   3 1 3.0
>   4 1 0.4
>   4 1 0.3
>   5 0 0.5
>   5 0 0.6
>
>Can someone help me with it? Thanks!
>
>Lei Liu
>Professor of Biostatistics
>Washington University in St. Louis
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

From rj@|nnet @end|ng |rom gm@||@com  Mon Sep 17 18:14:47 2018
From: rj@|nnet @end|ng |rom gm@||@com (RUPJYOTI DAS)
Date: Mon, 17 Sep 2018 21:44:47 +0530
Subject: [R] Unable to update R 3.4 to R 3.5 in Ubuntu 18.04 LTS
Message-ID: <CAMo+egkiwPriFXCbSvMH3234BEitjBMxuwmYBC4gEjPdzUqA8g@mail.gmail.com>

Dear All,
I am using R to carry out RNA-Seq workflow in my standalone machine which
needs the latest R version >=3.5. I was trying to update firstly removing
the R 3.4 and reinstalling from scratch again the latest version. Can
anybody just guide me how to carry out the process as I am getting only R
3.4 again and again.
Also when I remove the
*deb ... bionic-cran35 (mirror for R cran )*

from the* source.list* file (opened by* sudo gedit /etc/apt/sources.list*)
the command *sudo apt-get update* works fine which does not upgrade the R
3.4 to R 3.5.1.
Adding the line
*deb ... bionic-cran35/ *
gives the attached error log*. **Please find the attached file and  do
check.*

Any answers and suggestions will be of immense help!

Thanking you!

*Rupjyoti Das*
*M.Tech*, Information Technology
Tezpur University
Assam, India 784028
Mob. +91-8812807195


From j|ox @end|ng |rom mcm@@ter@c@  Mon Sep 17 19:16:19 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 17 Sep 2018 17:16:19 +0000
Subject: [R] Problem with lm.resid() when weights are provided
In-Reply-To: <CAAC89xdt93_tGBsLrHQqMjjAA9uEJ2eRH4ptiVz0gWJ2CJa8VA@mail.gmail.com>
References: <CAAC89xdXe5NEBeTjF+2znVB9bij6cH4EXOJsb-43+ZZxKpKjzQ@mail.gmail.com>
 <22333_1536669565_w8BCdOUV005487_CAAC89xeH6WyQ+GMKs6KKxC4LzPbr4zkVMg_NJ4_key_Q0SUuyg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368B0E61@FHSDB2D11-2.csu.mcmaster.ca>
 <CAAC89xexc0tHnC8n_n0Z+=3xtPDFmB394=U75V3KLe9RQ6OWdA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8368B12FB@FHSDB2D11-2.csu.mcmaster.ca>
 <CAAC89xdt93_tGBsLrHQqMjjAA9uEJ2eRH4ptiVz0gWJ2CJa8VA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368CC82D@FHSDB2D11-2.csu.mcmaster.ca>

Dear Hamed,

> -----Original Message-----
> From: Hamed Ha [mailto:hamedhaseli at gmail.com]
> Sent: Monday, September 17, 2018 3:56 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help at r-project.org
> Subject: Re: [R] Problem with lm.resid() when weights are provided
> 
> H i John,
> 
> 
> Thank you for your reply.
> 
> 
> I see your point, thanks. I checked lm.wfit() and realised that there is a tol
> parameter that is already set to 10^-7. This is not even the half decimal to the
> machine precision. Furthermore, plying with tol parameter does not solve the
> problem, as far as I checked.

tol plays a different role in lm.wfit(). It's for the QR decomposition (done in C code), I suppose to determine the rank of the weighted model matrix. Generally in this kind of context, you'd use something like the square root of the machine double epsilon to define a number that's effectively 0, and the tolerance used here isn't too far off that -- about an order of magnitude larger.
 
I'm not an expert in computer arithmetic or numerical linear algebra, so I don't have anything more to say about this.

> 
> 
> I still see this issue as critical and we should report it to the R core team to be
> investigated more. What do you think?

I don't think that it's a critical issue because it isn't sensible to specify nonzero weights so close to 0. A simple solution is to change these weights to 0 in your code calling lm().

That said, I suppose that it might be better to make lm.wfit() more robust to near-zero weights. If you feel strongly about this, you can file a bug report, but I'm not interested in pursuing it.

Best,
 John

> 
> 
> Regards,
> Hamed.
> 
> 
> On Fri, 14 Sep 2018 at 22:46, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Hamed,
> 
> 	When you post a question to r-help, generally you should cc
> subsequent messages there as well, as I've done to this response.
> 
> 	The algorithm that lm() uses is much more numerically stable than
> inverting the weighted sum-of-squares-and-product matrix. If you want to see
> how the computations are done, look at lm.wfit(), in which the residuals and
> fits are computed as
> 
> 	    z$residuals <- z$residuals/wts
> 	    z$fitted.values <- y - z$residuals
> 
> 	Zero weights are handled specially, and your tiny weights are thus the
> source of the problem. When you divide by a number less than the machine
> double-epsilon, you can't expect numerically stable results. I suppose that
> lm.wfit() could check for 0 weights to a tolerance rather than exactly.
> 
> 	John
> 
> 	> -----Original Message-----
> 	> From: Hamed Ha [mailto:hamedhaseli at gmail.com
> <mailto:hamedhaseli at gmail.com> ]
> 	> Sent: Friday, September 14, 2018 5:34 PM
> 	> To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> >
> 	> Subject: Re: [R] Problem with lm.resid() when weights are provided
> 	>
> 	> Hi John,
> 	>
> 	> Thank you for your reply.
> 	>
> 	> I agree that the small weights are the potential source of the
> instability in the
> 	> result. I also suspected that there are some failure/bugs in the actual
> 	> algorithm that R uses for fitting the model. I remember that at some
> points I
> 	> checked the theoretical estimation of the parameters, solve(t(x)
> %*% w %*%
> 	> x) %*% t(x) %*% w %*% y, (besides the point that I had to set tol
> parameter in
> 	> solve() to a super small value) and realised  that lm() and the
> theoretical
> 	> results match together. That is the parameter estimation is right in
> R.
> 	> Moreover, I checked the predictions, predict(lm.fit), and it was right.
> Then the
> 	> only source of error remained was resid() function. I further checked
> this
> 	> function and it is nothing more than calling a sub-element from and
> lm() fit.
> 	> Putting all together, I think that there is something wrong/bug/miss-
> 	> configuration in the lm() algorithm and I highly recommend the R
> core team to
> 	> fix that.
> 	>
> 	> Please feel free to contact me for more details if required.
> 	>
> 	> Warm regards,
> 	> Hamed.
> 	>
> 	>
> 	>
> 	>
> 	>
> 	>
> 	>
> 	>
> 	>
> 	> On Fri, 14 Sep 2018 at 13:35, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca>
> 	> <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > > wrote:
> 	>
> 	>
> 	>       Dear Hamed,
> 	>
> 	>       I don't think that anyone has picked up on this problem.
> 	>
> 	>       What's peculiar about your weights is that several are 0 within
> 	> rounding error but not exactly 0:
> 	>
> 	>       > head(df)
> 	>                  y          x       weight
> 	>       1  1.5115614  0.5520924 2.117337e-34
> 	>       2 -0.6365313 -0.1259932 2.117337e-34
> 	>       3  0.3778278  0.4209538 4.934135e-31
> 	>       4  3.0379232  1.4031545 2.679495e-24
> 	>       5  1.5364652  0.4607686 2.679495e-24
> 	>       6 -2.3772787 -0.7396358 6.244160e-21
> 	>
> 	>       I can reproduce the results that you report:
> 	>
> 	>       > (mod.1 <- lm(y ~ x, data=df))
> 	>
> 	>       Call:
> 	>       lm(formula = y ~ x, data = df)
> 	>
> 	>       Coefficients:
> 	>       (Intercept)            x
> 	>          -0.04173      2.03790
> 	>
> 	>       > max(resid(mod.1))
> 	>       [1] 1.14046
> 	>       > (mod.2 <- lm(y ~ x, data=df, weights=weight))
> 	>
> 	>       Call:
> 	>       lm(formula = y ~ x, data = df, weights = weight)
> 	>
> 	>       Coefficients:
> 	>       (Intercept)            x
> 	>          -0.05786      1.96087
> 	>
> 	>       > max(resid(mod.2))
> 	>       [1] 36.84939
> 	>
> 	>       But the problem disappears when the tiny nonzero weight are set
> to 0:
> 	>
> 	>       > df2 <- df
> 	>       > df2$weight <- zapsmall(df2$weight)
> 	>       > head(df2)
> 	>                  y          x weight
> 	>       1  1.5115614  0.5520924      0
> 	>       2 -0.6365313 -0.1259932      0
> 	>       3  0.3778278  0.4209538      0
> 	>       4  3.0379232  1.4031545      0
> 	>       5  1.5364652  0.4607686      0
> 	>       6 -2.3772787 -0.7396358      0
> 	>       > (mod.3 <- update(mod.2, data=df2))
> 	>
> 	>       Call:
> 	>       lm(formula = y ~ x, data = df2, weights = weight)
> 	>
> 	>       Coefficients:
> 	>       (Intercept)            x
> 	>          -0.05786      1.96087
> 	>
> 	>       > max(resid(mod.3))
> 	>       [1] 1.146663
> 	>
> 	>       I don't know exactly why this happens, but suspect numerical
> 	> instability produced by the near-zero weights, which are smaller
> than the
> 	> machine double-epsilon
> 	>
> 	>       > .Machine$double.neg.eps
> 	>       [1] 1.110223e-16
> 	>
> 	>       The problem also disappears, e.g., if the tiny weight are set to 1e-
> 15
> 	> rather than 0.
> 	>
> 	>       I hope this helps,
> 	>        John
> 	>
> 	>       -----------------------------------------------------------------
> 	>       John Fox
> 	>       Professor Emeritus
> 	>       McMaster University
> 	>       Hamilton, Ontario, Canada
> 	>       Web: https://socialsciences.mcmaster.ca/jfox/
> 	>
> 	>
> 	>
> 	>       > -----Original Message-----
> 	>       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-
> help-bounces at r-project.org>  <mailto:r-help- <mailto:r-help->
> 	> bounces at r-project.org <mailto:bounces at r-project.org> > ] On
> Behalf Of Hamed Ha
> 	>       > Sent: Tuesday, September 11, 2018 8:39 AM
> 	>       > To: r-help at r-project.org <mailto:r-help at r-project.org>
> <mailto:r-help at r-project.org <mailto:r-help at r-project.org> >
> 	>       > Subject: [R] Problem with lm.resid() when weights are provided
> 	>       >
> 	>       > Dear R Help Team.
> 	>       >
> 	>       > I get some weird results when I use the lm function with weight.
> The
> 	> issue can
> 	>       > be reproduced by the example below:
> 	>       >
> 	>       >
> 	>       > The input data is (weights are intentionally designed to reflect
> some
> 	>       > structures in the data)
> 	>       >
> 	>       >
> 	>       > > df
> 	>       > y x weight
> 	>       >  1.51156139  0.55209240 2.117337e-34
> 	>       > -0.63653132 -0.12599316 2.117337e-34
> 	>       >  0.37782776  0.42095384 4.934135e-31
> 	>       >  3.03792318  1.40315446 2.679495e-24
> 	>       >  1.53646523  0.46076858 2.679495e-24
> 	>       > -2.37727874 -0.73963576 6.244160e-21
> 	>       >  0.37183065  0.20407468 1.455107e-17
> 	>       > -1.53917553 -0.95519361 1.455107e-17
> 	>       >  1.10926675  0.03897129 3.390908e-14
> 	>       > -0.37786333 -0.17523593 3.390908e-14
> 	>       >  2.43973603  0.97970095 7.902000e-11
> 	>       > -0.35432394 -0.03742559 7.902000e-11
> 	>       >  2.19296613  1.00355263 4.289362e-04
> 	>       >  0.49845532  0.34816207 4.289362e-04
> 	>       >  1.25005260  0.76306225 5.000000e-01
> 	>       >  0.84360691  0.45152356 5.000000e-01
> 	>       >  0.29565993  0.53880068 5.000000e-01
> 	>       > -0.54081334 -0.28104525 5.000000e-01
> 	>       >  0.83612836 -0.12885659 9.995711e-01
> 	>       > -1.42526769 -0.87107631 9.999998e-01
> 	>       >  0.10204789 -0.11649899 1.000000e+00
> 	>       >  1.14292898  0.37249631 1.000000e+00
> 	>       > -3.02942081 -1.28966997 1.000000e+00
> 	>       > -1.37549764 -0.74676145 1.000000e+00
> 	>       > -2.00118016 -0.55182759 1.000000e+00
> 	>       > -4.24441674 -1.94603608 1.000000e+00
> 	>       >  1.17168144  1.00868008 1.000000e+00
> 	>       >  2.64007761  1.26333069 1.000000e+00
> 	>       >  1.98550114  1.18509599 1.000000e+00
> 	>       > -0.58941683 -0.61972416 9.999998e-01
> 	>       > -4.57559611 -2.30914920 9.995711e-01
> 	>       > -0.82610544 -0.39347576 9.995711e-01
> 	>       > -0.02768220  0.20076910 9.995711e-01
> 	>       >  0.78186399  0.25690215 9.995711e-01
> 	>       > -0.88314153 -0.20200148 5.000000e-01
> 	>       > -4.17076452 -2.03547588 5.000000e-01
> 	>       >  0.93373070  0.54190626 4.289362e-04
> 	>       > -0.08517734  0.17692491 4.289362e-04
> 	>       > -4.47546619 -2.14876688 4.289362e-04
> 	>       > -1.65509103 -0.76898087 4.289362e-04
> 	>       > -0.39403030 -0.12689705 4.289362e-04
> 	>       >  0.01203300 -0.18689898 1.841442e-07
> 	>       > -4.82762639 -2.31391121 1.841442e-07
> 	>       > -0.72658380 -0.39751171 3.397282e-14
> 	>       > -2.35886866 -1.01082109 0.000000e+00
> 	>       > -2.03762707 -0.96439902 0.000000e+00
> 	>       >  0.90115123  0.60172286 0.000000e+00
> 	>       >  1.55999194  0.83433953 0.000000e+00
> 	>       >  3.07994058  1.30942776 0.000000e+00
> 	>       >  1.78871462  1.10605530 0.000000e+00
> 	>       >
> 	>       >
> 	>       >
> 	>       > Running simple linear model returns:
> 	>       >
> 	>       > > lm(y~x,data=df)
> 	>       >
> 	>       > Call:
> 	>       > lm(formula = y ~ x, data = df)
> 	>       >
> 	>       > Coefficients:
> 	>       > (Intercept)            x
> 	>       >    -0.04173      2.03790
> 	>       >
> 	>       > and
> 	>       > > max(resid(lm(y~x,data=df)))
> 	>       > [1] 1.14046
> 	>       >
> 	>       >
> 	>       > *HOWEVER if I use the weighted model then:*
> 	>       >
> 	>       > lm(formula = y ~ x, data = df, weights = df$weights)
> 	>       >
> 	>       > Coefficients:
> 	>       > (Intercept)            x
> 	>       >    -0.05786      1.96087
> 	>       >
> 	>       > and
> 	>       > > max(resid(lm(y~x,data=df,weights=df$weights)))
> 	>       > [1] 60.91888
> 	>       >
> 	>       >
> 	>       > as you see, the estimation of the coefficients are nearly the
> same
> 	> but the
> 	>       > resid() function returns a giant residual (I have some cases
> where
> 	> the value is
> 	>       > much much higher). Further, if I calculate the residuals by
> simply
> 	>       > predict(lm(y~x,data=df,weights=df$weights))-df$y then I get the
> true
> 	> value for
> 	>       > the residuals.
> 	>       >
> 	>       >
> 	>       > Thanks.
> 	>       >
> 	>       > Please do not hesitate to contact me for more details.
> 	>       > Regards,
> 	>       > Hamed.
> 	>       >
> 	>       >       [[alternative HTML version deleted]]
> 	>       >
> 	>       > ______________________________________________
> 	>       > R-help at r-project.org <mailto:R-help at r-project.org>
> <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing list --
> 	> To UNSUBSCRIBE and more, see
> 	>       > https://stat.ethz.ch/mailman/listinfo/r-help
> 	>       > PLEASE do read the posting guide http://www.R-
> project.org/posting-
> 	>       > guide.html
> 	>       > and provide commented, minimal, self-contained, reproducible
> 	> code.
> 	>
> 
> 


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep 17 20:54:28 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 17 Sep 2018 11:54:28 -0700 (PDT)
Subject: [R] Applying by() when groups have different lengths
Message-ID: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>

   My dataframe has 113K rows split by a factor into 58 separate data.frames,
with a different numbers of rows (see error output below).

   I cannot think of a way of proving a sample of data; if a sample for a MWE
is desired advice on produing one using dput() is needed.

   To summarize each group within this dataframe I'm using by() and getting
an error because of the different number of rows:

> by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
+ mean.rain <- mean(rainfall_by_site[, 'prcp'])
+ })
Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  :
   arguments imply differing number of rows: 4900, 1085, 1894, 2844, 3520,
  647, 239, 3652, 3701, 3063, 176, 4713, 4887, 119, 165, 1221, 3358, 1457,
  4896, 166, 690, 1110, 212, 1727, 227, 236, 1175, 1485, 186, 769, 139, 203,
  2727, 4357, 1035, 1329, 1454, 973, 4536, 208, 350, 125, 3437, 731, 4894,
  2598, 2419, 752, 427, 136, 685, 4849, 914, 171

   My web searches have not found anything relevant; perhaps my search terms
(such as 'R: apply by() with different factor row numbers') can be improved.

   The help pages found using apropos('by') appear the same: ?by,
?by.data.frame, ?by.default and provide no hint on how to work with unequal
rows per factor.

   How can I apply by() on these data.frames?

Rich



From wdun|@p @end|ng |rom t|bco@com  Mon Sep 17 21:25:50 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 17 Sep 2018 12:25:50 -0700
Subject: [R] Applying by() when groups have different lengths
In-Reply-To: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcahiUWXnwMO7LV+jOmmYGahO5m_GUtp8imdWuaG5Mqzng@mail.gmail.com>

>
> by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
>
+ mean.rain <- mean(rainfall_by_site[, 'prcp'])
+ })

Note that you define a function of x which does not use x in it.
Hence, even if the function gave a value, it would give the same
value for each group.  To see what the 'x' in that function will
be, use the identity function:

> d <- data.frame(X=2^(0:5), Y=2^(6:11), Group=c("A","B","C","A","B","A"))
> by(d[,1:2], d$Group, function(x)x)
d$Group: A
   X    Y
1  1   64
4  8  512
6 32 2048
------------------------------------------------------------
d$Group: B
   X    Y
2  2  128
5 16 1024
------------------------------------------------------------
d$Group: C
  X   Y
3 4 256

I suspect you want to use the aggregate function.

> aggregate(d[,1:2], list(Group=d$Group), sum)
  Group  X    Y
1     A 41 2624
2     B 18 1152
3     C  4  256

or the functions in the dplyr package:

> d %>% group_by(Group) %>% summarize(sumX=sum(X), meanY=mean(Y))
# A tibble: 3 x 3
  Group  sumX meanY
  <fct> <dbl> <dbl>
1 A        41  875.
2 B        18  576
3 C         4  256






Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Sep 17, 2018 at 11:54 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>   My dataframe has 113K rows split by a factor into 58 separate
> data.frames,
> with a different numbers of rows (see error output below).
>
>   I cannot think of a way of proving a sample of data; if a sample for a
> MWE
> is desired advice on produing one using dput() is needed.
>
>   To summarize each group within this dataframe I'm using by() and getting
> an error because of the different number of rows:
>
> by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
>>
> + mean.rain <- mean(rainfall_by_site[, 'prcp'])
> + })
> Error in (function (..., row.names = NULL, check.rows = FALSE, check.names
> = TRUE,  :
>   arguments imply differing number of rows: 4900, 1085, 1894, 2844, 3520,
>  647, 239, 3652, 3701, 3063, 176, 4713, 4887, 119, 165, 1221, 3358, 1457,
>  4896, 166, 690, 1110, 212, 1727, 227, 236, 1175, 1485, 186, 769, 139, 203,
>  2727, 4357, 1035, 1329, 1454, 973, 4536, 208, 350, 125, 3437, 731, 4894,
>  2598, 2419, 752, 427, 136, 685, 4849, 914, 171
>
>   My web searches have not found anything relevant; perhaps my search terms
> (such as 'R: apply by() with different factor row numbers') can be
> improved.
>
>   The help pages found using apropos('by') appear the same: ?by,
> ?by.data.frame, ?by.default and provide no hint on how to work with unequal
> rows per factor.
>
>   How can I apply by() on these data.frames?
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Mon Sep 17 21:26:38 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 17 Sep 2018 19:26:38 +0000
Subject: [R] Applying by() when groups have different lengths
In-Reply-To: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
Message-ID: <604AEC5B-08C4-4467-8A7B-EB74A6DA300E@llnl.gov>

Try changing it to 

     by(rainfall_by_site, rainfall_by_site[, 'name'],
    function(x) {mean.rain <- mean(x[, 'prcp'])
     })

Inside the function, so to speak, the function sees an object named "x", because that's how the function is defined:  function(x).
So you have to operate on x inside the function.  

For sure, the fact that the subgroups have different numbers of rows is not the problem.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/17/18, 11:54 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       My dataframe has 113K rows split by a factor into 58 separate data.frames,
    with a different numbers of rows (see error output below).
    
       I cannot think of a way of proving a sample of data; if a sample for a MWE
    is desired advice on produing one using dput() is needed.
    
       To summarize each group within this dataframe I'm using by() and getting
    an error because of the different number of rows:
    
    > by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
    + mean.rain <- mean(rainfall_by_site[, 'prcp'])
    + })
    Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  :
       arguments imply differing number of rows: 4900, 1085, 1894, 2844, 3520,
      647, 239, 3652, 3701, 3063, 176, 4713, 4887, 119, 165, 1221, 3358, 1457,
      4896, 166, 690, 1110, 212, 1727, 227, 236, 1175, 1485, 186, 769, 139, 203,
      2727, 4357, 1035, 1329, 1454, 973, 4536, 208, 350, 125, 3437, 731, 4894,
      2598, 2419, 752, 427, 136, 685, 4849, 914, 171
    
       My web searches have not found anything relevant; perhaps my search terms
    (such as 'R: apply by() with different factor row numbers') can be improved.
    
       The help pages found using apropos('by') appear the same: ?by,
    ?by.data.frame, ?by.default and provide no hint on how to work with unequal
    rows per factor.
    
       How can I apply by() on these data.frames?
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From m@cqueen1 @end|ng |rom ||n|@gov  Mon Sep 17 21:35:36 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 17 Sep 2018 19:35:36 +0000
Subject: [R] Applying by() when groups have different lengths
In-Reply-To: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
Message-ID: <C045A3F5-26F3-4F18-8BC1-BF2E163FDB49@llnl.gov>

I'm also going to guess that maybe your object
   rainfall_by_site
has already been split into separate data frames (because of its name).

But by() does the splitting internally, so you should be passing it the original unsplit data frame.

You could supply example data by providing the first few rows of each of the first few groups. That would be enough to test with.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/17/18, 11:54 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       My dataframe has 113K rows split by a factor into 58 separate data.frames,
    with a different numbers of rows (see error output below).
    
       I cannot think of a way of proving a sample of data; if a sample for a MWE
    is desired advice on produing one using dput() is needed.
    
       To summarize each group within this dataframe I'm using by() and getting
    an error because of the different number of rows:
    
    > by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
    + mean.rain <- mean(rainfall_by_site[, 'prcp'])
    + })
    Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  :
       arguments imply differing number of rows: 4900, 1085, 1894, 2844, 3520,
      647, 239, 3652, 3701, 3063, 176, 4713, 4887, 119, 165, 1221, 3358, 1457,
      4896, 166, 690, 1110, 212, 1727, 227, 236, 1175, 1485, 186, 769, 139, 203,
      2727, 4357, 1035, 1329, 1454, 973, 4536, 208, 350, 125, 3437, 731, 4894,
      2598, 2419, 752, 427, 136, 685, 4849, 914, 171
    
       My web searches have not found anything relevant; perhaps my search terms
    (such as 'R: apply by() with different factor row numbers') can be improved.
    
       The help pages found using apropos('by') appear the same: ?by,
    ?by.data.frame, ?by.default and provide no hint on how to work with unequal
    rows per factor.
    
       How can I apply by() on these data.frames?
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 17 21:38:01 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 17 Sep 2018 12:38:01 -0700
Subject: [R] Applying by() when groups have different lengths
In-Reply-To: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbR4q6hG=b_w2Lo6W1=6o-364-mBdMRhnMniMwfSAkt_Gw@mail.gmail.com>

Inline.

Bert



On Mon, Sep 17, 2018 at 11:54 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>    My dataframe has 113K rows split by a factor into 58 separate
> data.frames,
> with a different numbers of rows (see error output below).
>
>    I cannot think of a way of proving a sample of data; if a sample for a
> MWE
> is desired advice on produing one using dput() is needed.
>

This is gibberish. What does "proving a sample of data" mean? etc. Please
proofread and edit.

>
>    To summarize each group within this dataframe I'm using by() and getting
> an error because of the different number of rows:
>

> > by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
> + mean.rain <- mean(rainfall_by_site[, 'prcp'])
> + })
>

You are misspecifying your function. It has argument x, but you do not use
x in your function. Also the assignment at the end is unnecessary and
probably wrong for your use case. Please go through a tutorial on how to
write functions in R.

You are probably also misusing by(), but as you did not provided sufficient
information -- head(your_data_frame) or similar would have told us its
structure, rather than having us guess -- nor a reproducible example, it's
hard (for me) to figure out your intent. **PLEASE** follow the posting
guide and provide such information. You have been requested to do this
several times already.

Here is the sort of thing I think you wanted to do:

> set.seed(54321) ## for reproducibility
> df <- data.frame(f = sample(LETTERS[1:3], 12, rep = TRUE), y = runif(12))
> df
   f          y
1  B 0.04529991
2  B 0.65272100
3  A 0.99406601
4  A 0.67763735
5  A 0.91854517
6  C 0.46244494
7  A 0.57141480
8  A 0.45193882
9  B 0.16770701
10 B 0.06826135
11 A 0.89691069
12 C 0.27383703

> by(df, df$f, function(x)mean(x$y))
df$f: A
[1] 0.7517521
------------------------------------------------------
df$f: B
[1] 0.2334973
------------------------------------------------------
df$f: C
[1] 0.368141

Note that you do not first break up the df into separate df's, which sounds
like what you tried to do.

However, note that if all you want to do is summarize a *single* numeric
column by a factor, you do not need to use by() at all, which is designed
to work on (several columns of) the whole data frame simultaneously. For a
single column, tapply() is all you need (or as Duncan noted, functionality
in the dplyr package.

> with(df,tapply(y,f,mean))
        A         B         C
0.7517521 0.2334973 0.3681410

Finally, if I have misunderstood your intent, my apologies. I tried.

-- Bert



mean.rain <- by(rainfall_by_site, rainfall_by_site[, 'name'], function(x) {
+ mean.rain <- mean(rainfall_by_site[, 'prcp'])
+ })

> Error in (function (..., row.names = NULL, check.rows = FALSE, check.names
> = TRUE,  :
>    arguments imply differing number of rows: 4900, 1085, 1894, 2844, 3520,
>   647, 239, 3652, 3701, 3063, 176, 4713, 4887, 119, 165, 1221, 3358, 1457,
>   4896, 166, 690, 1110, 212, 1727, 227, 236, 1175, 1485, 186, 769, 139,
> 203,
>   2727, 4357, 1035, 1329, 1454, 973, 4536, 208, 350, 125, 3437, 731, 4894,
>   2598, 2419, 752, 427, 136, 685, 4849, 914, 171
>
>    My web searches have not found anything relevant; perhaps my search
> terms
> (such as 'R: apply by() with different factor row numbers') can be
> improved.
>
>    The help pages found using apropos('by') appear the same: ?by,
> ?by.data.frame, ?by.default and provide no hint on how to work with unequal
> rows per factor.
>
>    How can I apply by() on these data.frames?
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep 17 21:56:04 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 17 Sep 2018 12:56:04 -0700 (PDT)
Subject: [R] Applying by() when groups have different lengths [RESOLVED]
In-Reply-To: <C045A3F5-26F3-4F18-8BC1-BF2E163FDB49@llnl.gov>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
 <C045A3F5-26F3-4F18-8BC1-BF2E163FDB49@llnl.gov>
Message-ID: <alpine.LNX.2.20.1809171252290.19471@salmo.appl-ecosys.com>

On Mon, 17 Sep 2018, MacQueen, Don wrote:

> I'm also going to guess that maybe your object rainfall_by_site has
> already been split into separate data frames (because of its name). But
> by() does the splitting internally, so you should be passing it the
> original unsplit data frame.

Don,

   I did not pick up on by() doing the splitting for me when I read the help
file and a few web sites!

   Using the unsplit data.frame did the job; e.g.,

rainfall[, "name"]: Sandy 1.4 NE
[1] 0.1636066
------------------------------------------------------------ 
rainfall[, "name"]: Sandy 1.7 SSW
[1] 0.2021324
------------------------------------------------------------ 
rainfall[, "name"]: Sherwood 3.3 SE
[1] 0.1461752

   Now I know how to properly apply by() to an unsplit dataframe. Thanks for
the insightful lesson.

Best regards,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep 17 22:10:16 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 17 Sep 2018 13:10:16 -0700 (PDT)
Subject: [R] Applying by() when groups have different lengths
In-Reply-To: <CAGxFJbR4q6hG=b_w2Lo6W1=6o-364-mBdMRhnMniMwfSAkt_Gw@mail.gmail.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
 <CAGxFJbR4q6hG=b_w2Lo6W1=6o-364-mBdMRhnMniMwfSAkt_Gw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809171309291.19471@salmo.appl-ecosys.com>

On Mon, 17 Sep 2018, Bert Gunter wrote:

>>    I cannot think of a way of proving a sample of data; if a sample for a

   Typo: s/proving/providing/

Rich



From henr|k@bengt@@on @end|ng |rom gm@||@com  Mon Sep 17 22:13:59 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Mon, 17 Sep 2018 13:13:59 -0700
Subject: [R] makeCluster() hangs infinitely
In-Reply-To: <CADBpgp3DNPHPaHmPkmS+PhF6XAo0cHPgHtGx=eC42o5TUyJQTw@mail.gmail.com>
References: <CADBpgp0PsJ7M5MATA8jkMQA1DnJ-HmQRXzGLcq=TyKe8UWG7Ag@mail.gmail.com>
 <CAFDcVCSvR_=-EEqkkq-yfNpFZ8TGLxa3M4teko935ZMCKMzsAw@mail.gmail.com>
 <CADBpgp3DNPHPaHmPkmS+PhF6XAo0cHPgHtGx=eC42o5TUyJQTw@mail.gmail.com>
Message-ID: <CAFDcVCT083NAze_fjmj94qva2iGxJS0amAMV-m3R=mS7W9+RTQ@mail.gmail.com>

On Mon, Sep 17, 2018 at 12:56 PM Zhihao Huang <zhhhwang at umich.edu> wrote:
>
> Hi Henrik,
>
> Thanks for the suggestions! I tried your approach, and obtained the following output, which is pretty similar to the previous ones.
>
> > cl <- future::makeClusterPSOCK(1, outfile = NULL, verbose = TRUE)
> Workers: [n = 1] ?localhost?
> Base port: 11214
> Creating node 1 of 1 ...
> - setting up node
> Starting worker #1 on ?localhost?: '/Library/Frameworks/R.framework/Resources/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT= TIMEOUT=2592000 XDR=TRUE
> Waiting for worker #1 on ?localhost? to connect back
> starting worker pid=13731 on localhost:11214 at 15:48:41.991
>
> I guess this is a connection problem. I am not sure what these numbers mean. Do you have any further idea on this? I very much appreciate it!

Yes, it looks similar with the important difference of displaying:

"starting worker pid=13731 on localhost:11214 at 15:48:41.991"

That tells us that the background worker (separate R session running
parallel:::.slaveRSOCK()) was successfully launched, which is good.

BTW, you should see something similar with:

    cl <- parallel::makeCluster(1, outfile = NULL)

which helps others help you (in case they say "oh, it might be a
problem with the future package - as the maintainer").

Yes, it looks like a "connection problem" - this could be a firewall
issue or similar.  I'm not on macOS, so I cannot help you there, but
maybe others can pitch in.

/Henrik

>
> Thanks,
> Zhihao
> --
> Zhihao (Daniel) Huang
> Graduate Student
> Department of Statistics,
> University of Michigan, Ann Arbor
> Email: zhhhwang at umich.edu
>
>
>
> On Mon, Sep 17, 2018 at 12:38 AM Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>
>> Hi,
>>
>> did you see my answer on StackOverflow? Specifically, if you set
>> argument 'outfile = NULL' to either of those two functions, you'll get
>> a little bit more information that *might* provide some clues.
>>
>> /Henrik
>>
>>
>> On Sun, Sep 16, 2018 at 5:38 PM Zhihao Huang <zhhhwang at umich.edu> wrote:
>> >
>> > Hi all,
>> >
>> > The function makeCluster() of parallel does not work on my laptop. It hangs
>> > infinitely.
>> >
>> > *1. Problem Summary:*
>> >
>> > > # Loading parallel packages
>> >
>> > > library(parallel)
>> >
>> > > cl <- makeCluster(2) # It hangs at this line of code.
>> > It hangs at the second line of the code.
>> >
>> > *2. Potential Reason*
>> > I also tried to see the details of what it does internally by using the
>> > following code.
>> >
>> > > library(future)
>> >
>> > > cl <- future::makeClusterPSOCK(1L, verbose = TRUE) # It hangs at this
>> > line of code.
>> > And it returns the following descriptions and hangs.
>> >
>> > *Workers: [n = 1] ?localhost?*
>> >
>> > *Base port: 11214*
>> >
>> > *Creating node 1 of 1 ...*
>> >
>> > *- setting up node*
>> >
>> > *Starting worker #1 on ?localhost?:
>> > '/Library/Frameworks/R.framework/Resources/bin/Rscript'
>> > --default-packages=datasets,utils,grDevices,graphics,stats,methods -e
>> > 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT=/dev/null
>> > TIMEOUT=2592000 XDR=TRUE*
>> >
>> > *Waiting for worker #1 on ?localhost? to connect back*
>> > So the problem is that the "worker #1 on 'local host'" never connects back,
>> > and that's why it hangs forever. I have no idea what causes this.
>> >
>> > *3. my sessionInfo():*
>> >
>> > R version 3.5.1 (2018-07-02)
>> >
>> > Platform: x86_64-apple-darwin15.6.0 (64-bit)
>> >
>> > Running under: macOS High Sierra 10.13.6
>> >
>> >
>> > Matrix products: default
>> >
>> > BLAS:
>> > /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
>> >
>> > LAPACK:
>> > /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
>> >
>> >
>> > locale:
>> >
>> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> >
>> >
>> > attached base packages:
>> >
>> > [1] stats     graphics  grDevices utils     datasets  methods   base
>> >
>> >
>> > loaded via a namespace (and not attached):
>> >
>> > [1] compiler_3.5.1
>> >
>> > I spent hours searching for the solutions but failed. It looks like some
>> > other people met similar problem here
>> > <http://r.789695.n4.nabble.com/makeCluster-hangs-td4748238.html>. Also, I
>> > posted this question online here
>> > <https://stackoverflow.com/questions/52264460/r-parallel-makecluster-hangs-infinitely-on-mac/52284709#52284709>
>> > a
>> > week ago.
>> >
>> > Any suggestion would be appreciated. Thanks a lot!
>> >
>> > Thanks,
>> > Zhihao
>> > --
>> > Zhihao (Daniel) Huang
>> > Graduate Student
>> > Department of Statistics,
>> > University of Michigan, Ann Arbor
>> > Email: zhhhwang at umich.edu
>> >
>> > --
>> > ? ??
>> > Zhihao Huang
>> >
>> > Graduate Student
>> > Department of Statistics,
>> > University of Michigan, Ann Arbor
>> > Email: zhhhwang at umich.edu
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 17 22:32:41 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 17 Sep 2018 13:32:41 -0700
Subject: [R] Applying by() when groups have different lengths [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.1809171252290.19471@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809171136220.19471@salmo.appl-ecosys.com>
 <C045A3F5-26F3-4F18-8BC1-BF2E163FDB49@llnl.gov>
 <alpine.LNX.2.20.1809171252290.19471@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSKjy_wBSFwJ3pC_MV71Xw6066C3xw_1m43CG4eg9nCSQ@mail.gmail.com>

"  I did not pick up on by() doing the splitting for me when I read the
help..."

>From ?by:
"A data frame is split by row into data frames subsetted by the values of
one or more factors, and function FUN is applied to each subset in turn."

I do not understand how it could be more clearly stated than that. Care to
elaborate?
Did you run the examples? You should **always** do so.

-- Bert


On Mon, Sep 17, 2018 at 12:56 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Mon, 17 Sep 2018, MacQueen, Don wrote:
>
> > I'm also going to guess that maybe your object rainfall_by_site has
> > already been split into separate data frames (because of its name). But
> > by() does the splitting internally, so you should be passing it the
> > original unsplit data frame.
>
> Don,
>
>    I did not pick up on by() doing the splitting for me when I read the
> help
> file and a few web sites!
>
>    Using the unsplit data.frame did the job; e.g.,
>
> rainfall[, "name"]: Sandy 1.4 NE
> [1] 0.1636066
> ------------------------------------------------------------
> rainfall[, "name"]: Sandy 1.7 SSW
> [1] 0.2021324
> ------------------------------------------------------------
> rainfall[, "name"]: Sherwood 3.3 SE
> [1] 0.1461752
>
>    Now I know how to properly apply by() to an unsplit dataframe. Thanks
> for
> the insightful lesson.
>
> Best regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jmh@nnon@ucd@v|@ @end|ng |rom gm@||@com  Mon Sep 17 23:57:15 2018
From: jmh@nnon@ucd@v|@ @end|ng |rom gm@||@com (Michael Hannon)
Date: Mon, 17 Sep 2018 14:57:15 -0700
Subject: [R] Unable to update R 3.4 to R 3.5 in Ubuntu 18.04 LTS
In-Reply-To: <CAMo+egkiwPriFXCbSvMH3234BEitjBMxuwmYBC4gEjPdzUqA8g@mail.gmail.com>
References: <CAMo+egkiwPriFXCbSvMH3234BEitjBMxuwmYBC4gEjPdzUqA8g@mail.gmail.com>
Message-ID: <CACdH2ZZn5w6+u4kW01K_t5U9v4JLRu78_M-mSSn4n=xa4btWZw@mail.gmail.com>

I didn't find an attached file, but I'm using Ubuntu 18.04 and have upgraded R
to version 3.5.

I don't recall exactly how I did the upgrade, but it must have been something
like:

https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-18-04-quickstart

-- Mike

$ cat /etc/os-release
NAME="Ubuntu"
VERSION="18.04.1 LTS (Bionic Beaver)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 18.04.1 LTS"
VERSION_ID="18.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic

$ grep cloud /etc/apt/sources.list
deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/


> devtools::session_info()
Session info ------------------------------------------------------------------
 setting  value
 version  R version 3.5.1 (2018-07-02)
 system   x86_64, linux-gnu
 ui       X11
 language (EN)
 collate  en_US.UTF-8
 tz       America/Los_Angeles
 date     2018-09-17

Packages ----------------------------------------------------------------------
 package   * version date       source
 base      * 3.5.1   2018-07-03 local
 compiler    3.5.1   2018-07-03 local
 datasets  * 3.5.1   2018-07-03 local
 devtools    1.13.6  2018-06-27 CRAN (R 3.5.1)
 digest      0.6.17  2018-09-12 CRAN (R 3.5.1)
 graphics  * 3.5.1   2018-07-03 local
 grDevices * 3.5.1   2018-07-03 local
 memoise     1.1.0   2017-04-21 CRAN (R 3.5.1)
 methods   * 3.5.1   2018-07-03 local
 stats     * 3.5.1   2018-07-03 local
 utils     * 3.5.1   2018-07-03 local
 withr       2.1.2   2018-03-15 CRAN (R 3.5.1)
On Mon, Sep 17, 2018 at 10:12 AM RUPJYOTI DAS <rj.innet at gmail.com> wrote:
>
> Dear All,
> I am using R to carry out RNA-Seq workflow in my standalone machine which
> needs the latest R version >=3.5. I was trying to update firstly removing
> the R 3.4 and reinstalling from scratch again the latest version. Can
> anybody just guide me how to carry out the process as I am getting only R
> 3.4 again and again.
> Also when I remove the
> *deb ... bionic-cran35 (mirror for R cran )*
>
> from the* source.list* file (opened by* sudo gedit /etc/apt/sources.list*)
> the command *sudo apt-get update* works fine which does not upgrade the R
> 3.4 to R 3.5.1.
> Adding the line
> *deb ... bionic-cran35/ *
> gives the attached error log*. **Please find the attached file and  do
> check.*
>
> Any answers and suggestions will be of immense help!
>
> Thanking you!
>
> *Rupjyoti Das*
> *M.Tech*, Information Technology
> Tezpur University
> Assam, India 784028
> Mob. +91-8812807195
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From zhhhw@ng @end|ng |rom um|ch@edu  Mon Sep 17 21:55:27 2018
From: zhhhw@ng @end|ng |rom um|ch@edu (Zhihao Huang)
Date: Mon, 17 Sep 2018 15:55:27 -0400
Subject: [R] makeCluster() hangs infinitely
In-Reply-To: <CAFDcVCSvR_=-EEqkkq-yfNpFZ8TGLxa3M4teko935ZMCKMzsAw@mail.gmail.com>
References: <CADBpgp0PsJ7M5MATA8jkMQA1DnJ-HmQRXzGLcq=TyKe8UWG7Ag@mail.gmail.com>
 <CAFDcVCSvR_=-EEqkkq-yfNpFZ8TGLxa3M4teko935ZMCKMzsAw@mail.gmail.com>
Message-ID: <CADBpgp3DNPHPaHmPkmS+PhF6XAo0cHPgHtGx=eC42o5TUyJQTw@mail.gmail.com>

Hi Henrik,

Thanks for the suggestions! I tried your approach, and obtained the
following output, which is pretty similar to the previous ones.

> cl <- future::makeClusterPSOCK(1, outfile = NULL, verbose = TRUE)

*Workers: [n = 1] ?localhost?*

*Base port: 11214*

*Creating node 1 of 1 ...*

*- setting up node*

*Starting worker #1 on ?localhost?:
'/Library/Frameworks/R.framework/Resources/bin/Rscript'
--default-packages=datasets,utils,grDevices,graphics,stats,methods -e
'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT= TIMEOUT=2592000
XDR=TRUE*

*Waiting for worker #1 on ?localhost? to connect back*

starting worker pid=13731 on localhost:11214 at 15:48:41.991
I guess this is a connection problem. I am not sure what these numbers
mean. Do you have any further idea on this? I very much appreciate it!

Thanks,
Zhihao
--
Zhihao (Daniel) Huang
Graduate Student
Department of Statistics,
University of Michigan, Ann Arbor
Email: zhhhwang at umich.edu



On Mon, Sep 17, 2018 at 12:38 AM Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> Hi,
>
> did you see my answer on StackOverflow? Specifically, if you set
> argument 'outfile = NULL' to either of those two functions, you'll get
> a little bit more information that *might* provide some clues.
>
> /Henrik
>
>
> On Sun, Sep 16, 2018 at 5:38 PM Zhihao Huang <zhhhwang at umich.edu> wrote:
> >
> > Hi all,
> >
> > The function makeCluster() of parallel does not work on my laptop. It
> hangs
> > infinitely.
> >
> > *1. Problem Summary:*
> >
> > > # Loading parallel packages
> >
> > > library(parallel)
> >
> > > cl <- makeCluster(2) # It hangs at this line of code.
> > It hangs at the second line of the code.
> >
> > *2. Potential Reason*
> > I also tried to see the details of what it does internally by using the
> > following code.
> >
> > > library(future)
> >
> > > cl <- future::makeClusterPSOCK(1L, verbose = TRUE) # It hangs at this
> > line of code.
> > And it returns the following descriptions and hangs.
> >
> > *Workers: [n = 1] ?localhost?*
> >
> > *Base port: 11214*
> >
> > *Creating node 1 of 1 ...*
> >
> > *- setting up node*
> >
> > *Starting worker #1 on ?localhost?:
> > '/Library/Frameworks/R.framework/Resources/bin/Rscript'
> > --default-packages=datasets,utils,grDevices,graphics,stats,methods -e
> > 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11214 OUT=/dev/null
> > TIMEOUT=2592000 XDR=TRUE*
> >
> > *Waiting for worker #1 on ?localhost? to connect back*
> > So the problem is that the "worker #1 on 'local host'" never connects
> back,
> > and that's why it hangs forever. I have no idea what causes this.
> >
> > *3. my sessionInfo():*
> >
> > R version 3.5.1 (2018-07-02)
> >
> > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> >
> > Running under: macOS High Sierra 10.13.6
> >
> >
> > Matrix products: default
> >
> > BLAS:
> >
> /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
> >
> > LAPACK:
> >
> /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
> >
> >
> > locale:
> >
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >
> >
> > attached base packages:
> >
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> >
> > loaded via a namespace (and not attached):
> >
> > [1] compiler_3.5.1
> >
> > I spent hours searching for the solutions but failed. It looks like some
> > other people met similar problem here
> > <http://r.789695.n4.nabble.com/makeCluster-hangs-td4748238.html>. Also,
> I
> > posted this question online here
> > <
> https://stackoverflow.com/questions/52264460/r-parallel-makecluster-hangs-infinitely-on-mac/52284709#52284709
> >
> > a
> > week ago.
> >
> > Any suggestion would be appreciated. Thanks a lot!
> >
> > Thanks,
> > Zhihao
> > --
> > Zhihao (Daniel) Huang
> > Graduate Student
> > Department of Statistics,
> > University of Michigan, Ann Arbor
> > Email: zhhhwang at umich.edu
> >
> > --
> > ? ??
> > Zhihao Huang
> >
> > Graduate Student
> > Department of Statistics,
> > University of Michigan, Ann Arbor
> > Email: zhhhwang at umich.edu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @rt@tem@u@ @end|ng |rom gm@||@com  Mon Sep 17 23:29:59 2018
From: @rt@tem@u@ @end|ng |rom gm@||@com (Art U)
Date: Mon, 17 Sep 2018 17:29:59 -0400
Subject: [R] pdredge error
Message-ID: <CAKY_brGivpC-t=LHxphUKoLxfw41i2Q1NL=jn8zUz=xbp=vWBQ@mail.gmail.com>

Hello,

I'm trying to use parallel computing in MuMIn package. It worked a couple
month ago, but now I'm getting the error. Here is a code:

#Data
x1 = rnorm(1000)
x2 = rnorm(1000)
x3 = rnorm(1000)
z = 1 + 0.5*x1 - x2
pr = 1/(1+exp(-z))
y = rbinom(1000, 1, pr)
dataD = cbind(y=y, x1=x1 ,x2=x2, x3=x3)

#Fixed variable
fix.var = c("x1")

#Model averaging
cl <- makeCluster(detectCores())
clusterExport(cl, c("dataD"), envir=environment())
clusterExport(cl, c("y"), envir=environment())
clusterExport(cl, c("fix.var"), envir=environment())
clusterEvalQ(cl, library(MuMIn))
d = data.frame(dataD)
      options(na.action = "na.fail")
      m.inc = glm(y~., family=binomial, data=d)
      MA.inc = pdredge(global.model = m.inc, rank = "AIC" , fixed =
fix.var, cluster=cl)
      mo.inc = model.avg(MA.inc, rank =  "AIC")
      atr.inc = attr(mo.inc, "modelList")
 stopCluster(cl)

The error says that data frame 'd' is not found and the pdredge result is
empty:

Warning messages:
1: In is.data.frame(data) : object 'd' not found (model 0 skipped)
2: In is.data.frame(data) : object 'd' not found (model 1 skipped)
3: In is.data.frame(data) : object 'd' not found (model 2 skipped)
4: In is.data.frame(data) : object 'd' not found (model 3 skipped)
5: In is.data.frame(data) : object 'd' not found (model 4 skipped)
Error in pdredge(global.model = m.inc, rank = "AIC" , fixed = fix.var,    :
  the result is empty



-- 
*I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
or plague*... *Whatever*. *No-one left to act normal for. No need to hide
who I really am. It would be... freeing*. *...*

	[[alternative HTML version deleted]]



From g||ted|||e2014 @end|ng |rom gm@||@com  Tue Sep 18 04:24:37 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Tue, 18 Sep 2018 03:24:37 +0100
Subject: [R] customizing the number of decimal places in xtable
Message-ID: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>

Dear Volunteers,

I have a table involving many decimal places:
2005-01-04 -2.13339817688037
2005-01-19 -6.86312349695117
2005-01-22 -4.33662370554386
2005-02-10 -1.40789214441639
2005-02-13 -1.1334121785854
2005-02-19 -1.28411233010119
2005-05-09 -1.6895978161324
2005-05-16 -3.07664523496947
2005-06-17 -1.69904491217129
2005-07-17 -3.44289318667434
2005-08-07 -2.29676435700659
2005-08-10 -1.08915071542227
2005-08-24 -1.8244123081697
2005-09-13 -4.57899147546373
2005-09-15 -3.96591895962343
 I used xtable to covert this to form of latex table.

The result I have is:
1 & 2005-01-04 & -2.13 \\
  2 & 2005-01-19 & -6.86 \\
  3 & 2005-01-22 & -4.34 \\
  4 & 2005-02-10 & -1.41 \\
  5 & 2005-02-13 & -1.13 \\
  6 & 2005-02-19 & -1.28 \\
  7 & 2005-05-09 & -1.69 \\
  8 & 2005-05-16 & -3.08 \\
  9 & 2005-06-17 & -1.70 \\
  10 & 2005-07-17 & -3.44 \\
  11 & 2005-08-07 & -2.30 \\
  12 & 2005-08-10 & -1.09 \\
  13 & 2005-08-24 & -1.82 \\
  14 & 2005-09-13 & -4.58 \\
  15 & 2005-09-15 & -3.97 \\.

It has truncated the long decimal places. Since it is not want I want, I
have to copy from the original table and place into xtable.

Can you please tell me how to customize the xtable so that I will be
responsible for the number of decimal places it displays.

Many thanks for your precious time.

Warmest regards
Ogbos

	[[alternative HTML version deleted]]



From choco|d12 @end|ng |rom gm@||@com  Tue Sep 18 06:44:45 2018
From: choco|d12 @end|ng |rom gm@||@com (lily li)
Date: Tue, 18 Sep 2018 12:44:45 +0800
Subject: [R] Open netcdf file in linux
Message-ID: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>

Hi R users,

I have installed ncdf4 package in R from the linux terminal, but have met
this problem when using nc_open to open a .nc file. What is the problem?
Any help would be appreciated.

Error in R_nc4_open: Is a directory

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep 18 07:27:29 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 17 Sep 2018 22:27:29 -0700
Subject: [R] customizing the number of decimal places in xtable
In-Reply-To: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>
References: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>
Message-ID: <EE269AA9-F2B2-4082-BB99-E237BC9E7266@dcn.davis.ca.us>

Have you read

?xtable


On September 17, 2018 7:24:37 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Volunteers,
>
>I have a table involving many decimal places:
>2005-01-04 -2.13339817688037
>2005-01-19 -6.86312349695117
>2005-01-22 -4.33662370554386
>2005-02-10 -1.40789214441639
>2005-02-13 -1.1334121785854
>2005-02-19 -1.28411233010119
>2005-05-09 -1.6895978161324
>2005-05-16 -3.07664523496947
>2005-06-17 -1.69904491217129
>2005-07-17 -3.44289318667434
>2005-08-07 -2.29676435700659
>2005-08-10 -1.08915071542227
>2005-08-24 -1.8244123081697
>2005-09-13 -4.57899147546373
>2005-09-15 -3.96591895962343
> I used xtable to covert this to form of latex table.
>
>The result I have is:
>1 & 2005-01-04 & -2.13 \\
>  2 & 2005-01-19 & -6.86 \\
>  3 & 2005-01-22 & -4.34 \\
>  4 & 2005-02-10 & -1.41 \\
>  5 & 2005-02-13 & -1.13 \\
>  6 & 2005-02-19 & -1.28 \\
>  7 & 2005-05-09 & -1.69 \\
>  8 & 2005-05-16 & -3.08 \\
>  9 & 2005-06-17 & -1.70 \\
>  10 & 2005-07-17 & -3.44 \\
>  11 & 2005-08-07 & -2.30 \\
>  12 & 2005-08-10 & -1.09 \\
>  13 & 2005-08-24 & -1.82 \\
>  14 & 2005-09-13 & -4.58 \\
>  15 & 2005-09-15 & -3.97 \\.
>
>It has truncated the long decimal places. Since it is not want I want,
>I
>have to copy from the original table and place into xtable.
>
>Can you please tell me how to customize the xtable so that I will be
>responsible for the number of decimal places it displays.
>
>Many thanks for your precious time.
>
>Warmest regards
>Ogbos
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep 18 07:33:10 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 17 Sep 2018 22:33:10 -0700
Subject: [R] Open netcdf file in linux
In-Reply-To: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>
References: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>
Message-ID: <16A5250F-1718-4D98-86D8-D5813C24D562@dcn.davis.ca.us>

I really don't know how you expect an answer when you don't show what you did or pointed us to an example of a file that yields this error. My best blind guess is that you have not given the name of an ncdf file to the function.

On September 17, 2018 9:44:45 PM PDT, lily li <chocold12 at gmail.com> wrote:
>Hi R users,
>
>I have installed ncdf4 package in R from the linux terminal, but have
>met
>this problem when using nc_open to open a .nc file. What is the
>problem?
>Any help would be appreciated.
>
>Error in R_nc4_open: Is a directory
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From g||ted|||e2014 @end|ng |rom gm@||@com  Tue Sep 18 07:49:43 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Tue, 18 Sep 2018 06:49:43 +0100
Subject: [R] 
 customizing the number of decimal places in xtable: RESOLVED
In-Reply-To: <EE269AA9-F2B2-4082-BB99-E237BC9E7266@dcn.davis.ca.us>
References: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>
 <EE269AA9-F2B2-4082-BB99-E237BC9E7266@dcn.davis.ca.us>
Message-ID: <CAC8ss33H5f4=BndZ7EwmfwbE=HnKW0p-GqAHKxu3w+r-zN=ezw@mail.gmail.com>

Dear Jeff,

Thank you please.

I did search before but could not get it resolved. But with your query now,
just typed ?xtable as key  search word and the first document I opened gave
an indication of digits. Without knowing what it was saying, I tried it in
my data and it gave the result I have been looking for.

xtable(data, digits=12) and I am fine.

Thank you so much.

Ogbos

On Tue, Sep 18, 2018 at 6:27 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Have you read
>
> ?xtable
>
>
> On September 17, 2018 7:24:37 PM PDT, Ogbos Okike <
> giftedlife2014 at gmail.com> wrote:
> >Dear Volunteers,
> >
> >I have a table involving many decimal places:
> >2005-01-04 -2.13339817688037
> >2005-01-19 -6.86312349695117
> >2005-01-22 -4.33662370554386
> >2005-02-10 -1.40789214441639
> >2005-02-13 -1.1334121785854
> >2005-02-19 -1.28411233010119
> >2005-05-09 -1.6895978161324
> >2005-05-16 -3.07664523496947
> >2005-06-17 -1.69904491217129
> >2005-07-17 -3.44289318667434
> >2005-08-07 -2.29676435700659
> >2005-08-10 -1.08915071542227
> >2005-08-24 -1.8244123081697
> >2005-09-13 -4.57899147546373
> >2005-09-15 -3.96591895962343
> > I used xtable to covert this to form of latex table.
> >
> >The result I have is:
> >1 & 2005-01-04 & -2.13 \\
> >  2 & 2005-01-19 & -6.86 \\
> >  3 & 2005-01-22 & -4.34 \\
> >  4 & 2005-02-10 & -1.41 \\
> >  5 & 2005-02-13 & -1.13 \\
> >  6 & 2005-02-19 & -1.28 \\
> >  7 & 2005-05-09 & -1.69 \\
> >  8 & 2005-05-16 & -3.08 \\
> >  9 & 2005-06-17 & -1.70 \\
> >  10 & 2005-07-17 & -3.44 \\
> >  11 & 2005-08-07 & -2.30 \\
> >  12 & 2005-08-10 & -1.09 \\
> >  13 & 2005-08-24 & -1.82 \\
> >  14 & 2005-09-13 & -4.58 \\
> >  15 & 2005-09-15 & -3.97 \\.
> >
> >It has truncated the long decimal places. Since it is not want I want,
> >I
> >have to copy from the original table and place into xtable.
> >
> >Can you please tell me how to customize the xtable so that I will be
> >responsible for the number of decimal places it displays.
> >
> >Many thanks for your precious time.
> >
> >Warmest regards
> >Ogbos
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From @@h|mk@poor @end|ng |rom gm@||@com  Tue Sep 18 07:51:21 2018
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Tue, 18 Sep 2018 11:21:21 +0530
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
Message-ID: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>

Dear All,

I was reading this page --->
https://cran.r-project.org/bin/linux/ubuntu/README.html

It says: R 3.4 packages for Ubuntu on i386 and amd64 are available for all
stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04) until
their official end of life date.

The page also shows how to install R 3.5 on Ubuntu 18.04.1

My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we only
install R 3.5 ?

Many thanks,
Ashim

	[[alternative HTML version deleted]]



From |@b|@no@|r@nc@d@ @end|ng |rom hotm@||@com  Tue Sep 18 04:34:30 2018
From: |@b|@no@|r@nc@d@ @end|ng |rom hotm@||@com (=?Windows-1252?Q?Fabiano_Fran=E7a?=)
Date: Tue, 18 Sep 2018 02:34:30 +0000
Subject: [R] =?windows-1252?q?How_to_troubleshoot_error_=93cannot_coerce_?=
 =?windows-1252?q?class_=94=93group=94=93_to_a_data=2Eframe=94=3F?=
Message-ID: <CY4PR13MB0966DE9F77B10894B45F0EA3831D0@CY4PR13MB0966.namprd13.prod.outlook.com>

Dear Volunteers,
When running the scriptbelow, specifically in the part of reproduction of the data.framesreturned the error:

Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) : cannot coerce class ""group"" to a data.frame

I searched the internet and could not reproduce the suggestions for my case, does anyone tell me a way?

setwd("https://drive.google.com/open?id=1FDMZfWrEjsvleVdNOUiPh8REGjvQHKQx")
rend <- read.table('IVCM.txt', header = TRUE, sep="\t")
rend <- transform(rend, Fungicidas=factor(Fungicidas), Doses=factor(Doses), Rep=factor(Rep))
str(rend)#---------------------------------------------------------------------------# unfolding the interaction in Tukey tests

require(agricolae)
require(plyr)

KinA <- sapply(levels(rend$Doses), simplify=FALSE,
               function(Doses){
                 with(subset(rend, Doses==Doses),
                      HSD.test(IVCM, Fungicidas,
                               DFerror=df.residual(m0),
                               MSerror=deviance(m0)/df.residual(m0)))
               })

KinA <- llply(KinA, NULL)
KinA$M <- gsub(" ", "", KinA$M, fixed=TRUE)
KinA$trt <- as.factor(as.numeric(as.character(KinA$trt)))
str(KinA)

AinK <- sapply(levels(rend$Fungicidas), simplify=FALSE,
               function(Fungicidas){
                 with(subset(rend, Fungicidas==Fungicidas),
                      HSD.test(IVCM, Doses,
                               DFerror=df.residual(m0),
                               MSerror=deviance(m0)/df.residual(m0)))
               })

AinK <- llply(AinK, NULL)
AinK$M <- toupper(gsub(" ", "", AinK$M, fixed=TRUE))
AinK$trt <- as.factor(as.numeric(as.character(AinK$trt)))
str(AinK)

Many thanks

Regards,

Fabiano Fran?a da Silva
Doutorando em Fitotecnia - ESALQ/USP
MSc Fitotecnia - UFLA
Eng?. Agr?nomo - UFLA
(35) 9 9155-5443 TIM



	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep 18 08:19:02 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 18 Sep 2018 07:19:02 +0100
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
Message-ID: <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>

Hello,

I am not completely sure but I think I installed Ubuntu 18.04 LTS first 
and R 3.5 days later, so yes, if I'm right it is possible to run R 3.4 
on 18.04.

(You ask whether we can *install* R 3.4 on Ubuntu 18.04.1, I'm saying it 
can be *run* on Ubuntu 18.04.1.)

Hope this helps,

Rui Barradas


?s 06:51 de 18/09/2018, Ashim Kapoor escreveu:
> Dear All,
> 
> I was reading this page --->
> https://cran.r-project.org/bin/linux/ubuntu/README.html
> 
> It says: R 3.4 packages for Ubuntu on i386 and amd64 are available for all
> stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04) until
> their official end of life date.
> 
> The page also shows how to install R 3.5 on Ubuntu 18.04.1
> 
> My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we only
> install R 3.5 ?
> 
> Many thanks,
> Ashim
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From choco|d12 @end|ng |rom gm@||@com  Tue Sep 18 08:53:22 2018
From: choco|d12 @end|ng |rom gm@||@com (lily li)
Date: Tue, 18 Sep 2018 14:53:22 +0800
Subject: [R] Open netcdf file in linux
In-Reply-To: <16A5250F-1718-4D98-86D8-D5813C24D562@dcn.davis.ca.us>
References: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>
 <16A5250F-1718-4D98-86D8-D5813C24D562@dcn.davis.ca.us>
Message-ID: <CAN5afy8A8uNCCMHKU8dd8fkxczoDuoEx4AH94ScMF=4WtcJhQg@mail.gmail.com>

Thanks, you are right that the file path is not correct. I just typed:
nc_open("file.nc"), and it gave the error above.

On Tue, Sep 18, 2018 at 1:33 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I really don't know how you expect an answer when you don't show what you
> did or pointed us to an example of a file that yields this error. My best
> blind guess is that you have not given the name of an ncdf file to the
> function.
>
> On September 17, 2018 9:44:45 PM PDT, lily li <chocold12 at gmail.com> wrote:
> >Hi R users,
> >
> >I have installed ncdf4 package in R from the linux terminal, but have
> >met
> >this problem when using nc_open to open a .nc file. What is the
> >problem?
> >Any help would be appreciated.
> >
> >Error in R_nc4_open: Is a directory
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From choco|d12 @end|ng |rom gm@||@com  Tue Sep 18 08:59:05 2018
From: choco|d12 @end|ng |rom gm@||@com (lily li)
Date: Tue, 18 Sep 2018 14:59:05 +0800
Subject: [R] Problem in installing rgdal package in linux
Message-ID: <CAN5afy-vwcHWqVCsm5xt5RDB4d2JdBT60HHLTk42VrayhqxPSA@mail.gmail.com>

Hi all,

I am installing rgdal package in linux for R, and got the error below. I
typed: $ install.packages("rgdal", repos= "http://cran.us.r-project.org")

What is the problem and how to correct it? Thanks for your kind help.

============================== print the error message here

downloaded 1.6 MB


* installing *source* package ?rgdal? ...

** package ?rgdal? successfully unpacked and MD5 sums checked

configure: R_HOME: /usr/lib64/R

configure: CC: gcc -m64 -std=gnu99

configure: CXX: g++ -m64

configure: C++11 support available

configure: rgdal: 1.3-4

checking for /usr/bin/svnversion... yes

configure: svn revision: 766

checking for gdal-config... no

no

configure: error: gdal-config not found or not executable.

ERROR: configuration failed for package ?rgdal?

* removing ?/directory/R/x86_64-redhat-linux-gnu-library/3.5/rgdal?


The downloaded source packages are in

?/tmp/RtmpplM8mi/downloaded_packages?

Warning message:

In install.packages("rgdal") :

  installation of package ?rgdal? had non-zero exit status

	[[alternative HTML version deleted]]



From @@h|mk@poor @end|ng |rom gm@||@com  Tue Sep 18 09:24:06 2018
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Tue, 18 Sep 2018 12:54:06 +0530
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
Message-ID: <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>

Dear Rui,

I am a little confused.

See this ---> : R 3.4 packages for Ubuntu on i386 and amd64 are available
for all stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04)
until their official end of life date. However, only the latest Long Term
Support (LTS) release is fully supported. As of June 11, 2018 the supported
releases are Artful Aardvark (17.10), Xenial Xerus (16.04; LTS), and Trusty
Tahr (14.04; LTS).

Bionic Beaver ( Ubuntu 18.04 ) is NOT in the list of supported releases for
R 3.4  What does this mean ? Can you please clarify ?

Many thanks,
Ashim

On Tue, Sep 18, 2018 at 11:49 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I am not completely sure but I think I installed Ubuntu 18.04 LTS first
> and R 3.5 days later, so yes, if I'm right it is possible to run R 3.4
> on 18.04.
>
> (You ask whether we can *install* R 3.4 on Ubuntu 18.04.1, I'm saying it
> can be *run* on Ubuntu 18.04.1.)
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 06:51 de 18/09/2018, Ashim Kapoor escreveu:
> > Dear All,
> >
> > I was reading this page --->
> > https://cran.r-project.org/bin/linux/ubuntu/README.html
> >
> > It says: R 3.4 packages for Ubuntu on i386 and amd64 are available for
> all
> > stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04) until
> > their official end of life date.
> >
> > The page also shows how to install R 3.5 on Ubuntu 18.04.1
> >
> > My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we only
> > install R 3.5 ?
> >
> > Many thanks,
> > Ashim
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep 18 09:24:31 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 18 Sep 2018 00:24:31 -0700
Subject: [R] 
 customizing the number of decimal places in xtable: RESOLVED
In-Reply-To: <CAC8ss33H5f4=BndZ7EwmfwbE=HnKW0p-GqAHKxu3w+r-zN=ezw@mail.gmail.com>
References: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>
 <EE269AA9-F2B2-4082-BB99-E237BC9E7266@dcn.davis.ca.us>
 <CAC8ss33H5f4=BndZ7EwmfwbE=HnKW0p-GqAHKxu3w+r-zN=ezw@mail.gmail.com>
Message-ID: <E841EFA0-1BB1-47C9-8D9F-C27D16C92E50@dcn.davis.ca.us>

I gather you find the content of the help page for the xtable function hard to understand, but you need to build the skill of reading them and gathering clues about functions you call from them.

* They always have a usage section that briefly summarizes how the function is called and what the default values are for those parameters that do have defaults.

* They always mention what each parameter is for. (The help page may not always be thorough enough to suit your preference, but CRAN requires the author to make some effort to describe every parameter. Note that people posting packages on GitHub have no one insisting that they put in this effort, so beware that quality may vary more if you start using non-CRAN packages.) The digits parameter is used by many data formatting functions, and it can usually be specified as a vector with each element affecting a corresponding column of data in order.

* They always indicate what kind of Value will be returned from the function.

* They usually have Notes on how the function reacts to different input values.

* They often have Examples of how to use the function.

* They often have  a See Also section indicating what other functions you might find relevant when using this function.

* They sometimes have a section listing References to read to learn more about the theory behind the function.

Not all authors of help pages put the same level of effort into making help pages readable, and there is undoubtedly some shorthand notation that gives you key information more compactly than you might wish for as a beginner. However, if you ask for help interpreting specific help pages then you may learn more about how they work or the authors may re-write certain help pages based on your questions to address the source of your confusion.  Beware that if you don't read them first and mention why they didn't answer your question then you may get less helpful responses when when you do ask questions.

On September 17, 2018 10:49:43 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Jeff,
>
>Thank you please.
>
>I did search before but could not get it resolved. But with your query
>now,
>just typed ?xtable as key  search word and the first document I opened
>gave
>an indication of digits. Without knowing what it was saying, I tried it
>in
>my data and it gave the result I have been looking for.
>
>xtable(data, digits=12) and I am fine.
>
>Thank you so much.
>
>Ogbos
>
>On Tue, Sep 18, 2018 at 6:27 AM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Have you read
>>
>> ?xtable
>>
>>
>> On September 17, 2018 7:24:37 PM PDT, Ogbos Okike <
>> giftedlife2014 at gmail.com> wrote:
>> >Dear Volunteers,
>> >
>> >I have a table involving many decimal places:
>> >2005-01-04 -2.13339817688037
>> >2005-01-19 -6.86312349695117
>> >2005-01-22 -4.33662370554386
>> >2005-02-10 -1.40789214441639
>> >2005-02-13 -1.1334121785854
>> >2005-02-19 -1.28411233010119
>> >2005-05-09 -1.6895978161324
>> >2005-05-16 -3.07664523496947
>> >2005-06-17 -1.69904491217129
>> >2005-07-17 -3.44289318667434
>> >2005-08-07 -2.29676435700659
>> >2005-08-10 -1.08915071542227
>> >2005-08-24 -1.8244123081697
>> >2005-09-13 -4.57899147546373
>> >2005-09-15 -3.96591895962343
>> > I used xtable to covert this to form of latex table.
>> >
>> >The result I have is:
>> >1 & 2005-01-04 & -2.13 \\
>> >  2 & 2005-01-19 & -6.86 \\
>> >  3 & 2005-01-22 & -4.34 \\
>> >  4 & 2005-02-10 & -1.41 \\
>> >  5 & 2005-02-13 & -1.13 \\
>> >  6 & 2005-02-19 & -1.28 \\
>> >  7 & 2005-05-09 & -1.69 \\
>> >  8 & 2005-05-16 & -3.08 \\
>> >  9 & 2005-06-17 & -1.70 \\
>> >  10 & 2005-07-17 & -3.44 \\
>> >  11 & 2005-08-07 & -2.30 \\
>> >  12 & 2005-08-10 & -1.09 \\
>> >  13 & 2005-08-24 & -1.82 \\
>> >  14 & 2005-09-13 & -4.58 \\
>> >  15 & 2005-09-15 & -3.97 \\.
>> >
>> >It has truncated the long decimal places. Since it is not want I
>want,
>> >I
>> >have to copy from the original table and place into xtable.
>> >
>> >Can you please tell me how to customize the xtable so that I will be
>> >responsible for the number of decimal places it displays.
>> >
>> >Many thanks for your precious time.
>> >
>> >Warmest regards
>> >Ogbos
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.



From choco|d12 @end|ng |rom gm@||@com  Tue Sep 18 09:38:57 2018
From: choco|d12 @end|ng |rom gm@||@com (lily li)
Date: Tue, 18 Sep 2018 15:38:57 +0800
Subject: [R] Open netcdf file in linux
In-Reply-To: <F4222F62-5F35-41ED-AE0F-B7B87F5E54BF@dcn.davis.ca.us>
References: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>
 <16A5250F-1718-4D98-86D8-D5813C24D562@dcn.davis.ca.us>
 <CAN5afy8A8uNCCMHKU8dd8fkxczoDuoEx4AH94ScMF=4WtcJhQg@mail.gmail.com>
 <F4222F62-5F35-41ED-AE0F-B7B87F5E54BF@dcn.davis.ca.us>
Message-ID: <CAN5afy975bGHuUxoxztjeph_1at4794nzKRZVw9J6pXdbTv4xQ@mail.gmail.com>

I did not set the correct path for the .nc file earlier. Now it is working
properly.



> I find your response confusing still... did you now no longer need help?
>
> If you are still puzzled, then what does
>
> file.info("file.nc")
>
> return?
>
> Do you see that file in your current directory via your operating system?
>
> On September 17, 2018 11:53:22 PM PDT, lily li <chocold12 at gmail.com>
> wrote:
> >Thanks, you are right that the file path is not correct. I just typed:
> >nc_open("file.nc"), and it gave the error above.
> >
> >On Tue, Sep 18, 2018 at 1:33 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> I really don't know how you expect an answer when you don't show what
> >you
> >> did or pointed us to an example of a file that yields this error. My
> >best
> >> blind guess is that you have not given the name of an ncdf file to
> >the
> >> function.
> >>
> >> On September 17, 2018 9:44:45 PM PDT, lily li <chocold12 at gmail.com>
> >wrote:
> >> >Hi R users,
> >> >
> >> >I have installed ncdf4 package in R from the linux terminal, but
> >have
> >> >met
> >> >this problem when using nc_open to open a .nc file. What is the
> >> >problem?
> >> >Any help would be appreciated.
> >> >
> >> >Error in R_nc4_open: Is a directory
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep 18 09:40:28 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 18 Sep 2018 00:40:28 -0700
Subject: [R] Problem in installing rgdal package in linux
In-Reply-To: <CAN5afy-vwcHWqVCsm5xt5RDB4d2JdBT60HHLTk42VrayhqxPSA@mail.gmail.com>
References: <CAN5afy-vwcHWqVCsm5xt5RDB4d2JdBT60HHLTk42VrayhqxPSA@mail.gmail.com>
Message-ID: <5221D1FD-B479-4178-B47D-B144D03E8F34@dcn.davis.ca.us>

Read [1], in particular about System Requirements. Some packages have underlying configuration that needs to be handled through your operating system before the package can be installed.

[1] https://cran.r-project.org/web/packages/rgdal/index.html

On September 17, 2018 11:59:05 PM PDT, lily li <chocold12 at gmail.com> wrote:
>Hi all,
>
>I am installing rgdal package in linux for R, and got the error below.
>I
>typed: $ install.packages("rgdal", repos=
>"http://cran.us.r-project.org")
>
>What is the problem and how to correct it? Thanks for your kind help.
>
>============================== print the error message here
>
>downloaded 1.6 MB
>
>
>* installing *source* package ?rgdal? ...
>
>** package ?rgdal? successfully unpacked and MD5 sums checked
>
>configure: R_HOME: /usr/lib64/R
>
>configure: CC: gcc -m64 -std=gnu99
>
>configure: CXX: g++ -m64
>
>configure: C++11 support available
>
>configure: rgdal: 1.3-4
>
>checking for /usr/bin/svnversion... yes
>
>configure: svn revision: 766
>
>checking for gdal-config... no
>
>no
>
>configure: error: gdal-config not found or not executable.
>
>ERROR: configuration failed for package ?rgdal?
>
>* removing ?/directory/R/x86_64-redhat-linux-gnu-library/3.5/rgdal?
>
>
>The downloaded source packages are in
>
>?/tmp/RtmpplM8mi/downloaded_packages?
>
>Warning message:
>
>In install.packages("rgdal") :
>
>  installation of package ?rgdal? had non-zero exit status
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From @|k@u||m @end|ng |rom |@@tm@||@|m  Tue Sep 18 09:30:47 2018
From: @|k@u||m @end|ng |rom |@@tm@||@|m (Albrecht Kauffmann)
Date: Tue, 18 Sep 2018 09:30:47 +0200
Subject: [R] Problem in installing rgdal package in linux
In-Reply-To: <CAN5afy-vwcHWqVCsm5xt5RDB4d2JdBT60HHLTk42VrayhqxPSA@mail.gmail.com>
References: <CAN5afy-vwcHWqVCsm5xt5RDB4d2JdBT60HHLTk42VrayhqxPSA@mail.gmail.com>
Message-ID: <1537255847.1561271.1511785856.56E37487@webmail.messagingengine.com>

Hi Lily,

did you install gdal on your system?

Best,
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Di, 18. Sep 2018, um 08:59, schrieb lily li:
> Hi all,
> 
> I am installing rgdal package in linux for R, and got the error below. I
> typed: $ install.packages("rgdal", repos= "http://cran.us.r-project.org")
> 
> What is the problem and how to correct it? Thanks for your kind help.
> 
> ============================== print the error message here
> 
> downloaded 1.6 MB
> 
> 
> * installing *source* package ?rgdal? ...
> 
> ** package ?rgdal? successfully unpacked and MD5 sums checked
> 
> configure: R_HOME: /usr/lib64/R
> 
> configure: CC: gcc -m64 -std=gnu99
> 
> configure: CXX: g++ -m64
> 
> configure: C++11 support available
> 
> configure: rgdal: 1.3-4
> 
> checking for /usr/bin/svnversion... yes
> 
> configure: svn revision: 766
> 
> checking for gdal-config... no
> 
> no
> 
> configure: error: gdal-config not found or not executable.
> 
> ERROR: configuration failed for package ?rgdal?
> 
> * removing ?/directory/R/x86_64-redhat-linux-gnu-library/3.5/rgdal?
> 
> 
> The downloaded source packages are in
> 
> ?/tmp/RtmpplM8mi/downloaded_packages?
> 
> Warning message:
> 
> In install.packages("rgdal") :
> 
>   installation of package ?rgdal? had non-zero exit status
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From g||ted|||e2014 @end|ng |rom gm@||@com  Tue Sep 18 09:31:20 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Tue, 18 Sep 2018 08:31:20 +0100
Subject: [R] 
 customizing the number of decimal places in xtable: RESOLVED
In-Reply-To: <E841EFA0-1BB1-47C9-8D9F-C27D16C92E50@dcn.davis.ca.us>
References: <CAC8ss30d=5F6Ckv1dA-XJy8DzCDBcK3a0y8NPe9ZHEbYov1jyw@mail.gmail.com>
 <EE269AA9-F2B2-4082-BB99-E237BC9E7266@dcn.davis.ca.us>
 <CAC8ss33H5f4=BndZ7EwmfwbE=HnKW0p-GqAHKxu3w+r-zN=ezw@mail.gmail.com>
 <E841EFA0-1BB1-47C9-8D9F-C27D16C92E50@dcn.davis.ca.us>
Message-ID: <CAC8ss31EgPgUV8TjjowBcoga-xoOYk145qjNE=m4_9a=qmH2ng@mail.gmail.com>

Dear Jeff,

Great!! Thanks for your concern/good advice.

Best regards
Ogbos

On Tue, Sep 18, 2018 at 8:24 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I gather you find the content of the help page for the xtable function
> hard to understand, but you need to build the skill of reading them and
> gathering clues about functions you call from them.
>
> * They always have a usage section that briefly summarizes how the
> function is called and what the default values are for those parameters
> that do have defaults.
>
> * They always mention what each parameter is for. (The help page may not
> always be thorough enough to suit your preference, but CRAN requires the
> author to make some effort to describe every parameter. Note that people
> posting packages on GitHub have no one insisting that they put in this
> effort, so beware that quality may vary more if you start using non-CRAN
> packages.) The digits parameter is used by many data formatting functions,
> and it can usually be specified as a vector with each element affecting a
> corresponding column of data in order.
>
> * They always indicate what kind of Value will be returned from the
> function.
>
> * They usually have Notes on how the function reacts to different input
> values.
>
> * They often have Examples of how to use the function.
>
> * They often have  a See Also section indicating what other functions you
> might find relevant when using this function.
>
> * They sometimes have a section listing References to read to learn more
> about the theory behind the function.
>
> Not all authors of help pages put the same level of effort into making
> help pages readable, and there is undoubtedly some shorthand notation that
> gives you key information more compactly than you might wish for as a
> beginner. However, if you ask for help interpreting specific help pages
> then you may learn more about how they work or the authors may re-write
> certain help pages based on your questions to address the source of your
> confusion.  Beware that if you don't read them first and mention why they
> didn't answer your question then you may get less helpful responses when
> when you do ask questions.
>
> On September 17, 2018 10:49:43 PM PDT, Ogbos Okike <
> giftedlife2014 at gmail.com> wrote:
> >Dear Jeff,
> >
> >Thank you please.
> >
> >I did search before but could not get it resolved. But with your query
> >now,
> >just typed ?xtable as key  search word and the first document I opened
> >gave
> >an indication of digits. Without knowing what it was saying, I tried it
> >in
> >my data and it gave the result I have been looking for.
> >
> >xtable(data, digits=12) and I am fine.
> >
> >Thank you so much.
> >
> >Ogbos
> >
> >On Tue, Sep 18, 2018 at 6:27 AM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> Have you read
> >>
> >> ?xtable
> >>
> >>
> >> On September 17, 2018 7:24:37 PM PDT, Ogbos Okike <
> >> giftedlife2014 at gmail.com> wrote:
> >> >Dear Volunteers,
> >> >
> >> >I have a table involving many decimal places:
> >> >2005-01-04 -2.13339817688037
> >> >2005-01-19 -6.86312349695117
> >> >2005-01-22 -4.33662370554386
> >> >2005-02-10 -1.40789214441639
> >> >2005-02-13 -1.1334121785854
> >> >2005-02-19 -1.28411233010119
> >> >2005-05-09 -1.6895978161324
> >> >2005-05-16 -3.07664523496947
> >> >2005-06-17 -1.69904491217129
> >> >2005-07-17 -3.44289318667434
> >> >2005-08-07 -2.29676435700659
> >> >2005-08-10 -1.08915071542227
> >> >2005-08-24 -1.8244123081697
> >> >2005-09-13 -4.57899147546373
> >> >2005-09-15 -3.96591895962343
> >> > I used xtable to covert this to form of latex table.
> >> >
> >> >The result I have is:
> >> >1 & 2005-01-04 & -2.13 \\
> >> >  2 & 2005-01-19 & -6.86 \\
> >> >  3 & 2005-01-22 & -4.34 \\
> >> >  4 & 2005-02-10 & -1.41 \\
> >> >  5 & 2005-02-13 & -1.13 \\
> >> >  6 & 2005-02-19 & -1.28 \\
> >> >  7 & 2005-05-09 & -1.69 \\
> >> >  8 & 2005-05-16 & -3.08 \\
> >> >  9 & 2005-06-17 & -1.70 \\
> >> >  10 & 2005-07-17 & -3.44 \\
> >> >  11 & 2005-08-07 & -2.30 \\
> >> >  12 & 2005-08-10 & -1.09 \\
> >> >  13 & 2005-08-24 & -1.82 \\
> >> >  14 & 2005-09-13 & -4.58 \\
> >> >  15 & 2005-09-15 & -3.97 \\.
> >> >
> >> >It has truncated the long decimal places. Since it is not want I
> >want,
> >> >I
> >> >have to copy from the original table and place into xtable.
> >> >
> >> >Can you please tell me how to customize the xtable so that I will be
> >> >responsible for the number of decimal places it displays.
> >> >
> >> >Many thanks for your precious time.
> >> >
> >> >Warmest regards
> >> >Ogbos
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep 18 09:36:51 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 18 Sep 2018 00:36:51 -0700
Subject: [R] Open netcdf file in linux
In-Reply-To: <CAN5afy8A8uNCCMHKU8dd8fkxczoDuoEx4AH94ScMF=4WtcJhQg@mail.gmail.com>
References: <CAN5afy8Jkn+N=C3E2aLUC3uB7-xcOmH1BAnNfREb4KEMTYdYAA@mail.gmail.com>
 <16A5250F-1718-4D98-86D8-D5813C24D562@dcn.davis.ca.us>
 <CAN5afy8A8uNCCMHKU8dd8fkxczoDuoEx4AH94ScMF=4WtcJhQg@mail.gmail.com>
Message-ID: <F4222F62-5F35-41ED-AE0F-B7B87F5E54BF@dcn.davis.ca.us>

I find your response confusing still... did you now no longer need help?

If you are still puzzled, then what does 

file.info("file.nc")

return?

Do you see that file in your current directory via your operating system?

On September 17, 2018 11:53:22 PM PDT, lily li <chocold12 at gmail.com> wrote:
>Thanks, you are right that the file path is not correct. I just typed:
>nc_open("file.nc"), and it gave the error above.
>
>On Tue, Sep 18, 2018 at 1:33 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> I really don't know how you expect an answer when you don't show what
>you
>> did or pointed us to an example of a file that yields this error. My
>best
>> blind guess is that you have not given the name of an ncdf file to
>the
>> function.
>>
>> On September 17, 2018 9:44:45 PM PDT, lily li <chocold12 at gmail.com>
>wrote:
>> >Hi R users,
>> >
>> >I have installed ncdf4 package in R from the linux terminal, but
>have
>> >met
>> >this problem when using nc_open to open a .nc file. What is the
>> >problem?
>> >Any help would be appreciated.
>> >
>> >Error in R_nc4_open: Is a directory
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep 18 10:04:35 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 18 Sep 2018 01:04:35 -0700
Subject: [R] bootstrap sample for clustered data
In-Reply-To: <SN4PR0201MB340523E42114316FC94E7837F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
References: <SN4PR0201MB340568ED119F5665F16A9386F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
 <894A4868-409A-44DA-A8D8-2C6CE7F252A6@dcn.davis.ca.us>
 <SN4PR0201MB340523E42114316FC94E7837F71E0@SN4PR0201MB3405.namprd02.prod.outlook.com>
Message-ID: <CEC78D7D-9465-4898-93DE-FD6D02C47DF0@dcn.davis.ca.us>

Seeing what you regard as a satisfactory solution, I think Bert's recommendation to create a factor was superior since it allows you to maintain consistent labeling of your clusters even as the set of clusters changes.

I also still think you are setting the stage for frequent failures of the analyses you plan to apply to these data, but that discussion is out of scope here.

On September 17, 2018 8:29:48 AM PDT, "Liu, Lei" <lei.liu at wustl.edu> wrote:
>Thanks for the help. My friend helped me and here is the solution:
>
>boot.cluster <- function(x, id){
>  boot.id <- sample(unique(id), replace=T)
>out <- lapply(1:length(boot.id),
>function(newid){cbind(x[id%in%boot.id[newid],],newid)})
>  return( do.call("rbind",out) )
>}
>
>Lei
>
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
>Sent: Monday, September 17, 2018 2:32 AM
>To: r-help at r-project.org; Liu, Lei <lei.liu at wustl.edu>;
>r-help at R-project.org
>Subject: Re: [R] bootstrap sample for clustered data
>
>You are telling us that the ID values in your data set indicate
>clusters. However you went about making that determination in the first
>place might be an obvious(?) way to do it again with your bootstrapped
>sample, ignoring the cluster assignments you have in place. This is the
>wrong place to have a discussion about which theoretical method for
>cluster identification you should use, and if you do know that then
>searching the web or using the sos package would be the appropriate way
>to find implementations of a specific clustering algorithm.
>
>I am not an ME expert, but AFAIK "complicated" analyses such as mixed
>effects models tend to have rather hefty appetites for data
>completeness, so you may have to design a special sampling plan in
>order to avoid generating data sets for which those analyses won't
>break, and you will probably need a very large data set to start with
>in order to have sufficient data in each cluster. That is, you may be
>better off keeping the original cluster identification and just
>restructuring your bootstrap sampling to sample within clusters.
>
>The R-sig-me mailing list is probably a better venue for your
>questions. 
>
>On September 16, 2018 8:22:44 PM PDT, "Liu, Lei" <lei.liu at wustl.edu>
>wrote:
>>Hi there,
>>
>>I posted this message before but there may be some confusion in my 
>>previous post. So here is a clearer version:
>>
>>I'd like to do a bootstrap sampling for clustered data. Then I will
>run 
>>some complicated models (say mixed effects models) on the bootstrapped
>
>>sample. Here id is the cluster. Note different clusters have different
>
>>number of subjects, e.g., id 2 has 2 observations, id 3 has 3 
>>observations.
>>
>>id=c(1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5) y=c(.5, .6, .4, .3, .4, 1,
>.9, 
>>1, .5, 2, 2.2, 3) x=c(0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1 )
>>
>>xx=data.frame(id, x, y)
>>
>>boot.cluster <- function(x, id){
>>
>>  boot.id <- sample(unique(id), replace=T)  out <- lapply(boot.id, 
>> function(i) x[id%in%i,])
>>
>>  return( do.call("rbind",out) )
>>
>>}
>>
>>boot.xx=boot.cluster(xx, xx$id)
>>
>>Here is the generated boot.xx dataset:
>>
>>   id x y
>>   3 0 0.4
>>   3 0 1.0
>>   3 0 0.9
>>   1 0 0.5
>>   1 0 0.6
>>   5 1 2.2
>>   5 1 3.0
>>   2 1 0.4
>>   2 1 0.3
>>   1 0 0.5
>>   1 0 0.6
>>
>>You can see that some clusters (ids) appears multiple times (e.g., id
>1 
>>appears in two places - 4 rows), since bootstrap does a sample with 
>>replacement, we could have the same cluster multiple times. Thus, we 
>>cannot do a mixed effects model using this data, as we should assume 
>>all the clusters are different in this new data. Instead, I will 
>>reorganize the data as below (id is reordered from the above boot.xx 
>>data). This is the step I need help:
>>
>>  id x  y
>>   1 0 0.4
>>   1 0 1.0
>>   1 0 0.9
>>   2 0 0.5
>>   2 0 0.6
>>   3 1 2.2
>>   3 1 3.0
>>   4 1 0.4
>>   4 1 0.3
>>   5 0 0.5
>>   5 0 0.6
>>
>>Can someone help me with it? Thanks!
>>
>>Lei Liu
>>Professor of Biostatistics
>>Washington University in St. Louis
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep 18 12:42:30 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 18 Sep 2018 11:42:30 +0100
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
 <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
Message-ID: <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>

Hello,

R 3.4.0 was released 2017-04-21 09:14 and R 3.4.4 2018-03-15 09:04. This 
is before the release of Ubuntu 18.04 LTS so that version of Ubuntu was 
not supported by any sub-version of R 3.4.

At least this is how I understand it. If you want to give R 3.4/Ubuntu 
18.04 a try, you can download older versions of R from CRAN and install 
them.

Do you have any practical reason for asking this?

Rui Barradas

?s 08:24 de 18/09/2018, Ashim Kapoor escreveu:
> Dear Rui,
> 
> I am a little confused.
> 
> See this ---> : R 3.4 packages for Ubuntu on i386 and amd64 are 
> available for all stable Desktop releases of Ubuntu prior to Bionic 
> Beaver (18.04) until their official end of life date. However, only the 
> latest Long Term Support (LTS) release is fully supported. As of June 
> 11, 2018 the supported releases are Artful Aardvark (17.10), Xenial 
> Xerus (16.04; LTS), and Trusty Tahr (14.04; LTS).
> 
> Bionic Beaver ( Ubuntu 18.04 ) is NOT in the list of supported releases 
> for R 3.4? What does this mean ? Can you please clarify ?
> 
> Many thanks,
> Ashim
> 
> On Tue, Sep 18, 2018 at 11:49 AM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     I am not completely sure but I think I installed Ubuntu 18.04 LTS first
>     and R 3.5 days later, so yes, if I'm right it is possible to run R 3.4
>     on 18.04.
> 
>     (You ask whether we can *install* R 3.4 on Ubuntu 18.04.1, I'm
>     saying it
>     can be *run* on Ubuntu 18.04.1.)
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
> 
>     ?s 06:51 de 18/09/2018, Ashim Kapoor escreveu:
>      > Dear All,
>      >
>      > I was reading this page --->
>      > https://cran.r-project.org/bin/linux/ubuntu/README.html
>      >
>      > It says: R 3.4 packages for Ubuntu on i386 and amd64 are
>     available for all
>      > stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04)
>     until
>      > their official end of life date.
>      >
>      > The page also shows how to install R 3.5 on Ubuntu 18.04.1
>      >
>      > My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we only
>      > install R 3.5 ?
>      >
>      > Many thanks,
>      > Ashim
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>



From @@h|mk@poor @end|ng |rom gm@||@com  Tue Sep 18 12:45:56 2018
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Tue, 18 Sep 2018 16:15:56 +0530
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
 <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
 <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>
Message-ID: <CAC8=1eoiB+mzu8mWO9ZmxRYnWOZD3VJojqvcPH_HOfdt+=OUeQ@mail.gmail.com>

Dear Rui,

I tried R 3.4.4 on Ubuntu 18.04.1. It runs FINE except for an inhouse
package created by us. That is why I asked.

Best,
Ashim

On Tue, Sep 18, 2018 at 4:12 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> R 3.4.0 was released 2017-04-21 09:14 and R 3.4.4 2018-03-15 09:04. This
> is before the release of Ubuntu 18.04 LTS so that version of Ubuntu was
> not supported by any sub-version of R 3.4.
>
> At least this is how I understand it. If you want to give R 3.4/Ubuntu
> 18.04 a try, you can download older versions of R from CRAN and install
> them.
>
> Do you have any practical reason for asking this?
>
> Rui Barradas
>
> ?s 08:24 de 18/09/2018, Ashim Kapoor escreveu:
> > Dear Rui,
> >
> > I am a little confused.
> >
> > See this ---> : R 3.4 packages for Ubuntu on i386 and amd64 are
> > available for all stable Desktop releases of Ubuntu prior to Bionic
> > Beaver (18.04) until their official end of life date. However, only the
> > latest Long Term Support (LTS) release is fully supported. As of June
> > 11, 2018 the supported releases are Artful Aardvark (17.10), Xenial
> > Xerus (16.04; LTS), and Trusty Tahr (14.04; LTS).
> >
> > Bionic Beaver ( Ubuntu 18.04 ) is NOT in the list of supported releases
> > for R 3.4  What does this mean ? Can you please clarify ?
> >
> > Many thanks,
> > Ashim
> >
> > On Tue, Sep 18, 2018 at 11:49 AM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     I am not completely sure but I think I installed Ubuntu 18.04 LTS
> first
> >     and R 3.5 days later, so yes, if I'm right it is possible to run R
> 3.4
> >     on 18.04.
> >
> >     (You ask whether we can *install* R 3.4 on Ubuntu 18.04.1, I'm
> >     saying it
> >     can be *run* on Ubuntu 18.04.1.)
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >
> >     ?s 06:51 de 18/09/2018, Ashim Kapoor escreveu:
> >      > Dear All,
> >      >
> >      > I was reading this page --->
> >      > https://cran.r-project.org/bin/linux/ubuntu/README.html
> >      >
> >      > It says: R 3.4 packages for Ubuntu on i386 and amd64 are
> >     available for all
> >      > stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04)
> >     until
> >      > their official end of life date.
> >      >
> >      > The page also shows how to install R 3.5 on Ubuntu 18.04.1
> >      >
> >      > My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we
> only
> >      > install R 3.5 ?
> >      >
> >      > Many thanks,
> >      > Ashim
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >      > and provide commented, minimal, self-contained, reproducible code.
> >      >
> >
>

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep 18 12:49:35 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 18 Sep 2018 11:49:35 +0100
Subject: [R] 
 =?utf-8?q?How_to_troubleshoot_error_=E2=80=9Ccannot_coerce_c?=
 =?utf-8?b?bGFzcyDigJ3igJxncm91cOKAneKAnCB0byBhIGRhdGEuZnJhbWXigJ0/?=
In-Reply-To: <CY4PR13MB0966DE9F77B10894B45F0EA3831D0@CY4PR13MB0966.namprd13.prod.outlook.com>
References: <CY4PR13MB0966DE9F77B10894B45F0EA3831D0@CY4PR13MB0966.namprd13.prod.outlook.com>
Message-ID: <366a886a-c183-d114-7b83-7a80f88fee66@sapo.pt>

Hello,

This is cross-posted from StackOverflow em Portugu?s [1].
Cross-posting is not well seen and you should wait for a while for an 
answer given where you have you original question before posting 
somewhere else.

[1] 
https://pt.stackoverflow.com/questions/330200/como-solucionar-erro-cannot-coerce-class-group-to-a-data-frame

Note: I will try to answer to it, if I have the time, in SOpt. This does 
not mean that you will not get other answers, for instance in R-Help.

Rui Barradas


?s 03:34 de 18/09/2018, Fabiano Fran?a escreveu:
> Dear Volunteers,
> When running the scriptbelow, specifically in the part of reproduction of the data.framesreturned the error:
> 
> Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) : cannot coerce class ""group"" to a data.frame
> 
> I searched the internet and could not reproduce the suggestions for my case, does anyone tell me a way?
> 
> setwd("https://drive.google.com/open?id=1FDMZfWrEjsvleVdNOUiPh8REGjvQHKQx")
> rend <- read.table('IVCM.txt', header = TRUE, sep="\t")
> rend <- transform(rend, Fungicidas=factor(Fungicidas), Doses=factor(Doses), Rep=factor(Rep))
> str(rend)#---------------------------------------------------------------------------# unfolding the interaction in Tukey tests
> 
> require(agricolae)
> require(plyr)
> 
> KinA <- sapply(levels(rend$Doses), simplify=FALSE,
>                 function(Doses){
>                   with(subset(rend, Doses==Doses),
>                        HSD.test(IVCM, Fungicidas,
>                                 DFerror=df.residual(m0),
>                                 MSerror=deviance(m0)/df.residual(m0)))
>                 })
> 
> KinA <- llply(KinA, NULL)
> KinA$M <- gsub(" ", "", KinA$M, fixed=TRUE)
> KinA$trt <- as.factor(as.numeric(as.character(KinA$trt)))
> str(KinA)
> 
> AinK <- sapply(levels(rend$Fungicidas), simplify=FALSE,
>                 function(Fungicidas){
>                   with(subset(rend, Fungicidas==Fungicidas),
>                        HSD.test(IVCM, Doses,
>                                 DFerror=df.residual(m0),
>                                 MSerror=deviance(m0)/df.residual(m0)))
>                 })
> 
> AinK <- llply(AinK, NULL)
> AinK$M <- toupper(gsub(" ", "", AinK$M, fixed=TRUE))
> AinK$trt <- as.factor(as.numeric(as.character(AinK$trt)))
> str(AinK)
> 
> Many thanks
> 
> Regards,
> 
> Fabiano Fran?a da Silva
> Doutorando em Fitotecnia - ESALQ/USP
> MSc Fitotecnia - UFLA
> Eng?. Agr?nomo - UFLA
> (35) 9 9155-5443 TIM
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From |@t@z@hn @end|ng |rom gm@||@com  Tue Sep 18 15:08:18 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Tue, 18 Sep 2018 09:08:18 -0400
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <CAC8=1eoiB+mzu8mWO9ZmxRYnWOZD3VJojqvcPH_HOfdt+=OUeQ@mail.gmail.com>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
 <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
 <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>
 <CAC8=1eoiB+mzu8mWO9ZmxRYnWOZD3VJojqvcPH_HOfdt+=OUeQ@mail.gmail.com>
Message-ID: <CA+vqiLHkJLonpbG6uC8+ZtZZgLQ2LaK8ejVqP3JcuaqtOKwh8g@mail.gmail.com>

This is really the wrong place for this discussion. Please post ubuntu
specific questions to r-sig-debian.

Best,
Ista
On Tue, Sep 18, 2018 at 6:52 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> Dear Rui,
>
> I tried R 3.4.4 on Ubuntu 18.04.1. It runs FINE except for an inhouse
> package created by us. That is why I asked.
>
> Best,
> Ashim
>
> On Tue, Sep 18, 2018 at 4:12 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> > Hello,
> >
> > R 3.4.0 was released 2017-04-21 09:14 and R 3.4.4 2018-03-15 09:04. This
> > is before the release of Ubuntu 18.04 LTS so that version of Ubuntu was
> > not supported by any sub-version of R 3.4.
> >
> > At least this is how I understand it. If you want to give R 3.4/Ubuntu
> > 18.04 a try, you can download older versions of R from CRAN and install
> > them.
> >
> > Do you have any practical reason for asking this?
> >
> > Rui Barradas
> >
> > ?s 08:24 de 18/09/2018, Ashim Kapoor escreveu:
> > > Dear Rui,
> > >
> > > I am a little confused.
> > >
> > > See this ---> : R 3.4 packages for Ubuntu on i386 and amd64 are
> > > available for all stable Desktop releases of Ubuntu prior to Bionic
> > > Beaver (18.04) until their official end of life date. However, only the
> > > latest Long Term Support (LTS) release is fully supported. As of June
> > > 11, 2018 the supported releases are Artful Aardvark (17.10), Xenial
> > > Xerus (16.04; LTS), and Trusty Tahr (14.04; LTS).
> > >
> > > Bionic Beaver ( Ubuntu 18.04 ) is NOT in the list of supported releases
> > > for R 3.4  What does this mean ? Can you please clarify ?
> > >
> > > Many thanks,
> > > Ashim
> > >
> > > On Tue, Sep 18, 2018 at 11:49 AM Rui Barradas <ruipbarradas at sapo.pt
> > > <mailto:ruipbarradas at sapo.pt>> wrote:
> > >
> > >     Hello,
> > >
> > >     I am not completely sure but I think I installed Ubuntu 18.04 LTS
> > first
> > >     and R 3.5 days later, so yes, if I'm right it is possible to run R
> > 3.4
> > >     on 18.04.
> > >
> > >     (You ask whether we can *install* R 3.4 on Ubuntu 18.04.1, I'm
> > >     saying it
> > >     can be *run* on Ubuntu 18.04.1.)
> > >
> > >     Hope this helps,
> > >
> > >     Rui Barradas
> > >
> > >
> > >     ?s 06:51 de 18/09/2018, Ashim Kapoor escreveu:
> > >      > Dear All,
> > >      >
> > >      > I was reading this page --->
> > >      > https://cran.r-project.org/bin/linux/ubuntu/README.html
> > >      >
> > >      > It says: R 3.4 packages for Ubuntu on i386 and amd64 are
> > >     available for all
> > >      > stable Desktop releases of Ubuntu prior to Bionic Beaver (18.04)
> > >     until
> > >      > their official end of life date.
> > >      >
> > >      > The page also shows how to install R 3.5 on Ubuntu 18.04.1
> > >      >
> > >      > My query is : Can we install R 3.4 on Ubuntu 18.04.1 ? Or can we
> > only
> > >      > install R 3.5 ?
> > >      >
> > >      > Many thanks,
> > >      > Ashim
> > >      >
> > >      >       [[alternative HTML version deleted]]
> > >      >
> > >      > ______________________________________________
> > >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> > >     -- To UNSUBSCRIBE and more, see
> > >      > https://stat.ethz.ch/mailman/listinfo/r-help
> > >      > PLEASE do read the posting guide
> > >     http://www.R-project.org/posting-guide.html
> > >      > and provide commented, minimal, self-contained, reproducible code.
> > >      >
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @@r@h@go@|ee @end|ng |rom gm@||@com  Tue Sep 18 15:25:35 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Tue, 18 Sep 2018 09:25:35 -0400
Subject: [R] Set the same colour range for 2 != rasters
In-Reply-To: <CAPL76w89=D1YRax-gN_ZRoeJfwspHcS5duMe8zxqsoc5S1rnrQ@mail.gmail.com>
References: <CAPL76w89=D1YRax-gN_ZRoeJfwspHcS5duMe8zxqsoc5S1rnrQ@mail.gmail.com>
Message-ID: <CAM_vjuk1bJPD9u9MCGfa6SHXvAJT_i3uZSJtv6K8-pzO71CeaA@mail.gmail.com>

Hi Jackson,

I think you would have gotten a faster response if you'd provided a
reproducible example. I at least let this message sit until I had time
to figure out what you were doing. If you have more raster questions,
there's also a r-sig-geo mailing list that would be more appropriate.

Nonetheless, you seem to be overthinking the problem. Is this what you need:

library(raster)

r1 <- matrix(sample(seq( 3, 20), size=25, replace=TRUE), 5, 5)
r2 <- matrix(sample(seq(15, 31), size=25, replace=TRUE), 5, 5)

r1 <- raster(r1)
r2 <- raster(r2)

cols <-colorRampPalette(c("royalblue","springgreen","yellow","orange","red"))(29)

# plot two rasters with different ranges but the same colors
par(mfrow=c(1, 2))
plot(r1, col=cols, zlim=c(3, 31))
plot(r2, col=cols, zlim=c(3, 31))

Sarah

On Sun, Sep 16, 2018 at 10:59 PM Jackson Rodrigues
<jacksonmrodrigues at gmail.com> wrote:
>
> Dear all,
>
> My name is Jackson.
> I am trying to set the same colour range for 2 rasters (max and min
> temperatures). Both rasters have different numerical ranges but the same
> dimensions
> dimensions  : 4346, 4365, 18970290, 1  (nrow, ncol, ncell, nlayers)
>
> The lowest value is 3 and the highest is 31. So my colour palette should
> range from 3 to 31 and be useful for both temperatures
>
> However I got a message saying that S4 and vector cannot be coerced.
> So far I understand why it is not working but how to fix it?
>
> A few lines from my code.
>
> ####
> cols<-colorRampPalette(c("royalblue","springgreen","yellow","orange","red"))(29)
>
> Temp.interval = seq(from=3, to=31)
>
> # creating colour vectors
> col1 <- cols[findInterval(TMin_masked$prj, vec =  Temp.interval  )]
>
> Error in as.double(x) :
>   cannot coerce type 'S4' to vector of type 'double'
> ####
>
> Thank you all!
>
> Best regards.
>
> Jackson
>

-- 
Sarah Goslee
http://www.functionaldiversity.org



From beno|t@v@|||@nt @end|ng |rom no-|og@org  Tue Sep 18 15:38:15 2018
From: beno|t@v@|||@nt @end|ng |rom no-|og@org (Benoit Vaillant)
Date: Tue, 18 Sep 2018 15:38:15 +0200
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <CA+vqiLHkJLonpbG6uC8+ZtZZgLQ2LaK8ejVqP3JcuaqtOKwh8g@mail.gmail.com>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
 <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
 <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>
 <CAC8=1eoiB+mzu8mWO9ZmxRYnWOZD3VJojqvcPH_HOfdt+=OUeQ@mail.gmail.com>
 <CA+vqiLHkJLonpbG6uC8+ZtZZgLQ2LaK8ejVqP3JcuaqtOKwh8g@mail.gmail.com>
Message-ID: <20180918133815.sgl7hqg22v5u4vxt@auroras.fr>

Hello,

On Tue, Sep 18, 2018 at 09:08:18AM -0400, Ista Zahn wrote:
> This is really the wrong place for this discussion. Please post ubuntu
> specific questions to r-sig-debian.

While i guess your asking to get on to r-sig-debian is a true start,
the package that seems to be causing troubles is "in house".

No matter the mailing-list the user should end up, the appropriate
consideration should be to get back at who made that package.

Cheers, :)

-- 
Beno?t Vaillant

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 866 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180918/33b7d99c/attachment-0002.sig>

From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Sep 18 22:35:05 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 19 Sep 2018 08:35:05 +1200
Subject: [R] 
 [FORGED]  Unable to update R 3.4 to R 3.5 in Ubuntu 18.04 LTS
In-Reply-To: <CAMo+egkiwPriFXCbSvMH3234BEitjBMxuwmYBC4gEjPdzUqA8g@mail.gmail.com>
References: <CAMo+egkiwPriFXCbSvMH3234BEitjBMxuwmYBC4gEjPdzUqA8g@mail.gmail.com>
Message-ID: <a0bb17da-92a6-dca6-0e92-11f390989efc@auckland.ac.nz>

On 09/18/2018 04:14 AM, RUPJYOTI DAS wrote:
> Dear All,
> I am using R to carry out RNA-Seq workflow in my standalone machine which
> needs the latest R version >=3.5. I was trying to update firstly removing
> the R 3.4 and reinstalling from scratch again the latest version. Can
> anybody just guide me how to carry out the process as I am getting only R
> 3.4 again and again.
> Also when I remove the
> *deb ... bionic-cran35 (mirror for R cran )*
> 
> from the* source.list* file (opened by* sudo gedit /etc/apt/sources.list*)
> the command *sudo apt-get update* works fine which does not upgrade the R
> 3.4 to R 3.5.1.
> Adding the line
> *deb ... bionic-cran35/ *
> gives the attached error log*. **Please find the attached file and  do
> check.*
> 
> Any answers and suggestions will be of immense help!
> 
> Thanking you!

You may find the following link helpful.  I did.

https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-18-04-quickstart

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From @@h|mk@poor @end|ng |rom gm@||@com  Wed Sep 19 05:42:58 2018
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Wed, 19 Sep 2018 09:12:58 +0530
Subject: [R] Does R version 3.4.4 work on Ubuntu 18.04.1
In-Reply-To: <20180918133815.sgl7hqg22v5u4vxt@auroras.fr>
References: <CAC8=1epF9tMdL9dsGc3nPkH0Q=N4misA5kWxzHnFeeDG6JMnGQ@mail.gmail.com>
 <129d07dd-1798-5936-10b4-f49046f2a3f3@sapo.pt>
 <CAC8=1erFcqace8Z1OOQwxTt3H+BbnYOCK_GVo768wKhSkXA9EQ@mail.gmail.com>
 <f8502f49-7b17-799e-061b-89f4f1baab3e@sapo.pt>
 <CAC8=1eoiB+mzu8mWO9ZmxRYnWOZD3VJojqvcPH_HOfdt+=OUeQ@mail.gmail.com>
 <CA+vqiLHkJLonpbG6uC8+ZtZZgLQ2LaK8ejVqP3JcuaqtOKwh8g@mail.gmail.com>
 <20180918133815.sgl7hqg22v5u4vxt@auroras.fr>
Message-ID: <CAC8=1erW2XVM605E9e4Bqzf5rK7JPi5VEuJk1XhQ7MUevUxzXw@mail.gmail.com>

Dear All,

Okay and thank you.

Best Regards,
Ashim

On Wed, Sep 19, 2018 at 3:32 AM Benoit Vaillant <benoit.vaillant at no-log.org>
wrote:

> Hello,
>
> On Tue, Sep 18, 2018 at 09:08:18AM -0400, Ista Zahn wrote:
> > This is really the wrong place for this discussion. Please post ubuntu
> > specific questions to r-sig-debian.
>
> While i guess your asking to get on to r-sig-debian is a true start,
> the package that seems to be causing troubles is "in house".
>
> No matter the mailing-list the user should end up, the appropriate
> consideration should be to get back at who made that package.
>
> Cheers, :)
>
> --
> Beno?t Vaillant
>

	[[alternative HTML version deleted]]



From ph@edru@v @end|ng |rom gm@||@com  Wed Sep 19 13:00:23 2018
From: ph@edru@v @end|ng |rom gm@||@com (Andrew)
Date: Wed, 19 Sep 2018 12:00:23 +0100
Subject: [R] Smallest Space Analysis (SSA) in R
Message-ID: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>

Hi

As part of my forensics psych course, we have been introduced to 
Guttman's smallest space analysis (SSA). I want to explore this approach 
using R, but despite finding some queries on the web about this same 
thing, have yet to find any answers. The MASS package doesn't seem to do 
the job, and the only thing I have been able to find is some proprietary 
software HUDAP? (Hebrew University Data Analysis Package) which may/ not 
be compatible with R (or GNU/Linux for that matter).

Does anyone have information on how to do SSA using R?

Many thanks

Andrew


	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Wed Sep 19 14:37:29 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 19 Sep 2018 12:37:29 +0000
Subject: [R] New to R
In-Reply-To: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
References: <DM6PR01MB390036C0EAB91930EC350F4DBC190@DM6PR01MB3900.prod.exchangelabs.com>
Message-ID: <BN7PR02MB5073092B6387599CE474622CEA1C0@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello Jim, as new use"R" myself, 1.5 years I HIGHLY recommend emersion.

Subscribe to :
https://www.r-bloggers.com/

https://stackoverflow.com

http://blog.revolutionanalytics.com/

Anything Hadley Wickam, he has several free e-books.

Depending on  r-help (r-help at r-project.org<mailto:r-help at r-project.org>) is a tough way to go, they can be hard on new users without the formality of:
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>

Be prepared for partial suggestions that depend on your further research, trial and error!

WHP



From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Blackburn
Sent: Friday, September 14, 2018 2:00 PM
To: r-help at r-project.org
Subject: [R] New to R

I am newly subscribed to r-project.


I have recently plunged into R on a totally self-taught basis (may not have been the smartest decision!)



I am attempting to download tickers as a time series. I can successfully create RDA files but I want to convert them to CVS. Following is the code I have created so far.



if (!require(BatchGetSymbols)) install.packages('BatchGetSymbols')

library(BatchGetSymbols)

tickers <- c('SPY','VCR', 'RPG')

first.date<http://first.date> <- Sys.Date()-365

last.date<http://last.date> <- Sys.Date<http://Sys.Date>

l.out <- BatchGetSymbols(tickers = tickers,

first.date<http://first.date> = first.date<http://first.date>,

last.date<http://last.date> = last.date<http://last.date>,

cache.folder = file.path("c://Users/Owner/Documents/R",

+ 'BGS_Cache') )

print(l.out$df.control)

print(l.out$df.tickers)







I can print(l.out) and see that it contains all the data, but it is not a data.frame



Can anyone help with creating a data.frame and then converting to CSV?



Any help is GREATLY appreciated!



Thanks



Jim


Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986<https://go.microsoft.com/fwlink/?LinkId=550986>> for Windows 10


[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Sep 19 15:07:41 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Wed, 19 Sep 2018 08:07:41 -0500
Subject: [R] frequent-pattern tree
Message-ID: <000a01d45019$c043a490$40caedb0$@sbcglobal.net>

r-help

 

Is there a r-package that will construct a frequent-pattern (FP) tree ?

 

Jeff Reichman


	[[alternative HTML version deleted]]



From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Sep 19 15:18:02 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 19 Sep 2018 09:18:02 -0400
Subject: [R] frequent-pattern tree
In-Reply-To: <000a01d45019$c043a490$40caedb0$@sbcglobal.net>
References: <000a01d45019$c043a490$40caedb0$@sbcglobal.net>
Message-ID: <CAM_vjukY2HajzUEdbjrs2f5YjB6Vxy1L1pDKPWbcbFns1ZyK=Q@mail.gmail.com>

A quick search on the incredibly useful rseek.org turns up a couple of
possibilities, including the rCBA package, and

https://stackoverflow.com/questions/38240190/frequent-pattern-growth-in-r-or-python

This is out of my area, but the searching suggests that FP tree and FP
growth are closely linked algorithms, at least.

With more knowledgeable search terms you can likely do a better job on
rseek.org yourself.

Sarah
On Wed, Sep 19, 2018 at 9:08 AM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>
> r-help
>
>
>
> Is there a r-package that will construct a frequent-pattern (FP) tree ?
>
>
>
> Jeff Reichman
>


-- 
Sarah Goslee
http://www.functionaldiversity.org



From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Sep 19 16:55:04 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 19 Sep 2018 15:55:04 +0100
Subject: [R] as.Date and ylim in empty plot
Message-ID: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>

Dear Experts,
I generated the plot attached. Every other thing is OK except the black
horizontal lines which should appear like points or dots as the coloured
ones. I can't understand why.

I tried to change it to look like dots by calling empty plots so that I
will add them as points.

Since I have a range of date that can fall any where within 2005, I tried:

plot(1, type="n", xlab="", ylab="",
xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")), ylim=c(-.5, -10))

ylim worked fine but xlim instead of appearing like date as indicated on
the x-axes of the attached plot, translated to ordinary numbers (12800,
12900,13000, 13100).

All the data is of the same format:
2005-01-04 -2.76105935648091
2005-01-19 -9.60813496025994
2005-01-22 -7.92101965866777
2005-02-19 -1.61308152604905
2005-02-24 -1.51497015807712
2005-05-09 -2.06465797304654
2005-05-11 -1.14840389007051
2005-05-16 -3.85281900888504
2005-06-13 -1.18659683796617
2005-06-17 -3.48787712566258
2005-06-22 -1.14223758296308
2005-07-18 -4.96013018907366
2005-08-03 -1.24313324914368
2005-08-07 -2.96672894841722
2005-08-10 -1.11868063781156
2005-08-25 -1.46453734930983
2005-09-13 -8.00895215754776
2005-09-15 -6.63439065989452
2005-10-13 -2.25054996925846
2005-12-15 -1.08933890547705

Thank you so much for your input.

Best regards
Ogbos


From m@cqueen1 @end|ng |rom ||n|@gov  Thu Sep 20 00:20:53 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Wed, 19 Sep 2018 22:20:53 +0000
Subject: [R] as.Date and ylim in empty plot
In-Reply-To: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
References: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
Message-ID: <463D5957-3728-4AC6-A83E-FF2F1662052F@llnl.gov>

I'm a little surprised at some of what happens, but you can get date labels on the x axis like this:

drng <- as.Date( c('2005-1-1' , '2005-12-31') )
plot(1, type="n", xlab="", ylab="", xaxt='n', xlim=drng, ylim=c(-.5, -10))
axis(1, at= pretty(drng), lab=format(pretty(drng)))

and if you prefer some other date format, specify it in the call to format()

Did you intend to reverse the direction of your  y axis?

-Don
--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/19/18, 7:55 AM, "R-help on behalf of Ogbos Okike" <r-help-bounces at r-project.org on behalf of giftedlife2014 at gmail.com> wrote:

    Dear Experts,
    I generated the plot attached. Every other thing is OK except the black
    horizontal lines which should appear like points or dots as the coloured
    ones. I can't understand why.
    
    I tried to change it to look like dots by calling empty plots so that I
    will add them as points.
    
    Since I have a range of date that can fall any where within 2005, I tried:
    
    plot(1, type="n", xlab="", ylab="",
    xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")), ylim=c(-.5, -10))
    
    ylim worked fine but xlim instead of appearing like date as indicated on
    the x-axes of the attached plot, translated to ordinary numbers (12800,
    12900,13000, 13100).
    
    All the data is of the same format:
    2005-01-04 -2.76105935648091
    2005-01-19 -9.60813496025994
    2005-01-22 -7.92101965866777
    2005-02-19 -1.61308152604905
    2005-02-24 -1.51497015807712
    2005-05-09 -2.06465797304654
    2005-05-11 -1.14840389007051
    2005-05-16 -3.85281900888504
    2005-06-13 -1.18659683796617
    2005-06-17 -3.48787712566258
    2005-06-22 -1.14223758296308
    2005-07-18 -4.96013018907366
    2005-08-03 -1.24313324914368
    2005-08-07 -2.96672894841722
    2005-08-10 -1.11868063781156
    2005-08-25 -1.46453734930983
    2005-09-13 -8.00895215754776
    2005-09-15 -6.63439065989452
    2005-10-13 -2.25054996925846
    2005-12-15 -1.08933890547705
    
    Thank you so much for your input.
    
    Best regards
    Ogbos
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Sep 20 00:34:45 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 19 Sep 2018 15:34:45 -0700
Subject: [R] as.Date and ylim in empty plot
In-Reply-To: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
References: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
Message-ID: <431EE567-5F41-4638-B31A-F6E7E3E95782@comcast.net>


> On Sep 19, 2018, at 7:55 AM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Dear Experts,
> I generated the plot attached. Every other thing is OK except the black
> horizontal lines which should appear like points or dots as the coloured
> ones. I can't understand why.
> 
> I tried to change it to look like dots by calling empty plots so that I
> will add them as points.
> 
> Since I have a range of date that can fall any where within 2005, I tried:
> 
> plot(1, type="n", xlab="", ylab="",
> xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")), ylim=c(-.5, -10))
> 
> ylim worked fine but xlim instead of appearing like date as indicated on
> the x-axes of the attached plot, translated to ordinary numbers (12800,
> 12900,13000, 13100).
> 
> All the data is of the same format:
> 2005-01-04 -2.76105935648091
> 2005-01-19 -9.60813496025994
> 2005-01-22 -7.92101965866777
> 2005-02-19 -1.61308152604905
> 2005-02-24 -1.51497015807712
> 2005-05-09 -2.06465797304654
> 2005-05-11 -1.14840389007051
> 2005-05-16 -3.85281900888504
> 2005-06-13 -1.18659683796617
> 2005-06-17 -3.48787712566258
> 2005-06-22 -1.14223758296308
> 2005-07-18 -4.96013018907366
> 2005-08-03 -1.24313324914368
> 2005-08-07 -2.96672894841722
> 2005-08-10 -1.11868063781156
> 2005-08-25 -1.46453734930983
> 2005-09-13 -8.00895215754776
> 2005-09-15 -6.63439065989452
> 2005-10-13 -2.25054996925846
> 2005-12-15 -1.08933890547705

You did not succeed in creating a plot that the rhelp mail server would accept. My guess is that the first column is a factor variable and that you did not use colClasses when doing your data input.

dd <- read.table(text="2005-01-04 -2.76105935648091
2005-01-19 -9.60813496025994
2005-01-22 -7.92101965866777
2005-02-19 -1.61308152604905
2005-02-24 -1.51497015807712
2005-05-09 -2.06465797304654
2005-05-11 -1.14840389007051
2005-05-16 -3.85281900888504
2005-06-13 -1.18659683796617
2005-06-17 -3.48787712566258
2005-06-22 -1.14223758296308
2005-07-18 -4.96013018907366
2005-08-03 -1.24313324914368
2005-08-07 -2.96672894841722
2005-08-10 -1.11868063781156
2005-08-25 -1.46453734930983
2005-09-13 -8.00895215754776
2005-09-15 -6.63439065989452
2005-10-13 -2.25054996925846
2005-12-15 -1.08933890547705", colClasses=c("Date","numeric")
)


No problems with:

 plot(dd[[1]], dd[[2]], xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")))

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 4727 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180919/0a6f7326/attachment-0002.pdf>

-------------- next part --------------


(Not a particularly good test of the use of an xlim argument since nothing was excluded.)

PDF's are accepted. PNGs are not.

-- 
David.
> 
> Thank you so much for your input.
> 
> Best regards
> Ogbos
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law






From g||ted|||e2014 @end|ng |rom gm@||@com  Thu Sep 20 07:48:55 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Thu, 20 Sep 2018 06:48:55 +0100
Subject: [R] as.Date and ylim in empty plot: RESOLVED
In-Reply-To: <431EE567-5F41-4638-B31A-F6E7E3E95782@comcast.net>
References: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
 <431EE567-5F41-4638-B31A-F6E7E3E95782@comcast.net>
Message-ID: <CAC8ss31dX7fnhWUXv97z_Fjd4pk8jmfqP1=Gc8ijUvYf1WwvpA@mail.gmail.com>

Hi David,
That's it!!! The outcome is attached.

Many thanks please.

Best
Ogbos

On Wed, Sep 19, 2018 at 11:34 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 19, 2018, at 7:55 AM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >
> > Dear Experts,
> > I generated the plot attached. Every other thing is OK except the black
> > horizontal lines which should appear like points or dots as the coloured
> > ones. I can't understand why.
> >
> > I tried to change it to look like dots by calling empty plots so that I
> > will add them as points.
> >
> > Since I have a range of date that can fall any where within 2005, I
> tried:
> >
> > plot(1, type="n", xlab="", ylab="",
> > xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")), ylim=c(-.5, -10))
> >
> > ylim worked fine but xlim instead of appearing like date as indicated on
> > the x-axes of the attached plot, translated to ordinary numbers (12800,
> > 12900,13000, 13100).
> >
> > All the data is of the same format:
> > 2005-01-04 -2.76105935648091
> > 2005-01-19 -9.60813496025994
> > 2005-01-22 -7.92101965866777
> > 2005-02-19 -1.61308152604905
> > 2005-02-24 -1.51497015807712
> > 2005-05-09 -2.06465797304654
> > 2005-05-11 -1.14840389007051
> > 2005-05-16 -3.85281900888504
> > 2005-06-13 -1.18659683796617
> > 2005-06-17 -3.48787712566258
> > 2005-06-22 -1.14223758296308
> > 2005-07-18 -4.96013018907366
> > 2005-08-03 -1.24313324914368
> > 2005-08-07 -2.96672894841722
> > 2005-08-10 -1.11868063781156
> > 2005-08-25 -1.46453734930983
> > 2005-09-13 -8.00895215754776
> > 2005-09-15 -6.63439065989452
> > 2005-10-13 -2.25054996925846
> > 2005-12-15 -1.08933890547705
>
> You did not succeed in creating a plot that the rhelp mail server would
> accept. My guess is that the first column is a factor variable and that you
> did not use colClasses when doing your data input.
>
> dd <- read.table(text="2005-01-04 -2.76105935648091
> 2005-01-19 -9.60813496025994
> 2005-01-22 -7.92101965866777
> 2005-02-19 -1.61308152604905
> 2005-02-24 -1.51497015807712
> 2005-05-09 -2.06465797304654
> 2005-05-11 -1.14840389007051
> 2005-05-16 -3.85281900888504
> 2005-06-13 -1.18659683796617
> 2005-06-17 -3.48787712566258
> 2005-06-22 -1.14223758296308
> 2005-07-18 -4.96013018907366
> 2005-08-03 -1.24313324914368
> 2005-08-07 -2.96672894841722
> 2005-08-10 -1.11868063781156
> 2005-08-25 -1.46453734930983
> 2005-09-13 -8.00895215754776
> 2005-09-15 -6.63439065989452
> 2005-10-13 -2.25054996925846
> 2005-12-15 -1.08933890547705", colClasses=c("Date","numeric")
> )
>
>
> No problems with:
>
>  plot(dd[[1]], dd[[2]],
> xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")))
>
>
> (Not a particularly good test of the use of an xlim argument since nothing
> was excluded.)
>
> PDF's are accepted. PNGs are not.
>
> --
> David.
> >
> > Thank you so much for your input.
> >
> > Best regards
> > Ogbos
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Ogbos.pdf
Type: application/pdf
Size: 5483 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180920/e97bcfc1/attachment-0002.pdf>

From t@n@@@ @end|ng |rom gm@||@com  Thu Sep 20 09:26:12 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 20 Sep 2018 00:26:12 -0700
Subject: [R] about the series of numbers
Message-ID: <CA+JEM009nvbnNzm3twbxx+UxSTxnvH6vnYVmbs6L5RdCanTZgQ@mail.gmail.com>

Dear all,

if I may ask please a question that is likely very naive :

shall I write in R > "1:9", it will generate "1 2 3 4 5 6 7 8 9"

shall I write > "0.1:0.9", why does it generate only 0.1 ?

thank you !

-- bogdan

	[[alternative HTML version deleted]]



From @|k@u||m @end|ng |rom |@@tm@||@|m  Thu Sep 20 09:32:34 2018
From: @|k@u||m @end|ng |rom |@@tm@||@|m (Albrecht Kauffmann)
Date: Thu, 20 Sep 2018 09:32:34 +0200
Subject: [R] about the series of numbers
In-Reply-To: <CA+JEM009nvbnNzm3twbxx+UxSTxnvH6vnYVmbs6L5RdCanTZgQ@mail.gmail.com>
References: <CA+JEM009nvbnNzm3twbxx+UxSTxnvH6vnYVmbs6L5RdCanTZgQ@mail.gmail.com>
Message-ID: <1537428754.3568899.1514420408.520B336F@webmail.messagingengine.com>

Dear Bogdan,

for increments <>1, it needs "by". Try

seq(.1,.9,.1)

Best,
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Do, 20. Sep 2018, um 09:26, schrieb Bogdan Tanasa:
> Dear all,
> 
> if I may ask please a question that is likely very naive :
> 
> shall I write in R > "1:9", it will generate "1 2 3 4 5 6 7 8 9"
> 
> shall I write > "0.1:0.9", why does it generate only 0.1 ?
> 
> thank you !
> 
> -- bogdan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep 20 11:20:36 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 20 Sep 2018 09:20:36 +0000
Subject: [R] about the series of numbers
In-Reply-To: <CA+JEM009nvbnNzm3twbxx+UxSTxnvH6vnYVmbs6L5RdCanTZgQ@mail.gmail.com>
References: <CA+JEM009nvbnNzm3twbxx+UxSTxnvH6vnYVmbs6L5RdCanTZgQ@mail.gmail.com>
Message-ID: <e32aebcc1a124571ba495df9c451a37f@SRVEXCHCM1302.precheza.cz>

Hi

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Bogdan Tanasa
> Sent: Thursday, September 20, 2018 9:26 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] about the series of numbers
>
> Dear all,
>
> if I may ask please a question that is likely very naive :
>
> shall I write in R > "1:9", it will generate "1 2 3 4 5 6 7 8 9"
>
> shall I write > "0.1:0.9", why does it generate only 0.1 ?

Because it is said in help page!!!

"For other arguments from:to is equivalent to seq(from, to), and generates a sequence from *from* to *to* in steps of 1 or -1."

sequence from 0.1 to 0.9 in steps 1 starts at 0.1 but the second item is 1.1 which is bigger than 0.9 therefore the result is only one item 0.1.

Cheers
Petr

>
> thank you !
>
> -- bogdan
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From momtoom@x @end|ng |rom gm@||@com  Thu Sep 20 17:08:30 2018
From: momtoom@x @end|ng |rom gm@||@com (Lynette Chang)
Date: Thu, 20 Sep 2018 11:08:30 -0400
Subject: [R] How to vectorize this function
Message-ID: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>

Hello everyone,

     I?ve a function with five input argument and one output number. 
	  impVolC <- function(callM, K, T, F, r)

     I hope this function can take five vectors as input, then return one vector as output. My vectorization ran into problems with the nested if-else operation. As a result, I have to write another for loop to call this function. Can anyone suggest some methods to overcome it? I put my code below, thanks.

impVolC <- function(callM, K, T, F, r){


 if(y >= 0){
     call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
     if(callM <= call0){
       sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
     }else{
       sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
     }
 }else{
     call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
     if(callM <= call0){
       sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
     }else{
       sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
     }
 }
 sig
} 

for(i in 1:length(call)){
 sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r = r_m)  
}



From dc@r|@on @end|ng |rom t@mu@edu  Thu Sep 20 18:05:12 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Thu, 20 Sep 2018 16:05:12 +0000
Subject: [R] How to vectorize this function
In-Reply-To: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
Message-ID: <8c47b717c4b646429f29411e37c5dc98@tamu.edu>

Your function takes an argument "F" that is never used and uses an object "y" which is not defined. Give us some data to use for testing different approaches along with the answer you expect. It may be possible to use two ifelse() functions instead of the loop.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Lynette Chang
Sent: Thursday, September 20, 2018 10:09 AM
To: r-help at r-project.org
Subject: [R] How to vectorize this function

Hello everyone,

     I?ve a function with five input argument and one output number. 
	  impVolC <- function(callM, K, T, F, r)

     I hope this function can take five vectors as input, then return one vector as output. My vectorization ran into problems with the nested if-else operation. As a result, I have to write another for loop to call this function. Can anyone suggest some methods to overcome it? I put my code below, thanks.

impVolC <- function(callM, K, T, F, r){


 if(y >= 0){
     call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
     if(callM <= call0){
       sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
     }else{
       sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
     }
 }else{
     call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
     if(callM <= call0){
       sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
     }else{
       sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
     }
 }
 sig
} 

for(i in 1:length(call)){
 sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r = r_m) }

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 20 18:42:42 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 20 Sep 2018 09:42:42 -0700
Subject: [R] How to vectorize this function
In-Reply-To: <8c47b717c4b646429f29411e37c5dc98@tamu.edu>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
 <8c47b717c4b646429f29411e37c5dc98@tamu.edu>
Message-ID: <CAGxFJbRxE+PApCwW7fb2peZZJZ9DtHCqWYV5UBMHP9nUCg6n5g@mail.gmail.com>

Also:

What package does polya() come from and "gamma" (as a numeric value)is
undefined (it is a function).


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 20, 2018 at 9:06 AM David L Carlson <dcarlson at tamu.edu> wrote:

> Your function takes an argument "F" that is never used and uses an object
> "y" which is not defined. Give us some data to use for testing different
> approaches along with the answer you expect. It may be possible to use two
> ifelse() functions instead of the loop.
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Lynette Chang
> Sent: Thursday, September 20, 2018 10:09 AM
> To: r-help at r-project.org
> Subject: [R] How to vectorize this function
>
> Hello everyone,
>
>      I?ve a function with five input argument and one output number.
>           impVolC <- function(callM, K, T, F, r)
>
>      I hope this function can take five vectors as input, then return one
> vector as output. My vectorization ran into problems with the nested
> if-else operation. As a result, I have to write another for loop to call
> this function. Can anyone suggest some methods to overcome it? I put my
> code below, thanks.
>
> impVolC <- function(callM, K, T, F, r){
>
>
>  if(y >= 0){
>      call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
>      if(callM <= call0){
>        sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>      }else{
>        sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>      }
>  }else{
>      call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
>      if(callM <= call0){
>        sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
>      }else{
>        sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>      }
>  }
>  sig
> }
>
> for(i in 1:length(call)){
>  sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r =
> r_m) }
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Thu Sep 20 19:14:41 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Thu, 20 Sep 2018 13:14:41 -0400
Subject: [R] =?utf-8?q?Make_Month_variable_be_called_=E2=80=9CMay?=
	=?utf-8?b?4oCdLOKAnEp1bmXigJ0gZXRjLiwgaW5zdGVhZCBvZiBhIG51bWVyaWMg?=
	=?utf-8?q?quantity_5=2C6=2C_etc=2E?=
Message-ID: <CAE9stmevB6+5zfMOwa-HmfEa2gn8nSbpCicXGkwDTvmC5cCRCQ@mail.gmail.com>

Dear All:

*Re:* How to make the Month variable be called ?May?,?June?, "July",
"August", "September" instead of a numeric quantity (5,6,7,8,9)


In the airquality data set, please see the code below; How to make the
Month variable be called ?May?,?June?, "July", "August", "September"
instead of a numeric quantity (5,6,7,8,9)



data(airquality)

head(airquality)


#### Making Day and Month categorical variables


airquality$Day <- factor(airquality$Day)

airquality$Month <- factor(airquality$Month)


head(airquality)


> head(airquality)
  Ozone Solar.R Wind Temp Month Day
1    41     190  7.4   67     5   1
2    36     118  8.0   72     5   2
3    12     149 12.6   74     5   3
4    18     313 11.5   62     5   4
5    NA      NA 14.3   56     5   5
6    28      NA 14.9   66     5   6
>



Thank you very much for your help in advance


with thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 20 19:36:59 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 20 Sep 2018 10:36:59 -0700
Subject: [R] =?utf-8?q?Make_Month_variable_be_called_=E2=80=9CMay?=
 =?utf-8?b?4oCdLOKAnEp1bmXigJ0gZXRjLiwgaW5zdGVhZCBvZiBhIG51bWVyaWMgcXVh?=
 =?utf-8?b?bnRpdHkgNSw2LCBldGMu?=
In-Reply-To: <CAE9stmevB6+5zfMOwa-HmfEa2gn8nSbpCicXGkwDTvmC5cCRCQ@mail.gmail.com>
References: <CAE9stmevB6+5zfMOwa-HmfEa2gn8nSbpCicXGkwDTvmC5cCRCQ@mail.gmail.com>
Message-ID: <39BBA96A-667F-4CE2-A513-26816EFAA570@dcn.davis.ca.us>

airquality$Month <- factor(airquality$Month, levels=1:12, labels=month.name )

On September 20, 2018 10:14:41 AM PDT, AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com> wrote:
>Dear All:
>
>*Re:* How to make the Month variable be called ?May?,?June?, "July",
>"August", "September" instead of a numeric quantity (5,6,7,8,9)
>
>
>In the airquality data set, please see the code below; How to make the
>Month variable be called ?May?,?June?, "July", "August", "September"
>instead of a numeric quantity (5,6,7,8,9)
>
>
>
>data(airquality)
>
>head(airquality)
>
>
>#### Making Day and Month categorical variables
>
>
>airquality$Day <- factor(airquality$Day)
>
>airquality$Month <- factor(airquality$Month)
>
>
>head(airquality)
>
>
>> head(airquality)
>  Ozone Solar.R Wind Temp Month Day
>1    41     190  7.4   67     5   1
>2    36     118  8.0   72     5   2
>3    12     149 12.6   74     5   3
>4    18     313 11.5   62     5   4
>5    NA      NA 14.3   56     5   5
>6    28      NA 14.9   66     5   6
>>
>
>
>
>Thank you very much for your help in advance
>
>
>with thanks
>abou
>______________________
>
>
>*AbouEl-Makarim Aboueissa, PhD*
>
>*Professor of Statistics*
>*Graduate Coordinator*
>
>*Department of Mathematics and Statistics*
>*University of Southern Maine*
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Sep 20 19:56:22 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 20 Sep 2018 17:56:22 +0000
Subject: [R] How to vectorize this function
In-Reply-To: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
Message-ID: <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>

In addition to what the other said, if callM is a vector then an expression of the form
   if (callM <= call0)
is inappropriate. Objects inside the parentheses of   if()  should have length one. For example,

> if (1:5 < 3) 'a' else 'b'
[1] "a"
Warning message:
In if (1:5 < 3) "a" else "b" :
  the condition has length > 1 and only the first element will be used


instead of what you have:
         if(callM <= call0){
           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
         }else{
           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
        }

Here are a couple of (untested) possibilities:

  M.gt.0 <- callM > call0
  sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
  sig[M.gt.0] <- (1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y)))[M.gt.0]

or

    sig <- 1/sqrt(T)*(sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) * sqrt(gamma - y))

incidentally, I would write
   sig <- (sqrt(gamma + y) - sqrt(gamma - y))/sqrt(T)
instead of
   sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/20/18, 8:08 AM, "R-help on behalf of Lynette Chang" <r-help-bounces at r-project.org on behalf of momtoomax at gmail.com> wrote:

    Hello everyone,
    
         I?ve a function with five input argument and one output number. 
    	  impVolC <- function(callM, K, T, F, r)
    
         I hope this function can take five vectors as input, then return one vector as output. My vectorization ran into problems with the nested if-else operation. As a result, I have to write another for loop to call this function. Can anyone suggest some methods to overcome it? I put my code below, thanks.
    
    impVolC <- function(callM, K, T, F, r){
    
    
     if(y >= 0){
         call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
         if(callM <= call0){
           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
         }else{
           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
         }
     }else{
         call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
         if(callM <= call0){
           sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
         }else{
           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
         }
     }
     sig
    } 
    
    for(i in 1:length(call)){
     sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r = r_m)  
    }
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 20 21:36:06 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 20 Sep 2018 12:36:06 -0700
Subject: [R] How to vectorize this function
In-Reply-To: <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
 <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
Message-ID: <B9078087-DB4F-45CF-BF79-C6AAB866E4FB@dcn.davis.ca.us>

re: your last comment... why do you prefer to multiply by the reciprocal?

On September 20, 2018 10:56:22 AM PDT, "MacQueen, Don via R-help" <r-help at r-project.org> wrote:
>In addition to what the other said, if callM is a vector then an
>expression of the form
>   if (callM <= call0)
>is inappropriate. Objects inside the parentheses of   if()  should have
>length one. For example,
>
>> if (1:5 < 3) 'a' else 'b'
>[1] "a"
>Warning message:
>In if (1:5 < 3) "a" else "b" :
>  the condition has length > 1 and only the first element will be used
>
>
>instead of what you have:
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>        }
>
>Here are a couple of (untested) possibilities:
>
>  M.gt.0 <- callM > call0
>  sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
> sig[M.gt.0] <- (1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y)))[M.gt.0]
>
>or
>
>sig <- 1/sqrt(T)*(sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) *
>sqrt(gamma - y))
>
>incidentally, I would write
>   sig <- (sqrt(gamma + y) - sqrt(gamma - y))/sqrt(T)
>instead of
>   sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>
>--
>Don MacQueen
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>Lab cell 925-724-7509
> 
> 
>
>?On 9/20/18, 8:08 AM, "R-help on behalf of Lynette Chang"
><r-help-bounces at r-project.org on behalf of momtoomax at gmail.com> wrote:
>
>    Hello everyone,
>    
>       I?ve a function with five input argument and one output number. 
>    	  impVolC <- function(callM, K, T, F, r)
>    
>I hope this function can take five vectors as input, then return one
>vector as output. My vectorization ran into problems with the nested
>if-else operation. As a result, I have to write another for loop to
>call this function. Can anyone suggest some methods to overcome it? I
>put my code below, thanks.
>    
>    impVolC <- function(callM, K, T, F, r){
>    
>    
>     if(y >= 0){
>         call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>         }
>     }else{
>         call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>         }
>     }
>     sig
>    } 
>    
>    for(i in 1:length(call)){
>sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r =
>r_m)  
>    }
>    
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
>    
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From er|cjberger @end|ng |rom gm@||@com  Thu Sep 20 22:28:27 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 20 Sep 2018 23:28:27 +0300
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
Message-ID: <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>

Hi Andrew,
I don't have any experience in this area but I was intrigued by your
question. Here is what I learned.

1, A bit of poking around turned up a thread on stats.stackexchange that
mentions that "smallest space analysis" (SSA) is a special case of
"multidimensional scaling" (MDS).
See the thread here:
https://stats.stackexchange.com/questions/82462/guttmans-smallest-space-analysis

2. The R package SMACOF implements some solutions for MDS. See the
documentation "Multidimensional Scaling in R: SMACOF" available at
https://mran.microsoft.com/snapshot/2018-05-13/web/packages/smacof/vignettes/smacof.pdf

HTH,
Eric



On Wed, Sep 19, 2018 at 2:00 PM, Andrew <phaedrusv at gmail.com> wrote:

> Hi
>
> As part of my forensics psych course, we have been introduced to
> Guttman's smallest space analysis (SSA). I want to explore this approach
> using R, but despite finding some queries on the web about this same
> thing, have yet to find any answers. The MASS package doesn't seem to do
> the job, and the only thing I have been able to find is some proprietary
> software HUDAP  (Hebrew University Data Analysis Package) which may/ not
> be compatible with R (or GNU/Linux for that matter).
>
> Does anyone have information on how to do SSA using R?
>
> Many thanks
>
> Andrew
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Thu Sep 20 22:37:06 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Thu, 20 Sep 2018 16:37:06 -0400
Subject: [R] =?utf-8?q?Make_Month_variable_be_called_=E2=80=9CMay?=
	=?utf-8?b?4oCdLOKAnEp1bmXigJ0gZXRjLiwgaW5zdGVhZCBvZiBhIG51bWVyaWMg?=
	=?utf-8?q?quantity_5=2C6=2C_etc=2E?=
In-Reply-To: <39BBA96A-667F-4CE2-A513-26816EFAA570@dcn.davis.ca.us>
References: <CAE9stmevB6+5zfMOwa-HmfEa2gn8nSbpCicXGkwDTvmC5cCRCQ@mail.gmail.com>
 <39BBA96A-667F-4CE2-A513-26816EFAA570@dcn.davis.ca.us>
Message-ID: <CAE9stmePX9niYMU+L-KOVn85pbQD9qNf4+XJwebuJ8yfoWSVWA@mail.gmail.com>

Dear Jeff:

thank you very much

abou

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Thu, Sep 20, 2018 at 1:37 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> airquality$Month <- factor(airquality$Month, levels=1:12, labels=
> month.name )
>
> On September 20, 2018 10:14:41 AM PDT, AbouEl-Makarim Aboueissa <
> abouelmakarim1962 at gmail.com> wrote:
> >Dear All:
> >
> >*Re:* How to make the Month variable be called ?May?,?June?, "July",
> >"August", "September" instead of a numeric quantity (5,6,7,8,9)
> >
> >
> >In the airquality data set, please see the code below; How to make the
> >Month variable be called ?May?,?June?, "July", "August", "September"
> >instead of a numeric quantity (5,6,7,8,9)
> >
> >
> >
> >data(airquality)
> >
> >head(airquality)
> >
> >
> >#### Making Day and Month categorical variables
> >
> >
> >airquality$Day <- factor(airquality$Day)
> >
> >airquality$Month <- factor(airquality$Month)
> >
> >
> >head(airquality)
> >
> >
> >> head(airquality)
> >  Ozone Solar.R Wind Temp Month Day
> >1    41     190  7.4   67     5   1
> >2    36     118  8.0   72     5   2
> >3    12     149 12.6   74     5   3
> >4    18     313 11.5   62     5   4
> >5    NA      NA 14.3   56     5   5
> >6    28      NA 14.9   66     5   6
> >>
> >
> >
> >
> >Thank you very much for your help in advance
> >
> >
> >with thanks
> >abou
> >______________________
> >
> >
> >*AbouEl-Makarim Aboueissa, PhD*
> >
> >*Professor of Statistics*
> >*Graduate Coordinator*
> >
> >*Department of Mathematics and Statistics*
> >*University of Southern Maine*
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From ph@edru@v @end|ng |rom gm@||@com  Thu Sep 20 22:48:21 2018
From: ph@edru@v @end|ng |rom gm@||@com (Andrew)
Date: Thu, 20 Sep 2018 21:48:21 +0100
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>
Message-ID: <2b9aa89c-1141-5b8d-44ca-158c6472c0fa@gmail.com>

Hi Eric

I will need to dig into this a bit deeper, but this looks like it might 
hold some promise. The web link you shared seems familiar - perhaps I 
came across it but not at the site you linked to. I will read the 
sources with interest.

Thank you for bringing them to my attention.

Regards,
Andrew


On 20/09/18 21:28, Eric Berger wrote:
> Hi Andrew,
> I don't have any experience in this area but I was intrigued by your 
> question. Here is what I learned.
>
> 1, A bit of poking around turned up a thread on stats.stackexchange 
> that mentions that "smallest space analysis" (SSA) is a special case 
> of "multidimensional scaling" (MDS).
> See the thread here:
> https://stats.stackexchange.com/questions/82462/guttmans-smallest-space-analysis
>
> 2. The R package SMACOF implements some solutions for MDS. See the 
> documentation "Multidimensional Scaling in R: SMACOF" available at
> https://mran.microsoft.com/snapshot/2018-05-13/web/packages/smacof/vignettes/smacof.pdf
>
> HTH,
> Eric
>
>
>
> On Wed, Sep 19, 2018 at 2:00 PM, Andrew <phaedrusv at gmail.com 
> <mailto:phaedrusv at gmail.com>> wrote:
>
>     Hi
>
>     As part of my forensics psych course, we have been introduced to
>     Guttman's smallest space analysis (SSA). I want to explore this
>     approach
>     using R, but despite finding some queries on the web about this same
>     thing, have yet to find any answers. The MASS package doesn't seem
>     to do
>     the job, and the only thing I have been able to find is some
>     proprietary
>     software HUDAP? (Hebrew University Data Analysis Package) which
>     may/ not
>     be compatible with R (or GNU/Linux for that matter).
>
>     Does anyone have information on how to do SSA using R?
>
>     Many thanks
>
>     Andrew
>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Sep 20 22:53:03 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 20 Sep 2018 20:53:03 +0000
Subject: [R] How to vectorize this function
In-Reply-To: <B9078087-DB4F-45CF-BF79-C6AAB866E4FB@dcn.davis.ca.us>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
 <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
 <B9078087-DB4F-45CF-BF79-C6AAB866E4FB@dcn.davis.ca.us>
Message-ID: <BEC4139D-DD18-4346-A3B8-24AD4EEDA81E@llnl.gov>

You're asking me?

I prefer
> 4/2
[1] 2

not
> 1/2*4
[1] 2

(I think that's what I said)

And if I did want to multiply by the reciprocal, which does happen from time to time, I'd certainly do it this way:
   (1/2)*4

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/20/18, 12:36 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

    re: your last comment... why do you prefer to multiply by the reciprocal?
    
    On September 20, 2018 10:56:22 AM PDT, "MacQueen, Don via R-help" <r-help at r-project.org> wrote:
    >In addition to what the other said, if callM is a vector then an
    >expression of the form
    >   if (callM <= call0)
    >is inappropriate. Objects inside the parentheses of   if()  should have
    >length one. For example,
    >
    >> if (1:5 < 3) 'a' else 'b'
    >[1] "a"
    >Warning message:
    >In if (1:5 < 3) "a" else "b" :
    >  the condition has length > 1 and only the first element will be used
    >
    >
    >instead of what you have:
    >         if(callM <= call0){
    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
    >         }else{
    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
    >        }
    >
    >Here are a couple of (untested) possibilities:
    >
    >  M.gt.0 <- callM > call0
    >  sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
    > sig[M.gt.0] <- (1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y)))[M.gt.0]
    >
    >or
    >
    >sig <- 1/sqrt(T)*(sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) *
    >sqrt(gamma - y))
    >
    >incidentally, I would write
    >   sig <- (sqrt(gamma + y) - sqrt(gamma - y))/sqrt(T)
    >instead of
    >   sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
    >
    >--
    >Don MacQueen
    >Lawrence Livermore National Laboratory
    >7000 East Ave., L-627
    >Livermore, CA 94550
    >925-423-1062
    >Lab cell 925-724-7509
    > 
    > 
    >
    >On 9/20/18, 8:08 AM, "R-help on behalf of Lynette Chang"
    ><r-help-bounces at r-project.org on behalf of momtoomax at gmail.com> wrote:
    >
    >    Hello everyone,
    >    
    >       I?ve a function with five input argument and one output number. 
    >    	  impVolC <- function(callM, K, T, F, r)
    >    
    >I hope this function can take five vectors as input, then return one
    >vector as output. My vectorization ran into problems with the nested
    >if-else operation. As a result, I have to write another for loop to
    >call this function. Can anyone suggest some methods to overcome it? I
    >put my code below, thanks.
    >    
    >    impVolC <- function(callM, K, T, F, r){
    >    
    >    
    >     if(y >= 0){
    >         call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
    >         if(callM <= call0){
    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
    >         }else{
    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
    >         }
    >     }else{
    >         call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
    >         if(callM <= call0){
    >           sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
    >         }else{
    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
    >         }
    >     }
    >     sig
    >    } 
    >    
    >    for(i in 1:length(call)){
    >sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r =
    >r_m)  
    >    }
    >    
    >    ______________________________________________
    >    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >    https://stat.ethz.ch/mailman/listinfo/r-help
    >PLEASE do read the posting guide
    >http://www.R-project.org/posting-guide.html
    >    and provide commented, minimal, self-contained, reproducible code.
    >    
    >
    >______________________________________________
    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >https://stat.ethz.ch/mailman/listinfo/r-help
    >PLEASE do read the posting guide
    >http://www.R-project.org/posting-guide.html
    >and provide commented, minimal, self-contained, reproducible code.
    
    -- 
    Sent from my phone. Please excuse my brevity.
    


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 21 00:04:21 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 20 Sep 2018 15:04:21 -0700
Subject: [R] How to vectorize this function
In-Reply-To: <BEC4139D-DD18-4346-A3B8-24AD4EEDA81E@llnl.gov>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
 <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
 <B9078087-DB4F-45CF-BF79-C6AAB866E4FB@dcn.davis.ca.us>
 <BEC4139D-DD18-4346-A3B8-24AD4EEDA81E@llnl.gov>
Message-ID: <B9D72AA8-A00E-4B67-86B8-C1E25698600B@dcn.davis.ca.us>

Sorry, misread your comment, I agree. 4/2 has one arithmetic operation, (1/2)*4 has two to accomplish the same calculation.

On September 20, 2018 1:53:03 PM PDT, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
>You're asking me?
>
>I prefer
>> 4/2
>[1] 2
>
>not
>> 1/2*4
>[1] 2
>
>(I think that's what I said)
>
>And if I did want to multiply by the reciprocal, which does happen from
>time to time, I'd certainly do it this way:
>   (1/2)*4
>
>-Don
>
>--
>Don MacQueen
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>Lab cell 925-724-7509
> 
> 
>
>?On 9/20/18, 12:36 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>re: your last comment... why do you prefer to multiply by the
>reciprocal?
>    
>On September 20, 2018 10:56:22 AM PDT, "MacQueen, Don via R-help"
><r-help at r-project.org> wrote:
>    >In addition to what the other said, if callM is a vector then an
>    >expression of the form
>    >   if (callM <= call0)
>>is inappropriate. Objects inside the parentheses of   if()  should
>have
>    >length one. For example,
>    >
>    >> if (1:5 < 3) 'a' else 'b'
>    >[1] "a"
>    >Warning message:
>    >In if (1:5 < 3) "a" else "b" :
>>  the condition has length > 1 and only the first element will be used
>    >
>    >
>    >instead of what you have:
>    >         if(callM <= call0){
>    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>    >         }else{
>    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>    >        }
>    >
>    >Here are a couple of (untested) possibilities:
>    >
>    >  M.gt.0 <- callM > call0
>    >  sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>> sig[M.gt.0] <- (1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma -
>y)))[M.gt.0]
>    >
>    >or
>    >
>  >sig <- 1/sqrt(T)*(sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) *
>    >sqrt(gamma - y))
>    >
>    >incidentally, I would write
>    >   sig <- (sqrt(gamma + y) - sqrt(gamma - y))/sqrt(T)
>    >instead of
>    >   sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>    >
>    >--
>    >Don MacQueen
>    >Lawrence Livermore National Laboratory
>    >7000 East Ave., L-627
>    >Livermore, CA 94550
>    >925-423-1062
>    >Lab cell 925-724-7509
>    > 
>    > 
>    >
>    >On 9/20/18, 8:08 AM, "R-help on behalf of Lynette Chang"
>><r-help-bounces at r-project.org on behalf of momtoomax at gmail.com> wrote:
>    >
>    >    Hello everyone,
>    >    
>>       I?ve a function with five input argument and one output number.
>
>    >    	  impVolC <- function(callM, K, T, F, r)
>    >    
>  >I hope this function can take five vectors as input, then return one
>  >vector as output. My vectorization ran into problems with the nested
>   >if-else operation. As a result, I have to write another for loop to
> >call this function. Can anyone suggest some methods to overcome it? I
>    >put my code below, thanks.
>    >    
>    >    impVolC <- function(callM, K, T, F, r){
>    >    
>    >    
>    >     if(y >= 0){
>    >         call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
>    >         if(callM <= call0){
>    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>    >         }else{
>    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>    >         }
>    >     }else{
>    >         call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
>    >         if(callM <= call0){
>    >           sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
>    >         }else{
>    >           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>    >         }
>    >     }
>    >     sig
>    >    } 
>    >    
>    >    for(i in 1:length(call)){
>>sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r
>=
>    >r_m)  
>    >    }
>    >    
>    >    ______________________________________________
> >    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    >    https://stat.ethz.ch/mailman/listinfo/r-help
>    >PLEASE do read the posting guide
>    >http://www.R-project.org/posting-guide.html
>>    and provide commented, minimal, self-contained, reproducible code.
>    >    
>    >
>    >______________________________________________
>    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    >https://stat.ethz.ch/mailman/listinfo/r-help
>    >PLEASE do read the posting guide
>    >http://www.R-project.org/posting-guide.html
>    >and provide commented, minimal, self-contained, reproducible code.
>    
>    -- 
>    Sent from my phone. Please excuse my brevity.
>    

-- 
Sent from my phone. Please excuse my brevity.



From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Sep 21 02:50:04 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Thu, 20 Sep 2018 18:50:04 -0600
Subject: [R] tibble question with a mean
Message-ID: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>

Hello!

Here is a toy tibble problem:

xt <-
tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
str(xt)
Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
 $ x: chr  "A" "B" "C" "D"
 $ y: int  1 2 3 4
 $ z: num  0.3246 0.0504 0.339 0.4872
 $ a: chr  "dog" "cat" "tree" "ferret"
#No surprise
 xt %>% mean
[1] NA
Warning message:
In mean.default(.) : argument is not numeric or logical: returning NA
#surprised!
mean(xt[2:3])
[1] NA
Warning message:
In mean.default(xt[2:3]) : argument is not numeric or logical: returning NA
 xt[, 2:3] %>% mean
[1] NA
Warning message:
In mean.default(.) : argument is not numeric or logical: returning NA

I have a feeling that I'm doing something silly wrong.  Has anyone run into
this, please?  I saw something like this on this list, but didn't see a
solution.

Thanks,
Erin


Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]



From peter@|@ng|e|der @end|ng |rom gm@||@com  Fri Sep 21 03:07:35 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 20 Sep 2018 18:07:35 -0700
Subject: [R] tibble question with a mean
In-Reply-To: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
Message-ID: <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>

I don't know tibble, so I'll do the same with a plain data frame:

a =
data.frame(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> a
  x y           z      a
1 A 1 -0.08264865    dog
2 B 2  0.32344426    cat
3 C 3 -0.80416061   tree
4 D 4  1.27052529 ferret
> mean(a[2:3])
[1] NA
Warning message:
In mean.default(a[2:3]) : argument is not numeric or logical: returning NA
> mean(as.matrix(a[2:3]))
[1] 1.338395

The reason you get an error on mean(a[2:3]) is that a[2:3] is still a data
frame (a special list) and you cannot simply apply mean to a list. You need
to first convert to a matrix or vector which can then be fed to mean().

Peter


On Thu, Sep 20, 2018 at 5:50 PM Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello!
>
> Here is a toy tibble problem:
>
> xt <-
> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> str(xt)
> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
>  $ x: chr  "A" "B" "C" "D"
>  $ y: int  1 2 3 4
>  $ z: num  0.3246 0.0504 0.339 0.4872
>  $ a: chr  "dog" "cat" "tree" "ferret"
> #No surprise
>  xt %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
> #surprised!
> mean(xt[2:3])
> [1] NA
> Warning message:
> In mean.default(xt[2:3]) : argument is not numeric or logical: returning NA
>  xt[, 2:3] %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
>
> I have a feeling that I'm doing something silly wrong.  Has anyone run into
> this, please?  I saw something like this on this list, but didn't see a
> solution.
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Sep 21 03:38:26 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 21 Sep 2018 13:38:26 +1200
Subject: [R] [FORGED] Re:  tibble question with a mean
In-Reply-To: <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
 <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
Message-ID: <1b86773c-a2c6-933c-1710-164c5952fa4e@auckland.ac.nz>


Please see inline below.

n 09/21/2018 01:07 PM, Peter Langfelder wrote:
> I don't know tibble, so I'll do the same with a plain data frame:
> 
> a =
> data.frame(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
>> a
>    x y           z      a
> 1 A 1 -0.08264865    dog
> 2 B 2  0.32344426    cat
> 3 C 3 -0.80416061   tree
> 4 D 4  1.27052529 ferret
>> mean(a[2:3])
> [1] NA
> Warning message:
> In mean.default(a[2:3]) : argument is not numeric or logical: returning NA
>> mean(as.matrix(a[2:3]))
> [1] 1.338395
> 
> The reason you get an error on mean(a[2:3]) is that a[2:3] is still a data
> frame (a special list) and you cannot simply apply mean to a list. You need
> to first convert to a matrix or vector which can then be fed to mean().

Perhaps

sapply(a[2:3],mean)?

cheers,

Rolf

> 
> Peter
> 
> 
> On Thu, Sep 20, 2018 at 5:50 PM Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> 
>> Hello!
>>
>> Here is a toy tibble problem:
>>
>> xt <-
>> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
>> str(xt)
>> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
>>   $ x: chr  "A" "B" "C" "D"
>>   $ y: int  1 2 3 4
>>   $ z: num  0.3246 0.0504 0.339 0.4872
>>   $ a: chr  "dog" "cat" "tree" "ferret"
>> #No surprise
>>   xt %>% mean
>> [1] NA
>> Warning message:
>> In mean.default(.) : argument is not numeric or logical: returning NA
>> #surprised!
>> mean(xt[2:3])
>> [1] NA
>> Warning message:
>> In mean.default(xt[2:3]) : argument is not numeric or logical: returning NA
>>   xt[, 2:3] %>% mean
>> [1] NA
>> Warning message:
>> In mean.default(.) : argument is not numeric or logical: returning NA
>>
>> I have a feeling that I'm doing something silly wrong.  Has anyone run into
>> this, please?  I saw something like this on this list, but didn't see a
>> solution.
>>
>> Thanks,
>> Erin



From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Sep 21 03:56:11 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Thu, 20 Sep 2018 19:56:11 -0600
Subject: [R] [FORGED] Re:  tibble question with a mean
In-Reply-To: <1b86773c-a2c6-933c-1710-164c5952fa4e@auckland.ac.nz>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
 <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
 <1b86773c-a2c6-933c-1710-164c5952fa4e@auckland.ac.nz>
Message-ID: <CACxE24kThEWrL4Do5HK4prtu_+JcsLxMdazQ_xmfuqUvrbqMwA@mail.gmail.com>

Thanks to all for the good suggestions!!!

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Thu, Sep 20, 2018 at 7:38 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> Please see inline below.
>
> n 09/21/2018 01:07 PM, Peter Langfelder wrote:
> > I don't know tibble, so I'll do the same with a plain data frame:
> >
> > a =
> >
> data.frame(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> >> a
> >    x y           z      a
> > 1 A 1 -0.08264865    dog
> > 2 B 2  0.32344426    cat
> > 3 C 3 -0.80416061   tree
> > 4 D 4  1.27052529 ferret
> >> mean(a[2:3])
> > [1] NA
> > Warning message:
> > In mean.default(a[2:3]) : argument is not numeric or logical: returning
> NA
> >> mean(as.matrix(a[2:3]))
> > [1] 1.338395
> >
> > The reason you get an error on mean(a[2:3]) is that a[2:3] is still a
> data
> > frame (a special list) and you cannot simply apply mean to a list. You
> need
> > to first convert to a matrix or vector which can then be fed to mean().
>
> Perhaps
>
> sapply(a[2:3],mean)?
>
> cheers,
>
> Rolf
>
> >
> > Peter
> >
> >
> > On Thu, Sep 20, 2018 at 5:50 PM Erin Hodgess <erinm.hodgess at gmail.com>
> > wrote:
> >
> >> Hello!
> >>
> >> Here is a toy tibble problem:
> >>
> >> xt <-
> >> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> >> str(xt)
> >> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
> >>   $ x: chr  "A" "B" "C" "D"
> >>   $ y: int  1 2 3 4
> >>   $ z: num  0.3246 0.0504 0.339 0.4872
> >>   $ a: chr  "dog" "cat" "tree" "ferret"
> >> #No surprise
> >>   xt %>% mean
> >> [1] NA
> >> Warning message:
> >> In mean.default(.) : argument is not numeric or logical: returning NA
> >> #surprised!
> >> mean(xt[2:3])
> >> [1] NA
> >> Warning message:
> >> In mean.default(xt[2:3]) : argument is not numeric or logical:
> returning NA
> >>   xt[, 2:3] %>% mean
> >> [1] NA
> >> Warning message:
> >> In mean.default(.) : argument is not numeric or logical: returning NA
> >>
> >> I have a feeling that I'm doing something silly wrong.  Has anyone run
> into
> >> this, please?  I saw something like this on this list, but didn't see a
> >> solution.
> >>
> >> Thanks,
> >> Erin
>

	[[alternative HTML version deleted]]



From dc@r|@on @end|ng |rom t@mu@edu  Fri Sep 21 05:19:14 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Fri, 21 Sep 2018 03:19:14 +0000
Subject: [R] tibble question with a mean
In-Reply-To: <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
 <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
Message-ID: <61f17d3932514396a5be003c26bf3b03@tamu.edu>

> xt[, 2:3] %>% colMeans
         y          z 
 2.5000000 -0.4401625

> xt[2] %>% colMeans
  y 
2.5 
> t(xt[, 2]) %>% mean
[1] 2.5

-------------------------
David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter Langfelder
Sent: Thursday, September 20, 2018 8:08 PM
To: Erin Hodgess <erinm.hodgess at gmail.com>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] tibble question with a mean

I don't know tibble, so I'll do the same with a plain data frame:

a =
data.frame(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> a
  x y           z      a
1 A 1 -0.08264865    dog
2 B 2  0.32344426    cat
3 C 3 -0.80416061   tree
4 D 4  1.27052529 ferret
> mean(a[2:3])
[1] NA
Warning message:
In mean.default(a[2:3]) : argument is not numeric or logical: returning NA
> mean(as.matrix(a[2:3]))
[1] 1.338395

The reason you get an error on mean(a[2:3]) is that a[2:3] is still a data
frame (a special list) and you cannot simply apply mean to a list. You need
to first convert to a matrix or vector which can then be fed to mean().

Peter


On Thu, Sep 20, 2018 at 5:50 PM Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello!
>
> Here is a toy tibble problem:
>
> xt <-
> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> str(xt)
> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
>  $ x: chr  "A" "B" "C" "D"
>  $ y: int  1 2 3 4
>  $ z: num  0.3246 0.0504 0.339 0.4872
>  $ a: chr  "dog" "cat" "tree" "ferret"
> #No surprise
>  xt %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
> #surprised!
> mean(xt[2:3])
> [1] NA
> Warning message:
> In mean.default(xt[2:3]) : argument is not numeric or logical: returning NA
>  xt[, 2:3] %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
>
> I have a feeling that I'm doing something silly wrong.  Has anyone run into
> this, please?  I saw something like this on this list, but didn't see a
> solution.
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Sep 21 06:01:05 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Thu, 20 Sep 2018 22:01:05 -0600
Subject: [R] tibble question with a mean
In-Reply-To: <61f17d3932514396a5be003c26bf3b03@tamu.edu>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
 <CA+hbrhVThadx+4htmPb_EodSydb2gPPrO=bmRW7bYkXPtLdBnA@mail.gmail.com>
 <61f17d3932514396a5be003c26bf3b03@tamu.edu>
Message-ID: <CACxE24k+4Sxsp7uRCYz1LAp6zQm4bxy6+2mfrSwvgHT+YRfE7A@mail.gmail.com>

David
That's awesome!

Thank you!!!

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Thu, Sep 20, 2018 at 9:19 PM David L Carlson <dcarlson at tamu.edu> wrote:

> > xt[, 2:3] %>% colMeans
>          y          z
>  2.5000000 -0.4401625
>
> > xt[2] %>% colMeans
>   y
> 2.5
> > t(xt[, 2]) %>% mean
> [1] 2.5
>
> -------------------------
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter
> Langfelder
> Sent: Thursday, September 20, 2018 8:08 PM
> To: Erin Hodgess <erinm.hodgess at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] tibble question with a mean
>
> I don't know tibble, so I'll do the same with a plain data frame:
>
> a =
>
> data.frame(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> > a
>   x y           z      a
> 1 A 1 -0.08264865    dog
> 2 B 2  0.32344426    cat
> 3 C 3 -0.80416061   tree
> 4 D 4  1.27052529 ferret
> > mean(a[2:3])
> [1] NA
> Warning message:
> In mean.default(a[2:3]) : argument is not numeric or logical: returning NA
> > mean(as.matrix(a[2:3]))
> [1] 1.338395
>
> The reason you get an error on mean(a[2:3]) is that a[2:3] is still a data
> frame (a special list) and you cannot simply apply mean to a list. You need
> to first convert to a matrix or vector which can then be fed to mean().
>
> Peter
>
>
> On Thu, Sep 20, 2018 at 5:50 PM Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
>
> > Hello!
> >
> > Here is a toy tibble problem:
> >
> > xt <-
> > tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> > str(xt)
> > Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
> >  $ x: chr  "A" "B" "C" "D"
> >  $ y: int  1 2 3 4
> >  $ z: num  0.3246 0.0504 0.339 0.4872
> >  $ a: chr  "dog" "cat" "tree" "ferret"
> > #No surprise
> >  xt %>% mean
> > [1] NA
> > Warning message:
> > In mean.default(.) : argument is not numeric or logical: returning NA
> > #surprised!
> > mean(xt[2:3])
> > [1] NA
> > Warning message:
> > In mean.default(xt[2:3]) : argument is not numeric or logical: returning
> NA
> >  xt[, 2:3] %>% mean
> > [1] NA
> > Warning message:
> > In mean.default(.) : argument is not numeric or logical: returning NA
> >
> > I have a feeling that I'm doing something silly wrong.  Has anyone run
> into
> > this, please?  I saw something like this on this list, but didn't see a
> > solution.
> >
> > Thanks,
> > Erin
> >
> >
> > Erin Hodgess, PhD
> > mailto: erinm.hodgess at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From momtoom@x @end|ng |rom gm@||@com  Thu Sep 20 23:46:01 2018
From: momtoom@x @end|ng |rom gm@||@com (Lynette Chang)
Date: Thu, 20 Sep 2018 17:46:01 -0400
Subject: [R] How to vectorize this function
In-Reply-To: <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
References: <14AC3CDD-873B-49D8-A5B3-04B9EAA81B2C@gmail.com>
 <F9F7EC0F-1579-48C7-8D18-2D602E5617D7@llnl.gov>
Message-ID: <C5A9E207-E383-411E-960B-395B52FB69A8@gmail.com>

Here are the code and data file. I?m not sure if I put too much unrelated information here. 

My goal is to factor out volatilities from the data. I hope I can get sigV <- impVolC(callM, K, T, F, r), which has five vectors as input, and one vector as output. The length of all those six vectors are the same. However, I got stuck in the nested if-else sentence, as if-condition cannot handle vectors. I rewrite it as you guys suggestions, however, I still have one layer of if-condition. Any thoughts to improve it? Thanks.

Lynette

-------------- next part --------------


df <- read.csv(file = "/S&P500_ETF_Option_0917.csv", header = TRUE, 
               colClasses = c("integer", "character", "numeric", "numeric", "numeric",
                              "character", "numeric", "numeric", "numeric"))

call <- (df$callBid + df$callAsk)/2
put <- (df$putBid + df$putAsk)/2

y <- call - put
A <- cbind(rep(1, dim(df)[1]), -df$Strike)

x <- solve(t(A)%*%A)%*%t(A)%*%y
PVF <- x[1]
disc <- x[2]

S <- 2381



library(timeDate)
# Lets work in your environment:
getRmetricsOptions("myFinCenter")
setRmetricsOptions(myFinCenter = "America/New_York")

# define a sequence of days with  timeSequence 
t1 <- timeSequence(from = "2017-03-16", to = "2017-09-29")

# Define a calendar for your exchange (use an available one as a template, e.g. holidayNYSE) 
# subindex the sequence with isBizday using your calendar as an argument 
holidayNYSE(2017)
isBizday(t1, holidayNYSE())
t2 <- t1[isBizday(t1, holidayNYSE(2017))]

T <- length(t2)/252
q_m <- -log(PVF/S)/T
r_m <- log(disc)/(-T)


polya <- function(x){
  1/2 + sign(x)/2* sqrt(1- exp(-2*x^2/pi))
}
impVolC <- function(callM, K, T, F, r){
  
  y <- log(F/K)
  alpha <- callM/(K*exp(-r*T))
  R <- 2*alpha - exp(y) + 1
  
  A <- (exp((1 - 2/pi)*y) - exp(-(1 - 2/pi)*y))^2
  B <- 4*(exp(2/pi*y) + exp(-2/pi*y)) - 2*exp(-y)*(exp((1-2/pi)*y)+exp(-(1-2/pi)*y))*(exp(2*y) + 1 - R^2)
  C <- exp(-2*y)*(R^2 - (exp(y) -1)^2)*((exp(y) + 1)^2 - R^2)                                                
  
  beta <- (2*C)/(B + sqrt(B^2 + 4*A*C))
  gamma <- -pi/2*log(beta)
  
  if(y >= 0){
    call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
    sig <- (sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) * sqrt(gamma - y))/sqrt(T)
  }else{
    call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
    sig <-  (ifelse(callM <= call0, -1, 1)*sqrt(gamma + y)  +  sqrt(gamma - y))/sqrt(T)
  }
  sig
}

F <- PVF*exp(r_m*T)
sigV <- rep(0, length(call))

for(i in 1:length(call)){
  sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r = r_m)  
}


> On Sep 20, 2018, at 1:56 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> 
> In addition to what the other said, if callM is a vector then an expression of the form
>   if (callM <= call0)
> is inappropriate. Objects inside the parentheses of   if()  should have length one. For example,
> 
>> if (1:5 < 3) 'a' else 'b'
> [1] "a"
> Warning message:
> In if (1:5 < 3) "a" else "b" :
>  the condition has length > 1 and only the first element will be used
> 
> 
> instead of what you have:
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>        }
> 
> Here are a couple of (untested) possibilities:
> 
>  M.gt.0 <- callM > call0
>  sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>  sig[M.gt.0] <- (1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y)))[M.gt.0]
> 
> or
> 
>    sig <- 1/sqrt(T)*(sqrt(gamma + y)  + ifelse(callM <= call0, -1, 1) * sqrt(gamma - y))
> 
> incidentally, I would write
>   sig <- (sqrt(gamma + y) - sqrt(gamma - y))/sqrt(T)
> instead of
>   sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
> 
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
> 
> 
> 
> ?On 9/20/18, 8:08 AM, "R-help on behalf of Lynette Chang" <r-help-bounces at r-project.org on behalf of momtoomax at gmail.com> wrote:
> 
>    Hello everyone,
> 
>         I?ve a function with five input argument and one output number. 
>    	  impVolC <- function(callM, K, T, F, r)
> 
>         I hope this function can take five vectors as input, then return one vector as output. My vectorization ran into problems with the nested if-else operation. As a result, I have to write another for loop to call this function. Can anyone suggest some methods to overcome it? I put my code below, thanks.
> 
>    impVolC <- function(callM, K, T, F, r){
> 
> 
>     if(y >= 0){
>         call0 <- K*exp(-r*T)*(exp(y)*polya(sqrt(2*y)) - 0.5)
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) - sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>         }
>     }else{
>         call0 <- K*exp(-r*T)*(exp(y)/2 - polya(-sqrt(-2*y)))
>         if(callM <= call0){
>           sig <- 1/sqrt(T)*(-sqrt(gamma + y) + sqrt(gamma - y))
>         }else{
>           sig <- 1/sqrt(T)*(sqrt(gamma + y) + sqrt(gamma - y))
>         }
>     }
>     sig
>    } 
> 
>    for(i in 1:length(call)){
>     sigV[i] <- impVolC(callM = call[i], K = df$Strike[i], T = T, F = F, r = r_m)  
>    }
> 
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
> 
> 


From m|korym @end|ng |rom protonm@||@com  Fri Sep 21 07:31:07 2018
From: m|korym @end|ng |rom protonm@||@com (mikorym)
Date: Fri, 21 Sep 2018 05:31:07 +0000
Subject: [R] Fitting Production Curves
Message-ID: <_O_DvHZPLvQF7D5L6IDkx8lNvgTbN1NFC4xxX70VFIgOazkxU_PwIkJcJtvr25M4d0lzDuHySSUZnkrkUO9FWnL-qn1amYvUr04T5Nu-roQ=@protonmail.com>

Hi All,

By a production curve I mean for example the output of a mine, peak oil production or the yield of a farm over time within the same season. It is this last example that we should take as the prototypical case.

What I would like to do is to fit a curve that inherits qualities of the discrete production data (such as area of the curve equaling the total production for the season). Fitting a curve with least squares (such as a Gaussean or Hubbert) presents some issues (with regards to accuracy of inherited features). My next logical attempt would be to fit a sum of curves, such as a Fourier or Wavelet sum. Perhaps there is something simpler or more flexible in the way I am thinking?

My question is:

1. What would be an effective approach be to fit generalised production curves?
2. If a Wavelet sum is one of the best approaches, what would be a good way of implementing such curve fitting (including calculated coefficients) in R?
3. Is there anything else or another way that I should rather be thinking about this instead?

Best regards
Phillip-Jan van Zyl
MSc Mathematics, Stellenbosch



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Sep 21 08:46:27 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 21 Sep 2018 08:46:27 +0200
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>
Message-ID: <23460.37827.406552.35154@stat.math.ethz.ch>

>>>>> Eric Berger 
>>>>>     on Thu, 20 Sep 2018 23:28:27 +0300 writes:

    > Hi Andrew,
    > I don't have any experience in this area but I was intrigued by your
    > question. Here is what I learned.

    > 1, A bit of poking around turned up a thread on stats.stackexchange that
    > mentions that "smallest space analysis" (SSA) is a special case of
    > "multidimensional scaling" (MDS).
    > See the thread here:
    > https://stats.stackexchange.com/questions/82462/guttmans-smallest-space-analysis

    > 2. The R package SMACOF implements some solutions for MDS. See the
    > documentation "Multidimensional Scaling in R: SMACOF" available at
    > https://mran.microsoft.com/snapshot/2018-05-13/web/packages/smacof/vignettes/smacof.pdf

Well, but MDS  is "old" and already available in standard R in
its classical form:

> apropos("MDS")
[1] "cmdscale"
> ?cmdscale  # "Classical Multidimensional Scaling"

then gives the help page for 'cmdscale' which in its 'See Also:'
mentions the

	isomds()
	sammon()

functions from package MASS which (as formally "Recommended"
pkg) is part of every full R installation.

So, at first, there's no need for any extra package...


    > HTH,
    > Eric



    > On Wed, Sep 19, 2018 at 2:00 PM, Andrew <phaedrusv at gmail.com> wrote:

    >> Hi
    >> 
    >> As part of my forensics psych course, we have been introduced to
    >> Guttman's smallest space analysis (SSA). I want to explore this approach
    >> using R, but despite finding some queries on the web about this same
    >> thing, have yet to find any answers. The MASS package doesn't seem to do
    >> the job, and the only thing I have been able to find is some proprietary
    >> software HUDAP  (Hebrew University Data Analysis Package) which may/ not
    >> be compatible with R (or GNU/Linux for that matter).
    >> 
    >> Does anyone have information on how to do SSA using R?
    >> 
    >> Many thanks
    >> 
    >> Andrew
    >> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/
    >> posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >> 

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.



From ph@edru@v @end|ng |rom gm@||@com  Fri Sep 21 09:41:27 2018
From: ph@edru@v @end|ng |rom gm@||@com (Andrew)
Date: Fri, 21 Sep 2018 08:41:27 +0100
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <23460.37827.406552.35154@stat.math.ethz.ch>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <CAGgJW749QTUX=7A233tkOBy=qnQQiLNr0RTC-RMw=asK-v26GA@mail.gmail.com>
 <23460.37827.406552.35154@stat.math.ethz.ch>
Message-ID: <958b392f-075c-f494-5eb1-e6afbf167ee6@gmail.com>

Hi Martin

I was aware of the 'old' MDS package, thanks.

Hi Eric

I've now read the paper you referenced, thanks. Still didn't see 
anything about SSA however, so will keep looking.

However, if anyone on this list comes across something specific to SSA, 
could you kindly drop me a line to let me know?

Many thanks
Andrew


On 21/09/18 07:46, Martin Maechler wrote:
>>>>>> Eric Berger
>>>>>>      on Thu, 20 Sep 2018 23:28:27 +0300 writes:
>      > Hi Andrew,
>      > I don't have any experience in this area but I was intrigued by your
>      > question. Here is what I learned.
>
>      > 1, A bit of poking around turned up a thread on stats.stackexchange that
>      > mentions that "smallest space analysis" (SSA) is a special case of
>      > "multidimensional scaling" (MDS).
>      > See the thread here:
>      > https://stats.stackexchange.com/questions/82462/guttmans-smallest-space-analysis
>
>      > 2. The R package SMACOF implements some solutions for MDS. See the
>      > documentation "Multidimensional Scaling in R: SMACOF" available at
>      > https://mran.microsoft.com/snapshot/2018-05-13/web/packages/smacof/vignettes/smacof.pdf
>
> Well, but MDS  is "old" and already available in standard R in
> its classical form:
>
>> apropos("MDS")
> [1] "cmdscale"
>> ?cmdscale  # "Classical Multidimensional Scaling"
> then gives the help page for 'cmdscale' which in its 'See Also:'
> mentions the
>
> 	isomds()
> 	sammon()
>
> functions from package MASS which (as formally "Recommended"
> pkg) is part of every full R installation.
>
> So, at first, there's no need for any extra package...
>
>
>      > HTH,
>      > Eric
>
>
>
>      > On Wed, Sep 19, 2018 at 2:00 PM, Andrew <phaedrusv at gmail.com> wrote:
>
>      >> Hi
>      >>
>      >> As part of my forensics psych course, we have been introduced to
>      >> Guttman's smallest space analysis (SSA). I want to explore this approach
>      >> using R, but despite finding some queries on the web about this same
>      >> thing, have yet to find any answers. The MASS package doesn't seem to do
>      >> the job, and the only thing I have been able to find is some proprietary
>      >> software HUDAP  (Hebrew University Data Analysis Package) which may/ not
>      >> be compatible with R (or GNU/Linux for that matter).
>      >>
>      >> Does anyone have information on how to do SSA using R?
>      >>
>      >> Many thanks
>      >>
>      >> Andrew
>      >>
>      >>
>      >> [[alternative HTML version deleted]]
>      >>
>      >> ______________________________________________
>      >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      >> https://stat.ethz.ch/mailman/listinfo/r-help
>      >> PLEASE do read the posting guide http://www.R-project.org/
>      >> posting-guide.html
>      >> and provide commented, minimal, self-contained, reproducible code.
>      >>
>
>      > [[alternative HTML version deleted]]
>
>      > ______________________________________________
>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>



From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Fri Sep 21 10:54:56 2018
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Fri, 21 Sep 2018 10:54:56 +0200
Subject: [R] Link from vignette to package documentation
Message-ID: <d9953a1b-8ff6-70ff-e847-d08059f683bb@wiwi.hu-berlin.de>

Hi,

is it possible to make a link from a vignette to a (Rd) help files in my 
own or other packages?

Best Sigbert

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep 21 11:02:32 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 21 Sep 2018 05:02:32 -0400
Subject: [R] Link from vignette to package documentation
In-Reply-To: <d9953a1b-8ff6-70ff-e847-d08059f683bb@wiwi.hu-berlin.de>
References: <d9953a1b-8ff6-70ff-e847-d08059f683bb@wiwi.hu-berlin.de>
Message-ID: <1392b368-3045-36cd-5e03-ff83a0cc95f4@gmail.com>

On 21/09/2018 4:54 AM, Sigbert Klinke wrote:
> Hi,
> 
> is it possible to make a link from a vignette to a (Rd) help files in my
> own or other packages?

Only with some significant compromises.  R normally acts as the web 
server for Rd files, and the URL is not really predictable.  So you 
would need to make the URL predictable, either by something like

options(help.ports = 12345)

(which will put help on port 12345, blocking that port for any other 
use, including help in another R session), or by putting a static copy 
of the help pages on some other web server.

Duncan Murdoch



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Fri Sep 21 12:34:35 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Fri, 21 Sep 2018 16:04:35 +0530
Subject: [R] How to remove backslash
Message-ID: <CA+dpOJns1pSGZfgH+=bR56ok8gGJ2RYFyiVBNirE3U4WskvGYQ@mail.gmail.com>

Hi,

I have below string where I am trying to remove Backslash from. I tried
with gsub() function, however failed to remove that:

> str = '<span id=\"ctl00'
> gsub("\\", "", str)
Error in gsub("\\", "", str) :
  invalid regular expression '\', reason 'Trailing backslash'


Any pointer to the right approach?

Thanks for your time

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Sep 21 12:48:55 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 21 Sep 2018 11:48:55 +0100
Subject: [R] How to remove backslash
In-Reply-To: <CA+dpOJns1pSGZfgH+=bR56ok8gGJ2RYFyiVBNirE3U4WskvGYQ@mail.gmail.com>
References: <CA+dpOJns1pSGZfgH+=bR56ok8gGJ2RYFyiVBNirE3U4WskvGYQ@mail.gmail.com>
Message-ID: <ee6367b8-6a6d-e5cd-d495-f0309739356e@sapo.pt>

Hello,

The backslash is not a character of the string str. test it with nchar:

str = '<span id=\"ctl00'
nchar(str)
#[1] 15


It is there just to escape the double quotes.
if you want a backslash you would need to escape it, like in str1.


str1 = '<span id=\\"ctl00'
nchar(str1)
#[1] 16


Now yes, you can remove it.

str2 <- gsub("\\", "", str1, fixed = TRUE)
identical(str, str2)
#[1] TRUE



Hope this helps,

Rui Barradas

?s 11:34 de 21/09/2018, Christofer Bogaso escreveu:
> Hi,
> 
> I have below string where I am trying to remove Backslash from. I tried
> with gsub() function, however failed to remove that:
> 
>> str = '<span id=\"ctl00'
>> gsub("\\", "", str)
> Error in gsub("\\", "", str) :
>    invalid regular expression '\', reason 'Trailing backslash'
> 
> 
> Any pointer to the right approach?
> 
> Thanks for your time
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From |r|end|y @end|ng |rom yorku@c@  Fri Sep 21 15:07:35 2018
From: |r|end|y @end|ng |rom yorku@c@ (Michael Friendly)
Date: Fri, 21 Sep 2018 09:07:35 -0400
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
Message-ID: <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>

Smallest space analysis (SSA) is just the name given to software 
developed by Guttman & Lingoes around the time the various versions
of multidimensional scaling were being developed.  Call it Israeli MDS
or Falafel MDS if you prefer. The reason you encountered it in your
course is presumably that the instructor was trained in that.

There are several variants of MDS-like algorithms for embedding
points representing objects in a space, using data representing
similarities or distances among objects -- metric (cmdscale)
and non-metric (MASS::isoMDS), using only rank order information, and a 
variety of
measures of goodness-of-fit ("stress").  I don't recall the details
of the SSA programs, but that should matter little conceptually.

The smacof package offers the widest array of possibilities.

-Michael


On 9/19/2018 7:00 AM, Andrew wrote:
> Hi
> 
> As part of my forensics psych course, we have been introduced to
> Guttman's smallest space analysis (SSA). I want to explore this approach
> using R, but despite finding some queries on the web about this same
> thing, have yet to find any answers. The MASS package doesn't seem to do
> the job, and the only thing I have been able to find is some proprietary
> software HUDAP? (Hebrew University Data Analysis Package) which may/ not
> be compatible with R (or GNU/Linux for that matter).
> 
> Does anyone have information on how to do SSA using R?
> 
> Many thanks
> 
> Andrew
> 
> 
> 	[[alternative HTML version deleted]]
>



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 21 16:57:06 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 21 Sep 2018 07:57:06 -0700
Subject: [R] How to remove backslash
In-Reply-To: <ee6367b8-6a6d-e5cd-d495-f0309739356e@sapo.pt>
References: <CA+dpOJns1pSGZfgH+=bR56ok8gGJ2RYFyiVBNirE3U4WskvGYQ@mail.gmail.com>
 <ee6367b8-6a6d-e5cd-d495-f0309739356e@sapo.pt>
Message-ID: <589B2804-08FF-4ED1-AE9D-C7C174D7015F@dcn.davis.ca.us>

Even more convincing than nchar is cat vs. print:

s <- "<span id=\"ctl00"
cat( s )
print( s )

The print function formats character strings in a manner that allows you to copy and paste them into source files. The cat function just dumps the contents of the string out to the console, which can trigger the control behaviors of the terminal (moving cursor around, clearing the screen, beeping, etc.) but without the escapes needed to encode those characters in into source code.

Note that the whole reason R uses two kinds of quotes for character literals is to allow you to use fewer escape slashes:

s <- '<span id="ctl00'

A double quote inside a single-quote-delimited string is an ordinary character because there is no possible confusion that it might be the end of the string.

BTW the str symbol is a commonly-used function from base R... it is not a good idea to use it as a throwaway variable.


On September 21, 2018 3:48:55 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>Hello,
>
>The backslash is not a character of the string str. test it with nchar:
>
>str = '<span id=\"ctl00'
>nchar(str)
>#[1] 15
>
>
>It is there just to escape the double quotes.
>if you want a backslash you would need to escape it, like in str1.
>
>
>str1 = '<span id=\\"ctl00'
>nchar(str1)
>#[1] 16
>
>
>Now yes, you can remove it.
>
>str2 <- gsub("\\", "", str1, fixed = TRUE)
>identical(str, str2)
>#[1] TRUE
>
>
>
>Hope this helps,
>
>Rui Barradas
>
>?s 11:34 de 21/09/2018, Christofer Bogaso escreveu:
>> Hi,
>> 
>> I have below string where I am trying to remove Backslash from. I
>tried
>> with gsub() function, however failed to remove that:
>> 
>>> str = '<span id=\"ctl00'
>>> gsub("\\", "", str)
>> Error in gsub("\\", "", str) :
>>    invalid regular expression '\', reason 'Trailing backslash'
>> 
>> 
>> Any pointer to the right approach?
>> 
>> Thanks for your time
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 21 17:28:32 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 21 Sep 2018 08:28:32 -0700
Subject: [R] Fitting Production Curves
In-Reply-To: <_O_DvHZPLvQF7D5L6IDkx8lNvgTbN1NFC4xxX70VFIgOazkxU_PwIkJcJtvr25M4d0lzDuHySSUZnkrkUO9FWnL-qn1amYvUr04T5Nu-roQ=@protonmail.com>
References: <_O_DvHZPLvQF7D5L6IDkx8lNvgTbN1NFC4xxX70VFIgOazkxU_PwIkJcJtvr25M4d0lzDuHySSUZnkrkUO9FWnL-qn1amYvUr04T5Nu-roQ=@protonmail.com>
Message-ID: <CAGxFJbT0wkNQ_W+ix9RNFM9sQi=P7dt3CnS6=YmZ0nmvjFsyEQ@mail.gmail.com>

This list doesn't do statistics -- it does R programming, though statistics
does occur incidentally sometimes in that context. Not in your post
though. You should post on a statistics site like stats.stackexchange.com
for statistics questions.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 20, 2018 at 10:38 PM mikorym via R-help <r-help at r-project.org>
wrote:

> Hi All,
>
> By a production curve I mean for example the output of a mine, peak oil
> production or the yield of a farm over time within the same season. It is
> this last example that we should take as the prototypical case.
>
> What I would like to do is to fit a curve that inherits qualities of the
> discrete production data (such as area of the curve equaling the total
> production for the season). Fitting a curve with least squares (such as a
> Gaussean or Hubbert) presents some issues (with regards to accuracy of
> inherited features). My next logical attempt would be to fit a sum of
> curves, such as a Fourier or Wavelet sum. Perhaps there is something
> simpler or more flexible in the way I am thinking?
>
> My question is:
>
> 1. What would be an effective approach be to fit generalised production
> curves?
> 2. If a Wavelet sum is one of the best approaches, what would be a good
> way of implementing such curve fitting (including calculated coefficients)
> in R?
> 3. Is there anything else or another way that I should rather be thinking
> about this instead?
>
> Best regards
> Phillip-Jan van Zyl
> MSc Mathematics, Stellenbosch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Fri Sep 21 18:32:33 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 21 Sep 2018 09:32:33 -0700
Subject: [R] tibble question with a mean
In-Reply-To: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
Message-ID: <CAF8bMcat-QX561L23puZ7g5EbNUYteei876rnHNtUtRG6+TjgA@mail.gmail.com>

Since you are using tibbles you may want to go whole-hog and use the dplyr
package as well.

> xt <-
tibble(x=LETTERS[1:4],y=1:4,z=log2(1:4),a=c("dog","cat","tree","ferret"))
> xt %>% summarize(yMean=mean(y), zMean=mean(z), aLast=last(a))
# A tibble: 1 x 3
  yMean zMean aLast
  <dbl> <dbl> <chr>
1   2.5  1.15 ferret


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Sep 20, 2018 at 5:50 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello!
>
> Here is a toy tibble problem:
>
> xt <-
> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
> str(xt)
> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
>  $ x: chr  "A" "B" "C" "D"
>  $ y: int  1 2 3 4
>  $ z: num  0.3246 0.0504 0.339 0.4872
>  $ a: chr  "dog" "cat" "tree" "ferret"
> #No surprise
>  xt %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
> #surprised!
> mean(xt[2:3])
> [1] NA
> Warning message:
> In mean.default(xt[2:3]) : argument is not numeric or logical: returning NA
>  xt[, 2:3] %>% mean
> [1] NA
> Warning message:
> In mean.default(.) : argument is not numeric or logical: returning NA
>
> I have a feeling that I'm doing something silly wrong.  Has anyone run into
> this, please?  I saw something like this on this list, but didn't see a
> solution.
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Sep 21 18:34:11 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Fri, 21 Sep 2018 10:34:11 -0600
Subject: [R] tibble question with a mean
In-Reply-To: <CAF8bMcat-QX561L23puZ7g5EbNUYteei876rnHNtUtRG6+TjgA@mail.gmail.com>
References: <CACxE24mgTRBF+SCPvOGKerxBdT6FXhCqk0_vTKAeTBjY8FgGHg@mail.gmail.com>
 <CAF8bMcat-QX561L23puZ7g5EbNUYteei876rnHNtUtRG6+TjgA@mail.gmail.com>
Message-ID: <CACxE24kjDNwDqNp0See=1A3=sKz4k6wM+O2UFkO0tAqP=3Surg@mail.gmail.com>

Nice!

I didn?t realize you could do all that!

Thanks!


On Fri, Sep 21, 2018 at 10:32 AM William Dunlap <wdunlap at tibco.com> wrote:

> Since you are using tibbles you may want to go whole-hog and use the dplyr
> package as well.
>
> > xt <-
> tibble(x=LETTERS[1:4],y=1:4,z=log2(1:4),a=c("dog","cat","tree","ferret"))
> > xt %>% summarize(yMean=mean(y), zMean=mean(z), aLast=last(a))
> # A tibble: 1 x 3
>   yMean zMean aLast
>   <dbl> <dbl> <chr>
> 1   2.5  1.15 ferret
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Sep 20, 2018 at 5:50 PM, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
>
>> Hello!
>>
>> Here is a toy tibble problem:
>>
>> xt <-
>> tibble(x=LETTERS[1:4],y=1:4,z=rnorm(4),a=c("dog","cat","tree","ferret"))
>> str(xt)
>> Classes ?tbl_df?, ?tbl? and 'data.frame': 4 obs. of  4 variables:
>>  $ x: chr  "A" "B" "C" "D"
>>  $ y: int  1 2 3 4
>>  $ z: num  0.3246 0.0504 0.339 0.4872
>>  $ a: chr  "dog" "cat" "tree" "ferret"
>> #No surprise
>>  xt %>% mean
>> [1] NA
>> Warning message:
>> In mean.default(.) : argument is not numeric or logical: returning NA
>> #surprised!
>> mean(xt[2:3])
>> [1] NA
>> Warning message:
>> In mean.default(xt[2:3]) : argument is not numeric or logical: returning
>> NA
>>  xt[, 2:3] %>% mean
>> [1] NA
>> Warning message:
>> In mean.default(.) : argument is not numeric or logical: returning NA
>>
>> I have a feeling that I'm doing something silly wrong.  Has anyone run
>> into
>> this, please?  I saw something like this on this list, but didn't see a
>> solution.
>>
>> Thanks,
>> Erin
>>
>>
>> Erin Hodgess, PhD
>> mailto: erinm.hodgess at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]



From tomm@c @end|ng |rom nov@@edu  Fri Sep 21 20:17:10 2018
From: tomm@c @end|ng |rom nov@@edu (Thomas MacFarland)
Date: Fri, 21 Sep 2018 18:17:10 +0000
Subject: [R] Use ggplot to create a state map with counties and county names
 as labels
Message-ID: <BN3PR0601MB105772455B4C42AD73F96239AF120@BN3PR0601MB1057.namprd06.prod.outlook.com>

Everyone:

Using multiple resources I've been able to create a state (Kentucky) map that shows all 120 counties, with two selected counties highlighted in red.

Fine, except - I also want to show the names of the two selected counties, likely as labels.

Any ideas on how to achieve this aim would be greatly appreciated.

The code shows below.

Best wishes.

Tom

library(ggplot2)
library(ggthemes)
library(ggmap)
library(maps)
library(mapdata)

ls()
rm(list=ls(all=TRUE))
ls()


# U.S. States

states <- map_data("state")
head(states)
str(states)
ky_df <- subset(states, region == "kentucky")
head(ky_df)
str(states)

# U.S. Counties

counties <- map_data("county")
ky_county <- subset(counties, region == "kentucky")
head(ky_county)
str(ky_county)

ky_base <- ggplot2::ggplot(data = ky_df,
  mapping = aes(x = long, y = lat, group = group)) +
coord_fixed(1.3) +
geom_polygon(color = "black", fill = "aliceblue")
par(ask=TRUE); ky_base # Map of Kentucky with no counties, yet

par(ask=TRUE)
ky_base +
geom_polygon(data = ky_county, fill = NA, color = "black") +
geom_polygon(color = "black", fill = NA)  # Map of Kentucky with counties

# Select Pike County and Warren County as subregions
multiple_county_ky <- subset(ky_county, subregion=="pike" | subregion=="warren")

# Create a map with Pike County and Warren County in red
ky_base +
labs(title = "Kentucky Counties of Importance to the Study") +
geom_polygon(data = ky_county, fill = NA, color = "black") +
geom_polygon(color = "black", fill = NA) +
geom_polygon(data = multiple_county_ky, fill = "red", color = "white") +
theme_void()

# But how can I add the county name as a label to the two
# selected counties, Pike County and Warren County?


----------
Thomas W. MacFarland, Ed.D.
Senior Research Associate; Institutional Effectiveness and Associate Professor
Nova Southeastern University
Voice 954-262-5395 tommac at nova.edu<mailto:tommac at nova.edu>


	[[alternative HTML version deleted]]



From jwd @end|ng |rom @urewe@t@net  Fri Sep 21 23:19:37 2018
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Fri, 21 Sep 2018 14:19:37 -0700
Subject: [R] 
 Use ggplot to create a state map with counties and county names
 as labels
In-Reply-To: <BN3PR0601MB105772455B4C42AD73F96239AF120@BN3PR0601MB1057.namprd06.prod.outlook.com>
References: <BN3PR0601MB105772455B4C42AD73F96239AF120@BN3PR0601MB1057.namprd06.prod.outlook.com>
Message-ID: <20180921141937.1ee00fce@Draco.localdomain>

On Fri, 21 Sep 2018 18:17:10 +0000
Thomas MacFarland <tommac at nova.edu> wrote:

> Everyone:
> 
> Using multiple resources I've been able to create a state (Kentucky)
> map that shows all 120 counties, with two selected counties
> highlighted in red.
> 
> Fine, except - I also want to show the names of the two selected
> counties, likely as labels.
> 
> Any ideas on how to achieve this aim would be greatly appreciated.
> 
> The code shows below.
> 
> Best wishes.
> 
> Tom
You might want to try the ggplot2 group at Google Groups instead.  They
are specifically ggplot2.

JWDougherty



From eyibum+658k2q6uzi4qg m@iii@g oii guerriii@m@ii@com  Fri Sep 21 19:58:50 2018
From: eyibum+658k2q6uzi4qg m@iii@g oii guerriii@m@ii@com (eyibum+658k2q6uzi4qg m@iii@g oii guerriii@m@ii@com)
Date: Fri, 21 Sep 2018 17:58:50 +0000
Subject: [R] =?utf-8?b?UmNtZHIgcHJvYmxlbSByZXR1cm4oUmNtZHIg5ZWP6aGM5Zue?=
 =?utf-8?b?5aCxKQ==?=
Message-ID: <453982ae23baea4548a5c61682b137fef88@guerrillamail.com>

????R????????????R Commander ????????????????Excel???????(???????????)?????????!!(?????????)


??Hello, I am a hobby user of R. I recently used R Commander to select data from the toolbar ? import data ? import into Excel, but I can't import it (and I don't have a screen to choose from), I hope I can improve it soon!!(If you receive it, please reply.)


                                                                    ???????(Problem return user)?JML
                                                                    ????(E-mail)?my9890866 at yahoo.com.tw





----
Sent using Guerrillamail.com
Block or report abuse: https://www.guerrillamail.com//abuse/?a=Uwx8AAEQY4ZYmBy7%2BnscZlrIX80%3D

-------------- next part --------------
A non-text attachment was scrubbed...
Name: =?UTF-8?B?5pyq5ZG95ZCNLnBuZw==?=
Type: image/png
Size: 267789 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180921/18f57a5d/attachment-0002.png>

From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Sat Sep 22 10:14:51 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sat, 22 Sep 2018 10:14:51 +0200
Subject: [R] Link from vignette to package documentation
In-Reply-To: <1392b368-3045-36cd-5e03-ff83a0cc95f4@gmail.com>
References: <d9953a1b-8ff6-70ff-e847-d08059f683bb@wiwi.hu-berlin.de>
 <1392b368-3045-36cd-5e03-ff83a0cc95f4@gmail.com>
Message-ID: <23461.63995.924257.175982@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Fri, 21 Sep 2018 05:02:32 -0400 writes:

    > On 21/09/2018 4:54 AM, Sigbert Klinke wrote:
    >> Hi,
    >> 
    >> is it possible to make a link from a vignette to a (Rd)
    >> help files in my own or other packages?

    > Only with some significant compromises.  R normally acts
    > as the web server for Rd files, and the URL is not really
    > predictable.  So you would need to make the URL
    > predictable, either by something like

    > options(help.ports = 12345)

    > (which will put help on port 12345, blocking that port for
    > any other use, including help in another R session), or by
    > putting a static copy of the help pages on some other web
    > server.

    > Duncan Murdoch

Yes, and the other way around -- making working links from
package (*.Rmd or *.Rnw) vignettes to help pages of the same
package is also not easily and portably possible AFAICS.

Both would be desirable quite desirable for improved R
documentation and ideally so in a way that could also work with
an internet connection.

[and if we continue this, it may become more of an issue for
'R-devel' instead of 'R-help' ...]

Martin Maechler



From ph@edru@v @end|ng |rom gm@||@com  Sat Sep 22 12:49:02 2018
From: ph@edru@v @end|ng |rom gm@||@com (Andrew)
Date: Sat, 22 Sep 2018 11:49:02 +0100
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>
Message-ID: <c226c952-b8f3-3c1a-6c62-5d19530afce6@gmail.com>

Hi Michael

This looks like it could be really helpful in moving my project forwards 
thank you.

I remember many years ago using (proprietary) software from the 
University of Liverpool which did a nice job of allowing regions to be 
defined, and then for the space to be rotated to obtain visual 
inspection of relative distance from different angles. I appreciate that 
smacof will not do that, but as long as the analysis allows for the 
graph to be plotted and analysed, that's what's important.

Thank you again, and to all of those who responded.

Best wishes
Andrew


On 21/09/18 14:07, Michael Friendly wrote:
> Smallest space analysis (SSA) is just the name given to software 
> developed by Guttman & Lingoes around the time the various versions
> of multidimensional scaling were being developed.? Call it Israeli MDS
> or Falafel MDS if you prefer. The reason you encountered it in your
> course is presumably that the instructor was trained in that.
>
> There are several variants of MDS-like algorithms for embedding
> points representing objects in a space, using data representing
> similarities or distances among objects -- metric (cmdscale)
> and non-metric (MASS::isoMDS), using only rank order information, and 
> a variety of
> measures of goodness-of-fit ("stress").? I don't recall the details
> of the SSA programs, but that should matter little conceptually.
>
> The smacof package offers the widest array of possibilities.
>
> -Michael
>
>
> On 9/19/2018 7:00 AM, Andrew wrote:
>> Hi
>>
>> As part of my forensics psych course, we have been introduced to
>> Guttman's smallest space analysis (SSA). I want to explore this approach
>> using R, but despite finding some queries on the web about this same
>> thing, have yet to find any answers. The MASS package doesn't seem to do
>> the job, and the only thing I have been able to find is some proprietary
>> software HUDAP? (Hebrew University Data Analysis Package) which may/ not
>> be compatible with R (or GNU/Linux for that matter).
>>
>> Does anyone have information on how to do SSA using R?
>>
>> Many thanks
>>
>> Andrew
>>
>>
>> ????[[alternative HTML version deleted]]
>>
>
>



From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Sep 22 12:49:15 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 22 Sep 2018 06:49:15 -0400
Subject: [R] Link from vignette to package documentation
In-Reply-To: <23461.63995.924257.175982@stat.math.ethz.ch>
References: <d9953a1b-8ff6-70ff-e847-d08059f683bb@wiwi.hu-berlin.de>
 <1392b368-3045-36cd-5e03-ff83a0cc95f4@gmail.com>
 <23461.63995.924257.175982@stat.math.ethz.ch>
Message-ID: <35418624-a144-93be-9dfa-c635eae24be8@gmail.com>

On 22/09/2018 4:14 AM, Martin Maechler wrote:
>>>>>> Duncan Murdoch
>>>>>>      on Fri, 21 Sep 2018 05:02:32 -0400 writes:
> 
>      > On 21/09/2018 4:54 AM, Sigbert Klinke wrote:
>      >> Hi,
>      >>
>      >> is it possible to make a link from a vignette to a (Rd)
>      >> help files in my own or other packages?
> 
>      > Only with some significant compromises.  R normally acts
>      > as the web server for Rd files, and the URL is not really
>      > predictable.  So you would need to make the URL
>      > predictable, either by something like
> 
>      > options(help.ports = 12345)
> 
>      > (which will put help on port 12345, blocking that port for
>      > any other use, including help in another R session), or by
>      > putting a static copy of the help pages on some other web
>      > server.
> 
>      > Duncan Murdoch
> 
> Yes, and the other way around -- making working links from
> package (*.Rmd or *.Rnw) vignettes to help pages of the same
> package is also not easily and portably possible AFAICS.

Actually I was overly pessimistic above.  If both the vignette and the 
help page are being viewed in a web browser, it should be possible using 
relative links.

My rgl package does this:  the "rgl Overview" vignette is written in R 
Markdown and displayed in HTML.  It has links to the help pages.  There 
are some limitations:  the links only work while the same R session is 
running.

To make a link to help topic "points3d", it inserts code that produces 
the anchor

<a href="../../rgl/help/points3d">`points3d`</a>

in the text.  (It should also work to replace the prefix "../../rgl/" 
with just "../", but the longer path allows for links to help pages in 
other packages.)

This won't work if you are looking at the vignette somewhere else (e.g. 
at https://cran.r-project.org/web/packages/rgl/vignettes/rgl.html).

Duncan Murdoch


> 
> Both would be desirable quite desirable for improved R
> documentation and ideally so in a way that could also work with
> an internet connection.
> 
> [and if we continue this, it may become more of an issue for
> 'R-devel' instead of 'R-help' ...]
> 
> Martin Maechler
>



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Sep 22 18:51:25 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 22 Sep 2018 09:51:25 -0700
Subject: [R] as.Date and ylim in empty plot: RESOLVED
In-Reply-To: <CAC8ss31dX7fnhWUXv97z_Fjd4pk8jmfqP1=Gc8ijUvYf1WwvpA@mail.gmail.com>
References: <CAC8ss33ER-E2mbTQ5w5NL7wGJwaQW-g_yETne618q69BteicGA@mail.gmail.com>
 <431EE567-5F41-4638-B31A-F6E7E3E95782@comcast.net>
 <CAC8ss31dX7fnhWUXv97z_Fjd4pk8jmfqP1=Gc8ijUvYf1WwvpA@mail.gmail.com>
Message-ID: <5B38B320-CB43-42D4-88AC-1CB15099C983@comcast.net>


> On Sep 19, 2018, at 10:48 PM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Hi David,
> That's it!!! The outcome is attached.

The explanation for this is that columns that have digits separated by dashes will not be interpreted by R's read.table() as numeric or dates, but rather as the default for text entries:  as R factors. Factors are stored as numbers with an associated attribute that gets used to display the meaning of those numbers. Since the numbers used are integers from 1 to the count of unique items, using the xlim = as.numeric(as.Date(.)) creates values are far outside the range of the factor integers and nothing gets displayed as a result. If you had used range(as.numeric(<factor-variable-name>)) you might have seen something. Whether it was what you wanted to see .... well, that's another matter!

Good luck understanding R factors. Some research centers have adopted a policy of setting the option used by read.table for that behavior with:

options(stringsAsFactors= FALSE)  # can be set in .Rprofile or other "startup" file.

That produces text rather than factors by default and might result in less confusion.

-- 
David.
> 
> Many thanks please.
> 
> Best
> Ogbos
> 
> On Wed, Sep 19, 2018 at 11:34 PM David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Sep 19, 2018, at 7:55 AM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> > 
> > Dear Experts,
> > I generated the plot attached. Every other thing is OK except the black
> > horizontal lines which should appear like points or dots as the coloured
> > ones. I can't understand why.
> > 
> > I tried to change it to look like dots by calling empty plots so that I
> > will add them as points.
> > 
> > Since I have a range of date that can fall any where within 2005, I tried:
> > 
> > plot(1, type="n", xlab="", ylab="",
> > xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")), ylim=c(-.5, -10))
> > 
> > ylim worked fine but xlim instead of appearing like date as indicated on
> > the x-axes of the attached plot, translated to ordinary numbers (12800,
> > 12900,13000, 13100).
> > 
> > All the data is of the same format:
> > 2005-01-04 -2.76105935648091
> > 2005-01-19 -9.60813496025994
> > 2005-01-22 -7.92101965866777
> > 2005-02-19 -1.61308152604905
> > 2005-02-24 -1.51497015807712
> > 2005-05-09 -2.06465797304654
> > 2005-05-11 -1.14840389007051
> > 2005-05-16 -3.85281900888504
> > 2005-06-13 -1.18659683796617
> > 2005-06-17 -3.48787712566258
> > 2005-06-22 -1.14223758296308
> > 2005-07-18 -4.96013018907366
> > 2005-08-03 -1.24313324914368
> > 2005-08-07 -2.96672894841722
> > 2005-08-10 -1.11868063781156
> > 2005-08-25 -1.46453734930983
> > 2005-09-13 -8.00895215754776
> > 2005-09-15 -6.63439065989452
> > 2005-10-13 -2.25054996925846
> > 2005-12-15 -1.08933890547705
> 
> You did not succeed in creating a plot that the rhelp mail server would accept. My guess is that the first column is a factor variable and that you did not use colClasses when doing your data input.
> 
> dd <- read.table(text="2005-01-04 -2.76105935648091
> 2005-01-19 -9.60813496025994
> 2005-01-22 -7.92101965866777
> 2005-02-19 -1.61308152604905
> 2005-02-24 -1.51497015807712
> 2005-05-09 -2.06465797304654
> 2005-05-11 -1.14840389007051
> 2005-05-16 -3.85281900888504
> 2005-06-13 -1.18659683796617
> 2005-06-17 -3.48787712566258
> 2005-06-22 -1.14223758296308
> 2005-07-18 -4.96013018907366
> 2005-08-03 -1.24313324914368
> 2005-08-07 -2.96672894841722
> 2005-08-10 -1.11868063781156
> 2005-08-25 -1.46453734930983
> 2005-09-13 -8.00895215754776
> 2005-09-15 -6.63439065989452
> 2005-10-13 -2.25054996925846
> 2005-12-15 -1.08933890547705", colClasses=c("Date","numeric")
> )
> 
> 
> No problems with:
> 
>  plot(dd[[1]], dd[[2]], xlim=c(as.Date("2005-01-01"),as.Date("2005-12-31")))
> 
> 
> (Not a particularly good test of the use of an xlim argument since nothing was excluded.)
> 
> PDF's are accepted. PNGs are not.
> 
> -- 
> David.
> > 
> > Thank you so much for your input.
> > 
> > Best regards
> > Ogbos
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> <Ogbos.pdf>

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From r@herry8 @end|ng |rom comc@@t@net  Sat Sep 22 23:16:27 2018
From: r@herry8 @end|ng |rom comc@@t@net (rsherry8)
Date: Sat, 22 Sep 2018 17:16:27 -0400
Subject: [R] For Loop
Message-ID: <5BA6B12B.3090606@comcast.net>


It is my impression that good R programmers make very little use of the 
for statement. Please consider  the following
R statement:
         for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
One problem I have found with this statement is that s must exist before 
the statement is run. Can it be written without using a for
loop? Would that be better?

Thanks,
Bob



From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep 22 23:42:30 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 22 Sep 2018 14:42:30 -0700
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <CAGxFJbTcO47F11YT8EcPL=f0JytDY8TvPqXFTyESWyURR-FaEA@mail.gmail.com>

Bob:

Please, please spend some time with an R tutorial or two before you post
here. This list can help, but I think we assume that you have already made
an effort to learn basic R on your own. Your question is about as basic as
it gets, so it appears to me that you have not done this. There are many
many R tutorials out there. Some suggestions, by no means comprehensive,
can be found here:
https://www.rstudio.com/online-learning/#r-programming

Others will no doubt respond, but you can answer it yourself after only a
few minutes with most R tutorials.

Cheers,
Bert




On Sat, Sep 22, 2018 at 2:16 PM rsherry8 <rsherry8 at comcast.net> wrote:

>
> It is my impression that good R programmers make very little use of the
> for statement. Please consider  the following
> R statement:
>          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> One problem I have found with this statement is that s must exist before
> the statement is run. Can it be written without using a for
> loop? Would that be better?
>
> Thanks,
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From rmh @end|ng |rom temp|e@edu  Sat Sep 22 23:57:32 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Sat, 22 Sep 2018 17:57:32 -0400
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <CAGx1TMBT53Pj=Ts4TVBiuuu2Ud86ysaLajh6M_6=k3jWdbXJHA@mail.gmail.com>

c1 <- 1:1000000
len <- 1000000
system.time(
s1 <- log(c1[-1]/c1[-len])
)
s <- c1[-len]
system.time(
for (i in 1:(len-1)) s[i] <- log(c1[i+1]/c1[i])
)
all.equal(s,s1)


>
> c1 <- 1:1000000
> len <- 1000000
> system.time(
+ s1 <- log(c1[-1]/c1[-len])
+ )
   user  system elapsed
  0.032   0.005   0.037
> s <- c1[-len]
> system.time(
+ for (i in 1:(len-1)) s[i] <- log(c1[i+1]/c1[i])
+ )
   user  system elapsed
  0.226   0.002   0.232
> all.equal(s,s1)
[1] TRUE
>

much faster, and much easier to understand when vectorized

On Sat, Sep 22, 2018 at 5:16 PM, rsherry8 <rsherry8 at comcast.net> wrote:
>
> It is my impression that good R programmers make very little use of the for
> statement. Please consider  the following
> R statement:
>         for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> One problem I have found with this statement is that s must exist before the
> statement is run. Can it be written without using a for
> loop? Would that be better?
>
> Thanks,
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From e@@w|ek @end|ng |rom gm@||@com  Sun Sep 23 01:22:05 2018
From: e@@w|ek @end|ng |rom gm@||@com (Ek Esawi)
Date: Sat, 22 Sep 2018 19:22:05 -0400
Subject: [R] error "The system cannot find the file specified..."
Message-ID: <CA+ZkTxuJSPgPL-QWjGOXLP7eRP2HW0DZR7MA4Jc6-VBF0oqbpw@mail.gmail.com>

Hi All,

I am using the R Tabulizer package to extract tables from a set of pdf
files. Tabulizer creates a list of data frames; each corresponds to a
table in a file. My aim is to create a list of lists, one for each
file.i have 8 files
The code below kept giving me the error "Error in
normalizePath(path.expand(path), winslash, mustWork) : path[1]="April
24.PDF": The system cannot find the file specified". But when i used
table_extract (file) for individual files, it works perfectly.

Any help is greatly appreciated.


EK


path = "C:/Users/name/Documents/TextMining/"
file.names <- dir(path, pattern =".PDF")
A <- vector("list", length(file.names))
for(i in 1:length(file.names)){
  A[i] <- extract_tables(file.names[i])}



From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep 23 02:45:55 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 22 Sep 2018 17:45:55 -0700
Subject: [R] error "The system cannot find the file specified..."
In-Reply-To: <CA+ZkTxuJSPgPL-QWjGOXLP7eRP2HW0DZR7MA4Jc6-VBF0oqbpw@mail.gmail.com>
References: <CA+ZkTxuJSPgPL-QWjGOXLP7eRP2HW0DZR7MA4Jc6-VBF0oqbpw@mail.gmail.com>
Message-ID: <CAGxFJbRTKwLayx+NkhPvCZyXBTbYNQ85yjO48wmB9kYXZ+G1mA@mail.gmail.com>

You probably want pattern = "\\.PDF" , as "." has a special meaning for
regex's. However, that really shouldn't make any difference.

Obvious questions:
1. dir() returns a vector of file names. Are they pdf's "PDF" or "pdf"
(case matters!) ?
2. extract.tables() almost certainly wants the full path names to the
files, not just the file names, if your working directory isn't set to the
directory containing the files. So what does getwd() give?

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Sep 22, 2018 at 4:22 PM Ek Esawi <esawiek at gmail.com> wrote:

> Hi All,
>
> I am using the R Tabulizer package to extract tables from a set of pdf
> files. Tabulizer creates a list of data frames; each corresponds to a
> table in a file. My aim is to create a list of lists, one for each
> file.i have 8 files
> The code below kept giving me the error "Error in
> normalizePath(path.expand(path), winslash, mustWork) : path[1]="April
> 24.PDF": The system cannot find the file specified". But when i used
> table_extract (file) for individual files, it works perfectly.
>
> Any help is greatly appreciated.
>
>
> EK
>
>
> path = "C:/Users/name/Documents/TextMining/"
> file.names <- dir(path, pattern =".PDF")
> A <- vector("list", length(file.names))
> for(i in 1:length(file.names)){
>   A[i] <- extract_tables(file.names[i])}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From ||uwen@u| @end|ng |rom gm@||@com  Sun Sep 23 02:53:38 2018
From: ||uwen@u| @end|ng |rom gm@||@com (Wensui Liu)
Date: Sat, 22 Sep 2018 19:53:38 -0500
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <CAKyN3iA+ZeVatA=O5cz=czDLHvZr60qgWTkgan-zd27Nn+fkBg@mail.gmail.com>

another version just for fun

s <- parallel::pvec(1:len, function(i) log(c1[i + 1] / c1[i]))
On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>
>
> It is my impression that good R programmers make very little use of the
> for statement. Please consider  the following
> R statement:
>          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> One problem I have found with this statement is that s must exist before
> the statement is run. Can it be written without using a for
> loop? Would that be better?
>
> Thanks,
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ||uwen@u| @end|ng |rom gm@||@com  Sun Sep 23 02:57:56 2018
From: ||uwen@u| @end|ng |rom gm@||@com (Wensui Liu)
Date: Sat, 22 Sep 2018 19:57:56 -0500
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>

or this one:

(Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))

On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>
>
> It is my impression that good R programmers make very little use of the
> for statement. Please consider  the following
> R statement:
>          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> One problem I have found with this statement is that s must exist before
> the statement is run. Can it be written without using a for
> loop? Would that be better?
>
> Thanks,
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep 23 03:45:52 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 22 Sep 2018 18:45:52 -0700
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <9D7649DE-E0B7-4E6D-8306-544E8C7F95E7@dcn.davis.ca.us>

I do use for loops a few times per month, but only wrapped around large chunks of vectorized calculations, not for this kind of use case. In those cases I also pre-allocate output vectors/lists (e.g. vector( "list", len )) to avoid memory thrashing as you grow lists or other vectors one element at a time (v <- c( v, new value ) is an inefficient trick). I also create variables to hold intermediate results that would yield the same answer each time before going into the loop (e.g. exp(1)).

As regards your toy example, I would use a one-liner:

s <- diff( log( c1 ) )

which avoids executing exp(1) at all, much less every time through the loop, and it uses vectorized incremental subtraction rather than division (laws of logarithms from algebra). The default base for the log function is e, so it is unnecessary to specify it. Note that your loop calculates logs involving all but the first and last elements of c1 twice... once when indexing for i+1, and again in the next iteration of the loop it is accessed as index i.

You would be surprised how many iterative algorithms can be accomplished with cumsum and diff. Bill Dunlap has demonstrated examples quite a few times in the mailing list archives if you have time  to search.

On September 22, 2018 2:16:27 PM PDT, rsherry8 <rsherry8 at comcast.net> wrote:
>
>It is my impression that good R programmers make very little use of the
>
>for statement. Please consider  the following
>R statement:
>       for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>One problem I have found with this statement is that s must exist
>before 
>the statement is run. Can it be written without using a for
>loop? Would that be better?
>
>Thanks,
>Bob
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From |@b|@no@|r@nc@d@ @end|ng |rom hotm@||@com  Sun Sep 23 06:26:06 2018
From: |@b|@no@|r@nc@d@ @end|ng |rom hotm@||@com (=?iso-8859-1?Q?Fabiano_Fran=E7a?=)
Date: Sun, 23 Sep 2018 04:26:06 +0000
Subject: [R] How to adjust the regression script R/Rstudio?
Message-ID: <CY4PR13MB0966785A2048D84E3A0B38DD83100@CY4PR13MB0966.namprd13.prod.outlook.com>

Dear, how to set up the equation of the straight line and the R ^ 2, remove the bars of the chart area and the caption to the right?

Follow the attached file containing the data. We used the R version 3.4.4.

library(plotly)
library(ggplot2)


setwd("C:\\Users\\Fabiano\\Desktop\\Artigo OE")
dados <- read.table('IVCM.txt', header =T)

lm_labels <- function(dados) {
  mod <- lm(IVCM ~ Doses, data=dados)
  formula <- sprintf("italic(y) == %.2f %+.2f * italic(x)",
                     round(coef(mod)[1], 2), round(coef(mod)[2], 2))

  r <- cor(dados$Doses, dados$IVCM)
  r2 <- sprintf("italic(R^2) == %.2f", r^2)
  data.frame(formula=formula, r2=r2, stringsAsFactors=FALSE)
}

library(plyr) # For the ddply() function
labels <- ddply(dados, "Fungicidas", lm_labels)
labels

f_labels <- data.frame(Fungicidas = c("?gua", "Frowncide", "Cravo", "Canela", "Capim-Lim?o", "Tomilho"), label = c("H2O", "F500SC", "cv", "Can", "CL", "Tom"))

p <- ggplot(dados, aes(x=Doses, y=IVCM, add = "reg.line", conf.int = TRUE, parse = TRUE)) +
  geom_point(size = .5) +
  facet_wrap(~ Fungicidas) +
  stat_smooth(aes(colour = Fungicidas), add = "loess", method = "lm", formula = y ~ x) +
  geom_text(x=0.6, y=9.5, size = 3, aes(label=formula), data=labels, parse=TRUE, hjust=0) +
  geom_text(x=0.6, y=9, size = 3, aes(label=r2), data=labels, parse=TRUE, hjust=0) +
  theme_bw()



(p=ggplotly(p))

Best regards,

Fabiano Fran?a da Silva
Doutorando em Fitotecnia - ESALQ/USP
MSc Fitotecnia - UFLA
Eng?. Agr?nomo - UFLA
(35) 9 9155-5443 TIM



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: IVCM.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180923/f8e28835/attachment-0002.txt>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Sep 23 11:29:59 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 23 Sep 2018 10:29:59 +0100
Subject: [R] error "The system cannot find the file specified..."
In-Reply-To: <CAGxFJbRTKwLayx+NkhPvCZyXBTbYNQ85yjO48wmB9kYXZ+G1mA@mail.gmail.com>
References: <CA+ZkTxuJSPgPL-QWjGOXLP7eRP2HW0DZR7MA4Jc6-VBF0oqbpw@mail.gmail.com>
 <CAGxFJbRTKwLayx+NkhPvCZyXBTbYNQ85yjO48wmB9kYXZ+G1mA@mail.gmail.com>
Message-ID: <efc0ee37-e464-3ec3-ba7d-c60575c3e192@sapo.pt>

Hello,

I would add that it's probably better to assign

for(i in seq_along(file.names)){
   A[[i]] <- extract_tables(file.names[i])
}


(It's a list so double [[, not just [).

Hope this helps,

Rui Barradas

?s 01:45 de 23/09/2018, Bert Gunter escreveu:
> for(i in 1:length(file.names)){
>    A[i] <- extract_tables(file.names[i])}



From er|cjberger @end|ng |rom gm@||@com  Sun Sep 23 12:15:11 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 23 Sep 2018 13:15:11 +0300
Subject: [R] Packaged exe and Shiny
In-Reply-To: <4C65246C-FDF7-4D4C-9F40-E510D50F9206@dcn.davis.ca.us>
References: <d71e9b46-7a37-4e1c-b6ca-8142baaadbcd@me.com>
 <CA+8X3fUQYVu2zhrd6DDu-a3wP2OVuF0DUBcFvwd5iG-US0x=ZQ@mail.gmail.com>
 <4C65246C-FDF7-4D4C-9F40-E510D50F9206@dcn.davis.ca.us>
Message-ID: <CAGgJW74c3LH2ihEgCWh+mQdEHFGR76GaCBwoEURsZ0F9aTMcAA@mail.gmail.com>

Hi Kevin,
I did something along these lines using shiny and I had a good experience
with it.
You would require a server (virtual or physical) to run the shiny-server
program.
This approach is particularly suitable if your target users do not know (or
use) R.
If you go down this route I also suggest that your server be separate from
your
development machine. This way you can test new functionality and reboot your
development machine as you wish without causing issues for your users.
In my case I created a virtual server so there was no requirement to buy
additional hardware.

HTH,
Eric





On Tue, Sep 11, 2018 at 1:58 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> IMO the best short answer is don't target making an install package or msi
> at all... the obstacles are quite significant. Aim for building most of
> your capabilities in packages and having people install them. You can setup
> an in-house package repo to simplify this and give them a startup script
> that configures their R environment.
>
> There is also the option to use R-Portable [1] but this leads to massive
> deployment files that don't upgrade easily.
>
> I also think that when the time crunch happens many people will go to the
> internet and copy-paste solutions that you would be unlikely to have
> anticipated. Closing off that scary console completely will keep you in the
> hot seat indefinitely, whereas giving them the option to go around your UI
> lets more resources be allocated later.
>
> [1] https://www.r-bloggers.com/deploying-desktop-apps-with-r/amp/
>
> On September 10, 2018 3:17:02 PM PDT, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >Hi Kevin,
> >It might be just as easy to write R scripts that would do basic
> >analyses. Users could "source" these scripts in an R session or from
> >the command line. The scripts would be much more compact than the .exe
> >files that you describe.
> >
> >Jim
> >
> >On Tue, Sep 11, 2018 at 8:06 AM Kevin Kowitski via R-help
> ><r-help at r-project.org> wrote:
> >>
> >> Hey Everyone,
> >>
> >>   I do not know if this topic has been covered, I'm sure it must
> >have, but is there a good environment for packaging R code into a
> >distributed exe. (which includes all of the required libraries, etc.)?
> >I have seen that Shiny is a good GUI / Web library for sharing R
> >programs, but I have never used it.
> >>
> >> What is the groups input on this?
> >>
> >> My goal is to create some basic tools (with interfaces) at work for
> >analyzing .csv files and generating basic graphs and output csv files.
> >These tools would be distributed to team members to have on their
> >desktops.   I considered doing this in Java, but I am more well versed
> >in R so it would be quicker for me to whip up the varying tools in R
> >than re-learning Java.
> >>
> >> Thank you!
> >>
> >> -Kevin
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From |@t@z@hn @end|ng |rom gm@||@com  Sun Sep 23 14:53:51 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Sun, 23 Sep 2018 08:53:51 -0400
Subject: [R] For Loop
In-Reply-To: <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
Message-ID: <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>

On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
>
> or this one:
>
> (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))

Oh dear god no.

>
> On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> >
> >
> > It is my impression that good R programmers make very little use of the
> > for statement. Please consider  the following
> > R statement:
> >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> > One problem I have found with this statement is that s must exist before
> > the statement is run. Can it be written without using a for
> > loop? Would that be better?
> >
> > Thanks,
> > Bob
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From |r|end|y @end|ng |rom yorku@c@  Sun Sep 23 16:22:58 2018
From: |r|end|y @end|ng |rom yorku@c@ (Michael Friendly)
Date: Sun, 23 Sep 2018 10:22:58 -0400
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <c226c952-b8f3-3c1a-6c62-5d19530afce6@gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>
 <c226c952-b8f3-3c1a-6c62-5d19530afce6@gmail.com>
Message-ID: <4d2400ea-28ef-875a-064e-79a0bd7325ac@yorku.ca>

On 9/22/2018 6:49 AM, Andrew wrote:
> Hi Michael
> 
> This looks like it could be really helpful in moving my project forwards 
> thank you.
> 
> I remember many years ago using (proprietary) software from the 
> University of Liverpool which did a nice job of allowing regions to be 
> defined, and then for the space to be rotated to obtain visual 
> inspection of relative distance from different angles. I appreciate that 
> smacof will not do that, but as long as the analysis allows for the 
> graph to be plotted and analysed, that's what's important.

You need not rely on the plots provided directly by a given package.
Just roll your own using standard plotting libraries.
Here is just the first Google hit on "R MDS 3D plot"

http://omnilogia.blogspot.com/2014/05/basic-2d-3d-multi-dimensional-scaling.html

which shows a rotating 3D plot, colored by a grouping variable.  Here is 
another:

http://whatzcookinlab.blogspot.com/2013/05/spinning-3d-mds-plot.html

The vegan and ade4 packages also have a variety of plots and related 
methods.


-Michael

> 
> Thank you again, and to all of those who responded.
> 
> Best wishes
> Andrew
> 
> 
> On 21/09/18 14:07, Michael Friendly wrote:
>> Smallest space analysis (SSA) is just the name given to software 
>> developed by Guttman & Lingoes around the time the various versions
>> of multidimensional scaling were being developed.? Call it Israeli MDS
>> or Falafel MDS if you prefer. The reason you encountered it in your
>> course is presumably that the instructor was trained in that.
>>
>> There are several variants of MDS-like algorithms for embedding
>> points representing objects in a space, using data representing
>> similarities or distances among objects -- metric (cmdscale)
>> and non-metric (MASS::isoMDS), using only rank order information, and 
>> a variety of
>> measures of goodness-of-fit ("stress").? I don't recall the details
>> of the SSA programs, but that should matter little conceptually.
>>
>> The smacof package offers the widest array of possibilities.
>>
>> -Michael
>>
>>
>> On 9/19/2018 7:00 AM, Andrew wrote:
>>> Hi
>>>
>>> As part of my forensics psych course, we have been introduced to
>>> Guttman's smallest space analysis (SSA). I want to explore this approach
>>> using R, but despite finding some queries on the web about this same
>>> thing, have yet to find any answers. The MASS package doesn't seem to do
>>> the job, and the only thing I have been able to find is some proprietary
>>> software HUDAP? (Hebrew University Data Analysis Package) which may/ not
>>> be compatible with R (or GNU/Linux for that matter).
>>>
>>> Does anyone have information on how to do SSA using R?
>>>
>>> Many thanks
>>>
>>> Andrew
>>>
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>
>>
>



From |@t@z@hn @end|ng |rom gm@||@com  Sun Sep 23 19:32:50 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Sun, 23 Sep 2018 13:32:50 -0400
Subject: [R] For Loop
In-Reply-To: <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
Message-ID: <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>

On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
>
> Why?

The operations required for this algorithm are vectorized, as are most
operations in R. There is no need to iterate through each element.
Using Vectorize to achieve the iteration is no better than using
*apply or a for-loop, and betrays the same basic lack of insight into
basic principles of programming in R.

And/or, if you want a more practical reason:

> c1 <- 1:1000000
> len <- 1000000
> system.time( s1 <- log(c1[-1]/c1[-len]))
   user  system elapsed
  0.031   0.004   0.035
> system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
   user  system elapsed
  1.258   0.022   1.282

Best,
Ista

>
> On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
>>
>> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
>> >
>> > or this one:
>> >
>> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>
>> Oh dear god no.
>>
>> >
>> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>> > >
>> > >
>> > > It is my impression that good R programmers make very little use of the
>> > > for statement. Please consider  the following
>> > > R statement:
>> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>> > > One problem I have found with this statement is that s must exist before
>> > > the statement is run. Can it be written without using a for
>> > > loop? Would that be better?
>> > >
>> > > Thanks,
>> > > Bob
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.



From ||uwen@u| @end|ng |rom gm@||@com  Sun Sep 23 19:46:32 2018
From: ||uwen@u| @end|ng |rom gm@||@com (Wensui Liu)
Date: Sun, 23 Sep 2018 12:46:32 -0500
Subject: [R] For Loop
In-Reply-To: <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
Message-ID: <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>

actually, by the parallel pvec, the user time is a lot shorter. or did
I somewhere miss your invaluable insight?

> c1 <- 1:1000000
> len <- length(c1)
> rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
                  test replications elapsed relative user.self sys.self
1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
  user.child sys.child
1          0         0
> rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
                                                               test
1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
  replications elapsed relative user.self sys.self user.child sys.child
1          100   9.079        1     2.571    4.138      9.736     8.046
On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
>
> On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
> >
> > Why?
>
> The operations required for this algorithm are vectorized, as are most
> operations in R. There is no need to iterate through each element.
> Using Vectorize to achieve the iteration is no better than using
> *apply or a for-loop, and betrays the same basic lack of insight into
> basic principles of programming in R.
>
> And/or, if you want a more practical reason:
>
> > c1 <- 1:1000000
> > len <- 1000000
> > system.time( s1 <- log(c1[-1]/c1[-len]))
>    user  system elapsed
>   0.031   0.004   0.035
> > system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>    user  system elapsed
>   1.258   0.022   1.282
>
> Best,
> Ista
>
> >
> > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
> >>
> >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
> >> >
> >> > or this one:
> >> >
> >> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> >>
> >> Oh dear god no.
> >>
> >> >
> >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> >> > >
> >> > >
> >> > > It is my impression that good R programmers make very little use of the
> >> > > for statement. Please consider  the following
> >> > > R statement:
> >> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> >> > > One problem I have found with this statement is that s must exist before
> >> > > the statement is run. Can it be written without using a for
> >> > > loop? Would that be better?
> >> > >
> >> > > Thanks,
> >> > > Bob
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.



From |@t@z@hn @end|ng |rom gm@||@com  Sun Sep 23 20:18:25 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Sun, 23 Sep 2018 14:18:25 -0400
Subject: [R] For Loop
In-Reply-To: <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
Message-ID: <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>

On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
>
> actually, by the parallel pvec, the user time is a lot shorter. or did
> I somewhere miss your invaluable insight?
>
> > c1 <- 1:1000000
> > len <- length(c1)
> > rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
>                   test replications elapsed relative user.self sys.self
> 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
>   user.child sys.child
> 1          0         0
> > rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
>                                                                test
> 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
>   replications elapsed relative user.self sys.self user.child sys.child
> 1          100   9.079        1     2.571    4.138      9.736     8.046

Your output is mangled in my email, but on my system your pvec
approach takes more than twice as long:

c1 <- 1:1000000
len <- length(c1)
library(parallel)
library(rbenchmark)

regular <- function() log(c1[-1]/c1[-len])
iterate.parallel <- function() {
  pvec(1:(len - 1), mc.cores = 4,
       function(i) log(c1[i + 1] / c1[i]))
}

benchmark(regular(), iterate.parallel(),
          replications = 100,
          columns = c("test", "elapsed", "relative"))
##                 test elapsed relative
## 2 iterate.parallel()   7.517    2.482
## 1          regular()   3.028    1.000

Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
to understand and it runs pretty fast. There is usually no reason to
make it more complicated.
--Ista

> On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
> >
> > On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
> > >
> > > Why?
> >
> > The operations required for this algorithm are vectorized, as are most
> > operations in R. There is no need to iterate through each element.
> > Using Vectorize to achieve the iteration is no better than using
> > *apply or a for-loop, and betrays the same basic lack of insight into
> > basic principles of programming in R.
> >
> > And/or, if you want a more practical reason:
> >
> > > c1 <- 1:1000000
> > > len <- 1000000
> > > system.time( s1 <- log(c1[-1]/c1[-len]))
> >    user  system elapsed
> >   0.031   0.004   0.035
> > > system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> >    user  system elapsed
> >   1.258   0.022   1.282
> >
> > Best,
> > Ista
> >
> > >
> > > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
> > >>
> > >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
> > >> >
> > >> > or this one:
> > >> >
> > >> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > >>
> > >> Oh dear god no.
> > >>
> > >> >
> > >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> > >> > >
> > >> > >
> > >> > > It is my impression that good R programmers make very little use of the
> > >> > > for statement. Please consider  the following
> > >> > > R statement:
> > >> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> > >> > > One problem I have found with this statement is that s must exist before
> > >> > > the statement is run. Can it be written without using a for
> > >> > > loop? Would that be better?
> > >> > >
> > >> > > Thanks,
> > >> > > Bob
> > >> > >
> > >> > > ______________________________________________
> > >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> > > and provide commented, minimal, self-contained, reproducible code.
> > >> >
> > >> > ______________________________________________
> > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> > and provide commented, minimal, self-contained, reproducible code.



From ||uwen@u| @end|ng |rom gm@||@com  Sun Sep 23 20:26:32 2018
From: ||uwen@u| @end|ng |rom gm@||@com (Wensui Liu)
Date: Sun, 23 Sep 2018 13:26:32 -0500
Subject: [R] For Loop
In-Reply-To: <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
Message-ID: <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>

what you measures is the "elapsed" time in the default setting. you
might need to take a closer look at the beautiful benchmark() function
and see what time I am talking about.

I just provided tentative solution for the person asking for it  and
believe he has enough wisdom to decide what's best. why bother to
judge others subjectively?
On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>
> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
> >
> > actually, by the parallel pvec, the user time is a lot shorter. or did
> > I somewhere miss your invaluable insight?
> >
> > > c1 <- 1:1000000
> > > len <- length(c1)
> > > rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
> >                   test replications elapsed relative user.self sys.self
> > 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
> >   user.child sys.child
> > 1          0         0
> > > rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
> >                                                                test
> > 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
> >   replications elapsed relative user.self sys.self user.child sys.child
> > 1          100   9.079        1     2.571    4.138      9.736     8.046
>
> Your output is mangled in my email, but on my system your pvec
> approach takes more than twice as long:
>
> c1 <- 1:1000000
> len <- length(c1)
> library(parallel)
> library(rbenchmark)
>
> regular <- function() log(c1[-1]/c1[-len])
> iterate.parallel <- function() {
>   pvec(1:(len - 1), mc.cores = 4,
>        function(i) log(c1[i + 1] / c1[i]))
> }
>
> benchmark(regular(), iterate.parallel(),
>           replications = 100,
>           columns = c("test", "elapsed", "relative"))
> ##                 test elapsed relative
> ## 2 iterate.parallel()   7.517    2.482
> ## 1          regular()   3.028    1.000
>
> Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
> to understand and it runs pretty fast. There is usually no reason to
> make it more complicated.
> --Ista
>
> > On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
> > >
> > > On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
> > > >
> > > > Why?
> > >
> > > The operations required for this algorithm are vectorized, as are most
> > > operations in R. There is no need to iterate through each element.
> > > Using Vectorize to achieve the iteration is no better than using
> > > *apply or a for-loop, and betrays the same basic lack of insight into
> > > basic principles of programming in R.
> > >
> > > And/or, if you want a more practical reason:
> > >
> > > > c1 <- 1:1000000
> > > > len <- 1000000
> > > > system.time( s1 <- log(c1[-1]/c1[-len]))
> > >    user  system elapsed
> > >   0.031   0.004   0.035
> > > > system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > >    user  system elapsed
> > >   1.258   0.022   1.282
> > >
> > > Best,
> > > Ista
> > >
> > > >
> > > > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
> > > >>
> > > >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
> > > >> >
> > > >> > or this one:
> > > >> >
> > > >> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > > >>
> > > >> Oh dear god no.
> > > >>
> > > >> >
> > > >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> > > >> > >
> > > >> > >
> > > >> > > It is my impression that good R programmers make very little use of the
> > > >> > > for statement. Please consider  the following
> > > >> > > R statement:
> > > >> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> > > >> > > One problem I have found with this statement is that s must exist before
> > > >> > > the statement is run. Can it be written without using a for
> > > >> > > loop? Would that be better?
> > > >> > >
> > > >> > > Thanks,
> > > >> > > Bob
> > > >> > >
> > > >> > > ______________________________________________
> > > >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> > > and provide commented, minimal, self-contained, reproducible code.
> > > >> >
> > > >> > ______________________________________________
> > > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> > and provide commented, minimal, self-contained, reproducible code.



From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Sun Sep 23 20:36:17 2018
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Sun, 23 Sep 2018 18:36:17 +0000
Subject: [R] For Loop
In-Reply-To: <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>,
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
Message-ID: <CO2PR03MB2232C408FB8829CCB53C17D5E2100@CO2PR03MB2232.namprd03.prod.outlook.com>

At the risk of asking something fundamental . . . .

does log(c1[-1]/c1[-len]

do the following


(1) use all elements of c and perform the calculation

(2) delete the first element of c and perform the calculation,

(2) delete the first two elements of c and perform the calculation,

 . . .

(n) use only the last element of c and perform the calculation.


Thank you,

John



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Wensui Liu <liuwensui at gmail.com>
Sent: Sunday, September 23, 2018 2:26 PM
To: Ista Zahn
Cc: r-help at r-project.org
Subject: Re: [R] For Loop

CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.



what you measures is the "elapsed" time in the default setting. you
might need to take a closer look at the beautiful benchmark() function
and see what time I am talking about.

I just provided tentative solution for the person asking for it  and
believe he has enough wisdom to decide what's best. why bother to
judge others subjectively?
On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>
> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
> >
> > actually, by the parallel pvec, the user time is a lot shorter. or did
> > I somewhere miss your invaluable insight?
> >
> > > c1 <- 1:1000000
> > > len <- length(c1)
> > > rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
> >                   test replications elapsed relative user.self sys.self
> > 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
> >   user.child sys.child
> > 1          0         0
> > > rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
> >                                                                test
> > 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
> >   replications elapsed relative user.self sys.self user.child sys.child
> > 1          100   9.079        1     2.571    4.138      9.736     8.046
>
> Your output is mangled in my email, but on my system your pvec
> approach takes more than twice as long:
>
> c1 <- 1:1000000
> len <- length(c1)
> library(parallel)
> library(rbenchmark)
>
> regular <- function() log(c1[-1]/c1[-len])
> iterate.parallel <- function() {
>   pvec(1:(len - 1), mc.cores = 4,
>        function(i) log(c1[i + 1] / c1[i]))
> }
>
> benchmark(regular(), iterate.parallel(),
>           replications = 100,
>           columns = c("test", "elapsed", "relative"))
> ##                 test elapsed relative
> ## 2 iterate.parallel()   7.517    2.482
> ## 1          regular()   3.028    1.000
>
> Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
> to understand and it runs pretty fast. There is usually no reason to
> make it more complicated.
> --Ista
>
> > On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
> > >
> > > On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
> > > >
> > > > Why?
> > >
> > > The operations required for this algorithm are vectorized, as are most
> > > operations in R. There is no need to iterate through each element.
> > > Using Vectorize to achieve the iteration is no better than using
> > > *apply or a for-loop, and betrays the same basic lack of insight into
> > > basic principles of programming in R.
> > >
> > > And/or, if you want a more practical reason:
> > >
> > > > c1 <- 1:1000000
> > > > len <- 1000000
> > > > system.time( s1 <- log(c1[-1]/c1[-len]))
> > >    user  system elapsed
> > >   0.031   0.004   0.035
> > > > system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > >    user  system elapsed
> > >   1.258   0.022   1.282
> > >
> > > Best,
> > > Ista
> > >
> > > >
> > > > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
> > > >>
> > > >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
> > > >> >
> > > >> > or this one:
> > > >> >
> > > >> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > > >>
> > > >> Oh dear god no.
> > > >>
> > > >> >
> > > >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> > > >> > >
> > > >> > >
> > > >> > > It is my impression that good R programmers make very little use of the
> > > >> > > for statement. Please consider  the following
> > > >> > > R statement:
> > > >> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> > > >> > > One problem I have found with this statement is that s must exist before
> > > >> > > the statement is run. Can it be written without using a for
> > > >> > > loop? Would that be better?
> > > >> > >
> > > >> > > Thanks,
> > > >> > > Bob
> > > >> > >
> > > >> > > ______________________________________________
> > > >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> > > and provide commented, minimal, self-contained, reproducible code.
> > > >> >
> > > >> > ______________________________________________
> > > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> > and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Sep 23 20:48:52 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 23 Sep 2018 14:48:52 -0400
Subject: [R] For Loop
In-Reply-To: <CO2PR03MB2232C408FB8829CCB53C17D5E2100@CO2PR03MB2232.namprd03.prod.outlook.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <CO2PR03MB2232C408FB8829CCB53C17D5E2100@CO2PR03MB2232.namprd03.prod.outlook.com>
Message-ID: <bcbc32e2-bd01-51d0-c2d1-38d08d442f38@gmail.com>

On 23/09/2018 2:36 PM, Sorkin, John wrote:
> At the risk of asking something fundamental . . . .
> 
> does log(c1[-1]/c1[-len]
> 
> do the following
> 
> 
> (1) use all elements of c and perform the calculation
> 
> (2) delete the first element of c and perform the calculation,
> 
> (2) delete the first two elements of c and perform the calculation,
> 
>   . . .
> 
> (n) use only the last element of c and perform the calculation.

c1[-1] creates a new vector which is a copy of c1 leaving out element 1, 
and c1[-len] creates a new vector which copies everything except element 
len.  So your (1) is closest to the truth.

It is very similar to (but probably a little faster than)

log(c1[2:len]/c1[1:(len-1)])

There are differences in borderline cases (like length(c1) != len, or 
len < 2) that are not relevant in the original context.

Duncan Murdoch
> 
> 
> Thank you,
> 
> John
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> 
> ________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Wensui Liu <liuwensui at gmail.com>
> Sent: Sunday, September 23, 2018 2:26 PM
> To: Ista Zahn
> Cc: r-help at r-project.org
> Subject: Re: [R] For Loop
> 
> CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.
> 
> 
> 
> what you measures is the "elapsed" time in the default setting. you
> might need to take a closer look at the beautiful benchmark() function
> and see what time I am talking about.
> 
> I just provided tentative solution for the person asking for it  and
> believe he has enough wisdom to decide what's best. why bother to
> judge others subjectively?
> On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>>
>> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>
>>> actually, by the parallel pvec, the user time is a lot shorter. or did
>>> I somewhere miss your invaluable insight?
>>>
>>>> c1 <- 1:1000000
>>>> len <- length(c1)
>>>> rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
>>>                    test replications elapsed relative user.self sys.self
>>> 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
>>>    user.child sys.child
>>> 1          0         0
>>>> rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
>>>                                                                 test
>>> 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
>>>    replications elapsed relative user.self sys.self user.child sys.child
>>> 1          100   9.079        1     2.571    4.138      9.736     8.046
>>
>> Your output is mangled in my email, but on my system your pvec
>> approach takes more than twice as long:
>>
>> c1 <- 1:1000000
>> len <- length(c1)
>> library(parallel)
>> library(rbenchmark)
>>
>> regular <- function() log(c1[-1]/c1[-len])
>> iterate.parallel <- function() {
>>    pvec(1:(len - 1), mc.cores = 4,
>>         function(i) log(c1[i + 1] / c1[i]))
>> }
>>
>> benchmark(regular(), iterate.parallel(),
>>            replications = 100,
>>            columns = c("test", "elapsed", "relative"))
>> ##                 test elapsed relative
>> ## 2 iterate.parallel()   7.517    2.482
>> ## 1          regular()   3.028    1.000
>>
>> Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
>> to understand and it runs pretty fast. There is usually no reason to
>> make it more complicated.
>> --Ista
>>
>>> On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
>>>>
>>>> On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>
>>>>> Why?
>>>>
>>>> The operations required for this algorithm are vectorized, as are most
>>>> operations in R. There is no need to iterate through each element.
>>>> Using Vectorize to achieve the iteration is no better than using
>>>> *apply or a for-loop, and betrays the same basic lack of insight into
>>>> basic principles of programming in R.
>>>>
>>>> And/or, if you want a more practical reason:
>>>>
>>>>> c1 <- 1:1000000
>>>>> len <- 1000000
>>>>> system.time( s1 <- log(c1[-1]/c1[-len]))
>>>>     user  system elapsed
>>>>    0.031   0.004   0.035
>>>>> system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>     user  system elapsed
>>>>    1.258   0.022   1.282
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>>>
>>>>> On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
>>>>>>
>>>>>> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>>>
>>>>>>> or this one:
>>>>>>>
>>>>>>> (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>>>
>>>>>> Oh dear god no.
>>>>>>
>>>>>>>
>>>>>>> On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>> It is my impression that good R programmers make very little use of the
>>>>>>>> for statement. Please consider  the following
>>>>>>>> R statement:
>>>>>>>>           for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>>>>>>>> One problem I have found with this statement is that s must exist before
>>>>>>>> the statement is run. Can it be written without using a for
>>>>>>>> loop? Would that be better?
>>>>>>>>
>>>>>>>> Thanks,
>>>>>>>> Bob
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep 23 20:58:27 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 23 Sep 2018 11:58:27 -0700 (PDT)
Subject: [R] For Loop
In-Reply-To: <CO2PR03MB2232C408FB8829CCB53C17D5E2100@CO2PR03MB2232.namprd03.prod.outlook.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>,
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <CO2PR03MB2232C408FB8829CCB53C17D5E2100@CO2PR03MB2232.namprd03.prod.outlook.com>
Message-ID: <alpine.BSF.2.00.1809231147110.94794@pedal.dcn.davis.ca.us>

Below...

On Sun, 23 Sep 2018, Sorkin, John wrote:

> At the risk of asking something fundamental . . . .
>
> does log(c1[-1]/c1[-len]

You dropped the closing parenthesis.

log( c1[-1] / c1[-len] )

>
> do the following
>
>
> (1) use all elements of c and perform the calculation

No. a) "c" is the base "concatenate" function, and b) it is using two 
different subsets of the elements in c1.

> (2) delete the first element of c and perform the calculation,

It does not change c1. c1[-1] is an expression that creates an entirely 
new (but unnamed) vector that contains everything but the first element of 
c1.

> (2) delete the first two elements of c and perform the calculation,

You are wandering into the weeds here...

> . . .
>
> (n) use only the last element of c and perform the calculation.

No, c1[-len] creates a temporary array that contains all elements except 
the one(s) in the variable "len".  Note that the more conventional syntax 
here is c1[ length(c1) ].

c1 <- 1:3
c1[ -1 ]
#> [1] 2 3
c1[ -length(c1) ]
#> [1] 1 2
c1[ -1 ] / c1[ -length( c1 ) ] # c(2,3)/c(1,2)
#> [1] 2.0 1.5
log( c1[ -1 ] / c1[ -length( c1 ) ] ) # log( c(2, 1.5) )
#> [1] 0.6931472 0.4054651

#' Created on 2018-09-23 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).

>
>
> Thank you,
>
> John
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
> ________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Wensui Liu <liuwensui at gmail.com>
> Sent: Sunday, September 23, 2018 2:26 PM
> To: Ista Zahn
> Cc: r-help at r-project.org
> Subject: Re: [R] For Loop
>
> CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.
>
>
>
> what you measures is the "elapsed" time in the default setting. you
> might need to take a closer look at the beautiful benchmark() function
> and see what time I am talking about.
>
> I just provided tentative solution for the person asking for it  and
> believe he has enough wisdom to decide what's best. why bother to
> judge others subjectively?
> On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>>
>> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>
>>> actually, by the parallel pvec, the user time is a lot shorter. or did
>>> I somewhere miss your invaluable insight?
>>>
>>>> c1 <- 1:1000000
>>>> len <- length(c1)
>>>> rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
>>>                   test replications elapsed relative user.self sys.self
>>> 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
>>>   user.child sys.child
>>> 1          0         0
>>>> rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
>>>                                                                test
>>> 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
>>>   replications elapsed relative user.self sys.self user.child sys.child
>>> 1          100   9.079        1     2.571    4.138      9.736     8.046
>>
>> Your output is mangled in my email, but on my system your pvec
>> approach takes more than twice as long:
>>
>> c1 <- 1:1000000
>> len <- length(c1)
>> library(parallel)
>> library(rbenchmark)
>>
>> regular <- function() log(c1[-1]/c1[-len])
>> iterate.parallel <- function() {
>>   pvec(1:(len - 1), mc.cores = 4,
>>        function(i) log(c1[i + 1] / c1[i]))
>> }
>>
>> benchmark(regular(), iterate.parallel(),
>>           replications = 100,
>>           columns = c("test", "elapsed", "relative"))
>> ##                 test elapsed relative
>> ## 2 iterate.parallel()   7.517    2.482
>> ## 1          regular()   3.028    1.000
>>
>> Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
>> to understand and it runs pretty fast. There is usually no reason to
>> make it more complicated.
>> --Ista
>>
>>> On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
>>>>
>>>> On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>
>>>>> Why?
>>>>
>>>> The operations required for this algorithm are vectorized, as are most
>>>> operations in R. There is no need to iterate through each element.
>>>> Using Vectorize to achieve the iteration is no better than using
>>>> *apply or a for-loop, and betrays the same basic lack of insight into
>>>> basic principles of programming in R.
>>>>
>>>> And/or, if you want a more practical reason:
>>>>
>>>>> c1 <- 1:1000000
>>>>> len <- 1000000
>>>>> system.time( s1 <- log(c1[-1]/c1[-len]))
>>>>    user  system elapsed
>>>>   0.031   0.004   0.035
>>>>> system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>    user  system elapsed
>>>>   1.258   0.022   1.282
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>>>
>>>>> On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
>>>>>>
>>>>>> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>>>
>>>>>>> or this one:
>>>>>>>
>>>>>>> (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>>>
>>>>>> Oh dear god no.
>>>>>>
>>>>>>>
>>>>>>> On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>> It is my impression that good R programmers make very little use of the
>>>>>>>> for statement. Please consider  the following
>>>>>>>> R statement:
>>>>>>>>          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>>>>>>>> One problem I have found with this statement is that s must exist before
>>>>>>>> the statement is run. Can it be written without using a for
>>>>>>>> loop? Would that be better?
>>>>>>>>
>>>>>>>> Thanks,
>>>>>>>> Bob
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From |@t@z@hn @end|ng |rom gm@||@com  Sun Sep 23 21:13:06 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Sun, 23 Sep 2018 15:13:06 -0400
Subject: [R] For Loop
In-Reply-To: <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
Message-ID: <CA+vqiLF9mb5+Da4kPzm3i4ZhYdc8Dav7WrND3kxhBnj=hQ1HcQ@mail.gmail.com>

On Sun, Sep 23, 2018 at 2:26 PM Wensui Liu <liuwensui at gmail.com> wrote:
>
> what you measures is the "elapsed" time in the default setting. you
> might need to take a closer look at the beautiful benchmark() function
> and see what time I am talking about.

I'm pretty sure you do not know what you are talking about.

>
> I just provided tentative solution for the person asking for it  and
> believe he has enough wisdom to decide what's best. why bother to
> judge others subjectively?

You are giving bad and confused advice. Please stop doing that.

--Ista

> On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
> >
> > On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
> > >
> > > actually, by the parallel pvec, the user time is a lot shorter. or did
> > > I somewhere miss your invaluable insight?
> > >
> > > > c1 <- 1:1000000
> > > > len <- length(c1)
> > > > rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
> > >                   test replications elapsed relative user.self sys.self
> > > 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
> > >   user.child sys.child
> > > 1          0         0
> > > > rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
> > >                                                                test
> > > 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
> > >   replications elapsed relative user.self sys.self user.child sys.child
> > > 1          100   9.079        1     2.571    4.138      9.736     8.046
> >
> > Your output is mangled in my email, but on my system your pvec
> > approach takes more than twice as long:
> >
> > c1 <- 1:1000000
> > len <- length(c1)
> > library(parallel)
> > library(rbenchmark)
> >
> > regular <- function() log(c1[-1]/c1[-len])
> > iterate.parallel <- function() {
> >   pvec(1:(len - 1), mc.cores = 4,
> >        function(i) log(c1[i + 1] / c1[i]))
> > }
> >
> > benchmark(regular(), iterate.parallel(),
> >           replications = 100,
> >           columns = c("test", "elapsed", "relative"))
> > ##                 test elapsed relative
> > ## 2 iterate.parallel()   7.517    2.482
> > ## 1          regular()   3.028    1.000
> >
> > Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
> > to understand and it runs pretty fast. There is usually no reason to
> > make it more complicated.
> > --Ista
> >
> > > On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
> > > >
> > > > On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
> > > > >
> > > > > Why?
> > > >
> > > > The operations required for this algorithm are vectorized, as are most
> > > > operations in R. There is no need to iterate through each element.
> > > > Using Vectorize to achieve the iteration is no better than using
> > > > *apply or a for-loop, and betrays the same basic lack of insight into
> > > > basic principles of programming in R.
> > > >
> > > > And/or, if you want a more practical reason:
> > > >
> > > > > c1 <- 1:1000000
> > > > > len <- 1000000
> > > > > system.time( s1 <- log(c1[-1]/c1[-len]))
> > > >    user  system elapsed
> > > >   0.031   0.004   0.035
> > > > > system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > > >    user  system elapsed
> > > >   1.258   0.022   1.282
> > > >
> > > > Best,
> > > > Ista
> > > >
> > > > >
> > > > > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
> > > > >>
> > > > >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
> > > > >> >
> > > > >> > or this one:
> > > > >> >
> > > > >> > (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
> > > > >>
> > > > >> Oh dear god no.
> > > > >>
> > > > >> >
> > > > >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
> > > > >> > >
> > > > >> > >
> > > > >> > > It is my impression that good R programmers make very little use of the
> > > > >> > > for statement. Please consider  the following
> > > > >> > > R statement:
> > > > >> > >          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
> > > > >> > > One problem I have found with this statement is that s must exist before
> > > > >> > > the statement is run. Can it be written without using a for
> > > > >> > > loop? Would that be better?
> > > > >> > >
> > > > >> > > Thanks,
> > > > >> > > Bob
> > > > >> > >
> > > > >> > > ______________________________________________
> > > > >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > >> > > and provide commented, minimal, self-contained, reproducible code.
> > > > >> >
> > > > >> > ______________________________________________
> > > > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > >> > and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep 23 21:31:50 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 23 Sep 2018 12:31:50 -0700 (PDT)
Subject: [R] For Loop
In-Reply-To: <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>

On Sun, 23 Sep 2018, Wensui Liu wrote:

> what you measures is the "elapsed" time in the default setting. you
> might need to take a closer look at the beautiful benchmark() function
> and see what time I am talking about.

When I am waiting for the answer, elapsed time is what matters to me. 
Also, since each person usually has different hardware, running benchmark 
with multiple expressions as Ista did lets you pay attention to relative 
comparisons.

Keep in mind that parallel processing requires extra time just to 
distribute the calculations to the workers, so it doesn't pay to 
distribute tiny tasks like calculating the division of two numeric vector 
elements. That is the essence of vectorizing... bundle your simple 
calculations together so the processor can focus on getting answers rather 
than managing processes or even interpreting R for loops.

> I just provided tentative solution for the person asking for it  and
> believe he has enough wisdom to decide what's best. why bother to
> judge others subjectively?

I would say that Ista has backed up his objections with measurable 
performance metrics, so while his initial reaction was pretty subjective I 
think your reaction at this point is really off the mark.

One confusing aspect of your response is that Ista reacted to your 
use of the Vectorize function, but you responded as though he reacted 
to your use of the pvec function. I mentioned drawbacks of using pvec 
above, but it really is important to stress that the Vectorize function is 
a usability facade and is in no way a performance enhancement to be 
associated with what we refer to as vectorized (lowercase) code.

The Vectorize function creates a function that calls lapply, which in turn 
calls the C function do_lapply, which calls your R function with scalar 
inputs as many times as desired, storing the results in a list, which 
Vectorize then gives to mapply which runs another for loop over to create 
a matrix or vector result. This is clearly less efficient than a simple 
for loop would have been, rather than more efficient as a true vectorized 
solution such as log(c1[-1]/c1[-len]) will normally be. Vectorize is 
syntactic sugar with a performance penalty.

Please pay attention to the comments offered by others on this list... 
being told your solution is inferior doesn't feel good but it is a very 
real opportunity for you to improve.

End comment.

> On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>>
>> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>
>>> actually, by the parallel pvec, the user time is a lot shorter. or did
>>> I somewhere miss your invaluable insight?
>>>
>>>> c1 <- 1:1000000
>>>> len <- length(c1)
>>>> rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications = 100)
>>>                   test replications elapsed relative user.self sys.self
>>> 1 log(c1[-1]/c1[-len])          100   4.617        1     4.484    0.133
>>>   user.child sys.child
>>> 1          0         0
>>>> rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1] / c1[i])), replications = 100)
>>>                                                                test
>>> 1 pvec(1:(len - 1), mc.cores = 4, function(i) log(c1[i + 1]/c1[i]))
>>>   replications elapsed relative user.self sys.self user.child sys.child
>>> 1          100   9.079        1     2.571    4.138      9.736     8.046
>>
>> Your output is mangled in my email, but on my system your pvec
>> approach takes more than twice as long:
>>
>> c1 <- 1:1000000
>> len <- length(c1)
>> library(parallel)
>> library(rbenchmark)
>>
>> regular <- function() log(c1[-1]/c1[-len])
>> iterate.parallel <- function() {
>>   pvec(1:(len - 1), mc.cores = 4,
>>        function(i) log(c1[i + 1] / c1[i]))
>> }
>>
>> benchmark(regular(), iterate.parallel(),
>>           replications = 100,
>>           columns = c("test", "elapsed", "relative"))
>> ##                 test elapsed relative
>> ## 2 iterate.parallel()   7.517    2.482
>> ## 1          regular()   3.028    1.000
>>
>> Honestly, just use log(c1[-1]/c1[-len]). The code is simple and easy
>> to understand and it runs pretty fast. There is usually no reason to
>> make it more complicated.
>> --Ista
>>
>>> On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:
>>>>
>>>> On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>
>>>>> Why?
>>>>
>>>> The operations required for this algorithm are vectorized, as are most
>>>> operations in R. There is no need to iterate through each element.
>>>> Using Vectorize to achieve the iteration is no better than using
>>>> *apply or a for-loop, and betrays the same basic lack of insight into
>>>> basic principles of programming in R.
>>>>
>>>> And/or, if you want a more practical reason:
>>>>
>>>>> c1 <- 1:1000000
>>>>> len <- 1000000
>>>>> system.time( s1 <- log(c1[-1]/c1[-len]))
>>>>    user  system elapsed
>>>>   0.031   0.004   0.035
>>>>> system.time(s2 <- Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>    user  system elapsed
>>>>   1.258   0.022   1.282
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>>>
>>>>> On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn <istazahn at gmail.com> wrote:
>>>>>>
>>>>>> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu <liuwensui at gmail.com> wrote:
>>>>>>>
>>>>>>> or this one:
>>>>>>>
>>>>>>> (Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len))
>>>>>>
>>>>>> Oh dear god no.
>>>>>>
>>>>>>>
>>>>>>> On Sat, Sep 22, 2018 at 4:16 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>> It is my impression that good R programmers make very little use of the
>>>>>>>> for statement. Please consider  the following
>>>>>>>> R statement:
>>>>>>>>          for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>>>>>>>> One problem I have found with this statement is that s must exist before
>>>>>>>> the statement is run. Can it be written without using a for
>>>>>>>> loop? Would that be better?
>>>>>>>>
>>>>>>>> Thanks,
>>>>>>>> Bob
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Sep 23 21:42:28 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 23 Sep 2018 15:42:28 -0400
Subject: [R] For Loop
In-Reply-To: <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
Message-ID: <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>

On 23/09/2018 3:31 PM, Jeff Newmiller wrote:

[lots of good stuff deleted]

> Vectorize is
> syntactic sugar with a performance penalty.

[More deletions.]

I would say Vectorize isn't just "syntactic sugar".  When I use that 
term, I mean something that looks nice but is functionally equivalent.

However, Vectorize() really does something useful:  some functions (e.g. 
outer()) take other functions as arguments, but they assume the argument 
is a vectorized function.  If it is not, they fail, or generate garbage 
results.  Vectorize() is designed to modify the interface to a function 
so it acts as if it is vectorized.

The "performance penalty" part of your statement is true.  It will 
generally save some computing cycles to write a new function using a for 
loop instead of using Vectorize().  But that may waste some programmer time.

Duncan Murdoch
(writing as one of the authors of Vectorize())

P.S. I'd give an example of syntactic sugar, but I don't want to bruise 
some other author's feelings :-).



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep 23 22:03:42 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 23 Sep 2018 13:03:42 -0700 (PDT)
Subject: [R] For Loop
In-Reply-To: <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
 <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
Message-ID: <alpine.BSF.2.00.1809231250390.94794@pedal.dcn.davis.ca.us>

On Sun, 23 Sep 2018, Duncan Murdoch wrote:

> On 23/09/2018 3:31 PM, Jeff Newmiller wrote:
>
> [lots of good stuff deleted]
>
>> Vectorize is
>> syntactic sugar with a performance penalty.
>
> [More deletions.]
>
> I would say Vectorize isn't just "syntactic sugar".  When I use that term, I 
> mean something that looks nice but is functionally equivalent.
>
> However, Vectorize() really does something useful:  some functions (e.g. 
> outer()) take other functions as arguments, but they assume the argument is a 
> vectorized function.  If it is not, they fail, or generate garbage results. 
> Vectorize() is designed to modify the interface to a function so it acts as 
> if it is vectorized.
>
> The "performance penalty" part of your statement is true.  It will generally 
> save some computing cycles to write a new function using a for loop instead 
> of using Vectorize().  But that may waste some programmer time.
>
> Duncan Murdoch
> (writing as one of the authors of Vectorize())
>
> P.S. I'd give an example of syntactic sugar, but I don't want to bruise some 
> other author's feelings :-).

Perhaps my writing needs some syntactic sugar: inefficient looping 
algorithms can make sense when the calculations performed in each 
iteration are long and/or involve large amounts of data. As I mentioned 
earlier in this thread I use for loops fairly often, and I use other 
inefficient syntactic sugar as well but only to organize large 
blocks of already-vectorized (lowercase) calculation units.

In addition to the potential for inefficient use of programmer time, 
vectorizing code increases the maximum amount of memory used during 
execution of your program. A for loop is one simple way to allow memory 
re-use so really large problems can be solved with limited resources, and 
some syntactic sugar such as Vectorize can make it easier to keep track of 
those for loops.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From ||uwen@u| @end|ng |rom gm@||@com  Sun Sep 23 22:00:09 2018
From: ||uwen@u| @end|ng |rom gm@||@com (Wensui Liu)
Date: Sun, 23 Sep 2018 15:00:09 -0500
Subject: [R] For Loop
In-Reply-To: <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
 <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
Message-ID: <CAKyN3iD_nq-TeZWVxwWtFnRp00jTNxESg0arW8v4+VJi72t4mw@mail.gmail.com>

Very insightful. Thanks, Duncan

Based on your opinion, is there any benefit to use the parallelism in the
corporate computing environment where the size of data is far more than
million rows and there are multiple cores in the server.

Actually the practice of going concurrency or not is more related to my
production tasks instead of something academic.

Really appreciate your thoughts.

On Sun, Sep 23, 2018 at 2:42 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 23/09/2018 3:31 PM, Jeff Newmiller wrote:
>
> [lots of good stuff deleted]
>
> > Vectorize is
> > syntactic sugar with a performance penalty.
>
> [More deletions.]
>
> I would say Vectorize isn't just "syntactic sugar".  When I use that
> term, I mean something that looks nice but is functionally equivalent.
>
> However, Vectorize() really does something useful:  some functions (e.g.
> outer()) take other functions as arguments, but they assume the argument
> is a vectorized function.  If it is not, they fail, or generate garbage
> results.  Vectorize() is designed to modify the interface to a function
> so it acts as if it is vectorized.
>
> The "performance penalty" part of your statement is true.  It will
> generally save some computing cycles to write a new function using a for
> loop instead of using Vectorize().  But that may waste some programmer
> time.
>
> Duncan Murdoch
> (writing as one of the authors of Vectorize())
>
> P.S. I'd give an example of syntactic sugar, but I don't want to bruise
> some other author's feelings :-).
>

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Sep 23 22:10:57 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 23 Sep 2018 16:10:57 -0400
Subject: [R] For Loop
In-Reply-To: <CAKyN3iD_nq-TeZWVxwWtFnRp00jTNxESg0arW8v4+VJi72t4mw@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
 <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
 <CAKyN3iD_nq-TeZWVxwWtFnRp00jTNxESg0arW8v4+VJi72t4mw@mail.gmail.com>
Message-ID: <54fed059-9e92-304f-a7e6-4a8518f3a7a7@gmail.com>

On 23/09/2018 4:00 PM, Wensui Liu wrote:
> Very insightful. Thanks, Duncan
> 
> Based on your opinion, is there any benefit to use the parallelism in 
> the corporate computing environment where the size of data is far more 
> than million rows and there are multiple cores in the server.

I would say "try it and see".  Sometimes it probably helps a lot, 
sometimes it's probably detrimental.

Duncan Murdoch

P.S. I last worked in a corporate computing environment 40 years ago 
when I was still wet behind the ears, so you'd probably want to ask 
someone else.  However, more recently I worked in an academic 
environment where I learned to say "try it and see" in many different 
ways.  You just got the basic one today.


> 
> Actually the practice of going concurrency or not is more related to my 
> production tasks instead of something academic.
> 
> Really appreciate your thoughts.
> 
> On Sun, Sep 23, 2018 at 2:42 PM Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 23/09/2018 3:31 PM, Jeff Newmiller wrote:
> 
>     [lots of good stuff deleted]
> 
>      > Vectorize is
>      > syntactic sugar with a performance penalty.
> 
>     [More deletions.]
> 
>     I would say Vectorize isn't just "syntactic sugar".? When I use that
>     term, I mean something that looks nice but is functionally equivalent.
> 
>     However, Vectorize() really does something useful:? some functions
>     (e.g.
>     outer()) take other functions as arguments, but they assume the
>     argument
>     is a vectorized function.? If it is not, they fail, or generate garbage
>     results.? Vectorize() is designed to modify the interface to a function
>     so it acts as if it is vectorized.
> 
>     The "performance penalty" part of your statement is true.? It will
>     generally save some computing cycles to write a new function using a
>     for
>     loop instead of using Vectorize().? But that may waste some
>     programmer time.
> 
>     Duncan Murdoch
>     (writing as one of the authors of Vectorize())
> 
>     P.S. I'd give an example of syntactic sugar, but I don't want to bruise
>     some other author's feelings :-).
>



From e@@w|ek @end|ng |rom gm@||@com  Sun Sep 23 23:06:17 2018
From: e@@w|ek @end|ng |rom gm@||@com (Ek Esawi)
Date: Sun, 23 Sep 2018 17:06:17 -0400
Subject: [R] error "The system cannot find the file specified..."
In-Reply-To: <efc0ee37-e464-3ec3-ba7d-c60575c3e192@sapo.pt>
References: <CA+ZkTxuJSPgPL-QWjGOXLP7eRP2HW0DZR7MA4Jc6-VBF0oqbpw@mail.gmail.com>
 <CAGxFJbRTKwLayx+NkhPvCZyXBTbYNQ85yjO48wmB9kYXZ+G1mA@mail.gmail.com>
 <efc0ee37-e464-3ec3-ba7d-c60575c3e192@sapo.pt>
Message-ID: <CA+ZkTxs++gXPLzHnyeOOq9wG1xhWauhwpm90EpFBdpuqXgu7Hw@mail.gmail.com>

Thank you Bert and Rui. Everything mentioned on your posts was OK with
the exception of a typo in my original post where [a] was instead
[[a]]. I stumbled one something that stated if i delete the
sub-directory and create it it again might work. In my case once that
was done, it worked.

Thanks again,
EK
On Sun, Sep 23, 2018 at 5:30 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> I would add that it's probably better to assign
>
> for(i in seq_along(file.names)){
>    A[[i]] <- extract_tables(file.names[i])
> }
>
>
> (It's a list so double [[, not just [).
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 01:45 de 23/09/2018, Bert Gunter escreveu:
> > for(i in 1:length(file.names)){
> >    A[i] <- extract_tables(file.names[i])}



From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep 23 23:08:59 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 23 Sep 2018 14:08:59 -0700
Subject: [R] For Loop
In-Reply-To: <54fed059-9e92-304f-a7e6-4a8518f3a7a7@gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
 <alpine.BSF.2.00.1809231159590.94794@pedal.dcn.davis.ca.us>
 <2ec29ee4-1ce4-009b-b17d-1fb50c5883a8@gmail.com>
 <CAKyN3iD_nq-TeZWVxwWtFnRp00jTNxESg0arW8v4+VJi72t4mw@mail.gmail.com>
 <54fed059-9e92-304f-a7e6-4a8518f3a7a7@gmail.com>
Message-ID: <CAGxFJbQp3PMvTKV5MFpM-6xWPHE9jXk5CggLzmYXRN7VaSQF1g@mail.gmail.com>

"... I learned to say "try it and see" in many different ways. "

Version 2: *Never* parallelize your computations  .... except when you
should.

;-)

-- Bert



On Sun, Sep 23, 2018 at 1:20 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 23/09/2018 4:00 PM, Wensui Liu wrote:
> > Very insightful. Thanks, Duncan
> >
> > Based on your opinion, is there any benefit to use the parallelism in
> > the corporate computing environment where the size of data is far more
> > than million rows and there are multiple cores in the server.
>
> I would say "try it and see".  Sometimes it probably helps a lot,
> sometimes it's probably detrimental.
>
> Duncan Murdoch
>
> P.S. I last worked in a corporate computing environment 40 years ago
> when I was still wet behind the ears, so you'd probably want to ask
> someone else.  However, more recently I worked in an academic
> environment where I learned to say "try it and see" in many different
> ways.  You just got the basic one today.
>
>
> >
> > Actually the practice of going concurrency or not is more related to my
> > production tasks instead of something academic.
> >
> > Really appreciate your thoughts.
> >
> > On Sun, Sep 23, 2018 at 2:42 PM Duncan Murdoch <murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com>> wrote:
> >
> >     On 23/09/2018 3:31 PM, Jeff Newmiller wrote:
> >
> >     [lots of good stuff deleted]
> >
> >      > Vectorize is
> >      > syntactic sugar with a performance penalty.
> >
> >     [More deletions.]
> >
> >     I would say Vectorize isn't just "syntactic sugar".  When I use that
> >     term, I mean something that looks nice but is functionally
> equivalent.
> >
> >     However, Vectorize() really does something useful:  some functions
> >     (e.g.
> >     outer()) take other functions as arguments, but they assume the
> >     argument
> >     is a vectorized function.  If it is not, they fail, or generate
> garbage
> >     results.  Vectorize() is designed to modify the interface to a
> function
> >     so it acts as if it is vectorized.
> >
> >     The "performance penalty" part of your statement is true.  It will
> >     generally save some computing cycles to write a new function using a
> >     for
> >     loop instead of using Vectorize().  But that may waste some
> >     programmer time.
> >
> >     Duncan Murdoch
> >     (writing as one of the authors of Vectorize())
> >
> >     P.S. I'd give an example of syntactic sugar, but I don't want to
> bruise
> >     some other author's feelings :-).
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Mon Sep 24 00:18:07 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Sun, 23 Sep 2018 17:18:07 -0500
Subject: [R] Consequent  sorting
Message-ID: <000001d4538b$4ebbb130$ec331390$@sbcglobal.net>

r-help Forum

 

I'm using the following code to sort the "right-hand side (rhs, consequent)
of the rules output from the arules packages, which works.  But what I'd
really like is the ability to subset my rules where the rhs = "some item
set"

 

rules_info <-

  data.frame(

    LHS = labels(lhs(rules)), 

    RHS = labels(rhs(rules)),          

    quality(rules)

  )

 

rules_info[ order(rules_info$RHS=), ]

 

For example using my code above I'm able to sort as follow's

 

179  {Cereals,Eggs,Tomatoes,Vinegar}    {Bread} 0.1428571  1.0000000
1.1666667     1

184           {Eggs,Milk,Pork,Sugar}    {Bread} 0.1428571  1.0000000
1.1666667     1

189        {Eggs,Milk,Pork,Tomatoes}    {Bread} 0.1428571  1.0000000
1.1666667     1

1                                 {}  {Cereals} 0.2857143  0.2857143
1.0000000     2

8                          {Vinegar}  {Cereals} 0.1428571  1.0000000
3.5000000     1

15                        {Tomatoes}  {Cereals} 0.1428571  0.5000000
1.7500000     1

17                            {Eggs}  {Cereals} 0.2857143  0.3333333
1.1666667     2

 

But what I'd really like to do is just get (say) {Bread} like .

 

                                 LHS        RHS   support confidence
lift count

179  {Cereals,Eggs,Tomatoes,Vinegar}    {Bread} 0.1428571  1.0000000
1.1666667     1

184           {Eggs,Milk,Pork,Sugar}    {Bread} 0.1428571  1.0000000
1.1666667     1

189        {Eggs,Milk,Pork,Tomatoes}    {Bread} 0.1428571  1.0000000
1.1666667     1

 

Jeff Reichman

 


	[[alternative HTML version deleted]]



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Mon Sep 24 01:29:20 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Sun, 23 Sep 2018 18:29:20 -0500
Subject: [R] Consequent  sorting
In-Reply-To: <000001d4538b$4ebbb130$ec331390$@sbcglobal.net>
References: <000001d4538b$4ebbb130$ec331390$@sbcglobal.net>
Message-ID: <000501d45395$41ff7440$c5fe5cc0$@sbcglobal.net>

Never mind.  Working with the arules package notes I was able to figure it
out

rules <- apriori(fp.trans,
                 parameter = list(supp = 0.1, conf = 0.2, target = "rules"),
                 appearance = list(rhs="Sugar", default="lhs"),
                 control = list(verbose=F))
rules.sorted <- sort(rules, by="lift")
inspect(rules.sorted)

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Reichman
Sent: Sunday, September 23, 2018 5:18 PM
To: r-help at r-project.org
Subject: [R] Consequent sorting

r-help Forum

 I'm using the following code to sort the "right-hand side (rhs, consequent)
of the rules output from the arules packages, which works.  But what I'd
really like is the ability to subset my rules where the rhs = "some item
set"


rules_info <-
  data.frame(
    LHS = labels(lhs(rules)), 
    RHS = labels(rhs(rules)),          
    quality(rules)
  )

rules_info[ order(rules_info$RHS=), ]

For example using my code above I'm able to sort as follow's

179  {Cereals,Eggs,Tomatoes,Vinegar}   	{Bread} 0.1428571  1.0000000
1.1666667     1
184           {Eggs,Milk,Pork,Sugar}   	{Bread} 0.1428571  1.0000000
1.1666667     1
189        {Eggs,Milk,Pork,Tomatoes}    	{Bread} 0.1428571  1.0000000
1.1666667     1
1                                 {}  			{Cereals} 0.2857143
0.2857143 1.0000000     2
8                          {Vinegar}  		{Cereals} 0.1428571
1.0000000 3.5000000     1
15                        {Tomatoes} 		{Cereals} 0.1428571
0.5000000 1.7500000     1

But what I'd really like to do is just get (say) {Bread} like .

179  {Cereals,Eggs,Tomatoes,Vinegar}    {Bread} 0.1428571  1.0000000
1.1666667     1
184           {Eggs,Milk,Pork,Sugar}    {Bread} 0.1428571  1.0000000
1.1666667     1
189        {Eggs,Milk,Pork,Tomatoes}    {Bread} 0.1428571  1.0000000
1.1666667     1


Jeff Reichman


______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To
UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From ph@edru@v @end|ng |rom gm@||@com  Mon Sep 24 15:18:16 2018
From: ph@edru@v @end|ng |rom gm@||@com (Andrew)
Date: Mon, 24 Sep 2018 14:18:16 +0100
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <4d2400ea-28ef-875a-064e-79a0bd7325ac@yorku.ca>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>
 <c226c952-b8f3-3c1a-6c62-5d19530afce6@gmail.com>
 <4d2400ea-28ef-875a-064e-79a0bd7325ac@yorku.ca>
Message-ID: <ce6d102d-0ac0-853c-2741-e08a6214381c@gmail.com>

Ha! Even better - thank you. Plenty here for me to play around with.

Many thanks
Andrew


On 23/09/18 15:22, Michael Friendly wrote:
> On 9/22/2018 6:49 AM, Andrew wrote:
>> Hi Michael
>>
>> This looks like it could be really helpful in moving my project 
>> forwards thank you.
>>
>> I remember many years ago using (proprietary) software from the 
>> University of Liverpool which did a nice job of allowing regions to 
>> be defined, and then for the space to be rotated to obtain visual 
>> inspection of relative distance from different angles. I appreciate 
>> that smacof will not do that, but as long as the analysis allows for 
>> the graph to be plotted and analysed, that's what's important.
>
> You need not rely on the plots provided directly by a given package.
> Just roll your own using standard plotting libraries.
> Here is just the first Google hit on "R MDS 3D plot"
>
> http://omnilogia.blogspot.com/2014/05/basic-2d-3d-multi-dimensional-scaling.html 
>
>
> which shows a rotating 3D plot, colored by a grouping variable. Here 
> is another:
>
> http://whatzcookinlab.blogspot.com/2013/05/spinning-3d-mds-plot.html
>
> The vegan and ade4 packages also have a variety of plots and related 
> methods.
>
>
> -Michael
>
>>
>> Thank you again, and to all of those who responded.
>>
>> Best wishes
>> Andrew
>>
>>
>> On 21/09/18 14:07, Michael Friendly wrote:
>>> Smallest space analysis (SSA) is just the name given to software 
>>> developed by Guttman & Lingoes around the time the various versions
>>> of multidimensional scaling were being developed.? Call it Israeli MDS
>>> or Falafel MDS if you prefer. The reason you encountered it in your
>>> course is presumably that the instructor was trained in that.
>>>
>>> There are several variants of MDS-like algorithms for embedding
>>> points representing objects in a space, using data representing
>>> similarities or distances among objects -- metric (cmdscale)
>>> and non-metric (MASS::isoMDS), using only rank order information, 
>>> and a variety of
>>> measures of goodness-of-fit ("stress").? I don't recall the details
>>> of the SSA programs, but that should matter little conceptually.
>>>
>>> The smacof package offers the widest array of possibilities.
>>>
>>> -Michael
>>>
>>>
>>> On 9/19/2018 7:00 AM, Andrew wrote:
>>>> Hi
>>>>
>>>> As part of my forensics psych course, we have been introduced to
>>>> Guttman's smallest space analysis (SSA). I want to explore this 
>>>> approach
>>>> using R, but despite finding some queries on the web about this same
>>>> thing, have yet to find any answers. The MASS package doesn't seem 
>>>> to do
>>>> the job, and the only thing I have been able to find is some 
>>>> proprietary
>>>> software HUDAP? (Hebrew University Data Analysis Package) which 
>>>> may/ not
>>>> be compatible with R (or GNU/Linux for that matter).
>>>>
>>>> Does anyone have information on how to do SSA using R?
>>>>
>>>> Many thanks
>>>>
>>>> Andrew
>>>>
>>>>
>>>> ????[[alternative HTML version deleted]]
>>>>
>>>
>>>
>>
>
>



From jo@ec|@ud|o@|@r|@ @end|ng |rom gm@||@com  Mon Sep 24 16:32:19 2018
From: jo@ec|@ud|o@|@r|@ @end|ng |rom gm@||@com (Jose Claudio Faria)
Date: Mon, 24 Sep 2018 11:32:19 -0300
Subject: [R] cut{base}: is it a bug?
Message-ID: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>

Dears members,

Is the below a bug of the cut {base} function?

dat <- c(
 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
 )

# making class from function "cut"
(f <- cut(dat,
          breaks= seq(from=.6, to=2.2, by=.2),
          include.lowest=TRUE,
          dig.lab=10L,
          right=FALSE))

# more easy to see the table
as.matrix(tb <- table(f))

# Checking
print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]

Best,
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
55(73)98817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms;
if you have good software, you have arms and legs;
if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

	[[alternative HTML version deleted]]



From dc@r|@on @end|ng |rom t@mu@edu  Mon Sep 24 17:14:09 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Mon, 24 Sep 2018 15:14:09 +0000
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
Message-ID: <a73f82dbede144399b2376a1b5e27f44@tamu.edu>

You've been bitten by FAQ 7.31: Why doesn't R think these numbers are equal?
https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

Your boundaries and your data values are not what you think they are. This is a limitation of digital computing not R.

> print(seq(from=.6, to=2.2, by=.2), digits=17)
[1] 0.59999999999999998 0.80000000000000004 1.00000000000000000 1.20000000000000018
[5] 1.39999999999999991 1.60000000000000009 1.80000000000000027 2.00000000000000000
[9] 2.20000000000000018

> print(dat, digits=17)
 [1] 0.59999999999999998 0.59999999999999998 0.59999999999999998 0.69999999999999996
 [5] 0.69999999999999996 0.69999999999999996 0.69999999999999996 0.69999999999999996
 [9] 0.80000000000000004 0.80000000000000004 0.80000000000000004 0.90000000000000002
[13] 0.90000000000000002 0.90000000000000002 0.90000000000000002 1.00000000000000000
[17] 1.00000000000000000 1.00000000000000000 1.00000000000000000 1.10000000000000009
[21] 1.10000000000000009 1.10000000000000009 1.19999999999999996 1.19999999999999996
[25] 1.19999999999999996 1.19999999999999996 1.30000000000000004 1.30000000000000004
[29] 1.30000000000000004 1.39999999999999991 1.39999999999999991 1.39999999999999991
[33] 1.50000000000000000 1.50000000000000000 1.50000000000000000 1.60000000000000009
[37] 1.60000000000000009 1.69999999999999996 1.69999999999999996 1.69999999999999996
[41] 1.69999999999999996 1.80000000000000004 1.80000000000000004 1.80000000000000004
[45] 1.89999999999999991 1.89999999999999991 2.00000000000000000 2.00000000000000000
[49] 2.00000000000000000 2.00000000000000000 2.00000000000000000 2.10000000000000009

The simplest solution is to subtract a bit. This also means you don't need the include.lowest= or right= arguments:

> f <- cut(dat,
+           breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
+           dig.lab=10L)
> as.matrix(tb <- table(f))
            [,1]
[0.59,0.79)    8
[0.79,0.99)    7
[0.99,1.19)    7
[1.19,1.39)    7
[1.39,1.59)    6
[1.59,1.79)    6
[1.79,1.99)    5
[1.99,2.19]    6

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jose Claudio Faria
Sent: Monday, September 24, 2018 9:32 AM
To: r-help at r-project.org
Subject: [R] cut{base}: is it a bug?

Dears members,

Is the below a bug of the cut {base} function?

dat <- c(
 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
 )

# making class from function "cut"
(f <- cut(dat,
          breaks= seq(from=.6, to=2.2, by=.2),
          include.lowest=TRUE,
          dig.lab=10L,
          right=FALSE))

# more easy to see the table
as.matrix(tb <- table(f))

# Checking
print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1] print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2] print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5] print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]

Best,
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
55(73)98817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms; if you have good software, you have arms and legs; if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep 24 17:40:32 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 24 Sep 2018 08:40:32 -0700
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
 <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
Message-ID: <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>

"Subtracting a bit" only fixes the problem for the test data... it introduces a bias in any continuous data you happen to throw at it. However, if you have data with known rounding applied (e.g. published tabular data) then the subtracting trick can be useful. In general you should not expect floating point fractions to behave like exact values in your analysis.

On September 24, 2018 8:14:09 AM PDT, David L Carlson <dcarlson at tamu.edu> wrote:
>You've been bitten by FAQ 7.31: Why doesn't R think these numbers are
>equal?
>https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>
>Your boundaries and your data values are not what you think they are.
>This is a limitation of digital computing not R.
>
>> print(seq(from=.6, to=2.2, by=.2), digits=17)
>[1] 0.59999999999999998 0.80000000000000004 1.00000000000000000
>1.20000000000000018
>[5] 1.39999999999999991 1.60000000000000009 1.80000000000000027
>2.00000000000000000
>[9] 2.20000000000000018
>
>> print(dat, digits=17)
>[1] 0.59999999999999998 0.59999999999999998 0.59999999999999998
>0.69999999999999996
>[5] 0.69999999999999996 0.69999999999999996 0.69999999999999996
>0.69999999999999996
>[9] 0.80000000000000004 0.80000000000000004 0.80000000000000004
>0.90000000000000002
>[13] 0.90000000000000002 0.90000000000000002 0.90000000000000002
>1.00000000000000000
>[17] 1.00000000000000000 1.00000000000000000 1.00000000000000000
>1.10000000000000009
>[21] 1.10000000000000009 1.10000000000000009 1.19999999999999996
>1.19999999999999996
>[25] 1.19999999999999996 1.19999999999999996 1.30000000000000004
>1.30000000000000004
>[29] 1.30000000000000004 1.39999999999999991 1.39999999999999991
>1.39999999999999991
>[33] 1.50000000000000000 1.50000000000000000 1.50000000000000000
>1.60000000000000009
>[37] 1.60000000000000009 1.69999999999999996 1.69999999999999996
>1.69999999999999996
>[41] 1.69999999999999996 1.80000000000000004 1.80000000000000004
>1.80000000000000004
>[45] 1.89999999999999991 1.89999999999999991 2.00000000000000000
>2.00000000000000000
>[49] 2.00000000000000000 2.00000000000000000 2.00000000000000000
>2.10000000000000009
>
>The simplest solution is to subtract a bit. This also means you don't
>need the include.lowest= or right= arguments:
>
>> f <- cut(dat,
>+           breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
>+           dig.lab=10L)
>> as.matrix(tb <- table(f))
>            [,1]
>[0.59,0.79)    8
>[0.79,0.99)    7
>[0.99,1.19)    7
>[1.19,1.39)    7
>[1.39,1.59)    6
>[1.59,1.79)    6
>[1.79,1.99)    5
>[1.99,2.19]    6
>
>----------------------------------------
>David L Carlson
>Department of Anthropology
>Texas A&M University
>College Station, TX 77843-4352
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Jose Claudio
>Faria
>Sent: Monday, September 24, 2018 9:32 AM
>To: r-help at r-project.org
>Subject: [R] cut{base}: is it a bug?
>
>Dears members,
>
>Is the below a bug of the cut {base} function?
>
>dat <- c(
> 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
> 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
> 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
> 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
> 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
> 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
> 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
> 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
> )
>
># making class from function "cut"
>(f <- cut(dat,
>          breaks= seq(from=.6, to=2.2, by=.2),
>          include.lowest=TRUE,
>          dig.lab=10L,
>          right=FALSE))
>
># more easy to see the table
>as.matrix(tb <- table(f))
>
># Checking
>print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
>print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
>print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
>print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
>print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
>print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
>print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
>print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]
>
>Best,
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>Jose Claudio Faria
>UESC/DCET/Brasil
>joseclaudio.faria at gmail.com
>Telefones:
>55(73)3680.5545 - UESC
>55(73)99966.9100 - VIVO
>55(73)98817.6159 - OI
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>
>If you have software to deal with statistics, you have arms; if you
>have good software, you have arms and legs; if you have software like
>R, you have arms, legs and wings...
>the height of your flight depends only on you!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From m@cqueen1 @end|ng |rom ||n|@gov  Mon Sep 24 18:13:43 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 24 Sep 2018 16:13:43 +0000
Subject: [R] For Loop
In-Reply-To: <5BA6B12B.3090606@comcast.net>
References: <5BA6B12B.3090606@comcast.net>
Message-ID: <15902D1C-2E14-439A-9D24-0E64E1AD6902@llnl.gov>

In my opinion this is a pretty reasonable question for someone new to R.

Yes, it can be written without a for loop, and it would be better. Rich Heiberger gave a good solution early on, but I'd like to add an outline of the reasoning that leads to the solution.

You are taking the log of a ratio, and in the ratio, the numerator uses elements 2 through len, and the denominator uses elements 1 through (len-1). So, just write it that way:

   c1[2:len]/c1[1:(len-1)]

or, taking advantage of using negative numbers when indexing vectors,

   c1[-1]/c1[-len]

then take the log

   s <- log( c1[-1]/c1[-len] )

Comparing this with the loop version makes an example of why people say the R language is vectorized.

Do good R programmers make very little use of the for statement? Since R is vectorized, the for statement is necessary less often than in  non-vectorized languages. But "very little use" would be too broad a generalization. It will depend on what problems are being solved.

Finally, if using the loop in this case, it's true that s must exist before the statement is run. But that's not much of a problem. Just put
  s <- numeric( len-1)
before the loop.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/22/18, 2:16 PM, "R-help on behalf of rsherry8" <r-help-bounces at r-project.org on behalf of rsherry8 at comcast.net> wrote:

    
    It is my impression that good R programmers make very little use of the 
    for statement. Please consider  the following
    R statement:
             for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
    One problem I have found with this statement is that s must exist before 
    the statement is run. Can it be written without using a for
    loop? Would that be better?
    
    Thanks,
    Bob
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From pro|jcn@@h @end|ng |rom gm@||@com  Mon Sep 24 18:36:07 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Mon, 24 Sep 2018 12:36:07 -0400
Subject: [R] For Loop
In-Reply-To: <15902D1C-2E14-439A-9D24-0E64E1AD6902@llnl.gov>
References: <5BA6B12B.3090606@comcast.net>
 <15902D1C-2E14-439A-9D24-0E64E1AD6902@llnl.gov>
Message-ID: <30e2d3ae-a489-ef37-38ec-69f1071882c4@gmail.com>

One issue I haven't seen mentioned (and apologize if I've missed it) is that
of making programs readable for long-term use. In the histoRicalg project to
try to document and test some of the codes from long ago that are the underpinnings
of some important R computations, things like the negative index approach require
what we might term "local knowledge" i.e., to R. In such cases the old fashioned
for loop is easier for humans to understand.

The i:j form is a bit easier.

Compromise is to comment, and if your code is EVER to be used later, especially
by non-R users, it is a good idea to do so.

i.e.,

 c1[-1] # does loop from 2 to end of vector

John Nash

histoRicalg links, to which all welcome:
https://gitlab.com/nashjc/histoRicalg
https://gitlab.com/nashjc/histoRicalg/wikis/home
https://lists.r-consortium.org/g/rconsortium-project-histoRicalg

On 2018-09-24 12:13 PM, MacQueen, Don via R-help wrote:
> In my opinion this is a pretty reasonable question for someone new to R.
> 
> Yes, it can be written without a for loop, and it would be better. Rich Heiberger gave a good solution early on, but I'd like to add an outline of the reasoning that leads to the solution.
> 
> You are taking the log of a ratio, and in the ratio, the numerator uses elements 2 through len, and the denominator uses elements 1 through (len-1). So, just write it that way:
> 
>    c1[2:len]/c1[1:(len-1)]
> 
> or, taking advantage of using negative numbers when indexing vectors,
> 
>    c1[-1]/c1[-len]
> 
> then take the log
> 
>    s <- log( c1[-1]/c1[-len] )
> 
> Comparing this with the loop version makes an example of why people say the R language is vectorized.
> 
> Do good R programmers make very little use of the for statement? Since R is vectorized, the for statement is necessary less often than in  non-vectorized languages. But "very little use" would be too broad a generalization. It will depend on what problems are being solved.
> 
> Finally, if using the loop in this case, it's true that s must exist before the statement is run. But that's not much of a problem. Just put
>   s <- numeric( len-1)
> before the loop.
> 
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>  
>  
> 
> ?On 9/22/18, 2:16 PM, "R-help on behalf of rsherry8" <r-help-bounces at r-project.org on behalf of rsherry8 at comcast.net> wrote:
> 
>     
>     It is my impression that good R programmers make very little use of the 
>     for statement. Please consider  the following
>     R statement:
>              for( i in 1:(len-1) )  s[i] = log(c1[i+1]/c1[i], base = exp(1) )
>     One problem I have found with this statement is that s must exist before 
>     the statement is run. Can it be written without using a for
>     loop? Would that be better?
>     
>     Thanks,
>     Bob
>     
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>     
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From tmg1970 @end|ng |rom gm@||@com  Mon Sep 24 19:37:12 2018
From: tmg1970 @end|ng |rom gm@||@com (Tania Morgado Garcia)
Date: Mon, 24 Sep 2018 12:37:12 -0500
Subject: [R] About uniroot error
Message-ID: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>

Thanks for your answers. I continue to learn R and now I am detained in an
error with uniroot that I see happens to others but I can not find the
solution. Next the code

x1 <- BAaxOrd$V1
y1 <- BAaxOrd$V2
x1R <- BAaxOrdRCOS$V1
y1R <- BAaxOrdRCOS$V2
FCOS1 <- splinefun(smooth.spline(x1,y1))
FRCOS1 <- splinefun(smooth.spline(x1R,y1R))
FCOS1 <- Vectorize(FCOS1)
FRCOS1 <- Vectorize(FRCOS1)

req(input$file1)
      tryCatch(
      {
        df <- read.csv(input$file1$datapath,
                       header = input$header,
                       sep = "\t",
                       quote = '"')
      },
      error = function(e) {
        # return a safeError if a parsing error occurs
        stop(safeError(e))
      }
    )

    #if(input$disp == "head") {
     # return(head(df))
    #}
    #else {

      # Determine Carbon Reserve
      for (row in 1:nrow(df)) {
        if(df$ts==1) {
           prof <-
uniroot(f=function(x){FCOS1(x1)-df$carbono},interval=c(0,20))$root
           limsup <- prof + df$pu
           reserva <- integrate(FRCOS1,prof,limsup)$value
        }

The if is because there are several types of soil, but I only put one.  The
error is

Warning in if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
  the condition has length > 1 and only the first element will be used
Warning in if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
  the condition has length > 1 and only the first element will be used
Warning: Error in uniroot: f() values at end points not of opposite sign

The file that I load with data has a single row with the values ts = 1,
carbon = 2.04 and pu = 15 (I left only that row to be able to determine the
origin of the error). The functions FCOS1 and FRCOS1 are monotone
decreasing.Graphic attachment of FCOS1

I would appreciate some help in this regard

thanks a lot


From dc@r|@on @end|ng |rom t@mu@edu  Mon Sep 24 19:42:52 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Mon, 24 Sep 2018 17:42:52 +0000
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
 <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
 <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>
Message-ID: <c266d1a09f8742ee900ee491e8c74977@tamu.edu>

Yes, I should have included that point. The cut() function "encourages" exact comparison of values by including the right= argument without a warning that this may create unexpected results. With truly continuous data, values falling exactly on the boundary would be rare. 

Most data arrives from instruments that measure to limited precision. Introductory statistics texts deal with this by distinguishing between "true" and "stated" class limits. Or, like Lyman Ott, recommend choosing the starting point interval such that "no measurement falls on a point of division between two intervals."

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Monday, September 24, 2018 10:41 AM
To: r-help at r-project.org; David L Carlson <dcarlson at tamu.edu>; Jose Claudio Faria <joseclaudio.faria at gmail.com>; r-help at r-project.org
Subject: Re: [R] cut{base}: is it a bug?

"Subtracting a bit" only fixes the problem for the test data... it introduces a bias in any continuous data you happen to throw at it. However, if you have data with known rounding applied (e.g. published tabular data) then the subtracting trick can be useful. In general you should not expect floating point fractions to behave like exact values in your analysis.

On September 24, 2018 8:14:09 AM PDT, David L Carlson <dcarlson at tamu.edu> wrote:
>You've been bitten by FAQ 7.31: Why doesn't R think these numbers are
>equal?
>https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>
>Your boundaries and your data values are not what you think they are.
>This is a limitation of digital computing not R.
>
>> print(seq(from=.6, to=2.2, by=.2), digits=17)
>[1] 0.59999999999999998 0.80000000000000004 1.00000000000000000
>1.20000000000000018
>[5] 1.39999999999999991 1.60000000000000009 1.80000000000000027
>2.00000000000000000
>[9] 2.20000000000000018
>
>> print(dat, digits=17)
>[1] 0.59999999999999998 0.59999999999999998 0.59999999999999998
>0.69999999999999996
>[5] 0.69999999999999996 0.69999999999999996 0.69999999999999996
>0.69999999999999996
>[9] 0.80000000000000004 0.80000000000000004 0.80000000000000004
>0.90000000000000002
>[13] 0.90000000000000002 0.90000000000000002 0.90000000000000002
>1.00000000000000000
>[17] 1.00000000000000000 1.00000000000000000 1.00000000000000000
>1.10000000000000009
>[21] 1.10000000000000009 1.10000000000000009 1.19999999999999996
>1.19999999999999996
>[25] 1.19999999999999996 1.19999999999999996 1.30000000000000004
>1.30000000000000004
>[29] 1.30000000000000004 1.39999999999999991 1.39999999999999991
>1.39999999999999991
>[33] 1.50000000000000000 1.50000000000000000 1.50000000000000000
>1.60000000000000009
>[37] 1.60000000000000009 1.69999999999999996 1.69999999999999996
>1.69999999999999996
>[41] 1.69999999999999996 1.80000000000000004 1.80000000000000004
>1.80000000000000004
>[45] 1.89999999999999991 1.89999999999999991 2.00000000000000000
>2.00000000000000000
>[49] 2.00000000000000000 2.00000000000000000 2.00000000000000000
>2.10000000000000009
>
>The simplest solution is to subtract a bit. This also means you don't
>need the include.lowest= or right= arguments:
>
>> f <- cut(dat,
>+           breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
>+           dig.lab=10L)
>> as.matrix(tb <- table(f))
>            [,1]
>[0.59,0.79)    8
>[0.79,0.99)    7
>[0.99,1.19)    7
>[1.19,1.39)    7
>[1.39,1.59)    6
>[1.59,1.79)    6
>[1.79,1.99)    5
>[1.99,2.19]    6
>
>----------------------------------------
>David L Carlson
>Department of Anthropology
>Texas A&M University
>College Station, TX 77843-4352
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Jose Claudio
>Faria
>Sent: Monday, September 24, 2018 9:32 AM
>To: r-help at r-project.org
>Subject: [R] cut{base}: is it a bug?
>
>Dears members,
>
>Is the below a bug of the cut {base} function?
>
>dat <- c(
> 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
> 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
> 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
> 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
> 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
> 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
> 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
> 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
> )
>
># making class from function "cut"
>(f <- cut(dat,
>          breaks= seq(from=.6, to=2.2, by=.2),
>          include.lowest=TRUE,
>          dig.lab=10L,
>          right=FALSE))
>
># more easy to see the table
>as.matrix(tb <- table(f))
>
># Checking
>print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
>print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
>print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
>print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
>print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
>print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
>print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
>print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]
>
>Best,
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>Jose Claudio Faria
>UESC/DCET/Brasil
>joseclaudio.faria at gmail.com
>Telefones:
>55(73)3680.5545 - UESC
>55(73)99966.9100 - VIVO
>55(73)98817.6159 - OI
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>
>If you have software to deal with statistics, you have arms; if you
>have good software, you have arms and legs; if you have software like
>R, you have arms, legs and wings...
>the height of your flight depends only on you!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.

From pro|jcn@@h @end|ng |rom gm@||@com  Mon Sep 24 19:46:57 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Mon, 24 Sep 2018 13:46:57 -0400
Subject: [R] About uniroot error
In-Reply-To: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>
References: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>
Message-ID: <710d3514-91e8-a5d0-d871-9b2067628709@gmail.com>

uniroot REQUIRES that the function be of opposite sign at each end
of the starting interval.

I won't address the other issues raised, but you can use simple stepping
from a starting argument until a sign change occurs. Or you could try a
different type of rootfinder, such as newtonRaphson in package pracma.

There's some discussion in the (still in draft) vignette

https://gitlab.com/nashjc/histoRicalg/blob/master/provenance-of-rootfinding/rootfinder.pdf

by Oliver Dechant and myself as part of an investigation of "older"
codes.

JN


On 2018-09-24 01:37 PM, Tania Morgado Garcia wrote:
> Thanks for your answers. I continue to learn R and now I am detained in an
> error with uniroot that I see happens to others but I can not find the
> solution. Next the code
> 
> x1 <- BAaxOrd$V1
> y1 <- BAaxOrd$V2
> x1R <- BAaxOrdRCOS$V1
> y1R <- BAaxOrdRCOS$V2
> FCOS1 <- splinefun(smooth.spline(x1,y1))
> FRCOS1 <- splinefun(smooth.spline(x1R,y1R))
> FCOS1 <- Vectorize(FCOS1)
> FRCOS1 <- Vectorize(FRCOS1)
> 
> req(input$file1)
>       tryCatch(
>       {
>         df <- read.csv(input$file1$datapath,
>                        header = input$header,
>                        sep = "\t",
>                        quote = '"')
>       },
>       error = function(e) {
>         # return a safeError if a parsing error occurs
>         stop(safeError(e))
>       }
>     )
> 
>     #if(input$disp == "head") {
>      # return(head(df))
>     #}
>     #else {
> 
>       # Determine Carbon Reserve
>       for (row in 1:nrow(df)) {
>         if(df$ts==1) {
>            prof <-
> uniroot(f=function(x){FCOS1(x1)-df$carbono},interval=c(0,20))$root
>            limsup <- prof + df$pu
>            reserva <- integrate(FRCOS1,prof,limsup)$value
>         }
> 
> The if is because there are several types of soil, but I only put one.  The
> error is
> 
> Warning in if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
>   the condition has length > 1 and only the first element will be used
> Warning in if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
>   the condition has length > 1 and only the first element will be used
> Warning: Error in uniroot: f() values at end points not of opposite sign
> 
> The file that I load with data has a single row with the values ts = 1,
> carbon = 2.04 and pu = 15 (I left only that row to be able to determine the
> origin of the error). The functions FCOS1 and FRCOS1 are monotone
> decreasing.Graphic attachment of FCOS1
> 
> I would appreciate some help in this regard
> 
> thanks a lot
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From gkr@emer @end|ng |rom bgc-jen@@mpg@de  Mon Sep 24 15:43:01 2018
From: gkr@emer @end|ng |rom bgc-jen@@mpg@de (Guido Kraemer)
Date: Mon, 24 Sep 2018 15:43:01 +0200
Subject: [R] object 'nativeRoutines' not found
Message-ID: <76b118ab-4235-f0fd-4499-eb56aa7ab8bc@bgc-jena.mpg.de>

Hi all,

Since a couple of days travis-ci fails for my package coRanking with "R: 
devel".
The error message is:

Error in nativeRoutines[[lib]] <- routines :
object 'nativeRoutines' not found

"R: release" and "R: oldrel" work fine. Did some R internals change or 
is the "R: devel" on travis currently broken?

I also sent the package to winbuilder and it works fine with R-devel

You can find the travis build here:

https://travis-ci.org/gdkrmr/coRanking/jobs/428661435

Best Regards,

Guido



From m@k@hho||y @end|ng |rom gm@||@com  Mon Sep 24 20:26:39 2018
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Mon, 24 Sep 2018 13:26:39 -0500
Subject: [R] reading data problem
Message-ID: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>

Hi Dear all;

I have a dataset with 151*291 dimension. After making data read into R I am
getting a data with 96*291 dimension. Even though  I have no error message
from R I could not understand the reason why I cannot get data correctly?

Here are my codes to make read the data
a<-read.table("for_R_graphs.csv", header=T, sep=",")
a<-read.table("for_R_graphs.txt", header=T, sep="\t")

Regards,

Greg

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 24 20:36:05 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 24 Sep 2018 11:36:05 -0700
Subject: [R] reading data problem
In-Reply-To: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
Message-ID: <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>

*Perhaps* useful questions (perhaps *not*, though):

1. What is your OS? What is your R version?
2. How do you know that your data has 151 rows?
3. Are there stray characters -- perhaps a stray eof -- in your data? Have
you checked around row 96 to see what's there?
4. Are the data you did get in R what you expect?

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com> wrote:

> Hi Dear all;
>
> I have a dataset with 151*291 dimension. After making data read into R I am
> getting a data with 96*291 dimension. Even though  I have no error message
> from R I could not understand the reason why I cannot get data correctly?
>
> Here are my codes to make read the data
> a<-read.table("for_R_graphs.csv", header=T, sep=",")
> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
>
> Regards,
>
> Greg
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 24 20:40:47 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 24 Sep 2018 11:40:47 -0700
Subject: [R] reading data problem
In-Reply-To: <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
Message-ID: <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>

One more question:

5. Have you tried shutting down, restarting R, and rereading?

-- Bert

On Mon, Sep 24, 2018 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> *Perhaps* useful questions (perhaps *not*, though):
>
> 1. What is your OS? What is your R version?
> 2. How do you know that your data has 151 rows?
> 3. Are there stray characters -- perhaps a stray eof -- in your data? Have
> you checked around row 96 to see what's there?
> 4. Are the data you did get in R what you expect?
>
> -- Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com> wrote:
>
>> Hi Dear all;
>>
>> I have a dataset with 151*291 dimension. After making data read into R I
>> am
>> getting a data with 96*291 dimension. Even though  I have no error message
>> from R I could not understand the reason why I cannot get data correctly?
>>
>> Here are my codes to make read the data
>> a<-read.table("for_R_graphs.csv", header=T, sep=",")
>> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
>>
>> Regards,
>>
>> Greg
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From jttk|m @end|ng |rom goog|em@||@com  Mon Sep 24 21:04:48 2018
From: jttk|m @end|ng |rom goog|em@||@com (Jan T Kim)
Date: Mon, 24 Sep 2018 20:04:48 +0100
Subject: [R] reading data problem
In-Reply-To: <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
 <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>
Message-ID: <20180924190447.GE26688@paftolwp3a>

Yet one more: have you tried adding quote="" to your read.table
parameters? Quote characters have a 50% chance of being balanced,
and they can encompass multiple lines...

On Mon, Sep 24, 2018 at 11:40:47AM -0700, Bert Gunter wrote:
> One more question:
> 
> 5. Have you tried shutting down, restarting R, and rereading?
> 
> -- Bert
> 
> On Mon, Sep 24, 2018 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> > *Perhaps* useful questions (perhaps *not*, though):
> >
> > 1. What is your OS? What is your R version?
> > 2. How do you know that your data has 151 rows?
> > 3. Are there stray characters -- perhaps a stray eof -- in your data? Have
> > you checked around row 96 to see what's there?
> > 4. Are the data you did get in R what you expect?
> >
> > -- Bert
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com> wrote:
> >
> >> Hi Dear all;
> >>
> >> I have a dataset with 151*291 dimension. After making data read into R I
> >> am
> >> getting a data with 96*291 dimension. Even though  I have no error message
> >> from R I could not understand the reason why I cannot get data correctly?
> >>
> >> Here are my codes to make read the data
> >> a<-read.table("for_R_graphs.csv", header=T, sep=",")
> >> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
> >>
> >> Regards,
> >>
> >> Greg
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jo@ec|@ud|o@|@r|@ @end|ng |rom gm@||@com  Mon Sep 24 21:00:58 2018
From: jo@ec|@ud|o@|@r|@ @end|ng |rom gm@||@com (Jose Claudio Faria)
Date: Mon, 24 Sep 2018 16:00:58 -0300
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <c266d1a09f8742ee900ee491e8c74977@tamu.edu>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
 <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
 <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>
 <c266d1a09f8742ee900ee491e8c74977@tamu.edu>
Message-ID: <CAN+Emd9SX4eZkNVS0-NHXYguGi=Qge4-xnKh59-xri7GBBig1g@mail.gmail.com>

Dears,

Thank you for your contribution!

However, this function is important in a generic usage package for
frequency distribution tables: fdth (
https://cran.r-project.org/web/packages/fdth/index.html).

In this case, when I do not know in advance what the user data is, what is
the best option to avoid deviations as centuados as the example?

The data used in the example was sent to me from a teacher trying to
reproduce in class the table of a book.

Best,

///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
55(73)98817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms;
if you have good software, you have arms and legs;
if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

2018-09-24 14:42 GMT-03:00 David L Carlson <dcarlson at tamu.edu>:

> Yes, I should have included that point. The cut() function "encourages"
> exact comparison of values by including the right= argument without a
> warning that this may create unexpected results. With truly continuous
> data, values falling exactly on the boundary would be rare.
>
> Most data arrives from instruments that measure to limited precision.
> Introductory statistics texts deal with this by distinguishing between
> "true" and "stated" class limits. Or, like Lyman Ott, recommend choosing
> the starting point interval such that "no measurement falls on a point of
> division between two intervals."
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
> -----Original Message-----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Sent: Monday, September 24, 2018 10:41 AM
> To: r-help at r-project.org; David L Carlson <dcarlson at tamu.edu>; Jose
> Claudio Faria <joseclaudio.faria at gmail.com>; r-help at r-project.org
> Subject: Re: [R] cut{base}: is it a bug?
>
> "Subtracting a bit" only fixes the problem for the test data... it
> introduces a bias in any continuous data you happen to throw at it.
> However, if you have data with known rounding applied (e.g. published
> tabular data) then the subtracting trick can be useful. In general you
> should not expect floating point fractions to behave like exact values in
> your analysis.
>
> On September 24, 2018 8:14:09 AM PDT, David L Carlson <dcarlson at tamu.edu>
> wrote:
> >You've been bitten by FAQ 7.31: Why doesn't R think these numbers are
> >equal?
> >https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_
> 0027t-R-think-these-numbers-are-equal_003f
> >
> >Your boundaries and your data values are not what you think they are.
> >This is a limitation of digital computing not R.
> >
> >> print(seq(from=.6, to=2.2, by=.2), digits=17)
> >[1] 0.59999999999999998 0.80000000000000004 1.00000000000000000
> >1.20000000000000018
> >[5] 1.39999999999999991 1.60000000000000009 1.80000000000000027
> >2.00000000000000000
> >[9] 2.20000000000000018
> >
> >> print(dat, digits=17)
> >[1] 0.59999999999999998 0.59999999999999998 0.59999999999999998
> >0.69999999999999996
> >[5] 0.69999999999999996 0.69999999999999996 0.69999999999999996
> >0.69999999999999996
> >[9] 0.80000000000000004 0.80000000000000004 0.80000000000000004
> >0.90000000000000002
> >[13] 0.90000000000000002 0.90000000000000002 0.90000000000000002
> >1.00000000000000000
> >[17] 1.00000000000000000 1.00000000000000000 1.00000000000000000
> >1.10000000000000009
> >[21] 1.10000000000000009 1.10000000000000009 1.19999999999999996
> >1.19999999999999996
> >[25] 1.19999999999999996 1.19999999999999996 1.30000000000000004
> >1.30000000000000004
> >[29] 1.30000000000000004 1.39999999999999991 1.39999999999999991
> >1.39999999999999991
> >[33] 1.50000000000000000 1.50000000000000000 1.50000000000000000
> >1.60000000000000009
> >[37] 1.60000000000000009 1.69999999999999996 1.69999999999999996
> >1.69999999999999996
> >[41] 1.69999999999999996 1.80000000000000004 1.80000000000000004
> >1.80000000000000004
> >[45] 1.89999999999999991 1.89999999999999991 2.00000000000000000
> >2.00000000000000000
> >[49] 2.00000000000000000 2.00000000000000000 2.00000000000000000
> >2.10000000000000009
> >
> >The simplest solution is to subtract a bit. This also means you don't
> >need the include.lowest= or right= arguments:
> >
> >> f <- cut(dat,
> >+           breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
> >+           dig.lab=10L)
> >> as.matrix(tb <- table(f))
> >            [,1]
> >[0.59,0.79)    8
> >[0.79,0.99)    7
> >[0.99,1.19)    7
> >[1.19,1.39)    7
> >[1.39,1.59)    6
> >[1.59,1.79)    6
> >[1.79,1.99)    5
> >[1.99,2.19]    6
> >
> >----------------------------------------
> >David L Carlson
> >Department of Anthropology
> >Texas A&M University
> >College Station, TX 77843-4352
> >
> >
> >-----Original Message-----
> >From: R-help <r-help-bounces at r-project.org> On Behalf Of Jose Claudio
> >Faria
> >Sent: Monday, September 24, 2018 9:32 AM
> >To: r-help at r-project.org
> >Subject: [R] cut{base}: is it a bug?
> >
> >Dears members,
> >
> >Is the below a bug of the cut {base} function?
> >
> >dat <- c(
> > 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
> > 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
> > 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
> > 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
> > 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
> > 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
> > 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
> > 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
> > )
> >
> ># making class from function "cut"
> >(f <- cut(dat,
> >          breaks= seq(from=.6, to=2.2, by=.2),
> >          include.lowest=TRUE,
> >          dig.lab=10L,
> >          right=FALSE))
> >
> ># more easy to see the table
> >as.matrix(tb <- table(f))
> >
> ># Checking
> >print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
> >print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
> >print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
> >print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
> >print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
> >print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
> >print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
> >print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]
> >
> >Best,
> >///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> >Jose Claudio Faria
> >UESC/DCET/Brasil
> >joseclaudio.faria at gmail.com
> >Telefones:
> >55(73)3680.5545 - UESC
> >55(73)99966.9100 - VIVO
> >55(73)98817.6159 - OI
> >///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> >
> >If you have software to deal with statistics, you have arms; if you
> >have good software, you have arms and legs; if you have software like
> >R, you have arms, legs and wings...
> >the height of your flight depends only on you!
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From m@k@hho||y @end|ng |rom gm@||@com  Mon Sep 24 21:36:58 2018
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Mon, 24 Sep 2018 14:36:58 -0500
Subject: [R] reading data problem
In-Reply-To: <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
Message-ID: <CAM9Qe4gxdmP6pOnsYey9XO4F6scUBZUiaLh_w7vbY0+gFPaHGw@mail.gmail.com>

Hi Bert;

Thanks for writing. Here are my answers to your questions:

Regards,

Greg

1. What is your OS? What is your R version?          *The version is 3.5.0*
2. How do you know that your data has 151 rows?  *Because I looked in excel
also I work on the same data in SAS*
3. Are there stray characters -- perhaps a stray eof -- in your data? Have
you checked around row 96 to see what's there?  *I don't think so if I have
stray characters*
4. Are the data you did get in R what you expect? * I will run for some
graphics*
5. Have you tried shutting down, restarting R, and rereading?  *Yes and
again I had the same problem*

On Mon, Sep 24, 2018 at 1:36 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> *Perhaps* useful questions (perhaps *not*, though):
>
> 1. What is your OS? What is your R version?
> 2. How do you know that your data has 151 rows?
> 3. Are there stray characters -- perhaps a stray eof -- in your data? Have
> you checked around row 96 to see what's there?
> 4. Are the data you did get in R what you expect?
>
> -- Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com> wrote:
>
>> Hi Dear all;
>>
>> I have a dataset with 151*291 dimension. After making data read into R I
>> am
>> getting a data with 96*291 dimension. Even though  I have no error message
>> from R I could not understand the reason why I cannot get data correctly?
>>
>> Here are my codes to make read the data
>> a<-read.table("for_R_graphs.csv", header=T, sep=",")
>> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
>>
>> Regards,
>>
>> Greg
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From m@k@hho||y @end|ng |rom gm@||@com  Mon Sep 24 21:39:49 2018
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Mon, 24 Sep 2018 14:39:49 -0500
Subject: [R] reading data problem
In-Reply-To: <20180924190447.GE26688@paftolwp3a>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
 <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>
 <20180924190447.GE26688@paftolwp3a>
Message-ID: <CAM9Qe4gOQ1U6SJbMQjBJTmqxRzU4GjSRHmng2vkHAxbHDYNY+g@mail.gmail.com>

Hi Jan;

Thanks so much for this. Yes, I did. Her is my code to read
data: a<-read.csv("for_R_graphs.csv", header=T, sep=",")

On Mon, Sep 24, 2018 at 2:07 PM Jan T Kim via R-help <r-help at r-project.org>
wrote:

> Yet one more: have you tried adding quote="" to your read.table
> parameters? Quote characters have a 50% chance of being balanced,
> and they can encompass multiple lines...
>
> On Mon, Sep 24, 2018 at 11:40:47AM -0700, Bert Gunter wrote:
> > One more question:
> >
> > 5. Have you tried shutting down, restarting R, and rereading?
> >
> > -- Bert
> >
> > On Mon, Sep 24, 2018 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > > *Perhaps* useful questions (perhaps *not*, though):
> > >
> > > 1. What is your OS? What is your R version?
> > > 2. How do you know that your data has 151 rows?
> > > 3. Are there stray characters -- perhaps a stray eof -- in your data?
> Have
> > > you checked around row 96 to see what's there?
> > > 4. Are the data you did get in R what you expect?
> > >
> > > -- Bert
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> and
> > > sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com>
> wrote:
> > >
> > >> Hi Dear all;
> > >>
> > >> I have a dataset with 151*291 dimension. After making data read into
> R I
> > >> am
> > >> getting a data with 96*291 dimension. Even though  I have no error
> message
> > >> from R I could not understand the reason why I cannot get data
> correctly?
> > >>
> > >> Here are my codes to make read the data
> > >> a<-read.table("for_R_graphs.csv", header=T, sep=",")
> > >> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
> > >>
> > >> Regards,
> > >>
> > >> Greg
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jttk|m @end|ng |rom goog|em@||@com  Mon Sep 24 22:05:18 2018
From: jttk|m @end|ng |rom goog|em@||@com (Jan T Kim)
Date: Mon, 24 Sep 2018 21:05:18 +0100
Subject: [R] reading data problem
In-Reply-To: <CAM9Qe4gOQ1U6SJbMQjBJTmqxRzU4GjSRHmng2vkHAxbHDYNY+g@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
 <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>
 <20180924190447.GE26688@paftolwp3a>
 <CAM9Qe4gOQ1U6SJbMQjBJTmqxRzU4GjSRHmng2vkHAxbHDYNY+g@mail.gmail.com>
Message-ID: <CAGLFf7qCsYLrShg7VhqUZiduSBVcYh-3+O7xztrc-HbJiM48Ow@mail.gmail.com>

hmm... I don't see the quote="" paraneter in your read.csv call


Best regards, Jan
--
Sent from my mobile. Apologies for typos and terseness

On Mon, Sep 24, 2018, 20:40 greg holly <mak.hholly at gmail.com> wrote:

> Hi Jan;
>
> Thanks so much for this. Yes, I did. Her is my code to read
> data: a<-read.csv("for_R_graphs.csv", header=T, sep=",")
>
> On Mon, Sep 24, 2018 at 2:07 PM Jan T Kim via R-help <r-help at r-project.org>
> wrote:
>
>> Yet one more: have you tried adding quote="" to your read.table
>> parameters? Quote characters have a 50% chance of being balanced,
>> and they can encompass multiple lines...
>>
>> On Mon, Sep 24, 2018 at 11:40:47AM -0700, Bert Gunter wrote:
>> > One more question:
>> >
>> > 5. Have you tried shutting down, restarting R, and rereading?
>> >
>> > -- Bert
>> >
>> > On Mon, Sep 24, 2018 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >
>> > > *Perhaps* useful questions (perhaps *not*, though):
>> > >
>> > > 1. What is your OS? What is your R version?
>> > > 2. How do you know that your data has 151 rows?
>> > > 3. Are there stray characters -- perhaps a stray eof -- in your data?
>> Have
>> > > you checked around row 96 to see what's there?
>> > > 4. Are the data you did get in R what you expect?
>> > >
>> > > -- Bert
>> > >
>> > > Bert Gunter
>> > >
>> > > "The trouble with having an open mind is that people keep coming
>> along and
>> > > sticking things into it."
>> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> > >
>> > >
>> > > On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com>
>> wrote:
>> > >
>> > >> Hi Dear all;
>> > >>
>> > >> I have a dataset with 151*291 dimension. After making data read into
>> R I
>> > >> am
>> > >> getting a data with 96*291 dimension. Even though  I have no error
>> message
>> > >> from R I could not understand the reason why I cannot get data
>> correctly?
>> > >>
>> > >> Here are my codes to make read the data
>> > >> a<-read.table("for_R_graphs.csv", header=T, sep=",")
>> > >> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
>> > >>
>> > >> Regards,
>> > >>
>> > >> Greg
>> > >>
>> > >>         [[alternative HTML version deleted]]
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide
>> > >> http://www.R-project.org/posting-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >>
>> > >
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From m@k@hho||y @end|ng |rom gm@||@com  Mon Sep 24 22:08:50 2018
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Mon, 24 Sep 2018 15:08:50 -0500
Subject: [R] reading data problem
In-Reply-To: <CAGLFf7qCsYLrShg7VhqUZiduSBVcYh-3+O7xztrc-HbJiM48Ow@mail.gmail.com>
References: <CAM9Qe4gcfGeonEMSDa-injUwJvap0CsN+SbqOF-Jn=oGL-eOYg@mail.gmail.com>
 <CAGxFJbTADUD7bDy+hyoC9juz+FM4VSEdFy9Fjq1YAVz_hPEtaQ@mail.gmail.com>
 <CAGxFJbT+Xx+FotkDrttbnnL7dxoWvrSWNjspSnUaOjQrcBOoJA@mail.gmail.com>
 <20180924190447.GE26688@paftolwp3a>
 <CAM9Qe4gOQ1U6SJbMQjBJTmqxRzU4GjSRHmng2vkHAxbHDYNY+g@mail.gmail.com>
 <CAGLFf7qCsYLrShg7VhqUZiduSBVcYh-3+O7xztrc-HbJiM48Ow@mail.gmail.com>
Message-ID: <CAM9Qe4gOgeGOUuWubhC4yE6zNDJzMkHcOizT4n15BXZVDa5WEw@mail.gmail.com>

Hi Jan;

Thanks so much. It is much appreciated. The problem has been solved.

Regards,

Greg

On Mon, Sep 24, 2018 at 3:05 PM Jan T Kim <jttkim at googlemail.com> wrote:

> hmm... I don't see the quote="" paraneter in your read.csv call
>
>
> Best regards, Jan
> --
> Sent from my mobile. Apologies for typos and terseness
>
> On Mon, Sep 24, 2018, 20:40 greg holly <mak.hholly at gmail.com> wrote:
>
>> Hi Jan;
>>
>> Thanks so much for this. Yes, I did. Her is my code to read
>> data: a<-read.csv("for_R_graphs.csv", header=T, sep=",")
>>
>> On Mon, Sep 24, 2018 at 2:07 PM Jan T Kim via R-help <
>> r-help at r-project.org> wrote:
>>
>>> Yet one more: have you tried adding quote="" to your read.table
>>> parameters? Quote characters have a 50% chance of being balanced,
>>> and they can encompass multiple lines...
>>>
>>> On Mon, Sep 24, 2018 at 11:40:47AM -0700, Bert Gunter wrote:
>>> > One more question:
>>> >
>>> > 5. Have you tried shutting down, restarting R, and rereading?
>>> >
>>> > -- Bert
>>> >
>>> > On Mon, Sep 24, 2018 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> >
>>> > > *Perhaps* useful questions (perhaps *not*, though):
>>> > >
>>> > > 1. What is your OS? What is your R version?
>>> > > 2. How do you know that your data has 151 rows?
>>> > > 3. Are there stray characters -- perhaps a stray eof -- in your
>>> data? Have
>>> > > you checked around row 96 to see what's there?
>>> > > 4. Are the data you did get in R what you expect?
>>> > >
>>> > > -- Bert
>>> > >
>>> > > Bert Gunter
>>> > >
>>> > > "The trouble with having an open mind is that people keep coming
>>> along and
>>> > > sticking things into it."
>>> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> > >
>>> > >
>>> > > On Mon, Sep 24, 2018 at 11:27 AM greg holly <mak.hholly at gmail.com>
>>> wrote:
>>> > >
>>> > >> Hi Dear all;
>>> > >>
>>> > >> I have a dataset with 151*291 dimension. After making data read
>>> into R I
>>> > >> am
>>> > >> getting a data with 96*291 dimension. Even though  I have no error
>>> message
>>> > >> from R I could not understand the reason why I cannot get data
>>> correctly?
>>> > >>
>>> > >> Here are my codes to make read the data
>>> > >> a<-read.table("for_R_graphs.csv", header=T, sep=",")
>>> > >> a<-read.table("for_R_graphs.txt", header=T, sep="\t")
>>> > >>
>>> > >> Regards,
>>> > >>
>>> > >> Greg
>>> > >>
>>> > >>         [[alternative HTML version deleted]]
>>> > >>
>>> > >> ______________________________________________
>>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >> PLEASE do read the posting guide
>>> > >> http://www.R-project.org/posting-guide.html
>>> > >> and provide commented, minimal, self-contained, reproducible code.
>>> > >>
>>> > >
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Sep 24 22:12:34 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 24 Sep 2018 13:12:34 -0700
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <CAN+Emd9SX4eZkNVS0-NHXYguGi=Qge4-xnKh59-xri7GBBig1g@mail.gmail.com>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
 <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
 <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>
 <c266d1a09f8742ee900ee491e8c74977@tamu.edu>
 <CAN+Emd9SX4eZkNVS0-NHXYguGi=Qge4-xnKh59-xri7GBBig1g@mail.gmail.com>
Message-ID: <DEBE1C75-7709-4846-97B6-50AFE597FBE3@comcast.net>


> On Sep 24, 2018, at 12:00 PM, Jose Claudio Faria <joseclaudio.faria at gmail.com> wrote:
> 
> Dears,
> 
> Thank you for your contribution!
> 
> However, this function is important in a generic usage package for
> frequency distribution tables: fdth (
> https://cran.r-project.org/web/packages/fdth/index.html).
> 
> In this case, when I do not know in advance what the user data is, what is
> the best option to avoid deviations as centuados as the example?
> 
> The data used in the example was sent to me from a teacher trying to
> reproduce in class the table of a book.

If you want to provide tools that protect unsuspecting users from falling into common numerical and well understood potential traps, then why don't you process your data inputs with round( obj, 8) or something similar to your liking.

> round( 3*.1, 8) == 3*.1
[1] FALSE
> 0.3 == 3*.1
[1] FALSE
> round( 3*.1, 8) == 0.3
[1] TRUE


-- 
David.
> 
> Best,
> 
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> Jose Claudio Faria
> UESC/DCET/Brasil
> joseclaudio.faria at gmail.com
> Telefones:
> 55(73)3680.5545 - UESC
> 55(73)99966.9100 - VIVO
> 55(73)98817.6159 - OI
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> 
> If you have software to deal with statistics, you have arms;
> if you have good software, you have arms and legs;
> if you have software like R, you have arms, legs and wings...
> the height of your flight depends only on you!
> 
> 2018-09-24 14:42 GMT-03:00 David L Carlson <dcarlson at tamu.edu>:
> 
>> Yes, I should have included that point. The cut() function "encourages"
>> exact comparison of values by including the right= argument without a
>> warning that this may create unexpected results. With truly continuous
>> data, values falling exactly on the boundary would be rare.
>> 
>> Most data arrives from instruments that measure to limited precision.
>> Introductory statistics texts deal with this by distinguishing between
>> "true" and "stated" class limits. Or, like Lyman Ott, recommend choosing
>> the starting point interval such that "no measurement falls on a point of
>> division between two intervals."
>> 
>> ----------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77843-4352
>> 
>> -----Original Message-----
>> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> Sent: Monday, September 24, 2018 10:41 AM
>> To: r-help at r-project.org; David L Carlson <dcarlson at tamu.edu>; Jose
>> Claudio Faria <joseclaudio.faria at gmail.com>; r-help at r-project.org
>> Subject: Re: [R] cut{base}: is it a bug?
>> 
>> "Subtracting a bit" only fixes the problem for the test data... it
>> introduces a bias in any continuous data you happen to throw at it.
>> However, if you have data with known rounding applied (e.g. published
>> tabular data) then the subtracting trick can be useful. In general you
>> should not expect floating point fractions to behave like exact values in
>> your analysis.
>> 
>> On September 24, 2018 8:14:09 AM PDT, David L Carlson <dcarlson at tamu.edu>
>> wrote:
>>> You've been bitten by FAQ 7.31: Why doesn't R think these numbers are
>>> equal?
>>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_
>> 0027t-R-think-these-numbers-are-equal_003f
>>> 
>>> Your boundaries and your data values are not what you think they are.
>>> This is a limitation of digital computing not R.
>>> 
>>>> print(seq(from=.6, to=2.2, by=.2), digits=17)
>>> [1] 0.59999999999999998 0.80000000000000004 1.00000000000000000
>>> 1.20000000000000018
>>> [5] 1.39999999999999991 1.60000000000000009 1.80000000000000027
>>> 2.00000000000000000
>>> [9] 2.20000000000000018
>>> 
>>>> print(dat, digits=17)
>>> [1] 0.59999999999999998 0.59999999999999998 0.59999999999999998
>>> 0.69999999999999996
>>> [5] 0.69999999999999996 0.69999999999999996 0.69999999999999996
>>> 0.69999999999999996
>>> [9] 0.80000000000000004 0.80000000000000004 0.80000000000000004
>>> 0.90000000000000002
>>> [13] 0.90000000000000002 0.90000000000000002 0.90000000000000002
>>> 1.00000000000000000
>>> [17] 1.00000000000000000 1.00000000000000000 1.00000000000000000
>>> 1.10000000000000009
>>> [21] 1.10000000000000009 1.10000000000000009 1.19999999999999996
>>> 1.19999999999999996
>>> [25] 1.19999999999999996 1.19999999999999996 1.30000000000000004
>>> 1.30000000000000004
>>> [29] 1.30000000000000004 1.39999999999999991 1.39999999999999991
>>> 1.39999999999999991
>>> [33] 1.50000000000000000 1.50000000000000000 1.50000000000000000
>>> 1.60000000000000009
>>> [37] 1.60000000000000009 1.69999999999999996 1.69999999999999996
>>> 1.69999999999999996
>>> [41] 1.69999999999999996 1.80000000000000004 1.80000000000000004
>>> 1.80000000000000004
>>> [45] 1.89999999999999991 1.89999999999999991 2.00000000000000000
>>> 2.00000000000000000
>>> [49] 2.00000000000000000 2.00000000000000000 2.00000000000000000
>>> 2.10000000000000009
>>> 
>>> The simplest solution is to subtract a bit. This also means you don't
>>> need the include.lowest= or right= arguments:
>>> 
>>>> f <- cut(dat,
>>> +           breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
>>> +           dig.lab=10L)
>>>> as.matrix(tb <- table(f))
>>>           [,1]
>>> [0.59,0.79)    8
>>> [0.79,0.99)    7
>>> [0.99,1.19)    7
>>> [1.19,1.39)    7
>>> [1.39,1.59)    6
>>> [1.59,1.79)    6
>>> [1.79,1.99)    5
>>> [1.99,2.19]    6
>>> 
>>> ----------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77843-4352
>>> 
>>> 
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jose Claudio
>>> Faria
>>> Sent: Monday, September 24, 2018 9:32 AM
>>> To: r-help at r-project.org
>>> Subject: [R] cut{base}: is it a bug?
>>> 
>>> Dears members,
>>> 
>>> Is the below a bug of the cut {base} function?
>>> 
>>> dat <- c(
>>> 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
>>> 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,        #(7)
>>> 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,        #(7)
>>> 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,        #(7)
>>> 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,               #(6)
>>> 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,               #(6)
>>> 1.8, 1.8, 1.8, 1.9, 1.9,                      #(5)
>>> 2.0, 2.0, 2.0, 2.0, 2.0, 2.1                #(6)
>>> )
>>> 
>>> # making class from function "cut"
>>> (f <- cut(dat,
>>>         breaks= seq(from=.6, to=2.2, by=.2),
>>>         include.lowest=TRUE,
>>>         dig.lab=10L,
>>>         right=FALSE))
>>> 
>>> # more easy to see the table
>>> as.matrix(tb <- table(f))
>>> 
>>> # Checking
>>> print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
>>> print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
>>> print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]  # !?
>>> print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]  # !?
>>> print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
>>> print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]  # !?
>>> print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]  # !?
>>> print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]
>>> 
>>> Best,
>>> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>>> Jose Claudio Faria
>>> UESC/DCET/Brasil
>>> joseclaudio.faria at gmail.com
>>> Telefones:
>>> 55(73)3680.5545 - UESC
>>> 55(73)99966.9100 - VIVO
>>> 55(73)98817.6159 - OI
>>> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>>> 
>>> If you have software to deal with statistics, you have arms; if you
>>> have good software, you have arms and legs; if you have software like
>>> R, you have arms, legs and wings...
>>> the height of your flight depends only on you!
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From dc@r|@on @end|ng |rom t@mu@edu  Mon Sep 24 22:26:51 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Mon, 24 Sep 2018 20:26:51 +0000
Subject: [R] cut{base}: is it a bug?
In-Reply-To: <CAN+Emd9SX4eZkNVS0-NHXYguGi=Qge4-xnKh59-xri7GBBig1g@mail.gmail.com>
References: <CAN+Emd_bbSkVFq9XhuNT2OtdAnO58Z8aYU1D9W5nmmM+EFHjBA@mail.gmail.com>
 <a73f82dbede144399b2376a1b5e27f44@tamu.edu>
 <D6AF2EA4-9221-47D9-93FA-2DBEFD16FB1D@dcn.davis.ca.us>
 <c266d1a09f8742ee900ee491e8c74977@tamu.edu>
 <CAN+Emd9SX4eZkNVS0-NHXYguGi=Qge4-xnKh59-xri7GBBig1g@mail.gmail.com>
Message-ID: <375b4b147ad046f1af65f83b8c2a0247@tamu.edu>

You need to know the number of decimal places reported for the data. I don't know of any straightforward way to compute that from the data. 

Given the number of decimals, you can compute "true" limit boundaries. This would be a way to compute the upper and lower boundaries and the number of intervals from the data:

> decimals <- 1
> tlimit <- (10^-decimals)/2
> bks <- pretty(c(dat, max(dat)+tlimit), nclass.Sturges(dat))
> f <- cut(dat, breaks= bks-tlimit, right=FALSE, dig.lab=10L)

You would also need to decide if you want your factor levels to reflect the true boundaries or the stated boundaries:

> levels(f)
[1] "[0.55,0.75)" "[0.75,0.95)" "[0.95,1.15)" "[1.15,1.35)" "[1.35,1.55)"
[6] "[1.55,1.75)" "[1.75,1.95)" "[1.95,2.15)"

Vs. 

> lvls <- levels(cut(dat, breaks= bks, right=FALSE, dig.lab=10L))
> levels(f) <- lvls
> levels(f)
[1] "[0.6,0.8)" "[0.8,1)"   "[1,1.2)"   "[1.2,1.4)" "[1.4,1.6)" "[1.6,1.8)"
[7] "[1.8,2)"   "[2,2.2)"  

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

From: Jose Claudio Faria <joseclaudio.faria at gmail.com> 
Sent: Monday, September 24, 2018 2:01 PM
To: David L Carlson <dcarlson at tamu.edu>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
Subject: Re: [R] cut{base}: is it a bug?

Dears,

Thank you for your contribution!

However, this function is important in a generic usage package for frequency distribution tables: fdth (https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_web_packages_fdth_index.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=wB3zkm0Z2hvc1svMqrK7BS3aQS7VlLlteA8BFZd-sQA&e=).

In this case, when I do not know in advance what the user data is, what is the best option to avoid deviations as centuados as the example?

The data used in the example was sent to me from a teacher trying to reproduce in class the table of a book.

Best,


///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at https://urldefense.proofpoint.com/v2/url?u=http-3A__gmail.com&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=3NkW6wyXOvCsrjWVqle139SjYzQ1xGL_aOQ3ec8L85Y&e=
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
55(73)98817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms;
if you have good software, you have arms and legs;
if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

2018-09-24 14:42 GMT-03:00 David L Carlson <mailto:dcarlson at tamu.edu>:
Yes, I should have included that point. The cut() function "encourages" exact comparison of values by including the right= argument without a warning that this may create unexpected results. With truly continuous data, values falling exactly on the boundary would be rare. 

Most data arrives from instruments that measure to limited precision. Introductory statistics texts deal with this by distinguishing between "true" and "stated" class limits. Or, like Lyman Ott, recommend choosing the starting point interval such that "no measurement falls on a point of division between two intervals."

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us> 
Sent: Monday, September 24, 2018 10:41 AM
To: mailto:r-help at r-project.org; David L Carlson <mailto:dcarlson at tamu.edu>; Jose Claudio Faria <mailto:joseclaudio.faria at gmail.com>; mailto:r-help at r-project.org
Subject: Re: [R] cut{base}: is it a bug?

"Subtracting a bit" only fixes the problem for the test data... it introduces a bias in any continuous data you happen to throw at it. However, if you have data with known rounding applied (e.g. published tabular data) then the subtracting trick can be useful. In general you should not expect floating point fractions to behave like exact values in your analysis.

On September 24, 2018 8:14:09 AM PDT, David L Carlson <mailto:dcarlson at tamu.edu> wrote:
>You've been bitten by FAQ 7.31: Why doesn't R think these numbers are
>equal?
>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_doc_FAQ_R-2DFAQ.html-23Why-2Ddoesn-5F0027t-2DR-2Dthink-2Dthese-2Dnumbers-2Dare-2Dequal-5F003f&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=bmSMJ_7ca1pAJtmWsC5SlqVYRV2rn75Kgco0uSbRHkE&e=
>
>Your boundaries and your data values are not what you think they are.
>This is a limitation of digital computing not R.
>
>> print(seq(from=.6, to=2.2, by=.2), digits=17)
>[1] 0.59999999999999998 0.80000000000000004 1.00000000000000000
>1.20000000000000018
>[5] 1.39999999999999991 1.60000000000000009 1.80000000000000027
>2.00000000000000000
>[9] 2.20000000000000018
>
>> print(dat, digits=17)
>[1] 0.59999999999999998 0.59999999999999998 0.59999999999999998
>0.69999999999999996
>[5] 0.69999999999999996 0.69999999999999996 0.69999999999999996
>0.69999999999999996
>[9] 0.80000000000000004 0.80000000000000004 0.80000000000000004
>0.90000000000000002
>[13] 0.90000000000000002 0.90000000000000002 0.90000000000000002
>1.00000000000000000
>[17] 1.00000000000000000 1.00000000000000000 1.00000000000000000
>1.10000000000000009
>[21] 1.10000000000000009 1.10000000000000009 1.19999999999999996
>1.19999999999999996
>[25] 1.19999999999999996 1.19999999999999996 1.30000000000000004
>1.30000000000000004
>[29] 1.30000000000000004 1.39999999999999991 1.39999999999999991
>1.39999999999999991
>[33] 1.50000000000000000 1.50000000000000000 1.50000000000000000
>1.60000000000000009
>[37] 1.60000000000000009 1.69999999999999996 1.69999999999999996
>1.69999999999999996
>[41] 1.69999999999999996 1.80000000000000004 1.80000000000000004
>1.80000000000000004
>[45] 1.89999999999999991 1.89999999999999991 2.00000000000000000
>2.00000000000000000
>[49] 2.00000000000000000 2.00000000000000000 2.00000000000000000
>2.10000000000000009
>
>The simplest solution is to subtract a bit. This also means you don't
>need the include.lowest= or right= arguments:
>
>> f <- cut(dat,
>+? ? ? ? ? ?breaks= seq(from=.6-.01, to=2.2-.01, by=.2),
>+? ? ? ? ? ?dig.lab=10L)
>> as.matrix(tb <- table(f))
>? ? ? ? ? ? [,1]
>[0.59,0.79)? ? 8
>[0.79,0.99)? ? 7
>[0.99,1.19)? ? 7
>[1.19,1.39)? ? 7
>[1.39,1.59)? ? 6
>[1.59,1.79)? ? 6
>[1.79,1.99)? ? 5
>[1.99,2.19]? ? 6
>
>----------------------------------------
>David L Carlson
>Department of Anthropology
>Texas A&M University
>College Station, TX 77843-4352
>
>
>-----Original Message-----
>From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Jose Claudio
>Faria
>Sent: Monday, September 24, 2018 9:32 AM
>To: mailto:r-help at r-project.org
>Subject: [R] cut{base}: is it a bug?
>
>Dears members,
>
>Is the below a bug of the cut {base} function?
>
>dat <- c(
> 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, #(8)
> 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,? ? ? ? #(7)
> 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1,? ? ? ? #(7)
> 1.2, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3,? ? ? ? #(7)
> 1.4, 1.4, 1.4, 1.5, 1.5, 1.5,? ? ? ? ? ? ? ?#(6)
> 1.6, 1.6, 1.7, 1.7, 1.7, 1.7,? ? ? ? ? ? ? ?#(6)
> 1.8, 1.8, 1.8, 1.9, 1.9,? ? ? ? ? ? ? ? ? ? ? #(5)
> 2.0, 2.0, 2.0, 2.0, 2.0, 2.1? ? ? ? ? ? ? ? #(6)
> )
>
># making class from function "cut"
>(f <- cut(dat,
>? ? ? ? ? breaks= seq(from=.6, to=2.2, by=.2),
>? ? ? ? ? include.lowest=TRUE,
>? ? ? ? ? dig.lab=10L,
>? ? ? ? ? right=FALSE))
>
># more easy to see the table
>as.matrix(tb <- table(f))
>
># Checking
>print(length(dat[dat >= 0.6 & dat < 0.8])) == tb[1]
>print(length(dat[dat >= 0.8 & dat < 1.0])) == tb[2]
>print(length(dat[dat >= 1.0 & dat < 1.2])) == tb[3]? # !?
>print(length(dat[dat >= 1.2 & dat < 1.4])) == tb[4]? # !?
>print(length(dat[dat >= 1.4 & dat < 1.6])) == tb[5]
>print(length(dat[dat >= 1.6 & dat < 1.8])) == tb[6]? # !?
>print(length(dat[dat >= 1.8 & dat < 2.0])) == tb[7]? # !?
>print(length(dat[dat >= 2.0 & dat < 2.2])) == tb[8]
>
>Best,
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>Jose Claudio Faria
>UESC/DCET/Brasil
>joseclaudio.faria at https://urldefense.proofpoint.com/v2/url?u=http-3A__gmail.com&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=3NkW6wyXOvCsrjWVqle139SjYzQ1xGL_aOQ3ec8L85Y&e=
>Telefones:
>55(73)3680.5545 - UESC
>55(73)99966.9100 - VIVO
>55(73)98817.6159 - OI
>///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>
>If you have software to deal with statistics, you have arms; if you
>have good software, you have arms and legs; if you have software like
>R, you have arms, legs and wings...
>the height of your flight depends only on you!
>
>? ? ? ?[[alternative HTML version deleted]]
>
>______________________________________________
>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=B_9d6gWXu0q4UO6J41Ve_rNsdRdGpGychN2ABZzb3Z4&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=vyr1qxeTCBubIC7Ora6AWijq6kMLQ0yomzD31wUGgfY&e=
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=B_9d6gWXu0q4UO6J41Ve_rNsdRdGpGychN2ABZzb3Z4&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=uucFFh4rZR34wAl-W854iMcjYtwQL9AF0bUtWXNd1rQ&s=vyr1qxeTCBubIC7Ora6AWijq6kMLQ0yomzD31wUGgfY&e=
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From g@@per@c@nk@r @end|ng |rom r|c@@|  Mon Sep 24 15:25:38 2018
From: g@@per@c@nk@r @end|ng |rom r|c@@| (Gasper Cankar)
Date: Mon, 24 Sep 2018 13:25:38 +0000
Subject: [R] Smallest Space Analysis (SSA) in R
In-Reply-To: <ce6d102d-0ac0-853c-2741-e08a6214381c@gmail.com>
References: <4d59dc48-2dbc-c26f-32e9-6c5def56afb2@gmail.com>
 <a6be1f88-65d8-b779-b1f9-f215f9df6c36@yorku.ca>
 <c226c952-b8f3-3c1a-6c62-5d19530afce6@gmail.com>
 <4d2400ea-28ef-875a-064e-79a0bd7325ac@yorku.ca>,
 <ce6d102d-0ac0-853c-2741-e08a6214381c@gmail.com>
Message-ID: <9AF3B98F746E140F.7db34733-20e0-4675-bf20-f454e9ff8f06@mail.outlook.com>



Get Outlook for Android<https://aka.ms/ghei36>




On Mon, Sep 24, 2018 at 3:18 PM +0200, "Andrew" <phaedrusv at gmail.com<mailto:phaedrusv at gmail.com>> wrote:


Ha! Even better - thank you. Plenty here for me to play around with.

Many thanks
Andrew


On 23/09/18 15:22, Michael Friendly wrote:
> On 9/22/2018 6:49 AM, Andrew wrote:
>> Hi Michael
>>
>> This looks like it could be really helpful in moving my project
>> forwards thank you.
>>
>> I remember many years ago using (proprietary) software from the
>> University of Liverpool which did a nice job of allowing regions to
>> be defined, and then for the space to be rotated to obtain visual
>> inspection of relative distance from different angles. I appreciate
>> that smacof will not do that, but as long as the analysis allows for
>> the graph to be plotted and analysed, that's what's important.
>
> You need not rely on the plots provided directly by a given package.
> Just roll your own using standard plotting libraries.
> Here is just the first Google hit on "R MDS 3D plot"
>
> http://omnilogia.blogspot.com/2014/05/basic-2d-3d-multi-dimensional-scaling.html
>
>
> which shows a rotating 3D plot, colored by a grouping variable. Here
> is another:
>
> http://whatzcookinlab.blogspot.com/2013/05/spinning-3d-mds-plot.html
>
> The vegan and ade4 packages also have a variety of plots and related
> methods.
>
>
> -Michael
>
>>
>> Thank you again, and to all of those who responded.
>>
>> Best wishes
>> Andrew
>>
>>
>> On 21/09/18 14:07, Michael Friendly wrote:
>>> Smallest space analysis (SSA) is just the name given to software
>>> developed by Guttman & Lingoes around the time the various versions
>>> of multidimensional scaling were being developed.  Call it Israeli MDS
>>> or Falafel MDS if you prefer. The reason you encountered it in your
>>> course is presumably that the instructor was trained in that.
>>>
>>> There are several variants of MDS-like algorithms for embedding
>>> points representing objects in a space, using data representing
>>> similarities or distances among objects -- metric (cmdscale)
>>> and non-metric (MASS::isoMDS), using only rank order information,
>>> and a variety of
>>> measures of goodness-of-fit ("stress").  I don't recall the details
>>> of the SSA programs, but that should matter little conceptually.
>>>
>>> The smacof package offers the widest array of possibilities.
>>>
>>> -Michael
>>>
>>>
>>> On 9/19/2018 7:00 AM, Andrew wrote:
>>>> Hi
>>>>
>>>> As part of my forensics psych course, we have been introduced to
>>>> Guttman's smallest space analysis (SSA). I want to explore this
>>>> approach
>>>> using R, but despite finding some queries on the web about this same
>>>> thing, have yet to find any answers. The MASS package doesn't seem
>>>> to do
>>>> the job, and the only thing I have been able to find is some
>>>> proprietary
>>>> software HUDAP  (Hebrew University Data Analysis Package) which
>>>> may/ not
>>>> be compatible with R (or GNU/Linux for that matter).
>>>>
>>>> Does anyone have information on how to do SSA using R?
>>>>
>>>> Many thanks
>>>>
>>>> Andrew
>>>>
>>>>
>>>>     [[alternative HTML version deleted]]
>>>>
>>>
>>>
>>
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Sep 25 10:50:49 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 25 Sep 2018 10:50:49 +0200
Subject: [R] For Loop
In-Reply-To: <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
References: <5BA6B12B.3090606@comcast.net>
 <CAKyN3iA5zq4uhs196q+uXFLm8+Dougy+E4KadpZEGr9isyAaMA@mail.gmail.com>
 <CA+vqiLH3CKALqLgDKjeGK5_7AaZkbRY7JuKn74qvOXW13cyVOQ@mail.gmail.com>
 <CAKyN3iCQaLJUT1oPLGwVC-X1ALZx2NPMkR1YUw9K9yRgyDQufA@mail.gmail.com>
 <CA+vqiLGTpooBx0J7ccB=PCcOeVzry5mxhp_edu=zasW-0t7Fkg@mail.gmail.com>
 <CAKyN3iBQS0=-_BPHwO6c9c=3uzLOKS9wAjrWwrPVtsShW+ZwGw@mail.gmail.com>
 <CA+vqiLEn7jLaeX5zGC76rPbNYaEBHWdX9S95YP6dB2AWj2vmsg@mail.gmail.com>
 <CAKyN3iBdsFtyNEUYN=Bc+iSRYv89PBHB95FZFJ9jN-eofRtiog@mail.gmail.com>
Message-ID: <23465.63209.180983.97854@stat.math.ethz.ch>

>>>>> Wensui Liu 
>>>>>     on Sun, 23 Sep 2018 13:26:32 -0500 writes:

    > what you measures is the "elapsed" time in the default
    > setting. you might need to take a closer look at the
    > beautiful benchmark() function and see what time I am
    > talking about.

    > I just provided tentative solution for the person asking
    > for it and believe he has enough wisdom to decide what's
    > best. why bother to judge others subjectively?  

Well, because  Ista Zahn is much much much better R programmer
than you, sorry to be blunt!

Martin

    > On Sun, Sep 23, 2018 at 1:18 PM Ista Zahn <istazahn at gmail.com>
    > wrote:
    >> 
    >> On Sun, Sep 23, 2018 at 1:46 PM Wensui Liu
    >> <liuwensui at gmail.com> wrote:
    >> >
    >> > actually, by the parallel pvec, the user time is a lot
    >> shorter. or did > I somewhere miss your invaluable
    >> insight?
    >> >
    >> > > c1 <- 1:1000000 > > len <- length(c1) > >
    >> rbenchmark::benchmark(log(c1[-1]/c1[-len]), replications
    >> = 100) > test replications elapsed relative user.self
    >> sys.self > 1 log(c1[-1]/c1[-len]) 100 4.617 1 4.484 0.133
    >> > user.child sys.child > 1 0 0 > >
    >> rbenchmark::benchmark(pvec(1:(len - 1), mc.cores = 4,
    >> function(i) log(c1[i + 1] / c1[i])), replications = 100)
    >> > test > 1 pvec(1:(len - 1), mc.cores = 4, function(i)
    >> log(c1[i + 1]/c1[i])) > replications elapsed relative
    >> user.self sys.self user.child sys.child > 1 100 9.079 1
    >> 2.571 4.138 9.736 8.046
    >> 
    >> Your output is mangled in my email, but on my system your
    >> pvec approach takes more than twice as long:
    >> 
    >> c1 <- 1:1000000 len <- length(c1) library(parallel)
    >> library(rbenchmark)
    >> 
    >> regular <- function() log(c1[-1]/c1[-len])
    >> iterate.parallel <- function() { pvec(1:(len - 1),
    >> mc.cores = 4, function(i) log(c1[i + 1] / c1[i])) }
    >> 
    >> benchmark(regular(), iterate.parallel(), replications =
    >> 100, columns = c("test", "elapsed", "relative")) ## test
    >> elapsed relative ## 2 iterate.parallel() 7.517 2.482 ## 1
    >> regular() 3.028 1.000
    >> 
    >> Honestly, just use log(c1[-1]/c1[-len]). The code is
    >> simple and easy to understand and it runs pretty
    >> fast. There is usually no reason to make it more
    >> complicated.  --Ista
    >> 
    >> > On Sun, Sep 23, 2018 at 12:33 PM Ista Zahn
    >> <istazahn at gmail.com> wrote:
    >> > >
    >> > > On Sun, Sep 23, 2018 at 10:09 AM Wensui Liu
    >> <liuwensui at gmail.com> wrote:
    >> > > >
    >> > > > Why?
    >> > >
    >> > > The operations required for this algorithm are
    >> vectorized, as are most > > operations in R. There is no
    >> need to iterate through each element.  > > Using
    >> Vectorize to achieve the iteration is no better than
    >> using > > *apply or a for-loop, and betrays the same
    >> basic lack of insight into > > basic principles of
    >> programming in R.
    >> > >
    >> > > And/or, if you want a more practical reason:
    >> > >
    >> > > > c1 <- 1:1000000 > > > len <- 1000000 > > >
    >> system.time( s1 <- log(c1[-1]/c1[-len])) > > user system
    >> elapsed > > 0.031 0.004 0.035 > > > system.time(s2 <-
    >> Vectorize(function(i) log(c1[i + 1] / c1[i])) (1:len)) >
    >> > user system elapsed > > 1.258 0.022 1.282
    >> > >
    >> > > Best, > > Ista
    >> > >
    >> > > >
    >> > > > On Sun, Sep 23, 2018 at 7:54 AM Ista Zahn
    >> <istazahn at gmail.com> wrote:
    >> > > >>
    >> > > >> On Sat, Sep 22, 2018 at 9:06 PM Wensui Liu
    >> <liuwensui at gmail.com> wrote:
    >> > > >> >
    >> > > >> > or this one:
    >> > > >> >
    >> > > >> > (Vectorize(function(i) log(c1[i + 1] / c1[i]))
    >> (1:len))
    >> > > >>
    >> > > >> Oh dear god no.
    >> > > >>
    >> > > >> >
    >> > > >> > On Sat, Sep 22, 2018 at 4:16 PM rsherry8
    >> <rsherry8 at comcast.net> wrote:
    >> > > >> > >
    >> > > >> > >
    >> > > >> > > It is my impression that good R programmers
    >> make very little use of the > > >> > > for
    >> statement. Please consider the following > > >> > > R
    >> statement: > > >> > > for( i in 1:(len-1) ) s[i] =
    >> log(c1[i+1]/c1[i], base = exp(1) ) > > >> > > One problem
    >> I have found with this statement is that s must exist
    >> before > > >> > > the statement is run. Can it be written
    >> without using a for > > >> > > loop? Would that be
    >> better?
    >> > > >> > >
    >> > > >> > > Thanks, > > >> > > Bob
    >> > > >> > >
    >> > > >> > > ______________________________________________
    >> > > >> > > R-help at r-project.org mailing list -- To
    >> UNSUBSCRIBE and more, see > > >> > >
    >> https://stat.ethz.ch/mailman/listinfo/r-help > > >> > >
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html > > >> > >
    >> and provide commented, minimal, self-contained,
    >> reproducible code.
    >> > > >> >
    >> > > >> > ______________________________________________ >
    >> > >> > R-help at r-project.org mailing list -- To
    >> UNSUBSCRIBE and more, see > > >> >
    >> https://stat.ethz.ch/mailman/listinfo/r-help > > >> >
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html > > >> > and
    >> provide commented, minimal, self-contained, reproducible
    >> code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.



From h@en|e|n @end|ng |rom gm@||@com  Tue Sep 25 17:15:24 2018
From: h@en|e|n @end|ng |rom gm@||@com (Michael Haenlein)
Date: Tue, 25 Sep 2018 17:15:24 +0200
Subject: [R] Instagram Analysis
Message-ID: <CAOyz9G50VYP7=ekm2uspoq+8U=PVwn9eFjg5_zDV9sxXKp2rDA@mail.gmail.com>

Dear all,

I'm looking for an R package that allows me to analyze Instagram.
Specifically I would like to download for a given account the list of other
accounts that either this account follows or that follow this account (the
followers and following numbers).

I know there is instaR but this package is quite old (August 2016) and
seems not to have been updated in the meantime. Is there a new package or
any other way to get this information in an easy way?

Thanks,

Michael

	[[alternative HTML version deleted]]



From h@@@n@d|w@n @end|ng |rom gm@||@com  Tue Sep 25 17:24:31 2018
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Tue, 25 Sep 2018 08:24:31 -0700
Subject: [R] Instagram Analysis
In-Reply-To: <CAOyz9G50VYP7=ekm2uspoq+8U=PVwn9eFjg5_zDV9sxXKp2rDA@mail.gmail.com>
References: <CAOyz9G50VYP7=ekm2uspoq+8U=PVwn9eFjg5_zDV9sxXKp2rDA@mail.gmail.com>
Message-ID: <CAP+bYWBPJVToY8qtvrYb3niMs+3ZxW78FTK+57kjDkMuPiAA4A@mail.gmail.com>

Michael,
On Tue, 25 Sep 2018 at 08:15, Michael Haenlein <haenlein at gmail.com> wrote:
> I'm looking for an R package that allows me to analyze Instagram.
> Specifically I would like to download for a given account the list of other
> accounts that either this account follows or that follow this account (the
> followers and following numbers).
> any other way to get this information in an easy way?

Send a get request to
https://api.instagram.com/v1/users/{user-id}/follows?access_token=ACCESS-TOKEN
and you'll get JSON back with (among other things) the accounts said
user follows. Hope that helps... Feel free to drop me a line off-list
should you need further help. -- H


-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable



From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Sep 25 17:29:48 2018
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 25 Sep 2018 16:29:48 +0100
Subject: [R] About uniroot error
In-Reply-To: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>
References: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>
Message-ID: <3719d912-731a-06ad-6dfc-88295b3ce41c@dewey.myzen.co.uk>

Dear Tania

Without your dataset I am not sure but a comment below to suggest where 
to look next.

On 24/09/2018 18:37, Tania Morgado Garcia wrote:
> Thanks for your answers. I continue to learn R and now I am detained in an
> error with uniroot that I see happens to others but I can not find the
> solution. Next the code
> 
> x1 <- BAaxOrd$V1
> y1 <- BAaxOrd$V2
> x1R <- BAaxOrdRCOS$V1
> y1R <- BAaxOrdRCOS$V2
> FCOS1 <- splinefun(smooth.spline(x1,y1))
> FRCOS1 <- splinefun(smooth.spline(x1R,y1R))
> FCOS1 <- Vectorize(FCOS1)
> FRCOS1 <- Vectorize(FRCOS1)
> 
> req(input$file1)
>        tryCatch(
>        {
>          df <- read.csv(input$file1$datapath,
>                         header = input$header,
>                         sep = "\t",
>                         quote = '"')
>        },
>        error = function(e) {
>          # return a safeError if a parsing error occurs
>          stop(safeError(e))
>        }
>      )
> 
>      #if(input$disp == "head") {
>       # return(head(df))
>      #}
>      #else {
> 
>        # Determine Carbon Reserve
>        for (row in 1:nrow(df)) {
>          if(df$ts==1) {
>             prof <-
> uniroot(f=function(x){FCOS1(x1)-df$carbono},interval=c(0,20))$root
>             limsup <- prof + df$pu
>             reserva <- integrate(FRCOS1,prof,limsup)$value
>          }

Are you sure that FCOS(x1) - df$carbono returns a scalar? It looks as 
though it returns a vector to me but without your data I am not sure so 
ignore my post if it does.
> 
> The if is because there are several types of soil, but I only put one.  The
> error is
> 
> Warning in if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
>    the condition has length > 1 and only the first element will be used
> Warning in if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
>    the condition has length > 1 and only the first element will be used
> Warning: Error in uniroot: f() values at end points not of opposite sign
> 
> The file that I load with data has a single row with the values ts = 1,
> carbon = 2.04 and pu = 15 (I left only that row to be able to determine the
> origin of the error). The functions FCOS1 and FRCOS1 are monotone
> decreasing.Graphic attachment of FCOS1
> 
> I would appreciate some help in this regard
> 
> thanks a lot
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html



From tmg1970 @end|ng |rom gm@||@com  Tue Sep 25 17:46:58 2018
From: tmg1970 @end|ng |rom gm@||@com (Tania Morgado Garcia)
Date: Tue, 25 Sep 2018 10:46:58 -0500
Subject: [R] About uniroot error
In-Reply-To: <3719d912-731a-06ad-6dfc-88295b3ce41c@dewey.myzen.co.uk>
References: <CAGObTgrtn6pmcxOkQfZKO3tCmjH9UuGgEGrC3d6kPcNrgpZ9bA@mail.gmail.com>
 <3719d912-731a-06ad-6dfc-88295b3ce41c@dewey.myzen.co.uk>
Message-ID: <CAGObTgpdas1O45x_mr4fc1e2BwEzDU2xwcF_q3+oMf+-ObJLjw@mail.gmail.com>

Thanks for your reply. You're right, return a vector. An example of the
dataset:
ts pu carbono
1 15 2.04
1 37 1.27
1 55 0.93
1 80 0.5
1 105 0.49
1 22 2.08
1 41 1.43
1 65 0.78

The data that originate the FCOS and FRCOS pattern functions are others,
which I only use to obtain the functions.

Thanks again

El mar., 25 sept. 2018 a las 10:29, Michael Dewey (<lists at dewey.myzen.co.uk>)
escribi?:

> Dear Tania
>
> Without your dataset I am not sure but a comment below to suggest where
> to look next.
>
> On 24/09/2018 18:37, Tania Morgado Garcia wrote:
> > Thanks for your answers. I continue to learn R and now I am detained in
> an
> > error with uniroot that I see happens to others but I can not find the
> > solution. Next the code
> >
> > x1 <- BAaxOrd$V1
> > y1 <- BAaxOrd$V2
> > x1R <- BAaxOrdRCOS$V1
> > y1R <- BAaxOrdRCOS$V2
> > FCOS1 <- splinefun(smooth.spline(x1,y1))
> > FRCOS1 <- splinefun(smooth.spline(x1R,y1R))
> > FCOS1 <- Vectorize(FCOS1)
> > FRCOS1 <- Vectorize(FRCOS1)
> >
> > req(input$file1)
> >        tryCatch(
> >        {
> >          df <- read.csv(input$file1$datapath,
> >                         header = input$header,
> >                         sep = "\t",
> >                         quote = '"')
> >        },
> >        error = function(e) {
> >          # return a safeError if a parsing error occurs
> >          stop(safeError(e))
> >        }
> >      )
> >
> >      #if(input$disp == "head") {
> >       # return(head(df))
> >      #}
> >      #else {
> >
> >        # Determine Carbon Reserve
> >        for (row in 1:nrow(df)) {
> >          if(df$ts==1) {
> >             prof <-
> > uniroot(f=function(x){FCOS1(x1)-df$carbono},interval=c(0,20))$root
> >             limsup <- prof + df$pu
> >             reserva <- integrate(FRCOS1,prof,limsup)$value
> >          }
>
> Are you sure that FCOS(x1) - df$carbono returns a scalar? It looks as
> though it returns a vector to me but without your data I am not sure so
> ignore my post if it does.
> >
> > The if is because there are several types of soil, but I only put one.
> The
> > error is
> >
> > Warning in if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
> >    the condition has length > 1 and only the first element will be used
> > Warning in if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
> >    the condition has length > 1 and only the first element will be used
> > Warning: Error in uniroot: f() values at end points not of opposite sign
> >
> > The file that I load with data has a single row with the values ts = 1,
> > carbon = 2.04 and pu = 15 (I left only that row to be able to determine
> the
> > origin of the error). The functions FCOS1 and FRCOS1 are monotone
> > decreasing.Graphic attachment of FCOS1
> >
> > I would appreciate some help in this regard
> >
> > thanks a lot
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]



From |@co@t|g@n @end|ng |rom me@com  Wed Sep 26 07:10:47 2018
From: |@co@t|g@n @end|ng |rom me@com (Imanuel Costigan)
Date: Wed, 26 Sep 2018 15:10:47 +1000
Subject: [R] Odd R CMD build behaviour on Windows
References: <5D9D741F94C2FC498DE8D3CE76553DBEAB41D3CB@PWMXS0032.btfin.com>
Message-ID: <B2CCA9A8-BED4-4FCB-8EC7-F4F136EFD04B@me.com>

Hi all

I am finding that on Windows 10:

* the archive file produced by R (i386) CMD build command saves the resulting archive file in the present working directory 
* ...BUT the archive produced by the R (x64) CMD build command is **not** saved in the present working directory. Instead it is saved in the file path produced by `paste0(Sys.getenv("HOMEDRIVE"), Sys.getenv("HOMEPATH"))` or `Sys.getenv("HOMESHARE")` (the former resolves to H:\ which is an alias for the latter). This path is not represented in any other environment variables returned by Sys.getenv()

This behaviour persists for R-3.5.1 (release) and R-3.4.4. It also persists after I uninstall R and Rtools and then clean reinstall R-3.4.4 and R-3.5.1.

Has anyone else had this issue? Or tips on what might be causing this?

I am running these commands in Powershell using the following commands:

Thanks.

```
& 'C:\R\R-3.5.1\bin\x64\R.exe' --no-site-file --no-environ --no-save --no-restore --quiet CMD build "C:\users\XXXX\Coding\testpackage\" --no-resave-data --no-manual

# Archive is **not** saved in present working directory, but saved to H:\

& 'C:\R\R-3.5.1\bin\i386\R.exe' --no-site-file --no-environ --no-save --no-restore --quiet CMD build "C:\users\XXXX\Coding\testpackage\" --no-resave-data --no-manual

# Archive is saved in present working directory.
```



From |n|ojomy @end|ng |rom gm@||@com  Wed Sep 26 09:55:08 2018
From: |n|ojomy @end|ng |rom gm@||@com (Jomy Jose)
Date: Wed, 26 Sep 2018 13:25:08 +0530
Subject: [R] Accessing files from Linux Server
Message-ID: <CADGufDE=08FQzLGLssKZyuAEu0UcYhECpPXWMRUyktaEMFb1yg@mail.gmail.com>

Hi
Which R package can be best employed to access the files in Linux server

Thanks in advance
Jose

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 26 11:28:53 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 26 Sep 2018 10:28:53 +0100
Subject: [R] Accessing files from Linux Server
In-Reply-To: <CADGufDE=08FQzLGLssKZyuAEu0UcYhECpPXWMRUyktaEMFb1yg@mail.gmail.com>
References: <CADGufDE=08FQzLGLssKZyuAEu0UcYhECpPXWMRUyktaEMFb1yg@mail.gmail.com>
Message-ID: <a51da657-5107-52f3-bf3d-9e44037a0e90@sapo.pt>

Hello,

There are functions in base R to access files, you will need an external 
package only for special file types (such as, for instance, .xls or JSON).

At an R prompt type

?read.table
?readLines
?file
?scan

and start from there. I suggest you start with the first, it's the most 
used of all. And tghe first of those pages have links to their companion 
'write' versions.

There are also packages to read from the web.

Hope this helps,

Rui Barradas

?s 08:55 de 26/09/2018, Jomy Jose escreveu:
> Hi
> Which R package can be best employed to access the files in Linux server
> 
> Thanks in advance
> Jose
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From Anne@Ch@tton @end|ng |rom hcuge@ch  Wed Sep 26 10:42:56 2018
From: Anne@Ch@tton @end|ng |rom hcuge@ch (CHATTON Anne)
Date: Wed, 26 Sep 2018 08:42:56 +0000
Subject: [R] Problems to obtain standardized betas in multiply-imputed data
Message-ID: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>

Dear all,

I am having problems in obtaining standardized betas on a multiply-imputed data set. Here are the codes I used?:
imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
Up to here everything is fine. But when I ask for the standardized coefficients of the multiply-imputed regressions using this command?:
sdBeta <- lm.beta(FitImp)
I get the following error message: 
Error in b * sx : argument non num?rique pour un op?rateur binaire

Can anyone help me with this please?

Anne



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Wed Sep 26 16:00:08 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Wed, 26 Sep 2018 10:00:08 -0400
Subject: [R] Summarizing R script
In-Reply-To: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
Message-ID: <CAPQaxLMOTx+cOpxu+SO=k=BdiqaOjg+A8JkGQF+q-zsifN54tA@mail.gmail.com>

R users,

  Is anyone aware of the proper procedure for summarizing a script(your
complete list of functions, arguments , and error codes within your R
console for say a formal report or publication?

Many thanks,

Best wishes,

Spencer Brackett

---------- Forwarded message ---------
From: CHATTON Anne via R-help <r-help at r-project.org>
Date: Wed, Sep 26, 2018 at 6:03 AM
Subject: [R] Problems to obtain standardized betas in multiply-imputed data
To: r-help at r-project.org <r-help at r-project.org>


Dear all,

I am having problems in obtaining standardized betas on a multiply-imputed
data set. Here are the codes I used :
imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
Up to here everything is fine. But when I ask for the standardized
coefficients of the multiply-imputed regressions using this command :
sdBeta <- lm.beta(FitImp)
I get the following error message:
Error in b * sx : argument non num?rique pour un op?rateur binaire

Can anyone help me with this please?

Anne

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From rkoenker @end|ng |rom ||||no|@@edu  Wed Sep 26 16:06:31 2018
From: rkoenker @end|ng |rom ||||no|@@edu (Roger Koenker)
Date: Wed, 26 Sep 2018 15:06:31 +0100
Subject: [R] Summarizing R script
In-Reply-To: <f3b031553cdd468a8fe5da3b148b9564@CHIHT4.ad.uillinois.edu>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
 <f3b031553cdd468a8fe5da3b148b9564@CHIHT4.ad.uillinois.edu>
Message-ID: <62534FAE-2A72-4EBE-8A54-DFD5DF2F1964@illinois.edu>

I use R CMD BATCH foo which produces a file called foo.Rout and provided the script includes
sessionInfo() constitutes a quite sufficient summary for my purposes, it isn?t exactly pretty, but it
is informative.

> On Sep 26, 2018, at 3:00 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> 
> R users,
> 
>  Is anyone aware of the proper procedure for summarizing a script(your
> complete list of functions, arguments , and error codes within your R
> console for say a formal report or publication?
> 
> Many thanks,
> 
> Best wishes,
> 
> Spencer Brackett
> 
> ---------- Forwarded message ---------
> From: CHATTON Anne via R-help <r-help at r-project.org>
> Date: Wed, Sep 26, 2018 at 6:03 AM
> Subject: [R] Problems to obtain standardized betas in multiply-imputed data
> To: r-help at r-project.org <r-help at r-project.org>
> 
> 
> Dear all,
> 
> I am having problems in obtaining standardized betas on a multiply-imputed
> data set. Here are the codes I used :
> imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
> FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
> Up to here everything is fine. But when I ask for the standardized
> coefficients of the multiply-imputed regressions using this command :
> sdBeta <- lm.beta(FitImp)
> I get the following error message:
> Error in b * sx : argument non num?rique pour un op?rateur binaire
> 
> Can anyone help me with this please?
> 
> Anne
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Wed Sep 26 16:24:32 2018
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Wed, 26 Sep 2018 09:24:32 -0500
Subject: [R] Summarizing R script
In-Reply-To: <62534FAE-2A72-4EBE-8A54-DFD5DF2F1964@illinois.edu>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
 <f3b031553cdd468a8fe5da3b148b9564@CHIHT4.ad.uillinois.edu>
 <62534FAE-2A72-4EBE-8A54-DFD5DF2F1964@illinois.edu>
Message-ID: <5ec95596-5248-abf9-75fe-2cfba219874e@effectivedefense.org>



 ????? It depends on what you want, but I've found it very useful to 
create packages and submitting them to CRAN.? See "Creating R Packages" 
for how to do that.[1]? Part of this involves creating vignettes using 
Rmarkdown within RStudio.? Creating R packages and routinely running "R 
CMD check" sounds like it would take extra time.? My experience has been 
very much the opposite, because it dramatically reduces the bugs in my 
software and makes it vastly easier to find the bugs that still exist.? 
AND I have something I can just hand to others, and they can use it.? 
That would be exceedingly difficult otherwise.


 ????? And there are publications like "R Journal" that are looking for 
descriptions of what you've done.? I have a paper in "R Journal" 
describing the "sos" package;? that article is a vignette in that 
package.? This process has worked for me.[2]


 ?????? Spencer


[1] Available from help.start().? See also 
"https://cran.r-project.org/doc/manuals/r-release/R-exts.html".


[2] The "sos" package is the fastest literature search I know for 
anything statistical.? It's availability on CRAN combined with the R 
Journal article got me invited to help organize a plenary session on 
"Navigating the R Package Universe" at the useR!2017 conference in 
Brussels last year.? This is an example of how creating an R package 
with a vignette has helped me find an audience.


On 2018-09-26 09:06, Roger Koenker wrote:
> I use R CMD BATCH foo which produces a file called foo.Rout and provided the script includes
> sessionInfo() constitutes a quite sufficient summary for my purposes, it isn?t exactly pretty, but it
> is informative.
>
>> On Sep 26, 2018, at 3:00 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>>
>> R users,
>>
>>   Is anyone aware of the proper procedure for summarizing a script(your
>> complete list of functions, arguments , and error codes within your R
>> console for say a formal report or publication?
>>
>> Many thanks,
>>
>> Best wishes,
>>
>> Spencer Brackett
>>
>> ---------- Forwarded message ---------
>> From: CHATTON Anne via R-help <r-help at r-project.org>
>> Date: Wed, Sep 26, 2018 at 6:03 AM
>> Subject: [R] Problems to obtain standardized betas in multiply-imputed data
>> To: r-help at r-project.org <r-help at r-project.org>
>>
>>
>> Dear all,
>>
>> I am having problems in obtaining standardized betas on a multiply-imputed
>> data set. Here are the codes I used :
>> imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
>> FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
>> Up to here everything is fine. But when I ask for the standardized
>> coefficients of the multiply-imputed regressions using this command :
>> sdBeta <- lm.beta(FitImp)
>> I get the following error message:
>> Error in b * sx : argument non num?rique pour un op?rateur binaire
>>
>> Can anyone help me with this please?
>>
>> Anne
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep 26 17:28:50 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 26 Sep 2018 11:28:50 -0400
Subject: [R] Summarizing R script
In-Reply-To: <5ec95596-5248-abf9-75fe-2cfba219874e@effectivedefense.org>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
 <f3b031553cdd468a8fe5da3b148b9564@CHIHT4.ad.uillinois.edu>
 <62534FAE-2A72-4EBE-8A54-DFD5DF2F1964@illinois.edu>
 <5ec95596-5248-abf9-75fe-2cfba219874e@effectivedefense.org>
Message-ID: <3223af2d-e963-9607-8707-82c8d71dfc0f@gmail.com>

On 26/09/2018 10:24 AM, Spencer Graves wrote:
> 
> 
>   ????? It depends on what you want, but I've found it very useful to
> create packages and submitting them to CRAN.? See "Creating R Packages"
> for how to do that.[1]? Part of this involves creating vignettes using
> Rmarkdown within RStudio.? Creating R packages and routinely running "R
> CMD check" sounds like it would take extra time.? My experience has been
> very much the opposite, because it dramatically reduces the bugs in my
> software and makes it vastly easier to find the bugs that still exist.
> AND I have something I can just hand to others, and they can use it.
> That would be exceedingly difficult otherwise.

I think that's very good advice.  Even if the R script is something not 
suitable for publication on CRAN (containing proprietary data, or 
solving one unique problem, for example), preparing it as though for 
submission there enforces some good coding and documentation practices.

Duncan Murdoch

> 
> 
>   ????? And there are publications like "R Journal" that are looking for
> descriptions of what you've done.? I have a paper in "R Journal"
> describing the "sos" package;? that article is a vignette in that
> package.? This process has worked for me.[2]
> 
> 
>   ?????? Spencer
> 
> 
> [1] Available from help.start().? See also
> "https://cran.r-project.org/doc/manuals/r-release/R-exts.html".
> 
> 
> [2] The "sos" package is the fastest literature search I know for
> anything statistical.? It's availability on CRAN combined with the R
> Journal article got me invited to help organize a plenary session on
> "Navigating the R Package Universe" at the useR!2017 conference in
> Brussels last year.? This is an example of how creating an R package
> with a vignette has helped me find an audience.
> 
> 
> On 2018-09-26 09:06, Roger Koenker wrote:
>> I use R CMD BATCH foo which produces a file called foo.Rout and provided the script includes
>> sessionInfo() constitutes a quite sufficient summary for my purposes, it isn?t exactly pretty, but it
>> is informative.
>>
>>> On Sep 26, 2018, at 3:00 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>>>
>>> R users,
>>>
>>>    Is anyone aware of the proper procedure for summarizing a script(your
>>> complete list of functions, arguments , and error codes within your R
>>> console for say a formal report or publication?
>>>
>>> Many thanks,
>>>
>>> Best wishes,
>>>
>>> Spencer Brackett
>>>
>>> ---------- Forwarded message ---------
>>> From: CHATTON Anne via R-help <r-help at r-project.org>
>>> Date: Wed, Sep 26, 2018 at 6:03 AM
>>> Subject: [R] Problems to obtain standardized betas in multiply-imputed data
>>> To: r-help at r-project.org <r-help at r-project.org>
>>>
>>>
>>> Dear all,
>>>
>>> I am having problems in obtaining standardized betas on a multiply-imputed
>>> data set. Here are the codes I used :
>>> imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
>>> FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
>>> Up to here everything is fine. But when I ask for the standardized
>>> coefficients of the multiply-imputed regressions using this command :
>>> sdBeta <- lm.beta(FitImp)
>>> I get the following error message:
>>> Error in b * sx : argument non num?rique pour un op?rateur binaire
>>>
>>> Can anyone help me with this please?
>>>
>>> Anne
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From m@cqueen1 @end|ng |rom ||n|@gov  Wed Sep 26 17:38:37 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Wed, 26 Sep 2018 15:38:37 +0000
Subject: [R] Summarizing R script
In-Reply-To: <CAPQaxLMOTx+cOpxu+SO=k=BdiqaOjg+A8JkGQF+q-zsifN54tA@mail.gmail.com>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
 <CAPQaxLMOTx+cOpxu+SO=k=BdiqaOjg+A8JkGQF+q-zsifN54tA@mail.gmail.com>
Message-ID: <236B8DC2-5768-47DB-880C-9645E4F8E5C0@llnl.gov>

I wonder if the lintr package might be helpful.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/26/18, 7:00 AM, "R-help on behalf of Spencer Brackett" <r-help-bounces at r-project.org on behalf of spbrackett20 at saintjosephhs.com> wrote:

    R users,
    
      Is anyone aware of the proper procedure for summarizing a script(your
    complete list of functions, arguments , and error codes within your R
    console for say a formal report or publication?
    
    Many thanks,
    
    Best wishes,
    
    Spencer Brackett
    
    ---------- Forwarded message ---------
    From: CHATTON Anne via R-help <r-help at r-project.org>
    Date: Wed, Sep 26, 2018 at 6:03 AM
    Subject: [R] Problems to obtain standardized betas in multiply-imputed data
    To: r-help at r-project.org <r-help at r-project.org>
    
    
    Dear all,
    
    I am having problems in obtaining standardized betas on a multiply-imputed
    data set. Here are the codes I used :
    imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
    FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
    Up to here everything is fine. But when I ask for the standardized
    coefficients of the multiply-imputed regressions using this command :
    sdBeta <- lm.beta(FitImp)
    I get the following error message:
    Error in b * sx : argument non num?rique pour un op?rateur binaire
    
    Can anyone help me with this please?
    
    Anne
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 26 17:58:48 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 26 Sep 2018 08:58:48 -0700
Subject: [R] Summarizing R script
In-Reply-To: <236B8DC2-5768-47DB-880C-9645E4F8E5C0@llnl.gov>
References: <1b906c9b735b4d428ae528ef6609f74e@wexchprod08.huge.ad.hcuge.ch>
 <CAPQaxLMOTx+cOpxu+SO=k=BdiqaOjg+A8JkGQF+q-zsifN54tA@mail.gmail.com>
 <236B8DC2-5768-47DB-880C-9645E4F8E5C0@llnl.gov>
Message-ID: <CAGxFJbSan7ixPL_vuyxRcEPq49chPTSeVsD2AgGWZBcuyomrOQ@mail.gmail.com>

All suggestions made by others here are useful, but I would suggest that
computer scientists are probably a better -- or at least valuable
additional -- resource for this sort of knowledge than R programmers. A web
search on "self-documenting code" and/or "reproducible research" should
yield lots of relevant hits. For R specifically, the CRAN "Reproducible
Research" task view should be useful..

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 26, 2018 at 8:39 AM MacQueen, Don via R-help <
r-help at r-project.org> wrote:

> I wonder if the lintr package might be helpful.
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 9/26/18, 7:00 AM, "R-help on behalf of Spencer Brackett" <
> r-help-bounces at r-project.org on behalf of spbrackett20 at saintjosephhs.com>
> wrote:
>
>     R users,
>
>       Is anyone aware of the proper procedure for summarizing a script(your
>     complete list of functions, arguments , and error codes within your R
>     console for say a formal report or publication?
>
>     Many thanks,
>
>     Best wishes,
>
>     Spencer Brackett
>
>     ---------- Forwarded message ---------
>     From: CHATTON Anne via R-help <r-help at r-project.org>
>     Date: Wed, Sep 26, 2018 at 6:03 AM
>     Subject: [R] Problems to obtain standardized betas in multiply-imputed
> data
>     To: r-help at r-project.org <r-help at r-project.org>
>
>
>     Dear all,
>
>     I am having problems in obtaining standardized betas on a
> multiply-imputed
>     data set. Here are the codes I used :
>     imp = mice(data, 5, maxit=10, seed=42, print=FALSE)
>     FitImp <- with(imp,lm(y ~ x1 + x2 + x3))
>     Up to here everything is fine. But when I ask for the standardized
>     coefficients of the multiply-imputed regressions using this command :
>     sdBeta <- lm.beta(FitImp)
>     I get the following error message:
>     Error in b * sx : argument non num?rique pour un op?rateur binaire
>
>     Can anyone help me with this please?
>
>     Anne
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Wed Sep 26 22:16:33 2018
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Wed, 26 Sep 2018 15:16:33 -0500
Subject: [R] using S4 objects in "with"?
Message-ID: <d943cdd7-d0ea-9d55-7831-9f89db45b66b@effectivedefense.org>

 ????? Is there anything comparable to "with" for S4 objects?


EXAMPLE:


 ????? A "Wave" object in the tuneR package has slots "left" and 
"right", plus others.? I'd like to be able to do something like the 
following:


library(tuneR)
x <- seq(0, 2*pi, length = 6)
all.equal(x, rev(x))
channel <- round(32000 * sin(440 * x))
Wobj <- Wave(left = channel, right=rev(channel))

with(Wobj, quantile(left-right))


 ????? ** This last statement throws "Error ... object 'left' not found".


 ????? Is there something comparable to "with" that can do this?


 ????? Thanks,
 ????? Spencer Graves



From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep 26 22:34:46 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 26 Sep 2018 16:34:46 -0400
Subject: [R] using S4 objects in "with"?
In-Reply-To: <d943cdd7-d0ea-9d55-7831-9f89db45b66b@effectivedefense.org>
References: <d943cdd7-d0ea-9d55-7831-9f89db45b66b@effectivedefense.org>
Message-ID: <4d6f033e-3929-3648-a408-55c78f29a9bc@gmail.com>

On 26/09/2018 4:16 PM, Spencer Graves wrote:
>   ????? Is there anything comparable to "with" for S4 objects?
> 
> 
> EXAMPLE:
> 
> 
>   ????? A "Wave" object in the tuneR package has slots "left" and
> "right", plus others.? I'd like to be able to do something like the
> following:
> 
> 
> library(tuneR)
> x <- seq(0, 2*pi, length = 6)
> all.equal(x, rev(x))
> channel <- round(32000 * sin(440 * x))
> Wobj <- Wave(left = channel, right=rev(channel))
> 
> with(Wobj, quantile(left-right))
> 
> 
>   ????? ** This last statement throws "Error ... object 'left' not found".
> 
> 
>   ????? Is there something comparable to "with" that can do this?

I don't know of anything that is "officially sanctioned".  A couple of 
ideas:

1.  Slots in S4 are stored in attributes.  So

   with(attributes(Wobj), quantile(left - right))

works.  BUT:  as far as I recall, this is an undocumented implementation 
detail, and you aren't supposed to count on it.

2.  You could write an as.list() method for the Wave class, then

   with(as.list(Wobj),

would work.  This may be the "right" way to do this.

Duncan Murdoch



From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Wed Sep 26 23:23:17 2018
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Wed, 26 Sep 2018 16:23:17 -0500
Subject: [R] using S4 objects in "with"?
In-Reply-To: <4d6f033e-3929-3648-a408-55c78f29a9bc@gmail.com>
References: <d943cdd7-d0ea-9d55-7831-9f89db45b66b@effectivedefense.org>
 <4d6f033e-3929-3648-a408-55c78f29a9bc@gmail.com>
Message-ID: <243b9ca4-10f9-b331-841b-6d4c69677559@effectivedefense.org>



On 2018-09-26 15:34, Duncan Murdoch wrote:
> On 26/09/2018 4:16 PM, Spencer Graves wrote:
>> ? ????? Is there anything comparable to "with" for S4 objects?
>>
>>
>> EXAMPLE:
>>
>>
>> ? ????? A "Wave" object in the tuneR package has slots "left" and
>> "right", plus others.? I'd like to be able to do something like the
>> following:
>>
>>
>> library(tuneR)
>> x <- seq(0, 2*pi, length = 6)
>> all.equal(x, rev(x))
>> channel <- round(32000 * sin(440 * x))
>> Wobj <- Wave(left = channel, right=rev(channel))
>>
>> with(Wobj, quantile(left-right))
>>
>>
>> ? ????? ** This last statement throws "Error ... object 'left' not 
>> found".
>>
>>
>> ? ????? Is there something comparable to "with" that can do this?
>
> I don't know of anything that is "officially sanctioned".? A couple of 
> ideas:
>
> 1.? Slots in S4 are stored in attributes.? So
>
> ? with(attributes(Wobj), quantile(left - right))
>
> works.? BUT:? as far as I recall, this is an undocumented 
> implementation detail, and you aren't supposed to count on it.
>
> 2.? You could write an as.list() method for the Wave class, then
>
> ? with(as.list(Wobj),
>
> would work.? This may be the "right" way to do this.


 ????? Thanks.? I'd prefer to have as.list.default convert every S4 
object to a list.? And have with(S4_object, ...) interpret it equivalent 
to with(as.list(S4_object), ...).


 ????? I think I'll do it other ways for the time being.


 ????? Best Wishes,
 ????? Spencer

>
> Duncan Murdoch



From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 27 09:28:49 2018
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 27 Sep 2018 09:28:49 +0200
Subject: [R] Erase content of dataframe in a single stroke
Message-ID: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>

Dear all,
I would like to erase the content of a dataframe -- but not the
dataframe itself -- in a simple and fast way.
At the moment I do that by re-defining the dataframe itself in this way:

> df <- data.frame(A = numeric(),
+                   B = numeric(),
+                   C = character())
> # assign
> A <- 5
> B <- 0.6
> C <- 103
> # load
> R <- cbind(A, B, C)
> df <- rbind(df, R)
> df
  A   B   C
1 5 0.6 103
> # erase
> df <- data.frame(A = numeric(),
+                  B = numeric(),
+                  C = character())
> df
[1] A B C
<0 rows> (or 0-length row.names)
>

Is there a way to erase the content of the dataframe in a simplier
(acting on all the dataframe at once instead of naming each column
individually) and nicer (with a specific erasure command instead of
re-defyining the object itself) way?

Thank you.
-- 
Best regards,
Luigi



From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 27 09:44:52 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 27 Sep 2018 17:44:52 +1000
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
Message-ID: <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>

Hi Luigi,
Maybe this:

testdf<-data.frame(A=1,B=2,C=3)
> testdf
 A B C
1 1 2 3
toNull<-function(x) return(NULL)
testdf<-sapply(testdf,toNull)

Jim
On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I would like to erase the content of a dataframe -- but not the
> dataframe itself -- in a simple and fast way.
> At the moment I do that by re-defining the dataframe itself in this way:
>
> > df <- data.frame(A = numeric(),
> +                   B = numeric(),
> +                   C = character())
> > # assign
> > A <- 5
> > B <- 0.6
> > C <- 103
> > # load
> > R <- cbind(A, B, C)
> > df <- rbind(df, R)
> > df
>   A   B   C
> 1 5 0.6 103
> > # erase
> > df <- data.frame(A = numeric(),
> +                  B = numeric(),
> +                  C = character())
> > df
> [1] A B C
> <0 rows> (or 0-length row.names)
> >
>
> Is there a way to erase the content of the dataframe in a simplier
> (acting on all the dataframe at once instead of naming each column
> individually) and nicer (with a specific erasure command instead of
> re-defyining the object itself) way?
>
> Thank you.
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 27 10:12:11 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 27 Sep 2018 18:12:11 +1000
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
Message-ID: <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>

Ah, yes, try 'as.data.frame" on it.

Jim

On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Thank you Jim,
> this requires the definition of an ad hoc function; strange that R
> does not have a function for this purpose...
> Anyway, it works but it changes the structure of the data. By
> redefining the dataframe as I did, I obtain:
>
> > df
> [1] A B C
> <0 rows> (or 0-length row.names)
> > str(df)
> 'data.frame': 0 obs. of  3 variables:
>  $ A: num
>  $ B: num
>  $ C: num
>
> When applying your function, I get:
>
> > df
> $A
> NULL
>
> $B
> NULL
>
> $C
> NULL
>
> > str(df)
> List of 3
>  $ A: NULL
>  $ B: NULL
>  $ C: NULL
>
> The dataframe has become a list. Would that affect downstream applications?
>
> Thank you,
> Luigi
> On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Luigi,
> > Maybe this:
> >
> > testdf<-data.frame(A=1,B=2,C=3)
> > > testdf
> >  A B C
> > 1 1 2 3
> > toNull<-function(x) return(NULL)
> > testdf<-sapply(testdf,toNull)
> >
> > Jim
> > On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Dear all,
> > > I would like to erase the content of a dataframe -- but not the
> > > dataframe itself -- in a simple and fast way.
> > > At the moment I do that by re-defining the dataframe itself in this way:
> > >
> > > > df <- data.frame(A = numeric(),
> > > +                   B = numeric(),
> > > +                   C = character())
> > > > # assign
> > > > A <- 5
> > > > B <- 0.6
> > > > C <- 103
> > > > # load
> > > > R <- cbind(A, B, C)
> > > > df <- rbind(df, R)
> > > > df
> > >   A   B   C
> > > 1 5 0.6 103
> > > > # erase
> > > > df <- data.frame(A = numeric(),
> > > +                  B = numeric(),
> > > +                  C = character())
> > > > df
> > > [1] A B C
> > > <0 rows> (or 0-length row.names)
> > > >
> > >
> > > Is there a way to erase the content of the dataframe in a simplier
> > > (acting on all the dataframe at once instead of naming each column
> > > individually) and nicer (with a specific erasure command instead of
> > > re-defyining the object itself) way?
> > >
> > > Thank you.
> > > --
> > > Best regards,
> > > Luigi
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi



From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep 27 10:32:51 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 27 Sep 2018 08:32:51 +0000
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
 <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
Message-ID: <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>

Hm

I would use

> testdf<-data.frame(A=c(1,2),B=c(2,3),C=c(3,4))
> str(testdf)
'data.frame':   2 obs. of  3 variables:
 $ A: num  1 2
 $ B: num  2 3
 $ C: num  3 4
> testdf<-testdf[-(1:nrow(testdf)),]
> str(testdf)
'data.frame':   0 obs. of  3 variables:
 $ A: num
 $ B: num
 $ C: num

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
> Sent: Thursday, September 27, 2018 10:12 AM
> To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help mailing list <r-help at r-
> project.org>
> Subject: Re: [R] Erase content of dataframe in a single stroke
>
> Ah, yes, try 'as.data.frame" on it.
>
> Jim
>
> On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >
> > Thank you Jim,
> > this requires the definition of an ad hoc function; strange that R
> > does not have a function for this purpose...
> > Anyway, it works but it changes the structure of the data. By
> > redefining the dataframe as I did, I obtain:
> >
> > > df
> > [1] A B C
> > <0 rows> (or 0-length row.names)
> > > str(df)
> > 'data.frame': 0 obs. of  3 variables:
> >  $ A: num
> >  $ B: num
> >  $ C: num
> >
> > When applying your function, I get:
> >
> > > df
> > $A
> > NULL
> >
> > $B
> > NULL
> >
> > $C
> > NULL
> >
> > > str(df)
> > List of 3
> >  $ A: NULL
> >  $ B: NULL
> >  $ C: NULL
> >
> > The dataframe has become a list. Would that affect downstream
> applications?
> >
> > Thank you,
> > Luigi
> > On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com>
> wrote:
> > >
> > > Hi Luigi,
> > > Maybe this:
> > >
> > > testdf<-data.frame(A=1,B=2,C=3)
> > > > testdf
> > >  A B C
> > > 1 1 2 3
> > > toNull<-function(x) return(NULL)
> > > testdf<-sapply(testdf,toNull)
> > >
> > > Jim
> > > On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu
> <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Dear all,
> > > > I would like to erase the content of a dataframe -- but not the
> > > > dataframe itself -- in a simple and fast way.
> > > > At the moment I do that by re-defining the dataframe itself in this way:
> > > >
> > > > > df <- data.frame(A = numeric(),
> > > > +                   B = numeric(),
> > > > +                   C = character())
> > > > > # assign
> > > > > A <- 5
> > > > > B <- 0.6
> > > > > C <- 103
> > > > > # load
> > > > > R <- cbind(A, B, C)
> > > > > df <- rbind(df, R)
> > > > > df
> > > >   A   B   C
> > > > 1 5 0.6 103
> > > > > # erase
> > > > > df <- data.frame(A = numeric(),
> > > > +                  B = numeric(),
> > > > +                  C = character())
> > > > > df
> > > > [1] A B C
> > > > <0 rows> (or 0-length row.names)
> > > > >
> > > >
> > > > Is there a way to erase the content of the dataframe in a simplier
> > > > (acting on all the dataframe at once instead of naming each column
> > > > individually) and nicer (with a specific erasure command instead
> > > > of re-defyining the object itself) way?
> > > >
> > > > Thank you.
> > > > --
> > > > Best regards,
> > > > Luigi
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 27 10:36:13 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 27 Sep 2018 18:36:13 +1000
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <CAMk+s2QCa8PTkBgzQgkVX06o8O1_jbW-bLHOJ6Bze383bhgK7A@mail.gmail.com>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
 <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
 <CAMk+s2QCa8PTkBgzQgkVX06o8O1_jbW-bLHOJ6Bze383bhgK7A@mail.gmail.com>
Message-ID: <CA+8X3fUqu6a_si7F5PZnPBE-snG0rXx_nSoAR=NgEuiekuHURA@mail.gmail.com>

You're right. Apparently one can form a list with NULL elements but
not a data frame. I just saw Petr's answer, which seems to do the
trick.

Jim
On Thu, Sep 27, 2018 at 6:19 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> I am not sure if I got it right; Now I get:
>
> >  toNull<-function(x) return(NULL)
> >  df<-as.data.frame(sapply(df,toNull))
> >  df
> data frame with 0 columns and 0 rows
> >  str(df)
> 'data.frame': 0 obs. of  0 variables
> On Thu, Sep 27, 2018 at 10:12 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Ah, yes, try 'as.data.frame" on it.
> >
> > Jim
> >
> > On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Thank you Jim,
> > > this requires the definition of an ad hoc function; strange that R
> > > does not have a function for this purpose...
> > > Anyway, it works but it changes the structure of the data. By
> > > redefining the dataframe as I did, I obtain:
> > >
> > > > df
> > > [1] A B C
> > > <0 rows> (or 0-length row.names)
> > > > str(df)
> > > 'data.frame': 0 obs. of  3 variables:
> > >  $ A: num
> > >  $ B: num
> > >  $ C: num
> > >
> > > When applying your function, I get:
> > >
> > > > df
> > > $A
> > > NULL
> > >
> > > $B
> > > NULL
> > >
> > > $C
> > > NULL
> > >
> > > > str(df)
> > > List of 3
> > >  $ A: NULL
> > >  $ B: NULL
> > >  $ C: NULL
> > >
> > > The dataframe has become a list. Would that affect downstream applications?
> > >
> > > Thank you,
> > > Luigi
> > > On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > >
> > > > Hi Luigi,
> > > > Maybe this:
> > > >
> > > > testdf<-data.frame(A=1,B=2,C=3)
> > > > > testdf
> > > >  A B C
> > > > 1 1 2 3
> > > > toNull<-function(x) return(NULL)
> > > > testdf<-sapply(testdf,toNull)
> > > >
> > > > Jim
> > > > On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > > >
> > > > > Dear all,
> > > > > I would like to erase the content of a dataframe -- but not the
> > > > > dataframe itself -- in a simple and fast way.
> > > > > At the moment I do that by re-defining the dataframe itself in this way:
> > > > >
> > > > > > df <- data.frame(A = numeric(),
> > > > > +                   B = numeric(),
> > > > > +                   C = character())
> > > > > > # assign
> > > > > > A <- 5
> > > > > > B <- 0.6
> > > > > > C <- 103
> > > > > > # load
> > > > > > R <- cbind(A, B, C)
> > > > > > df <- rbind(df, R)
> > > > > > df
> > > > >   A   B   C
> > > > > 1 5 0.6 103
> > > > > > # erase
> > > > > > df <- data.frame(A = numeric(),
> > > > > +                  B = numeric(),
> > > > > +                  C = character())
> > > > > > df
> > > > > [1] A B C
> > > > > <0 rows> (or 0-length row.names)
> > > > > >
> > > > >
> > > > > Is there a way to erase the content of the dataframe in a simplier
> > > > > (acting on all the dataframe at once instead of naming each column
> > > > > individually) and nicer (with a specific erasure command instead of
> > > > > re-defyining the object itself) way?
> > > > >
> > > > > Thank you.
> > > > > --
> > > > > Best regards,
> > > > > Luigi
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
>
>
>
> --
> Best regards,
> Luigi



From rhe|p @end|ng |rom eoo@@dd@@n|  Thu Sep 27 11:11:00 2018
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Thu, 27 Sep 2018 11:11:00 +0200
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
 <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
 <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>
Message-ID: <5BAC9EA4.50504@eoos.dds.nl>

Or

testdf <- testdf[FALSE, ]

or

testdf <- testdf[numeric(0), ]

which seems to be slightly faster.

Best,
Jan


Op 27-9-2018 om 10:32 schreef PIKAL Petr:
> Hm
>
> I would use
>
>> testdf<-data.frame(A=c(1,2),B=c(2,3),C=c(3,4))
>> str(testdf)
> 'data.frame':   2 obs. of  3 variables:
>   $ A: num  1 2
>   $ B: num  2 3
>   $ C: num  3 4
>> testdf<-testdf[-(1:nrow(testdf)),]
>> str(testdf)
> 'data.frame':   0 obs. of  3 variables:
>   $ A: num
>   $ B: num
>   $ C: num
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
>> Sent: Thursday, September 27, 2018 10:12 AM
>> To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help mailing list <r-help at r-
>> project.org>
>> Subject: Re: [R] Erase content of dataframe in a single stroke
>>
>> Ah, yes, try 'as.data.frame" on it.
>>
>> Jim
>>
>> On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu <marongiu.luigi at gmail.com>
>> wrote:
>>> Thank you Jim,
>>> this requires the definition of an ad hoc function; strange that R
>>> does not have a function for this purpose...
>>> Anyway, it works but it changes the structure of the data. By
>>> redefining the dataframe as I did, I obtain:
>>>
>>>> df
>>> [1] A B C
>>> <0 rows> (or 0-length row.names)
>>>> str(df)
>>> 'data.frame': 0 obs. of  3 variables:
>>>   $ A: num
>>>   $ B: num
>>>   $ C: num
>>>
>>> When applying your function, I get:
>>>
>>>> df
>>> $A
>>> NULL
>>>
>>> $B
>>> NULL
>>>
>>> $C
>>> NULL
>>>
>>>> str(df)
>>> List of 3
>>>   $ A: NULL
>>>   $ B: NULL
>>>   $ C: NULL
>>>
>>> The dataframe has become a list. Would that affect downstream
>> applications?
>>> Thank you,
>>> Luigi
>>> On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>>>> Hi Luigi,
>>>> Maybe this:
>>>>
>>>> testdf<-data.frame(A=1,B=2,C=3)
>>>>> testdf
>>>>   A B C
>>>> 1 1 2 3
>>>> toNull<-function(x) return(NULL)
>>>> testdf<-sapply(testdf,toNull)
>>>>
>>>> Jim
>>>> On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu
>> <marongiu.luigi at gmail.com> wrote:
>>>>> Dear all,
>>>>> I would like to erase the content of a dataframe -- but not the
>>>>> dataframe itself -- in a simple and fast way.
>>>>> At the moment I do that by re-defining the dataframe itself in this way:
>>>>>
>>>>>> df <- data.frame(A = numeric(),
>>>>> +                   B = numeric(),
>>>>> +                   C = character())
>>>>>> # assign
>>>>>> A <- 5
>>>>>> B <- 0.6
>>>>>> C <- 103
>>>>>> # load
>>>>>> R <- cbind(A, B, C)
>>>>>> df <- rbind(df, R)
>>>>>> df
>>>>>    A   B   C
>>>>> 1 5 0.6 103
>>>>>> # erase
>>>>>> df <- data.frame(A = numeric(),
>>>>> +                  B = numeric(),
>>>>> +                  C = character())
>>>>>> df
>>>>> [1] A B C
>>>>> <0 rows> (or 0-length row.names)
>>>>> Is there a way to erase the content of the dataframe in a simplier
>>>>> (acting on all the dataframe at once instead of naming each column
>>>>> individually) and nicer (with a specific erasure command instead
>>>>> of re-defyining the object itself) way?
>>>>>
>>>>> Thank you.
>>>>> --
>>>>> Best regards,
>>>>> Luigi
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> --
>>> Best regards,
>>> Luigi
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From proi@@mit@mitt@i m@iii@g oii gm@ii@com  Thu Sep 27 11:46:33 2018
From: proi@@mit@mitt@i m@iii@g oii gm@ii@com (proi@@mit@mitt@i m@iii@g oii gm@ii@com)
Date: Thu, 27 Sep 2018 15:16:33 +0530
Subject: [R] Erase content of data.frame in a single stroke
Message-ID: <009301d45646$fe3b5df0$fab219d0$@gmail.com>


I never bother with the dimensions of a data frame . That way you can assign
a new var before a for and auto assign it columns inside or nullify the
whole df instead of separate columns?

BR
-----Original Message-----
From: R-help <> On Behalf Of Jim Lemon
Sent: Thursday, September 27, 2018 2:06 PM
To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help mailing list
<r-help at r-project.org>
Subject: Re: [R] Erase content of dataframe in a single stroke

You're right. Apparently one can form a list with NULL elements but not a
data frame. I just saw Petr's answer, which seems to do the trick.

Jim
On Thu, Sep 27, 2018 at 6:19 PM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:
>
> I am not sure if I got it right; Now I get:
>
> >  toNull<-function(x) return(NULL)
> >  df<-as.data.frame(sapply(df,toNull))
> >  df
> data frame with 0 columns and 0 rows
> >  str(df)
> 'data.frame': 0 obs. of  0 variables
> On Thu, Sep 27, 2018 at 10:12 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Ah, yes, try 'as.data.frame" on it.
> >
> > Jim
> >
> > On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> > >
> > > Thank you Jim,
> > > this requires the definition of an ad hoc function; strange that R 
> > > does not have a function for this purpose...
> > > Anyway, it works but it changes the structure of the data. By 
> > > redefining the dataframe as I did, I obtain:
> > >
> > > > df
> > > [1] A B C
> > > <0 rows> (or 0-length row.names)
> > > > str(df)
> > > 'data.frame': 0 obs. of  3 variables:
> > >  $ A: num
> > >  $ B: num
> > >  $ C: num
> > >
> > > When applying your function, I get:
> > >
> > > > df
> > > $A
> > > NULL
> > >
> > > $B
> > > NULL
> > >
> > > $C
> > > NULL
> > >
> > > > str(df)
> > > List of 3
> > >  $ A: NULL
> > >  $ B: NULL
> > >  $ C: NULL
> > >
> > > The dataframe has become a list. Would that affect downstream
applications?
> > >
> > > Thank you,
> > > Luigi
> > > On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com>
wrote:
> > > >
> > > > Hi Luigi,
> > > > Maybe this:
> > > >
> > > > testdf<-data.frame(A=1,B=2,C=3)
> > > > > testdf
> > > >  A B C
> > > > 1 1 2 3
> > > > toNull<-function(x) return(NULL)
> > > > testdf<-sapply(testdf,toNull)
> > > >
> > > > Jim
> > > > On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> > > > >
> > > > > Dear all,
> > > > > I would like to erase the content of a dataframe -- but not 
> > > > > the dataframe itself -- in a simple and fast way.
> > > > > At the moment I do that by re-defining the dataframe itself in
this way:
> > > > >
> > > > > > df <- data.frame(A = numeric(),
> > > > > +                   B = numeric(),
> > > > > +                   C = character())
> > > > > > # assign
> > > > > > A <- 5
> > > > > > B <- 0.6
> > > > > > C <- 103
> > > > > > # load
> > > > > > R <- cbind(A, B, C)
> > > > > > df <- rbind(df, R)
> > > > > > df
> > > > >   A   B   C
> > > > > 1 5 0.6 103
> > > > > > # erase
> > > > > > df <- data.frame(A = numeric(),
> > > > > +                  B = numeric(),
> > > > > +                  C = character())
> > > > > > df
> > > > > [1] A B C
> > > > > <0 rows> (or 0-length row.names)
> > > > > >
> > > > >
> > > > > Is there a way to erase the content of the dataframe in a 
> > > > > simplier (acting on all the dataframe at once instead of 
> > > > > naming each column
> > > > > individually) and nicer (with a specific erasure command 
> > > > > instead of re-defyining the object itself) way?
> > > > >
> > > > > Thank you.
> > > > > --
> > > > > Best regards,
> > > > > Luigi
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, 
> > > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide 
> > > > > http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
>
>
>
> --
> Best regards,
> Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From toth@dene@ @end|ng |rom kogentum@hu  Thu Sep 27 12:12:59 2018
From: toth@dene@ @end|ng |rom kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Thu, 27 Sep 2018 12:12:59 +0200
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <5BAC9EA4.50504@eoos.dds.nl>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
 <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
 <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>
 <5BAC9EA4.50504@eoos.dds.nl>
Message-ID: <8c1520f7-3ba9-9e39-aae6-9db682a9024f@kogentum.hu>

Hi Luigi,

Actually I doubt that the original problem you try to solve requires the 
initialization of an empty data.frame with a particular structure. 
However, if you think you really need this step, I would write a 
function for it and also consider edge cases.

getSkeleton <- function(x, drop_levels = FALSE) {
   out <- x[numeric(0L), , drop = FALSE]
   if (isTRUE(drop_levels)) out <- droplevels(out)
   out
}

Note that it retains or drops factor levels depending on 'drop_levels'. 
It only matters if you have factors in your data.frame.
'drop = FALSE' is required to guard against silent conversion to a 
vector if 'x' has only one column.

Regards,
Denes



On 09/27/2018 11:11 AM, Jan van der Laan wrote:
> Or
> 
> testdf <- testdf[FALSE, ]
> 
> or
> 
> testdf <- testdf[numeric(0), ]
> 
> which seems to be slightly faster.
> 
> Best,
> Jan
> 
> 
> Op 27-9-2018 om 10:32 schreef PIKAL Petr:
>> Hm
>>
>> I would use
>>
>>> testdf<-data.frame(A=c(1,2),B=c(2,3),C=c(3,4))
>>> str(testdf)
>> 'data.frame':   2 obs. of  3 variables:
>>   $ A: num  1 2
>>   $ B: num  2 3
>>   $ C: num  3 4
>>> testdf<-testdf[-(1:nrow(testdf)),]
>>> str(testdf)
>> 'data.frame':   0 obs. of  3 variables:
>>   $ A: num
>>   $ B: num
>>   $ C: num
>>
>> Cheers
>> Petr
>>
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
>>> Sent: Thursday, September 27, 2018 10:12 AM
>>> To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help mailing list 
>>> <r-help at r-
>>> project.org>
>>> Subject: Re: [R] Erase content of dataframe in a single stroke
>>>
>>> Ah, yes, try 'as.data.frame" on it.
>>>
>>> Jim
>>>
>>> On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu 
>>> <marongiu.luigi at gmail.com>
>>> wrote:
>>>> Thank you Jim,
>>>> this requires the definition of an ad hoc function; strange that R
>>>> does not have a function for this purpose...
>>>> Anyway, it works but it changes the structure of the data. By
>>>> redefining the dataframe as I did, I obtain:
>>>>
>>>>> df
>>>> [1] A B C
>>>> <0 rows> (or 0-length row.names)
>>>>> str(df)
>>>> 'data.frame': 0 obs. of  3 variables:
>>>>   $ A: num
>>>>   $ B: num
>>>>   $ C: num
>>>>
>>>> When applying your function, I get:
>>>>
>>>>> df
>>>> $A
>>>> NULL
>>>>
>>>> $B
>>>> NULL
>>>>
>>>> $C
>>>> NULL
>>>>
>>>>> str(df)
>>>> List of 3
>>>>   $ A: NULL
>>>>   $ B: NULL
>>>>   $ C: NULL
>>>>
>>>> The dataframe has become a list. Would that affect downstream
>>> applications?
>>>> Thank you,
>>>> Luigi
>>>> On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>>>> Hi Luigi,
>>>>> Maybe this:
>>>>>
>>>>> testdf<-data.frame(A=1,B=2,C=3)
>>>>>> testdf
>>>>>   A B C
>>>>> 1 1 2 3
>>>>> toNull<-function(x) return(NULL)
>>>>> testdf<-sapply(testdf,toNull)
>>>>>
>>>>> Jim
>>>>> On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu
>>> <marongiu.luigi at gmail.com> wrote:
>>>>>> Dear all,
>>>>>> I would like to erase the content of a dataframe -- but not the
>>>>>> dataframe itself -- in a simple and fast way.
>>>>>> At the moment I do that by re-defining the dataframe itself in 
>>>>>> this way:
>>>>>>
>>>>>>> df <- data.frame(A = numeric(),
>>>>>> +                   B = numeric(),
>>>>>> +                   C = character())
>>>>>>> # assign
>>>>>>> A <- 5
>>>>>>> B <- 0.6
>>>>>>> C <- 103
>>>>>>> # load
>>>>>>> R <- cbind(A, B, C)
>>>>>>> df <- rbind(df, R)
>>>>>>> df
>>>>>>    A   B   C
>>>>>> 1 5 0.6 103
>>>>>>> # erase
>>>>>>> df <- data.frame(A = numeric(),
>>>>>> +                  B = numeric(),
>>>>>> +                  C = character())
>>>>>>> df
>>>>>> [1] A B C
>>>>>> <0 rows> (or 0-length row.names)
>>>>>> Is there a way to erase the content of the dataframe in a simplier
>>>>>> (acting on all the dataframe at once instead of naming each column
>>>>>> individually) and nicer (with a specific erasure command instead
>>>>>> of re-defyining the object itself) way?
>>>>>>
>>>>>> Thank you.
>>>>>> -- 
>>>>>> Best regards,
>>>>>> Luigi
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>> -- 
>>>> Best regards,
>>>> Luigi
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? 
>> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: 
>> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information 
>> about processing and protection of business partner?s personal data 
>> are available on website: 
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou 
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? 
>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any 
>> documents attached to it may be confidential and are subject to the 
>> legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Thu Sep 27 12:30:39 2018
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Thu, 27 Sep 2018 12:30:39 +0200
Subject: [R] Access function as text from package by name
Message-ID: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>

Hi,

I want to have a function, e.g. graphics::box, as text.
Currently I'am using

deparse(eval(parse(text='graphics::box')))

It is important that '::' and ':::' can be used in the name.

Is there a simpler way?

Thanks

Sigbert

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 27 13:55:29 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 27 Sep 2018 12:55:29 +0100
Subject: [R] Access function as text from package by name
In-Reply-To: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
Message-ID: <8514c9d8-9849-b17a-3358-343d1e616d45@sapo.pt>

Hello,

Maybe

capture.output(graphics::box)


Hope this helps,

Rui Barradas

?s 11:30 de 27/09/2018, Sigbert Klinke escreveu:
> Hi,
> 
> I want to have a function, e.g. graphics::box, as text.
> Currently I'am using
> 
> deparse(eval(parse(text='graphics::box')))
> 
> It is important that '::' and ':::' can be used in the name.
> 
> Is there a simpler way?
> 
> Thanks
> 
> Sigbert
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From pd@|gd @end|ng |rom gm@||@com  Thu Sep 27 14:04:02 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 27 Sep 2018 14:04:02 +0200
Subject: [R] Erase content of dataframe in a single stroke
In-Reply-To: <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>
References: <CAMk+s2T4=T2F4NbLHMUR-7Vu4YDqjNpBFDc5F3f3PMaiK9X_6w@mail.gmail.com>
 <CA+8X3fUT8aDAcuxxmzzOnOxwhfS9Ejvj7N8xpta+fcFyVkVMAQ@mail.gmail.com>
 <CAMk+s2QXgSgX6xxsOfd3jOBWkN8X1Tg-7wTzkBPi+j6FJixCNg@mail.gmail.com>
 <CA+8X3fWTDpRzJEKpGDPFYx78DKQS+5i6hJFS0-p7BFxLKRyRSA@mail.gmail.com>
 <ad5449a19a544e1f8359fdb2fd8c9ca4@SRVEXCHCM1301.precheza.cz>
Message-ID: <6766997C-5387-4985-B17C-AA49CC1078FA@gmail.com>

Variations on the same theme:

> testdf<-data.frame(A=c(1,2),B=c(2,3),C=c(3,4))
> testdf[0,]
[1] A B C
<0 rows> (or 0-length row.names)
> testdf[FALSE,]
[1] A B C
<0 rows> (or 0-length row.names)
> testdf[integer(0),]
[1] A B C
<0 rows> (or 0-length row.names)
> testdf[NULL,]
[1] A B C
<0 rows> (or 0-length row.names)

-pd

> On 27 Sep 2018, at 10:32 , PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Hm
> 
> I would use
> 
>> testdf<-data.frame(A=c(1,2),B=c(2,3),C=c(3,4))
>> str(testdf)
> 'data.frame':   2 obs. of  3 variables:
> $ A: num  1 2
> $ B: num  2 3
> $ C: num  3 4
>> testdf<-testdf[-(1:nrow(testdf)),]
>> str(testdf)
> 'data.frame':   0 obs. of  3 variables:
> $ A: num
> $ B: num
> $ C: num
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
>> Sent: Thursday, September 27, 2018 10:12 AM
>> To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help mailing list <r-help at r-
>> project.org>
>> Subject: Re: [R] Erase content of dataframe in a single stroke
>> 
>> Ah, yes, try 'as.data.frame" on it.
>> 
>> Jim
>> 
>> On Thu, Sep 27, 2018 at 6:00 PM Luigi Marongiu <marongiu.luigi at gmail.com>
>> wrote:
>>> 
>>> Thank you Jim,
>>> this requires the definition of an ad hoc function; strange that R
>>> does not have a function for this purpose...
>>> Anyway, it works but it changes the structure of the data. By
>>> redefining the dataframe as I did, I obtain:
>>> 
>>>> df
>>> [1] A B C
>>> <0 rows> (or 0-length row.names)
>>>> str(df)
>>> 'data.frame': 0 obs. of  3 variables:
>>> $ A: num
>>> $ B: num
>>> $ C: num
>>> 
>>> When applying your function, I get:
>>> 
>>>> df
>>> $A
>>> NULL
>>> 
>>> $B
>>> NULL
>>> 
>>> $C
>>> NULL
>>> 
>>>> str(df)
>>> List of 3
>>> $ A: NULL
>>> $ B: NULL
>>> $ C: NULL
>>> 
>>> The dataframe has become a list. Would that affect downstream
>> applications?
>>> 
>>> Thank you,
>>> Luigi
>>> On Thu, Sep 27, 2018 at 9:45 AM Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>>>> 
>>>> Hi Luigi,
>>>> Maybe this:
>>>> 
>>>> testdf<-data.frame(A=1,B=2,C=3)
>>>>> testdf
>>>> A B C
>>>> 1 1 2 3
>>>> toNull<-function(x) return(NULL)
>>>> testdf<-sapply(testdf,toNull)
>>>> 
>>>> Jim
>>>> On Thu, Sep 27, 2018 at 5:29 PM Luigi Marongiu
>> <marongiu.luigi at gmail.com> wrote:
>>>>> 
>>>>> Dear all,
>>>>> I would like to erase the content of a dataframe -- but not the
>>>>> dataframe itself -- in a simple and fast way.
>>>>> At the moment I do that by re-defining the dataframe itself in this way:
>>>>> 
>>>>>> df <- data.frame(A = numeric(),
>>>>> +                   B = numeric(),
>>>>> +                   C = character())
>>>>>> # assign
>>>>>> A <- 5
>>>>>> B <- 0.6
>>>>>> C <- 103
>>>>>> # load
>>>>>> R <- cbind(A, B, C)
>>>>>> df <- rbind(df, R)
>>>>>> df
>>>>> A   B   C
>>>>> 1 5 0.6 103
>>>>>> # erase
>>>>>> df <- data.frame(A = numeric(),
>>>>> +                  B = numeric(),
>>>>> +                  C = character())
>>>>>> df
>>>>> [1] A B C
>>>>> <0 rows> (or 0-length row.names)
>>>>>> 
>>>>> 
>>>>> Is there a way to erase the content of the dataframe in a simplier
>>>>> (acting on all the dataframe at once instead of naming each column
>>>>> individually) and nicer (with a specific erasure command instead
>>>>> of re-defyining the object itself) way?
>>>>> 
>>>>> Thank you.
>>>>> --
>>>>> Best regards,
>>>>> Luigi
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> --
>>> Best regards,
>>> Luigi
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From pjb10 @end|ng |rom c@m@@c@uk  Thu Sep 27 12:56:49 2018
From: pjb10 @end|ng |rom c@m@@c@uk (Patrick Barrie)
Date: Thu, 27 Sep 2018 11:56:49 +0100
Subject: [R] Query on R-squared correlation coefficient for linear
 regression through origin
Message-ID: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>

I have a query on the R-squared correlation coefficient for linear 
regression through the origin.

The general expression for R-squared in regression (whether linear or 
non-linear) is
R-squared = 1 - sum(y-ypredicted)^2 / sum(y-ybar)^2

However, the lm function within R does not seem to use this expression 
when the intercept is constrained to be zero. It gives results different 
to Excel and other data analysis packages.

As an example (using built-in cars dataframe):
>  cars.lm=lm(dist ~ 0+speed, data=cars)???? # linear regression through 
origin
> summary(cars.lm)$r.squared # report R-squared [1] 0.8962893 > 
1-deviance(cars.lm)/sum((cars$dist-mean(cars$dist))^2) ? ? # calculates 
R-squared directly [1] 0.6018997 > # The latter corresponds to the value 
reported by Excel (and other data analysis packages) > > # Note that we 
expect R-squared to be smaller for linear regression through the origin
 > # than for linear regression without a constraint (which is 0.6511 in 
this example)

Does anyone know what R is doing in this case? Is there an option to get 
R to return what I termed the "general" expression for R-squared? The 
adjusted R-squared value is also affected. [Other parameters all seem 
correct.]

Thanks for any help on this issue,

Patrick

P.S. I believe old versions of Excel (before 2003) also had this issue.

-- 
Dr Patrick J. Barrie
Department of Chemical Engineering and Biotechnology
University of Cambridge
Philippa Fawcett Drive, Cambridge CB3 0AS
01223 331864
pjb10 at cam.ac.uk


	[[alternative HTML version deleted]]



From pro|jcn@@h @end|ng |rom gm@||@com  Thu Sep 27 14:43:17 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Thu, 27 Sep 2018 08:43:17 -0400
Subject: [R] Query on R-squared correlation coefficient for linear
 regression through origin
In-Reply-To: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
References: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
Message-ID: <96009784-9176-60f4-fc6b-a11726ebc1ec@gmail.com>

This issue that traces back to the very unfortunate use
of R-squared as the name of a tool to simply compare a model to the model that
is a single number (the mean). The mean can be shown to be the optimal choice
for a model that is a single number, so it makes sense to try to do better.

The OP has the correct form -- and I find no matter what the software, when
working with models that do NOT have a constant in them (i.e., nonlinear
models, regression through the origin) it pays to do the calculation
"manually". In R it is really easy to write the necessary function, so
why take a chance that a software developer has tried to expand the concept
using a personal choice that is beyond a clear definition.

I've commented elsewhere that I use this statistic even for nonlinear
models in my own software, since I think one should do better than the
mean for a model, but other workers shy away from using it for nonlinear
models because there may be false interpretation based on its use for
linear models.

JN


On 2018-09-27 06:56 AM, Patrick Barrie wrote:
> I have a query on the R-squared correlation coefficient for linear 
> regression through the origin.
> 
> The general expression for R-squared in regression (whether linear or 
> non-linear) is
> R-squared = 1 - sum(y-ypredicted)^2 / sum(y-ybar)^2
> 
> However, the lm function within R does not seem to use this expression 
> when the intercept is constrained to be zero. It gives results different 
> to Excel and other data analysis packages.
> 
> As an example (using built-in cars dataframe):
>>  cars.lm=lm(dist ~ 0+speed, data=cars)???? # linear regression through 
> origin
>> summary(cars.lm)$r.squared # report R-squared [1] 0.8962893 > 
> 1-deviance(cars.lm)/sum((cars$dist-mean(cars$dist))^2) ? ? # calculates 
> R-squared directly [1] 0.6018997 > # The latter corresponds to the value 
> reported by Excel (and other data analysis packages) > > # Note that we 
> expect R-squared to be smaller for linear regression through the origin
>  > # than for linear regression without a constraint (which is 0.6511 in 
> this example)
> 
> Does anyone know what R is doing in this case? Is there an option to get 
> R to return what I termed the "general" expression for R-squared? The 
> adjusted R-squared value is also affected. [Other parameters all seem 
> correct.]
> 
> Thanks for any help on this issue,
> 
> Patrick
> 
> P.S. I believe old versions of Excel (before 2003) also had this issue.
>



From er|cjberger @end|ng |rom gm@||@com  Thu Sep 27 14:50:23 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 27 Sep 2018 15:50:23 +0300
Subject: [R] Query on R-squared correlation coefficient for linear
 regression through origin
In-Reply-To: <96009784-9176-60f4-fc6b-a11726ebc1ec@gmail.com>
References: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
 <96009784-9176-60f4-fc6b-a11726ebc1ec@gmail.com>
Message-ID: <CAGgJW75tpWw-aLtFTM8_Q24u-N=ngGqwuorVNNDwZ031giKt2Q@mail.gmail.com>

See also this thread in stats.stackexchange

https://stats.stackexchange.com/questions/26176/removal-of-statistically-significant-intercept-term-increases-r2-in-linear-mo



On Thu, Sep 27, 2018 at 3:43 PM, J C Nash <profjcnash at gmail.com> wrote:

> This issue that traces back to the very unfortunate use
> of R-squared as the name of a tool to simply compare a model to the model
> that
> is a single number (the mean). The mean can be shown to be the optimal
> choice
> for a model that is a single number, so it makes sense to try to do better.
>
> The OP has the correct form -- and I find no matter what the software, when
> working with models that do NOT have a constant in them (i.e., nonlinear
> models, regression through the origin) it pays to do the calculation
> "manually". In R it is really easy to write the necessary function, so
> why take a chance that a software developer has tried to expand the concept
> using a personal choice that is beyond a clear definition.
>
> I've commented elsewhere that I use this statistic even for nonlinear
> models in my own software, since I think one should do better than the
> mean for a model, but other workers shy away from using it for nonlinear
> models because there may be false interpretation based on its use for
> linear models.
>
> JN
>
>
> On 2018-09-27 06:56 AM, Patrick Barrie wrote:
> > I have a query on the R-squared correlation coefficient for linear
> > regression through the origin.
> >
> > The general expression for R-squared in regression (whether linear or
> > non-linear) is
> > R-squared = 1 - sum(y-ypredicted)^2 / sum(y-ybar)^2
> >
> > However, the lm function within R does not seem to use this expression
> > when the intercept is constrained to be zero. It gives results different
> > to Excel and other data analysis packages.
> >
> > As an example (using built-in cars dataframe):
> >>  cars.lm=lm(dist ~ 0+speed, data=cars)     # linear regression through
> > origin
> >> summary(cars.lm)$r.squared # report R-squared [1] 0.8962893 >
> > 1-deviance(cars.lm)/sum((cars$dist-mean(cars$dist))^2)     # calculates
> > R-squared directly [1] 0.6018997 > # The latter corresponds to the value
> > reported by Excel (and other data analysis packages) > > # Note that we
> > expect R-squared to be smaller for linear regression through the origin
> >  > # than for linear regression without a constraint (which is 0.6511 in
> > this example)
> >
> > Does anyone know what R is doing in this case? Is there an option to get
> > R to return what I termed the "general" expression for R-squared? The
> > adjusted R-squared value is also affected. [Other parameters all seem
> > correct.]
> >
> > Thanks for any help on this issue,
> >
> > Patrick
> >
> > P.S. I believe old versions of Excel (before 2003) also had this issue.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From pd@|gd @end|ng |rom gm@||@com  Thu Sep 27 16:22:49 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 27 Sep 2018 16:22:49 +0200
Subject: [R] Query on R-squared correlation coefficient for linear
 regression through origin
In-Reply-To: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
References: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
Message-ID: <C8D38472-F013-4E29-BD20-23E3D841C16F@gmail.com>

This is an old discussion. The thing that R is doing is to compare the model to the model without any regressors, which in the no-intercept case is the constant zero. Otherwise, you would be comparing non-nested models and the R^2 would not satisfy the property of being between 0 and 1. 

A similar issue affects anova tables, where the regression sum of squares is sum(yhat^2) rather than sum((yhat - ybar)^2).

-pd

> On 27 Sep 2018, at 12:56 , Patrick Barrie <pjb10 at cam.ac.uk> wrote:
> 
> I have a query on the R-squared correlation coefficient for linear 
> regression through the origin.
> 
> The general expression for R-squared in regression (whether linear or 
> non-linear) is
> R-squared = 1 - sum(y-ypredicted)^2 / sum(y-ybar)^2
> 
> However, the lm function within R does not seem to use this expression 
> when the intercept is constrained to be zero. It gives results different 
> to Excel and other data analysis packages.
> 
> As an example (using built-in cars dataframe):
>> cars.lm=lm(dist ~ 0+speed, data=cars)     # linear regression through 
> origin
>> summary(cars.lm)$r.squared # report R-squared [1] 0.8962893 > 
> 1-deviance(cars.lm)/sum((cars$dist-mean(cars$dist))^2)     # calculates 
> R-squared directly [1] 0.6018997 > # The latter corresponds to the value 
> reported by Excel (and other data analysis packages) > > # Note that we 
> expect R-squared to be smaller for linear regression through the origin
>> # than for linear regression without a constraint (which is 0.6511 in 
> this example)
> 
> Does anyone know what R is doing in this case? Is there an option to get 
> R to return what I termed the "general" expression for R-squared? The 
> adjusted R-squared value is also affected. [Other parameters all seem 
> correct.]
> 
> Thanks for any help on this issue,
> 
> Patrick
> 
> P.S. I believe old versions of Excel (before 2003) also had this issue.
> 
> -- 
> Dr Patrick J. Barrie
> Department of Chemical Engineering and Biotechnology
> University of Cambridge
> Philippa Fawcett Drive, Cambridge CB3 0AS
> 01223 331864
> pjb10 at cam.ac.uk
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From rhe|p @end|ng |rom krueger-|@m||y@de  Thu Sep 27 16:48:41 2018
From: rhe|p @end|ng |rom krueger-|@m||y@de (Knut Krueger)
Date: Thu, 27 Sep 2018 16:48:41 +0200
Subject: [R] subset only if f.e a column is successive for more than 3 values
Message-ID: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>

Hi to all

I need a subset for values if there are f.e 3 values successive in a 
column of a Data Frame:
Example from the subset help page:

subset(airquality, Temp > 80, select = c(Ozone, Temp))
29     45   81
35     NA   84
36     NA   85
38     29   82
39     NA   87
40     71   90
41     39   87
42     NA   93
43     NA   92
44     23   82
.....

I would like to get only

...
40     71   90
41     39   87
42     NA   93
43     NA   92
44     23   82
....

because the left column is ascending more than f.e three times without gap

Any hints for a package or do I need to build a own function?

Kind Regards Knut



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 27 16:51:24 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 27 Sep 2018 15:51:24 +0100
Subject: [R] Query on R-squared correlation coefficient for linear
 regression through origin
In-Reply-To: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
References: <4b2a7d28-9d99-4ba4-a9ad-c0d7db3fc82a@cam.ac.uk>
Message-ID: <c5f20120-c1de-d454-2c46-1848336428bb@sapo.pt>

Hello,

As for R^2 in Excel for models without an intercept, maybe the following 
are relevant.

https://support.microsoft.com/en-us/help/829249/you-will-receive-an-incorrect-r-squared-value-in-the-chart-tool-in-exc

https://stat.ethz.ch/pipermail/r-help/2012-July/318347.html


Hope this helps,

Rui Barradas

?s 11:56 de 27/09/2018, Patrick Barrie escreveu:
> I have a query on the R-squared correlation coefficient for linear
> regression through the origin.
> 
> The general expression for R-squared in regression (whether linear or
> non-linear) is
> R-squared = 1 - sum(y-ypredicted)^2 / sum(y-ybar)^2
> 
> However, the lm function within R does not seem to use this expression
> when the intercept is constrained to be zero. It gives results different
> to Excel and other data analysis packages.
> 
> As an example (using built-in cars dataframe):
>>   cars.lm=lm(dist ~ 0+speed, data=cars)???? # linear regression through
> origin
>> summary(cars.lm)$r.squared # report R-squared [1] 0.8962893 >
> 1-deviance(cars.lm)/sum((cars$dist-mean(cars$dist))^2) ? ? # calculates
> R-squared directly [1] 0.6018997 > # The latter corresponds to the value
> reported by Excel (and other data analysis packages) > > # Note that we
> expect R-squared to be smaller for linear regression through the origin
>   > # than for linear regression without a constraint (which is 0.6511 in
> this example)
> 
> Does anyone know what R is doing in this case? Is there an option to get
> R to return what I termed the "general" expression for R-squared? The
> adjusted R-squared value is also affected. [Other parameters all seem
> correct.]
> 
> Thanks for any help on this issue,
> 
> Patrick
> 
> P.S. I believe old versions of Excel (before 2003) also had this issue.
>



From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 27 17:09:18 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 27 Sep 2018 08:09:18 -0700
Subject: [R] subset only if f.e a column is successive for more than 3
 values
In-Reply-To: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
References: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
Message-ID: <CAGxFJbTPq7PK3vorgEiU0LcuaUKmYd3TwkbdDM11aLUB=6essA@mail.gmail.com>

1. I assume the values are integers, not floats/numerics (which woud make
it more complicated).

2. Strategy: Take differences (e.g. see ?diff) and look for >3 1's in a
row.

I don't have time to work out details, but perhaps that helps.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 27, 2018 at 7:49 AM Knut Krueger <rhelp at krueger-family.de>
wrote:

> Hi to all
>
> I need a subset for values if there are f.e 3 values successive in a
> column of a Data Frame:
> Example from the subset help page:
>
> subset(airquality, Temp > 80, select = c(Ozone, Temp))
> 29     45   81
> 35     NA   84
> 36     NA   85
> 38     29   82
> 39     NA   87
> 40     71   90
> 41     39   87
> 42     NA   93
> 43     NA   92
> 44     23   82
> .....
>
> I would like to get only
>
> ...
> 40     71   90
> 41     39   87
> 42     NA   93
> 43     NA   92
> 44     23   82
> ....
>
> because the left column is ascending more than f.e three times without gap
>
> Any hints for a package or do I need to build a own function?
>
> Kind Regards Knut
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @w@p@nkum@rtr|p@thy @end|ng |rom gm@||@com  Thu Sep 27 17:02:13 2018
From: @w@p@nkum@rtr|p@thy @end|ng |rom gm@||@com (Swapan Kumar Tripathy)
Date: Thu, 27 Sep 2018 20:32:13 +0530
Subject: [R] Installation of R/qtl
Message-ID: <CAKYa35hewkA-gfwE9Wmb3qSQ3LMVE4pg6G+cynw=XsqW5j0ohw@mail.gmail.com>

Sir,
I have successfully installed R, but could not install the R/qtl.
There is instruction that "To install R/qtl, the simplest approach is to
start R and type install.packages("qtl"). But, I do not find any step where
to type install.packages("qtl") during the process of installing R.
 Kindly, advice me and suggest steps to install R/qtl.
Looking forward your suggestion.

-- 
*Dr. S.K. Tripathy*
*Professor (Agril. Biotechnology)*
*Dept. of Agril. Biotechnology*
*College of Agriculture*
*Orissa University of Agriculture and Technology, BBSR*
*Odisha, India, 751003*

	[[alternative HTML version deleted]]



From L@J@Bonnett @end|ng |rom ||verpoo|@@c@uk  Thu Sep 27 17:26:31 2018
From: L@J@Bonnett @end|ng |rom ||verpoo|@@c@uk (Bonnett, Laura)
Date: Thu, 27 Sep 2018 15:26:31 +0000
Subject: [R] Choosing between functional forms using flexible parametric
 survival models
Message-ID: <811b8ea4f35646d2afff7c903c6b1b8c@liverpool.ac.uk>

Dear all,

I am using R 3.4.3 on Windows 10.  I am writing code to use in a forthcoming teaching session.  As part of the workshop the students are using breast cancer data made available by Patrick Royston and available from http://www.statapress.com/data/fpsaus.html (I didn't pick the dataset by the way).  I would like the students to visualise linear, fractional polynomial and spline transformations of the "node" variable using a flexible parametric model with 3 knots for the baseline hazard.  I can do this using the "predict" option within stpm2 as follows:

flex_nodes_lin <- stpm2(Surv(rfs/12,rfsi)~nodes, data=Practical_Rott_dev,df=3)
haz_lin <- predict(flex_nodes_lin,type="hazard")

flex_nodes_fp <- stpm2(Surv(rfs/12,rfsi)~log(nodes),data=Practical_Rott_dev,df=3)
haz_fp <- predict(flex_nodes_fp,type="hazard")

spline3 <- stpm2(Surv(rfs/12,rfsi)~1, data=Practical_Rott_dev,df=3)
haz_spline3 <- predict(spline3,type="hazard")

data_part9 <- data.frame(nodes,haz_lin[nodes],haz_spline3[nodes],haz_fp[nodes])
data_part9_m <- melt(data_part9,id.vars='nodes',factorsAsStrings=F)
plot_part9 <- ggplot(data_part9_m,aes(nodes,value,colour=variable))+geom_line()+scale_colour_manual(labels=c("Linear","FP1","Spline 3 knots"),values=c("green","red","blue"))+theme_bw()
plot_part9 + labs(x="Number of positive nodes",y="",color="") + theme(legend.position=c(0.8,0.8))

However, to my mind using "hazard" (or "survival") leads to a plot which do not help to understand the different functional form of "nodes".  Therefore, I would prefer to do this using the linear predictor for each model instead.  I've written the following code to do this:
lp_nodes_lin <- flex_nodes_lin at lm$fitted.values
lp_nodes_spline <- flex_nodes_spline at lm$fitted.values
lp_nodes_fp <- flex_nodes_fp at lm$fitted.values

data_part9 <- data.frame(flex_nodes_lin at lm$model$nodes,lp_nodes_lin,lp_nodes_spline,lp_nodes_fp)
colnames(data_part9)[1] <- "nodes"

data_part9_m <- melt(data_part9,id.vars='nodes')
plot_part9 <- ggplot(data_part9_m,aes(nodes,value,colour=variable))+geom_line()+scale_colour_manual(labels=c("Linear","Spline (3 knots)", "FP1"),values=c("green","red","blue"))+theme_bw()
plot_part9 + labs(x="Number of positive nodes",y="Prediction",color="") + theme(legend.position=c(0.8,0.8))

I have 2 concerns over this:

1.       The plots are still not the shape I would expect them to be i.e. a line along the 45 degree line for the linear transformation, and a curve for each of the spline and FP transformations.

2.       This code is really complicated - there must be an easier way?!

Any help gratefully received!

Kind regards,
Laura

P.S. If I was doing this in the logistic regression the code would be relatively simple:
age_mod <- glm(DAY30~AGE,family="binomial")
lp_age_lin <- predict(age_mod)

agefp1_mod <- mfp(DAY30~fp(AGE,df=2,alpha=1),family="binomial")
lp_agefp1 <- predict(agefp1_mod)

age3_mod <- glm(DAY30~age3_spline,family="binomial")
lp_age3 <- predict(age3_mod)

data_part8 <- data.frame(AGE,lp_age_lin,lp_agefp1,lp_age3)
data_part8_m <- melt(data_part8,id.vars='AGE')
plot_part8 <- ggplot(data_part8_m,aes(AGE,value,colour=variable))+geom_line()+scale_colour_manual(labels=c("Linear","FP1","Spline 3 knots"),values=c("green","blue","red"))+theme_bw()
plot_part8 + labs(x="Age (years)",y="Linear Predictor (log odds)",color="") + theme(legend.position=c(0.2,0.8))

	[[alternative HTML version deleted]]



From rhe|p @end|ng |rom krueger-|@m||y@de  Thu Sep 27 17:31:50 2018
From: rhe|p @end|ng |rom krueger-|@m||y@de (Knut Krueger)
Date: Thu, 27 Sep 2018 17:31:50 +0200
Subject: [R] Installation of R/qtl
In-Reply-To: <CAKYa35hewkA-gfwE9Wmb3qSQ3LMVE4pg6G+cynw=XsqW5j0ohw@mail.gmail.com>
References: <CAKYa35hewkA-gfwE9Wmb3qSQ3LMVE4pg6G+cynw=XsqW5j0ohw@mail.gmail.com>
Message-ID: <19b049e1-4ebe-abfe-bbbc-71422de02a54@krueger-family.de>

Am 27.09.2018 um 17:02 schrieb Swapan Kumar Tripathy:
> Sir,
> I have successfully installed R, but could not install the R/qtl.
> There is instruction that "To install R/qtl, the simplest approach is to
> start R and type install.packages("qtl"). But, I do not find any step where
> to type install.packages("qtl") during the process of installing R.
>   Kindly, advice me and suggest steps to install R/qtl.
> Looking forward your suggestion.
> 
You can install packages only after R is installed and working.

If you are not familiar with the R console  you can try the GUI Rstudio 
https://www.rstudio.com/

Kind regards Knut



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep 27 17:32:47 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 27 Sep 2018 08:32:47 -0700 (PDT)
Subject: [R] Installation of R/qtl
In-Reply-To: <CAKYa35hewkA-gfwE9Wmb3qSQ3LMVE4pg6G+cynw=XsqW5j0ohw@mail.gmail.com>
References: <CAKYa35hewkA-gfwE9Wmb3qSQ3LMVE4pg6G+cynw=XsqW5j0ohw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809270830260.24044@salmo.appl-ecosys.com>

On Thu, 27 Sep 2018, Swapan Kumar Tripathy wrote:

> I have successfully installed R, but could not install the R/qtl. There is
> instruction that "To install R/qtl, the simplest approach is to start R
> and type install.packages("qtl"). But, I do not find any step where to
> type install.packages("qtl") during the process of installing R. Kindly,
> advice me and suggest steps to install R/qtl. Looking forward your
> suggestion.

Swapan,

   After installing R you need to invoke the application before you can use
it. From the command line type
 	R
When it loads you'll see the prompt > and you can then type
 	install.packages("qtl")

   R will ask you to select a repository, then proceed to install the package
for you.

Regards,

Rich



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Sep 27 17:33:36 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 27 Sep 2018 15:33:36 +0000
Subject: [R] Access function as text from package by name
In-Reply-To: <8514c9d8-9849-b17a-3358-343d1e616d45@sapo.pt>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
 <8514c9d8-9849-b17a-3358-343d1e616d45@sapo.pt>
Message-ID: <E8E07739-0B5B-4983-A9C4-D8B334716942@llnl.gov>

Or

  sink('stuff.txt') ; graphics::box ; sink()

to have it in a text file.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/27/18, 4:55 AM, "R-help on behalf of Rui Barradas" <r-help-bounces at r-project.org on behalf of ruipbarradas at sapo.pt> wrote:

    Hello,
    
    Maybe
    
    capture.output(graphics::box)
    
    
    Hope this helps,
    
    Rui Barradas
    
    ?s 11:30 de 27/09/2018, Sigbert Klinke escreveu:
    > Hi,
    > 
    > I want to have a function, e.g. graphics::box, as text.
    > Currently I'am using
    > 
    > deparse(eval(parse(text='graphics::box')))
    > 
    > It is important that '::' and ':::' can be used in the name.
    > 
    > Is there a simpler way?
    > 
    > Thanks
    > 
    > Sigbert
    > 
    > 
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    >
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Sep 27 18:35:29 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 27 Sep 2018 09:35:29 -0700
Subject: [R] Access function as text from package by name
In-Reply-To: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
Message-ID: <CAFDcVCQRqF25O_miA4_TV--Za628uJYhOzZMax20eSQKxBTonw@mail.gmail.com>

deparse(graphics::box)

/Henrik
On Thu, Sep 27, 2018 at 3:30 AM Sigbert Klinke
<sigbert at wiwi.hu-berlin.de> wrote:
>
> Hi,
>
> I want to have a function, e.g. graphics::box, as text.
> Currently I'am using
>
> deparse(eval(parse(text='graphics::box')))
>
> It is important that '::' and ':::' can be used in the name.
>
> Is there a simpler way?
>
> Thanks
>
> Sigbert
>
> --
> https://hu.berlin/sk
> https://hu.berlin/mmstat3
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dd|@@b01 @end|ng |rom gm@||@com  Thu Sep 27 18:35:25 2018
From: dd|@@b01 @end|ng |rom gm@||@com (David Disabato)
Date: Thu, 27 Sep 2018 12:35:25 -0400
Subject: [R] Printing standard notation and scientific notation in the same
 column of a dataframe
Message-ID: <CACg022_=Zz+B9V006q2c3NgJn_G+==GxWQ1NVzgmQC5thEGa1Q@mail.gmail.com>

Hi R-help,

I was wondering if it was possible for a column of a dataframe to print
some numbers in standard notation and some in scientific notation. Say my
column of data (i.e., dat$x) has numbers between 0 and 1 with a few numbers
very close to 0. When using the "scipen" argument in "options," R seems to
print all numbers of a column in scientific notation if one number in the
column is a decimal with a starting digit smaller than the "scipen"
argument. It is annoying that is changes ALL numbers in that column to
scientific notation though. For example, I do want .00000000000000000001 in
scientific notation, but I want .52 in standard form. Ideally, an example
dataframe column would print as something like this:

print(dat$x)
.52
.17
.03
1.0e-20

However, I cannot figure out how to do this. Any solutions people are aware
of?

-- 
David J. Disabato, M.A.
Clinical Psychology Doctoral Student
George Mason University
ddisabat at gmu.edu

Email is not a secure form of communication as information and
confidentiality cannot be guaranteed. Information provided in an email is
not intended to be a professional service. In the case of a crisis or
emergency situation, call 911.

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Sep 27 20:53:22 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 27 Sep 2018 11:53:22 -0700
Subject: [R] 
 Printing standard notation and scientific notation in the same
 column of a dataframe
In-Reply-To: <CACg022_=Zz+B9V006q2c3NgJn_G+==GxWQ1NVzgmQC5thEGa1Q@mail.gmail.com>
References: <CACg022_=Zz+B9V006q2c3NgJn_G+==GxWQ1NVzgmQC5thEGa1Q@mail.gmail.com>
Message-ID: <98F2B61B-F692-4D94-8C03-55101A15F2A6@comcast.net>


> On Sep 27, 2018, at 9:35 AM, David Disabato <ddisab01 at gmail.com> wrote:
> 
> Hi R-help,
> 
> I was wondering if it was possible for a column of a dataframe to print
> some numbers in standard notation and some in scientific notation. Say my
> column of data (i.e., dat$x) has numbers between 0 and 1 with a few numbers
> very close to 0. When using the "scipen" argument in "options," R seems to
> print all numbers of a column in scientific notation if one number in the
> column is a decimal with a starting digit smaller than the "scipen"
> argument. It is annoying that is changes ALL numbers in that column to
> scientific notation though. For example, I do want .00000000000000000001 in
> scientific notation, but I want .52 in standard form. Ideally, an example
> dataframe column would print as something like this:
> 
> print(dat$x)
> .52
> .17
> .03
> 1.0e-20
> 
> However, I cannot figure out how to do this. Any solutions people are aware
> of?

Perhaps cat?

> cat(x)
0.52 0.17 0.03 1e-20

> 
> -- 
> David J. Disabato, M.A.
> Clinical Psychology Doctoral Student
> George Mason University
> ddisabat at gmu.edu
> 
> Email is not a secure form of communication as information and
> confidentiality cannot be guaranteed. Information provided in an email is
> not intended to be a professional service. In the case of a crisis or
> emergency situation, call 911.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Sep 27 23:51:12 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 27 Sep 2018 21:51:12 +0000
Subject: [R] 
 Printing standard notation and scientific notation in the same
 column of a dataframe
In-Reply-To: <98F2B61B-F692-4D94-8C03-55101A15F2A6@comcast.net>
References: <CACg022_=Zz+B9V006q2c3NgJn_G+==GxWQ1NVzgmQC5thEGa1Q@mail.gmail.com>
 <98F2B61B-F692-4D94-8C03-55101A15F2A6@comcast.net>
Message-ID: <27CBEE40-B81D-4B2F-A38E-248F4EC6F809@llnl.gov>

First compare

> format(c(0.52, 0.17, 0.03, 1e-20))
[1] "5.2e-01" "1.7e-01" "3.0e-02" "1.0e-20"

> prettyNum(c(0.52, 0.17, 0.03, 1e-20))
[1] "0.52"  "0.17"  "0.03"  "1e-20"
>

If you want to print one column at a time, that will do what you ask. If you want to print the entire data frame, with numeric columns formatting this way when needed, it will take more work.

Start with ?print.data.frame, which says, in part,

     This calls 'format' which formats the data frame column-by-column,
     then converts to a character matrix and dispatches to the 'print'
     method for matrices.

Fortunately the code for print.data.frame is fairly short and simple. Looking at it, it calls format.data.frame (also fairly short and simple), which in turn uses format(). So there does not appear to be a built in option for the formatting you want.

Some possible approaches:

1) create your own version of format.data.frame which uses prettyNum on numeric columns and format on all other types. If it appears earlier in the path than base R's format.data.frame it might be used instead.
2) create your own versions of both print.data.frame and format.data.frame, again causing it to use prettyNum on numeric columns
3) manually convert your numeric columns to character columns using prettyNum, then print that. Alignment will probably change, which you may not want, but at least you'll get nicer to read numbers.


(as an aside, I'll claim that this is an example of the power of open-source software -- if you don't like the defaults, one can make one's own version to work however is desired -- but it does take some work)

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/27/18, 11:53 AM, "R-help on behalf of David Winsemius" <r-help-bounces at r-project.org on behalf of dwinsemius at comcast.net> wrote:

    
    > On Sep 27, 2018, at 9:35 AM, David Disabato <ddisab01 at gmail.com> wrote:
    > 
    > Hi R-help,
    > 
    > I was wondering if it was possible for a column of a dataframe to print
    > some numbers in standard notation and some in scientific notation. Say my
    > column of data (i.e., dat$x) has numbers between 0 and 1 with a few numbers
    > very close to 0. When using the "scipen" argument in "options," R seems to
    > print all numbers of a column in scientific notation if one number in the
    > column is a decimal with a starting digit smaller than the "scipen"
    > argument. It is annoying that is changes ALL numbers in that column to
    > scientific notation though. For example, I do want .00000000000000000001 in
    > scientific notation, but I want .52 in standard form. Ideally, an example
    > dataframe column would print as something like this:
    > 
    > print(dat$x)
    > .52
    > .17
    > .03
    > 1.0e-20
    > 
    > However, I cannot figure out how to do this. Any solutions people are aware
    > of?
    
    Perhaps cat?
    
    > cat(x)
    0.52 0.17 0.03 1e-20
    
    > 
    > -- 
    > David J. Disabato, M.A.
    > Clinical Psychology Doctoral Student
    > George Mason University
    > ddisabat at gmu.edu
    > 
    > Email is not a secure form of communication as information and
    > confidentiality cannot be guaranteed. Information provided in an email is
    > not intended to be a professional service. In the case of a crisis or
    > emergency situation, call 911.
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    David Winsemius
    Alameda, CA, USA
    
    'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 28 00:35:37 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 28 Sep 2018 08:35:37 +1000
Subject: [R] subset only if f.e a column is successive for more than 3
 values
In-Reply-To: <CAGxFJbTPq7PK3vorgEiU0LcuaUKmYd3TwkbdDM11aLUB=6essA@mail.gmail.com>
References: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
 <CAGxFJbTPq7PK3vorgEiU0LcuaUKmYd3TwkbdDM11aLUB=6essA@mail.gmail.com>
Message-ID: <CA+8X3fWRz9NU1LZoSQz3K9dzF4McS2RpUaM-KOSvyUcjOfxf3g@mail.gmail.com>

Hi Knut,
As Bert said, you can start with diff and work from there. I can
easily get the text for the subset, but despite fooling around with
"parse", "eval" and "expression", I couldn't get it to work:

# use a bigger subset to test whether multiple runs can be extracted
kkdf<-subset(airquality,Temp > 77,select=c("Ozone","Temp"))
kkdf$index<-as.numeric(rownames(kkdf))
# get the run length encoding
seqindx<-rle(diff(kkdf$index)==1)
# get a logical vector of the starts of the runs
runsel<-seqindx$lengths >= 3 & seqindx$values
# get the indices for the starts of the runs
starts<-cumsum(seqindx$lengths)[runsel[-1]]+1
# and the ends
ends<-cumsum(seqindx$lengths)[runsel]+1
# the character representation of the subset as indices is
paste0("c(",paste(starts,ends,sep=":",collapse=","),")")

I expect there will be a lightning response from someone who knows
about converting the resulting string into whatever is needed.

Jim
On Fri, Sep 28, 2018 at 1:13 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> 1. I assume the values are integers, not floats/numerics (which woud make
> it more complicated).
>
> 2. Strategy: Take differences (e.g. see ?diff) and look for >3 1's in a
> row.
>
> I don't have time to work out details, but perhaps that helps.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Sep 27, 2018 at 7:49 AM Knut Krueger <rhelp at krueger-family.de>
> wrote:
>
> > Hi to all
> >
> > I need a subset for values if there are f.e 3 values successive in a
> > column of a Data Frame:
> > Example from the subset help page:
> >
> > subset(airquality, Temp > 80, select = c(Ozone, Temp))
> > 29     45   81
> > 35     NA   84
> > 36     NA   85
> > 38     29   82
> > 39     NA   87
> > 40     71   90
> > 41     39   87
> > 42     NA   93
> > 43     NA   92
> > 44     23   82
> > .....
> >
> > I would like to get only
> >
> > ...
> > 40     71   90
> > 41     39   87
> > 42     NA   93
> > 43     NA   92
> > 44     23   82
> > ....
> >
> > because the left column is ascending more than f.e three times without gap
> >
> > Any hints for a package or do I need to build a own function?
> >
> > Kind Regards Knut
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 28 00:43:35 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 28 Sep 2018 08:43:35 +1000
Subject: [R] subset only if f.e a column is successive for more than 3
 values
In-Reply-To: <CA+8X3fWRz9NU1LZoSQz3K9dzF4McS2RpUaM-KOSvyUcjOfxf3g@mail.gmail.com>
References: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
 <CAGxFJbTPq7PK3vorgEiU0LcuaUKmYd3TwkbdDM11aLUB=6essA@mail.gmail.com>
 <CA+8X3fWRz9NU1LZoSQz3K9dzF4McS2RpUaM-KOSvyUcjOfxf3g@mail.gmail.com>
Message-ID: <CA+8X3fU477t2RYpVFJCYQ0R_3EoqiorOWmeS3iGXuqafXi89GQ@mail.gmail.com>

Bugger! It's

eval(parse(text=paste0("kkdf[c(",paste(starts,ends,sep=":",collapse=","),"),]")))

What a mess!

Jim
On Fri, Sep 28, 2018 at 8:35 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Knut,
> As Bert said, you can start with diff and work from there. I can
> easily get the text for the subset, but despite fooling around with
> "parse", "eval" and "expression", I couldn't get it to work:
>
> # use a bigger subset to test whether multiple runs can be extracted
> kkdf<-subset(airquality,Temp > 77,select=c("Ozone","Temp"))
> kkdf$index<-as.numeric(rownames(kkdf))
> # get the run length encoding
> seqindx<-rle(diff(kkdf$index)==1)
> # get a logical vector of the starts of the runs
> runsel<-seqindx$lengths >= 3 & seqindx$values
> # get the indices for the starts of the runs
> starts<-cumsum(seqindx$lengths)[runsel[-1]]+1
> # and the ends
> ends<-cumsum(seqindx$lengths)[runsel]+1
> # the character representation of the subset as indices is
> paste0("c(",paste(starts,ends,sep=":",collapse=","),")")
>
> I expect there will be a lightning response from someone who knows
> about converting the resulting string into whatever is needed.
>
> Jim
> On Fri, Sep 28, 2018 at 1:13 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > 1. I assume the values are integers, not floats/numerics (which woud make
> > it more complicated).
> >
> > 2. Strategy: Take differences (e.g. see ?diff) and look for >3 1's in a
> > row.
> >
> > I don't have time to work out details, but perhaps that helps.
> >
> > Cheers,
> > Bert
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Thu, Sep 27, 2018 at 7:49 AM Knut Krueger <rhelp at krueger-family.de>
> > wrote:
> >
> > > Hi to all
> > >
> > > I need a subset for values if there are f.e 3 values successive in a
> > > column of a Data Frame:
> > > Example from the subset help page:
> > >
> > > subset(airquality, Temp > 80, select = c(Ozone, Temp))
> > > 29     45   81
> > > 35     NA   84
> > > 36     NA   85
> > > 38     29   82
> > > 39     NA   87
> > > 40     71   90
> > > 41     39   87
> > > 42     NA   93
> > > 43     NA   92
> > > 44     23   82
> > > .....
> > >
> > > I would like to get only
> > >
> > > ...
> > > 40     71   90
> > > 41     39   87
> > > 42     NA   93
> > > 43     NA   92
> > > 44     23   82
> > > ....
> > >
> > > because the left column is ascending more than f.e three times without gap
> > >
> > > Any hints for a package or do I need to build a own function?
> > >
> > > Kind Regards Knut
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



From du|c@|m@ @end|ng |rom b|gpond@com  Fri Sep 28 07:41:48 2018
From: du|c@|m@ @end|ng |rom b|gpond@com (Duncan Mackay)
Date: Fri, 28 Sep 2018 15:41:48 +1000
Subject: [R] 
 Printing standard notation and scientific notation in the same
 column of a dataframe
In-Reply-To: <98F2B61B-F692-4D94-8C03-55101A15F2A6@comcast.net>
References: <CACg022_=Zz+B9V006q2c3NgJn_G+==GxWQ1NVzgmQC5thEGa1Q@mail.gmail.com>
 <98F2B61B-F692-4D94-8C03-55101A15F2A6@comcast.net>
Message-ID: <001401d456ed$f3840360$da8c0a20$@bigpond.com>

Hi

If you do not require the zeros to the right in the scientific notation
  x
[1] 5.2e-01 1.7e-01 3.0e-02 1.0e-20
  zapsmall(x)
[1] 0.52 0.17 0.03 0.00

Then use format, formatC or  sprintf for character conversions

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350
 
-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
Winsemius
Sent: Friday, 28 September 2018 04:53
To: David Disabato
Cc: r-help at r-project.org
Subject: Re: [R] Printing standard notation and scientific notation in the
same column of a dataframe


> On Sep 27, 2018, at 9:35 AM, David Disabato <ddisab01 at gmail.com> wrote:
> 
> Hi R-help,
> 
> I was wondering if it was possible for a column of a dataframe to print
> some numbers in standard notation and some in scientific notation. Say my
> column of data (i.e., dat$x) has numbers between 0 and 1 with a few
numbers
> very close to 0. When using the "scipen" argument in "options," R seems to
> print all numbers of a column in scientific notation if one number in the
> column is a decimal with a starting digit smaller than the "scipen"
> argument. It is annoying that is changes ALL numbers in that column to
> scientific notation though. For example, I do want .00000000000000000001
in
> scientific notation, but I want .52 in standard form. Ideally, an example
> dataframe column would print as something like this:
> 
> print(dat$x)
> .52
> .17
> .03
> 1.0e-20
> 
> However, I cannot figure out how to do this. Any solutions people are
aware
> of?

Perhaps cat?

> cat(x)
0.52 0.17 0.03 1e-20

> 
> -- 
> David J. Disabato, M.A.
> Clinical Psychology Doctoral Student
> George Mason University
> ddisabat at gmu.edu
> 
> Email is not a secure form of communication as information and
> confidentiality cannot be guaranteed. Information provided in an email is
> not intended to be a professional service. In the case of a crisis or
> emergency situation, call 911.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'
-Gehm's Corollary to Clarke's Third Law

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Fri Sep 28 08:44:32 2018
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Fri, 28 Sep 2018 08:44:32 +0200
Subject: [R] Access function as text from package by name
In-Reply-To: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
Message-ID: <bc84db17-44bb-5a27-18e1-dca9decede84@wiwi.hu-berlin.de>

Hi,

I guess I was not clear enough: the name of the function is stored as 
string. Solutions which use the object directly do not help unfortunately.

Thanks Sigbert

Am 27.09.2018 um 12:30 schrieb Sigbert Klinke:
> Hi,
> 
> I want to have a function, e.g. graphics::box, as text.
> Currently I'am using
> 
> deparse(eval(parse(text='graphics::box')))
> 
> It is important that '::' and ':::' can be used in the name.
> 
> Is there a simpler way?
> 
> Thanks
> 
> Sigbert
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 28 10:45:27 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 28 Sep 2018 01:45:27 -0700
Subject: [R] Access function as text from package by name
In-Reply-To: <bc84db17-44bb-5a27-18e1-dca9decede84@wiwi.hu-berlin.de>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
 <bc84db17-44bb-5a27-18e1-dca9decede84@wiwi.hu-berlin.de>
Message-ID: <CAGxFJbTQ3Gui2-9W+ygTTZ=2Gg1piLb0vgG4Cj+Rev69sa8BaA@mail.gmail.com>

Do you mean:
?get



On Thu, Sep 27, 2018, 11:44 PM Sigbert Klinke <sigbert at wiwi.hu-berlin.de>
wrote:

> Hi,
>
> I guess I was not clear enough: the name of the function is stored as
> string. Solutions which use the object directly do not help unfortunately.
>
> Thanks Sigbert
>
> Am 27.09.2018 um 12:30 schrieb Sigbert Klinke:
> > Hi,
> >
> > I want to have a function, e.g. graphics::box, as text.
> > Currently I'am using
> >
> > deparse(eval(parse(text='graphics::box')))
> >
> > It is important that '::' and ':::' can be used in the name.
> >
> > Is there a simpler way?
> >
> > Thanks
> >
> > Sigbert
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> https://hu.berlin/sk
> https://hu.berlin/mmstat3
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Fri Sep 28 10:58:58 2018
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Fri, 28 Sep 2018 14:28:58 +0530
Subject: [R] Access function as text from package by name
In-Reply-To: <CAGxFJbTQ3Gui2-9W+ygTTZ=2Gg1piLb0vgG4Cj+Rev69sa8BaA@mail.gmail.com>
References: <c94ff0de-b785-416a-efaf-bb4c5004cd38@wiwi.hu-berlin.de>
 <bc84db17-44bb-5a27-18e1-dca9decede84@wiwi.hu-berlin.de>
 <CAGxFJbTQ3Gui2-9W+ygTTZ=2Gg1piLb0vgG4Cj+Rev69sa8BaA@mail.gmail.com>
Message-ID: <CADfFDC7opA8Jqj_V54VzKzHRxGJO37A-6eNuhV3uqr6+9TVxJw@mail.gmail.com>

On Fri, Sep 28, 2018 at 2:16 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Do you mean:
> ?get

Doesn't work with :: etc:

> get("graphics::box")
Error in get("graphics::box") : object 'graphics::box' not found

I think parse()+eval() is pretty much unavoidable. After that, it's a
choice between deparse() and print()+capture.output().

-Deepayan


> On Thu, Sep 27, 2018, 11:44 PM Sigbert Klinke <sigbert at wiwi.hu-berlin.de>
> wrote:
>
> > Hi,
> >
> > I guess I was not clear enough: the name of the function is stored as
> > string. Solutions which use the object directly do not help unfortunately.
> >
> > Thanks Sigbert
> >
> > Am 27.09.2018 um 12:30 schrieb Sigbert Klinke:
> > > Hi,
> > >
> > > I want to have a function, e.g. graphics::box, as text.
> > > Currently I'am using
> > >
> > > deparse(eval(parse(text='graphics::box')))
> > >
> > > It is important that '::' and ':::' can be used in the name.
> > >
> > > Is there a simpler way?
> > >
> > > Thanks
> > >
> > > Sigbert
> > >
> > >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> > --
> > https://hu.berlin/sk
> > https://hu.berlin/mmstat3
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 28 11:50:29 2018
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 28 Sep 2018 11:50:29 +0200
Subject: [R] Boxplot: draw outliers in colours
Message-ID: <CAMk+s2TYtKpxPmyx69-hoMAZGVAr+1fPd39fL54-s__HE5F1vw@mail.gmail.com>

Dear all,
I am trying to overlap two series of boxplots on the same graph. In
order to distinguish the outliers from one series to the other, would
be possible to colour the outliers?: instead of the standard black, is
it possible to give a chosen colour?
Thank you

>>>
This is the example. I could not generate not normally distributed
random values (even with runif), so I had to create the values
manually and they are still a bit rough (in the real thing, the two
series are more distant), anyway this should better explain the case.
Note that the three outliers at the bottom right belong to the 'blue'
distribution and the upper outlier on the right belongs to the 'green'
distribution, so making them in blue and green colours would make
clearer their positions.

# generate data.frames
A = c(70, 22, 4, 21, 29, 35, 24, 20, 9, 21,
      22, 12, 20, 21, 13, 18, 15, 3, 9, 23,
      6, 5, 2, 24, 25, 21, 16, 0, 4, 1)
B = c(17, 21, 70, 6, 23, 10, 8, 5, 22, 5,
      21, 5, 19, 9, 23, 24, 11, 13, 7, 15,
      25, 9, 13, 14, 11, 9, 12, 0, 5, 9)
C = c(17, 8, 30, 22, 11, 32, 33, 8, 160, 11,
      35, 7, 36, 15, 11, 25, 16, 6, 38, 19,
      35, 30, 12, 27, 22, 32, 47, 39, 31, 26)
D = c(79, 26, 8, 33, 59, 67, 60, 65, 54, 88,
      78, 105, 59, 40, 109, 81, 28, 26, 94,
      35, 10, 38, 58, 79, 58, 10, 5, 8, 4, 50)
E = c(98, 104, 101, 102, 97, 97, 97,
      100, 97, 102, 100, 103, 104,
      104, 99, 102, 100, 97, 102, 105,
      99, 105, 100, 102, 100, 115,
      112, 113, 111, 115)
G = c(105, 130, 97, 105, 113, 123,
      149, 15,     134, 148, 98, 104,
      113, 108, 209, 145, 138, 119,
      142, 129, 298, 101, 136, 129,
      148, 295, 125, 277, 107, 642)
X = rep(c(1, 3, 5),30*3)
dfA <- data.frame(X, c(A, B, C))
dfB <- data.frame(X, c(D, E, G))
names(dfA) <- c("X", "Y")
names(dfB) <- c("X", "Y")

# plot
boxplot(dfA$Y ~ dfA$X,
        ylim=c(0, 200),
        col="green",
        ylab="Y-values",
        xlab="X-values"
)
par(new=TRUE)
boxplot(dfB$Y ~ dfB$X,
        ylim=c(0, 200),
        col="blue",
        ylab="", xlab="",
        xaxt="n", yaxt="n"
)


-- 
Best regards,
Luigi



From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 28 12:05:48 2018
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 28 Sep 2018 12:05:48 +0200
Subject: [R] Boxplot with linear (not categorical) x-axis
Message-ID: <CAMk+s2Qn+5KyzZYCE_1OqmCBqXn9Jg0FCGmogqGt=KkK0aTUaw@mail.gmail.com>

Dear all,
I am using boxplot to draw some data. Would be possible to have the
X-axis linear (as in a scatter plot) instead of the standard
categorical axis?
The data I have is subdivided into three groups at the numerical
values 1, 3, 5; boxplot treats these as categorical values; in fact, I
can write my own labels simply by using the values 1, 2, 3 for the
position of the labels as in the example.
Thank you,

>>>>
# generate data.frames
A = c(70, 22, 4, 21, 29, 35, 24, 20, 9, 21,
      22, 12, 20, 21, 13, 18, 15, 3, 9, 23,
      6, 5, 2, 24, 25, 21, 16, 0, 4, 1)
B = c(17, 21, 70, 6, 23, 10, 8, 5, 22, 5,
      21, 5, 19, 9, 23, 24, 11, 13, 7, 15,
      25, 9, 13, 14, 11, 9, 12, 0, 5, 9)
C = c(17, 8, 30, 22, 11, 32, 33, 8, 160, 11,
      35, 7, 36, 15, 11, 25, 16, 6, 38, 19,
      35, 30, 12, 27, 22, 32, 47, 39, 31, 26)
X = rep(c(1, 3, 5),30*3)
dfA <- data.frame(X, c(A, B, C))
names(dfA) <- c("X", "Y")
par(mfrow=c(2,1))
boxplot(dfA$Y ~ dfA$X,
        ylim=c(0, 80),
        col="green",
        ylab="Y-values",
        xlab="X-values",
        main="usual X labels"
)
boxplot(dfA$Y ~ dfA$X,
        ylim=c(0, 80),
        col="green",
        ylab="Y-values",
        xlab="X-values",
        main="custom X labels",
        xaxt="n"
)
x.lab = c("A", "B", "C")
x.pos = c(1, 2, 3)
axis(side=1, at=x.pos,
     lab=x.lab, cex.axis=1)

-- 
Best regards,
Luigi



From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 28 13:14:27 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 28 Sep 2018 21:14:27 +1000
Subject: [R] Boxplot: draw outliers in colours
In-Reply-To: <CAMk+s2TYtKpxPmyx69-hoMAZGVAr+1fPd39fL54-s__HE5F1vw@mail.gmail.com>
References: <CAMk+s2TYtKpxPmyx69-hoMAZGVAr+1fPd39fL54-s__HE5F1vw@mail.gmail.com>
Message-ID: <CA+8X3fX0tORXpAZm_2GVsHm6SsWZxab-j0mfVhCAQZR6jeOpww@mail.gmail.com>

Hi Luigi,
An easy way is to use "points" to overplot the outliers:

grbxp<-boxplot(dfA$Y ~ dfA$X,
         ylim=c(0, 200),
         col="green",
         ylab="Y-values",
         xlab="X-values"
 )
points(grbxp$group,grbxp$out,col="green")


On Fri, Sep 28, 2018 at 7:51 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I am trying to overlap two series of boxplots on the same graph. In
> order to distinguish the outliers from one series to the other, would
> be possible to colour the outliers?: instead of the standard black, is
> it possible to give a chosen colour?
> Thank you
>
> >>>
> This is the example. I could not generate not normally distributed
> random values (even with runif), so I had to create the values
> manually and they are still a bit rough (in the real thing, the two
> series are more distant), anyway this should better explain the case.
> Note that the three outliers at the bottom right belong to the 'blue'
> distribution and the upper outlier on the right belongs to the 'green'
> distribution, so making them in blue and green colours would make
> clearer their positions.
>
> # generate data.frames
> A = c(70, 22, 4, 21, 29, 35, 24, 20, 9, 21,
>       22, 12, 20, 21, 13, 18, 15, 3, 9, 23,
>       6, 5, 2, 24, 25, 21, 16, 0, 4, 1)
> B = c(17, 21, 70, 6, 23, 10, 8, 5, 22, 5,
>       21, 5, 19, 9, 23, 24, 11, 13, 7, 15,
>       25, 9, 13, 14, 11, 9, 12, 0, 5, 9)
> C = c(17, 8, 30, 22, 11, 32, 33, 8, 160, 11,
>       35, 7, 36, 15, 11, 25, 16, 6, 38, 19,
>       35, 30, 12, 27, 22, 32, 47, 39, 31, 26)
> D = c(79, 26, 8, 33, 59, 67, 60, 65, 54, 88,
>       78, 105, 59, 40, 109, 81, 28, 26, 94,
>       35, 10, 38, 58, 79, 58, 10, 5, 8, 4, 50)
> E = c(98, 104, 101, 102, 97, 97, 97,
>       100, 97, 102, 100, 103, 104,
>       104, 99, 102, 100, 97, 102, 105,
>       99, 105, 100, 102, 100, 115,
>       112, 113, 111, 115)
> G = c(105, 130, 97, 105, 113, 123,
>       149, 15,     134, 148, 98, 104,
>       113, 108, 209, 145, 138, 119,
>       142, 129, 298, 101, 136, 129,
>       148, 295, 125, 277, 107, 642)
> X = rep(c(1, 3, 5),30*3)
> dfA <- data.frame(X, c(A, B, C))
> dfB <- data.frame(X, c(D, E, G))
> names(dfA) <- c("X", "Y")
> names(dfB) <- c("X", "Y")
>
> # plot
> boxplot(dfA$Y ~ dfA$X,
>         ylim=c(0, 200),
>         col="green",
>         ylab="Y-values",
>         xlab="X-values"
> )
> par(new=TRUE)
> boxplot(dfB$Y ~ dfB$X,
>         ylim=c(0, 200),
>         col="blue",
>         ylab="", xlab="",
>         xaxt="n", yaxt="n"
> )
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From rmh @end|ng |rom temp|e@edu  Fri Sep 28 15:45:36 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 28 Sep 2018 09:45:36 -0400
Subject: [R] Boxplot with linear (not categorical) x-axis
In-Reply-To: <CAMk+s2Qn+5KyzZYCE_1OqmCBqXn9Jg0FCGmogqGt=KkK0aTUaw@mail.gmail.com>
References: <CAMk+s2Qn+5KyzZYCE_1OqmCBqXn9Jg0FCGmogqGt=KkK0aTUaw@mail.gmail.com>
Message-ID: <CAGx1TMAwFrGXzB=QmPnffuC6E-Px2Mgjx3ToU5xBjgQyqb-RgQ@mail.gmail.com>

install.packages("HH")
library(HH)
system.file("demo/bwplot.examples.r", package="HH")
demo("bwplot.examples", package="HH", ask=FALSE)

## your example
dfA <- data.frame(X, Y=c(A, B, C))
dfA$X.factor <- factor(dfA$X)
position(dfA$X.factor) <- c(1,3,5)
bwplot(Y ~ X.factor, panel=panel.bwplot.intermediate.hh, data=dfA, xlim=c(0,6))

On Fri, Sep 28, 2018 at 6:05 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> Dear all,
> I am using boxplot to draw some data. Would be possible to have the
> X-axis linear (as in a scatter plot) instead of the standard
> categorical axis?
> The data I have is subdivided into three groups at the numerical
> values 1, 3, 5; boxplot treats these as categorical values; in fact, I
> can write my own labels simply by using the values 1, 2, 3 for the
> position of the labels as in the example.
> Thank you,
>
>>>>>
> # generate data.frames
> A = c(70, 22, 4, 21, 29, 35, 24, 20, 9, 21,
>       22, 12, 20, 21, 13, 18, 15, 3, 9, 23,
>       6, 5, 2, 24, 25, 21, 16, 0, 4, 1)
> B = c(17, 21, 70, 6, 23, 10, 8, 5, 22, 5,
>       21, 5, 19, 9, 23, 24, 11, 13, 7, 15,
>       25, 9, 13, 14, 11, 9, 12, 0, 5, 9)
> C = c(17, 8, 30, 22, 11, 32, 33, 8, 160, 11,
>       35, 7, 36, 15, 11, 25, 16, 6, 38, 19,
>       35, 30, 12, 27, 22, 32, 47, 39, 31, 26)
> X = rep(c(1, 3, 5),30*3)
> dfA <- data.frame(X, c(A, B, C))
> names(dfA) <- c("X", "Y")
> par(mfrow=c(2,1))
> boxplot(dfA$Y ~ dfA$X,
>         ylim=c(0, 80),
>         col="green",
>         ylab="Y-values",
>         xlab="X-values",
>         main="usual X labels"
> )
> boxplot(dfA$Y ~ dfA$X,
>         ylim=c(0, 80),
>         col="green",
>         ylab="Y-values",
>         xlab="X-values",
>         main="custom X labels",
>         xaxt="n"
> )
> x.lab = c("A", "B", "C")
> x.pos = c(1, 2, 3)
> axis(side=1, at=x.pos,
>      lab=x.lab, cex.axis=1)
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From rhe|p @end|ng |rom krueger-|@m||y@de  Fri Sep 28 17:08:31 2018
From: rhe|p @end|ng |rom krueger-|@m||y@de (Knut Krueger)
Date: Fri, 28 Sep 2018 17:08:31 +0200
Subject: [R] subset only if f.e a column is successive for more than 3
 values
In-Reply-To: <CA+8X3fU477t2RYpVFJCYQ0R_3EoqiorOWmeS3iGXuqafXi89GQ@mail.gmail.com>
References: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
 <CAGxFJbTPq7PK3vorgEiU0LcuaUKmYd3TwkbdDM11aLUB=6essA@mail.gmail.com>
 <CA+8X3fWRz9NU1LZoSQz3K9dzF4McS2RpUaM-KOSvyUcjOfxf3g@mail.gmail.com>
 <CA+8X3fU477t2RYpVFJCYQ0R_3EoqiorOWmeS3iGXuqafXi89GQ@mail.gmail.com>
Message-ID: <955b2ee9-c5b0-cb0d-363d-25642ef1c2dd@krueger-family.de>

Hi Jim,
thank's it is working with the given example,
but whats the difference when using

testdata=data.frame(TIME=c("17:11:20", "17:11:21", "17:11:22", 
"17:11:23", "17:11:24", "17:11:25", "17:11:26", "17:11:27", "17:11:28", 
"17:21:43",
                         "17:22:16", "17:22:19", "18:04:48", "18:04:49", 
"18:04:50", "18:04:51", "18:04:52", "19:50:09", "00:59:27", "00:59:28",
                         "00:59:29", "04:13:40", "04:13:43", "04:13:44"),

index=c(8960,8961,8962,8963,8964,8965,8966,8967,8968,9583,9616,9619,12168,12169,12170,12171,12172,18489
                               ,37047,37048,37049,48700,48701,48702))

seqindx<-rle(diff(testdata$index)==1)
runsel<-seqindx$lengths >= 3 & seqindx$values
# get the indices for the starts of the runs
starts<-cumsum(seqindx$lengths)[runsel[-1]]+1
# and the ends
ends<-cumsum(seqindx$lengths)[runsel]+1

eval(parse(text=paste0("testdata[c(",paste(starts,ends,sep=":",collapse=","),"),]")))

the result (index)  is 
12168,9619,9616,9583,8968,12168,12169,12170,12171,12172


maybe the gaps between .. 8967,8968,9583,9616,9619,12168,12169 ..?

Regards Knut



From wdun|@p @end|ng |rom t|bco@com  Fri Sep 28 17:22:59 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 28 Sep 2018 08:22:59 -0700
Subject: [R] subset only if f.e a column is successive for more than 3
 values
In-Reply-To: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
References: <06c7b992-3fc5-6f2e-0222-531a8ecec659@krueger-family.de>
Message-ID: <CAF8bMcaqfA=ZnJFzBh0nmV=XAY1y6GxXKD+FJ=Ek-Q+O41EsVQ@mail.gmail.com>

Do you also want lines 38 and 39 (in addition to 40:44), or do I
misunderstand your problem?

When you deal with runs of data, think of the rle (run-length encoding)
function.  E.g. here is
a barely tested function to find runs of a given minimum length and a given
difference between
successive values.  It also returns a 'runNumber' so you can split the
result into runs.

findRuns <- function(x, minRunLength=3, difference=1) {
     # for integral x, find runs of length at least 'minRunLength'
     # with 'difference' between succesive values
     d <- diff(x)
     dRle <- rle(d)
     w <- rep(dRle$lengths>=minRunLength-1 & dRle$values==difference,
dRle$lengths)
     values <- x[c(FALSE,w) | c(w,FALSE)]
     runNumber <- cumsum(c(TRUE, diff(values)!=difference))
     data.frame(values=values, runNumber=runNumber)
}

> findRuns(c(10,8,6,4,1,2,3,20,17,18,19,20))
  values runNumber
1      1         1
2      2         1
3      3         1
4     17         2
5     18         2
6     19         2
7     20         2
> findRuns(c(10,8,6,4,1,2,3,20,17,18,19,20), minRunLength=4)
  values runNumber
1     17         1
2     18         1
3     19         1
4     20         1
> findRuns(c(10,8,6,4,1,2,3,20,17,18,19,20), difference=-2)
  values runNumber
1     10         1
2      8         1
3      6         1
4      4         1


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Sep 27, 2018 at 7:48 AM, Knut Krueger <rhelp at krueger-family.de>
wrote:

> Hi to all
>
> I need a subset for values if there are f.e 3 values successive in a
> column of a Data Frame:
> Example from the subset help page:
>
> subset(airquality, Temp > 80, select = c(Ozone, Temp))
> 29     45   81
> 35     NA   84
> 36     NA   85
> 38     29   82
> 39     NA   87
> 40     71   90
> 41     39   87
> 42     NA   93
> 43     NA   92
> 44     23   82
> .....
>
> I would like to get only
>
> ...
> 40     71   90
> 41     39   87
> 42     NA   93
> 43     NA   92
> 44     23   82
> ....
>
> because the left column is ascending more than f.e three times without gap
>
> Any hints for a package or do I need to build a own function?
>
> Kind Regards Knut
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Fri Sep 28 17:33:47 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 28 Sep 2018 08:33:47 -0700
Subject: [R] Boxplot with linear (not categorical) x-axis
In-Reply-To: <CAMk+s2Qn+5KyzZYCE_1OqmCBqXn9Jg0FCGmogqGt=KkK0aTUaw@mail.gmail.com>
References: <CAMk+s2Qn+5KyzZYCE_1OqmCBqXn9Jg0FCGmogqGt=KkK0aTUaw@mail.gmail.com>
Message-ID: <CAF8bMca1M3FP5MF8hxtYH+NM7L0GMxGfZk2W9jz7DLTO6b2zyg@mail.gmail.com>

Use the 'at' argument to boxplot.  E.g.,

> x <- rep(c(2,4,8,16), c(5,10,20,30))
> y <- seq_along(x)
> par(mfrow=c(2,1))
> boxplot(y~x, at=unique(x))
> boxplot(y~x)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Sep 28, 2018 at 3:05 AM, Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Dear all,
> I am using boxplot to draw some data. Would be possible to have the
> X-axis linear (as in a scatter plot) instead of the standard
> categorical axis?
> The data I have is subdivided into three groups at the numerical
> values 1, 3, 5; boxplot treats these as categorical values; in fact, I
> can write my own labels simply by using the values 1, 2, 3 for the
> position of the labels as in the example.
> Thank you,
>
> >>>>
> # generate data.frames
> A = c(70, 22, 4, 21, 29, 35, 24, 20, 9, 21,
>       22, 12, 20, 21, 13, 18, 15, 3, 9, 23,
>       6, 5, 2, 24, 25, 21, 16, 0, 4, 1)
> B = c(17, 21, 70, 6, 23, 10, 8, 5, 22, 5,
>       21, 5, 19, 9, 23, 24, 11, 13, 7, 15,
>       25, 9, 13, 14, 11, 9, 12, 0, 5, 9)
> C = c(17, 8, 30, 22, 11, 32, 33, 8, 160, 11,
>       35, 7, 36, 15, 11, 25, 16, 6, 38, 19,
>       35, 30, 12, 27, 22, 32, 47, 39, 31, 26)
> X = rep(c(1, 3, 5),30*3)
> dfA <- data.frame(X, c(A, B, C))
> names(dfA) <- c("X", "Y")
> par(mfrow=c(2,1))
> boxplot(dfA$Y ~ dfA$X,
>         ylim=c(0, 80),
>         col="green",
>         ylab="Y-values",
>         xlab="X-values",
>         main="usual X labels"
> )
> boxplot(dfA$Y ~ dfA$X,
>         ylim=c(0, 80),
>         col="green",
>         ylab="Y-values",
>         xlab="X-values",
>         main="custom X labels",
>         xaxt="n"
> )
> x.lab = c("A", "B", "C")
> x.pos = c(1, 2, 3)
> axis(side=1, at=x.pos,
>      lab=x.lab, cex.axis=1)
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



