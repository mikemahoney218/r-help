From r|tm84 @end|ng |rom gm@||@com  Fri Jan  1 12:59:20 2021
From: r|tm84 @end|ng |rom gm@||@com (Ritwik Mohapatra)
Date: Fri, 1 Jan 2021 17:29:20 +0530
Subject: [R] Multiple values not getting displayed in output based on
 multiple input selection from dropdown in R shiny
Message-ID: <CAGY2U90zfJV_ff+C+QADKPmCMOmw5S2fe1rYRdzj3=jXjqh4+Q@mail.gmail.com>

Hi All,

Happy New Year to All.

I have been trying to create a multi input select list/dropdown using r
shiny but when i select more than two values from the input,it doesn't show
the output for all the values selected in the dropdown.

The code is as follows:

knitr::opts_chunk$set(echo = TRUE)
library(shiny)

ui <- fluidPage(
selectInput("Region","Select
Region",max_usage_hours_per_region$Region,multiple=TRUE),
tableOutput("table")
)
server <- function(input, output) {
output$table <- renderTable(
max_usage_hours_per_region[max_usage_hours_per_region$Region==input$Region,])}
shinyApp(ui = ui, server = server)

  max_usage_hours_per_region is a dataframe with the following output:-

    Region Sum_as_Hours
1   Africa    1156.0833
2 Americas     740.1667
3     APAC     740.2833
4   Europe    1895.2000
5      PDO    1053.3500
6       UK       0.0000


Can anyone help with the same.

Thanks.

Regards,
Ritwik

	[[alternative HTML version deleted]]


From @rne@henn|ng@en @end|ng |rom gm@||@com  Fri Jan  1 13:01:41 2021
From: @rne@henn|ng@en @end|ng |rom gm@||@com (Arne Henningsen)
Date: Fri, 1 Jan 2021 13:01:41 +0100
Subject: [R] Interpreting coefficient in selection and outcome Heckman
 models in sampleSelection
In-Reply-To: <2123327297.541879.1609160065199@mail1.libero.it>
References: <2123327297.541879.1609160065199@mail1.libero.it>
Message-ID: <CAMTWbJgRzzTYqyQThJapisyhQpBJCN37V7_VcnTmOQJwBsm-tg@mail.gmail.com>

Dear Marinella

Implementing a function in the sampleSelection package that calculates
marginal effects is still on my to-do list but I probably won't
implement it soon, because I have many other things with higher
priority. Sorry! However, you are invited to implement this feature in
the sampleSelection package; I would assist you with this.

Best regards,
Arne


On Mon, 28 Dec 2020 at 15:22, Marinella Cirillo via R-help
<r-help at r-project.org> wrote:
>
> Dear Arne,
>
> I have just read the exchange of messages with Mark Bulling.I was wondering if you have discovered/developed a function to calculate the marginal effects of the selection and outcome equations (sampleSelection).
>
>
>
> Thank you
>
> Marinella
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Arne Henningsen
http://www.arne-henningsen.name


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jan  1 16:49:53 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 1 Jan 2021 07:49:53 -0800
Subject: [R] Multiple values not getting displayed in output based on
 multiple input selection from dropdown in R shiny
In-Reply-To: <CAGY2U90zfJV_ff+C+QADKPmCMOmw5S2fe1rYRdzj3=jXjqh4+Q@mail.gmail.com>
References: <CAGY2U90zfJV_ff+C+QADKPmCMOmw5S2fe1rYRdzj3=jXjqh4+Q@mail.gmail.com>
Message-ID: <CAGxFJbRmute7f492u5gndjjSg3_RtMAu6TFxkfCEQ44SP4VJ9Q@mail.gmail.com>

Shiny is an R package from RStudio, a wholly separate organization from R.
So note, per the posting guide linked below,

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<http://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help
If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

RStudio maintains their own help resources  and there may even be something
specifically devoted to Shiny. So their site is where you should go for
help, not here (though you might get lucky and get a reply here).

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 1, 2021 at 3:59 AM Ritwik Mohapatra <ritm84 at gmail.com> wrote:

> Hi All,
>
> Happy New Year to All.
>
> I have been trying to create a multi input select list/dropdown using r
> shiny but when i select more than two values from the input,it doesn't show
> the output for all the values selected in the dropdown.
>
> The code is as follows:
>
> knitr::opts_chunk$set(echo = TRUE)
> library(shiny)
>
> ui <- fluidPage(
> selectInput("Region","Select
> Region",max_usage_hours_per_region$Region,multiple=TRUE),
> tableOutput("table")
> )
> server <- function(input, output) {
> output$table <- renderTable(
>
> max_usage_hours_per_region[max_usage_hours_per_region$Region==input$Region,])}
> shinyApp(ui = ui, server = server)
>
>   max_usage_hours_per_region is a dataframe with the following output:-
>
>     Region Sum_as_Hours
> 1   Africa    1156.0833
> 2 Americas     740.1667
> 3     APAC     740.2833
> 4   Europe    1895.2000
> 5      PDO    1053.3500
> 6       UK       0.0000
>
>
> Can anyone help with the same.
>
> Thanks.
>
> Regards,
> Ritwik
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jan  1 21:20:00 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 1 Jan 2021 12:20:00 -0800
Subject: [R] Does anyone have any use for this?
Message-ID: <CAGxFJbQwMLHBFc93-O4dav_+gL=RAMGAL6gcrGYxnRtbcOKz2g@mail.gmail.com>

Hi all:

In the course of playing around with other issues, I wrote the following
little function that allows functions to keep state
and easily replay and update their state.(see comments after):

memify <- function(f)
{
   if (is.primitive(f)) {
      cat("Cannot memify primitive functions.\n")
      return(NULL)
   }
   if (!inherits(f, "function"))
      stop("Argument must inherit from class 'function'")
   arglist <- list()
   structure(
      function(...) {
         m <- tryCatch(
            as.list(match.call(f)[-1]),
            error = function(e) {
               warning("Bad function call; cannot update arguments\n")
               return(NULL)
            }
         )
         nm <- names(m)
         hasname <- nm != "" #logical index of named values
         if (any(hasname)) {
            if (anyDuplicated(nm, incomparables = ""))
               warning("Duplicated names in call; only the first will be
used.")
            arglist <<- modifyList(arglist, m[hasname]) ## this is what
does the job
         }
         do.call(f, modifyList(m, arglist))
      },
      class = c("memified", class(f)))
}

Examples:

 x <- 1:9; y <- runif(9)
 plt <- memify(plot)
 x <- 1:9; y <- runif(9)
 plt(x,y, col = "blue")  ## plt "remembers" these arguments; i.e. keeps
state
 plt( type = "b") ## all other arguments as previous
 plt(col = "red") ## ditto

So my question is: Beyond allowing one to easily change/add argument values
and replay when there are lots of arguments floating around, which we often
use an IDE's editor to do, is there any real use for this? I confess that,
like Pygmalion, I have been charmed by this idea, but it could well be
useless, By all means feel free to chastise me if so.

1. I am aware that many functions already have "update" methods to "update"
their results without re-entering all arguments -- e.g. lattice graphics,
glm, etc.
2. Several packages -- rlang and R6 anyway -- but very likely more, do this
sort of thing and way more; the price is added complexity, of course.
3. I realize also that keeping state would be a bad idea in many
circumstances, e.g. essentially changing documented defaults.

Reply privately to praise or bury if you do not think this is of any
interest to readers of this list. Publicly is fine, too. If it's dumb it's
dumb.

Cheers and best wishes for a better new year for us all,

Bert Gunter

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Sat Jan  2 02:32:02 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 2 Jan 2021 14:32:02 +1300
Subject: [R] Does anyone have any use for this?
In-Reply-To: <CAGxFJbQwMLHBFc93-O4dav_+gL=RAMGAL6gcrGYxnRtbcOKz2g@mail.gmail.com>
References: <CAGxFJbQwMLHBFc93-O4dav_+gL=RAMGAL6gcrGYxnRtbcOKz2g@mail.gmail.com>
Message-ID: <CAB8pepw1+cFC6ahrpUiYjo60Fmk4LZMYHSoaHgzVXDO+5ppj4Q@mail.gmail.com>

I'm not enthusiastic about nonstandard evaluation and allowing
functions to change state data.
Currently, I use some of this in my own packages, but I'm planning to
remove most of it.

But I did have some fun with your function.

----------
plt <- memify (plot)

x <- 1:12
y1 <- seq (0, 18,, 12)
y2 <- c (
    16.88, 16.04, 13.23, 13.88, 11.85, 9.61,
     9.28,  5.81,  7.52,  3.40,  3.37, 0.07)

#test 1
plt (x, y1, type="l")
#test 2
plt (ylim = c (18, 0) )

#important econometric timeseries analysis
plt (y=y2, main="Monthly NZ GDP (Millions)")
----------

Note:
This data is not accurate.


On Sat, Jan 2, 2021 at 9:20 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Hi all:
>
> In the course of playing around with other issues, I wrote the following
> little function that allows functions to keep state
> and easily replay and update their state.(see comments after):
>
> memify <- function(f)
> {
>    if (is.primitive(f)) {
>       cat("Cannot memify primitive functions.\n")
>       return(NULL)
>    }
>    if (!inherits(f, "function"))
>       stop("Argument must inherit from class 'function'")
>    arglist <- list()
>    structure(
>       function(...) {
>          m <- tryCatch(
>             as.list(match.call(f)[-1]),
>             error = function(e) {
>                warning("Bad function call; cannot update arguments\n")
>                return(NULL)
>             }
>          )
>          nm <- names(m)
>          hasname <- nm != "" #logical index of named values
>          if (any(hasname)) {
>             if (anyDuplicated(nm, incomparables = ""))
>                warning("Duplicated names in call; only the first will be
> used.")
>             arglist <<- modifyList(arglist, m[hasname]) ## this is what
> does the job
>          }
>          do.call(f, modifyList(m, arglist))
>       },
>       class = c("memified", class(f)))
> }
>
> Examples:
>
>  x <- 1:9; y <- runif(9)
>  plt <- memify(plot)
>  x <- 1:9; y <- runif(9)
>  plt(x,y, col = "blue")  ## plt "remembers" these arguments; i.e. keeps
> state
>  plt( type = "b") ## all other arguments as previous
>  plt(col = "red") ## ditto
>
> So my question is: Beyond allowing one to easily change/add argument values
> and replay when there are lots of arguments floating around, which we often
> use an IDE's editor to do, is there any real use for this? I confess that,
> like Pygmalion, I have been charmed by this idea, but it could well be
> useless, By all means feel free to chastise me if so.
>
> 1. I am aware that many functions already have "update" methods to "update"
> their results without re-entering all arguments -- e.g. lattice graphics,
> glm, etc.
> 2. Several packages -- rlang and R6 anyway -- but very likely more, do this
> sort of thing and way more; the price is added complexity, of course.
> 3. I realize also that keeping state would be a bad idea in many
> circumstances, e.g. essentially changing documented defaults.
>
> Reply privately to praise or bury if you do not think this is of any
> interest to readers of this list. Publicly is fine, too. If it's dumb it's
> dumb.
>
> Cheers and best wishes for a better new year for us all,
>
> Bert Gunter
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Sat Jan  2 02:35:38 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 2 Jan 2021 14:35:38 +1300
Subject: [R] Does anyone have any use for this?
In-Reply-To: <CAB8pepw1+cFC6ahrpUiYjo60Fmk4LZMYHSoaHgzVXDO+5ppj4Q@mail.gmail.com>
References: <CAGxFJbQwMLHBFc93-O4dav_+gL=RAMGAL6gcrGYxnRtbcOKz2g@mail.gmail.com>
 <CAB8pepw1+cFC6ahrpUiYjo60Fmk4LZMYHSoaHgzVXDO+5ppj4Q@mail.gmail.com>
Message-ID: <CAB8pepwVEmcVx1mB5+hoistdykX-k=G=brLjxFD__v1xW5M8nQ@mail.gmail.com>

And it was supposed to say billions.

plt (main="Monthly NZ GDP (Billions)")


On Sat, Jan 2, 2021 at 2:32 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I'm not enthusiastic about nonstandard evaluation and allowing
> functions to change state data.
> Currently, I use some of this in my own packages, but I'm planning to
> remove most of it.
>
> But I did have some fun with your function.
>
> ----------
> plt <- memify (plot)
>
> x <- 1:12
> y1 <- seq (0, 18,, 12)
> y2 <- c (
>     16.88, 16.04, 13.23, 13.88, 11.85, 9.61,
>      9.28,  5.81,  7.52,  3.40,  3.37, 0.07)
>
> #test 1
> plt (x, y1, type="l")
> #test 2
> plt (ylim = c (18, 0) )
>
> #important econometric timeseries analysis
> plt (y=y2, main="Monthly NZ GDP (Millions)")
> ----------
>
> Note:
> This data is not accurate.
>
>
> On Sat, Jan 2, 2021 at 9:20 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > Hi all:
> >
> > In the course of playing around with other issues, I wrote the following
> > little function that allows functions to keep state
> > and easily replay and update their state.(see comments after):
> >
> > memify <- function(f)
> > {
> >    if (is.primitive(f)) {
> >       cat("Cannot memify primitive functions.\n")
> >       return(NULL)
> >    }
> >    if (!inherits(f, "function"))
> >       stop("Argument must inherit from class 'function'")
> >    arglist <- list()
> >    structure(
> >       function(...) {
> >          m <- tryCatch(
> >             as.list(match.call(f)[-1]),
> >             error = function(e) {
> >                warning("Bad function call; cannot update arguments\n")
> >                return(NULL)
> >             }
> >          )
> >          nm <- names(m)
> >          hasname <- nm != "" #logical index of named values
> >          if (any(hasname)) {
> >             if (anyDuplicated(nm, incomparables = ""))
> >                warning("Duplicated names in call; only the first will be
> > used.")
> >             arglist <<- modifyList(arglist, m[hasname]) ## this is what
> > does the job
> >          }
> >          do.call(f, modifyList(m, arglist))
> >       },
> >       class = c("memified", class(f)))
> > }
> >
> > Examples:
> >
> >  x <- 1:9; y <- runif(9)
> >  plt <- memify(plot)
> >  x <- 1:9; y <- runif(9)
> >  plt(x,y, col = "blue")  ## plt "remembers" these arguments; i.e. keeps
> > state
> >  plt( type = "b") ## all other arguments as previous
> >  plt(col = "red") ## ditto
> >
> > So my question is: Beyond allowing one to easily change/add argument values
> > and replay when there are lots of arguments floating around, which we often
> > use an IDE's editor to do, is there any real use for this? I confess that,
> > like Pygmalion, I have been charmed by this idea, but it could well be
> > useless, By all means feel free to chastise me if so.
> >
> > 1. I am aware that many functions already have "update" methods to "update"
> > their results without re-entering all arguments -- e.g. lattice graphics,
> > glm, etc.
> > 2. Several packages -- rlang and R6 anyway -- but very likely more, do this
> > sort of thing and way more; the price is added complexity, of course.
> > 3. I realize also that keeping state would be a bad idea in many
> > circumstances, e.g. essentially changing documented defaults.
> >
> > Reply privately to praise or bury if you do not think this is of any
> > interest to readers of this list. Publicly is fine, too. If it's dumb it's
> > dumb.
> >
> > Cheers and best wishes for a better new year for us all,
> >
> > Bert Gunter
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From peter@|@ng|e|der @end|ng |rom gm@||@com  Sat Jan  2 07:03:56 2021
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Fri, 1 Jan 2021 22:03:56 -0800
Subject: [R] Does anyone have any use for this?
In-Reply-To: <CAGxFJbQwMLHBFc93-O4dav_+gL=RAMGAL6gcrGYxnRtbcOKz2g@mail.gmail.com>
References: <CAGxFJbQwMLHBFc93-O4dav_+gL=RAMGAL6gcrGYxnRtbcOKz2g@mail.gmail.com>
Message-ID: <CA+hbrhXzWPo2tsjVmq6D6qxRWXv=pbdx8DhV7cUGUUECiKK3Gw@mail.gmail.com>

This would certainly simplify and make more readable some of my code where
I create multiple versions of the same plot calling the same function with
minor variations of a few of many arguments. Thanks!

Peter

On Fri, Jan 1, 2021 at 12:20 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Hi all:
>
> In the course of playing around with other issues, I wrote the following
> little function that allows functions to keep state
> and easily replay and update their state.(see comments after):
>
> memify <- function(f)
> {
>    if (is.primitive(f)) {
>       cat("Cannot memify primitive functions.\n")
>       return(NULL)
>    }
>    if (!inherits(f, "function"))
>       stop("Argument must inherit from class 'function'")
>    arglist <- list()
>    structure(
>       function(...) {
>          m <- tryCatch(
>             as.list(match.call(f)[-1]),
>             error = function(e) {
>                warning("Bad function call; cannot update arguments\n")
>                return(NULL)
>             }
>          )
>          nm <- names(m)
>          hasname <- nm != "" #logical index of named values
>          if (any(hasname)) {
>             if (anyDuplicated(nm, incomparables = ""))
>                warning("Duplicated names in call; only the first will be
> used.")
>             arglist <<- modifyList(arglist, m[hasname]) ## this is what
> does the job
>          }
>          do.call(f, modifyList(m, arglist))
>       },
>       class = c("memified", class(f)))
> }
>
> Examples:
>
>  x <- 1:9; y <- runif(9)
>  plt <- memify(plot)
>  x <- 1:9; y <- runif(9)
>  plt(x,y, col = "blue")  ## plt "remembers" these arguments; i.e. keeps
> state
>  plt( type = "b") ## all other arguments as previous
>  plt(col = "red") ## ditto
>
> So my question is: Beyond allowing one to easily change/add argument values
> and replay when there are lots of arguments floating around, which we often
> use an IDE's editor to do, is there any real use for this? I confess that,
> like Pygmalion, I have been charmed by this idea, but it could well be
> useless, By all means feel free to chastise me if so.
>
> 1. I am aware that many functions already have "update" methods to "update"
> their results without re-entering all arguments -- e.g. lattice graphics,
> glm, etc.
> 2. Several packages -- rlang and R6 anyway -- but very likely more, do this
> sort of thing and way more; the price is added complexity, of course.
> 3. I realize also that keeping state would be a bad idea in many
> circumstances, e.g. essentially changing documented defaults.
>
> Reply privately to praise or bury if you do not think this is of any
> interest to readers of this list. Publicly is fine, too. If it's dumb it's
> dumb.
>
> Cheers and best wishes for a better new year for us all,
>
> Bert Gunter
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sat Jan  2 21:49:58 2021
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sat, 2 Jan 2021 21:49:58 +0100
Subject: [R] error in parameters tuning of svm
Message-ID: <CA+nrPnu=q13NgQazx1PBVhU=PZqpb=WnGybTGnL=CAbSQ=j8fA@mail.gmail.com>

Hello everyone

I m using the parameters optimization of svm in mlr3. I am setting the
parameters of 'C' and 'type'.

search_space = paradox::ParamSet$new(
 params = list(paradox::ParamInt$new("C", lower = 1, upper = 7),
 paradox::ParamFct$new(id = "type", default = "eps-svr",
   levels = c("eps-svr", "nu-svr", "eps-bsvr"), tags = "train")))

When I run, it gives me the error as follows:

Error in self$assert(xs) :
  Assertion on 'xs' failed: The parameter 'C' can only be set if the
following condition is met 'type <U+2208> {eps-svr, eps-bsvr}'. Instead the
current parameter value is: type=nu-svr.

I do not know why this error comes? Any idea about it?

Warm regards

	[[alternative HTML version deleted]]


From nqu|rozp @end|ng |rom hotm@||@com  Mon Jan  4 08:07:48 2021
From: nqu|rozp @end|ng |rom hotm@||@com (=?iso-8859-1?Q?Norma_Elizabeth_Quiroz_P=E9rez?=)
Date: Mon, 4 Jan 2021 07:07:48 +0000
Subject: [R] false.nearest on tseriesChaos
Message-ID: <SN6PR11MB33270CB85D32360E30CABE01DBD20@SN6PR11MB3327.namprd11.prod.outlook.com>

Dear all:

I am new in R and in Analysis of Chaotic Time Series. I have seen that the package tseriesChaos
can estimate the embedding dimension using the FNN. In this program false.nearest does the work,
but to use it, I need the escape factor(rt) and the neighborhood diameter (eps = sd(x)/10).
My problem is that I do not understand the definitions of these parameters.
I have read Kennel, Brown, and Abarbanel?s paper. There the authors suggest two criteria for the embedding dimension looking at the FNN. One is the ratio between the distances in d and d+1 dimensions, respectively. If such ratio is bigger than a threshold R_tol, then one has a false neighbor.
The second criterio is that R_{d+1} > A_{tol} x fractal size then one has a FNN.
 What these thresholds  R_{tol} and A_{tol}  have to do  with the escape factor and the eps?


I hope someone can help me.
Thanks

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jan  4 10:08:12 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 04 Jan 2021 01:08:12 -0800
Subject: [R] false.nearest on tseriesChaos
In-Reply-To: <SN6PR11MB33270CB85D32360E30CABE01DBD20@SN6PR11MB3327.namprd11.prod.outlook.com>
References: <SN6PR11MB33270CB85D32360E30CABE01DBD20@SN6PR11MB3327.namprd11.prod.outlook.com>
Message-ID: <43442D03-45F8-40F1-A1BC-1E978BD64876@dcn.davis.ca.us>

This theory question doesn't seem on-topic here. Read the Posting Guide mentioned below... contact the package maintainer if the package description doesn't inform you where to go for support.

On January 3, 2021 11:07:48 PM PST, "Norma Elizabeth Quiroz P?rez" <nquirozp at hotmail.com> wrote:
>Dear all:
>
>I am new in R and in Analysis of Chaotic Time Series. I have seen that
>the package tseriesChaos
>can estimate the embedding dimension using the FNN. In this program
>false.nearest does the work,
>but to use it, I need the escape factor(rt) and the neighborhood
>diameter (eps = sd(x)/10).
>My problem is that I do not understand the definitions of these
>parameters.
>I have read Kennel, Brown, and Abarbanel?s paper. There the authors
>suggest two criteria for the embedding dimension looking at the FNN.
>One is the ratio between the distances in d and d+1 dimensions,
>respectively. If such ratio is bigger than a threshold R_tol, then one
>has a false neighbor.
>The second criterio is that R_{d+1} > A_{tol} x fractal size then one
>has a FNN.
>What these thresholds  R_{tol} and A_{tol}  have to do  with the escape
>factor and the eps?
>
>
>I hope someone can help me.
>Thanks
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From @tyen @end|ng |rom ntu@edu@tw  Tue Jan  5 08:14:54 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Tue, 5 Jan 2021 15:14:54 +0800
Subject: [R] Defining partial list of variables
Message-ID: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>

I constantly define variable lists from a data frame (e.g., to define a 
regression equation). Line 3 below does just that. Placing each variable 
name in quotation marks is too much work especially for a long list so I 
do that with line 4. Is there an easier way to accomplish this----to 
define a list of variable names containing "a","c","e"? Thank you!

 > data<-as.data.frame(matrix(1:30,nrow=6))
 > colnames(data)<-c("a","b","c","d","e"); data

 ? a? b? c? d? e
1 1? 7 13 19 25
2 2? 8 14 20 26
3 3? 9 15 21 27
4 4 10 16 22 28
5 5 11 17 23 29
6 6 12 18 24 30
 > x1<-c("a","c","e"); x1 # line 3
[1] "a" "c" "e"
 > x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4

[1] "a" "c" "e"


From cbuddenh@gen @end|ng |rom gm@||@com  Tue Jan  5 03:08:43 2021
From: cbuddenh@gen @end|ng |rom gm@||@com (Chris Buddenhagen)
Date: Tue, 5 Jan 2021 15:08:43 +1300
Subject: [R] Search list of igraph objects to return some with certain values
Message-ID: <CAD8OqpsF6fxqy9kbLp2mxKF2vqoYabWBthFSLqcSJ71z0Ky+jA@mail.gmail.com>

Hi all

I stochastically simulated thousands of directed igraph objects in list
format.  I want to find and plot an example graph that meets a certain
criteria (a link to a certain node). Does anyone have pointers on how to
subset a list of igraph objects?

Sincerely,


Chris Buddenhagen
cbuddenhagen at gmail.com

	[[alternative HTML version deleted]]


From tuech|er @end|ng |rom gmx@@t  Tue Jan  5 09:09:27 2021
From: tuech|er @end|ng |rom gmx@@t (Heinz Tuechler)
Date: Tue, 5 Jan 2021 09:09:27 +0100
Subject: [R] Defining partial list of variables
In-Reply-To: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
Message-ID: <961d14ee-9556-e608-b96a-82fca488c213@gmx.at>

see below

Steven Yen wrote/hat geschrieben on/am 05.01.2021 08:14:
> I constantly define variable lists from a data frame (e.g., to define a
> regression equation). Line 3 below does just that. Placing each variable
> name in quotation marks is too much work especially for a long list so I
> do that with line 4. Is there an easier way to accomplish this----to
> define a list of variable names containing "a","c","e"? Thank you!
>
>> data<-as.data.frame(matrix(1:30,nrow=6))
>> colnames(data)<-c("a","b","c","d","e"); data
>
>   a  b  c  d  e
> 1 1  7 13 19 25
> 2 2  8 14 20 26
> 3 3  9 15 21 27
> 4 4 10 16 22 28
> 5 5 11 17 23 29
> 6 6 12 18 24 30
>> x1<-c("a","c","e"); x1 # line 3
> [1] "a" "c" "e"
>> x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4
>
> [1] "a" "c" "e"
>
What about:
x3 <- names(data)[c(1,3,5)]
x3
[1] "a" "c" "e"

If I have to compile longer vectors of variable names I do it as follows:
First I use:
dput(names(data))
resulting in a vector of names.
c("a", "b", "c", "d", "e")
Then I edit the output by hand, e.g.
x4 <- c("a", "b", "c", "d", "e")
x4 <- c("a", "c", "e")
This is especially useful with long names, where I could easily make
typing errors.

regards,
Heinz


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan  5 09:18:27 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 05 Jan 2021 00:18:27 -0800
Subject: [R] Defining partial list of variables
In-Reply-To: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
Message-ID: <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>

IMO if you want to hardcode a formula then simply hardcode a formula. If you want 20 formulas, write 20 formulas. Is that really so bad?

If you want to have an abbreviated way to specify sets of variables without conforming to R syntax then put them into data files and read them in using a format of your choice.

But using NSE to avoid using quotes for entering what amounts to in-script data is abuse of the language justified by laziness... the amount of work you put yourself and anyone else who reads your code through is excessive relative to the benefit gained.

NSE has its strengths... but as a method of creating data objects it sucks. Note that even the tidyverse (now) requires you to use quotes when you are not directly referring to something that already exists. And if you were... you might as well be creating a formula.

On January 4, 2021 11:14:54 PM PST, Steven Yen <styen at ntu.edu.tw> wrote:
>I constantly define variable lists from a data frame (e.g., to define a
>
>regression equation). Line 3 below does just that. Placing each
>variable 
>name in quotation marks is too much work especially for a long list so
>I 
>do that with line 4. Is there an easier way to accomplish this----to 
>define a list of variable names containing "a","c","e"? Thank you!
>
> > data<-as.data.frame(matrix(1:30,nrow=6))
> > colnames(data)<-c("a","b","c","d","e"); data
>
> ? a? b? c? d? e
>1 1? 7 13 19 25
>2 2? 8 14 20 26
>3 3? 9 15 21 27
>4 4 10 16 22 28
>5 5 11 17 23 29
>6 6 12 18 24 30
> > x1<-c("a","c","e"); x1 # line 3
>[1] "a" "c" "e"
> > x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4
>
>[1] "a" "c" "e"
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan  5 09:23:38 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 05 Jan 2021 00:23:38 -0800
Subject: [R] Search list of igraph objects to return some with certain
 values
In-Reply-To: <CAD8OqpsF6fxqy9kbLp2mxKF2vqoYabWBthFSLqcSJ71z0Ky+jA@mail.gmail.com>
References: <CAD8OqpsF6fxqy9kbLp2mxKF2vqoYabWBthFSLqcSJ71z0Ky+jA@mail.gmail.com>
Message-ID: <E53E49DB-82BD-43BC-8034-BABC715C2060@dcn.davis.ca.us>

Standard logical indexing. Write a function that returns TRUE or FALSE given an igraph object. Use sapply or Vectorize to make a logical vector as long as your list. Then use that vector to index the list with single bracket indexing.

On January 4, 2021 6:08:43 PM PST, Chris Buddenhagen <cbuddenhagen at gmail.com> wrote:
>Hi all
>
>I stochastically simulated thousands of directed igraph objects in list
>format.  I want to find and plot an example graph that meets a certain
>criteria (a link to a certain node). Does anyone have pointers on how
>to
>subset a list of igraph objects?
>
>Sincerely,
>
>
>Chris Buddenhagen
>cbuddenhagen at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @tyen @end|ng |rom ntu@edu@tw  Tue Jan  5 10:01:11 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Tue, 5 Jan 2021 17:01:11 +0800
Subject: [R] Defining partial list of variables
In-Reply-To: <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
 <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>
Message-ID: <e468d57b-9096-6132-b058-e29ac89254a8@ntu.edu.tw>

Thank you, Jeff. IMO, we are all here to make R work better to suit our 
various needs. All I am asking is an easier way to define variable list 
zx, differently from the way z0 , x0, and treat are defined.

 > zx<-colnames(subset(mydata,select=c(
+ age,exercise,income,white,black,hispanic,base,somcol,grad,employed,
+???? unable,homeowner,married,divorced,widowed)))
 > z0<-c("fruit","highblood")
 > x0<-c("vgood","poor")
 > treat<-"depression"
 > eq1 <-my.formula(y="depression",x=zx,z0)
 > eq2 <-my.formula(y="bmi",?????? x=zx,x0)
 > eq2t<-my.formula(y="bmi",?????? x=zx,treat)
 > eqs<-list(eq1,eq2); eqs
[[1]]
depression ~ age + exercise + income + white + black + hispanic +
 ??? base + somcol + grad + employed + unable + homeowner + married +
 ??? divorced + widowed + fruit + highblood

[[2]]
bmi ~ age + exercise + income + white + black + hispanic + base +
 ??? somcol + grad + employed + unable + homeowner + married +
 ??? divorced + widowed + vgood + poor

 > eqt<-list(eq1,eq2t); eqt
[[1]]
depression ~ age + exercise + income + white + black + hispanic +
 ??? base + somcol + grad + employed + unable + homeowner + married +
 ??? divorced + widowed + fruit + highblood

[[2]]
bmi ~ age + exercise + income + white + black + hispanic + base +
 ??? somcol + grad + employed + unable + homeowner + married +
 ??? divorced + widowed + depression

On 2021/1/5 ?? 04:18, Jeff Newmiller wrote:
> IMO if you want to hardcode a formula then simply hardcode a formula. If you want 20 formulas, write 20 formulas. Is that really so bad?
>
> If you want to have an abbreviated way to specify sets of variables without conforming to R syntax then put them into data files and read them in using a format of your choice.
>
> But using NSE to avoid using quotes for entering what amounts to in-script data is abuse of the language justified by laziness... the amount of work you put yourself and anyone else who reads your code through is excessive relative to the benefit gained.
>
> NSE has its strengths... but as a method of creating data objects it sucks. Note that even the tidyverse (now) requires you to use quotes when you are not directly referring to something that already exists. And if you were... you might as well be creating a formula.
>
> On January 4, 2021 11:14:54 PM PST, Steven Yen <styen at ntu.edu.tw> wrote:
>> I constantly define variable lists from a data frame (e.g., to define a
>>
>> regression equation). Line 3 below does just that. Placing each
>> variable
>> name in quotation marks is too much work especially for a long list so
>> I
>> do that with line 4. Is there an easier way to accomplish this----to
>> define a list of variable names containing "a","c","e"? Thank you!
>>
>>> data<-as.data.frame(matrix(1:30,nrow=6))
>>> colnames(data)<-c("a","b","c","d","e"); data
>>  ? a? b? c? d? e
>> 1 1? 7 13 19 25
>> 2 2? 8 14 20 26
>> 3 3? 9 15 21 27
>> 4 4 10 16 22 28
>> 5 5 11 17 23 29
>> 6 6 12 18 24 30
>>> x1<-c("a","c","e"); x1 # line 3
>> [1] "a" "c" "e"
>>> x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4
>> [1] "a" "c" "e"
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Tue Jan  5 10:34:46 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 5 Jan 2021 11:34:46 +0200
Subject: [R] Defining partial list of variables
In-Reply-To: <e468d57b-9096-6132-b058-e29ac89254a8@ntu.edu.tw>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
 <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>
 <e468d57b-9096-6132-b058-e29ac89254a8@ntu.edu.tw>
Message-ID: <CAGgJW74nqB9qBJfmd5rvo-qPxQUg=HfFM+jsEe_r1-JQesTA5A@mail.gmail.com>

zx<-strsplit("age,exercise,income,white,black,hispanic,base,somcol,grad,employed,unable,homeowner,married,divorced,widowed",",")



On Tue, Jan 5, 2021 at 11:01 AM Steven Yen <styen at ntu.edu.tw> wrote:

> Thank you, Jeff. IMO, we are all here to make R work better to suit our
> various needs. All I am asking is an easier way to define variable list
> zx, differently from the way z0 , x0, and treat are defined.
>
>  > zx<-colnames(subset(mydata,select=c(
> + age,exercise,income,white,black,hispanic,base,somcol,grad,employed,
> +     unable,homeowner,married,divorced,widowed)))
>  > z0<-c("fruit","highblood")
>  > x0<-c("vgood","poor")
>  > treat<-"depression"
>  > eq1 <-my.formula(y="depression",x=zx,z0)
>  > eq2 <-my.formula(y="bmi",       x=zx,x0)
>  > eq2t<-my.formula(y="bmi",       x=zx,treat)
>  > eqs<-list(eq1,eq2); eqs
> [[1]]
> depression ~ age + exercise + income + white + black + hispanic +
>      base + somcol + grad + employed + unable + homeowner + married +
>      divorced + widowed + fruit + highblood
>
> [[2]]
> bmi ~ age + exercise + income + white + black + hispanic + base +
>      somcol + grad + employed + unable + homeowner + married +
>      divorced + widowed + vgood + poor
>
>  > eqt<-list(eq1,eq2t); eqt
> [[1]]
> depression ~ age + exercise + income + white + black + hispanic +
>      base + somcol + grad + employed + unable + homeowner + married +
>      divorced + widowed + fruit + highblood
>
> [[2]]
> bmi ~ age + exercise + income + white + black + hispanic + base +
>      somcol + grad + employed + unable + homeowner + married +
>      divorced + widowed + depression
>
> On 2021/1/5 ?? 04:18, Jeff Newmiller wrote:
> > IMO if you want to hardcode a formula then simply hardcode a formula. If
> you want 20 formulas, write 20 formulas. Is that really so bad?
> >
> > If you want to have an abbreviated way to specify sets of variables
> without conforming to R syntax then put them into data files and read them
> in using a format of your choice.
> >
> > But using NSE to avoid using quotes for entering what amounts to
> in-script data is abuse of the language justified by laziness... the amount
> of work you put yourself and anyone else who reads your code through is
> excessive relative to the benefit gained.
> >
> > NSE has its strengths... but as a method of creating data objects it
> sucks. Note that even the tidyverse (now) requires you to use quotes when
> you are not directly referring to something that already exists. And if you
> were... you might as well be creating a formula.
> >
> > On January 4, 2021 11:14:54 PM PST, Steven Yen <styen at ntu.edu.tw> wrote:
> >> I constantly define variable lists from a data frame (e.g., to define a
> >>
> >> regression equation). Line 3 below does just that. Placing each
> >> variable
> >> name in quotation marks is too much work especially for a long list so
> >> I
> >> do that with line 4. Is there an easier way to accomplish this----to
> >> define a list of variable names containing "a","c","e"? Thank you!
> >>
> >>> data<-as.data.frame(matrix(1:30,nrow=6))
> >>> colnames(data)<-c("a","b","c","d","e"); data
> >>    a  b  c  d  e
> >> 1 1  7 13 19 25
> >> 2 2  8 14 20 26
> >> 3 3  9 15 21 27
> >> 4 4 10 16 22 28
> >> 5 5 11 17 23 29
> >> 6 6 12 18 24 30
> >>> x1<-c("a","c","e"); x1 # line 3
> >> [1] "a" "c" "e"
> >>> x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4
> >> [1] "a" "c" "e"
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Tue Jan  5 10:47:55 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Tue, 5 Jan 2021 17:47:55 +0800
Subject: [R] Defining partial list of variables
In-Reply-To: <CAGgJW74nqB9qBJfmd5rvo-qPxQUg=HfFM+jsEe_r1-JQesTA5A@mail.gmail.com>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
 <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>
 <e468d57b-9096-6132-b058-e29ac89254a8@ntu.edu.tw>
 <CAGgJW74nqB9qBJfmd5rvo-qPxQUg=HfFM+jsEe_r1-JQesTA5A@mail.gmail.com>
Message-ID: <fd8b09ca-fe2f-3612-a93a-7f32564e34df@ntu.edu.tw>

Here we go! BUT, it works great for a continuous line. With line 
break(s), I got the nuisance "\n" inserted.

 > x<-strsplit("hhsize,urban,male,gov,nongov,married",","); x
[[1]]
[1] "hhsize"? "urban"?? "male"??? "gov"???? "nongov"? "married"

 > x<-strsplit("hhsize,urban,male,
+???????????? gov,nongov,married",","); x
[[1]]
[1] "hhsize"??????????? "urban"???????????? "male" "\n??????????? gov"
[5] "nongov"??????????? "married"

On 2021/1/5 ?? 05:34, Eric Berger wrote:
> zx<-strsplit("age,exercise,income,white,black,hispanic,base,somcol,grad,employed,unable,homeowner,married,divorced,widowed",",")
>
>
>
> On Tue, Jan 5, 2021 at 11:01 AM Steven Yen <styen at ntu.edu.tw 
> <mailto:styen at ntu.edu.tw>> wrote:
>
>     Thank you, Jeff. IMO, we are all here to make R work better to
>     suit our
>     various needs. All I am asking is an easier way to define variable
>     list
>     zx, differently from the way z0 , x0, and treat are defined.
>
>     ?> zx<-colnames(subset(mydata,select=c(
>     + age,exercise,income,white,black,hispanic,base,somcol,grad,employed,
>     +???? unable,homeowner,married,divorced,widowed)))
>     ?> z0<-c("fruit","highblood")
>     ?> x0<-c("vgood","poor")
>     ?> treat<-"depression"
>     ?> eq1 <-my.formula(y="depression",x=zx,z0)
>     ?> eq2 <-my.formula(y="bmi",?????? x=zx,x0)
>     ?> eq2t<-my.formula(y="bmi",?????? x=zx,treat)
>     ?> eqs<-list(eq1,eq2); eqs
>     [[1]]
>     depression ~ age + exercise + income + white + black + hispanic +
>     ???? base + somcol + grad + employed + unable + homeowner + married +
>     ???? divorced + widowed + fruit + highblood
>
>     [[2]]
>     bmi ~ age + exercise + income + white + black + hispanic + base +
>     ???? somcol + grad + employed + unable + homeowner + married +
>     ???? divorced + widowed + vgood + poor
>
>     ?> eqt<-list(eq1,eq2t); eqt
>     [[1]]
>     depression ~ age + exercise + income + white + black + hispanic +
>     ???? base + somcol + grad + employed + unable + homeowner + married +
>     ???? divorced + widowed + fruit + highblood
>
>     [[2]]
>     bmi ~ age + exercise + income + white + black + hispanic + base +
>     ???? somcol + grad + employed + unable + homeowner + married +
>     ???? divorced + widowed + depression
>
>     On 2021/1/5 ?? 04:18, Jeff Newmiller wrote:
>     > IMO if you want to hardcode a formula then simply hardcode a
>     formula. If you want 20 formulas, write 20 formulas. Is that
>     really so bad?
>     >
>     > If you want to have an abbreviated way to specify sets of
>     variables without conforming to R syntax then put them into data
>     files and read them in using a format of your choice.
>     >
>     > But using NSE to avoid using quotes for entering what amounts to
>     in-script data is abuse of the language justified by laziness...
>     the amount of work you put yourself and anyone else who reads your
>     code through is excessive relative to the benefit gained.
>     >
>     > NSE has its strengths... but as a method of creating data
>     objects it sucks. Note that even the tidyverse (now) requires you
>     to use quotes when you are not directly referring to something
>     that already exists. And if you were... you might as well be
>     creating a formula.
>     >
>     > On January 4, 2021 11:14:54 PM PST, Steven Yen <styen at ntu.edu.tw
>     <mailto:styen at ntu.edu.tw>> wrote:
>     >> I constantly define variable lists from a data frame (e.g., to
>     define a
>     >>
>     >> regression equation). Line 3 below does just that. Placing each
>     >> variable
>     >> name in quotation marks is too much work especially for a long
>     list so
>     >> I
>     >> do that with line 4. Is there an easier way to accomplish
>     this----to
>     >> define a list of variable names containing "a","c","e"? Thank you!
>     >>
>     >>> data<-as.data.frame(matrix(1:30,nrow=6))
>     >>> colnames(data)<-c("a","b","c","d","e"); data
>     >>? ? a? b? c? d? e
>     >> 1 1? 7 13 19 25
>     >> 2 2? 8 14 20 26
>     >> 3 3? 9 15 21 27
>     >> 4 4 10 16 22 28
>     >> 5 5 11 17 23 29
>     >> 6 6 12 18 24 30
>     >>> x1<-c("a","c","e"); x1 # line 3
>     >> [1] "a" "c" "e"
>     >>> x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4
>     >> [1] "a" "c" "e"
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     >> PLEASE do read the posting guide
>     >> http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     >> and provide commented, minimal, self-contained, reproducible code.
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Jan  5 11:01:25 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 5 Jan 2021 12:01:25 +0200
Subject: [R] Defining partial list of variables
In-Reply-To: <fd8b09ca-fe2f-3612-a93a-7f32564e34df@ntu.edu.tw>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
 <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>
 <e468d57b-9096-6132-b058-e29ac89254a8@ntu.edu.tw>
 <CAGgJW74nqB9qBJfmd5rvo-qPxQUg=HfFM+jsEe_r1-JQesTA5A@mail.gmail.com>
 <fd8b09ca-fe2f-3612-a93a-7f32564e34df@ntu.edu.tw>
Message-ID: <CAGgJW76R-sfKGYXbWvez_VkNu9abpDJTG=5QcC4ts5dfzq+VTw@mail.gmail.com>

If your column names have no spaces the following should work

 x<-strsplit(gsub("[\n ]","",
             "hhsize,urban,male,
+             gov,nongov,married"),","); x

On Tue, Jan 5, 2021 at 11:47 AM Steven Yen <styen at ntu.edu.tw> wrote:

> Here we go! BUT, it works great for a continuous line. With line break(s),
> I got the nuisance "\n" inserted.
>
> > x<-strsplit("hhsize,urban,male,gov,nongov,married",","); x
> [[1]]
> [1] "hhsize"  "urban"   "male"    "gov"     "nongov"  "married"
>
> > x<-strsplit("hhsize,urban,male,
> +             gov,nongov,married",","); x
> [[1]]
> [1] "hhsize"            "urban"             "male"
> "\n            gov"
> [5] "nongov"            "married"
> On 2021/1/5 ?? 05:34, Eric Berger wrote:
>
>
> zx<-strsplit("age,exercise,income,white,black,hispanic,base,somcol,grad,employed,unable,homeowner,married,divorced,widowed",",")
>
>
>
> On Tue, Jan 5, 2021 at 11:01 AM Steven Yen <styen at ntu.edu.tw> wrote:
>
>> Thank you, Jeff. IMO, we are all here to make R work better to suit our
>> various needs. All I am asking is an easier way to define variable list
>> zx, differently from the way z0 , x0, and treat are defined.
>>
>>  > zx<-colnames(subset(mydata,select=c(
>> + age,exercise,income,white,black,hispanic,base,somcol,grad,employed,
>> +     unable,homeowner,married,divorced,widowed)))
>>  > z0<-c("fruit","highblood")
>>  > x0<-c("vgood","poor")
>>  > treat<-"depression"
>>  > eq1 <-my.formula(y="depression",x=zx,z0)
>>  > eq2 <-my.formula(y="bmi",       x=zx,x0)
>>  > eq2t<-my.formula(y="bmi",       x=zx,treat)
>>  > eqs<-list(eq1,eq2); eqs
>> [[1]]
>> depression ~ age + exercise + income + white + black + hispanic +
>>      base + somcol + grad + employed + unable + homeowner + married +
>>      divorced + widowed + fruit + highblood
>>
>> [[2]]
>> bmi ~ age + exercise + income + white + black + hispanic + base +
>>      somcol + grad + employed + unable + homeowner + married +
>>      divorced + widowed + vgood + poor
>>
>>  > eqt<-list(eq1,eq2t); eqt
>> [[1]]
>> depression ~ age + exercise + income + white + black + hispanic +
>>      base + somcol + grad + employed + unable + homeowner + married +
>>      divorced + widowed + fruit + highblood
>>
>> [[2]]
>> bmi ~ age + exercise + income + white + black + hispanic + base +
>>      somcol + grad + employed + unable + homeowner + married +
>>      divorced + widowed + depression
>>
>> On 2021/1/5 ?? 04:18, Jeff Newmiller wrote:
>> > IMO if you want to hardcode a formula then simply hardcode a formula.
>> If you want 20 formulas, write 20 formulas. Is that really so bad?
>> >
>> > If you want to have an abbreviated way to specify sets of variables
>> without conforming to R syntax then put them into data files and read them
>> in using a format of your choice.
>> >
>> > But using NSE to avoid using quotes for entering what amounts to
>> in-script data is abuse of the language justified by laziness... the amount
>> of work you put yourself and anyone else who reads your code through is
>> excessive relative to the benefit gained.
>> >
>> > NSE has its strengths... but as a method of creating data objects it
>> sucks. Note that even the tidyverse (now) requires you to use quotes when
>> you are not directly referring to something that already exists. And if you
>> were... you might as well be creating a formula.
>> >
>> > On January 4, 2021 11:14:54 PM PST, Steven Yen <styen at ntu.edu.tw>
>> wrote:
>> >> I constantly define variable lists from a data frame (e.g., to define a
>> >>
>> >> regression equation). Line 3 below does just that. Placing each
>> >> variable
>> >> name in quotation marks is too much work especially for a long list so
>> >> I
>> >> do that with line 4. Is there an easier way to accomplish this----to
>> >> define a list of variable names containing "a","c","e"? Thank you!
>> >>
>> >>> data<-as.data.frame(matrix(1:30,nrow=6))
>> >>> colnames(data)<-c("a","b","c","d","e"); data
>> >>    a  b  c  d  e
>> >> 1 1  7 13 19 25
>> >> 2 2  8 14 20 26
>> >> 3 3  9 15 21 27
>> >> 4 4 10 16 22 28
>> >> 5 5 11 17 23 29
>> >> 6 6 12 18 24 30
>> >>> x1<-c("a","c","e"); x1 # line 3
>> >> [1] "a" "c" "e"
>> >>> x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4
>> >> [1] "a" "c" "e"
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Tue Jan  5 11:59:28 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Tue, 5 Jan 2021 18:59:28 +0800
Subject: [R] Defining partial list of variables
In-Reply-To: <CAGgJW76R-sfKGYXbWvez_VkNu9abpDJTG=5QcC4ts5dfzq+VTw@mail.gmail.com>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
 <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>
 <e468d57b-9096-6132-b058-e29ac89254a8@ntu.edu.tw>
 <CAGgJW74nqB9qBJfmd5rvo-qPxQUg=HfFM+jsEe_r1-JQesTA5A@mail.gmail.com>
 <fd8b09ca-fe2f-3612-a93a-7f32564e34df@ntu.edu.tw>
 <CAGgJW76R-sfKGYXbWvez_VkNu9abpDJTG=5QcC4ts5dfzq+VTw@mail.gmail.com>
Message-ID: <a50842f7-c3a3-56d6-f7f1-319e308f62d8@ntu.edu.tw>

Thanks Eric. Perhaps I should know when to stop. The approach produces a 
slightly different variable list (note the [[1]]). Consequently, I was 
not able to use xx in defining my regression formula.

 > x<-colnames(subset(mydata,select=c(

+??? hhsize,urban,male,
+??? age3045,age4659,age60, # age1529
+??? highsc,tert,?????????? # primary
+??? gov,nongov,??????????? # unemp
+??? married))); x
 ?[1] "hhsize"? "urban"?? "male"??? "age3045" "age4659" "age60" 
"highsc"? "tert"
 ?[9] "gov"???? "nongov"? "married"
 > xx<-strsplit(gsub("[\n ]","",
+??? "hhsize,urban,male,
+???? age3045,age4659,age60,
+???? highsc,tert,
+???? gov,nongov,
+???? married"
+ ),","); xx
[[1]]
 ?[1] "hhsize"? "urban"?? "male"??? "age3045" "age4659" "age60" 
"highsc"? "tert"
 ?[9] "gov"???? "nongov"? "married"

 > eq1<-my.formula(y="cig",x=x); eq1
cig ~ hhsize + urban + male + age3045 + age4659 + age60 + highsc +
 ??? tert + gov + nongov + married
 > eq2<-my.formula(y="cig",x=xx); eq2
cig ~ c("hhsize", "urban", "male", "age3045", "age4659", "age60",
 ??? "highsc", "tert", "gov", "nongov", "married")

On 2021/1/5 ?? 06:01, Eric Berger wrote:
> If your column names have no spaces the following should work
>
> ?x<-strsplit(gsub("[\n ]","",
> ?"hhsize,urban,male,
> + gov,nongov,married"),","); x
>
> On Tue, Jan 5, 2021 at 11:47 AM Steven Yen <styen at ntu.edu.tw 
> <mailto:styen at ntu.edu.tw>> wrote:
>
>     Here we go! BUT, it works great for a continuous line. With line
>     break(s), I got the nuisance "\n" inserted.
>
>     > x<-strsplit("hhsize,urban,male,gov,nongov,married",","); x
>     [[1]]
>     [1] "hhsize"? "urban"?? "male"??? "gov"???? "nongov" "married"
>
>     > x<-strsplit("hhsize,urban,male,
>     +???????????? gov,nongov,married",","); x
>     [[1]]
>     [1] "hhsize"??????????? "urban" "male"????????????? "\n???????????
>     gov"
>     [5] "nongov"??????????? "married"
>
>     On 2021/1/5 ?? 05:34, Eric Berger wrote:
>>     zx<-strsplit("age,exercise,income,white,black,hispanic,base,somcol,grad,employed,unable,homeowner,married,divorced,widowed",",")
>>
>>
>>
>>     On Tue, Jan 5, 2021 at 11:01 AM Steven Yen <styen at ntu.edu.tw
>>     <mailto:styen at ntu.edu.tw>> wrote:
>>
>>         Thank you, Jeff. IMO, we are all here to make R work better
>>         to suit our
>>         various needs. All I am asking is an easier way to define
>>         variable list
>>         zx, differently from the way z0 , x0, and treat are defined.
>>
>>         ?> zx<-colnames(subset(mydata,select=c(
>>         +
>>         age,exercise,income,white,black,hispanic,base,somcol,grad,employed,
>>         +???? unable,homeowner,married,divorced,widowed)))
>>         ?> z0<-c("fruit","highblood")
>>         ?> x0<-c("vgood","poor")
>>         ?> treat<-"depression"
>>         ?> eq1 <-my.formula(y="depression",x=zx,z0)
>>         ?> eq2 <-my.formula(y="bmi",?????? x=zx,x0)
>>         ?> eq2t<-my.formula(y="bmi",?????? x=zx,treat)
>>         ?> eqs<-list(eq1,eq2); eqs
>>         [[1]]
>>         depression ~ age + exercise + income + white + black + hispanic +
>>         ???? base + somcol + grad + employed + unable + homeowner +
>>         married +
>>         ???? divorced + widowed + fruit + highblood
>>
>>         [[2]]
>>         bmi ~ age + exercise + income + white + black + hispanic + base +
>>         ???? somcol + grad + employed + unable + homeowner + married +
>>         ???? divorced + widowed + vgood + poor
>>
>>         ?> eqt<-list(eq1,eq2t); eqt
>>         [[1]]
>>         depression ~ age + exercise + income + white + black + hispanic +
>>         ???? base + somcol + grad + employed + unable + homeowner +
>>         married +
>>         ???? divorced + widowed + fruit + highblood
>>
>>         [[2]]
>>         bmi ~ age + exercise + income + white + black + hispanic + base +
>>         ???? somcol + grad + employed + unable + homeowner + married +
>>         ???? divorced + widowed + depression
>>
>>         On 2021/1/5 ?? 04:18, Jeff Newmiller wrote:
>>         > IMO if you want to hardcode a formula then simply hardcode
>>         a formula. If you want 20 formulas, write 20 formulas. Is
>>         that really so bad?
>>         >
>>         > If you want to have an abbreviated way to specify sets of
>>         variables without conforming to R syntax then put them into
>>         data files and read them in using a format of your choice.
>>         >
>>         > But using NSE to avoid using quotes for entering what
>>         amounts to in-script data is abuse of the language justified
>>         by laziness... the amount of work you put yourself and anyone
>>         else who reads your code through is excessive relative to the
>>         benefit gained.
>>         >
>>         > NSE has its strengths... but as a method of creating data
>>         objects it sucks. Note that even the tidyverse (now) requires
>>         you to use quotes when you are not directly referring to
>>         something that already exists. And if you were... you might
>>         as well be creating a formula.
>>         >
>>         > On January 4, 2021 11:14:54 PM PST, Steven Yen
>>         <styen at ntu.edu.tw <mailto:styen at ntu.edu.tw>> wrote:
>>         >> I constantly define variable lists from a data frame
>>         (e.g., to define a
>>         >>
>>         >> regression equation). Line 3 below does just that. Placing
>>         each
>>         >> variable
>>         >> name in quotation marks is too much work especially for a
>>         long list so
>>         >> I
>>         >> do that with line 4. Is there an easier way to accomplish
>>         this----to
>>         >> define a list of variable names containing "a","c","e"?
>>         Thank you!
>>         >>
>>         >>> data<-as.data.frame(matrix(1:30,nrow=6))
>>         >>> colnames(data)<-c("a","b","c","d","e"); data
>>         >>? ? a? b? c? d? e
>>         >> 1 1? 7 13 19 25
>>         >> 2 2? 8 14 20 26
>>         >> 3 3? 9 15 21 27
>>         >> 4 4 10 16 22 28
>>         >> 5 5 11 17 23 29
>>         >> 6 6 12 18 24 30
>>         >>> x1<-c("a","c","e"); x1 # line 3
>>         >> [1] "a" "c" "e"
>>         >>> x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4
>>         >> [1] "a" "c" "e"
>>         >>
>>         >> ______________________________________________
>>         >> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         >> https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         >> PLEASE do read the posting guide
>>         >> http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         >> and provide commented, minimal, self-contained,
>>         reproducible code.
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible
>>         code.
>>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Jan  5 12:08:02 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 5 Jan 2021 13:08:02 +0200
Subject: [R] Defining partial list of variables
In-Reply-To: <a50842f7-c3a3-56d6-f7f1-319e308f62d8@ntu.edu.tw>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
 <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>
 <e468d57b-9096-6132-b058-e29ac89254a8@ntu.edu.tw>
 <CAGgJW74nqB9qBJfmd5rvo-qPxQUg=HfFM+jsEe_r1-JQesTA5A@mail.gmail.com>
 <fd8b09ca-fe2f-3612-a93a-7f32564e34df@ntu.edu.tw>
 <CAGgJW76R-sfKGYXbWvez_VkNu9abpDJTG=5QcC4ts5dfzq+VTw@mail.gmail.com>
 <a50842f7-c3a3-56d6-f7f1-319e308f62d8@ntu.edu.tw>
Message-ID: <CAGgJW77fnn7gfczXeJJ4bxo3rhF2OuV=K_jFRUtGZa6PjdSScA@mail.gmail.com>

wrap it in unlist

xx <- unlist(strsplit( .... ))



On Tue, Jan 5, 2021 at 12:59 PM Steven Yen <styen at ntu.edu.tw> wrote:

> Thanks Eric. Perhaps I should know when to stop. The approach produces a
> slightly different variable list (note the [[1]]). Consequently, I was not
> able to use xx in defining my regression formula.
>
> > x<-colnames(subset(mydata,select=c(
>
> +    hhsize,urban,male,
> +    age3045,age4659,age60, # age1529
> +    highsc,tert,           # primary
> +    gov,nongov,            # unemp
> +    married))); x
>  [1] "hhsize"  "urban"   "male"    "age3045" "age4659" "age60"   "highsc"
> "tert"
>  [9] "gov"     "nongov"  "married"
> > xx<-strsplit(gsub("[\n ]","",
> +    "hhsize,urban,male,
> +     age3045,age4659,age60,
> +     highsc,tert,
> +     gov,nongov,
> +     married"
> + ),","); xx
> [[1]]
>  [1] "hhsize"  "urban"   "male"    "age3045" "age4659" "age60"   "highsc"
> "tert"
>  [9] "gov"     "nongov"  "married"
>
> > eq1<-my.formula(y="cig",x=x); eq1
> cig ~ hhsize + urban + male + age3045 + age4659 + age60 + highsc +
>     tert + gov + nongov + married
> > eq2<-my.formula(y="cig",x=xx); eq2
> cig ~ c("hhsize", "urban", "male", "age3045", "age4659", "age60",
>     "highsc", "tert", "gov", "nongov", "married")
>
> On 2021/1/5 ?? 06:01, Eric Berger wrote:
>
> If your column names have no spaces the following should work
>
>  x<-strsplit(gsub("[\n ]","",
>              "hhsize,urban,male,
> +             gov,nongov,married"),","); x
>
> On Tue, Jan 5, 2021 at 11:47 AM Steven Yen <styen at ntu.edu.tw> wrote:
>
>> Here we go! BUT, it works great for a continuous line. With line
>> break(s), I got the nuisance "\n" inserted.
>>
>> > x<-strsplit("hhsize,urban,male,gov,nongov,married",","); x
>> [[1]]
>> [1] "hhsize"  "urban"   "male"    "gov"     "nongov"  "married"
>>
>> > x<-strsplit("hhsize,urban,male,
>> +             gov,nongov,married",","); x
>> [[1]]
>> [1] "hhsize"            "urban"             "male"
>> "\n            gov"
>> [5] "nongov"            "married"
>> On 2021/1/5 ?? 05:34, Eric Berger wrote:
>>
>>
>> zx<-strsplit("age,exercise,income,white,black,hispanic,base,somcol,grad,employed,unable,homeowner,married,divorced,widowed",",")
>>
>>
>>
>> On Tue, Jan 5, 2021 at 11:01 AM Steven Yen <styen at ntu.edu.tw> wrote:
>>
>>> Thank you, Jeff. IMO, we are all here to make R work better to suit our
>>> various needs. All I am asking is an easier way to define variable list
>>> zx, differently from the way z0 , x0, and treat are defined.
>>>
>>>  > zx<-colnames(subset(mydata,select=c(
>>> + age,exercise,income,white,black,hispanic,base,somcol,grad,employed,
>>> +     unable,homeowner,married,divorced,widowed)))
>>>  > z0<-c("fruit","highblood")
>>>  > x0<-c("vgood","poor")
>>>  > treat<-"depression"
>>>  > eq1 <-my.formula(y="depression",x=zx,z0)
>>>  > eq2 <-my.formula(y="bmi",       x=zx,x0)
>>>  > eq2t<-my.formula(y="bmi",       x=zx,treat)
>>>  > eqs<-list(eq1,eq2); eqs
>>> [[1]]
>>> depression ~ age + exercise + income + white + black + hispanic +
>>>      base + somcol + grad + employed + unable + homeowner + married +
>>>      divorced + widowed + fruit + highblood
>>>
>>> [[2]]
>>> bmi ~ age + exercise + income + white + black + hispanic + base +
>>>      somcol + grad + employed + unable + homeowner + married +
>>>      divorced + widowed + vgood + poor
>>>
>>>  > eqt<-list(eq1,eq2t); eqt
>>> [[1]]
>>> depression ~ age + exercise + income + white + black + hispanic +
>>>      base + somcol + grad + employed + unable + homeowner + married +
>>>      divorced + widowed + fruit + highblood
>>>
>>> [[2]]
>>> bmi ~ age + exercise + income + white + black + hispanic + base +
>>>      somcol + grad + employed + unable + homeowner + married +
>>>      divorced + widowed + depression
>>>
>>> On 2021/1/5 ?? 04:18, Jeff Newmiller wrote:
>>> > IMO if you want to hardcode a formula then simply hardcode a formula.
>>> If you want 20 formulas, write 20 formulas. Is that really so bad?
>>> >
>>> > If you want to have an abbreviated way to specify sets of variables
>>> without conforming to R syntax then put them into data files and read them
>>> in using a format of your choice.
>>> >
>>> > But using NSE to avoid using quotes for entering what amounts to
>>> in-script data is abuse of the language justified by laziness... the amount
>>> of work you put yourself and anyone else who reads your code through is
>>> excessive relative to the benefit gained.
>>> >
>>> > NSE has its strengths... but as a method of creating data objects it
>>> sucks. Note that even the tidyverse (now) requires you to use quotes when
>>> you are not directly referring to something that already exists. And if you
>>> were... you might as well be creating a formula.
>>> >
>>> > On January 4, 2021 11:14:54 PM PST, Steven Yen <styen at ntu.edu.tw>
>>> wrote:
>>> >> I constantly define variable lists from a data frame (e.g., to define
>>> a
>>> >>
>>> >> regression equation). Line 3 below does just that. Placing each
>>> >> variable
>>> >> name in quotation marks is too much work especially for a long list so
>>> >> I
>>> >> do that with line 4. Is there an easier way to accomplish this----to
>>> >> define a list of variable names containing "a","c","e"? Thank you!
>>> >>
>>> >>> data<-as.data.frame(matrix(1:30,nrow=6))
>>> >>> colnames(data)<-c("a","b","c","d","e"); data
>>> >>    a  b  c  d  e
>>> >> 1 1  7 13 19 25
>>> >> 2 2  8 14 20 26
>>> >> 3 3  9 15 21 27
>>> >> 4 4 10 16 22 28
>>> >> 5 5 11 17 23 29
>>> >> 6 6 12 18 24 30
>>> >>> x1<-c("a","c","e"); x1 # line 3
>>> >> [1] "a" "c" "e"
>>> >>> x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4
>>> >> [1] "a" "c" "e"
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Tue Jan  5 13:29:03 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Tue, 5 Jan 2021 20:29:03 +0800
Subject: [R] Defining partial list of variables
In-Reply-To: <CAGgJW77fnn7gfczXeJJ4bxo3rhF2OuV=K_jFRUtGZa6PjdSScA@mail.gmail.com>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
 <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>
 <e468d57b-9096-6132-b058-e29ac89254a8@ntu.edu.tw>
 <CAGgJW74nqB9qBJfmd5rvo-qPxQUg=HfFM+jsEe_r1-JQesTA5A@mail.gmail.com>
 <fd8b09ca-fe2f-3612-a93a-7f32564e34df@ntu.edu.tw>
 <CAGgJW76R-sfKGYXbWvez_VkNu9abpDJTG=5QcC4ts5dfzq+VTw@mail.gmail.com>
 <a50842f7-c3a3-56d6-f7f1-319e308f62d8@ntu.edu.tw>
 <CAGgJW77fnn7gfczXeJJ4bxo3rhF2OuV=K_jFRUtGZa6PjdSScA@mail.gmail.com>
Message-ID: <70f2ed07-c78f-0886-7f06-ae86a74c53f5@ntu.edu.tw>

Thanks Eric. Yes, "unlist" makes a difference. Below, I am doing not 
regression but summary to keep the example simple.

 > set.seed(123)
 > data<-matrix(runif(1:25),nrow=5)
 > colnames(data)<-c("x1","x2","x3","x4","x5"); data
 ??????????? x1??????? x2??????? x3???????? x4??????? x5
[1,] 0.2875775 0.0455565 0.9568333 0.89982497 0.8895393
[2,] 0.7883051 0.5281055 0.4533342 0.24608773 0.6928034
[3,] 0.4089769 0.8924190 0.6775706 0.04205953 0.6405068
[4,] 0.8830174 0.5514350 0.5726334 0.32792072 0.9942698
[5,] 0.9404673 0.4566147 0.1029247 0.95450365 0.6557058
 > j<-strsplit(gsub("[\n ]","","x1,x3,x5"),",")
 > j<-unlist(j); j
[1] "x1" "x3" "x5"
 > summary(data[,j])
 ?????? x1?????????????? x3?????????????? x5
 ?Min.?? :0.2876?? Min.?? :0.1029?? Min.?? :0.6405
 ?1st Qu.:0.4090?? 1st Qu.:0.4533?? 1st Qu.:0.6557
 ?Median :0.7883?? Median :0.5726?? Median :0.6928
 ?Mean?? :0.6617?? Mean?? :0.5527?? Mean?? :0.7746
 ?3rd Qu.:0.8830?? 3rd Qu.:0.6776?? 3rd Qu.:0.8895
 ?Max.?? :0.9405?? Max.?? :0.9568?? Max.?? :0.9943

On 2021/1/5 ?? 07:08, Eric Berger wrote:
> wrap it in unlist
>
> xx <- unlist(strsplit( .... ))
>
>
>
> On Tue, Jan 5, 2021 at 12:59 PM Steven Yen <styen at ntu.edu.tw 
> <mailto:styen at ntu.edu.tw>> wrote:
>
>     Thanks Eric. Perhaps I should know when to stop. The approach
>     produces a slightly different variable list (note the [[1]]).
>     Consequently, I was not able to use xx in defining my regression
>     formula.
>
>     > x<-colnames(subset(mydata,select=c(
>
>     +??? hhsize,urban,male,
>     +??? age3045,age4659,age60, # age1529
>     +??? highsc,tert,?????????? # primary
>     +??? gov,nongov,??????????? # unemp
>     +??? married))); x
>     ?[1] "hhsize"? "urban"?? "male"??? "age3045" "age4659" "age60"??
>     "highsc"? "tert"
>     ?[9] "gov"???? "nongov"? "married"
>     > xx<-strsplit(gsub("[\n ]","",
>     +??? "hhsize,urban,male,
>     +???? age3045,age4659,age60,
>     +???? highsc,tert,
>     +???? gov,nongov,
>     +???? married"
>     + ),","); xx
>     [[1]]
>     ?[1] "hhsize"? "urban"?? "male"??? "age3045" "age4659" "age60"??
>     "highsc"? "tert"
>     ?[9] "gov"???? "nongov"? "married"
>
>     > eq1<-my.formula(y="cig",x=x); eq1
>     cig ~ hhsize + urban + male + age3045 + age4659 + age60 + highsc +
>     ??? tert + gov + nongov + married
>     > eq2<-my.formula(y="cig",x=xx); eq2
>     cig ~ c("hhsize", "urban", "male", "age3045", "age4659", "age60",
>     ??? "highsc", "tert", "gov", "nongov", "married")
>
>     On 2021/1/5 ?? 06:01, Eric Berger wrote:
>>     If your column names have no spaces the following should work
>>
>>     ?x<-strsplit(gsub("[\n ]","",
>>     ?"hhsize,urban,male,
>>     + gov,nongov,married"),","); x
>>
>>     On Tue, Jan 5, 2021 at 11:47 AM Steven Yen <styen at ntu.edu.tw
>>     <mailto:styen at ntu.edu.tw>> wrote:
>>
>>         Here we go! BUT, it works great for a continuous line. With
>>         line break(s), I got the nuisance "\n" inserted.
>>
>>         > x<-strsplit("hhsize,urban,male,gov,nongov,married",","); x
>>         [[1]]
>>         [1] "hhsize"? "urban"?? "male"??? "gov" "nongov"? "married"
>>
>>         > x<-strsplit("hhsize,urban,male,
>>         +???????????? gov,nongov,married",","); x
>>         [[1]]
>>         [1] "hhsize"??????????? "urban" "male"?????????????
>>         "\n??????????? gov"
>>         [5] "nongov"??????????? "married"
>>
>>         On 2021/1/5 ?? 05:34, Eric Berger wrote:
>>>         zx<-strsplit("age,exercise,income,white,black,hispanic,base,somcol,grad,employed,unable,homeowner,married,divorced,widowed",",")
>>>
>>>
>>>
>>>         On Tue, Jan 5, 2021 at 11:01 AM Steven Yen <styen at ntu.edu.tw
>>>         <mailto:styen at ntu.edu.tw>> wrote:
>>>
>>>             Thank you, Jeff. IMO, we are all here to make R work
>>>             better to suit our
>>>             various needs. All I am asking is an easier way to
>>>             define variable list
>>>             zx, differently from the way z0 , x0, and treat are defined.
>>>
>>>             ?> zx<-colnames(subset(mydata,select=c(
>>>             +
>>>             age,exercise,income,white,black,hispanic,base,somcol,grad,employed,
>>>             + unable,homeowner,married,divorced,widowed)))
>>>             ?> z0<-c("fruit","highblood")
>>>             ?> x0<-c("vgood","poor")
>>>             ?> treat<-"depression"
>>>             ?> eq1 <-my.formula(y="depression",x=zx,z0)
>>>             ?> eq2 <-my.formula(y="bmi", x=zx,x0)
>>>             ?> eq2t<-my.formula(y="bmi", x=zx,treat)
>>>             ?> eqs<-list(eq1,eq2); eqs
>>>             [[1]]
>>>             depression ~ age + exercise + income + white + black +
>>>             hispanic +
>>>             ???? base + somcol + grad + employed + unable +
>>>             homeowner + married +
>>>             ???? divorced + widowed + fruit + highblood
>>>
>>>             [[2]]
>>>             bmi ~ age + exercise + income + white + black + hispanic
>>>             + base +
>>>             ???? somcol + grad + employed + unable + homeowner +
>>>             married +
>>>             ???? divorced + widowed + vgood + poor
>>>
>>>             ?> eqt<-list(eq1,eq2t); eqt
>>>             [[1]]
>>>             depression ~ age + exercise + income + white + black +
>>>             hispanic +
>>>             ???? base + somcol + grad + employed + unable +
>>>             homeowner + married +
>>>             ???? divorced + widowed + fruit + highblood
>>>
>>>             [[2]]
>>>             bmi ~ age + exercise + income + white + black + hispanic
>>>             + base +
>>>             ???? somcol + grad + employed + unable + homeowner +
>>>             married +
>>>             ???? divorced + widowed + depression
>>>
>>>             On 2021/1/5 ?? 04:18, Jeff Newmiller wrote:
>>>             > IMO if you want to hardcode a formula then simply
>>>             hardcode a formula. If you want 20 formulas, write 20
>>>             formulas. Is that really so bad?
>>>             >
>>>             > If you want to have an abbreviated way to specify sets
>>>             of variables without conforming to R syntax then put
>>>             them into data files and read them in using a format of
>>>             your choice.
>>>             >
>>>             > But using NSE to avoid using quotes for entering what
>>>             amounts to in-script data is abuse of the language
>>>             justified by laziness... the amount of work you put
>>>             yourself and anyone else who reads your code through is
>>>             excessive relative to the benefit gained.
>>>             >
>>>             > NSE has its strengths... but as a method of creating
>>>             data objects it sucks. Note that even the tidyverse
>>>             (now) requires you to use quotes when you are not
>>>             directly referring to something that already exists. And
>>>             if you were... you might as well be creating a formula.
>>>             >
>>>             > On January 4, 2021 11:14:54 PM PST, Steven Yen
>>>             <styen at ntu.edu.tw <mailto:styen at ntu.edu.tw>> wrote:
>>>             >> I constantly define variable lists from a data frame
>>>             (e.g., to define a
>>>             >>
>>>             >> regression equation). Line 3 below does just that.
>>>             Placing each
>>>             >> variable
>>>             >> name in quotation marks is too much work especially
>>>             for a long list so
>>>             >> I
>>>             >> do that with line 4. Is there an easier way to
>>>             accomplish this----to
>>>             >> define a list of variable names containing
>>>             "a","c","e"? Thank you!
>>>             >>
>>>             >>> data<-as.data.frame(matrix(1:30,nrow=6))
>>>             >>> colnames(data)<-c("a","b","c","d","e"); data
>>>             >>? ? a? b? c? d? e
>>>             >> 1 1? 7 13 19 25
>>>             >> 2 2? 8 14 20 26
>>>             >> 3 3? 9 15 21 27
>>>             >> 4 4 10 16 22 28
>>>             >> 5 5 11 17 23 29
>>>             >> 6 6 12 18 24 30
>>>             >>> x1<-c("a","c","e"); x1 # line 3
>>>             >> [1] "a" "c" "e"
>>>             >>> x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4
>>>             >> [1] "a" "c" "e"
>>>             >>
>>>             >> ______________________________________________
>>>             >> R-help at r-project.org <mailto:R-help at r-project.org>
>>>             mailing list -- To UNSUBSCRIBE and more, see
>>>             >> https://stat.ethz.ch/mailman/listinfo/r-help
>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>             >> PLEASE do read the posting guide
>>>             >> http://www.R-project.org/posting-guide.html
>>>             <http://www.R-project.org/posting-guide.html>
>>>             >> and provide commented, minimal, self-contained,
>>>             reproducible code.
>>>
>>>             ______________________________________________
>>>             R-help at r-project.org <mailto:R-help at r-project.org>
>>>             mailing list -- To UNSUBSCRIBE and more, see
>>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>             PLEASE do read the posting guide
>>>             http://www.R-project.org/posting-guide.html
>>>             <http://www.R-project.org/posting-guide.html>
>>>             and provide commented, minimal, self-contained,
>>>             reproducible code.
>>>

	[[alternative HTML version deleted]]


From tuech|er @end|ng |rom gmx@@t  Tue Jan  5 13:49:37 2021
From: tuech|er @end|ng |rom gmx@@t (Heinz Tuechler)
Date: Tue, 5 Jan 2021 13:49:37 +0100
Subject: [R] Defining partial list of variables
In-Reply-To: <70f2ed07-c78f-0886-7f06-ae86a74c53f5@ntu.edu.tw>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
 <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>
 <e468d57b-9096-6132-b058-e29ac89254a8@ntu.edu.tw>
 <CAGgJW74nqB9qBJfmd5rvo-qPxQUg=HfFM+jsEe_r1-JQesTA5A@mail.gmail.com>
 <fd8b09ca-fe2f-3612-a93a-7f32564e34df@ntu.edu.tw>
 <CAGgJW76R-sfKGYXbWvez_VkNu9abpDJTG=5QcC4ts5dfzq+VTw@mail.gmail.com>
 <a50842f7-c3a3-56d6-f7f1-319e308f62d8@ntu.edu.tw>
 <CAGgJW77fnn7gfczXeJJ4bxo3rhF2OuV=K_jFRUtGZa6PjdSScA@mail.gmail.com>
 <70f2ed07-c78f-0886-7f06-ae86a74c53f5@ntu.edu.tw>
Message-ID: <120a955a-1a76-370d-32e0-2ff422f52192@gmx.at>

What about the Cs()-function in Hmisc?
library(Hmisc)
Cs(a,b,c)
[1] "a" "b" "c"

Steven Yen wrote/hat geschrieben on/am 05.01.2021 13:29:
> Thanks Eric. Yes, "unlist" makes a difference. Below, I am doing not
> regression but summary to keep the example simple.
>
>  > set.seed(123)
>  > data<-matrix(runif(1:25),nrow=5)
>  > colnames(data)<-c("x1","x2","x3","x4","x5"); data
>              x1        x2        x3         x4        x5
> [1,] 0.2875775 0.0455565 0.9568333 0.89982497 0.8895393
> [2,] 0.7883051 0.5281055 0.4533342 0.24608773 0.6928034
> [3,] 0.4089769 0.8924190 0.6775706 0.04205953 0.6405068
> [4,] 0.8830174 0.5514350 0.5726334 0.32792072 0.9942698
> [5,] 0.9404673 0.4566147 0.1029247 0.95450365 0.6557058
>  > j<-strsplit(gsub("[\n ]","","x1,x3,x5"),",")
>  > j<-unlist(j); j
> [1] "x1" "x3" "x5"
>  > summary(data[,j])
>         x1               x3               x5
>   Min.   :0.2876   Min.   :0.1029   Min.   :0.6405
>   1st Qu.:0.4090   1st Qu.:0.4533   1st Qu.:0.6557
>   Median :0.7883   Median :0.5726   Median :0.6928
>   Mean   :0.6617   Mean   :0.5527   Mean   :0.7746
>   3rd Qu.:0.8830   3rd Qu.:0.6776   3rd Qu.:0.8895
>   Max.   :0.9405   Max.   :0.9568   Max.   :0.9943
>
> On 2021/1/5 ?? 07:08, Eric Berger wrote:
>> wrap it in unlist
>>
>> xx <- unlist(strsplit( .... ))
>>
>>
>>
>> On Tue, Jan 5, 2021 at 12:59 PM Steven Yen <styen at ntu.edu.tw
>> <mailto:styen at ntu.edu.tw>> wrote:
>>
>>     Thanks Eric. Perhaps I should know when to stop. The approach
>>     produces a slightly different variable list (note the [[1]]).
>>     Consequently, I was not able to use xx in defining my regression
>>     formula.
>>
>>     > x<-colnames(subset(mydata,select=c(
>>
>>     +    hhsize,urban,male,
>>     +    age3045,age4659,age60, # age1529
>>     +    highsc,tert,           # primary
>>     +    gov,nongov,            # unemp
>>     +    married))); x
>>      [1] "hhsize"  "urban"   "male"    "age3045" "age4659" "age60"
>>     "highsc"  "tert"
>>      [9] "gov"     "nongov"  "married"
>>     > xx<-strsplit(gsub("[\n ]","",
>>     +    "hhsize,urban,male,
>>     +     age3045,age4659,age60,
>>     +     highsc,tert,
>>     +     gov,nongov,
>>     +     married"
>>     + ),","); xx
>>     [[1]]
>>      [1] "hhsize"  "urban"   "male"    "age3045" "age4659" "age60"
>>     "highsc"  "tert"
>>      [9] "gov"     "nongov"  "married"
>>
>>     > eq1<-my.formula(y="cig",x=x); eq1
>>     cig ~ hhsize + urban + male + age3045 + age4659 + age60 + highsc +
>>         tert + gov + nongov + married
>>     > eq2<-my.formula(y="cig",x=xx); eq2
>>     cig ~ c("hhsize", "urban", "male", "age3045", "age4659", "age60",
>>         "highsc", "tert", "gov", "nongov", "married")
>>
>>     On 2021/1/5 ?? 06:01, Eric Berger wrote:
>>>     If your column names have no spaces the following should work
>>>
>>>      x<-strsplit(gsub("[\n ]","",
>>>      "hhsize,urban,male,
>>>     + gov,nongov,married"),","); x
>>>
>>>     On Tue, Jan 5, 2021 at 11:47 AM Steven Yen <styen at ntu.edu.tw
>>>     <mailto:styen at ntu.edu.tw>> wrote:
>>>
>>>         Here we go! BUT, it works great for a continuous line. With
>>>         line break(s), I got the nuisance "\n" inserted.
>>>
>>>         > x<-strsplit("hhsize,urban,male,gov,nongov,married",","); x
>>>         [[1]]
>>>         [1] "hhsize"  "urban"   "male"    "gov" "nongov"  "married"
>>>
>>>         > x<-strsplit("hhsize,urban,male,
>>>         +             gov,nongov,married",","); x
>>>         [[1]]
>>>         [1] "hhsize"            "urban" "male"
>>>         "\n            gov"
>>>         [5] "nongov"            "married"
>>>
>>>         On 2021/1/5 ?? 05:34, Eric Berger wrote:
>>>>         zx<-strsplit("age,exercise,income,white,black,hispanic,base,somcol,grad,employed,unable,homeowner,married,divorced,widowed",",")
>>>>
>>>>
>>>>
>>>>         On Tue, Jan 5, 2021 at 11:01 AM Steven Yen <styen at ntu.edu.tw
>>>>         <mailto:styen at ntu.edu.tw>> wrote:
>>>>
>>>>             Thank you, Jeff. IMO, we are all here to make R work
>>>>             better to suit our
>>>>             various needs. All I am asking is an easier way to
>>>>             define variable list
>>>>             zx, differently from the way z0 , x0, and treat are defined.
>>>>
>>>>              > zx<-colnames(subset(mydata,select=c(
>>>>             +
>>>>             age,exercise,income,white,black,hispanic,base,somcol,grad,employed,
>>>>             + unable,homeowner,married,divorced,widowed)))
>>>>              > z0<-c("fruit","highblood")
>>>>              > x0<-c("vgood","poor")
>>>>              > treat<-"depression"
>>>>              > eq1 <-my.formula(y="depression",x=zx,z0)
>>>>              > eq2 <-my.formula(y="bmi", x=zx,x0)
>>>>              > eq2t<-my.formula(y="bmi", x=zx,treat)
>>>>              > eqs<-list(eq1,eq2); eqs
>>>>             [[1]]
>>>>             depression ~ age + exercise + income + white + black +
>>>>             hispanic +
>>>>                  base + somcol + grad + employed + unable +
>>>>             homeowner + married +
>>>>                  divorced + widowed + fruit + highblood
>>>>
>>>>             [[2]]
>>>>             bmi ~ age + exercise + income + white + black + hispanic
>>>>             + base +
>>>>                  somcol + grad + employed + unable + homeowner +
>>>>             married +
>>>>                  divorced + widowed + vgood + poor
>>>>
>>>>              > eqt<-list(eq1,eq2t); eqt
>>>>             [[1]]
>>>>             depression ~ age + exercise + income + white + black +
>>>>             hispanic +
>>>>                  base + somcol + grad + employed + unable +
>>>>             homeowner + married +
>>>>                  divorced + widowed + fruit + highblood
>>>>
>>>>             [[2]]
>>>>             bmi ~ age + exercise + income + white + black + hispanic
>>>>             + base +
>>>>                  somcol + grad + employed + unable + homeowner +
>>>>             married +
>>>>                  divorced + widowed + depression
>>>>
>>>>             On 2021/1/5 ?? 04:18, Jeff Newmiller wrote:
>>>>             > IMO if you want to hardcode a formula then simply
>>>>             hardcode a formula. If you want 20 formulas, write 20
>>>>             formulas. Is that really so bad?
>>>>             >
>>>>             > If you want to have an abbreviated way to specify sets
>>>>             of variables without conforming to R syntax then put
>>>>             them into data files and read them in using a format of
>>>>             your choice.
>>>>             >
>>>>             > But using NSE to avoid using quotes for entering what
>>>>             amounts to in-script data is abuse of the language
>>>>             justified by laziness... the amount of work you put
>>>>             yourself and anyone else who reads your code through is
>>>>             excessive relative to the benefit gained.
>>>>             >
>>>>             > NSE has its strengths... but as a method of creating
>>>>             data objects it sucks. Note that even the tidyverse
>>>>             (now) requires you to use quotes when you are not
>>>>             directly referring to something that already exists. And
>>>>             if you were... you might as well be creating a formula.
>>>>             >
>>>>             > On January 4, 2021 11:14:54 PM PST, Steven Yen
>>>>             <styen at ntu.edu.tw <mailto:styen at ntu.edu.tw>> wrote:
>>>>             >> I constantly define variable lists from a data frame
>>>>             (e.g., to define a
>>>>             >>
>>>>             >> regression equation). Line 3 below does just that.
>>>>             Placing each
>>>>             >> variable
>>>>             >> name in quotation marks is too much work especially
>>>>             for a long list so
>>>>             >> I
>>>>             >> do that with line 4. Is there an easier way to
>>>>             accomplish this----to
>>>>             >> define a list of variable names containing
>>>>             "a","c","e"? Thank you!
>>>>             >>
>>>>             >>> data<-as.data.frame(matrix(1:30,nrow=6))
>>>>             >>> colnames(data)<-c("a","b","c","d","e"); data
>>>>             >>    a  b  c  d  e
>>>>             >> 1 1  7 13 19 25
>>>>             >> 2 2  8 14 20 26
>>>>             >> 3 3  9 15 21 27
>>>>             >> 4 4 10 16 22 28
>>>>             >> 5 5 11 17 23 29
>>>>             >> 6 6 12 18 24 30
>>>>             >>> x1<-c("a","c","e"); x1 # line 3
>>>>             >> [1] "a" "c" "e"
>>>>             >>> x2<-colnames(subset(data,select=c(a,c,e))); x2 # line 4
>>>>             >> [1] "a" "c" "e"
>>>>             >>
>>>>             >> ______________________________________________
>>>>             >> R-help at r-project.org <mailto:R-help at r-project.org>
>>>>             mailing list -- To UNSUBSCRIBE and more, see
>>>>             >> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>             >> PLEASE do read the posting guide
>>>>             >> http://www.R-project.org/posting-guide.html
>>>>             <http://www.R-project.org/posting-guide.html>
>>>>             >> and provide commented, minimal, self-contained,
>>>>             reproducible code.
>>>>
>>>>             ______________________________________________
>>>>             R-help at r-project.org <mailto:R-help at r-project.org>
>>>>             mailing list -- To UNSUBSCRIBE and more, see
>>>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>             PLEASE do read the posting guide
>>>>             http://www.R-project.org/posting-guide.html
>>>>             <http://www.R-project.org/posting-guide.html>
>>>>             and provide commented, minimal, self-contained,
>>>>             reproducible code.
>>>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kev|neg@n31 @end|ng |rom gm@||@com  Tue Jan  5 13:26:18 2021
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Tue, 5 Jan 2021 12:26:18 +0000
Subject: [R] Error Running Bootstrap Function within Wrapper Function
Message-ID: <CAMKuLyTw13c=1qfWE9XSev1ajKDZm36dEy+Y1ER19F7SHPXuSQ@mail.gmail.com>

Hello,

I am currently trying to solve a problem with the boot package and writing
a function within a function in R. I have developed several functions to
perform the lasso but continue to receive an error when bootstrapping these
functions within a wrapper function. When I perform these methods using
tsboot outside the wrapper function, I do not get an error. However, when
placed within my function I continue to get the error "Error in t[r, ] <-
res[[r]] : number of items to replace is not a multiple of length."

I've attached an example of my functions as well as a data file of the data
I am using. I'm sorry the file is so large, but I do not get a problem with
a smaller number of observations.


library(boot)
library(glmnet)
library(np)
foo1 <- function(data,index){ #index is the bootstrap sample index
  x <- data[index, -1] %>%
    as.matrix() %>%
    unname()
  y <- data[index, 1] %>%
    scale(center = TRUE, scale = FALSE) %>%
    as.matrix() %>%
    unname()
  ols <- lm(y ~ x)
  # The intercept estimate should be dropped.
  ols.coef <- as.numeric(coef(ols))[-1]
  ols.coef[is.na(ols.coef)] <- 0
  ## The intercept estimate should be dropped.
  lasso <- cv.glmnet(x, y, alpha = 1,
                     penalty.factor = 1 / abs(ols.coef))
  # Select nonzero coefficients from bic.out
  coef <- as.vector(coef(lasso,
                         s = lasso$lambda.min))[-1]
  return(coef)
}
foo2 <- function(data, index){ #index is the bootstrap sample index
  x <- data[index, -1] %>%
    as.matrix() %>%
    unname()
  y <- data[index, 1] %>%
    scale(center = TRUE, scale = FALSE) %>%
    as.matrix() %>%
    unname()
  # ic.glmnet provides coefficients with lowest BIC
  ols <- lm(y ~ x)
  # The intercept estimate should be dropped.
  ols.coef <- as.numeric(coef(ols))[-1]
  ols.coef[is.na(ols.coef)] <- 0
  lasso <- cv.glmnet(x, y, alpha = 1,
                     penalty.factor = 1 / abs(ols.coef))
  # Select nonzero coefficients from bic.out
  coef <- as.vector(coef(lasso,
                         s = lasso$lambda.min))[-1]
  coef_nonzero <- coef != 0
  if(sum(coef_nonzero) > 0) {
    ls_obj <- lm(y ~ x[, coef_nonzero, drop = FALSE])
    ls_coef <- as.vector(coef(ls_obj))[-1]
    coef[coef_nonzero] <- ls_coef
  }
  return(coef)
}
foo3 <- function(data, num_samples) {
  bstar <- b.star(data[, 1], round = TRUE)
  # Select Block Length of circular block result
  blocklength <- bstar[, 2]
  init_boot_ts <- tsboot(tseries = data,
                         statistic = foo1,
                         R = num_samples, l = blocklength,
                         sim = "fixed")
  final_boot_ts <- tsboot(tseries = data,
                          statistic = foo2,
                          R = num_samples,
                          l = blocklength, sim = "fixed")
  # point estimates
  final_boot_t0 <- final_boot_ts$t0
  return(list(point_estimates = final_boot_t0))
}
num_samples <- 50
test.foo3 <- foo3(data, num_samples = num_samples)

Which *sometimes *works, however, sometimes I get the error: ?Error in t[r,
] <- res[[r]] : number of items to replace is not a multiple of length".
I've also gotten the error "Error in x[, coef_nonzero, drop = FALSE]
:(subscript) logical subscript too long" at times, when running foo2 within
foo3. Which seems to be unclear as there should never be an index which is
greater than the number of columns in x.
As I stated, this error particularly occurs when I increase the number of
bootstrap samples I try to run, and only when I run foo3. When I run foo1
and foo2 separately, I don?t get an error at all. I?m wondering if there is
something I need to add to my function ?foo3? to ensure that an error like
this doesn?t occur since I am calling several other functions within this
function, ie., tsboot, foo1, and foo2.

Lastly, although I have not provided an example here, I get an error for
this code when running with lapply for several dataframes similar to the
attached.

Again, I apologise for attaching such a large data frame but the function
seems to work with fewer observations. Perhaps it is a data issue?

Thanks

From bgunter@4567 @end|ng |rom gm@||@com  Tue Jan  5 17:15:52 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 5 Jan 2021 08:15:52 -0800
Subject: [R] Defining partial list of variables
In-Reply-To: <120a955a-1a76-370d-32e0-2ff422f52192@gmx.at>
References: <1409200c-b1f8-51e6-0710-d7968209277b@ntu.edu.tw>
 <EE6A9991-E2EC-43B4-8B57-75ADE48B735C@dcn.davis.ca.us>
 <e468d57b-9096-6132-b058-e29ac89254a8@ntu.edu.tw>
 <CAGgJW74nqB9qBJfmd5rvo-qPxQUg=HfFM+jsEe_r1-JQesTA5A@mail.gmail.com>
 <fd8b09ca-fe2f-3612-a93a-7f32564e34df@ntu.edu.tw>
 <CAGgJW76R-sfKGYXbWvez_VkNu9abpDJTG=5QcC4ts5dfzq+VTw@mail.gmail.com>
 <a50842f7-c3a3-56d6-f7f1-319e308f62d8@ntu.edu.tw>
 <CAGgJW77fnn7gfczXeJJ4bxo3rhF2OuV=K_jFRUtGZa6PjdSScA@mail.gmail.com>
 <70f2ed07-c78f-0886-7f06-ae86a74c53f5@ntu.edu.tw>
 <120a955a-1a76-370d-32e0-2ff422f52192@gmx.at>
Message-ID: <CAGxFJbSeYCdJgEuw3z2yS71p8Uu+-JePTZ0K0CfRA04dNUPH+A@mail.gmail.com>

I may not I properly understand the context of this discussion, and, in
particular what the my.formula() function does. But if I do, the following,
from ?formula, seems relevant and would indicate that the discussion is
unnecessary:

"There are two special interpretations of . in a formula. The usual one is
in the context of a data argument of model fitting functions and means ?all
columns not otherwise in the formula?:"

This means you can fit different models just by indexing the columns -- by
number --  you wish to use in a data argument, viz:

y <- runif(100)
dat <- data.frame(matrix(runif(500), ncol = 5))
names(dat) <- letters[1:5]
head(dat)

## Use columns 1,3, and 5 only
mdl1 <- lm(y ~ ., data = dat[,c(1,3,5)])

## Result:
 summary(mdl1)

Call:
lm(formula = y ~ ., data = dat[, c(1, 3, 5)])

Residuals:
     Min       1Q   Median       3Q      Max
-0.52334 -0.27494  0.01245  0.28637  0.51998

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.51461    0.08236   6.248 1.14e-08 ***
a            0.01516    0.10928   0.139    0.890
c            0.03517    0.10399   0.338    0.736
e           -0.09437    0.10967  -0.861    0.392
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.299 on 96 degrees of freedom
Multiple R-squared:  0.008256, Adjusted R-squared:  -0.02274
F-statistic: 0.2664 on 3 and 96 DF,  p-value: 0.8495


If I have misunderstood and this is unhelpful, just ignore without comment.
You don't need to waste time explaining it to me.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 5, 2021 at 4:49 AM Heinz Tuechler <tuechler at gmx.at> wrote:

> What about the Cs()-function in Hmisc?
> library(Hmisc)
> Cs(a,b,c)
> [1] "a" "b" "c"
>
> Steven Yen wrote/hat geschrieben on/am 05.01.2021 13:29:
> > Thanks Eric. Yes, "unlist" makes a difference. Below, I am doing not
> > regression but summary to keep the example simple.
> >
> >  > set.seed(123)
> >  > data<-matrix(runif(1:25),nrow=5)
> >  > colnames(data)<-c("x1","x2","x3","x4","x5"); data
> >              x1        x2        x3         x4        x5
> > [1,] 0.2875775 0.0455565 0.9568333 0.89982497 0.8895393
> > [2,] 0.7883051 0.5281055 0.4533342 0.24608773 0.6928034
> > [3,] 0.4089769 0.8924190 0.6775706 0.04205953 0.6405068
> > [4,] 0.8830174 0.5514350 0.5726334 0.32792072 0.9942698
> > [5,] 0.9404673 0.4566147 0.1029247 0.95450365 0.6557058
> >  > j<-strsplit(gsub("[\n ]","","x1,x3,x5"),",")
> >  > j<-unlist(j); j
> > [1] "x1" "x3" "x5"
> >  > summary(data[,j])
> >         x1               x3               x5
> >   Min.   :0.2876   Min.   :0.1029   Min.   :0.6405
> >   1st Qu.:0.4090   1st Qu.:0.4533   1st Qu.:0.6557
> >   Median :0.7883   Median :0.5726   Median :0.6928
> >   Mean   :0.6617   Mean   :0.5527   Mean   :0.7746
> >   3rd Qu.:0.8830   3rd Qu.:0.6776   3rd Qu.:0.8895
> >   Max.   :0.9405   Max.   :0.9568   Max.   :0.9943
> >
> > On 2021/1/5 ?? 07:08, Eric Berger wrote:
> >> wrap it in unlist
> >>
> >> xx <- unlist(strsplit( .... ))
> >>
> >>
> >>
> >> On Tue, Jan 5, 2021 at 12:59 PM Steven Yen <styen at ntu.edu.tw
> >> <mailto:styen at ntu.edu.tw>> wrote:
> >>
> >>     Thanks Eric. Perhaps I should know when to stop. The approach
> >>     produces a slightly different variable list (note the [[1]]).
> >>     Consequently, I was not able to use xx in defining my regression
> >>     formula.
> >>
> >>     > x<-colnames(subset(mydata,select=c(
> >>
> >>     +    hhsize,urban,male,
> >>     +    age3045,age4659,age60, # age1529
> >>     +    highsc,tert,           # primary
> >>     +    gov,nongov,            # unemp
> >>     +    married))); x
> >>      [1] "hhsize"  "urban"   "male"    "age3045" "age4659" "age60"
> >>     "highsc"  "tert"
> >>      [9] "gov"     "nongov"  "married"
> >>     > xx<-strsplit(gsub("[\n ]","",
> >>     +    "hhsize,urban,male,
> >>     +     age3045,age4659,age60,
> >>     +     highsc,tert,
> >>     +     gov,nongov,
> >>     +     married"
> >>     + ),","); xx
> >>     [[1]]
> >>      [1] "hhsize"  "urban"   "male"    "age3045" "age4659" "age60"
> >>     "highsc"  "tert"
> >>      [9] "gov"     "nongov"  "married"
> >>
> >>     > eq1<-my.formula(y="cig",x=x); eq1
> >>     cig ~ hhsize + urban + male + age3045 + age4659 + age60 + highsc +
> >>         tert + gov + nongov + married
> >>     > eq2<-my.formula(y="cig",x=xx); eq2
> >>     cig ~ c("hhsize", "urban", "male", "age3045", "age4659", "age60",
> >>         "highsc", "tert", "gov", "nongov", "married")
> >>
> >>     On 2021/1/5 ?? 06:01, Eric Berger wrote:
> >>>     If your column names have no spaces the following should work
> >>>
> >>>      x<-strsplit(gsub("[\n ]","",
> >>>      "hhsize,urban,male,
> >>>     + gov,nongov,married"),","); x
> >>>
> >>>     On Tue, Jan 5, 2021 at 11:47 AM Steven Yen <styen at ntu.edu.tw
> >>>     <mailto:styen at ntu.edu.tw>> wrote:
> >>>
> >>>         Here we go! BUT, it works great for a continuous line. With
> >>>         line break(s), I got the nuisance "\n" inserted.
> >>>
> >>>         > x<-strsplit("hhsize,urban,male,gov,nongov,married",","); x
> >>>         [[1]]
> >>>         [1] "hhsize"  "urban"   "male"    "gov" "nongov"  "married"
> >>>
> >>>         > x<-strsplit("hhsize,urban,male,
> >>>         +             gov,nongov,married",","); x
> >>>         [[1]]
> >>>         [1] "hhsize"            "urban" "male"
> >>>         "\n            gov"
> >>>         [5] "nongov"            "married"
> >>>
> >>>         On 2021/1/5 ?? 05:34, Eric Berger wrote:
> >>>>
>  zx<-strsplit("age,exercise,income,white,black,hispanic,base,somcol,grad,employed,unable,homeowner,married,divorced,widowed",",")
> >>>>
> >>>>
> >>>>
> >>>>         On Tue, Jan 5, 2021 at 11:01 AM Steven Yen <styen at ntu.edu.tw
> >>>>         <mailto:styen at ntu.edu.tw>> wrote:
> >>>>
> >>>>             Thank you, Jeff. IMO, we are all here to make R work
> >>>>             better to suit our
> >>>>             various needs. All I am asking is an easier way to
> >>>>             define variable list
> >>>>             zx, differently from the way z0 , x0, and treat are
> defined.
> >>>>
> >>>>              > zx<-colnames(subset(mydata,select=c(
> >>>>             +
> >>>>
>  age,exercise,income,white,black,hispanic,base,somcol,grad,employed,
> >>>>             + unable,homeowner,married,divorced,widowed)))
> >>>>              > z0<-c("fruit","highblood")
> >>>>              > x0<-c("vgood","poor")
> >>>>              > treat<-"depression"
> >>>>              > eq1 <-my.formula(y="depression",x=zx,z0)
> >>>>              > eq2 <-my.formula(y="bmi", x=zx,x0)
> >>>>              > eq2t<-my.formula(y="bmi", x=zx,treat)
> >>>>              > eqs<-list(eq1,eq2); eqs
> >>>>             [[1]]
> >>>>             depression ~ age + exercise + income + white + black +
> >>>>             hispanic +
> >>>>                  base + somcol + grad + employed + unable +
> >>>>             homeowner + married +
> >>>>                  divorced + widowed + fruit + highblood
> >>>>
> >>>>             [[2]]
> >>>>             bmi ~ age + exercise + income + white + black + hispanic
> >>>>             + base +
> >>>>                  somcol + grad + employed + unable + homeowner +
> >>>>             married +
> >>>>                  divorced + widowed + vgood + poor
> >>>>
> >>>>              > eqt<-list(eq1,eq2t); eqt
> >>>>             [[1]]
> >>>>             depression ~ age + exercise + income + white + black +
> >>>>             hispanic +
> >>>>                  base + somcol + grad + employed + unable +
> >>>>             homeowner + married +
> >>>>                  divorced + widowed + fruit + highblood
> >>>>
> >>>>             [[2]]
> >>>>             bmi ~ age + exercise + income + white + black + hispanic
> >>>>             + base +
> >>>>                  somcol + grad + employed + unable + homeowner +
> >>>>             married +
> >>>>                  divorced + widowed + depression
> >>>>
> >>>>             On 2021/1/5 ?? 04:18, Jeff Newmiller wrote:
> >>>>             > IMO if you want to hardcode a formula then simply
> >>>>             hardcode a formula. If you want 20 formulas, write 20
> >>>>             formulas. Is that really so bad?
> >>>>             >
> >>>>             > If you want to have an abbreviated way to specify sets
> >>>>             of variables without conforming to R syntax then put
> >>>>             them into data files and read them in using a format of
> >>>>             your choice.
> >>>>             >
> >>>>             > But using NSE to avoid using quotes for entering what
> >>>>             amounts to in-script data is abuse of the language
> >>>>             justified by laziness... the amount of work you put
> >>>>             yourself and anyone else who reads your code through is
> >>>>             excessive relative to the benefit gained.
> >>>>             >
> >>>>             > NSE has its strengths... but as a method of creating
> >>>>             data objects it sucks. Note that even the tidyverse
> >>>>             (now) requires you to use quotes when you are not
> >>>>             directly referring to something that already exists. And
> >>>>             if you were... you might as well be creating a formula.
> >>>>             >
> >>>>             > On January 4, 2021 11:14:54 PM PST, Steven Yen
> >>>>             <styen at ntu.edu.tw <mailto:styen at ntu.edu.tw>> wrote:
> >>>>             >> I constantly define variable lists from a data frame
> >>>>             (e.g., to define a
> >>>>             >>
> >>>>             >> regression equation). Line 3 below does just that.
> >>>>             Placing each
> >>>>             >> variable
> >>>>             >> name in quotation marks is too much work especially
> >>>>             for a long list so
> >>>>             >> I
> >>>>             >> do that with line 4. Is there an easier way to
> >>>>             accomplish this----to
> >>>>             >> define a list of variable names containing
> >>>>             "a","c","e"? Thank you!
> >>>>             >>
> >>>>             >>> data<-as.data.frame(matrix(1:30,nrow=6))
> >>>>             >>> colnames(data)<-c("a","b","c","d","e"); data
> >>>>             >>    a  b  c  d  e
> >>>>             >> 1 1  7 13 19 25
> >>>>             >> 2 2  8 14 20 26
> >>>>             >> 3 3  9 15 21 27
> >>>>             >> 4 4 10 16 22 28
> >>>>             >> 5 5 11 17 23 29
> >>>>             >> 6 6 12 18 24 30
> >>>>             >>> x1<-c("a","c","e"); x1 # line 3
> >>>>             >> [1] "a" "c" "e"
> >>>>             >>> x2<-colnames(subset(data,select=c(a,c,e))); x2 # line
> 4
> >>>>             >> [1] "a" "c" "e"
> >>>>             >>
> >>>>             >> ______________________________________________
> >>>>             >> R-help at r-project.org <mailto:R-help at r-project.org>
> >>>>             mailing list -- To UNSUBSCRIBE and more, see
> >>>>             >> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>>>             >> PLEASE do read the posting guide
> >>>>             >> http://www.R-project.org/posting-guide.html
> >>>>             <http://www.R-project.org/posting-guide.html>
> >>>>             >> and provide commented, minimal, self-contained,
> >>>>             reproducible code.
> >>>>
> >>>>             ______________________________________________
> >>>>             R-help at r-project.org <mailto:R-help at r-project.org>
> >>>>             mailing list -- To UNSUBSCRIBE and more, see
> >>>>             https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>>>             PLEASE do read the posting guide
> >>>>             http://www.R-project.org/posting-guide.html
> >>>>             <http://www.R-project.org/posting-guide.html>
> >>>>             and provide commented, minimal, self-contained,
> >>>>             reproducible code.
> >>>>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S@E|||@on @end|ng |rom LGCGroup@com  Wed Jan  6 13:48:02 2021
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Wed, 6 Jan 2021 12:48:02 +0000
Subject: [R] Error Running Bootstrap Function within Wrapper Function
In-Reply-To: <CAMKuLyTw13c=1qfWE9XSev1ajKDZm36dEy+Y1ER19F7SHPXuSQ@mail.gmail.com>
References: <CAMKuLyTw13c=1qfWE9XSev1ajKDZm36dEy+Y1ER19F7SHPXuSQ@mail.gmail.com>
Message-ID: <c5680702983840339f226e31f7c436cf@GBDCVPEXC04.corp.lgc-group.com>

Kevin,

I didn't have the data set (you might want to post a link to a downloadable file instead), but on a quick look at the code your foo1 function looks as if it is not guaranteed to return an array of the same length each time. It's testing for nonzero coefs in a fitted model and then dropping exact zero coefs. That need not (and often will not) return the same coefficients every time in a simulation.  foo2 does the same general kind of thing. 

Could that be part of the problem?

S Ellison


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Egan
> Sent: 05 January 2021 12:26
> To: r-help <r-help at r-project.org>
> Subject: [R] Error Running Bootstrap Function within Wrapper Function
> 
> ===============
>  EXTERNAL EMAIL
> ===============
> 
> Hello,
> 
> I am currently trying to solve a problem with the boot package and writing a
> function within a function in R. I have developed several functions to
> perform the lasso but continue to receive an error when bootstrapping these
> functions within a wrapper function. When I perform these methods using
> tsboot outside the wrapper function, I do not get an error. However, when
> placed within my function I continue to get the error "Error in t[r, ] <- res[[r]]
> : number of items to replace is not a multiple of length."
> 
> I've attached an example of my functions as well as a data file of the data I
> am using. I'm sorry the file is so large, but I do not get a problem with a
> smaller number of observations.
> 
> 
> library(boot)
> library(glmnet)
> library(np)
> foo1 <- function(data,index){ #index is the bootstrap sample index
>   x <- data[index, -1] %>%
>     as.matrix() %>%
>     unname()
>   y <- data[index, 1] %>%
>     scale(center = TRUE, scale = FALSE) %>%
>     as.matrix() %>%
>     unname()
>   ols <- lm(y ~ x)
>   # The intercept estimate should be dropped.
>   ols.coef <- as.numeric(coef(ols))[-1]
>   ols.coef[is.na(ols.coef)] <- 0
>   ## The intercept estimate should be dropped.
>   lasso <- cv.glmnet(x, y, alpha = 1,
>                      penalty.factor = 1 / abs(ols.coef))
>   # Select nonzero coefficients from bic.out
>   coef <- as.vector(coef(lasso,
>                          s = lasso$lambda.min))[-1]
>   return(coef)
> }
> foo2 <- function(data, index){ #index is the bootstrap sample index
>   x <- data[index, -1] %>%
>     as.matrix() %>%
>     unname()
>   y <- data[index, 1] %>%
>     scale(center = TRUE, scale = FALSE) %>%
>     as.matrix() %>%
>     unname()
>   # ic.glmnet provides coefficients with lowest BIC
>   ols <- lm(y ~ x)
>   # The intercept estimate should be dropped.
>   ols.coef <- as.numeric(coef(ols))[-1]
>   ols.coef[is.na(ols.coef)] <- 0
>   lasso <- cv.glmnet(x, y, alpha = 1,
>                      penalty.factor = 1 / abs(ols.coef))
>   # Select nonzero coefficients from bic.out
>   coef <- as.vector(coef(lasso,
>                          s = lasso$lambda.min))[-1]
>   coef_nonzero <- coef != 0
>   if(sum(coef_nonzero) > 0) {
>     ls_obj <- lm(y ~ x[, coef_nonzero, drop = FALSE])
>     ls_coef <- as.vector(coef(ls_obj))[-1]
>     coef[coef_nonzero] <- ls_coef
>   }
>   return(coef)
> }
> foo3 <- function(data, num_samples) {
>   bstar <- b.star(data[, 1], round = TRUE)
>   # Select Block Length of circular block result
>   blocklength <- bstar[, 2]
>   init_boot_ts <- tsboot(tseries = data,
>                          statistic = foo1,
>                          R = num_samples, l = blocklength,
>                          sim = "fixed")
>   final_boot_ts <- tsboot(tseries = data,
>                           statistic = foo2,
>                           R = num_samples,
>                           l = blocklength, sim = "fixed")
>   # point estimates
>   final_boot_t0 <- final_boot_ts$t0
>   return(list(point_estimates = final_boot_t0)) } num_samples <- 50
> test.foo3 <- foo3(data, num_samples = num_samples)
> 
> Which *sometimes *works, however, sometimes I get the error: ?Error in t[r,
> ] <- res[[r]] : number of items to replace is not a multiple of length".
> I've also gotten the error "Error in x[, coef_nonzero, drop = FALSE]
> :(subscript) logical subscript too long" at times, when running foo2 within
> foo3. Which seems to be unclear as there should never be an index which is
> greater than the number of columns in x.
> As I stated, this error particularly occurs when I increase the number of
> bootstrap samples I try to run, and only when I run foo3. When I run foo1
> and foo2 separately, I don?t get an error at all. I?m wondering if there is
> something I need to add to my function ?foo3? to ensure that an error like
> this doesn?t occur since I am calling several other functions within this
> function, ie., tsboot, foo1, and foo2.
> 
> Lastly, although I have not provided an example here, I get an error for this
> code when running with lapply for several dataframes similar to the
> attached.
> 
> Again, I apologise for attaching such a large data frame but the function
> seems to work with fewer observations. Perhaps it is a data issue?
> 
> Thanks
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ==========================================================
> ====================================
> WARNING - EXTERNAL: This email originated from outside of LGC. Do not click
> any links or open any attachments unless you trust the sender and know that
> the content is safe
> ==========================================================
> ====================================


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed Jan  6 21:16:59 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 6 Jan 2021 20:16:59 +0000 (UTC)
Subject: [R] AIC for robust GAM ?
References: <1126246033.11932597.1609964219484.ref@mail.yahoo.com>
Message-ID: <1126246033.11932597.1609964219484@mail.yahoo.com>

Dear R-Experts,

Here below my reproducible R code.
How can I get the AIC of my model (robust GAM) ?

Best Regards,


y<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
x<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)
library(robustgam)
true.family <- poisson()
fit=robustgam(x,y,sp=0,family=true.family,smooth.basis='ps',K=3)
AIC(fit)

?

?


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jan  6 21:47:02 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 6 Jan 2021 12:47:02 -0800
Subject: [R] AIC for robust GAM ?
In-Reply-To: <1126246033.11932597.1609964219484@mail.yahoo.com>
References: <1126246033.11932597.1609964219484.ref@mail.yahoo.com>
 <1126246033.11932597.1609964219484@mail.yahoo.com>
Message-ID: <CAGxFJbQ9YkFW7RA3n2JeP5OXf1mGsa7v234Ld6_7UPZsmp_v=w@mail.gmail.com>

Per the posting guide linked below:

"If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

So I believe that you should try to contact the maintainer for your
question first. You may get lucky here, of course, but your query seems
rather too technical to expect a useful response on R-Help.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 6, 2021 at 12:17 PM varin sacha via R-help <r-help at r-project.org>
wrote:

> Dear R-Experts,
>
> Here below my reproducible R code.
> How can I get the AIC of my model (robust GAM) ?
>
> Best Regards,
>
>
>
> y<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
>
> x<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)
> library(robustgam)
> true.family <- poisson()
> fit=robustgam(x,y,sp=0,family=true.family,smooth.basis='ps',K=3)
> AIC(fit)
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Jan  6 23:22:25 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 7 Jan 2021 11:22:25 +1300
Subject: [R] Updated version of the hse package.
Message-ID: <20210107112225.0d5e1efa@rolf-Latitude-E7470>


I have recently submitted a fairly major revision of my hse
package to CRAN.  The source of the revised package is now
available.  Windoze and MacOS binaries will appear soon.

*After* submitting (psigh!) I noticed a distressingly large
number of typos and glitches in the help files.  These have
now been corrected, and the corrected version of the help
will appear in the next release.  However I'm sure that there
are many more such glitches that I *haven't* noticed!

I would be very grateful to anyone who points out such errors
to me.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From gob@@|||ngrud @end|ng |rom gm@||@com  Thu Jan  7 00:39:10 2021
From: gob@@|||ngrud @end|ng |rom gm@||@com (Gordon Ballingrud)
Date: Wed, 6 Jan 2021 18:39:10 -0500
Subject: [R] text analysis errors
Message-ID: <CAJ6CFDsfU7BCmKARzhtGSCGJJMK9O2FgK8hyYypXOi0wyMUeZQ@mail.gmail.com>

Hello all,

I have asked this question on many forums without response. And although
I've made progress myself, I am stuck as to how to respond to a particular
error message.

I have a question about text-analysis packages and code. The general idea
is that I am trying to perform readability analyses on a collection of
about 4,000 Word files. I would like to do any of a number of such
analyses, but the problem now is getting R to recognize the uploaded files
as data ready for analysis. But I have been getting error messages. Let me
show what I have done so far. I have three separate commands because I
broke the file of 4,000 files up into three separate ones because,
evidently, the file was too voluminous to be read alone in its entirety.
So, I divided the files up into three roughly similar folders. They are
called ?WPSCASES? one through three. Here is my code, with the error
messages for each command recorded below:

token <-
tokenize("/Users/Gordon/Desktop/WPSCASESONE/",lang="en",doc_id="sample")

The code is the same for the other folders; the name of the folder is
different, but otherwise identical.

The error message reads:

*Error in nchar(tagged.text[, "token"], type = "width") : invalid multibyte
string, element 348*

The error messages are the same for the other two commands. But the
'element' number is different. It's 925 for the second folder, and 4302 for
the third.

token2 <-
tokenize("/Users/Gordon/Desktop/WPSCASES2/",lang="en",doc_id="sample")

token3 <-
tokenize("/Users/Gordon/Desktop/WPSCASES3/",lang="en",doc_id="sample")

These are the other commands if that's helpful.

I?ve tried to discover whether the ?element? that the error message
mentions corresponds to the file of that number in the file?s order. But
since folder 3 does not have 4,300 files in it, I think that that was
unlikely. Please let me know if you can figure out how to fix this stuff so
that I can start to use ?koRpus? commands, like ?readability? and its
progeny.

Thank you,
Gordon

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Jan  7 01:34:21 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 7 Jan 2021 11:34:21 +1100
Subject: [R] text analysis errors
In-Reply-To: <CAJ6CFDsfU7BCmKARzhtGSCGJJMK9O2FgK8hyYypXOi0wyMUeZQ@mail.gmail.com>
References: <CAJ6CFDsfU7BCmKARzhtGSCGJJMK9O2FgK8hyYypXOi0wyMUeZQ@mail.gmail.com>
Message-ID: <CA+8X3fXcXtahueYe0q=0S5E95gL-5t2=5FTpv47nu6A3wfrMNg@mail.gmail.com>

Hi Gordon,
Looks to me as though you may have to extract the text from the Word
files. Export As Text.

Jim

On Thu, Jan 7, 2021 at 10:40 AM Gordon Ballingrud
<gob.allingrud at gmail.com> wrote:
>
> Hello all,
>
> I have asked this question on many forums without response. And although
> I've made progress myself, I am stuck as to how to respond to a particular
> error message.
>
> I have a question about text-analysis packages and code. The general idea
> is that I am trying to perform readability analyses on a collection of
> about 4,000 Word files. I would like to do any of a number of such
> analyses, but the problem now is getting R to recognize the uploaded files
> as data ready for analysis. But I have been getting error messages. Let me
> show what I have done so far. I have three separate commands because I
> broke the file of 4,000 files up into three separate ones because,
> evidently, the file was too voluminous to be read alone in its entirety.
> So, I divided the files up into three roughly similar folders. They are
> called ?WPSCASES? one through three. Here is my code, with the error
> messages for each command recorded below:
>
> token <-
> tokenize("/Users/Gordon/Desktop/WPSCASESONE/",lang="en",doc_id="sample")
>
> The code is the same for the other folders; the name of the folder is
> different, but otherwise identical.
>
> The error message reads:
>
> *Error in nchar(tagged.text[, "token"], type = "width") : invalid multibyte
> string, element 348*
>
> The error messages are the same for the other two commands. But the
> 'element' number is different. It's 925 for the second folder, and 4302 for
> the third.
>
> token2 <-
> tokenize("/Users/Gordon/Desktop/WPSCASES2/",lang="en",doc_id="sample")
>
> token3 <-
> tokenize("/Users/Gordon/Desktop/WPSCASES3/",lang="en",doc_id="sample")
>
> These are the other commands if that's helpful.
>
> I?ve tried to discover whether the ?element? that the error message
> mentions corresponds to the file of that number in the file?s order. But
> since folder 3 does not have 4,300 files in it, I think that that was
> unlikely. Please let me know if you can figure out how to fix this stuff so
> that I can start to use ?koRpus? commands, like ?readability? and its
> progeny.
>
> Thank you,
> Gordon
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kev|neg@n31 @end|ng |rom gm@||@com  Wed Jan  6 14:15:40 2021
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Wed, 6 Jan 2021 13:15:40 +0000
Subject: [R] Error Running Bootstrap Function within Wrapper Function
In-Reply-To: <c5680702983840339f226e31f7c436cf@GBDCVPEXC04.corp.lgc-group.com>
References: <CAMKuLyTw13c=1qfWE9XSev1ajKDZm36dEy+Y1ER19F7SHPXuSQ@mail.gmail.com>
 <c5680702983840339f226e31f7c436cf@GBDCVPEXC04.corp.lgc-group.com>
Message-ID: <CAMKuLyRSfF-w_SV7_HmvcwHT_suJ1M1xC3L70e7xFQeeE3jfNg@mail.gmail.com>

Hi Stephen,

Thanks for the advice, from my understanding, the function foo1 should
provide a vector of coefficients which are the same length as the columns
in the data frame provided. This is based on the results from glmnet. With
foo2, this should be the same case, I've provided an if statement that
performs OLS if the sum of coef_nonzero is greater than 0. Meaning there
should be at least one independent variable from the original data set to
perform OLS since it's coefficient from glmnet was nonzero.

I previously have not had any issues with this method for other tests I
have run, it seems to only occur as this data increases in observations.
Would it be possible for you to look at the attached file? I provide a new
foo1 function that generates the data I am using, the same 3 functions I
sent previously, and the function I am using for glmnet. I'm still not sure
why, but as the number of bootstrap samples increases, I get an error with
my methods, particularly with foo3.

At this point, I think the problem could be with the wrapper function or
with the data itself.

I appreciate any help I can get at this point. I've been trying to debug
this function for almost a month.

Thanks,

Kevin


https://www.dropbox.com/s/1sdidrnmzrqmukt/r-help%20example.R?dl=0

On Wed, Jan 6, 2021 at 12:48 PM Stephen Ellison <S.Ellison at lgcgroup.com>
wrote:

> Kevin,
>
> I didn't have the data set (you might want to post a link to a
> downloadable file instead), but on a quick look at the code your foo1
> function looks as if it is not guaranteed to return an array of the same
> length each time. It's testing for nonzero coefs in a fitted model and then
> dropping exact zero coefs. That need not (and often will not) return the
> same coefficients every time in a simulation.  foo2 does the same general
> kind of thing.
>
> Could that be part of the problem?
>
> S Ellison
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Egan
> > Sent: 05 January 2021 12:26
> > To: r-help <r-help at r-project.org>
> > Subject: [R] Error Running Bootstrap Function within Wrapper Function
> >
> > ===============
> >  EXTERNAL EMAIL
> > ===============
> >
> > Hello,
> >
> > I am currently trying to solve a problem with the boot package and
> writing a
> > function within a function in R. I have developed several functions to
> > perform the lasso but continue to receive an error when bootstrapping
> these
> > functions within a wrapper function. When I perform these methods using
> > tsboot outside the wrapper function, I do not get an error. However, when
> > placed within my function I continue to get the error "Error in t[r, ]
> <- res[[r]]
> > : number of items to replace is not a multiple of length."
> >
> > I've attached an example of my functions as well as a data file of the
> data I
> > am using. I'm sorry the file is so large, but I do not get a problem
> with a
> > smaller number of observations.
> >
> >
> > library(boot)
> > library(glmnet)
> > library(np)
> > foo1 <- function(data,index){ #index is the bootstrap sample index
> >   x <- data[index, -1] %>%
> >     as.matrix() %>%
> >     unname()
> >   y <- data[index, 1] %>%
> >     scale(center = TRUE, scale = FALSE) %>%
> >     as.matrix() %>%
> >     unname()
> >   ols <- lm(y ~ x)
> >   # The intercept estimate should be dropped.
> >   ols.coef <- as.numeric(coef(ols))[-1]
> >   ols.coef[is.na(ols.coef)] <- 0
> >   ## The intercept estimate should be dropped.
> >   lasso <- cv.glmnet(x, y, alpha = 1,
> >                      penalty.factor = 1 / abs(ols.coef))
> >   # Select nonzero coefficients from bic.out
> >   coef <- as.vector(coef(lasso,
> >                          s = lasso$lambda.min))[-1]
> >   return(coef)
> > }
> > foo2 <- function(data, index){ #index is the bootstrap sample index
> >   x <- data[index, -1] %>%
> >     as.matrix() %>%
> >     unname()
> >   y <- data[index, 1] %>%
> >     scale(center = TRUE, scale = FALSE) %>%
> >     as.matrix() %>%
> >     unname()
> >   # ic.glmnet provides coefficients with lowest BIC
> >   ols <- lm(y ~ x)
> >   # The intercept estimate should be dropped.
> >   ols.coef <- as.numeric(coef(ols))[-1]
> >   ols.coef[is.na(ols.coef)] <- 0
> >   lasso <- cv.glmnet(x, y, alpha = 1,
> >                      penalty.factor = 1 / abs(ols.coef))
> >   # Select nonzero coefficients from bic.out
> >   coef <- as.vector(coef(lasso,
> >                          s = lasso$lambda.min))[-1]
> >   coef_nonzero <- coef != 0
> >   if(sum(coef_nonzero) > 0) {
> >     ls_obj <- lm(y ~ x[, coef_nonzero, drop = FALSE])
> >     ls_coef <- as.vector(coef(ls_obj))[-1]
> >     coef[coef_nonzero] <- ls_coef
> >   }
> >   return(coef)
> > }
> > foo3 <- function(data, num_samples) {
> >   bstar <- b.star(data[, 1], round = TRUE)
> >   # Select Block Length of circular block result
> >   blocklength <- bstar[, 2]
> >   init_boot_ts <- tsboot(tseries = data,
> >                          statistic = foo1,
> >                          R = num_samples, l = blocklength,
> >                          sim = "fixed")
> >   final_boot_ts <- tsboot(tseries = data,
> >                           statistic = foo2,
> >                           R = num_samples,
> >                           l = blocklength, sim = "fixed")
> >   # point estimates
> >   final_boot_t0 <- final_boot_ts$t0
> >   return(list(point_estimates = final_boot_t0)) } num_samples <- 50
> > test.foo3 <- foo3(data, num_samples = num_samples)
> >
> > Which *sometimes *works, however, sometimes I get the error: ?Error in
> t[r,
> > ] <- res[[r]] : number of items to replace is not a multiple of length".
> > I've also gotten the error "Error in x[, coef_nonzero, drop = FALSE]
> > :(subscript) logical subscript too long" at times, when running foo2
> within
> > foo3. Which seems to be unclear as there should never be an index which
> is
> > greater than the number of columns in x.
> > As I stated, this error particularly occurs when I increase the number of
> > bootstrap samples I try to run, and only when I run foo3. When I run foo1
> > and foo2 separately, I don?t get an error at all. I?m wondering if there
> is
> > something I need to add to my function ?foo3? to ensure that an error
> like
> > this doesn?t occur since I am calling several other functions within this
> > function, ie., tsboot, foo1, and foo2.
> >
> > Lastly, although I have not provided an example here, I get an error for
> this
> > code when running with lapply for several dataframes similar to the
> > attached.
> >
> > Again, I apologise for attaching such a large data frame but the function
> > seems to work with fewer observations. Perhaps it is a data issue?
> >
> > Thanks
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > ==========================================================
> > ====================================
> > WARNING - EXTERNAL: This email originated from outside of LGC. Do not
> click
> > any links or open any attachments unless you trust the sender and know
> that
> > the content is safe
> > ==========================================================
> > ====================================
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:12}}


From jr@| @end|ng |rom po@teo@no  Thu Jan  7 14:06:45 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 7 Jan 2021 14:06:45 +0100
Subject: [R] text analysis errors
In-Reply-To: <CA+8X3fXcXtahueYe0q=0S5E95gL-5t2=5FTpv47nu6A3wfrMNg@mail.gmail.com>
References: <CAJ6CFDsfU7BCmKARzhtGSCGJJMK9O2FgK8hyYypXOi0wyMUeZQ@mail.gmail.com>
 <CA+8X3fXcXtahueYe0q=0S5E95gL-5t2=5FTpv47nu6A3wfrMNg@mail.gmail.com>
Message-ID: <X/cHZVjfR6/InUw3@posteo.no>

On 2021-01-07 11:34 +1100, Jim Lemon wrote:
> On Thu, Jan 7, 2021 at 10:40 AM Gordon Ballingrud
> <gob.allingrud at gmail.com> wrote:
> >
> > Hello all,
> >
> > I have asked this question on many forums without response. And although
> > I've made progress myself, I am stuck as to how to respond to a particular
> > error message.
> >
> > I have a question about text-analysis packages and code. The general idea
> > is that I am trying to perform readability analyses on a collection of
> > about 4,000 Word files. I would like to do any of a number of such
> > analyses, but the problem now is getting R to recognize the uploaded files
> > as data ready for analysis. But I have been getting error messages. Let me
> > show what I have done so far. I have three separate commands because I
> > broke the file of 4,000 files up into three separate ones because,
> > evidently, the file was too voluminous to be read alone in its entirety.
> > So, I divided the files up into three roughly similar folders. They are
> > called ?WPSCASES? one through three. Here is my code, with the error
> > messages for each command recorded below:
> >
> > token <-
> > tokenize("/Users/Gordon/Desktop/WPSCASESONE/",lang="en",doc_id="sample")
> >
> > The code is the same for the other folders; the name of the folder is
> > different, but otherwise identical.
> >
> > The error message reads:
> >
> > *Error in nchar(tagged.text[, "token"], type = "width") : invalid multibyte
> > string, element 348*
> >
> > The error messages are the same for the other two commands. But the
> > 'element' number is different. It's 925 for the second folder, and 4302 for
> > the third.
> >
> > token2 <-
> > tokenize("/Users/Gordon/Desktop/WPSCASES2/",lang="en",doc_id="sample")
> >
> > token3 <-
> > tokenize("/Users/Gordon/Desktop/WPSCASES3/",lang="en",doc_id="sample")
> >
> > These are the other commands if that's helpful.
> >
> > I?ve tried to discover whether the ?element? that the error message
> > mentions corresponds to the file of that number in the file?s order. But
> > since folder 3 does not have 4,300 files in it, I think that that was
> > unlikely. Please let me know if you can figure out how to fix this stuff so
> > that I can start to use ?koRpus? commands, like ?readability? and its
> > progeny.
> >
> > Thank you,
> > Gordon
> 
> Hi Gordon,
> Looks to me as though you may have to extract the text from the Word
> files. Export As Text.

Hi!  

quanteda::tokenizer says it needs a 
character vector or ?corpus? as input

	https://www.rdocumentation.org/packages/quanteda/versions/0.99.12/topics/tokenize

... or is this tokenize from the 
tokenizers package, I found something 
about ?doc_id? here:

	https://cran.r-project.org/web/packages/tokenizers/vignettes/introduction-to-tokenizers.html

You can convert docx to markdown using 
pandoc:

	pandoc --from docx --to markdown $inputfile

odt also works, and many others.  

I believe pandoc is included in RStudio.  
But I have never used it from there 
myself, so that is really bad advice I 
think.

To read doc, I use wvHtml:

	wvHtml $inputfile - 2> /dev/null | w3m -dump -T text/html

Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210107/7fd2204a/attachment.sig>

From zu|ut|me@net @end|ng |rom gm@||@com  Thu Jan  7 16:02:19 2021
From: zu|ut|me@net @end|ng |rom gm@||@com (Magnus Torfason)
Date: Thu, 7 Jan 2021 15:02:19 +0000
Subject: [R] New mask.ok option for libraries
Message-ID: <CAAwbYcy45=-PAQPD63u2Yj3aQCsLGSi6iMEBt7tvAWc+6c8J+g@mail.gmail.com>

I had sent the following to r-devel a while ago, but perhaps r-help is more
appropriate. I guess my question is what to do with this, would people
generally file an issue, or is there a way to hear if this is something
that makes sense to add ? whether more info would be helpful and so on?

=====
I was very happy to see the new mask.ok option. It works very well when
conflicts.policy is "strict":

---
options(conflicts.policy="strict")
library(igraph, exclude="decompose", mask.ok=c("spectrum","union"))
#> [No messages]
---

However, if no conflicts.policy has been set, the masked objects are loudly
reported, even if they are specified with mask.ok:

---
library(igraph, exclude="decompose", mask.ok=c("spectrum","union"))
#>
#> Attaching package: 'igraph'
#> The following object is masked from 'package:stats':
#>
#>     spectrum
#> The following object is masked from 'package:base':
#>
#>     union
---

It seems that if I specify mask.ok, that particular masking is expected and
should NOT be reported, regardless of what the conflicts.policy is. It
would be very useful for many users who are not ready to switch over to a
strict conflicts.policy, to nevertheless be able to suppress messages about
expected conflicts using mask.ok and thus only get messages when unexpected
masking occurs.
=====

Best,
Magnus

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jan  7 18:43:30 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 7 Jan 2021 12:43:30 -0500
Subject: [R] New mask.ok option for libraries
In-Reply-To: <CAAwbYcy45=-PAQPD63u2Yj3aQCsLGSi6iMEBt7tvAWc+6c8J+g@mail.gmail.com>
References: <CAAwbYcy45=-PAQPD63u2Yj3aQCsLGSi6iMEBt7tvAWc+6c8J+g@mail.gmail.com>
Message-ID: <abfa5a01-0df4-83f7-3806-2ba544d69c93@gmail.com>

On 07/01/2021 10:02 a.m., Magnus Torfason wrote:
> I had sent the following to r-devel a while ago, but perhaps r-help is more
> appropriate.

No, this is definitely an R-devel topic.  You didn't get any replies 
there, but that doesn't mean you should post it again in the wrong place.

Duncan Murdoch

  I guess my question is what to do with this, would people
> generally file an issue, or is there a way to hear if this is something
> that makes sense to add ? whether more info would be helpful and so on?
> 
> =====
> I was very happy to see the new mask.ok option. It works very well when
> conflicts.policy is "strict":
> 
> ---
> options(conflicts.policy="strict")
> library(igraph, exclude="decompose", mask.ok=c("spectrum","union"))
> #> [No messages]
> ---
> 
> However, if no conflicts.policy has been set, the masked objects are loudly
> reported, even if they are specified with mask.ok:
> 
> ---
> library(igraph, exclude="decompose", mask.ok=c("spectrum","union"))
> #>
> #> Attaching package: 'igraph'
> #> The following object is masked from 'package:stats':
> #>
> #>     spectrum
> #> The following object is masked from 'package:base':
> #>
> #>     union
> ---
> 
> It seems that if I specify mask.ok, that particular masking is expected and
> should NOT be reported, regardless of what the conflicts.policy is. It
> would be very useful for many users who are not ready to switch over to a
> strict conflicts.policy, to nevertheless be able to suppress messages about
> expected conflicts using mask.ok and thus only get messages when unexpected
> masking occurs.
> =====
> 
> Best,
> Magnus
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ycd|ng @end|ng |rom coh@org  Thu Jan  7 19:39:41 2021
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 7 Jan 2021 18:39:41 +0000
Subject: [R] non-standard reshape from long to wide
Message-ID: <SJ0PR02MB7645BBDCF04B9BA76C554317D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>

Dear R user,

I want to reshape a long data frame to wide format, I made the following example files.  Can you help me?

Thank you,

Yuan Chun Ding

sample <-c("xr" , "xr" , "fh" , "fh" , "fh" , "uy" , "uy" , "uy" , "uy");
marker <-c("x" , "y" , "g" , "x" , "k" , "y" , "x" , "u" , "j");
df.long <-data.frame(sample, marker);
           
xr <-c(1,1,NA,NA,NA,NA);
fh <-c(1,NA,1,1,NA,NA);
uy <-c(1,1,NA,NA,1,1);

df.wide <- t(data.frame(xr,fh,uy));
colnames(df.wide)<-c("x","y","g","k", "u","j");

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jan  7 19:51:38 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 7 Jan 2021 10:51:38 -0800
Subject: [R] non-standard reshape from long to wide
In-Reply-To: <SJ0PR02MB7645BBDCF04B9BA76C554317D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
References: <SJ0PR02MB7645BBDCF04B9BA76C554317D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbS4SRhY5CsRdRzf2_sL9CFe1QwxmRLFbFf7f6=PQsPx-Q@mail.gmail.com>

Is this homework? There is a no-homework policy on this list.

If not, note that you are usually asked to show what you tried and the
error messages you received.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 7, 2021 at 10:40 AM Yuan Chun Ding <ycding at coh.org> wrote:

> Dear R user,
>
> I want to reshape a long data frame to wide format, I made the following
> example files.  Can you help me?
>
> Thank you,
>
> Yuan Chun Ding
>
> sample <-c("xr" , "xr" , "fh" , "fh" , "fh" , "uy" , "uy" , "uy" , "uy");
> marker <-c("x" , "y" , "g" , "x" , "k" , "y" , "x" , "u" , "j");
> df.long <-data.frame(sample, marker);
>
> xr <-c(1,1,NA,NA,NA,NA);
> fh <-c(1,NA,1,1,NA,NA);
> uy <-c(1,1,NA,NA,1,1);
>
> df.wide <- t(data.frame(xr,fh,uy));
> colnames(df.wide)<-c("x","y","g","k", "u","j");
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to receive further
> communications via e-mail, please reply to this message and inform the
> sender that you do not wish to receive further e-mail from the sender.
> (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ycd|ng @end|ng |rom coh@org  Thu Jan  7 20:09:50 2021
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 7 Jan 2021 19:09:50 +0000
Subject: [R] non-standard reshape from long to wide
In-Reply-To: <CAGxFJbS4SRhY5CsRdRzf2_sL9CFe1QwxmRLFbFf7f6=PQsPx-Q@mail.gmail.com>
References: <SJ0PR02MB7645BBDCF04B9BA76C554317D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
 <CAGxFJbS4SRhY5CsRdRzf2_sL9CFe1QwxmRLFbFf7f6=PQsPx-Q@mail.gmail.com>
Message-ID: <SJ0PR02MB7645D88444EE45A9C7935B36D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>

Hi Bert,

No, this Is not home work related.  Original data have 87352 rows. I used the standard reshape function and got warning message. So I reformatted the wide format to meet my research purpose.

mut2 <-mut[,c("Tumor_Sample_Barcode","mut.id", "Hugo_Symbol")]
mut2 <-mut2[order(mut2$Hugo_Symbol),]
mut3 <-mut2[!duplicated(mut2),]
mut4 <-reshape(mut3, idvar = "Hugo_Symbol", timevar = "Tumor_Sample_Barcode", direction = "wide")

There were 50 or more warnings (use warnings() to see the first 50)
> View(mut4)
> warnings()
Warning messages:
1: In reshapeWide(data, idvar = idvar, timevar = timevar,  ... :
  multiple rows match for Tumor_Sample_Barcode=TCGA-A8-A09Z-01A-11W-A019-09: first taken
2: In reshapeWide(data, idvar = idvar, timevar = timevar,  ... :
From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Thursday, January 7, 2021 10:52 AM
To: Yuan Chun Ding <ycding at coh.org>
Cc: r-help at r-project.org
Subject: Re: [R] non-standard reshape from long to wide

Is this homework? There is a no-homework policy on this list.

If not, note that you are usually asked to show what you tried and the error messages you received.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 7, 2021 at 10:40 AM Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>> wrote:
Dear R user,

I want to reshape a long data frame to wide format, I made the following example files.  Can you help me?

Thank you,

Yuan Chun Ding

sample <-c("xr" , "xr" , "fh" , "fh" , "fh" , "uy" , "uy" , "uy" , "uy");
marker <-c("x" , "y" , "g" , "x" , "k" , "y" , "x" , "u" , "j");
df.long <-data.frame(sample, marker);

xr <-c(1,1,NA,NA,NA,NA);
fh <-c(1,NA,1,1,NA,NA);
uy <-c(1,1,NA,NA,1,1);

df.wide <- t(data.frame(xr,fh,uy));
colnames(df.wide)<-c("x","y","g","k", "u","j");

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!8Xh6f5YkEhmPfDyrfZAdBKkVH3I-iNCUoXNhMSZyF6JgRliIYBMD4tWItfuZ$>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!8Xh6f5YkEhmPfDyrfZAdBKkVH3I-iNCUoXNhMSZyF6JgRliIYBMD4qvlyPfu$>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jan  7 20:17:43 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 7 Jan 2021 11:17:43 -0800
Subject: [R] non-standard reshape from long to wide
In-Reply-To: <SJ0PR02MB7645D88444EE45A9C7935B36D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
References: <SJ0PR02MB7645BBDCF04B9BA76C554317D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
 <CAGxFJbS4SRhY5CsRdRzf2_sL9CFe1QwxmRLFbFf7f6=PQsPx-Q@mail.gmail.com>
 <SJ0PR02MB7645D88444EE45A9C7935B36D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbQPeqxk2AToGmVJHu_pcgJJBhKfiyYT5ZiETWTcEvTEGA@mail.gmail.com>

Show us your attempt on your example data. Also note that warnings are
*not* errors, though they typically do indicate problems.

-- Bert

On Thu, Jan 7, 2021 at 11:09 AM Yuan Chun Ding <ycding at coh.org> wrote:

> Hi Bert,
>
>
>
> No, this Is not home work related.  Original data have 87352 rows. I used
> the standard reshape function and got warning message. So I reformatted the
> wide format to meet my research purpose.
>
>
>
> mut2 <-mut[,c("Tumor_Sample_Barcode","mut.id", "Hugo_Symbol")]
>
> mut2 <-mut2[order(mut2$Hugo_Symbol),]
>
> mut3 <-mut2[!duplicated(mut2),]
>
> mut4 <-reshape(mut3, idvar = "Hugo_Symbol", timevar =
> "Tumor_Sample_Barcode", direction = "wide")
>
>
>
> There were 50 or more warnings (use warnings() to see the first 50)
>
> > View(mut4)
>
> > warnings()
>
> Warning messages:
>
> 1: In reshapeWide(data, idvar = idvar, timevar = timevar,  ... :
>
>   multiple rows match for
> Tumor_Sample_Barcode=TCGA-A8-A09Z-01A-11W-A019-09: first taken
>
> 2: In reshapeWide(data, idvar = idvar, timevar = timevar,  ... :
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Thursday, January 7, 2021 10:52 AM
> *To:* Yuan Chun Ding <ycding at coh.org>
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] non-standard reshape from long to wide
>
>
>
> Is this homework? There is a no-homework policy on this list.
>
>
>
> If not, note that you are usually asked to show what you tried and the
> error messages you received.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
>
>
> On Thu, Jan 7, 2021 at 10:40 AM Yuan Chun Ding <ycding at coh.org> wrote:
>
> Dear R user,
>
> I want to reshape a long data frame to wide format, I made the following
> example files.  Can you help me?
>
> Thank you,
>
> Yuan Chun Ding
>
> sample <-c("xr" , "xr" , "fh" , "fh" , "fh" , "uy" , "uy" , "uy" , "uy");
> marker <-c("x" , "y" , "g" , "x" , "k" , "y" , "x" , "u" , "j");
> df.long <-data.frame(sample, marker);
>
> xr <-c(1,1,NA,NA,NA,NA);
> fh <-c(1,NA,1,1,NA,NA);
> uy <-c(1,1,NA,NA,1,1);
>
> df.wide <- t(data.frame(xr,fh,uy));
> colnames(df.wide)<-c("x","y","g","k", "u","j");
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to receive further
> communications via e-mail, please reply to this message and inform the
> sender that you do not wish to receive further e-mail from the sender.
> (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!8Xh6f5YkEhmPfDyrfZAdBKkVH3I-iNCUoXNhMSZyF6JgRliIYBMD4tWItfuZ$>
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!8Xh6f5YkEhmPfDyrfZAdBKkVH3I-iNCUoXNhMSZyF6JgRliIYBMD4qvlyPfu$>
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jerem|eju@te @end|ng |rom gm@||@com  Thu Jan  7 20:18:36 2021
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Thu, 07 Jan 2021 20:18:36 +0100
Subject: [R] seq.Date when date is the last date of the month
Message-ID: <877dooh7xv.fsf@gmail.com>

Hello,

I recently bumped into a behavior that surprised me.
When performing the following command, I would expect the second
argument to be "2012-09-30" but got "2012-10-01" instead
> seq(as.Date("2012-08-31"),by="1 month",length=2)
[1] "2012-08-31" "2012-10-01"

When the same command is performed for the start of the month. I get a
result I expect.
> seq(as.Date("2012-08-01"),by="1 month",length=2)
[1] "2012-08-01"


Is there an explanation for this behavior?

Best regards,
-- 
Jeremie Juste


From jho|tm@n @end|ng |rom gm@||@com  Thu Jan  7 20:40:50 2021
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Thu, 7 Jan 2021 11:40:50 -0800
Subject: [R] seq.Date when date is the last date of the month
In-Reply-To: <877dooh7xv.fsf@gmail.com>
References: <877dooh7xv.fsf@gmail.com>
Message-ID: <CAAxdm-47Z5f-wVgXyotj3cxr4VTo3ptmF9yRPY7aGGLCpgp4iw@mail.gmail.com>

yes it is the expected behaviour is you check the documentation:

Using "month" first advances the month without changing the day: if
this results in an invalid day of the month, it is counted forward
into the next month: see the examples.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Jan 7, 2021 at 11:20 AM Jeremie Juste <jeremiejuste at gmail.com> wrote:
>
> Hello,
>
> I recently bumped into a behavior that surprised me.
> When performing the following command, I would expect the second
> argument to be "2012-09-30" but got "2012-10-01" instead
> > seq(as.Date("2012-08-31"),by="1 month",length=2)
> [1] "2012-08-31" "2012-10-01"
>
> When the same command is performed for the start of the month. I get a
> result I expect.
> > seq(as.Date("2012-08-01"),by="1 month",length=2)
> [1] "2012-08-01"
>
>
> Is there an explanation for this behavior?
>
> Best regards,
> --
> Jeremie Juste
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edd @end|ng |rom deb|@n@org  Thu Jan  7 20:59:42 2021
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Thu, 7 Jan 2021 13:59:42 -0600
Subject: [R] seq.Date when date is the last date of the month
In-Reply-To: <877dooh7xv.fsf@gmail.com>
References: <877dooh7xv.fsf@gmail.com>
Message-ID: <24567.26670.290005.444615@rob.eddelbuettel.com>


Jeremie,

As months have irregular number of dates, one needs to use a function that
accounts for that (date libraries and packages have that, one of the earliest
for R was my RcppBDT package using Boost Date_Time), or be otherwise clever.

Here is a one-liner using the latter approach:

   seq(as.Date("2010-02-01"), length=24, by="1 month") - 1

See this old StackOverflow answer where I used this before:

   https://stackoverflow.com/questions/8333838/generate-a-sequence-of-the-last-day-of-the-month-over-two-years

Dirk

-- 
https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Thu Jan  7 21:07:26 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Thu, 7 Jan 2021 20:07:26 +0000 (UTC)
Subject: [R] AIC for robust GAM ?
In-Reply-To: <CAGxFJbQ9YkFW7RA3n2JeP5OXf1mGsa7v234Ld6_7UPZsmp_v=w@mail.gmail.com>
References: <1126246033.11932597.1609964219484.ref@mail.yahoo.com>
 <1126246033.11932597.1609964219484@mail.yahoo.com>
 <CAGxFJbQ9YkFW7RA3n2JeP5OXf1mGsa7v234Ld6_7UPZsmp_v=w@mail.gmail.com>
Message-ID: <162996110.710699.1610050046509@mail.yahoo.com>

Hi Bert,

Many thanks for your response.

Best,


Le mercredi 6 janvier 2021 ? 21:47:14 UTC+1, Bert Gunter <bgunter.4567 at gmail.com> a ?crit : 





Per the posting guide linked below:

"If the question relates to a contributed package , e.g., one downloaded from CRAN, try contacting the package maintainer first. You can also use find("functionname") and packageDescription("packagename") to find this information. Only send such questions to R-help or R-devel if you get no reply or need further assistance. This applies to both requests for help and to bug reports."

So I believe that you should try to contact the maintainer for your question first. You may get lucky here, of course, but your query seems rather too technical to expect a useful response on R-Help.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 6, 2021 at 12:17 PM varin sacha via R-help <r-help at r-project.org> wrote:
> Dear R-Experts,
> 
> Here below my reproducible R code.
> How can I get the AIC of my model (robust GAM) ?
> 
> Best Regards,
> 
> 
> y<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
> x<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)
> library(robustgam)
> true.family <- poisson()
> fit=robustgam(x,y,sp=0,family=true.family,smooth.basis='ps',K=3)
> AIC(fit)
> 
> ?
> 
> ?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jan  7 21:19:11 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 7 Jan 2021 20:19:11 +0000
Subject: [R] non-standard reshape from long to wide
In-Reply-To: <SJ0PR02MB7645BBDCF04B9BA76C554317D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
References: <SJ0PR02MB7645BBDCF04B9BA76C554317D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
Message-ID: <a1e99f54-a815-026f-72bd-436f10a9e12d@sapo.pt>

Hello,

Here is a dplyr solution. The main trick is to create a column of 1's, 
then pipe to pivot_wider.


library(dplyr)
library(tidyr)

df.long %>%
   mutate(values = 1) %>%
   pivot_wider(
     id_cols = sample,
     names_from = marker,
     values_from = values,
     values_fill = NA
   )


Note: your df.wide is not a data.frame, the transpose coerces it to 
matrix. In this case it doesn't matter because it was just an example of 
expected output but in other, real use cases you must be careful.

df.wide <- as.data.frame(df.wide)

would solve it.


Hope this helps,

Rui Barradas

?s 18:39 de 07/01/21, Yuan Chun Ding escreveu:
> Dear R user,
> 
> I want to reshape a long data frame to wide format, I made the following example files.  Can you help me?
> 
> Thank you,
> 
> Yuan Chun Ding
> 
> sample <-c("xr" , "xr" , "fh" , "fh" , "fh" , "uy" , "uy" , "uy" , "uy");
> marker <-c("x" , "y" , "g" , "x" , "k" , "y" , "x" , "u" , "j");
> df.long <-data.frame(sample, marker);
>             
> xr <-c(1,1,NA,NA,NA,NA);
> fh <-c(1,NA,1,1,NA,NA);
> uy <-c(1,1,NA,NA,1,1);
> 
> df.wide <- t(data.frame(xr,fh,uy));
> colnames(df.wide)<-c("x","y","g","k", "u","j");
> 
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> 
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

From ycd|ng @end|ng |rom coh@org  Thu Jan  7 21:40:18 2021
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 7 Jan 2021 20:40:18 +0000
Subject: [R] non-standard reshape from long to wide
In-Reply-To: <a1e99f54-a815-026f-72bd-436f10a9e12d@sapo.pt>
References: <SJ0PR02MB7645BBDCF04B9BA76C554317D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
 <a1e99f54-a815-026f-72bd-436f10a9e12d@sapo.pt>
Message-ID: <SJ0PR02MB7645B271672144F6C89585FAD4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>

Hi Rui,

Thank you so much!!   You code works well and I am looking into the pivot_wider function.

Yuan Ding

-----Original Message-----
From: Rui Barradas [mailto:ruipbarradas at sapo.pt] 
Sent: Thursday, January 7, 2021 12:19 PM
To: Yuan Chun Ding <ycding at coh.org>; r-help at r-project.org
Subject: Re: [R] non-standard reshape from long to wide

Hello,

Here is a dplyr solution. The main trick is to create a column of 1's, then pipe to pivot_wider.


library(dplyr)
library(tidyr)

df.long %>%
   mutate(values = 1) %>%
   pivot_wider(
     id_cols = sample,
     names_from = marker,
     values_from = values,
     values_fill = NA
   )


Note: your df.wide is not a data.frame, the transpose coerces it to 
matrix. In this case it doesn't matter because it was just an example of 
expected output but in other, real use cases you must be careful.

df.wide <- as.data.frame(df.wide)

would solve it.


Hope this helps,

Rui Barradas

?s 18:39 de 07/01/21, Yuan Chun Ding escreveu:
> Dear R user,
> 
> I want to reshape a long data frame to wide format, I made the following example files.  Can you help me?
> 
> Thank you,
> 
> Yuan Chun Ding
> 
> sample <-c("xr" , "xr" , "fh" , "fh" , "fh" , "uy" , "uy" , "uy" , "uy");
> marker <-c("x" , "y" , "g" , "x" , "k" , "y" , "x" , "u" , "j");
> df.long <-data.frame(sample, marker);
>             
> xr <-c(1,1,NA,NA,NA,NA);
> fh <-c(1,NA,1,1,NA,NA);
> uy <-c(1,1,NA,NA,1,1);
> 
> df.wide <- t(data.frame(xr,fh,uy));
> colnames(df.wide)<-c("x","y","g","k", "u","j");
> 
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> 
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!9ccbhtYzBJoahdschhouzo2kkluOs-EdoH8jn32fv9E22xaJ4GzfrI0bOvVl$ 
> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!9ccbhtYzBJoahdschhouzo2kkluOs-EdoH8jn32fv9E22xaJ4GzfrKjC2095$ 
> and provide commented, minimal, self-contained, reproducible code.
> 

From jerem|eju@te @end|ng |rom gm@||@com  Thu Jan  7 21:59:23 2021
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Thu, 07 Jan 2021 21:59:23 +0100
Subject: [R] seq.Date when date is the last date of the month
In-Reply-To: <CAAxdm-47Z5f-wVgXyotj3cxr4VTo3ptmF9yRPY7aGGLCpgp4iw@mail.gmail.com>
 (jim holtman's message of "Thu, 7 Jan 2021 11:40:50 -0800")
References: <877dooh7xv.fsf@gmail.com>
 <CAAxdm-47Z5f-wVgXyotj3cxr4VTo3ptmF9yRPY7aGGLCpgp4iw@mail.gmail.com>
Message-ID: <87zh1kfopg.fsf@gmail.com>


Hello Jim,

Many thanks for the feedback

> Using "month" first advances the month without changing the day: if
> this results in an invalid day of the month, it is counted forward
> into the next month: see the examples.
Indeed I missed the documentation of seq.Date that refers to
seq.POSIXt. Many thanks for pointing this out.

Still I would be tempted to count back the day into the same month
instead of counting forward. But this behavior seems intentional and
documented so no need to question it. 

> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
The problem I'm trying to solve is this.

for a date d and an integer m
add.month(d,m)

would

Using "month" first advance the month without changing the day: if
this results in an invalid day of the month, it is counted backward
into the same month.

so nearly the same behavior as seq.Date except
add.month("2020-08-31",1) ==> 2020-09-30
add.month("2020-08-01",1) ==> 2020-09-01


Best regards,
Jeremie


From jerem|eju@te @end|ng |rom gm@||@com  Thu Jan  7 22:13:03 2021
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Thu, 07 Jan 2021 22:13:03 +0100
Subject: [R] seq.Date when date is the last date of the month
In-Reply-To: <24567.26670.290005.444615@rob.eddelbuettel.com> (Dirk
 Eddelbuettel's message of "Thu, 7 Jan 2021 13:59:42 -0600")
References: <877dooh7xv.fsf@gmail.com>
 <24567.26670.290005.444615@rob.eddelbuettel.com>
Message-ID: <87v9c8fo2o.fsf@gmail.com>

Hello Dirk,

Many thanks for the feedback. I did came across your SO answer but
didn't know the RcppBDT package, thanks for pointing that out.

Best regards,
Jeremie

On Thursday,  7 Jan 2021 at 13:59, Dirk Eddelbuettel wrote:
> Jeremie,
>
> As months have irregular number of dates, one needs to use a function that
> accounts for that (date libraries and packages have that, one of the earliest
> for R was my RcppBDT package using Boost Date_Time), or be otherwise clever.
>
> Here is a one-liner using the latter approach:
>
>    seq(as.Date("2010-02-01"), length=24, by="1 month") - 1
>
> See this old StackOverflow answer where I used this before:
>
>    https://stackoverflow.com/questions/8333838/generate-a-sequence-of-the-last-day-of-the-month-over-two-years
>
> Dirk

-- 
Jeremie Juste


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Fri Jan  8 02:01:36 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Thu, 7 Jan 2021 17:01:36 -0800
Subject: [R] Secondary y axis in ggplot2: did not respond when change its
 y-axis value
Message-ID: <CAMwU6B3NtSDnBQ+1cZZDqZ_t18u0faW3jyEmY2YUwqPnaODLgA@mail.gmail.com>

Hi R users,
I was trying to plot a graph with a secondary axis, and used the following
code for the data but the secondary line and secondary y -axis value did
not match. I would like to show both lines in one graph.

Any suggestions?

library(ggplot2)
library(reshape2)
daT<-structure(list(x = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 1L, 2L,
3L, 4L, 5L, 6L, 7L, 8L), y1 = c(9754L, 1051L, 5833L, 5769L, 2479L,
470L, 5828L, 174L, 2045L, 6099L, 8780L, 8732L, 4053L, 9419L,
4728L, 3587L), y2 = c(0.51, 0.61, 0.3, 0.81, 0.89, 0, 1.9, 0.76,
0.87, 0.29, 0, 0.42, 0.73, 0.96, 0.62, 0.06), group = c("A",
"A", "A", "A", "A", "A", "A", "A", "B", "B", "B", "B", "B", "B",
"B", "B")), class = "data.frame", row.names = c(NA, -16L))
print(daT)
daT1<-melt(daT, id.vars=c("x", "group"))
daT1%>%
  ggplot() +
  geom_line(aes(x = x, y = value, group = variable, color = variable)) +
  facet_wrap(~group) +
  scale_y_continuous(sec.axis = sec_axis(~ .*0.0001))

	[[alternative HTML version deleted]]


From gregco@t@ @end|ng |rom me@com  Fri Jan  8 07:54:42 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Fri, 8 Jan 2021 01:54:42 -0500
Subject: [R] Expected min height of view
In-Reply-To: <CAMwU6B3NtSDnBQ+1cZZDqZ_t18u0faW3jyEmY2YUwqPnaODLgA@mail.gmail.com>
References: <CAMwU6B3NtSDnBQ+1cZZDqZ_t18u0faW3jyEmY2YUwqPnaODLgA@mail.gmail.com>
Message-ID: <AB88D6DB-3F2A-44A7-8F97-A893198862A0@me.com>

I upgraded from R 4.0.2 to R 4.0.3 for Apple Mac at Duke University. Now, the only output I get from R 4.0.3 is an error message. Greg Coats
2021-01-07 22:58:42.997 R[8311:37566] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fcb6c592570>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.
> version
               _                           
platform       x86_64-apple-darwin17.0     
arch           x86_64                      
os             darwin17.0                  
system         x86_64, darwin17.0          
status                                     
major          4                           
minor          0.3                         
year           2020                        
month          10                          
day            10                          
svn rev        79318                       
language       R                           
version.string R version 4.0.3 (2020-10-10)
nickname       Bunny-Wunnies Freak Out     
> 
	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Jan  8 10:57:38 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 8 Jan 2021 09:57:38 +0000
Subject: [R] non-standard reshape from long to wide
In-Reply-To: <SJ0PR02MB7645BBDCF04B9BA76C554317D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
References: <SJ0PR02MB7645BBDCF04B9BA76C554317D4AF0@SJ0PR02MB7645.namprd02.prod.outlook.com>
Message-ID: <8c2d348b2ee845c28cec15fc8b74f305@SRVEXCHCM1302.precheza.cz>

Hi

dcast from reshape is close, however column order is different

mydf <- dcast(df.long, sample~marker)
(!is.na(mydf[,-1]))*1
     g j k u x y
[1,] 1 0 1 0 1 0
[2,] 0 1 0 1 1 1
[3,] 0 0 0 0 1 1

You just need to change 0 to NA and add rownames from mydf.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Yuan Chun Ding
> Sent: Thursday, January 7, 2021 7:40 PM
> To: r-help at r-project.org
> Subject: [R] non-standard reshape from long to wide
> 
> Dear R user,
> 
> I want to reshape a long data frame to wide format, I made the following
> example files.  Can you help me?
> 
> Thank you,
> 
> Yuan Chun Ding
> 
> sample <-c("xr" , "xr" , "fh" , "fh" , "fh" , "uy" , "uy" , "uy" , "uy");
marker <-
> c("x" , "y" , "g" , "x" , "k" , "y" , "x" , "u" , "j"); df.long
<-data.frame(sample,
> marker);
> 
> xr <-c(1,1,NA,NA,NA,NA);
> fh <-c(1,NA,1,1,NA,NA);
> uy <-c(1,1,NA,NA,1,1);
> 
> df.wide <- t(data.frame(xr,fh,uy));
> colnames(df.wide)<-c("x","y","g","k", "u","j");
> 
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> 
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
under
> applicable law (e.g., personal health information, research data,
financial
> information). Because this e-mail has been sent without encryption,
> individuals other than the intended recipient may be able to view the
> information, forward it to others or tamper with the information without
the
> knowledge or consent of the sender. If you are not the intended recipient,
or
> the employee or person responsible for delivering the message to the
> intended recipient, any dissemination, distribution or copying of the
> communication is strictly prohibited. If you received the communication in
> error, please notify the sender immediately by replying to this message
and
> deleting the message and any accompanying files from your system. If, due
> to the security risks, you do not wish to receive further communications
via
> e-mail, please reply to this message and inform the sender that you do not
> wish to receive further e-mail from the sender. (LCP301)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jan  8 15:58:27 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 8 Jan 2021 14:58:27 +0000
Subject: [R] 
 Secondary y axis in ggplot2: did not respond when change its
 y-axis value
In-Reply-To: <CAMwU6B3NtSDnBQ+1cZZDqZ_t18u0faW3jyEmY2YUwqPnaODLgA@mail.gmail.com>
References: <CAMwU6B3NtSDnBQ+1cZZDqZ_t18u0faW3jyEmY2YUwqPnaODLgA@mail.gmail.com>
Message-ID: <729e927c-50a7-fd4b-c5fc-443a3f896aff@sapo.pt>

Hello,

What about the following?
First get the min and max of value by variable == "y1".
Then use that range to scale up "y2".

rng <- tapply(daT1$value, daT1$variable, range)$y1

ggplot(data = daT1, aes(x = x, group = variable, color = variable)) +
   geom_line(data = subset(daT1, variable == "y1"),
             aes(y = value)) +
   geom_line(data = subset(daT1, variable == "y2"),
             aes(y = value*diff(rng) + rng[1])) +
   facet_wrap(~group) +
   scale_y_continuous(sec.axis = sec_axis(~ .*0.0001))


Hope this helps,

Rui Barradas

?s 01:01 de 08/01/21, Marna Wagley escreveu:
> Hi R users,
> I was trying to plot a graph with a secondary axis, and used the following
> code for the data but the secondary line and secondary y -axis value did
> not match. I would like to show both lines in one graph.
> 
> Any suggestions?
> 
> library(ggplot2)
> library(reshape2)
> daT<-structure(list(x = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 1L, 2L,
> 3L, 4L, 5L, 6L, 7L, 8L), y1 = c(9754L, 1051L, 5833L, 5769L, 2479L,
> 470L, 5828L, 174L, 2045L, 6099L, 8780L, 8732L, 4053L, 9419L,
> 4728L, 3587L), y2 = c(0.51, 0.61, 0.3, 0.81, 0.89, 0, 1.9, 0.76,
> 0.87, 0.29, 0, 0.42, 0.73, 0.96, 0.62, 0.06), group = c("A",
> "A", "A", "A", "A", "A", "A", "A", "B", "B", "B", "B", "B", "B",
> "B", "B")), class = "data.frame", row.names = c(NA, -16L))
> print(daT)
> daT1<-melt(daT, id.vars=c("x", "group"))
> daT1%>%
>    ggplot() +
>    geom_line(aes(x = x, y = value, group = variable, color = variable)) +
>    facet_wrap(~group) +
>    scale_y_continuous(sec.axis = sec_axis(~ .*0.0001))
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Fri Jan  8 16:55:04 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Fri, 8 Jan 2021 07:55:04 -0800
Subject: [R] 
 Secondary y axis in ggplot2: did not respond when change its
 y-axis value
In-Reply-To: <729e927c-50a7-fd4b-c5fc-443a3f896aff@sapo.pt>
References: <CAMwU6B3NtSDnBQ+1cZZDqZ_t18u0faW3jyEmY2YUwqPnaODLgA@mail.gmail.com>
 <729e927c-50a7-fd4b-c5fc-443a3f896aff@sapo.pt>
Message-ID: <CAMwU6B09Ut73Uu32J1c8ve1nRbt=0CCBxCJZV_3Y4yKR5ekQ+w@mail.gmail.com>

Thank you Rui and Thierry for the suggestion, it helped me.
thanks


On Fri, Jan 8, 2021 at 6:58 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> What about the following?
> First get the min and max of value by variable == "y1".
> Then use that range to scale up "y2".
>
> rng <- tapply(daT1$value, daT1$variable, range)$y1
>
> ggplot(data = daT1, aes(x = x, group = variable, color = variable)) +
>    geom_line(data = subset(daT1, variable == "y1"),
>              aes(y = value)) +
>    geom_line(data = subset(daT1, variable == "y2"),
>              aes(y = value*diff(rng) + rng[1])) +
>    facet_wrap(~group) +
>    scale_y_continuous(sec.axis = sec_axis(~ .*0.0001))
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 01:01 de 08/01/21, Marna Wagley escreveu:
> > Hi R users,
> > I was trying to plot a graph with a secondary axis, and used the
> following
> > code for the data but the secondary line and secondary y -axis value did
> > not match. I would like to show both lines in one graph.
> >
> > Any suggestions?
> >
> > library(ggplot2)
> > library(reshape2)
> > daT<-structure(list(x = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 1L, 2L,
> > 3L, 4L, 5L, 6L, 7L, 8L), y1 = c(9754L, 1051L, 5833L, 5769L, 2479L,
> > 470L, 5828L, 174L, 2045L, 6099L, 8780L, 8732L, 4053L, 9419L,
> > 4728L, 3587L), y2 = c(0.51, 0.61, 0.3, 0.81, 0.89, 0, 1.9, 0.76,
> > 0.87, 0.29, 0, 0.42, 0.73, 0.96, 0.62, 0.06), group = c("A",
> > "A", "A", "A", "A", "A", "A", "A", "B", "B", "B", "B", "B", "B",
> > "B", "B")), class = "data.frame", row.names = c(NA, -16L))
> > print(daT)
> > daT1<-melt(daT, id.vars=c("x", "group"))
> > daT1%>%
> >    ggplot() +
> >    geom_line(aes(x = x, y = value, group = variable, color = variable)) +
> >    facet_wrap(~group) +
> >    scale_y_continuous(sec.axis = sec_axis(~ .*0.0001))
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From zyr@em@dhe @end|ng |rom gm@||@com  Fri Jan  8 15:43:34 2021
From: zyr@em@dhe @end|ng |rom gm@||@com (zyra e madhe)
Date: Fri, 8 Jan 2021 15:43:34 +0100
Subject: [R] HW help
Message-ID: <CAJWAM5KbAv1Ko7KyFJ3nrs8vjgtobZ75B0H3ktt6BkWmNUu_7w@mail.gmail.com>

Hello,

I'm having difficulty doing the following exercise.
Can you please provide the code and some written explanation?

Thank you in advance,

Zyra

-------------- next part --------------
A non-text attachment was scrubbed...
Name: php6hX1Pn.png
Type: image/png
Size: 38530 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210108/fb34f2a5/attachment.png>

From jrg @end|ng |rom |oe@|@u@  Fri Jan  8 22:31:24 2021
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Fri, 8 Jan 2021 16:31:24 -0500
Subject: [R] HW help
In-Reply-To: <CAJWAM5KbAv1Ko7KyFJ3nrs8vjgtobZ75B0H3ktt6BkWmNUu_7w@mail.gmail.com>
References: <CAJWAM5KbAv1Ko7KyFJ3nrs8vjgtobZ75B0H3ktt6BkWmNUu_7w@mail.gmail.com>
Message-ID: <67368d1c-37f1-8c1a-eb44-ffa4381c62f1@loesl.us>

This list has a no-homework policy.

---JRG




On 2021-01-08 09:43, zyra e madhe wrote:
> Hello,
> 
> I'm having difficulty doing the following exercise.
> Can you please provide the code and some written explanation?
> 
> Thank you in advance,
> 
> Zyra
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ycd|ng @end|ng |rom coh@org  Fri Jan  8 23:33:13 2021
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Fri, 8 Jan 2021 22:33:13 +0000
Subject: [R] replace zero in a matrix using random numbers
Message-ID: <SJ0PR02MB7645CBA0B184021E32C45447D4AE0@SJ0PR02MB7645.namprd02.prod.outlook.com>

Hi R users,

I am analyzing miRNA sequence data for a special network analysis, I need to replace zero values in a matrix as random numbers with mean of 1 and standard deviation of 0.1.

er.miRCounts[er.miRCounts==0] <- rnorm(1,mean=1, sd=0.1);

this code made all zero values as 1.13, not random numbers across different zero values.  If all zero values in one row are replaced by the same 1.13,  then sd in that row is zero, causing other problem in the following calculation.

Can you help me?

Thank you,

Yuan chun Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jan  8 23:44:53 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 8 Jan 2021 22:44:53 +0000
Subject: [R] replace zero in a matrix using random numbers
In-Reply-To: <SJ0PR02MB7645CBA0B184021E32C45447D4AE0@SJ0PR02MB7645.namprd02.prod.outlook.com>
References: <SJ0PR02MB7645CBA0B184021E32C45447D4AE0@SJ0PR02MB7645.namprd02.prod.outlook.com>
Message-ID: <c80a4ac9-585e-74cc-0f1e-d43dc151c0b0@sapo.pt>

Hello,

Try to get the number of zero values before:

i <- er.miRCounts == 0
n <- sum(i)
er.miRCounts[i] <- rnorm(n,mean=1, sd=0.1)


Also, there is no need for a end-of-instruction ';'.
The semi-colon is the instruction separator, so if you put it at the end 
you will be separating the instruction you wrote from the NULL 
instruction. A simpler example could be

mean(1:5);

This is *two* instructions:

mean(1:5); NULL


Hope this helps,

Rui Barradas

?s 22:33 de 08/01/21, Yuan Chun Ding escreveu:
> Hi R users,
> 
> I am analyzing miRNA sequence data for a special network analysis, I need to replace zero values in a matrix as random numbers with mean of 1 and standard deviation of 0.1.
> 
> er.miRCounts[er.miRCounts==0] <- rnorm(1,mean=1, sd=0.1);
> 
> this code made all zero values as 1.13, not random numbers across different zero values.  If all zero values in one row are replaced by the same 1.13,  then sd in that row is zero, causing other problem in the following calculation.
> 
> Can you help me?
> 
> Thank you,
> 
> Yuan chun Ding
> 
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> 
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

From bgunter@4567 @end|ng |rom gm@||@com  Fri Jan  8 23:49:12 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 8 Jan 2021 14:49:12 -0800
Subject: [R] replace zero in a matrix using random numbers
In-Reply-To: <SJ0PR02MB7645CBA0B184021E32C45447D4AE0@SJ0PR02MB7645.namprd02.prod.outlook.com>
References: <SJ0PR02MB7645CBA0B184021E32C45447D4AE0@SJ0PR02MB7645.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbSD5in92f-N7N_ykguv6C-Oeqa7pZxCWXverDzuDHWHoQ@mail.gmail.com>

?rnorm tells you that n, the first argument, is the number of
observations/random numbers you wish to generate. You asked for 1.
So you need to ask for the number of 0's, something like:

> a <- matrix(rep(0:1, 3), nrow =3)
> a
     [,1] [,2]
[1,]    0    1
[2,]    1    0
[3,]    0    1
> a[!a] <- rnorm(sum(!a), 1,.1)
> a
          [,1]     [,2]
[1,] 0.8136788 1.000000
[2,] 1.0000000 1.146225
[3,] 0.9081908 1.000000

Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 8, 2021 at 2:33 PM Yuan Chun Ding <ycding at coh.org> wrote:

> Hi R users,
>
> I am analyzing miRNA sequence data for a special network analysis, I need
> to replace zero values in a matrix as random numbers with mean of 1 and
> standard deviation of 0.1.
>
> er.miRCounts[er.miRCounts==0] <- rnorm(1,mean=1, sd=0.1);
>
> this code made all zero values as 1.13, not random numbers across
> different zero values.  If all zero values in one row are replaced by the
> same 1.13,  then sd in that row is zero, causing other problem in the
> following calculation.
>
> Can you help me?
>
> Thank you,
>
> Yuan chun Ding
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to receive further
> communications via e-mail, please reply to this message and inform the
> sender that you do not wish to receive further e-mail from the sender.
> (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ycd|ng @end|ng |rom coh@org  Sat Jan  9 00:00:38 2021
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Fri, 8 Jan 2021 23:00:38 +0000
Subject: [R] replace zero in a matrix using random numbers
In-Reply-To: <CAGxFJbSD5in92f-N7N_ykguv6C-Oeqa7pZxCWXverDzuDHWHoQ@mail.gmail.com>
References: <SJ0PR02MB7645CBA0B184021E32C45447D4AE0@SJ0PR02MB7645.namprd02.prod.outlook.com>
 <CAGxFJbSD5in92f-N7N_ykguv6C-Oeqa7pZxCWXverDzuDHWHoQ@mail.gmail.com>
Message-ID: <SJ0PR02MB7645DCD7E4AA496CA7F06C16D4AE0@SJ0PR02MB7645.namprd02.prod.outlook.com>

Hi Bert and Rui,

Thank you very much!  I had thought for every condition of  matrix ==0 ,  rnrom(n=1, 1, 0.1) will randomly generate a number with mean 1 and sd 0.1.

Yuan

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Friday, January 8, 2021 2:49 PM
To: Yuan Chun Ding <ycding at coh.org>
Cc: r-help at r-project.org
Subject: Re: [R] replace zero in a matrix using random numbers

?rnorm tells you that n, the first argument, is the number of observations/random numbers you wish to generate. You asked for 1.
So you need to ask for the number of 0's, something like:

> a <- matrix(rep(0:1, 3), nrow =3)
> a
     [,1] [,2]
[1,]    0    1
[2,]    1    0
[3,]    0    1
> a[!a] <- rnorm(sum(!a), 1,.1)
> a
          [,1]     [,2]
[1,] 0.8136788 1.000000
[2,] 1.0000000 1.146225
[3,] 0.9081908 1.000000

Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 8, 2021 at 2:33 PM Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>> wrote:
Hi R users,

I am analyzing miRNA sequence data for a special network analysis, I need to replace zero values in a matrix as random numbers with mean of 1 and standard deviation of 0.1.

er.miRCounts[er.miRCounts==0] <- rnorm(1,mean=1, sd=0.1);

this code made all zero values as 1.13, not random numbers across different zero values.  If all zero values in one row are replaced by the same 1.13,  then sd in that row is zero, causing other problem in the following calculation.

Can you help me?

Thank you,

Yuan chun Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!6DmiKt7lXx7yfq0jUsdRHh-P5ZiKxoViTNaEApo8IZkGCfXY5v2vD0NYpbXt$>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!6DmiKt7lXx7yfq0jUsdRHh-P5ZiKxoViTNaEApo8IZkGCfXY5v2vD0eS8lpe$>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From |@ur@coco @end|ng |rom gm@||@com  Sat Jan  9 04:30:16 2021
From: |@ur@coco @end|ng |rom gm@||@com (Laura Coco)
Date: Fri, 8 Jan 2021 20:30:16 -0700
Subject: [R] Error in contrasts adding bonferroni adjustment
Message-ID: <CAKgKnP4R=s9CUoyQrVR190OeyB8DOjyc5gq2RCbBbYFoSNskpg@mail.gmail.com>

Hello

I am trying to add a Bonferroni adjustment to two comparisons, and I'm
getting an error msg.

The contrasts run just fine; I used a contrast matrix with dummy
variables: Experimental
vs Control at post1 (first contrast) and Experimental vs Control at post2
(second contrast).

contrast.outcome <-contrast(emmeans.outcome, method =
list("experimental_post1 - control_post1" = c(1, 0, -1, 0),
"experimental_post2 - control_post2" = c(0, 1, 0, -1), adjust = "bonf"))

The code runs except when I add the adjust = "bonf" - The error is "Error
in tcmat %*% linfct : requires numeric/complex matrix/vector arguments"

I see many tutorials online about adjusting in pairwise comparisons and
ANOVA but not in this situation. Any guidance you can provide would be much
appreciated.

Thank you!

Laura

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Sat Jan  9 13:57:57 2021
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Sat, 9 Jan 2021 07:57:57 -0500
Subject: [R] Error in contrasts adding bonferroni adjustment
In-Reply-To: <CAKgKnP4R=s9CUoyQrVR190OeyB8DOjyc5gq2RCbBbYFoSNskpg@mail.gmail.com>
References: <CAKgKnP4R=s9CUoyQrVR190OeyB8DOjyc5gq2RCbBbYFoSNskpg@mail.gmail.com>
Message-ID: <CAJc=yOEGLGe8GgQjCz9ATBikkNHPcupiKtb9nT1q_vh3i01aLQ@mail.gmail.com>

Looks like a misplaced right parenthesis. Try

contrast.outcome <-contrast(emmeans.outcome, method =
list("experimental_post1 - control_post1" = c(1, 0, -1, 0),
"experimental_post2 - control_post2" = c(0, 1, 0, -1)), adjust = "bonf")

Pat


On Sat, Jan 9, 2021 at 3:10 AM Laura Coco <lauracoco at gmail.com> wrote:
>
> Hello
>
> I am trying to add a Bonferroni adjustment to two comparisons, and I'm
> getting an error msg.
>
> The contrasts run just fine; I used a contrast matrix with dummy
> variables: Experimental
> vs Control at post1 (first contrast) and Experimental vs Control at post2
> (second contrast).
>
> contrast.outcome <-contrast(emmeans.outcome, method =
> list("experimental_post1 - control_post1" = c(1, 0, -1, 0),
> "experimental_post2 - control_post2" = c(0, 1, 0, -1), adjust = "bonf"))
>
> The code runs except when I add the adjust = "bonf" - The error is "Error
> in tcmat %*% linfct : requires numeric/complex matrix/vector arguments"
>
> I see many tutorials online about adjusting in pairwise comparisons and
> ANOVA but not in this situation. Any guidance you can provide would be much
> appreciated.
>
> Thank you!
>
> Laura
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sat Jan  9 20:58:57 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sat, 9 Jan 2021 19:58:57 +0000 (UTC)
Subject: [R] Problem with a LOESS curve
References: <170518512.349410.1610222337123.ref@mail.yahoo.com>
Message-ID: <170518512.349410.1610222337123@mail.yahoo.com>

Dear R-experts,

Here below my R code. What is happening with my green curve ? How to solve the problem ?

Many thanks,

##############################
#DATA
y<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
x<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)

#PLOT
plot(x,y)

#GAM
library(mgcv)
fit3=gam(y~s(x,bs='ps'))
x.new<- seq(range(x)[1], range(x)[2], len=1000)
gamfit.new <- as.vector(predict.gam(fit3,data.frame(x=x.new),type="response"))
lines(x.new, gamfit.new, col="red", lwd=2) 

# LOESS
mod=loess(y~x, span=0.8)
yfit=predict(mod,newdata=x)
lines(x,yfit,col="green",lwd=2)
##############################


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Jan  9 21:13:27 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 9 Jan 2021 15:13:27 -0500
Subject: [R] Problem with a LOESS curve
In-Reply-To: <170518512.349410.1610222337123@mail.yahoo.com>
References: <170518512.349410.1610222337123.ref@mail.yahoo.com>
 <170518512.349410.1610222337123@mail.yahoo.com>
Message-ID: <9fd299e8-0ab9-d2e9-46cc-164584ec2610@gmail.com>

Your x values aren't in increasing order.  When you plot lines(x, yfit), 
it joins the points in the order you give them, which jumps back and 
forth.  To fix, try

o <- order(x)
lines(x[o], yfit[o], col="green", lwd=2)

Duncan Murdoch

On 09/01/2021 2:58 p.m., varin sacha via R-help wrote:
> ##############################
> #DATA
> y<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
> x<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)
> 
> #PLOT
> plot(x,y)
> 
> #GAM
> library(mgcv)
> fit3=gam(y~s(x,bs='ps'))
> x.new<- seq(range(x)[1], range(x)[2], len=1000)
> gamfit.new <- as.vector(predict.gam(fit3,data.frame(x=x.new),type="response"))
> lines(x.new, gamfit.new, col="red", lwd=2)
> 
> # LOESS
> mod=loess(y~x, span=0.8)
> yfit=predict(mod,newdata=x)
> lines(x,yfit,col="green",lwd=2)
> ##############################


From chr|@ho|d @end|ng |rom p@yctc@org  Sun Jan 10 11:26:25 2021
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Sun, 10 Jan 2021 10:26:25 +0000 (GMT)
Subject: [R] How to avoid ggplot clipping the x axis
Message-ID: <988720390.7953615.1610274385838.JavaMail.zimbra@psyctc.org>

I am sure I am doing something stupid but I can't see what. I am plotting data and want the x axis labels to reflect the theoretical range of the x variable which happens to be 1:6 but the observed values have range 2.6 to 5.9. 

I thought xlim(c(1,6)) should have got me that quite simply but it doesn't.  I think this is a reproducible example of my failures (!)

library(tidyverse)
library(ggplot2)
x <- seq(2,5.8,.2)
list(x = x,
     y = rnorm(length(x))) %>%
  as_tibble() -> tibDat

ggplot(dat = tibDat,
       aes(x = x, y = y)) +
  geom_point() +
  xlim(c(1,6))
  
ggplot(dat = tibDat,
       aes(x = x, y = y)) +
  geom_point() +
  scale_x_continuous(breaks = 1:6, labels = 1:6) 
  
ggplot(dat = tibDat,
       aes(x = x, y = y)) +
  geom_point() +
  xlim(c(1,6)) +
  coord_cartesian(clip = "off")

ggplot(dat = tibDat,
       aes(x = x, y = y)) +
  geom_point() +
  xlim(c(1,6)) +
  coord_cartesian(expand = TRUE)

Bizarrely (to me)

ggplot(dat = tibDat,
       aes(x = x, y = y)) +
  geom_point() +
  xlim(c(0,6))

-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From chr|@ho|d @end|ng |rom p@yctc@org  Sun Jan 10 11:34:43 2021
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Sun, 10 Jan 2021 10:34:43 +0000 (GMT)
Subject: [R] How to avoid ggplot clipping the x axis [damn,
 replaces previous Email]
Message-ID: <1638985892.7959044.1610274883233.JavaMail.zimbra@psyctc.org>

[I must try to remember that swapping between Rstudio and my Emailer is a recipe for hitting ctrl-enter and posting prematurely: sorry!] 

I am sure I am doing something stupid but I can't see what. I am plotting data and want the x axis labels to reflect the theoretical range of the x variable which happens to be 1:6 but the observed values have range 2.6 to 5.9. 

I thought xlim(c(1,6)) should have got me that quite simply but it doesn't. I think this is a reproducible example of my failures (!) 
library(tidyverse) 
library(ggplot2) 
x <- seq(2,5.8,.2) 
list(x = x, 
y = rnorm(length(x))) %>% 
as_tibble() -> tibDat 

ggplot(dat = tibDat, 
aes(x = x, y = y)) + 
geom_point() + 
xlim(c(1,6)) 
# x labels on plot are 2, 4 & 6 

ggplot(dat = tibDat, 
aes(x = x, y = y)) + 
geom_point() + 
expand_limits(x = c(1,6)) 
# same 

ggplot(dat = tibDat, 
aes(x = x, y = y)) + 
geom_point() + 
scale_x_continuous(breaks = 1:6, labels = 1:6) 
# x labelled at 2:5 (why?!) 

ggplot(dat = tibDat, 
aes(x = x, y = y)) + 
geom_point() + 
xlim(c(1,6)) + 
coord_cartesian(clip = "off") 
# back to 2, 4, 6 

ggplot(dat = tibDat, 
aes(x = x, y = y)) + 
geom_point() + 
xlim(c(1,6)) + 
coord_cartesian(expand = TRUE) 
# same 

### OK, getting desperately hopeful 
ggplot(dat = tibDat, 
aes(x = x, y = y)) + 
geom_point() + 
xlim(c(0,6)) 
# x axis has 0, 2, 4 and 6 (surely inconsistent behaviour?) 

ggplot(dat = tibDat, 
aes(x = x, y = y)) + 
geom_point() + 
xlim(c(0.1,6)) 
# x axis has 0, 2, 4 and 6 

Can anyone see the simple answer that is eluding me?! 

TIA, 

Chris 


-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/ 

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk> 
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places 
but <chris at psyctc.org> remains my main Email address. I have a work web site at: 
https://www.psyctc.org/psyctc/ 
and a site I manage for CORE and CORE system trust at: 
http://www.coresystemtrust.org.uk/ 
I have "semigrated" to France, see: 
https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/ 

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at: 
https://www.psyctc.org/pelerinage2016/ceworkdiary/ 
Beware: French time, generally an hour ahead of UK. 

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jan 10 19:10:16 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 10 Jan 2021 18:10:16 +0000
Subject: [R] How to avoid ggplot clipping the x axis [damn,
 replaces previous Email]
In-Reply-To: <1638985892.7959044.1610274883233.JavaMail.zimbra@psyctc.org>
References: <1638985892.7959044.1610274883233.JavaMail.zimbra@psyctc.org>
Message-ID: <9243d51c-4a5c-1a17-fef0-307b3f36c0a5@sapo.pt>

Hello,

You are almost there.

With scale_x_continuous use argument limits.


ggplot(dat = tibDat,
        aes(x = x, y = y)) +
   geom_point() +
   scale_x_continuous(breaks = 1:6, labels = 1:6,
                      limits = c(1, 6))


And with xlim it's not a vector c(1, 6), it's each element on its own:

xlim(1, 6)


Or

lims(x = c(1, 6))


But with these two, the labels are not like you want them, they are 2 by 2.

Hope this helps,

Rui Barradas

?s 10:34 de 10/01/21, Chris Evans escreveu:
> [I must try to remember that swapping between Rstudio and my Emailer is a recipe for hitting ctrl-enter and posting prematurely: sorry!]
> 
> I am sure I am doing something stupid but I can't see what. I am plotting data and want the x axis labels to reflect the theoretical range of the x variable which happens to be 1:6 but the observed values have range 2.6 to 5.9.
> 
> I thought xlim(c(1,6)) should have got me that quite simply but it doesn't. I think this is a reproducible example of my failures (!)
> library(tidyverse)
> library(ggplot2)
> x <- seq(2,5.8,.2)
> list(x = x,
> y = rnorm(length(x))) %>%
> as_tibble() -> tibDat
> 
> ggplot(dat = tibDat,
> aes(x = x, y = y)) +
> geom_point() +
> xlim(c(1,6))
> # x labels on plot are 2, 4 & 6
> 
> ggplot(dat = tibDat,
> aes(x = x, y = y)) +
> geom_point() +
> expand_limits(x = c(1,6))
> # same
> 
> ggplot(dat = tibDat,
> aes(x = x, y = y)) +
> geom_point() +
> scale_x_continuous(breaks = 1:6, labels = 1:6)
> # x labelled at 2:5 (why?!)
> 
> ggplot(dat = tibDat,
> aes(x = x, y = y)) +
> geom_point() +
> xlim(c(1,6)) +
> coord_cartesian(clip = "off")
> # back to 2, 4, 6
> 
> ggplot(dat = tibDat,
> aes(x = x, y = y)) +
> geom_point() +
> xlim(c(1,6)) +
> coord_cartesian(expand = TRUE)
> # same
> 
> ### OK, getting desperately hopeful
> ggplot(dat = tibDat,
> aes(x = x, y = y)) +
> geom_point() +
> xlim(c(0,6))
> # x axis has 0, 2, 4 and 6 (surely inconsistent behaviour?)
> 
> ggplot(dat = tibDat,
> aes(x = x, y = y)) +
> geom_point() +
> xlim(c(0.1,6))
> # x axis has 0, 2, 4 and 6
> 
> Can anyone see the simple answer that is eluding me?!
> 
> TIA,
> 
> Chris
> 
>


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun Jan 10 20:10:40 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 10 Jan 2021 19:10:40 +0000 (UTC)
Subject: [R] Problem with a LOESS curve
In-Reply-To: <9fd299e8-0ab9-d2e9-46cc-164584ec2610@gmail.com>
References: <170518512.349410.1610222337123.ref@mail.yahoo.com>
 <170518512.349410.1610222337123@mail.yahoo.com>
 <9fd299e8-0ab9-d2e9-46cc-164584ec2610@gmail.com>
Message-ID: <2069886278.689864.1610305840240@mail.yahoo.com>

Duncan,

Great, many thanks, it works.

Best,




Le samedi 9 janvier 2021 ? 21:13:30 UTC+1, Duncan Murdoch <murdoch.duncan at gmail.com> a ?crit : 





Your x values aren't in increasing order.? When you plot lines(x, yfit), 
it joins the points in the order you give them, which jumps back and 
forth.? To fix, try

o <- order(x)
lines(x[o], yfit[o], col="green", lwd=2)

Duncan Murdoch

On 09/01/2021 2:58 p.m., varin sacha via R-help wrote:
> ##############################
> #DATA
> y<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
> x<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)
> 
> #PLOT
> plot(x,y)
> 
> #GAM
> library(mgcv)
> fit3=gam(y~s(x,bs='ps'))
> x.new<- seq(range(x)[1], range(x)[2], len=1000)
> gamfit.new <- as.vector(predict.gam(fit3,data.frame(x=x.new),type="response"))
> lines(x.new, gamfit.new, col="red", lwd=2)
> 
> # LOESS
> mod=loess(y~x, span=0.8)
> yfit=predict(mod,newdata=x)
> lines(x,yfit,col="green",lwd=2)
> ##############################


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun Jan 10 20:17:25 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 10 Jan 2021 19:17:25 +0000 (UTC)
Subject: [R] Green curve/line does not appear on the plot
References: <1034286840.704980.1610306245230.ref@mail.yahoo.com>
Message-ID: <1034286840.704980.1610306245230@mail.yahoo.com>

Dear R-experts,

I dont get any error message but I can't get the green curve/line on the plot.
What is going on ? How to solve my problem ?

Here is the R code :

####################
PIB.hab<-c(12000,34000,25000,43000,12500,32400,76320,45890,76345,90565,76580,45670,23450,34560,65430,65435,56755,87655,90755,45675)
ISQ.2018<-c(564,587,489,421,478,499,521,510,532,476,421,467,539,521,478,532,449,487,465,500)

A=c("Australie","Autriche","Belgique","Canada","Chili","R?p. Tch?que","Danemark","Estonie","Finlande","France","Allemange","Gr?ce","Hongrie","Islande","Irlande","Isra?l","Italie","Japon","Cor?e","Lettonie")
?
plot(ISQ.2018,PIB.hab)

library(basicPlotteR)? 

# Add non-overlapping text labels

addTextLabels(ISQ.2018, PIB.hab, A, col.label="black")?


## LOESS FIT
mod=loess(PIB.hab~ISQ.2018,span=1)
yfit=predict(mod,newdata=ISQ.2018)
o=order(ISQ.2018)
lines(ISQ.2018[o],yfit[o],col="blue",lwd=2)

#GAM
library(mgcv)
fit3=gam(PIB.hab~s(ISQ.2018,bs='ps'))
x.new<- seq(range(ISQ.2018)[1], range(ISQ.2018)[2])
gamfit.new <- as.vector(predict.gam(fit3,data.frame(ISQ.2018=x.new),type="response"))
lines(x.new, gamfit.new, col="red", lwd=2)

#Robust GAM
library(robustgam)
true.family <- poisson() 
fit=robustgam(PIB.hab,ISQ.2018, sp=0,family=true.family,smooth.basis='ps',K=3)
x.new <- seq(range(ISQ.2018)[1], range(ISQ.2018)[2])
robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
lines(x.new, robustfit.new, col="green", lwd=2)
####################


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sun Jan 10 20:57:05 2021
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sun, 10 Jan 2021 20:57:05 +0100
Subject: [R] How to get Mean Magnitude of Relative Error with caret library
Message-ID: <CA+nrPnsuDP17CKLZidaL5igMa=4TB7d1qypT=RUKkxGabqL6dA@mail.gmail.com>

Hi, I am using caret package and using nested resampling method (i.e. 5
fold for outer fold). I am getting the RMSE and MAE values, which are
default to the caret library.
My question is how can we implement the Mean Magnitude of Relative Error
(MRE and MMRE) with caret. My code is the following:

outer_folds <- createFolds(d$price, k = 5)
boot <- trainControl(method = "boot", number=100)

CV1 <- lapply(outer_folds, function(index){
  tr <- d[-index, ]
  ts <- d[index,]

  cart1 <- train(bug ~ ., data = tr,
                  method = "rf",
                 metric = "MAE",
                 preProc = c("center", "scale", "nzv"),
                 trControl = boot)

  postResample(predict(cart1, ts), ts$price)
})
sapply(CV1, function(x) x[3]) -> CV_MAE1
CV_MAE1

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jan 10 22:24:20 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 10 Jan 2021 16:24:20 -0500
Subject: [R] Green curve/line does not appear on the plot
In-Reply-To: <1034286840.704980.1610306245230@mail.yahoo.com>
References: <1034286840.704980.1610306245230.ref@mail.yahoo.com>
 <1034286840.704980.1610306245230@mail.yahoo.com>
Message-ID: <b8b3f133-eadd-66b2-d28d-7a42db47500f@gmail.com>

On 10/01/2021 2:17 p.m., varin sacha via R-help wrote:
> Dear R-experts,
> 
> I dont get any error message but I can't get the green curve/line on the plot.
> What is going on ? How to solve my problem ?

Look at the values of robustfit.new.  They are far smaller than any of 
the other values, and don't fall in the range of the plot.  I think 
you've messed up the call to robustgam().

Duncan Murdoch

> 
> Here is the R code :
> 
> ####################
> PIB.hab<-c(12000,34000,25000,43000,12500,32400,76320,45890,76345,90565,76580,45670,23450,34560,65430,65435,56755,87655,90755,45675)
> ISQ.2018<-c(564,587,489,421,478,499,521,510,532,476,421,467,539,521,478,532,449,487,465,500)
> 
> A=c("Australie","Autriche","Belgique","Canada","Chili","R?p. Tch?que","Danemark","Estonie","Finlande","France","Allemange","Gr?ce","Hongrie","Islande","Irlande","Isra?l","Italie","Japon","Cor?e","Lettonie")
>   
> plot(ISQ.2018,PIB.hab)
> 
> library(basicPlotteR)
> 
> # Add non-overlapping text labels
> 
> addTextLabels(ISQ.2018, PIB.hab, A, col.label="black")
> 
> 
> ## LOESS FIT
> mod=loess(PIB.hab~ISQ.2018,span=1)
> yfit=predict(mod,newdata=ISQ.2018)
> o=order(ISQ.2018)
> lines(ISQ.2018[o],yfit[o],col="blue",lwd=2)
> 
> #GAM
> library(mgcv)
> fit3=gam(PIB.hab~s(ISQ.2018,bs='ps'))
> x.new<- seq(range(ISQ.2018)[1], range(ISQ.2018)[2])
> gamfit.new <- as.vector(predict.gam(fit3,data.frame(ISQ.2018=x.new),type="response"))
> lines(x.new, gamfit.new, col="red", lwd=2)
> 
> #Robust GAM
> library(robustgam)
> true.family <- poisson()
> fit=robustgam(PIB.hab,ISQ.2018, sp=0,family=true.family,smooth.basis='ps',K=3)
> x.new <- seq(range(ISQ.2018)[1], range(ISQ.2018)[2])
> robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
> lines(x.new, robustfit.new, col="green", lwd=2)
> ####################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nz@h@@m @end|ng |rom gm@||@com  Sun Jan 10 09:53:14 2021
From: nz@h@@m @end|ng |rom gm@||@com (Shaami)
Date: Sun, 10 Jan 2021 13:53:14 +0500
Subject: [R] log of small values in R
Message-ID: <CAGR+MS7n24pe05-XVPA2-of=43PzcS+NU5ANAqcbA-YRQ33ZUA@mail.gmail.com>

Dear Friends        I am facing the problem of log values in R. The
log(1-0.99999999999999999) is giving -Inf while log(1e-18) gives finite
answer. Any suggestion to deal with this problem?  Thank you

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jan 11 08:38:17 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 10 Jan 2021 23:38:17 -0800
Subject: [R] log of small values in R
In-Reply-To: <CAGR+MS7n24pe05-XVPA2-of=43PzcS+NU5ANAqcbA-YRQ33ZUA@mail.gmail.com>
References: <CAGR+MS7n24pe05-XVPA2-of=43PzcS+NU5ANAqcbA-YRQ33ZUA@mail.gmail.com>
Message-ID: <E2B771C0-F812-46E7-9D1A-C71A8D24AE3C@dcn.davis.ca.us>

?log1p

On January 10, 2021 12:53:14 AM PST, Shaami <nzshaam at gmail.com> wrote:
>Dear Friends        I am facing the problem of log values in R. The
>log(1-0.99999999999999999) is giving -Inf while log(1e-18) gives finite
>answer. Any suggestion to deal with this problem?  Thank you
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Jan 11 09:12:20 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 11 Jan 2021 00:12:20 -0800
Subject: [R] log of small values in R
In-Reply-To: <E2B771C0-F812-46E7-9D1A-C71A8D24AE3C@dcn.davis.ca.us>
References: <CAGR+MS7n24pe05-XVPA2-of=43PzcS+NU5ANAqcbA-YRQ33ZUA@mail.gmail.com>
 <E2B771C0-F812-46E7-9D1A-C71A8D24AE3C@dcn.davis.ca.us>
Message-ID: <53BB8ADD-0C68-4A0E-B306-40C9D5FD1586@comcast.net>



> On Jan 10, 2021, at 11:38 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> ?log1p
> 
> On January 10, 2021 12:53:14 AM PST, Shaami <nzshaam at gmail.com> wrote:
>> Dear Friends        I am facing the problem of log values in R. The
>> log(1-0.99999999999999999) is giving -Inf while log(1e-18) gives finite
>> answer. Any suggestion to deal with this problem?  Thank you

Jeff answers the specific question (of how to deal with the issue) but as to why?

> 0.9999999999999999999 == 1
[1] TRUE


And you should switch your mail client to plain text in future contributions to Rhelp.

-- 
David.


>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chr|@ho|d @end|ng |rom p@yctc@org  Mon Jan 11 11:15:35 2021
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Mon, 11 Jan 2021 10:15:35 +0000 (GMT)
Subject: [R] How to avoid ggplot clipping the x axis [damn,
 replaces previous Email]
In-Reply-To: <9243d51c-4a5c-1a17-fef0-307b3f36c0a5@sapo.pt>
References: <1638985892.7959044.1610274883233.JavaMail.zimbra@psyctc.org>
 <9243d51c-4a5c-1a17-fef0-307b3f36c0a5@sapo.pt>
Message-ID: <2044704809.9390649.1610360135555.JavaMail.zimbra@psyctc.org>

Perfect.  Can't believe I failed to find that!  Thanks, as ever, Rui

----- Original Message -----
> From: "Rui Barradas" <ruipbarradas at sapo.pt>
> To: "Chris Evans" <chrishold at psyctc.org>, R-help at r-project.org
> Sent: Sunday, 10 January, 2021 18:10:16
> Subject: Re: [R] How to avoid ggplot clipping the x axis [damn, replaces previous Email]

> Hello,
> 
> You are almost there.
> 
> With scale_x_continuous use argument limits.
> 
> 
> ggplot(dat = tibDat,
>        aes(x = x, y = y)) +
>   geom_point() +
>   scale_x_continuous(breaks = 1:6, labels = 1:6,
>                      limits = c(1, 6))
> 
> 
> And with xlim it's not a vector c(1, 6), it's each element on its own:
> 
> xlim(1, 6)
> 
> 
> Or
> 
> lims(x = c(1, 6))
> 
> 
> But with these two, the labels are not like you want them, they are 2 by 2.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 10:34 de 10/01/21, Chris Evans escreveu:
>> [I must try to remember that swapping between Rstudio and my Emailer is a recipe
>> for hitting ctrl-enter and posting prematurely: sorry!]
>> 
>> I am sure I am doing something stupid but I can't see what. I am plotting data
>> and want the x axis labels to reflect the theoretical range of the x variable
>> which happens to be 1:6 but the observed values have range 2.6 to 5.9.
>> 
>> I thought xlim(c(1,6)) should have got me that quite simply but it doesn't. I
>> think this is a reproducible example of my failures (!)
>> library(tidyverse)
>> library(ggplot2)
>> x <- seq(2,5.8,.2)
>> list(x = x,
>> y = rnorm(length(x))) %>%
>> as_tibble() -> tibDat
>> 
>> ggplot(dat = tibDat,
>> aes(x = x, y = y)) +
>> geom_point() +
>> xlim(c(1,6))
>> # x labels on plot are 2, 4 & 6
>> 
>> ggplot(dat = tibDat,
>> aes(x = x, y = y)) +
>> geom_point() +
>> expand_limits(x = c(1,6))
>> # same
>> 
>> ggplot(dat = tibDat,
>> aes(x = x, y = y)) +
>> geom_point() +
>> scale_x_continuous(breaks = 1:6, labels = 1:6)
>> # x labelled at 2:5 (why?!)
>> 
>> ggplot(dat = tibDat,
>> aes(x = x, y = y)) +
>> geom_point() +
>> xlim(c(1,6)) +
>> coord_cartesian(clip = "off")
>> # back to 2, 4, 6
>> 
>> ggplot(dat = tibDat,
>> aes(x = x, y = y)) +
>> geom_point() +
>> xlim(c(1,6)) +
>> coord_cartesian(expand = TRUE)
>> # same
>> 
>> ### OK, getting desperately hopeful
>> ggplot(dat = tibDat,
>> aes(x = x, y = y)) +
>> geom_point() +
>> xlim(c(0,6))
>> # x axis has 0, 2, 4 and 6 (surely inconsistent behaviour?)
>> 
>> ggplot(dat = tibDat,
>> aes(x = x, y = y)) +
>> geom_point() +
>> xlim(c(0.1,6))
>> # x axis has 0, 2, 4 and 6
>> 
>> Can anyone see the simple answer that is eluding me?!
>> 
>> TIA,
>> 
>> Chris
>> 

-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From phii m@iii@g oii phiiipsmith@c@  Mon Jan 11 16:42:10 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Mon, 11 Jan 2021 10:42:10 -0500
Subject: [R] Showing error distributions in a point plot
Message-ID: <bc6accc993575e77795912dbb43b94b0@philipsmith.ca>

I have a point plot where the estimated points have normally distributed 
errors and I want to plot not just the estimated points, but also an 
indication of the range of uncertainty in each case. The usual way of 
doing this, I believe, is with geom_pointrange, as shown in my reprex. 
However, this suggests to the eye that the errors are uniformly 
distributed when in fact they are normally distributed. I would prefer 
to show bell curves instead of straight lines. As far as I have been 
able to determine, there is no R package to help in doing this. I would 
appreciate suggestions as to how best to proceed.

Philip

# Reprex for error distributions
library(ggplot2)
df <- data.frame(x=1:10,y=rnorm(n=10))
ggplot(df)+
   geom_point(aes(x=x,y=y))+
   geom_hline(yintercept=0)+
   geom_pointrange(aes(x=x,y=y,ymin=y-sd(y),ymax=y+sd(y)))


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jan 11 17:05:01 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 11 Jan 2021 08:05:01 -0800
Subject: [R] Showing error distributions in a point plot
In-Reply-To: <bc6accc993575e77795912dbb43b94b0@philipsmith.ca>
References: <bc6accc993575e77795912dbb43b94b0@philipsmith.ca>
Message-ID: <CAGxFJbRcfLPxzngQwUA7RqfncY081duKm9otOQv3tkYoFSx4xg@mail.gmail.com>

Search for "violin plots"  at rseek.org.
There is a whole package devoted to them, many packages provide them, and
there is a geom_violin in ggplot2.

Don't know if this satisfies your aesthetic sensibilities, of course.
That's for you to decide.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 11, 2021 at 7:42 AM <phil at philipsmith.ca> wrote:

> I have a point plot where the estimated points have normally distributed
> errors and I want to plot not just the estimated points, but also an
> indication of the range of uncertainty in each case. The usual way of
> doing this, I believe, is with geom_pointrange, as shown in my reprex.
> However, this suggests to the eye that the errors are uniformly
> distributed when in fact they are normally distributed. I would prefer
> to show bell curves instead of straight lines. As far as I have been
> able to determine, there is no R package to help in doing this. I would
> appreciate suggestions as to how best to proceed.
>
> Philip
>
> # Reprex for error distributions
> library(ggplot2)
> df <- data.frame(x=1:10,y=rnorm(n=10))
> ggplot(df)+
>    geom_point(aes(x=x,y=y))+
>    geom_hline(yintercept=0)+
>    geom_pointrange(aes(x=x,y=y,ymin=y-sd(y),ymax=y+sd(y)))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @teph@ne@ch@mpe|y @end|ng |rom un|v-|yon1@|r  Mon Jan 11 12:45:01 2021
From: @teph@ne@ch@mpe|y @end|ng |rom un|v-|yon1@|r (CHAMPELY STEPHANE)
Date: Mon, 11 Jan 2021 11:45:01 +0000
Subject: [R] Troubles installing Rcmdr on Mac
Message-ID: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>

Dear colleagues,
I try to help my (french) student since five days to install Rcmd for mac and they have (ALL of them, and I use windows so I am not very skilled for that task) the same problem. When they load Rcmd, some supplementary tools (in order to use the command "otool") are missing according a message and trying to download them leads to a message indicated that it is not at the present moment available (since Thursday last week...)
So the menu of the Rcmdr are "white". Any idea where this technical problem come from ?
Thank you fr any help !

	[[alternative HTML version deleted]]


From e| @end|ng |rom ||@@e@n@  Mon Jan 11 19:55:26 2021
From: e| @end|ng |rom ||@@e@n@ (Dr Eberhard W Lisse)
Date: Mon, 11 Jan 2021 20:55:26 +0200
Subject: [R] Troubles installing Rcmdr on Mac
In-Reply-To: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>
References: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>
Message-ID: <782ff48b-0bee-475c-beae-0b61fd856e58@Spark>

Use RStudio.

But it can be that the command line tools are missing, which you (may) need to compile packages (from source).Ask one of them to open a terminal window and type the command ?make ?version? without the ??) if that results in an error they need to enter ?sudo xcode-select ?install? and then their password when asked.If that fixes the issue have all of them do that.

el

?
Sent from Dr Lisse?s iPhone
On 11 Jan 2021, 20:39 +0200, CHAMPELY STEPHANE <stephane.champely at univ-lyon1.fr>, wrote:
> Dear colleagues,
> I try to help my (french) student since five days to install Rcmd for mac and they have (ALL of them, and I use windows so I am not very skilled for that task) the same problem. When they load Rcmd, some supplementary tools (in order to use the command "otool") are missing according a message and trying to download them leads to a message indicated that it is not at the present moment available (since Thursday last week...)
> So the menu of the Rcmdr are "white". Any idea where this technical problem come from ?
> Thank you fr any help !
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From phii m@iii@g oii phiiipsmith@c@  Mon Jan 11 20:17:58 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Mon, 11 Jan 2021 14:17:58 -0500
Subject: [R] Showing error distributions in a point plot
In-Reply-To: <CAGxFJbRcfLPxzngQwUA7RqfncY081duKm9otOQv3tkYoFSx4xg@mail.gmail.com>
References: <bc6accc993575e77795912dbb43b94b0@philipsmith.ca>
 <CAGxFJbRcfLPxzngQwUA7RqfncY081duKm9otOQv3tkYoFSx4xg@mail.gmail.com>
Message-ID: <064456eac133a67f80b44aea9d6da8f6@philipsmith.ca>

Yes, geom_violin does the trick. Thanks for your fast and useful reply, 
Bert.

Philip

On 2021-01-11 11:05, Bert Gunter wrote:
> Search for "violin plots"  at rseek.org [1].
> There is a whole package devoted to them, many packages provide them,
> and there is a geom_violin in ggplot2.
> 
> Don't know if this satisfies your aesthetic sensibilities, of course.
> That's for you to decide.
> 
> Cheers,
> Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Jan 11, 2021 at 7:42 AM <phil at philipsmith.ca> wrote:
> 
>> I have a point plot where the estimated points have normally
>> distributed
>> errors and I want to plot not just the estimated points, but also an
>> 
>> indication of the range of uncertainty in each case. The usual way
>> of
>> doing this, I believe, is with geom_pointrange, as shown in my
>> reprex.
>> However, this suggests to the eye that the errors are uniformly
>> distributed when in fact they are normally distributed. I would
>> prefer
>> to show bell curves instead of straight lines. As far as I have been
>> 
>> able to determine, there is no R package to help in doing this. I
>> would
>> appreciate suggestions as to how best to proceed.
>> 
>> Philip
>> 
>> # Reprex for error distributions
>> library(ggplot2)
>> df <- data.frame(x=1:10,y=rnorm(n=10))
>> ggplot(df)+
>> geom_point(aes(x=x,y=y))+
>> geom_hline(yintercept=0)+
>> geom_pointrange(aes(x=x,y=y,ymin=y-sd(y),ymax=y+sd(y)))
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> Links:
> ------
> [1] http://rseek.org


From j|ox @end|ng |rom mcm@@ter@c@  Mon Jan 11 21:33:55 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 11 Jan 2021 15:33:55 -0500
Subject: [R] Troubles installing Rcmdr on Mac
In-Reply-To: <26234_1610391374_10BIuDxO006548_782ff48b-0bee-475c-beae-0b61fd856e58@Spark>
References: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>
 <26234_1610391374_10BIuDxO006548_782ff48b-0bee-475c-beae-0b61fd856e58@Spark>
Message-ID: <bae9220a-c1a7-8f61-8e68-a2b3a408b889@mcmaster.ca>

Dear Stephane and Eberhard,

It should not be necessary to install Xcode (which includes otools) to 
install and use the Rcmdr package on macOS because it shouldn't be 
necessary to install the CRAN packages required from source. I'm 
currently running the Rcmdr on two macOS 11.1 systems, with all CRAN 
packages up-to-date, and don't have any problems.

Stephane, have you and your students checked the Rcmdr installation 
notes (at 
<https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>) 
and followed the instructions there? If you have, and still experience 
this problem, it would help to have some more information about what 
they did to install the Rcmdr and what happened.

In the meantime, I'll try a fresh install of the Rcmdr and dependencies 
to see whether I encounter any difficulties.

Best,
  John

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-01-11 1:55 p.m., Dr Eberhard W Lisse wrote:
> Use RStudio.
> 
> But it can be that the command line tools are missing, which you (may) need to compile packages (from source).Ask one of them to open a terminal window and type the command ?make ?version? without the ??) if that results in an error they need to enter ?sudo xcode-select ?install? and then their password when asked.If that fixes the issue have all of them do that.
> 
> el
> 
> ?
> Sent from Dr Lisse?s iPhone
> On 11 Jan 2021, 20:39 +0200, CHAMPELY STEPHANE <stephane.champely at univ-lyon1.fr>, wrote:
>> Dear colleagues,
>> I try to help my (french) student since five days to install Rcmd for mac and they have (ALL of them, and I use windows so I am not very skilled for that task) the same problem. When they load Rcmd, some supplementary tools (in order to use the command "otool") are missing according a message and trying to download them leads to a message indicated that it is not at the present moment available (since Thursday last week...)
>> So the menu of the Rcmdr are "white". Any idea where this technical problem come from ?
>> Thank you fr any help !
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j|ox @end|ng |rom mcm@@ter@c@  Mon Jan 11 21:53:01 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 11 Jan 2021 15:53:01 -0500
Subject: [R] Troubles installing Rcmdr on Mac
In-Reply-To: <22066_1610397266_10BKYMMn008773_bae9220a-c1a7-8f61-8e68-a2b3a408b889@mcmaster.ca>
References: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>
 <26234_1610391374_10BIuDxO006548_782ff48b-0bee-475c-beae-0b61fd856e58@Spark>
 <22066_1610397266_10BKYMMn008773_bae9220a-c1a7-8f61-8e68-a2b3a408b889@mcmaster.ca>
Message-ID: <b786e2aa-176b-34cf-5fc7-49f1d3c76f52@mcmaster.ca>

Dear Stephane and Eberhard,

As an addendum to my previous response, I uninstalled the Rcmdr package 
and all of its direct and indirect dependencies and then reinstalled the 
package -- on a macOS 11.1 system running R 4.0.3 with all other 
packages up-to-date.

I then reinstalled the Rcmdr and dependencies via the command 
install.packages("Rcmdr"), and responded "no" when asked whether to 
install some packages from source (perhaps this is the explanation for 
the problem, if your students responded "yes" without having Xcode 
installed).

Following these steps, everything (still) works fine. I therefore can't 
duplicate your students' problem, which makes it hard to suggest how to 
fix it, without having some additional details.

Best,
  John


On 2021-01-11 3:33 p.m., John Fox wrote:
> Dear Stephane and Eberhard,
> 
> It should not be necessary to install Xcode (which includes otools) to 
> install and use the Rcmdr package on macOS because it shouldn't be 
> necessary to install the CRAN packages required from source. I'm 
> currently running the Rcmdr on two macOS 11.1 systems, with all CRAN 
> packages up-to-date, and don't have any problems.
> 
> Stephane, have you and your students checked the Rcmdr installation 
> notes (at 
> <https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>) 
> and followed the instructions there? If you have, and still experience 
> this problem, it would help to have some more information about what 
> they did to install the Rcmdr and what happened.
> 
> In the meantime, I'll try a fresh install of the Rcmdr and dependencies 
> to see whether I encounter any difficulties.
> 
> Best,
>  ?John
>


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jan 12 03:30:46 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 11 Jan 2021 21:30:46 -0500
Subject: [R] Troubles installing Rcmdr on Mac
In-Reply-To: <24874_1610398402_10BKrLx4005352_b786e2aa-176b-34cf-5fc7-49f1d3c76f52@mcmaster.ca>
References: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>
 <26234_1610391374_10BIuDxO006548_782ff48b-0bee-475c-beae-0b61fd856e58@Spark>
 <22066_1610397266_10BKYMMn008773_bae9220a-c1a7-8f61-8e68-a2b3a408b889@mcmaster.ca>
 <24874_1610398402_10BKrLx4005352_b786e2aa-176b-34cf-5fc7-49f1d3c76f52@mcmaster.ca>
Message-ID: <910accaa-52a3-3a42-ce20-110f0271e0a4@mcmaster.ca>

Dear Stephane,

I've taken yet another look at this and have an additional suggestion 
for your students to try:

	install.packages("Rcmdr", type="mac.binary")

That should avoid any attempt to install Rcmdr package dependencies from 
source.

I hope this helps,
  John

On 2021-01-11 3:53 p.m., John Fox wrote:
> Dear Stephane and Eberhard,
> 
> As an addendum to my previous response, I uninstalled the Rcmdr package 
> and all of its direct and indirect dependencies and then reinstalled the 
> package -- on a macOS 11.1 system running R 4.0.3 with all other 
> packages up-to-date.
> 
> I then reinstalled the Rcmdr and dependencies via the command 
> install.packages("Rcmdr"), and responded "no" when asked whether to 
> install some packages from source (perhaps this is the explanation for 
> the problem, if your students responded "yes" without having Xcode 
> installed).
> 
> Following these steps, everything (still) works fine. I therefore can't 
> duplicate your students' problem, which makes it hard to suggest how to 
> fix it, without having some additional details.
> 
> Best,
>  ?John
> 
> 
> On 2021-01-11 3:33 p.m., John Fox wrote:
>> Dear Stephane and Eberhard,
>>
>> It should not be necessary to install Xcode (which includes otools) to 
>> install and use the Rcmdr package on macOS because it shouldn't be 
>> necessary to install the CRAN packages required from source. I'm 
>> currently running the Rcmdr on two macOS 11.1 systems, with all CRAN 
>> packages up-to-date, and don't have any problems.
>>
>> Stephane, have you and your students checked the Rcmdr installation 
>> notes (at 
>> <https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>) 
>> and followed the instructions there? If you have, and still experience 
>> this problem, it would help to have some more information about what 
>> they did to install the Rcmdr and what happened.
>>
>> In the meantime, I'll try a fresh install of the Rcmdr and 
>> dependencies to see whether I encounter any difficulties.
>>
>> Best,
>> ??John
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e| @end|ng |rom ||@@e@n@  Tue Jan 12 06:32:49 2021
From: e| @end|ng |rom ||@@e@n@ (Dr Eberhard W Lisse)
Date: Tue, 12 Jan 2021 07:32:49 +0200
Subject: [R] Troubles installing Rcmdr on Mac
In-Reply-To: <910accaa-52a3-3a42-ce20-110f0271e0a4@mcmaster.ca>
References: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>
 <26234_1610391374_10BIuDxO006548_782ff48b-0bee-475c-beae-0b61fd856e58@Spark>
 <22066_1610397266_10BKYMMn008773_bae9220a-c1a7-8f61-8e68-a2b3a408b889@mcmaster.ca>
 <24874_1610398402_10BKrLx4005352_b786e2aa-176b-34cf-5fc7-49f1d3c76f52@mcmaster.ca>
 <910accaa-52a3-3a42-ce20-110f0271e0a4@mcmaster.ca>
Message-ID: <c491e829-877c-48e2-b003-a1505a5f362a@Spark>

John,

what is wrong with installing Xcode?s command lime tools (not Xcode itself)?


?
Sent from Dr Lisse?s iPhone
On 12 Jan 2021, 04:30 +0200, John Fox <jfox at mcmaster.ca>, wrote:
> Dear Stephane,
>
> I've taken yet another look at this and have an additional suggestion
> for your students to try:
>
> install.packages("Rcmdr", type="mac.binary")
>
> That should avoid any attempt to install Rcmdr package dependencies from
> source.
>
> I hope this helps,
> John
>
> On 2021-01-11 3:53 p.m., John Fox wrote:
> > Dear Stephane and Eberhard,
> >
> > As an addendum to my previous response, I uninstalled the Rcmdr package
> > and all of its direct and indirect dependencies and then reinstalled the
> > package -- on a macOS 11.1 system running R 4.0.3 with all other
> > packages up-to-date.
> >
> > I then reinstalled the Rcmdr and dependencies via the command
> > install.packages("Rcmdr"), and responded "no" when asked whether to
> > install some packages from source (perhaps this is the explanation for
> > the problem, if your students responded "yes" without having Xcode
> > installed).
> >
> > Following these steps, everything (still) works fine. I therefore can't
> > duplicate your students' problem, which makes it hard to suggest how to
> > fix it, without having some additional details.
> >
> > Best,
> > ?John
> >
> >
> > On 2021-01-11 3:33 p.m., John Fox wrote:
> > > Dear Stephane and Eberhard,
> > >
> > > It should not be necessary to install Xcode (which includes otools) to
> > > install and use the Rcmdr package on macOS because it shouldn't be
> > > necessary to install the CRAN packages required from source. I'm
> > > currently running the Rcmdr on two macOS 11.1 systems, with all CRAN
> > > packages up-to-date, and don't have any problems.
> > >
> > > Stephane, have you and your students checked the Rcmdr installation
> > > notes (at
> > > <https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>)
> > > and followed the instructions there? If you have, and still experience
> > > this problem, it would help to have some more information about what
> > > they did to install the Rcmdr and what happened.
> > >
> > > In the meantime, I'll try a fresh install of the Rcmdr and
> > > dependencies to see whether I encounter any difficulties.
> > >
> > > Best,
> > > ??John
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Tue Jan 12 09:13:34 2021
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Tue, 12 Jan 2021 09:13:34 +0100
Subject: [R] roxygen2 & markdown & math
Message-ID: <8b2b6987-02aa-e128-e978-a440dd77c75b@wiwi.hu-berlin.de>

Hi,

I like to make my package documentation with markdown which is supported 
since roxygen2 6.0.0 . I used a math expression like $t_n \appox N(0,1)$ 
which leads in the package check to "unknown macro '\approx'".

I guess I get the warning because math is not supported in markdown. Are 
there any plans to support something like $...$ or $$...$$? Or there are 
general problems?

Best Sigbert

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat
https://hu.berlin/mmstat-int
https://hu.berlin/mmstat-ar


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Jan 12 10:41:59 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Tue, 12 Jan 2021 09:41:59 +0000
Subject: [R] roxygen2 & markdown & math
In-Reply-To: <8b2b6987-02aa-e128-e978-a440dd77c75b@wiwi.hu-berlin.de>
References: <8b2b6987-02aa-e128-e978-a440dd77c75b@wiwi.hu-berlin.de>
Message-ID: <80bfb24e8f944cafa01c18f81b809bc9@UM-MAIL3214.unimaas.nl>

Dear Sigbert,

The mathjaxr package provides this:

https://cran.r-project.org/package=mathjaxr
https://github.com/wviechtb/mathjaxr

Best,
Wolfgang

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sigbert
>Klinke
>Sent: Tuesday, 12 January, 2021 9:14
>To: r-help at r-project.org
>Subject: [R] roxygen2 & markdown & math
>
>Hi,
>
>I like to make my package documentation with markdown which is supported
>since roxygen2 6.0.0 . I used a math expression like $t_n \appox N(0,1)$
>which leads in the package check to "unknown macro '\approx'".
>
>I guess I get the warning because math is not supported in markdown. Are
>there any plans to support something like $...$ or $$...$$? Or there are
>general problems?
>
>Best Sigbert
>
>--
>https://hu.berlin/sk
>https://hu.berlin/mmstat
>https://hu.berlin/mmstat-int
>https://hu.berlin/mmstat-ar


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Jan  8 16:20:25 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 8 Jan 2021 16:20:25 +0100
Subject: [R] 
 Secondary y axis in ggplot2: did not respond when change its
 y-axis value
In-Reply-To: <CAMwU6B3NtSDnBQ+1cZZDqZ_t18u0faW3jyEmY2YUwqPnaODLgA@mail.gmail.com>
References: <CAMwU6B3NtSDnBQ+1cZZDqZ_t18u0faW3jyEmY2YUwqPnaODLgA@mail.gmail.com>
Message-ID: <CAJuCY5yj8Sr5s1uQ=b3znkWHRL8ATzGuyzkoweJrvkG2bcAb7g-349@mail.gmail.com>

The second y-axis in ggplot2 is only intended to relabel an axis with a
fixed transformation. E.g. one axis in degree Celcius and one in Kelvin,
km and miles, ...
It does not rescale the variables.

It looks like you want to display two variables with unrelated units on the
same y-axis. That is not a good idea. https://blog.datawrapper.de/dualaxis/

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 8 jan. 2021 om 02:02 schreef Marna Wagley <marna.wagley at gmail.com>:

> Hi R users,
> I was trying to plot a graph with a secondary axis, and used the following
> code for the data but the secondary line and secondary y -axis value did
> not match. I would like to show both lines in one graph.
>
> Any suggestions?
>
> library(ggplot2)
> library(reshape2)
> daT<-structure(list(x = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 1L, 2L,
> 3L, 4L, 5L, 6L, 7L, 8L), y1 = c(9754L, 1051L, 5833L, 5769L, 2479L,
> 470L, 5828L, 174L, 2045L, 6099L, 8780L, 8732L, 4053L, 9419L,
> 4728L, 3587L), y2 = c(0.51, 0.61, 0.3, 0.81, 0.89, 0, 1.9, 0.76,
> 0.87, 0.29, 0, 0.42, 0.73, 0.96, 0.62, 0.06), group = c("A",
> "A", "A", "A", "A", "A", "A", "A", "B", "B", "B", "B", "B", "B",
> "B", "B")), class = "data.frame", row.names = c(NA, -16L))
> print(daT)
> daT1<-melt(daT, id.vars=c("x", "group"))
> daT1%>%
>   ggplot() +
>   geom_line(aes(x = x, y = value, group = variable, color = variable)) +
>   facet_wrap(~group) +
>   scale_y_continuous(sec.axis = sec_axis(~ .*0.0001))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jan 12 15:19:39 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 12 Jan 2021 09:19:39 -0500
Subject: [R] Troubles installing Rcmdr on Mac
In-Reply-To: <19096_1610429608_10C5XRdw010761_c491e829-877c-48e2-b003-a1505a5f362a@Spark>
References: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>
 <26234_1610391374_10BIuDxO006548_782ff48b-0bee-475c-beae-0b61fd856e58@Spark>
 <22066_1610397266_10BKYMMn008773_bae9220a-c1a7-8f61-8e68-a2b3a408b889@mcmaster.ca>
 <24874_1610398402_10BKrLx4005352_b786e2aa-176b-34cf-5fc7-49f1d3c76f52@mcmaster.ca>
 <910accaa-52a3-3a42-ce20-110f0271e0a4@mcmaster.ca>
 <19096_1610429608_10C5XRdw010761_c491e829-877c-48e2-b003-a1505a5f362a@Spark>
Message-ID: <73075cc1-1bdc-93d1-3e6b-2e4eaedeb85b@mcmaster.ca>

Dear Eberhard,

On 2021-01-12 12:32 a.m., Dr Eberhard W Lisse wrote:
> John,
> 
> what is wrong with installing Xcode?s command lime tools (not Xcode itself)?

Nothing, and I did miss the distinction, but it shouldn't be necessary, 
and the instructions for installing the Rcmdr are already more 
complicated on macOS than on other platforms because of the necessity to 
install XQuartz. Users should be able to install the Rcmdr package on 
macOS without having to install packages from source.

Remember that Rcmdr users are typically students in basic statistics 
courses, many of whom have limited software sophistication. 
Unnecessarily complicating the installation is undesirable. Of course, 
if it's necessary to complicate the installation, one has to live with that.

I'll be interested to learn whether my suggestions solve the problem. If 
not, I can add an instruction concerning the Xcode tools to the Rcmdr 
installation notes for macOS.

Thanks for your help,
  John

> 
> 
> ?
> Sent from Dr Lisse?s iPhone
> On 12 Jan 2021, 04:30 +0200, John Fox <jfox at mcmaster.ca>, wrote:
>> Dear Stephane,
>>
>> I've taken yet another look at this and have an additional suggestion
>> for your students to try:
>>
>> install.packages("Rcmdr", type="mac.binary")
>>
>> That should avoid any attempt to install Rcmdr package dependencies from
>> source.
>>
>> I hope this helps,
>> John
>>
>> On 2021-01-11 3:53 p.m., John Fox wrote:
>>> Dear Stephane and Eberhard,
>>>
>>> As an addendum to my previous response, I uninstalled the Rcmdr package
>>> and all of its direct and indirect dependencies and then reinstalled the
>>> package -- on a macOS 11.1 system running R 4.0.3 with all other
>>> packages up-to-date.
>>>
>>> I then reinstalled the Rcmdr and dependencies via the command
>>> install.packages("Rcmdr"), and responded "no" when asked whether to
>>> install some packages from source (perhaps this is the explanation for
>>> the problem, if your students responded "yes" without having Xcode
>>> installed).
>>>
>>> Following these steps, everything (still) works fine. I therefore can't
>>> duplicate your students' problem, which makes it hard to suggest how to
>>> fix it, without having some additional details.
>>>
>>> Best,
>>>  ?John
>>>
>>>
>>> On 2021-01-11 3:33 p.m., John Fox wrote:
>>>> Dear Stephane and Eberhard,
>>>>
>>>> It should not be necessary to install Xcode (which includes otools) to
>>>> install and use the Rcmdr package on macOS because it shouldn't be
>>>> necessary to install the CRAN packages required from source. I'm
>>>> currently running the Rcmdr on two macOS 11.1 systems, with all CRAN
>>>> packages up-to-date, and don't have any problems.
>>>>
>>>> Stephane, have you and your students checked the Rcmdr installation
>>>> notes (at
>>>> <https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>)
>>>> and followed the instructions there? If you have, and still experience
>>>> this problem, it would help to have some more information about what
>>>> they did to install the Rcmdr and what happened.
>>>>
>>>> In the meantime, I'll try a fresh install of the Rcmdr and
>>>> dependencies to see whether I encounter any difficulties.
>>>>
>>>> Best,
>>>>  ??John
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jan 12 15:27:43 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 12 Jan 2021 09:27:43 -0500
Subject: [R] Troubles installing Rcmdr on Mac
In-Reply-To: <1610434110562.11118@univ-lyon1.fr>
References: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>
 <26234_1610391374_10BIuDxO006548_782ff48b-0bee-475c-beae-0b61fd856e58@Spark>
 <22066_1610397266_10BKYMMn008773_bae9220a-c1a7-8f61-8e68-a2b3a408b889@mcmaster.ca>
 <24874_1610398402_10BKrLx4005352_b786e2aa-176b-34cf-5fc7-49f1d3c76f52@mcmaster.ca>
 <910accaa-52a3-3a42-ce20-110f0271e0a4@mcmaster.ca>
 <1610434110562.11118@univ-lyon1.fr>
Message-ID: <34dd3765-0c1f-5b90-693f-a9abc171ca67@mcmaster.ca>

Dear Stephane,

On 2021-01-12 1:48 a.m., CHAMPELY STEPHANE wrote:
> Dear John,
> thank you for these responses, we will try this... today. We carefully read the installation notes, but it is sometimes difficult to really check what was done by the students because in France, our lessons are online lessons (covid-19...)

Yes, the pandemic has made teaching very difficult. As a general matter, 
it's been my experience that almost all Rcmdr installation problems are 
on macOS. It's usually easy to help students get going in person, much 
less so remotely.

Please let me know whether your students solve their problems, and if 
so, how, so that I can update the Rcmdr installation notes, if necessary.

Also please keep the conversation on r-help so that others are able to 
follow it.

Best,
  John

> All the best,
> St?phane CHAMPELY
> Ma?tre de conf?rences
> UFR STAPS , Laboratoire L-ViS, Universit? Lyon 1
> 
> 
> ________________________________________
> De : John Fox <jfox at mcmaster.ca>
> Envoy? : mardi 12 janvier 2021 03:30
> ? : CHAMPELY STEPHANE
> Cc : r-help at r-project.org; Dr Eberhard W Lisse
> Objet : Re: [R] Troubles installing Rcmdr on Mac
> 
> Dear Stephane,
> 
> I've taken yet another look at this and have an additional suggestion
> for your students to try:
> 
>          install.packages("Rcmdr", type="mac.binary")
> 
> That should avoid any attempt to install Rcmdr package dependencies from
> source.
> 
> I hope this helps,
>    John
> 
> On 2021-01-11 3:53 p.m., John Fox wrote:
>> Dear Stephane and Eberhard,
>>
>> As an addendum to my previous response, I uninstalled the Rcmdr package
>> and all of its direct and indirect dependencies and then reinstalled the
>> package -- on a macOS 11.1 system running R 4.0.3 with all other
>> packages up-to-date.
>>
>> I then reinstalled the Rcmdr and dependencies via the command
>> install.packages("Rcmdr"), and responded "no" when asked whether to
>> install some packages from source (perhaps this is the explanation for
>> the problem, if your students responded "yes" without having Xcode
>> installed).
>>
>> Following these steps, everything (still) works fine. I therefore can't
>> duplicate your students' problem, which makes it hard to suggest how to
>> fix it, without having some additional details.
>>
>> Best,
>>    John
>>
>>
>> On 2021-01-11 3:33 p.m., John Fox wrote:
>>> Dear Stephane and Eberhard,
>>>
>>> It should not be necessary to install Xcode (which includes otools) to
>>> install and use the Rcmdr package on macOS because it shouldn't be
>>> necessary to install the CRAN packages required from source. I'm
>>> currently running the Rcmdr on two macOS 11.1 systems, with all CRAN
>>> packages up-to-date, and don't have any problems.
>>>
>>> Stephane, have you and your students checked the Rcmdr installation
>>> notes (at
>>> <https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>)
>>> and followed the instructions there? If you have, and still experience
>>> this problem, it would help to have some more information about what
>>> they did to install the Rcmdr and what happened.
>>>
>>> In the meantime, I'll try a fresh install of the Rcmdr and
>>> dependencies to see whether I encounter any difficulties.
>>>
>>> Best,
>>>    John
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From e| @end|ng |rom ||@@e@NA  Tue Jan 12 15:41:11 2021
From: e| @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Tue, 12 Jan 2021 16:41:11 +0200
Subject: [R] Troubles installing Rcmdr on Mac
In-Reply-To: <73075cc1-1bdc-93d1-3e6b-2e4eaedeb85b@mcmaster.ca>
References: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>
 <26234_1610391374_10BIuDxO006548_782ff48b-0bee-475c-beae-0b61fd856e58@Spark>
 <22066_1610397266_10BKYMMn008773_bae9220a-c1a7-8f61-8e68-a2b3a408b889@mcmaster.ca>
 <24874_1610398402_10BKrLx4005352_b786e2aa-176b-34cf-5fc7-49f1d3c76f52@mcmaster.ca>
 <910accaa-52a3-3a42-ce20-110f0271e0a4@mcmaster.ca>
 <19096_1610429608_10C5XRdw010761_c491e829-877c-48e2-b003-a1505a5f362a@Spark>
 <73075cc1-1bdc-93d1-3e6b-2e4eaedeb85b@mcmaster.ca>
Message-ID: <82ecb1a1-afb9-70dd-874b-f47660b7be1e@lisse.NA>

John,

maybe I misunderestimate the students :-)-O but there is not much
sophistication required to follow simple instructions while thinking
about what one is doing when doing so.  At least that was my generation
of students did.

If they can install XQuartz, they can install the command line tools.

And, it's not about RCmdr but about the source packages that you may
want to have to install for which the command line tools are required.

Finally, RStudio is so much easier and more powerful, that I wonder why 
one is bothering with this including XQuartz.

greetings, el

On 12/01/2021 16:19, John Fox wrote:
> Dear Eberhard,
> 
> On 2021-01-12 12:32 a.m., Dr Eberhard W Lisse wrote:
>> John,
>>
>> what is wrong with installing Xcode?s command lime tools (not Xcode
>> itself)?
> 
> Nothing, and I did miss the distinction, but it shouldn't be
> necessary, and the instructions for installing the Rcmdr are already
> more complicated on macOS than on other platforms because of the
> necessity to install XQuartz.  Users should be able to install the
> Rcmdr package on macOS without having to install packages from source.
> 
> Remember that Rcmdr users are typically students in basic statistics
> courses, many of whom have limited software sophistication.
> Unnecessarily complicating the installation is undesirable.  Of
> course, if it's necessary to complicate the installation, one has to
> live with that.
> 
> I'll be interested to learn whether my suggestions solve the problem.
> If not, I can add an instruction concerning the Xcode tools to the
> Rcmdr installation notes for macOS.
> 
> Thanks for your help,
>  John
[...]

-- 
Dr. Eberhard W. Lisse   \         /       Obstetrician & Gynaecologist 
el at lisse.NA             / *      |  Telephone: +264 81 124 6733 (cell)
PO Box 8421 Bachbrecht  \      /  If this email is signed with GPG/PGP
10007, Namibia           ;____/ Sect 20 of Act No. 4 of 2019 may apply


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jan 12 16:43:26 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 12 Jan 2021 10:43:26 -0500
Subject: [R] Troubles installing Rcmdr on Mac
In-Reply-To: <22320_1610462500_10CEfd0S003609_82ecb1a1-afb9-70dd-874b-f47660b7be1e@lisse.NA>
References: <aabd9c0723724ba5b0bb8b8cd007e102@BPMBX2013-02.univ-lyon1.fr>
 <26234_1610391374_10BIuDxO006548_782ff48b-0bee-475c-beae-0b61fd856e58@Spark>
 <22066_1610397266_10BKYMMn008773_bae9220a-c1a7-8f61-8e68-a2b3a408b889@mcmaster.ca>
 <24874_1610398402_10BKrLx4005352_b786e2aa-176b-34cf-5fc7-49f1d3c76f52@mcmaster.ca>
 <910accaa-52a3-3a42-ce20-110f0271e0a4@mcmaster.ca>
 <19096_1610429608_10C5XRdw010761_c491e829-877c-48e2-b003-a1505a5f362a@Spark>
 <73075cc1-1bdc-93d1-3e6b-2e4eaedeb85b@mcmaster.ca>
 <22320_1610462500_10CEfd0S003609_82ecb1a1-afb9-70dd-874b-f47660b7be1e@lisse.NA>
Message-ID: <e6c64297-05d2-d064-4c67-acddeba0c14e@mcmaster.ca>

Dear Eberhard,

On 2021-01-12 9:41 a.m., Dr Eberhard W Lisse wrote:
> John,
> 
> maybe I misunderestimate the students :-)-O but there is not much
> sophistication required to follow simple instructions while thinking
> about what one is doing when doing so.  At least that was my generation
> of students did.
> 
> If they can install XQuartz, they can install the command line tools.

In my experience, mostly with social-science undergraduates and 
graduate students, the more steps an installation requires, the more 
likely students will encounter difficulties. Your students may well have 
a different level of computer sophistication than mine did, but I know 
that my experience isn't unique.

> 
> And, it's not about RCmdr but about the source packages that you may
> want to have to install for which the command line tools are required.

Right. But all of the packages on which the Rcmdr package depends have 
Mac binaries. As I confirmed yesterday, one can install the Rcmdr and 
its dependencies on macOS without building any packages from source.

> 
> Finally, RStudio is so much easier and more powerful, that I wonder why
> one is bothering with this including XQuartz.

Because I think you underestimate the obstacle that working at the 
command line presents to students who often are already struggling to 
learn basic statistical concepts. In my, and others', experience, it's 
easier for students at this level to work with a statistical GUI than to 
write commands. While working n RStudio or another IDE is undoubtedly 
more powerful, for them it certainly isn't easier. Your teaching 
experiences may be different.

Best,
  John


> 
> greetings, el 
> 
> On 12/01/2021 16:19, John Fox wrote:
>> Dear Eberhard,
>>
>> On 2021-01-12 12:32 a.m., Dr Eberhard W Lisse wrote:
>>> John,
>>>
>>> what is wrong with installing Xcode?s command lime tools (not Xcode
>>> itself)?
>>
>> Nothing, and I did miss the distinction, but it shouldn't be
>> necessary, and the instructions for installing the Rcmdr are already
>> more complicated on macOS than on other platforms because of the
>> necessity to install XQuartz.  Users should be able to install the
>> Rcmdr package on macOS without having to install packages from source.
>>
>> Remember that Rcmdr users are typically students in basic statistics
>> courses, many of whom have limited software sophistication.
>> Unnecessarily complicating the installation is undesirable.  Of
>> course, if it's necessary to complicate the installation, one has to
>> live with that.
>>
>> I'll be interested to learn whether my suggestions solve the problem.
>> If not, I can add an instruction concerning the Xcode tools to the
>> Rcmdr installation notes for macOS.
>>
>> Thanks for your help,
>>   John
> [...]
>


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Tue Jan 12 19:12:51 2021
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Tue, 12 Jan 2021 19:12:51 +0100
Subject: [R] roxygen2 & markdown & math
In-Reply-To: <80bfb24e8f944cafa01c18f81b809bc9@UM-MAIL3214.unimaas.nl>
References: <8b2b6987-02aa-e128-e978-a440dd77c75b@wiwi.hu-berlin.de>
 <80bfb24e8f944cafa01c18f81b809bc9@UM-MAIL3214.unimaas.nl>
Message-ID: <4ab1b9f6-7b5c-185b-be3c-67bd9c5f6d02@wiwi.hu-berlin.de>

Hi,

thanks a lot, but maybe I was to vague.

I do not want to replace \eqn{...} and \deqn{...} by \mjseqn{...} and 
\mjsdeqn{...}. I would like to use $...$ and $$...$$ as in Rmarkdown to 
get something better readable.

Best Sigbert

Am 12.01.21 um 10:41 schrieb Viechtbauer, Wolfgang (SP):
> Dear Sigbert,
> 
> The mathjaxr package provides this:
> 
> https://cran.r-project.org/package=mathjaxr
> https://github.com/wviechtb/mathjaxr
> 
> Best,
> Wolfgang
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sigbert
>> Klinke
>> Sent: Tuesday, 12 January, 2021 9:14
>> To: r-help at r-project.org
>> Subject: [R] roxygen2 & markdown & math
>>
>> Hi,
>>
>> I like to make my package documentation with markdown which is supported
>> since roxygen2 6.0.0 . I used a math expression like $t_n \appox N(0,1)$
>> which leads in the package check to "unknown macro '\approx'".
>>
>> I guess I get the warning because math is not supported in markdown. Are
>> there any plans to support something like $...$ or $$...$$? Or there are
>> general problems?
>>
>> Best Sigbert
>>
>> --
>> https://hu.berlin/sk
>> https://hu.berlin/mmstat
>> https://hu.berlin/mmstat-int
>> https://hu.berlin/mmstat-ar


-- 
https://hu.berlin/sk
https://hu.berlin/mmstat
https://hu.berlin/mmstat-int
https://hu.berlin/mmstat-ar


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 12 19:55:48 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 12 Jan 2021 10:55:48 -0800
Subject: [R] roxygen2 & markdown & math
In-Reply-To: <4ab1b9f6-7b5c-185b-be3c-67bd9c5f6d02@wiwi.hu-berlin.de>
References: <8b2b6987-02aa-e128-e978-a440dd77c75b@wiwi.hu-berlin.de>
 <80bfb24e8f944cafa01c18f81b809bc9@UM-MAIL3214.unimaas.nl>
 <4ab1b9f6-7b5c-185b-be3c-67bd9c5f6d02@wiwi.hu-berlin.de>
Message-ID: <E5029969-1850-4B2E-A42B-4D7A05D18640@dcn.davis.ca.us>

a) This discussion is on the wrong mailing list. Please go to R-package-devel if you want to continue this discussion.

b) You can do whatever you want in your vignettes, but R doc files are designed to work with multiple output devices, including text-only terminals, so syntax specific to certain environments is not allowed. If you want to contribute improvements to R doc capabilities, I am sure patches will be considered as long as you adhere to the existing multi-platform constraints.

On January 12, 2021 10:12:51 AM PST, Sigbert Klinke <sigbert at wiwi.hu-berlin.de> wrote:
>Hi,
>
>thanks a lot, but maybe I was to vague.
>
>I do not want to replace \eqn{...} and \deqn{...} by \mjseqn{...} and 
>\mjsdeqn{...}. I would like to use $...$ and $$...$$ as in Rmarkdown to
>
>get something better readable.
>
>Best Sigbert
>
>Am 12.01.21 um 10:41 schrieb Viechtbauer, Wolfgang (SP):
>> Dear Sigbert,
>> 
>> The mathjaxr package provides this:
>> 
>> https://cran.r-project.org/package=mathjaxr
>> https://github.com/wviechtb/mathjaxr
>> 
>> Best,
>> Wolfgang
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>Sigbert
>>> Klinke
>>> Sent: Tuesday, 12 January, 2021 9:14
>>> To: r-help at r-project.org
>>> Subject: [R] roxygen2 & markdown & math
>>>
>>> Hi,
>>>
>>> I like to make my package documentation with markdown which is
>supported
>>> since roxygen2 6.0.0 . I used a math expression like $t_n \appox
>N(0,1)$
>>> which leads in the package check to "unknown macro '\approx'".
>>>
>>> I guess I get the warning because math is not supported in markdown.
>Are
>>> there any plans to support something like $...$ or $$...$$? Or there
>are
>>> general problems?
>>>
>>> Best Sigbert
>>>
>>> --
>>> https://hu.berlin/sk
>>> https://hu.berlin/mmstat
>>> https://hu.berlin/mmstat-int
>>> https://hu.berlin/mmstat-ar

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Jan 12 20:32:26 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 12 Jan 2021 14:32:26 -0500
Subject: [R] roxygen2 & markdown & math
In-Reply-To: <4ab1b9f6-7b5c-185b-be3c-67bd9c5f6d02@wiwi.hu-berlin.de>
References: <8b2b6987-02aa-e128-e978-a440dd77c75b@wiwi.hu-berlin.de>
 <80bfb24e8f944cafa01c18f81b809bc9@UM-MAIL3214.unimaas.nl>
 <4ab1b9f6-7b5c-185b-be3c-67bd9c5f6d02@wiwi.hu-berlin.de>
Message-ID: <6578f8c5-4f67-ded9-0462-cef2987b6adc@gmail.com>

On 12/01/2021 1:12 p.m., Sigbert Klinke wrote:
> Hi,
> 
> thanks a lot, but maybe I was to vague.
> 
> I do not want to replace \eqn{...} and \deqn{...} by \mjseqn{...} and
> \mjsdeqn{...}. I would like to use $...$ and $$...$$ as in Rmarkdown to
> get something better readable.

I think that's a question/suggestion that would have to go to the 
roxygen2 team.  They're the ones who convert Markdown into the Rd input 
format.  Presumably they could convert $...$ into the appropriate macro 
using Mathjax or not, but I have no idea how difficult that would be.

Duncan Murdoch

> 
> Best Sigbert
> 
> Am 12.01.21 um 10:41 schrieb Viechtbauer, Wolfgang (SP):
>> Dear Sigbert,
>>
>> The mathjaxr package provides this:
>>
>> https://cran.r-project.org/package=mathjaxr
>> https://github.com/wviechtb/mathjaxr
>>
>> Best,
>> Wolfgang
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sigbert
>>> Klinke
>>> Sent: Tuesday, 12 January, 2021 9:14
>>> To: r-help at r-project.org
>>> Subject: [R] roxygen2 & markdown & math
>>>
>>> Hi,
>>>
>>> I like to make my package documentation with markdown which is supported
>>> since roxygen2 6.0.0 . I used a math expression like $t_n \appox N(0,1)$
>>> which leads in the package check to "unknown macro '\approx'".
>>>
>>> I guess I get the warning because math is not supported in markdown. Are
>>> there any plans to support something like $...$ or $$...$$? Or there are
>>> general problems?
>>>
>>> Best Sigbert
>>>
>>> --
>>> https://hu.berlin/sk
>>> https://hu.berlin/mmstat
>>> https://hu.berlin/mmstat-int
>>> https://hu.berlin/mmstat-ar
> 
>


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Jan 12 20:43:52 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 12 Jan 2021 19:43:52 +0000 (UTC)
Subject: [R] package not available for R version...
References: <707556763.2294517.1610480632725.ref@mail.yahoo.com>
Message-ID: <707556763.2294517.1610480632725@mail.yahoo.com>

Dear R-experts,

I have tried to reach the maintainer of the rgam package. Until now, no response. 
Since I'm in a bit of a hurry, I try to reach you because as I try to install the rgam package using the command :

install.packages("rgam")

I get this warning message :

Warning message:

package ?rgam? is not available (for R version 3.6.3)

The strange thing is that rgam depends R (>= 3.0.2) , stats

How can I solve this problem ?

Best,


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Jan 12 21:08:07 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 12 Jan 2021 15:08:07 -0500
Subject: [R] package not available for R version...
In-Reply-To: <707556763.2294517.1610480632725@mail.yahoo.com>
References: <707556763.2294517.1610480632725.ref@mail.yahoo.com>
 <707556763.2294517.1610480632725@mail.yahoo.com>
Message-ID: <3c26a82c-1fd5-b94c-6544-4938bf930a89@gmail.com>

On 12/01/2021 2:43 p.m., varin sacha via R-help wrote:
> Dear R-experts,
> 
> I have tried to reach the maintainer of the rgam package. Until now, no response.
> Since I'm in a bit of a hurry, I try to reach you because as I try to install the rgam package using the command :
> 
> install.packages("rgam")
> 
> I get this warning message :
> 
> Warning message:
> 
> package ?rgam? is not available (for R version 3.6.3)
> 
> The strange thing is that rgam depends R (>= 3.0.2) , stats
> 
> How can I solve this problem ?

That package is no longer listed on CRAN.  You can find some versions of 
it in https://cran.r-project.org/src/contrib/Archive, the most recent 
being from 2018.  I'd guess it doesn't pass all checks, so it was removed.

You could download the last version, and see if you can get it to work. 
  If you are really ambitious, you might be able to take it over as 
maintainer.

Or it might be easier to find a different package to do what you want to do.

Duncan Murdoch


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jan 13 07:24:34 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 13 Jan 2021 19:24:34 +1300
Subject: [R] package not available for R version...
In-Reply-To: <707556763.2294517.1610480632725@mail.yahoo.com>
References: <707556763.2294517.1610480632725.ref@mail.yahoo.com>
 <707556763.2294517.1610480632725@mail.yahoo.com>
Message-ID: <CAB8pepy=2JNSc29sEUfTxH6Dqe46pbEM3MZ5LmxuqZ0U3OTvkA@mail.gmail.com>

It's not clear from your post why you're trying to contact the maintainer.
But it gives the impression you're trying to contact the maintainer,
of an archived package, because you can't install the package.
It's not their responsibility to respond to these kinds of questions.

Also, I note the most obvious choice for GAM-based models in R, is
mgcv, which ships with R.
But there are other packages, if mgcv doesn't meet your needs.


On Wed, Jan 13, 2021 at 8:44 AM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> I have tried to reach the maintainer of the rgam package. Until now, no response.
> Since I'm in a bit of a hurry, I try to reach you because as I try to install the rgam package using the command :
>
> install.packages("rgam")
>
> I get this warning message :
>
> Warning message:
>
> package ?rgam? is not available (for R version 3.6.3)
>
> The strange thing is that rgam depends R (>= 3.0.2) , stats
>
> How can I solve this problem ?
>
> Best,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From b|oprogr@mmer @end|ng |rom gm@||@com  Wed Jan 13 07:41:18 2021
From: b|oprogr@mmer @end|ng |rom gm@||@com (Caitlin Gibbons)
Date: Tue, 12 Jan 2021 23:41:18 -0700
Subject: [R] package not available for R version...
In-Reply-To: <3c26a82c-1fd5-b94c-6544-4938bf930a89@gmail.com>
References: <3c26a82c-1fd5-b94c-6544-4938bf930a89@gmail.com>
Message-ID: <8B2F75C7-7046-440D-81A7-52943788E3C0@gmail.com>

Hi.

Can you upgrade your version of R? That might help. 

~Caitlin


> On Jan 12, 2021, at 1:08 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> ?On 12/01/2021 2:43 p.m., varin sacha via R-help wrote:
>> Dear R-experts,
>> I have tried to reach the maintainer of the rgam package. Until now, no response.
>> Since I'm in a bit of a hurry, I try to reach you because as I try to install the rgam package using the command :
>> install.packages("rgam")
>> I get this warning message :
>> Warning message:
>> package ?rgam? is not available (for R version 3.6.3)
>> The strange thing is that rgam depends R (>= 3.0.2) , stats
>> How can I solve this problem ?
> 
> That package is no longer listed on CRAN.  You can find some versions of it in https://cran.r-project.org/src/contrib/Archive, the most recent being from 2018.  I'd guess it doesn't pass all checks, so it was removed.
> 
> You could download the last version, and see if you can get it to work.  If you are really ambitious, you might be able to take it over as maintainer.
> 
> Or it might be easier to find a different package to do what you want to do.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tr@xp|@yer @end|ng |rom gm@||@com  Wed Jan 13 23:54:44 2021
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 13 Jan 2021 23:54:44 +0100
Subject: [R] log of small values in R
In-Reply-To: <CAGR+MS7n24pe05-XVPA2-of=43PzcS+NU5ANAqcbA-YRQ33ZUA@mail.gmail.com>
References: <CAGR+MS7n24pe05-XVPA2-of=43PzcS+NU5ANAqcbA-YRQ33ZUA@mail.gmail.com>
Message-ID: <CAGAA5bcSs+aUt-LBYtvJxfapoiZLfgQMNDB877WYCVxP9b1utg@mail.gmail.com>

On Mon, 11 Jan 2021 at 08:22, Shaami <nzshaam at gmail.com> wrote:
>
> Dear Friends        I am facing the problem of log values in R. The
> log(1-0.99999999999999999) is giving -Inf while log(1e-18) gives finite
> answer. Any suggestion to deal with this problem?  Thank you


This vignette has a lot of good information about log of small numbers.

vignette(package = "Rmpfr", "log1mexp-note")
https://cran.r-project.org/web/packages/Rmpfr/vignettes/log1mexp-note.pdf

Regards
Martin M. S. Pedersen

	[[alternative HTML version deleted]]


From t|m-gunn@r@hen@e| @end|ng |rom tu-ber||n@de  Wed Jan 13 09:59:35 2021
From: t|m-gunn@r@hen@e| @end|ng |rom tu-ber||n@de (Hensel, Tim-Gunnar)
Date: Wed, 13 Jan 2021 08:59:35 +0000
Subject: [R] [R-pkgs] weibulltools version 2.0.0 released on CRAN
Message-ID: <5ccc8b828aba487bb2fe02293acf27a3@tu-berlin.de>

Dear all, 

we are happy to announce that a new version of weibulltools is available on CRAN. 
https://CRAN.R-project.org/package=weibulltools  

weibulltools is a package that focuses on statistical methods and visualizations that are often used in reliability engineering. 
The core idea is to provide a compact and easily accessible set of methods and visualization tools that make the examination and 
adjustment as well as the analysis and interpretation of field and bench test data as simple as possible. 

Compared to previous releases (<= 1.0.1), the new version (2.0.0) includes a data-based interface through which the obtained function outputs 
can be easily passed into subsequent methods and visualizations. 
Furthermore, all visualizations that were generated dynamically with 'plotly', can now also be created statically with the support of 'ggplot2'. 

The previously used vector-based approach has been largely preserved but is no longer recommended.

Examples for the usage of the new interface, the documentation of all functions, as well as further changes can be found at 
https://tim-tu.github.io/weibulltools/

If you notice a bug or have suggestions for improvements, please submit an issue with a minimal reproducible example at 
https://github.com/Tim-TU/weibulltools/issues/

Best regards, 
Tim-Gunnar Hensel and David Barkemeyer

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From |@@u|o @end|ng |rom |@t@t@|t  Wed Jan 13 12:54:24 2021
From: |@@u|o @end|ng |rom |@t@t@|t (Andrea Fasulo)
Date: Wed, 13 Jan 2021 12:54:24 +0100 (CET)
Subject: [R] [R-pkgs] R2BEAT 1.0.2
In-Reply-To: <229720362.7377386.1610538781693.JavaMail.zimbra@istat.it>
References: <625278381.7227906.1610527875843.JavaMail.zimbra@istat.it>
 <229720362.7377386.1610538781693.JavaMail.zimbra@istat.it>
Message-ID: <490700049.7377939.1610538864402.JavaMail.zimbra@istat.it>

Dear R users, 
R2BEAT 1.0.2 is now available on CRAN. 
This package covers the two-stage stratified sample design,
offering functions for determining the optimal allocation of both Primary and Secondary stage units,
and for the selection of PSUs with pps, in such a way that the  final sample of SSU is almost self-weighting.

Full documentation and vignettes on: [ https://urlsand.esvalabs.com/?u=https%3A%2F%2Fbarcaroli.github.io%2FR2BEAT%2F&e=3cfb7ead&h=8644c130&f=y&p=y | https://barcaroli.github.io/R2BEAT/ ] 
Hope this can be useful, 
Regards 
Andrea Fasulo 


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From h@w|ckh@m @end|ng |rom gm@||@com  Thu Jan 14 15:37:17 2021
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Thu, 14 Jan 2021 08:37:17 -0600
Subject: [R] roxygen2 & markdown & math
In-Reply-To: <6578f8c5-4f67-ded9-0462-cef2987b6adc@gmail.com>
References: <8b2b6987-02aa-e128-e978-a440dd77c75b@wiwi.hu-berlin.de>
 <80bfb24e8f944cafa01c18f81b809bc9@UM-MAIL3214.unimaas.nl>
 <4ab1b9f6-7b5c-185b-be3c-67bd9c5f6d02@wiwi.hu-berlin.de>
 <6578f8c5-4f67-ded9-0462-cef2987b6adc@gmail.com>
Message-ID: <CABdHhvG2X3H8cXr=o+wrzTQUjKUqO2-z+7oh6k21YvegZiwrHQ@mail.gmail.com>

On Tuesday, January 12, 2021, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 12/01/2021 1:12 p.m., Sigbert Klinke wrote:
>
>> Hi,
>>
>> thanks a lot, but maybe I was to vague.
>>
>> I do not want to replace \eqn{...} and \deqn{...} by \mjseqn{...} and
>> \mjsdeqn{...}. I would like to use $...$ and $$...$$ as in Rmarkdown to
>> get something better readable.
>>
>
> I think that's a question/suggestion that would have to go to the roxygen2
> team.  They're the ones who convert Markdown into the Rd input format.
> Presumably they could convert $...$ into the appropriate macro using
> Mathjax or not, but I have no idea how difficult that would be.
>

If I remember correctly, I think it would be relatively hard since roxygen2
uses commonmark, which doesn?t include math in its parse tree. It might be
possible to hack something together with regular expressions, but of course
that brings with it the risk of introducing new edge cases that don?t
behave as expected.

Hadley


-- 
http://hadley.nz

	[[alternative HTML version deleted]]


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Fri Jan 15 12:30:40 2021
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Fri, 15 Jan 2021 12:30:40 +0100
Subject: [R] Converting "day of year" to "year", "month" and "day"
Message-ID: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>

Dear R users,
I am very new to R software. I have solar wind speed data needed for my
work. How do I convert day in the year to year, month, and day with R
software? I have used this code
as.Date(0, origin = "1998-01-01")
but it can only convert one day of the year at a time. Meanwhile, I have up
to the 1998-2002 data set. Attached is my data.
Kindly help, please.
Jibrin Alhassan

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jan 15 19:15:02 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 15 Jan 2021 18:15:02 +0000
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
Message-ID: <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>

Hello,

No dataset was attached. Like the posting guide says,

No binary attachments except for PS, PDF, and some image and archive 
formats (others are automatically stripped off because they can contain 
malicious software). Files in other formats and larger ones should 
rather be put on the web and have only their URLs posted. This way a 
reader has the option to download them or not.


Can you post sample data? Please post the output of `dput(df)`. Or, if 
it is too big the output of `dput(head(df, 20))`. (`df` is the name of 
your dataset.)

Hope this helps,

Rui Barradas

?s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
> Dear R users,
> I am very new to R software. I have solar wind speed data needed for my
> work. How do I convert day in the year to year, month, and day with R
> software? I have used this code
> as.Date(0, origin = "1998-01-01")
> but it can only convert one day of the year at a time. Meanwhile, I have up
> to the 1998-2002 data set. Attached is my data.
> Kindly help, please.
> Jibrin Alhassan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jan 15 19:49:24 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 15 Jan 2021 10:49:24 -0800
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
Message-ID: <CAGxFJbT7ad6ku_jySd26PkZuiVGCaPyMStA=fLXPGEATX1AxwQ@mail.gmail.com>

There are many good tutorials for R. As a "newbie", you need to avail
yourself of them. Although this forum is meant to "help", it is not
designed to provide tutorials. Understanding basic R functionality is
largely assumed here.

Searching on "tutorials on date-time data in R" brought up many
possibilities. Choose one or more that best suits your needs.

As for your specific query, you seem not to understand R's "vectorization"
behavior: your statement, "it can only convert one day of the year at a
time", is false. Again, search for a tutorial on "vectorization in R." But
note that the "Intro to R" tutorial that ships with R already has this.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 15, 2021 at 9:55 AM Jibrin Alhassan <jibrin.alhassan at unn.edu.ng>
wrote:

> Dear R users,
> I am very new to R software. I have solar wind speed data needed for my
> work. How do I convert day in the year to year, month, and day with R
> software? I have used this code
> as.Date(0, origin = "1998-01-01")
> but it can only convert one day of the year at a time. Meanwhile, I have up
> to the 1998-2002 data set. Attached is my data.
> Kindly help, please.
> Jibrin Alhassan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Fri Jan 15 20:20:16 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Fri, 15 Jan 2021 11:20:16 -0800
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
Message-ID: <CAHqSRuSRxqFeDG-_XPonuCpunRwqsXEtSc4aR5Vnx32kyKWU6g@mail.gmail.com>

Use one of the POSIXt classes, POSIXct or POSIXlt, instead of the Date
class.
They have more methods for doing arithmetic.  E.g.,

> dates <- as.POSIXct(tz="UTC", c("2004-03-01", "2005-03-01"))
> difftime(dates, trunc(dates, units="year"), units="days") # add 1 if you
want YYYY-01-01 to be day 1 instead of day 0
Time differences in days
[1] 60 59

There are packages like 'zoo' that make many time/date operations simpler,
but the above
works with core R.

-Bill



On Fri, Jan 15, 2021 at 9:55 AM Jibrin Alhassan <jibrin.alhassan at unn.edu.ng>
wrote:

> Dear R users,
> I am very new to R software. I have solar wind speed data needed for my
> work. How do I convert day in the year to year, month, and day with R
> software? I have used this code
> as.Date(0, origin = "1998-01-01")
> but it can only convert one day of the year at a time. Meanwhile, I have up
> to the 1998-2002 data set. Attached is my data.
> Kindly help, please.
> Jibrin Alhassan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Fri Jan 15 23:08:07 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Fri, 15 Jan 2021 22:08:07 +0000 (UTC)
Subject: [R] package not available for R version...
In-Reply-To: <CAB8pepy=2JNSc29sEUfTxH6Dqe46pbEM3MZ5LmxuqZ0U3OTvkA@mail.gmail.com>
References: <707556763.2294517.1610480632725.ref@mail.yahoo.com>
 <707556763.2294517.1610480632725@mail.yahoo.com>
 <CAB8pepy=2JNSc29sEUfTxH6Dqe46pbEM3MZ5LmxuqZ0U3OTvkA@mail.gmail.com>
Message-ID: <235945584.10435.1610748487460@mail.yahoo.com>

Hi,

Yes, I don't really know what the maintainer will answer to me. Except that rgam is no longer on CRAN, that I already know !
However, I know mgcv and "classical" GAM model but GAMs can be very sensitive to the presence of a small proportion of observations that deviate from the assumed model, so I was looking for a more robust/resistant GAM. I know the robustgam package but I prefered the rgam (more intuitive to me).
However, I have finished by fitting a robust gam using robustgam package. So everything is OK.

Best,








Le mercredi 13 janvier 2021 ? 07:25:07 UTC+1, Abby Spurdle <spurdle.a at gmail.com> a ?crit : 





It's not clear from your post why you're trying to contact the maintainer.
But it gives the impression you're trying to contact the maintainer,
of an archived package, because you can't install the package.
It's not their responsibility to respond to these kinds of questions.

Also, I note the most obvious choice for GAM-based models in R, is
mgcv, which ships with R.
But there are other packages, if mgcv doesn't meet your needs.


On Wed, Jan 13, 2021 at 8:44 AM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> I have tried to reach the maintainer of the rgam package. Until now, no response.
> Since I'm in a bit of a hurry, I try to reach you because as I try to install the rgam package using the command :
>
> install.packages("rgam")
>
> I get this warning message :
>
> Warning message:
>
> package ?rgam? is not available (for R version 3.6.3)
>
> The strange thing is that rgam depends R (>= 3.0.2) , stats
>
> How can I solve this problem ?
>
> Best,

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Fri Jan 15 23:09:01 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Fri, 15 Jan 2021 22:09:01 +0000 (UTC)
Subject: [R] package not available for R version...
In-Reply-To: <8B2F75C7-7046-440D-81A7-52943788E3C0@gmail.com>
References: <3c26a82c-1fd5-b94c-6544-4938bf930a89@gmail.com>
 <8B2F75C7-7046-440D-81A7-52943788E3C0@gmail.com>
Message-ID: <1807581064.4485255.1610748541769@mail.yahoo.com>

Hi,

Yes, I can but I don't know if it will solve my problem. I will give an attempt !

Best,







Le mercredi 13 janvier 2021 ? 07:41:22 UTC+1, Caitlin Gibbons <bioprogrammer at gmail.com> a ?crit : 





Hi.

Can you upgrade your version of R? That might help. 

~Caitlin


> On Jan 12, 2021, at 1:08 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> ?On 12/01/2021 2:43 p.m., varin sacha via R-help wrote:
>> Dear R-experts,
>> I have tried to reach the maintainer of the rgam package. Until now, no response.
>> Since I'm in a bit of a hurry, I try to reach you because as I try to install the rgam package using the command :
>> install.packages("rgam")
>> I get this warning message :
>> Warning message:
>> package ?rgam? is not available (for R version 3.6.3)
>> The strange thing is that rgam depends R (>= 3.0.2) , stats
>> How can I solve this problem ?
> 
> That package is no longer listed on CRAN.? You can find some versions of it in https://cran.r-project.org/src/contrib/Archive, the most recent being from 2018.? I'd guess it doesn't pass all checks, so it was removed.
> 
> You could download the last version, and see if you can get it to work.? If you are really ambitious, you might be able to take it over as maintainer.
> 
> Or it might be easier to find a different package to do what you want to do.
> 
> Duncan Murdoch

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tr@xp|@yer @end|ng |rom gm@||@com  Fri Jan 15 23:25:32 2021
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 15 Jan 2021 23:25:32 +0100
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
Message-ID: <CAGAA5beevo-kAx7cjvJbT5hst3ALstw+6SiUXFNG+hfKtcu73g@mail.gmail.com>

On Fri, 15 Jan 2021 at 18:55, Jibrin Alhassan <jibrin.alhassan at unn.edu.ng>
wrote:
>
> Dear R users,
> I am very new to R software. I have solar wind speed data needed for my
> work. How do I convert day in the year to year, month, and day with R
> software? I have used this code
> as.Date(0, origin = "1998-01-01")

Look at the package lubridate.
Here is an example for you:

library(lubridate)

v <- seq(ymd("2020-01-01"),ymd("2022-01-01"),1)
df <- data.frame(date = v, day = day(v), month = month(v),year = year(v))
str(df)
head(df,3)
tail(df,3)

'data.frame': 732 obs. of  4 variables:
 $ date : Date, format: "2020-01-01" "2020-01-02" ...
 $ day  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ month: num  1 1 1 1 1 1 1 1 1 1 ...
 $ year : num  2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 ...
        date day month year
1 2020-01-01   1     1 2020
2 2020-01-02   2     1 2020
3 2020-01-03   3     1 2020
          date day month year
730 2021-12-30  30    12 2021
731 2021-12-31  31    12 2021
732 2022-01-01   1     1 2022

Regards
Martin

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sat Jan 16 00:22:25 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 16 Jan 2021 10:22:25 +1100
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
Message-ID: <CA+8X3fUizZRstvr6MRVxT7ooJSnxqwnizNHwhAOpjBCReqaBvw@mail.gmail.com>

Hi Jibrin,
solar_wind_sps<-data.frame(sws=306,date="2021-016")
solar_wind_spd
solar_wind_spd$date<-as.Date(solar_wind_spd$date,"%Y-%j")
solar_wind_spd

This changes the "date" field to an actual date object. If you just
want to change a character string date to another format:

solar_wind_spd$date<-format(as.Date(solar_wind_spd$date,%Y-%j),"%Y-%m-%d")

Jim

On Sat, Jan 16, 2021 at 4:55 AM Jibrin Alhassan
<jibrin.alhassan at unn.edu.ng> wrote:
>
> Dear R users,
> I am very new to R software. I have solar wind speed data needed for my
> work. How do I convert day in the year to year, month, and day with R
> software? I have used this code
> as.Date(0, origin = "1998-01-01")
> but it can only convert one day of the year at a time. Meanwhile, I have up
> to the 1998-2002 data set. Attached is my data.
> Kindly help, please.
> Jibrin Alhassan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@edehk205 @end|ng |rom gm@||@com  Fri Jan 15 05:28:46 2021
From: m@edehk205 @end|ng |rom gm@||@com (maedeh kamali)
Date: Fri, 15 Jan 2021 12:28:46 +0800
Subject: [R] A question regarding 749 R[21525:2855847] Warning
Message-ID: <2EC1A46E-0A8A-4CB7-8C22-69D20DD59A28@gmail.com>

Dear Sir/Madam,

After installing R package version 4.0.3 and launching the R Console for the first time, below warning message appeared:

021-01-15 11:52:28.749 R[21525:2855847] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fdae3418d80>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.

Could you please guide me how to fix it.

Best, 
Maedeh KAMALI
	[[alternative HTML version deleted]]


From u@er2021 @end|ng |rom r-project@org  Thu Jan 14 22:14:23 2021
From: u@er2021 @end|ng |rom r-project@org (useR! 2021 global)
Date: Thu, 14 Jan 2021 18:14:23 -0300
Subject: [R] The useR! 2021 Call for Tutorials is open now!
Message-ID: <CAMZ-NW7Us12SjtahBxZxz2pFvC_4sn=zA-D5LVH_JP30cYdWMg@mail.gmail.com>

 The useR! 2021 Call for Tutorials is open now! *(Due Date Friday, February
5, 2021)*

useR! 2021 is going virtual, and we are happy to open the call for the
tutorial proposals.

The tutorials will be for R users in all sectors, e.g., researchers,
government officers and industry representatives who focus on the
applicability of R in practical settings and for all levels.

Each tutorial's duration can vary between two to four hours, we encourage
shorter length, but we expect at least two hours, and we will accept
proposals for tutorials to be taught in *English, Spanish, or French.*

These tutorials will be organized in *multiple time zones*, so we request
that you select a convenient time zone. We will later determine the
timezone based on all other tutorials and attendees? interest to combine
them into a session.

useR! offers *USD 500* for selected tutorials.

Find the full call for tutorials here:
https://user2021.r-project.org/participation/call-for-tutorials/

*We would appreciate it if you spread this call*,* and we await your
proposals.*

useR! 2021 Organizing Committee

	[[alternative HTML version deleted]]

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From gregco@t@ @end|ng |rom me@com  Sat Jan 16 01:18:23 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Fri, 15 Jan 2021 19:18:23 -0500
Subject: [R] A question regarding 749 R[21525:2855847] Warning
In-Reply-To: <2EC1A46E-0A8A-4CB7-8C22-69D20DD59A28@gmail.com>
References: <2EC1A46E-0A8A-4CB7-8C22-69D20DD59A28@gmail.com>
Message-ID: <3A8F43E8-118D-423F-84CB-D83C7F1F1919@me.com>

I reported this behavior on Thu Jan 7, 2021.
You did nothing wrong.
No fix has been issued.

This evening, I upgraded from R 4.0.2 to the Duke University R 4.0.3 for Apple Mac. Now all I can get from R 4.0.3 is this red error message (that means nothing to me). Is there an easy fix? Greg

2021-01-07 22:58:42.997 R[8311:37566] 
Warning: Expected min height of view: 
(<NSPopoverTouchBarItemButton: 0x7fcb6c592570>) 
to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.

> On Jan 14, 2021, at 11:28 PM, maedeh kamali <maedehk205 at gmail.com> wrote:
> 
> Dear Sir/Madam,
> 
> After installing R package version 4.0.3 and launching the R Console for the first time, below warning message appeared:
> 
> 021-01-15 11:52:28.749 R[21525:2855847] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fdae3418d80>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.
> 
> Could you please guide me how to fix it.
> 
> Best, 
> Maedeh KAMALI
> 	[[alternative HTML version deleted]]
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Sat Jan 16 07:48:07 2021
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Sat, 16 Jan 2021 07:48:07 +0100
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
Message-ID: <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>

Hi Barradas
 Sorry for the delay. Below is a section of my data. I have up to 1826
covering 1998 to 2002
year   day Hr SWS
1998   1  0  344.
1998   2  0  346.
1998   3  0  356.
1998   4  0  332.
1998   5  0  302.
1998   6  0  329.
1998   7  0  395.
1998   8  0  359.
1998   9  0  471.
1998  10  0  392.
1998  11  0  346.
1998  12  0  387.
1998  13  0  393.
1998  14  0  367.
1998  15  0  320.
1998  16  0  309.
1998  17  0  341.
1998  18  0  329.
1998  19  0  322.
1998  20  0  429.
1998  21  0  433.
1998  22  0  398.
1998  23  0  393.
1998  24  0  393.
1998  25  0  423.
1998  26  0  426.
1998  27  0  429.
1998  28  0  386.
1998  29  0  381.
1998  30  0  375.
1998  31  0  365.
1998  32  0  450.
1998  33  0  381.
1998  34  0  316.
1998  35  0  351.
1998  36  0  306.
1998  37  0  312.
1998  38  0  320.
1998  39  0  339.
1998  40  0  395.
1998  41  0  429.
1998  42  0  479.
1998  43  0  495.
1998  44  0  407.
1998  45  0  358.
1998  46  0  360.
1998  47  0  382.
1998  48  0  394.
1998  49  0  393.
1998  50  0  435.
1998  51  0  408.
1998  52  0  360.
1998  53  0  372.
1998  54  0  376.
1998  55  0  379.
1998  56  0  361.
1998  57  0  333.
1998  58  0  321.
1998  59  0  344.
1998  60  0  412.
1998  61  0  428.
1998  62  0  401.
1998  63  0  369.
1998  64  0  343.
1998  65  0  330.
1998  66  0  317.
1998  67  0  296.
1998  68  0  282.
1998  69  0  404.
1998  70  0  530.
1998  71  0  525.
1998  72  0  484.
1998  73  0  430.
1998  74  0  388.
1998  75  0  347.
1998  76  0  337.
1998  77  0  342.
1998  78  0  305.
1998  79  0  329.
1998  80  0  420.
1998  81  0  564.
1998  82  0  483.
1998  83  0  385.
1998  84  0  393.
1998  85  0  437.
1998  86  0  441.
1998  87  0  434.
1998  88  0  471.
1998  89  0  429.
1998  90  0  412.
1998  91  0  370.
1998  92  0  326.
1998  93  0  357.
1998  94  0  338.
1998  95  0  380.
1998  96  0  339.
1998  97  0  312.
1998  98  0  313.
1998  99  0  327.
1998 100  0  362.
1998 101  0  358.
1998 102  0  387.
1998 103  0  397.
1998 104  0  375.
1998 105  0  350.
1998 106  0  357.
1998 107  0  472.
1998 108  0  526.
1998 109  0  396.
1998 110  0  374.
1998 111  0  376.
1998 112  0  355.
1998 113  0  343.
1998 114  0  425.
1998 115  0  426.
1998 116  0  479.
1998 117  0  469.
1998 118  0  425.
1998 119  0  344.
1998 120  0  341.
1998 121  0  426.
1998 122  0  601.
1998 123  0  476.
1998 124  0  670.
1998 125  0  585.
1998 126  0  496.
1998 127  0  479.
1998 128  0  569.
1998 129  0  531.
1998 130  0  489.
1998 131  0  484.
1998 132  0  480.
1998 133  0  393.
1998 134  0  332.
1998 135  0  327.
1998 136  0  493.
1998 137  0  493.
1998 138  0  430.
1998 139  0  396.
1998 140  0  408.
1998 141  0  416.
1998 142  0  376.
1998 143  0  375.
1998 144  0  415.
1998 145  0  407.
1998 146  0  398.
1998 147  0  352.
1998 148  0  349.
1998 149  0  517.
1998 150  0  597.
1998 151  0  480.
1998 152  0  435.
1998 153  0  408.
1998 154  0  441.
1998 155  0  397.
1998 156  0  374.
1998 157  0  413.
1998 158  0  582.
1998 159  0  513.
1998 160  0  459.
1998 161  0  466.
1998 162  0  414.
1998 163  0  354.
1998 164  0  341.
1998 165  0  343.
1998 166  0  369.
1998 167  0  411.
1998 168  0  355.
Thanks
Jibrin

On Fri, Jan 15, 2021 at 7:15 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> No dataset was attached. Like the posting guide says,
>
> No binary attachments except for PS, PDF, and some image and archive
> formats (others are automatically stripped off because they can contain
> malicious software). Files in other formats and larger ones should
> rather be put on the web and have only their URLs posted. This way a
> reader has the option to download them or not.
>
>
> Can you post sample data? Please post the output of `dput(df)`. Or, if
> it is too big the output of `dput(head(df, 20))`. (`df` is the name of
> your dataset.)
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
> > Dear R users,
> > I am very new to R software. I have solar wind speed data needed for my
> > work. How do I convert day in the year to year, month, and day with R
> > software? I have used this code
> > as.Date(0, origin = "1998-01-01")
> > but it can only convert one day of the year at a time. Meanwhile, I have
> up
> > to the 1998-2002 data set. Attached is my data.
> > Kindly help, please.
> > Jibrin Alhassan
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jan 16 08:01:16 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 16 Jan 2021 07:01:16 +0000
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
 <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
Message-ID: <fc104a3c-6d2f-062a-d79e-42ec7c7811b3@sapo.pt>

Hello,

Thanks for the data, it makes things easier.

df1 <- read.table("Jibrin_data.txt", header = TRUE)
#'data.frame':	168 obs. of  4 variables:
# $ year: int  1998 1998 1998 1998 1998 1998 1998 1998 1998 1998 ...
# $ day : int  1 2 3 4 5 6 7 8 9 10 ...
# $ Hr  : int  0 0 0 0 0 0 0 0 0 0 ...
# $ SWS : num  344 346 356 332 302 329 395 359 471 392 ...

Here is a simple way of converting the year and day of year columns to a 
column of class "Date".
Like others have said, there are also CRAN packages to handle date/time 
data, my favorite being package lubridate, but base R can do it.


df1$date <- as.Date(paste(df1$year, df1$day),
                     format = "%Y %j",
                     origin = "1998-01-01")

head(df1)
#  year day Hr SWS       date
#1 1998   1  0 344 1998-01-01
#2 1998   2  0 346 1998-01-02
#3 1998   3  0 356 1998-01-03
#4 1998   4  0 332 1998-01-04
#5 1998   5  0 302 1998-01-05
#6 1998   6  0 329 1998-01-06


Hope this helps,

Rui Barradas


?s 06:48 de 16/01/21, Jibrin Alhassan escreveu:
> Hi Barradas
>  ?Sorry for the delay. Below is a section of my data. I have up to 1826 
> covering 1998 to 2002
> year ? day Hr SWS
> 1998 ? 1 ?0 ?344.
> 1998 ? 2 ?0 ?346.
> 1998 ? 3 ?0 ?356.
> 1998 ? 4 ?0 ?332.
> 1998 ? 5 ?0 ?302.
> 1998 ? 6 ?0 ?329.
> 1998 ? 7 ?0 ?395.
> 1998 ? 8 ?0 ?359.
> 1998 ? 9 ?0 ?471.
> 1998 ?10 ?0 ?392.
> 1998 ?11 ?0 ?346.
> 1998 ?12 ?0 ?387.
> 1998 ?13 ?0 ?393.
> 1998 ?14 ?0 ?367.
> 1998 ?15 ?0 ?320.
> 1998 ?16 ?0 ?309.
> 1998 ?17 ?0 ?341.
> 1998 ?18 ?0 ?329.
> 1998 ?19 ?0 ?322.
> 1998 ?20 ?0 ?429.
> 1998 ?21 ?0 ?433.
> 1998 ?22 ?0 ?398.
> 1998 ?23 ?0 ?393.
> 1998 ?24 ?0 ?393.
> 1998 ?25 ?0 ?423.
> 1998 ?26 ?0 ?426.
> 1998 ?27 ?0 ?429.
> 1998 ?28 ?0 ?386.
> 1998 ?29 ?0 ?381.
> 1998 ?30 ?0 ?375.
> 1998 ?31 ?0 ?365.
> 1998 ?32 ?0 ?450.
> 1998 ?33 ?0 ?381.
> 1998 ?34 ?0 ?316.
> 1998 ?35 ?0 ?351.
> 1998 ?36 ?0 ?306.
> 1998 ?37 ?0 ?312.
> 1998 ?38 ?0 ?320.
> 1998 ?39 ?0 ?339.
> 1998 ?40 ?0 ?395.
> 1998 ?41 ?0 ?429.
> 1998 ?42 ?0 ?479.
> 1998 ?43 ?0 ?495.
> 1998 ?44 ?0 ?407.
> 1998 ?45 ?0 ?358.
> 1998 ?46 ?0 ?360.
> 1998 ?47 ?0 ?382.
> 1998 ?48 ?0 ?394.
> 1998 ?49 ?0 ?393.
> 1998 ?50 ?0 ?435.
> 1998 ?51 ?0 ?408.
> 1998 ?52 ?0 ?360.
> 1998 ?53 ?0 ?372.
> 1998 ?54 ?0 ?376.
> 1998 ?55 ?0 ?379.
> 1998 ?56 ?0 ?361.
> 1998 ?57 ?0 ?333.
> 1998 ?58 ?0 ?321.
> 1998 ?59 ?0 ?344.
> 1998 ?60 ?0 ?412.
> 1998 ?61 ?0 ?428.
> 1998 ?62 ?0 ?401.
> 1998 ?63 ?0 ?369.
> 1998 ?64 ?0 ?343.
> 1998 ?65 ?0 ?330.
> 1998 ?66 ?0 ?317.
> 1998 ?67 ?0 ?296.
> 1998 ?68 ?0 ?282.
> 1998 ?69 ?0 ?404.
> 1998 ?70 ?0 ?530.
> 1998 ?71 ?0 ?525.
> 1998 ?72 ?0 ?484.
> 1998 ?73 ?0 ?430.
> 1998 ?74 ?0 ?388.
> 1998 ?75 ?0 ?347.
> 1998 ?76 ?0 ?337.
> 1998 ?77 ?0 ?342.
> 1998 ?78 ?0 ?305.
> 1998 ?79 ?0 ?329.
> 1998 ?80 ?0 ?420.
> 1998 ?81 ?0 ?564.
> 1998 ?82 ?0 ?483.
> 1998 ?83 ?0 ?385.
> 1998 ?84 ?0 ?393.
> 1998 ?85 ?0 ?437.
> 1998 ?86 ?0 ?441.
> 1998 ?87 ?0 ?434.
> 1998 ?88 ?0 ?471.
> 1998 ?89 ?0 ?429.
> 1998 ?90 ?0 ?412.
> 1998 ?91 ?0 ?370.
> 1998 ?92 ?0 ?326.
> 1998 ?93 ?0 ?357.
> 1998 ?94 ?0 ?338.
> 1998 ?95 ?0 ?380.
> 1998 ?96 ?0 ?339.
> 1998 ?97 ?0 ?312.
> 1998 ?98 ?0 ?313.
> 1998 ?99 ?0 ?327.
> 1998 100 ?0 ?362.
> 1998 101 ?0 ?358.
> 1998 102 ?0 ?387.
> 1998 103 ?0 ?397.
> 1998 104 ?0 ?375.
> 1998 105 ?0 ?350.
> 1998 106 ?0 ?357.
> 1998 107 ?0 ?472.
> 1998 108 ?0 ?526.
> 1998 109 ?0 ?396.
> 1998 110 ?0 ?374.
> 1998 111 ?0 ?376.
> 1998 112 ?0 ?355.
> 1998 113 ?0 ?343.
> 1998 114 ?0 ?425.
> 1998 115 ?0 ?426.
> 1998 116 ?0 ?479.
> 1998 117 ?0 ?469.
> 1998 118 ?0 ?425.
> 1998 119 ?0 ?344.
> 1998 120 ?0 ?341.
> 1998 121 ?0 ?426.
> 1998 122 ?0 ?601.
> 1998 123 ?0 ?476.
> 1998 124 ?0 ?670.
> 1998 125 ?0 ?585.
> 1998 126 ?0 ?496.
> 1998 127 ?0 ?479.
> 1998 128 ?0 ?569.
> 1998 129 ?0 ?531.
> 1998 130 ?0 ?489.
> 1998 131 ?0 ?484.
> 1998 132 ?0 ?480.
> 1998 133 ?0 ?393.
> 1998 134 ?0 ?332.
> 1998 135 ?0 ?327.
> 1998 136 ?0 ?493.
> 1998 137 ?0 ?493.
> 1998 138 ?0 ?430.
> 1998 139 ?0 ?396.
> 1998 140 ?0 ?408.
> 1998 141 ?0 ?416.
> 1998 142 ?0 ?376.
> 1998 143 ?0 ?375.
> 1998 144 ?0 ?415.
> 1998 145 ?0 ?407.
> 1998 146 ?0 ?398.
> 1998 147 ?0 ?352.
> 1998 148 ?0 ?349.
> 1998 149 ?0 ?517.
> 1998 150 ?0 ?597.
> 1998 151 ?0 ?480.
> 1998 152 ?0 ?435.
> 1998 153 ?0 ?408.
> 1998 154 ?0 ?441.
> 1998 155 ?0 ?397.
> 1998 156 ?0 ?374.
> 1998 157 ?0 ?413.
> 1998 158 ?0 ?582.
> 1998 159 ?0 ?513.
> 1998 160 ?0 ?459.
> 1998 161 ?0 ?466.
> 1998 162 ?0 ?414.
> 1998 163 ?0 ?354.
> 1998 164 ?0 ?341.
> 1998 165 ?0 ?343.
> 1998 166 ?0 ?369.
> 1998 167 ?0 ?411.
> 1998 168 ?0 ?355.
> Thanks
> Jibrin
> 
> On Fri, Jan 15, 2021 at 7:15 PM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     No dataset was attached. Like the posting guide says,
> 
>     No binary attachments except for PS, PDF, and some image and archive
>     formats (others are automatically stripped off because they can contain
>     malicious software). Files in other formats and larger ones should
>     rather be put on the web and have only their URLs posted. This way a
>     reader has the option to download them or not.
> 
> 
>     Can you post sample data? Please post the output of `dput(df)`. Or, if
>     it is too big the output of `dput(head(df, 20))`. (`df` is the name of
>     your dataset.)
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
>      > Dear R users,
>      > I am very new to R software. I have solar wind speed data needed
>     for my
>      > work. How do I convert day in the year to year, month, and day with R
>      > software? I have used this code
>      > as.Date(0, origin = "1998-01-01")
>      > but it can only convert one day of the year at a time. Meanwhile,
>     I have up
>      > to the 1998-2002 data set. Attached is my data.
>      > Kindly help, please.
>      > Jibrin Alhassan
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From pd@|gd @end|ng |rom gm@||@com  Sat Jan 16 18:24:02 2021
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sat, 16 Jan 2021 18:24:02 +0100
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
 <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
Message-ID: <A9758BCD-BC41-479F-933E-CB9958647078@gmail.com>

Something like this?

> as.Date(ISOdate(1998,1,1))+(1:100)-1
  [1] "1998-01-01" "1998-01-02" "1998-01-03" "1998-01-04" "1998-01-05"
  [6] "1998-01-06" "1998-01-07" "1998-01-08" "1998-01-09" "1998-01-10"
 [11] "1998-01-11" "1998-01-12" "1998-01-13" "1998-01-14" "1998-01-15"
 [16] "1998-01-16" "1998-01-17" "1998-01-18" "1998-01-19" "1998-01-20"
 [21] "1998-01-21" "1998-01-22" "1998-01-23" "1998-01-24" "1998-01-25"
 [26] "1998-01-26" "1998-01-27" "1998-01-28" "1998-01-29" "1998-01-30"
 [31] "1998-01-31" "1998-02-01" "1998-02-02" "1998-02-03" "1998-02-04"
 [36] "1998-02-05" "1998-02-06" "1998-02-07" "1998-02-08" "1998-02-09"
 [41] "1998-02-10" "1998-02-11" "1998-02-12" "1998-02-13" "1998-02-14"
 [46] "1998-02-15" "1998-02-16" "1998-02-17" "1998-02-18" "1998-02-19"
 [51] "1998-02-20" "1998-02-21" "1998-02-22" "1998-02-23" "1998-02-24"
 [56] "1998-02-25" "1998-02-26" "1998-02-27" "1998-02-28" "1998-03-01"
 [61] "1998-03-02" "1998-03-03" "1998-03-04" "1998-03-05" "1998-03-06"
 [66] "1998-03-07" "1998-03-08" "1998-03-09" "1998-03-10" "1998-03-11"
 [71] "1998-03-12" "1998-03-13" "1998-03-14" "1998-03-15" "1998-03-16"
 [76] "1998-03-17" "1998-03-18" "1998-03-19" "1998-03-20" "1998-03-21"
 [81] "1998-03-22" "1998-03-23" "1998-03-24" "1998-03-25" "1998-03-26"
 [86] "1998-03-27" "1998-03-28" "1998-03-29" "1998-03-30" "1998-03-31"
 [91] "1998-04-01" "1998-04-02" "1998-04-03" "1998-04-04" "1998-04-05"
 [96] "1998-04-06" "1998-04-07" "1998-04-08" "1998-04-09" "1998-04-10"

Or, if you want month numbers and day of month as numerics:

> as.POSIXlt(as.Date(ISOdate(1998,1,1))+(1:100)-1)$mon
  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1
 [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3
> as.POSIXlt(as.Date(ISOdate(1998,1,1))+(1:100)-1)$mday
  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
 [26] 26 27 28 29 30 31  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
 [51] 20 21 22 23 24 25 26 27 28  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16
 [76] 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  1  2  3  4  5  6  7  8  9 10

-pd

> On 16 Jan 2021, at 07:48 , Jibrin Alhassan <jibrin.alhassan at unn.edu.ng> wrote:
> 
> Hi Barradas
> Sorry for the delay. Below is a section of my data. I have up to 1826
> covering 1998 to 2002
> year   day Hr SWS
> 1998   1  0  344.
> 1998   2  0  346.
> 1998   3  0  356.
> 1998   4  0  332.
> 1998   5  0  302.
> 1998   6  0  329.
> 1998   7  0  395.
> 1998   8  0  359.
> 1998   9  0  471.
> 1998  10  0  392.
> 1998  11  0  346.
> 1998  12  0  387.
> 1998  13  0  393.
> 1998  14  0  367.
> 1998  15  0  320.
> 1998  16  0  309.
> 1998  17  0  341.
> 1998  18  0  329.
> 1998  19  0  322.
> 1998  20  0  429.
> 1998  21  0  433.
> 1998  22  0  398.
> 1998  23  0  393.
> 1998  24  0  393.
> 1998  25  0  423.
> 1998  26  0  426.
> 1998  27  0  429.
> 1998  28  0  386.
> 1998  29  0  381.
> 1998  30  0  375.
> 1998  31  0  365.
> 1998  32  0  450.
> 1998  33  0  381.
> 1998  34  0  316.
> 1998  35  0  351.
> 1998  36  0  306.
> 1998  37  0  312.
> 1998  38  0  320.
> 1998  39  0  339.
> 1998  40  0  395.
> 1998  41  0  429.
> 1998  42  0  479.
> 1998  43  0  495.
> 1998  44  0  407.
> 1998  45  0  358.
> 1998  46  0  360.
> 1998  47  0  382.
> 1998  48  0  394.
> 1998  49  0  393.
> 1998  50  0  435.
> 1998  51  0  408.
> 1998  52  0  360.
> 1998  53  0  372.
> 1998  54  0  376.
> 1998  55  0  379.
> 1998  56  0  361.
> 1998  57  0  333.
> 1998  58  0  321.
> 1998  59  0  344.
> 1998  60  0  412.
> 1998  61  0  428.
> 1998  62  0  401.
> 1998  63  0  369.
> 1998  64  0  343.
> 1998  65  0  330.
> 1998  66  0  317.
> 1998  67  0  296.
> 1998  68  0  282.
> 1998  69  0  404.
> 1998  70  0  530.
> 1998  71  0  525.
> 1998  72  0  484.
> 1998  73  0  430.
> 1998  74  0  388.
> 1998  75  0  347.
> 1998  76  0  337.
> 1998  77  0  342.
> 1998  78  0  305.
> 1998  79  0  329.
> 1998  80  0  420.
> 1998  81  0  564.
> 1998  82  0  483.
> 1998  83  0  385.
> 1998  84  0  393.
> 1998  85  0  437.
> 1998  86  0  441.
> 1998  87  0  434.
> 1998  88  0  471.
> 1998  89  0  429.
> 1998  90  0  412.
> 1998  91  0  370.
> 1998  92  0  326.
> 1998  93  0  357.
> 1998  94  0  338.
> 1998  95  0  380.
> 1998  96  0  339.
> 1998  97  0  312.
> 1998  98  0  313.
> 1998  99  0  327.
> 1998 100  0  362.
> 1998 101  0  358.
> 1998 102  0  387.
> 1998 103  0  397.
> 1998 104  0  375.
> 1998 105  0  350.
> 1998 106  0  357.
> 1998 107  0  472.
> 1998 108  0  526.
> 1998 109  0  396.
> 1998 110  0  374.
> 1998 111  0  376.
> 1998 112  0  355.
> 1998 113  0  343.
> 1998 114  0  425.
> 1998 115  0  426.
> 1998 116  0  479.
> 1998 117  0  469.
> 1998 118  0  425.
> 1998 119  0  344.
> 1998 120  0  341.
> 1998 121  0  426.
> 1998 122  0  601.
> 1998 123  0  476.
> 1998 124  0  670.
> 1998 125  0  585.
> 1998 126  0  496.
> 1998 127  0  479.
> 1998 128  0  569.
> 1998 129  0  531.
> 1998 130  0  489.
> 1998 131  0  484.
> 1998 132  0  480.
> 1998 133  0  393.
> 1998 134  0  332.
> 1998 135  0  327.
> 1998 136  0  493.
> 1998 137  0  493.
> 1998 138  0  430.
> 1998 139  0  396.
> 1998 140  0  408.
> 1998 141  0  416.
> 1998 142  0  376.
> 1998 143  0  375.
> 1998 144  0  415.
> 1998 145  0  407.
> 1998 146  0  398.
> 1998 147  0  352.
> 1998 148  0  349.
> 1998 149  0  517.
> 1998 150  0  597.
> 1998 151  0  480.
> 1998 152  0  435.
> 1998 153  0  408.
> 1998 154  0  441.
> 1998 155  0  397.
> 1998 156  0  374.
> 1998 157  0  413.
> 1998 158  0  582.
> 1998 159  0  513.
> 1998 160  0  459.
> 1998 161  0  466.
> 1998 162  0  414.
> 1998 163  0  354.
> 1998 164  0  341.
> 1998 165  0  343.
> 1998 166  0  369.
> 1998 167  0  411.
> 1998 168  0  355.
> Thanks
> Jibrin
> 
> On Fri, Jan 15, 2021 at 7:15 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
>> Hello,
>> 
>> No dataset was attached. Like the posting guide says,
>> 
>> No binary attachments except for PS, PDF, and some image and archive
>> formats (others are automatically stripped off because they can contain
>> malicious software). Files in other formats and larger ones should
>> rather be put on the web and have only their URLs posted. This way a
>> reader has the option to download them or not.
>> 
>> 
>> Can you post sample data? Please post the output of `dput(df)`. Or, if
>> it is too big the output of `dput(head(df, 20))`. (`df` is the name of
>> your dataset.)
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> ?s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
>>> Dear R users,
>>> I am very new to R software. I have solar wind speed data needed for my
>>> work. How do I convert day in the year to year, month, and day with R
>>> software? I have used this code
>>> as.Date(0, origin = "1998-01-01")
>>> but it can only convert one day of the year at a time. Meanwhile, I have
>> up
>>> to the 1998-2002 data set. Attached is my data.
>>> Kindly help, please.
>>> Jibrin Alhassan
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@|| @end|ng |rom p-roock@@de  Fri Jan 15 19:07:15 2021
From: m@|| @end|ng |rom p-roock@@de (Patrick Roocks)
Date: Fri, 15 Jan 2021 19:07:15 +0100
Subject: [R] [R-pkgs] listcompr: list comprehension for R
Message-ID: <e324992b-0dcb-5868-c252-beea44e7be21@p-roocks.de>

Dear R users,

I am happy to announce the first version of listcompr which is on CRAN 
now. listcompr is a "syntactic sugar" approach to generate lists, 
vectors and data frames with list comprehension.

Some examples are shown on the readme page on the github repository: 
https://github.com/patrickroocks/listcompr

I hope this is useful for some of you.

All the best,

Patrick

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun Jan 17 11:19:27 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 17 Jan 2021 10:19:27 +0000 (UTC)
Subject: [R] Error in UseMethod("predict")
References: <1991372792.4918972.1610878767028.ref@mail.yahoo.com>
Message-ID: <1991372792.4918972.1610878767028@mail.yahoo.com>

Dear R-experts,

Here below my reproducible R code. I get an error message (end of code) I can't solve.
Many thanks for your help.

##########################
#Data
y=c(34000,45000,19000,48900,65000,67000,78000,90000,51000,32000,54000,85000,38000,76345,87654,90990,78654,67894,56789,65432,18998,78987,67543,45678,76543,67876)
x=c(345,543,543,456,432,378,543,579,432,254,346,564,611,543,542,632,345,468,476,487,453,356,490,499,567,532)

Dataset=data.frame(y,x)

#Plot
plot(x,y)

#Robust GAM
library(robustgam)
true.family <- poisson()
fit=robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
x.new <- seq(range(x)[1], range(x)[2])
robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
lines(x.new, robustfit.new, col="green", lwd=2)

# To find the ??sp?? to include in the fit function here above
robustfit.gic<-robustgam.GIC.optim(x,y,family=true.family,p=3,c=1.6,show.msg=FALSE,smooth.basis="tp", method="L-BFGS-B")

## CROSS VALIDATION REPLICATIONS MSE ROBUST GAM
install.packages("ISLR")
library(ISLR)

# Create a list to store the results
lst<-list()

# This statement does the repetitions (looping)
for(i in 1?:1000)
{

n=dim(Dataset)[1]
p=0.667
sam=sample(1?:n,floor(p*n),replace=FALSE)
Training =Dataset [sam,]
Testing = Dataset [-sam,]

fit18<-robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)

ypred=predict(fit18,newdata=Testing)
y=Dataset[-sam,]$y
MSE = mean((y-ypred)^2)
MSE
lst[i]<-MSE
}
mean(unlist(lst))
####################################
?


From er|cjberger @end|ng |rom gm@||@com  Sun Jan 17 11:41:22 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 17 Jan 2021 12:41:22 +0200
Subject: [R] Error in UseMethod("predict")
In-Reply-To: <1991372792.4918972.1610878767028@mail.yahoo.com>
References: <1991372792.4918972.1610878767028.ref@mail.yahoo.com>
 <1991372792.4918972.1610878767028@mail.yahoo.com>
Message-ID: <CAGgJW75aPdXvbr8GRhqivvgZE5Ct2TnBx2H7hFpLRE30rDzHFA@mail.gmail.com>

Hi Sacha,
I never used these packages before but I installed them and tried your
code. I have a few observations that may help.

1. the statement
    ypred = predict(fit18,newdata=Testing)
    is wrong. Checkout the help page (?robustgam)  which shows in the
Examples section at the bottom to use something like
    ypred = pred.robustgam( fit18, data.frame(X=Testing)

2. your logic is wrong. You define the vectors x and y at the top. They
should remain untouched during your program.
    However in the loop you redefine y and then use the redefined y as an
argument to robustgam() the next time through
    the loop. This looks like a serious error.

HTH,
Eric


On Sun, Jan 17, 2021 at 12:20 PM varin sacha via R-help <
r-help at r-project.org> wrote:

> Dear R-experts,
>
> Here below my reproducible R code. I get an error message (end of code) I
> can't solve.
> Many thanks for your help.
>
> ##########################
> #Data
>
> y=c(34000,45000,19000,48900,65000,67000,78000,90000,51000,32000,54000,85000,38000,76345,87654,90990,78654,67894,56789,65432,18998,78987,67543,45678,76543,67876)
>
> x=c(345,543,543,456,432,378,543,579,432,254,346,564,611,543,542,632,345,468,476,487,453,356,490,499,567,532)
>
> Dataset=data.frame(y,x)
>
> #Plot
> plot(x,y)
>
> #Robust GAM
> library(robustgam)
> true.family <- poisson()
> fit=robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
> x.new <- seq(range(x)[1], range(x)[2])
> robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
> lines(x.new, robustfit.new, col="green", lwd=2)
>
> # To find the ? sp ? to include in the fit function here above
> robustfit.gic<-robustgam.GIC.optim(x,y,family=true.family,p=3,c=1.6,show.msg=FALSE,smooth.basis="tp",
> method="L-BFGS-B")
>
> ## CROSS VALIDATION REPLICATIONS MSE ROBUST GAM
> install.packages("ISLR")
> library(ISLR)
>
> # Create a list to store the results
> lst<-list()
>
> # This statement does the repetitions (looping)
> for(i in 1 :1000)
> {
>
> n=dim(Dataset)[1]
> p=0.667
> sam=sample(1 :n,floor(p*n),replace=FALSE)
> Training =Dataset [sam,]
> Testing = Dataset [-sam,]
>
> fit18<-robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
>
> ypred=predict(fit18,newdata=Testing)
> y=Dataset[-sam,]$y
> MSE = mean((y-ypred)^2)
> MSE
> lst[i]<-MSE
> }
> mean(unlist(lst))
> ####################################
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun Jan 17 14:22:26 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 17 Jan 2021 13:22:26 +0000 (UTC)
Subject: [R] Error in UseMethod("predict")
In-Reply-To: <CAGgJW75aPdXvbr8GRhqivvgZE5Ct2TnBx2H7hFpLRE30rDzHFA@mail.gmail.com>
References: <1991372792.4918972.1610878767028.ref@mail.yahoo.com>
 <1991372792.4918972.1610878767028@mail.yahoo.com>
 <CAGgJW75aPdXvbr8GRhqivvgZE5Ct2TnBx2H7hFpLRE30rDzHFA@mail.gmail.com>
Message-ID: <1101877080.256550.1610889746695@mail.yahoo.com>

Dear Eric,

Many thanks, I correct your 2 points and now I get another error message (Error in splineDesign(knots, x, ord, derivs, outer.ok = outer.ok, sparse = sparse) :
? empty 'derivs'). 
I have googleized and found some hints like (outer.ok=TRUE) but no one seems to work.

https://r.789695.n4.nabble.com/mgcv-gam-predict-problem-td3411006.html 

Any idea to make my code work would be appreciated.

Here below my new R code :

##########################
#Data
y=c(34000,45000,19000,48900,65000,67000,78000,90000,51000,32000,54000,85000,38000,76345,87654,90990,78654,67894,56789,65432,18998,78987,67543,45678,76543,67876)
x=c(345,543,543,456,432,378,543,579,432,254,346,564,611,543,542,632,345,468,476,487,453,356,490,499,567,532)

Dataset=data.frame(y,x)

#Plot
plot(x,y)

#Robust GAM
library(robustgam)
true.family <- poisson()
fit=robustgam(x,y, sp=2424,family=true.family,smooth.basis='ps',K=3)
x.new <- seq(range(x)[1], range(x)[2])
robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
lines(x.new, robustfit.new, col="green", lwd=2)

# To find the ??sp?? to include in the fit function here above
robustfit.gic<-robustgam.GIC.optim(x,y,family=true.family,p=3,c=1.6,show.msg=FALSE,smooth.basis="ps", method="L-BFGS-B")

## CROSS VALIDATION REPLICATIONS MSE ROBUST GAM
install.packages("ISLR")
library(ISLR)

# Create a list to store the results
lst<-list()

# This statement does the repetitions (looping)
for(i in 1?:1000)
{

n=dim(Dataset)[1]
p=0.667
sam=sample(1?:n,floor(p*n),replace=FALSE)
Training =Dataset [sam,]
Testing = Dataset [-sam,] 

fit18<-robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)

ypred=pred.robustgam(fit18,data.frame(X=Testing))
MSE = mean((y-ypred)^2)
MSE
lst[i]<-MSE
}
mean(unlist(lst))
####################################



?Le dimanche 17 janvier 2021 ? 11:41:49 UTC+1, Eric Berger <ericjberger at gmail.com> a ?crit : 


Hi Sacha,
I never used these packages before but I installed them and tried your code. I have a few observations that may help.

1. the statement
? ? ypred = predict(fit18,newdata=Testing)
? ? is wrong. Checkout the help page (?robustgam)? which shows in the Examples section at the bottom to use something like
? ? ypred = pred.robustgam( fit18, data.frame(X=Testing)

2. your logic is wrong. You define the vectors x and y at the top. They should?remain untouched during your program.
? ? However in the loop you redefine y and then use the redefined y as an argument to robustgam() the next time through
? ? the loop. This looks like a serious error.

HTH,
Eric


On Sun, Jan 17, 2021 at 12:20 PM varin sacha via R-help <r-help at r-project.org> wrote:
> Dear R-experts,
> 
> Here below my reproducible R code. I get an error message (end of code) I can't solve.
> Many thanks for your help.
> 
> ##########################
> #Data
> y=c(34000,45000,19000,48900,65000,67000,78000,90000,51000,32000,54000,85000,38000,76345,87654,90990,78654,67894,56789,65432,18998,78987,67543,45678,76543,67876)
> x=c(345,543,543,456,432,378,543,579,432,254,346,564,611,543,542,632,345,468,476,487,453,356,490,499,567,532)
> 
> Dataset=data.frame(y,x)
> 
> #Plot
> plot(x,y)
> 
> #Robust GAM
> library(robustgam)
> true.family <- poisson()
> fit=robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
> x.new <- seq(range(x)[1], range(x)[2])
> robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
> lines(x.new, robustfit.new, col="green", lwd=2)
> 
> # To find the ??sp?? to include in the fit function here above
> robustfit.gic<-robustgam.GIC.optim(x,y,family=true.family,p=3,c=1.6,show.msg=FALSE,smooth.basis="tp", method="L-BFGS-B")
> 
> ## CROSS VALIDATION REPLICATIONS MSE ROBUST GAM
> install.packages("ISLR")
> library(ISLR)
> 
> # Create a list to store the results
> lst<-list()
> 
> # This statement does the repetitions (looping)
> for(i in 1?:1000)
> {
> 
> n=dim(Dataset)[1]
> p=0.667
> sam=sample(1?:n,floor(p*n),replace=FALSE)
> Training =Dataset [sam,]
> Testing = Dataset [-sam,]
> 
> fit18<-robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
> 
> ypred=predict(fit18,newdata=Testing)
> y=Dataset[-sam,]$y
> MSE = mean((y-ypred)^2)
> MSE
> lst[i]<-MSE
> }
> mean(unlist(lst))
> ####################################
> ?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From er|cjberger @end|ng |rom gm@||@com  Sun Jan 17 15:02:11 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 17 Jan 2021 16:02:11 +0200
Subject: [R] Error in UseMethod("predict")
In-Reply-To: <1101877080.256550.1610889746695@mail.yahoo.com>
References: <1991372792.4918972.1610878767028.ref@mail.yahoo.com>
 <1991372792.4918972.1610878767028@mail.yahoo.com>
 <CAGgJW75aPdXvbr8GRhqivvgZE5Ct2TnBx2H7hFpLRE30rDzHFA@mail.gmail.com>
 <1101877080.256550.1610889746695@mail.yahoo.com>
Message-ID: <CAGgJW774d-LkJJP-ZxYH8ynNdgvZMuQkzZRzuTVotqDwuZ_81g@mail.gmail.com>

Hi Sacha,
I took a quick look. Sorry, I don't see immediately what is causing the
problem.
Maybe someone else can help.


On Sun, Jan 17, 2021 at 3:22 PM varin sacha <varinsacha at yahoo.fr> wrote:

> Dear Eric,
>
> Many thanks, I correct your 2 points and now I get another error message
> (Error in splineDesign(knots, x, ord, derivs, outer.ok = outer.ok, sparse =
> sparse) :
>   empty 'derivs').
> I have googleized and found some hints like (outer.ok=TRUE) but no one
> seems to work.
>
> https://r.789695.n4.nabble.com/mgcv-gam-predict-problem-td3411006.html
>
> Any idea to make my code work would be appreciated.
>
> Here below my new R code :
>
> ##########################
> #Data
>
> y=c(34000,45000,19000,48900,65000,67000,78000,90000,51000,32000,54000,85000,38000,76345,87654,90990,78654,67894,56789,65432,18998,78987,67543,45678,76543,67876)
>
> x=c(345,543,543,456,432,378,543,579,432,254,346,564,611,543,542,632,345,468,476,487,453,356,490,499,567,532)
>
> Dataset=data.frame(y,x)
>
> #Plot
> plot(x,y)
>
> #Robust GAM
> library(robustgam)
> true.family <- poisson()
> fit=robustgam(x,y, sp=2424,family=true.family,smooth.basis='ps',K=3)
> x.new <- seq(range(x)[1], range(x)[2])
> robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
> lines(x.new, robustfit.new, col="green", lwd=2)
>
> # To find the ? sp ? to include in the fit function here above
> robustfit.gic<-robustgam.GIC.optim(x,y,family=true.family,p=3,c=1.6,show.msg=FALSE,smooth.basis="ps",
> method="L-BFGS-B")
>
> ## CROSS VALIDATION REPLICATIONS MSE ROBUST GAM
> install.packages("ISLR")
> library(ISLR)
>
> # Create a list to store the results
> lst<-list()
>
> # This statement does the repetitions (looping)
> for(i in 1 :1000)
> {
>
> n=dim(Dataset)[1]
> p=0.667
> sam=sample(1 :n,floor(p*n),replace=FALSE)
> Training =Dataset [sam,]
> Testing = Dataset [-sam,]
>
> fit18<-robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
>
> ypred=pred.robustgam(fit18,data.frame(X=Testing))
> MSE = mean((y-ypred)^2)
> MSE
> lst[i]<-MSE
> }
> mean(unlist(lst))
> ####################################
>
>
>
>  Le dimanche 17 janvier 2021 ? 11:41:49 UTC+1, Eric Berger <
> ericjberger at gmail.com> a ?crit :
>
>
> Hi Sacha,
> I never used these packages before but I installed them and tried your
> code. I have a few observations that may help.
>
> 1. the statement
>     ypred = predict(fit18,newdata=Testing)
>     is wrong. Checkout the help page (?robustgam)  which shows in the
> Examples section at the bottom to use something like
>     ypred = pred.robustgam( fit18, data.frame(X=Testing)
>
> 2. your logic is wrong. You define the vectors x and y at the top. They
> should remain untouched during your program.
>     However in the loop you redefine y and then use the redefined y as an
> argument to robustgam() the next time through
>     the loop. This looks like a serious error.
>
> HTH,
> Eric
>
>
> On Sun, Jan 17, 2021 at 12:20 PM varin sacha via R-help <
> r-help at r-project.org> wrote:
> > Dear R-experts,
> >
> > Here below my reproducible R code. I get an error message (end of code)
> I can't solve.
> > Many thanks for your help.
> >
> > ##########################
> > #Data
> >
> y=c(34000,45000,19000,48900,65000,67000,78000,90000,51000,32000,54000,85000,38000,76345,87654,90990,78654,67894,56789,65432,18998,78987,67543,45678,76543,67876)
> >
> x=c(345,543,543,456,432,378,543,579,432,254,346,564,611,543,542,632,345,468,476,487,453,356,490,499,567,532)
> >
> > Dataset=data.frame(y,x)
> >
> > #Plot
> > plot(x,y)
> >
> > #Robust GAM
> > library(robustgam)
> > true.family <- poisson()
> > fit=robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
> > x.new <- seq(range(x)[1], range(x)[2])
> > robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
> > lines(x.new, robustfit.new, col="green", lwd=2)
> >
> > # To find the ? sp ? to include in the fit function here above
> >
> robustfit.gic<-robustgam.GIC.optim(x,y,family=true.family,p=3,c=1.6,show.msg=FALSE,smooth.basis="tp",
> method="L-BFGS-B")
> >
> > ## CROSS VALIDATION REPLICATIONS MSE ROBUST GAM
> > install.packages("ISLR")
> > library(ISLR)
> >
> > # Create a list to store the results
> > lst<-list()
> >
> > # This statement does the repetitions (looping)
> > for(i in 1 :1000)
> > {
> >
> > n=dim(Dataset)[1]
> > p=0.667
> > sam=sample(1 :n,floor(p*n),replace=FALSE)
> > Training =Dataset [sam,]
> > Testing = Dataset [-sam,]
> >
> > fit18<-robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
> >
> > ypred=predict(fit18,newdata=Testing)
> > y=Dataset[-sam,]$y
> > MSE = mean((y-ypred)^2)
> > MSE
> > lst[i]<-MSE
> > }
> > mean(unlist(lst))
> > ####################################
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Sun Jan 17 16:12:28 2021
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Sun, 17 Jan 2021 16:12:28 +0100
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <fc104a3c-6d2f-062a-d79e-42ec7c7811b3@sapo.pt>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
 <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
 <fc104a3c-6d2f-062a-d79e-42ec7c7811b3@sapo.pt>
Message-ID: <CAEGeL+HOZT_AzYS1cVB9wGC7OFvH7EM=U_n02y-sP1HZFs02wg@mail.gmail.com>

Hi Barradas,
Thanks for your assistance. It has brought me closer to what I am looking
for. I tried your code as shown below:
> df1 <- read.table("SWSdata_1998_2002", header = TRUE)
> df1$date <- as.Date(paste(df1$year, df1$day),format = "%Y %j",origin =
"1998-01-01")
> head(df1)
  year day Hr SWS       date
1 1998   1  0 344 1998-01-01
2 1998   2  0 346 1998-01-02
3 1998   3  0 356 1998-01-03
4 1998   4  0 332 1998-01-04
5 1998   5  0 302 1998-01-05
6 1998   6  0 329 1998-01-06
What I need is the last two columns only (SWS, date). The first 3 columns
(year, day Hr should go). Your code produced only 6 datasets. My dataset is
1,826 from 1998 to 2002. How do I generate this at once?
Many many thanks for your time. I have pasted below a section of my dataset
for your guidance, please.
Jibrin
year   day Hr SWS
1998   1  0  344.
1998   2  0  346.
1998   3  0  356.
1998   4  0  332.
1998   5  0  302.
1998   6  0  329.
1998   7  0  395.
1998   8  0  359.
1998   9  0  471.
1998  10  0  392.
1998  11  0  346.
1998  12  0  387.
1998  13  0  393.
1998  14  0  367.
1998  15  0  320.
1998  16  0  309.
1998  17  0  341.
1998  18  0  329.
1998  19  0  322.
1998  20  0  429.
1998  21  0  433.
1998  22  0  398.
1998  23  0  393.
1998  24  0  393.
1998  25  0  423.
1998  26  0  426.
1998  27  0  429.
1998  28  0  386.
1998  29  0  381.
1998  30  0  375.
1998  31  0  365.
1998  32  0  450.
1998  33  0  381.
1998  34  0  316.
1998  35  0  351.
1998  36  0  306.
1998  37  0  312.
1998  38  0  320.
1998  39  0  339.
1998  40  0  395.
1998  41  0  429.
1998  42  0  479.
1998  43  0  495.
1998  44  0  407.
1998  45  0  358.
1998  46  0  360.
1998  47  0  382.
1998  48  0  394.
1998  49  0  393.
1998  50  0  435.
1998  51  0  408.
1998  52  0  360.
1998  53  0  372.
1998  54  0  376.
1998  55  0  379.
1998  56  0  361.
1998  57  0  333.
1998  58  0  321.
1998  59  0  344.
1998  60  0  412.
1998  61  0  428.
1998  62  0  401.
1998  63  0  369.
1998  64  0  343.
1998  65  0  330.
1998  66  0  317.
1998  67  0  296.
1998  68  0  282.
1998  69  0  404.
1998  70  0  530.
1998  71  0  525.
1998  72  0  484.
1998  73  0  430.
1998  74  0  388.
1998  75  0  347.
1998  76  0  337.
1998  77  0  342.
1998  78  0  305.
1998  79  0  329.
1998  80  0  420.
1998  81  0  564.
1998  82  0  483.
1998  83  0  385.
1998  84  0  393.
1998  85  0  437.
1998  86  0  441.
1998  87  0  434.
1998  88  0  471.
1998  89  0  429.
1998  90  0  412.
1998  91  0  370.
1998  92  0  326.
1998  93  0  357.
1998  94  0  338.
1998  95  0  380.
1998  96  0  339.
1998  97  0  312.
1998  98  0  313.
1998  99  0  327.
1998 100  0  362.
1998 101  0  358.
1998 102  0  387.
1998 103  0  397.
1998 104  0  375.
1998 105  0  350.
1998 106  0  357.
1998 107  0  472.
1998 108  0  526.
1998 109  0  396.
1998 110  0  374.
1998 111  0  376.
1998 112  0  355.
1998 113  0  343.
1998 114  0  425.
1998 115  0  426.
1998 116  0  479.
1998 117  0  469.
1998 118  0  425.
1998 119  0  344.
1998 120  0  341.
1998 121  0  426.
1998 122  0  601.
1998 123  0  476.
1998 124  0  670.
1998 125  0  585.
1998 126  0  496.
1998 127  0  479.
1998 128  0  569.
1998 129  0  531.
1998 130  0  489.
1998 131  0  484.
1998 132  0  480.
1998 133  0  393.
1998 134  0  332.
1998 135  0  327.
1998 136  0  493.
1998 137  0  493.
1998 138  0  430.
1998 139  0  396.
1998 140  0  408.
1998 141  0  416.
1998 142  0  376.
1998 143  0  375.
1998 144  0  415.
1998 145  0  407.
1998 146  0  398.
1998 147  0  352.
1998 148  0  349.
1998 149  0  517.
1998 150  0  597.
1998 151  0  480.
1998 152  0  435.
1998 153  0  408.
1998 154  0  441.
1998 155  0  397.
1998 156  0  374.
1998 157  0  413.
1998 158  0  582.
1998 159  0  513.
1998 160  0  459.
1998 161  0  466.
1998 162  0  414.
1998 163  0  354.
1998 164  0  341.
1998 165  0  343.
1998 166  0  369.
1998 167  0  411.
1998 168  0  355.
1998 169  0  333.
1998 170  0  443.
1998 171  0  426.
1998 172  0  419.
1998 173  0  404.
1998 174  0  387.
1998 175  0  460.
1998 176  0  447.
1998 177  0  469.
1998 178  0  447.
1998 179  0  389.
1998 180  0  375.
1998 181  0  354.
1998 182  0  316.
1998 183  0  369.
1998 184  0  410.
1998 185  0  406.
1998 186  0  477.
1998 187  0  583.
1998 188  0  458.
1998 189  0  386.
1998 190  0  342.
1998 191  0  333.
1998 192  0  369.
1998 193  0  406.
1998 194  0  375.
1998 195  0  332.
1998 196  0  310.
1998 197  0  528.
1998 198  0  530.
1998 199  0  387.
1998 200  0  385.
1998 201  0  349.
1998 202  0  409.
1998 203  0  399.
1998 204  0  619.
1998 205  0  658.
1998 206  0  581.
1998 207  0  445.
1998 208  0  370.
1998 209  0  326.
1998 210  0  334.
1998 211  0  384.
1998 212  0  423.
1998 213  0  412.
1998 214  0  404.
1998 215  0  370.
1998 216  0  384.
1998 217  0  383.
1998 218  0  378.
1998 219  0  461.
1998 220  0  460.
1998 221  0  400.
1998 222  0  447.
1998 223  0  373.
1998 224  0  379.
1998 225  0  374.
1998 226  0  374.
1998 227  0  391.
1998 228  0  348.
1998 229  0  303.
1998 230  0  279.
1998 231  0  312.
1998 232  0  331.
1998 233  0  298.
1998 234  0  341.
1998 235  0  493.
1998 236  0  436.
1998 237  0  400.
1998 238  0  633.
1998 239  0  630.
1998 240  0  583.
1998 241  0  547.
1998 242  0  550.
1998 243  0  499.
1998 244  0  444.
1998 245  0  427.
1998 246  0  401.

On Sat, Jan 16, 2021 at 8:01 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Thanks for the data, it makes things easier.
>
> df1 <- read.table("Jibrin_data.txt", header = TRUE)
> #'data.frame':  168 obs. of  4 variables:
> # $ year: int  1998 1998 1998 1998 1998 1998 1998 1998 1998 1998 ...
> # $ day : int  1 2 3 4 5 6 7 8 9 10 ...
> # $ Hr  : int  0 0 0 0 0 0 0 0 0 0 ...
> # $ SWS : num  344 346 356 332 302 329 395 359 471 392 ...
>
> Here is a simple way of converting the year and day of year columns to a
> column of class "Date".
> Like others have said, there are also CRAN packages to handle date/time
> data, my favorite being package lubridate, but base R can do it.
>
>
> df1$date <- as.Date(paste(df1$year, df1$day),
>                      format = "%Y %j",
>                      origin = "1998-01-01")
>
> head(df1)
> #  year day Hr SWS       date
> #1 1998   1  0 344 1998-01-01
> #2 1998   2  0 346 1998-01-02
> #3 1998   3  0 356 1998-01-03
> #4 1998   4  0 332 1998-01-04
> #5 1998   5  0 302 1998-01-05
> #6 1998   6  0 329 1998-01-06
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 06:48 de 16/01/21, Jibrin Alhassan escreveu:
> > Hi Barradas
> >   Sorry for the delay. Below is a section of my data. I have up to 1826
> > covering 1998 to 2002
> > year   day Hr SWS
> > 1998   1  0  344.
> > 1998   2  0  346.
> > 1998   3  0  356.
> > 1998   4  0  332.
> > 1998   5  0  302.
> > 1998   6  0  329.
> > 1998   7  0  395.
> > 1998   8  0  359.
> > 1998   9  0  471.
> > 1998  10  0  392.
> > 1998  11  0  346.
> > 1998  12  0  387.
> > 1998  13  0  393.
> > 1998  14  0  367.
> > 1998  15  0  320.
> > 1998  16  0  309.
> > 1998  17  0  341.
> > 1998  18  0  329.
> > 1998  19  0  322.
> > 1998  20  0  429.
> > 1998  21  0  433.
> > 1998  22  0  398.
> > 1998  23  0  393.
> > 1998  24  0  393.
> > 1998  25  0  423.
> > 1998  26  0  426.
> > 1998  27  0  429.
> > 1998  28  0  386.
> > 1998  29  0  381.
> > 1998  30  0  375.
> > 1998  31  0  365.
> > 1998  32  0  450.
> > 1998  33  0  381.
> > 1998  34  0  316.
> > 1998  35  0  351.
> > 1998  36  0  306.
> > 1998  37  0  312.
> > 1998  38  0  320.
> > 1998  39  0  339.
> > 1998  40  0  395.
> > 1998  41  0  429.
> > 1998  42  0  479.
> > 1998  43  0  495.
> > 1998  44  0  407.
> > 1998  45  0  358.
> > 1998  46  0  360.
> > 1998  47  0  382.
> > 1998  48  0  394.
> > 1998  49  0  393.
> > 1998  50  0  435.
> > 1998  51  0  408.
> > 1998  52  0  360.
> > 1998  53  0  372.
> > 1998  54  0  376.
> > 1998  55  0  379.
> > 1998  56  0  361.
> > 1998  57  0  333.
> > 1998  58  0  321.
> > 1998  59  0  344.
> > 1998  60  0  412.
> > 1998  61  0  428.
> > 1998  62  0  401.
> > 1998  63  0  369.
> > 1998  64  0  343.
> > 1998  65  0  330.
> > 1998  66  0  317.
> > 1998  67  0  296.
> > 1998  68  0  282.
> > 1998  69  0  404.
> > 1998  70  0  530.
> > 1998  71  0  525.
> > 1998  72  0  484.
> > 1998  73  0  430.
> > 1998  74  0  388.
> > 1998  75  0  347.
> > 1998  76  0  337.
> > 1998  77  0  342.
> > 1998  78  0  305.
> > 1998  79  0  329.
> > 1998  80  0  420.
> > 1998  81  0  564.
> > 1998  82  0  483.
> > 1998  83  0  385.
> > 1998  84  0  393.
> > 1998  85  0  437.
> > 1998  86  0  441.
> > 1998  87  0  434.
> > 1998  88  0  471.
> > 1998  89  0  429.
> > 1998  90  0  412.
> > 1998  91  0  370.
> > 1998  92  0  326.
> > 1998  93  0  357.
> > 1998  94  0  338.
> > 1998  95  0  380.
> > 1998  96  0  339.
> > 1998  97  0  312.
> > 1998  98  0  313.
> > 1998  99  0  327.
> > 1998 100  0  362.
> > 1998 101  0  358.
> > 1998 102  0  387.
> > 1998 103  0  397.
> > 1998 104  0  375.
> > 1998 105  0  350.
> > 1998 106  0  357.
> > 1998 107  0  472.
> > 1998 108  0  526.
> > 1998 109  0  396.
> > 1998 110  0  374.
> > 1998 111  0  376.
> > 1998 112  0  355.
> > 1998 113  0  343.
> > 1998 114  0  425.
> > 1998 115  0  426.
> > 1998 116  0  479.
> > 1998 117  0  469.
> > 1998 118  0  425.
> > 1998 119  0  344.
> > 1998 120  0  341.
> > 1998 121  0  426.
> > 1998 122  0  601.
> > 1998 123  0  476.
> > 1998 124  0  670.
> > 1998 125  0  585.
> > 1998 126  0  496.
> > 1998 127  0  479.
> > 1998 128  0  569.
> > 1998 129  0  531.
> > 1998 130  0  489.
> > 1998 131  0  484.
> > 1998 132  0  480.
> > 1998 133  0  393.
> > 1998 134  0  332.
> > 1998 135  0  327.
> > 1998 136  0  493.
> > 1998 137  0  493.
> > 1998 138  0  430.
> > 1998 139  0  396.
> > 1998 140  0  408.
> > 1998 141  0  416.
> > 1998 142  0  376.
> > 1998 143  0  375.
> > 1998 144  0  415.
> > 1998 145  0  407.
> > 1998 146  0  398.
> > 1998 147  0  352.
> > 1998 148  0  349.
> > 1998 149  0  517.
> > 1998 150  0  597.
> > 1998 151  0  480.
> > 1998 152  0  435.
> > 1998 153  0  408.
> > 1998 154  0  441.
> > 1998 155  0  397.
> > 1998 156  0  374.
> > 1998 157  0  413.
> > 1998 158  0  582.
> > 1998 159  0  513.
> > 1998 160  0  459.
> > 1998 161  0  466.
> > 1998 162  0  414.
> > 1998 163  0  354.
> > 1998 164  0  341.
> > 1998 165  0  343.
> > 1998 166  0  369.
> > 1998 167  0  411.
> > 1998 168  0  355.
> > Thanks
> > Jibrin
> >
> > On Fri, Jan 15, 2021 at 7:15 PM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     No dataset was attached. Like the posting guide says,
> >
> >     No binary attachments except for PS, PDF, and some image and archive
> >     formats (others are automatically stripped off because they can
> contain
> >     malicious software). Files in other formats and larger ones should
> >     rather be put on the web and have only their URLs posted. This way a
> >     reader has the option to download them or not.
> >
> >
> >     Can you post sample data? Please post the output of `dput(df)`. Or,
> if
> >     it is too big the output of `dput(head(df, 20))`. (`df` is the name
> of
> >     your dataset.)
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >     ?s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
> >      > Dear R users,
> >      > I am very new to R software. I have solar wind speed data needed
> >     for my
> >      > work. How do I convert day in the year to year, month, and day
> with R
> >      > software? I have used this code
> >      > as.Date(0, origin = "1998-01-01")
> >      > but it can only convert one day of the year at a time. Meanwhile,
> >     I have up
> >      > to the 1998-2002 data set. Attached is my data.
> >      > Kindly help, please.
> >      > Jibrin Alhassan
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >      > and provide commented, minimal, self-contained, reproducible code.
> >      >
> >
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jan 17 19:04:37 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 17 Jan 2021 10:04:37 -0800
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAEGeL+HOZT_AzYS1cVB9wGC7OFvH7EM=U_n02y-sP1HZFs02wg@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
 <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
 <fc104a3c-6d2f-062a-d79e-42ec7c7811b3@sapo.pt>
 <CAEGeL+HOZT_AzYS1cVB9wGC7OFvH7EM=U_n02y-sP1HZFs02wg@mail.gmail.com>
Message-ID: <97590CFB-BF19-4751-9562-829FC373C2ED@dcn.davis.ca.us>

This is an opportunity for you to think for yourself (r-help) instead of expecting solutions neatly wrapped and delivered (r-do-my-work-for-me). Remove the no-longer-needed columns once the desired columns are available.

On January 17, 2021 7:12:28 AM PST, Jibrin Alhassan <jibrin.alhassan at unn.edu.ng> wrote:
>Hi Barradas,
>Thanks for your assistance. It has brought me closer to what I am
>looking
>for. I tried your code as shown below:
>> df1 <- read.table("SWSdata_1998_2002", header = TRUE)
>> df1$date <- as.Date(paste(df1$year, df1$day),format = "%Y %j",origin
>=
>"1998-01-01")
>> head(df1)
>  year day Hr SWS       date
>1 1998   1  0 344 1998-01-01
>2 1998   2  0 346 1998-01-02
>3 1998   3  0 356 1998-01-03
>4 1998   4  0 332 1998-01-04
>5 1998   5  0 302 1998-01-05
>6 1998   6  0 329 1998-01-06
>What I need is the last two columns only (SWS, date). The first 3
>columns
>(year, day Hr should go). Your code produced only 6 datasets. My
>dataset is
>1,826 from 1998 to 2002. How do I generate this at once?
>Many many thanks for your time. I have pasted below a section of my
>dataset
>for your guidance, please.
>Jibrin
>year   day Hr SWS
>1998   1  0  344.
>1998   2  0  346.
>1998   3  0  356.
>1998   4  0  332.
>1998   5  0  302.
>1998   6  0  329.
>1998   7  0  395.
>1998   8  0  359.
>1998   9  0  471.
>1998  10  0  392.
>1998  11  0  346.
>1998  12  0  387.
>1998  13  0  393.
>1998  14  0  367.
>1998  15  0  320.
>1998  16  0  309.
>1998  17  0  341.
>1998  18  0  329.
>1998  19  0  322.
>1998  20  0  429.
>1998  21  0  433.
>1998  22  0  398.
>1998  23  0  393.
>1998  24  0  393.
>1998  25  0  423.
>1998  26  0  426.
>1998  27  0  429.
>1998  28  0  386.
>1998  29  0  381.
>1998  30  0  375.
>1998  31  0  365.
>1998  32  0  450.
>1998  33  0  381.
>1998  34  0  316.
>1998  35  0  351.
>1998  36  0  306.
>1998  37  0  312.
>1998  38  0  320.
>1998  39  0  339.
>1998  40  0  395.
>1998  41  0  429.
>1998  42  0  479.
>1998  43  0  495.
>1998  44  0  407.
>1998  45  0  358.
>1998  46  0  360.
>1998  47  0  382.
>1998  48  0  394.
>1998  49  0  393.
>1998  50  0  435.
>1998  51  0  408.
>1998  52  0  360.
>1998  53  0  372.
>1998  54  0  376.
>1998  55  0  379.
>1998  56  0  361.
>1998  57  0  333.
>1998  58  0  321.
>1998  59  0  344.
>1998  60  0  412.
>1998  61  0  428.
>1998  62  0  401.
>1998  63  0  369.
>1998  64  0  343.
>1998  65  0  330.
>1998  66  0  317.
>1998  67  0  296.
>1998  68  0  282.
>1998  69  0  404.
>1998  70  0  530.
>1998  71  0  525.
>1998  72  0  484.
>1998  73  0  430.
>1998  74  0  388.
>1998  75  0  347.
>1998  76  0  337.
>1998  77  0  342.
>1998  78  0  305.
>1998  79  0  329.
>1998  80  0  420.
>1998  81  0  564.
>1998  82  0  483.
>1998  83  0  385.
>1998  84  0  393.
>1998  85  0  437.
>1998  86  0  441.
>1998  87  0  434.
>1998  88  0  471.
>1998  89  0  429.
>1998  90  0  412.
>1998  91  0  370.
>1998  92  0  326.
>1998  93  0  357.
>1998  94  0  338.
>1998  95  0  380.
>1998  96  0  339.
>1998  97  0  312.
>1998  98  0  313.
>1998  99  0  327.
>1998 100  0  362.
>1998 101  0  358.
>1998 102  0  387.
>1998 103  0  397.
>1998 104  0  375.
>1998 105  0  350.
>1998 106  0  357.
>1998 107  0  472.
>1998 108  0  526.
>1998 109  0  396.
>1998 110  0  374.
>1998 111  0  376.
>1998 112  0  355.
>1998 113  0  343.
>1998 114  0  425.
>1998 115  0  426.
>1998 116  0  479.
>1998 117  0  469.
>1998 118  0  425.
>1998 119  0  344.
>1998 120  0  341.
>1998 121  0  426.
>1998 122  0  601.
>1998 123  0  476.
>1998 124  0  670.
>1998 125  0  585.
>1998 126  0  496.
>1998 127  0  479.
>1998 128  0  569.
>1998 129  0  531.
>1998 130  0  489.
>1998 131  0  484.
>1998 132  0  480.
>1998 133  0  393.
>1998 134  0  332.
>1998 135  0  327.
>1998 136  0  493.
>1998 137  0  493.
>1998 138  0  430.
>1998 139  0  396.
>1998 140  0  408.
>1998 141  0  416.
>1998 142  0  376.
>1998 143  0  375.
>1998 144  0  415.
>1998 145  0  407.
>1998 146  0  398.
>1998 147  0  352.
>1998 148  0  349.
>1998 149  0  517.
>1998 150  0  597.
>1998 151  0  480.
>1998 152  0  435.
>1998 153  0  408.
>1998 154  0  441.
>1998 155  0  397.
>1998 156  0  374.
>1998 157  0  413.
>1998 158  0  582.
>1998 159  0  513.
>1998 160  0  459.
>1998 161  0  466.
>1998 162  0  414.
>1998 163  0  354.
>1998 164  0  341.
>1998 165  0  343.
>1998 166  0  369.
>1998 167  0  411.
>1998 168  0  355.
>1998 169  0  333.
>1998 170  0  443.
>1998 171  0  426.
>1998 172  0  419.
>1998 173  0  404.
>1998 174  0  387.
>1998 175  0  460.
>1998 176  0  447.
>1998 177  0  469.
>1998 178  0  447.
>1998 179  0  389.
>1998 180  0  375.
>1998 181  0  354.
>1998 182  0  316.
>1998 183  0  369.
>1998 184  0  410.
>1998 185  0  406.
>1998 186  0  477.
>1998 187  0  583.
>1998 188  0  458.
>1998 189  0  386.
>1998 190  0  342.
>1998 191  0  333.
>1998 192  0  369.
>1998 193  0  406.
>1998 194  0  375.
>1998 195  0  332.
>1998 196  0  310.
>1998 197  0  528.
>1998 198  0  530.
>1998 199  0  387.
>1998 200  0  385.
>1998 201  0  349.
>1998 202  0  409.
>1998 203  0  399.
>1998 204  0  619.
>1998 205  0  658.
>1998 206  0  581.
>1998 207  0  445.
>1998 208  0  370.
>1998 209  0  326.
>1998 210  0  334.
>1998 211  0  384.
>1998 212  0  423.
>1998 213  0  412.
>1998 214  0  404.
>1998 215  0  370.
>1998 216  0  384.
>1998 217  0  383.
>1998 218  0  378.
>1998 219  0  461.
>1998 220  0  460.
>1998 221  0  400.
>1998 222  0  447.
>1998 223  0  373.
>1998 224  0  379.
>1998 225  0  374.
>1998 226  0  374.
>1998 227  0  391.
>1998 228  0  348.
>1998 229  0  303.
>1998 230  0  279.
>1998 231  0  312.
>1998 232  0  331.
>1998 233  0  298.
>1998 234  0  341.
>1998 235  0  493.
>1998 236  0  436.
>1998 237  0  400.
>1998 238  0  633.
>1998 239  0  630.
>1998 240  0  583.
>1998 241  0  547.
>1998 242  0  550.
>1998 243  0  499.
>1998 244  0  444.
>1998 245  0  427.
>1998 246  0  401.
>
>On Sat, Jan 16, 2021 at 8:01 AM Rui Barradas <ruipbarradas at sapo.pt>
>wrote:
>
>> Hello,
>>
>> Thanks for the data, it makes things easier.
>>
>> df1 <- read.table("Jibrin_data.txt", header = TRUE)
>> #'data.frame':  168 obs. of  4 variables:
>> # $ year: int  1998 1998 1998 1998 1998 1998 1998 1998 1998 1998 ...
>> # $ day : int  1 2 3 4 5 6 7 8 9 10 ...
>> # $ Hr  : int  0 0 0 0 0 0 0 0 0 0 ...
>> # $ SWS : num  344 346 356 332 302 329 395 359 471 392 ...
>>
>> Here is a simple way of converting the year and day of year columns
>to a
>> column of class "Date".
>> Like others have said, there are also CRAN packages to handle
>date/time
>> data, my favorite being package lubridate, but base R can do it.
>>
>>
>> df1$date <- as.Date(paste(df1$year, df1$day),
>>                      format = "%Y %j",
>>                      origin = "1998-01-01")
>>
>> head(df1)
>> #  year day Hr SWS       date
>> #1 1998   1  0 344 1998-01-01
>> #2 1998   2  0 346 1998-01-02
>> #3 1998   3  0 356 1998-01-03
>> #4 1998   4  0 332 1998-01-04
>> #5 1998   5  0 302 1998-01-05
>> #6 1998   6  0 329 1998-01-06
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> ?s 06:48 de 16/01/21, Jibrin Alhassan escreveu:
>> > Hi Barradas
>> >   Sorry for the delay. Below is a section of my data. I have up to
>1826
>> > covering 1998 to 2002
>> > year   day Hr SWS
>> > 1998   1  0  344.
>> > 1998   2  0  346.
>> > 1998   3  0  356.
>> > 1998   4  0  332.
>> > 1998   5  0  302.
>> > 1998   6  0  329.
>> > 1998   7  0  395.
>> > 1998   8  0  359.
>> > 1998   9  0  471.
>> > 1998  10  0  392.
>> > 1998  11  0  346.
>> > 1998  12  0  387.
>> > 1998  13  0  393.
>> > 1998  14  0  367.
>> > 1998  15  0  320.
>> > 1998  16  0  309.
>> > 1998  17  0  341.
>> > 1998  18  0  329.
>> > 1998  19  0  322.
>> > 1998  20  0  429.
>> > 1998  21  0  433.
>> > 1998  22  0  398.
>> > 1998  23  0  393.
>> > 1998  24  0  393.
>> > 1998  25  0  423.
>> > 1998  26  0  426.
>> > 1998  27  0  429.
>> > 1998  28  0  386.
>> > 1998  29  0  381.
>> > 1998  30  0  375.
>> > 1998  31  0  365.
>> > 1998  32  0  450.
>> > 1998  33  0  381.
>> > 1998  34  0  316.
>> > 1998  35  0  351.
>> > 1998  36  0  306.
>> > 1998  37  0  312.
>> > 1998  38  0  320.
>> > 1998  39  0  339.
>> > 1998  40  0  395.
>> > 1998  41  0  429.
>> > 1998  42  0  479.
>> > 1998  43  0  495.
>> > 1998  44  0  407.
>> > 1998  45  0  358.
>> > 1998  46  0  360.
>> > 1998  47  0  382.
>> > 1998  48  0  394.
>> > 1998  49  0  393.
>> > 1998  50  0  435.
>> > 1998  51  0  408.
>> > 1998  52  0  360.
>> > 1998  53  0  372.
>> > 1998  54  0  376.
>> > 1998  55  0  379.
>> > 1998  56  0  361.
>> > 1998  57  0  333.
>> > 1998  58  0  321.
>> > 1998  59  0  344.
>> > 1998  60  0  412.
>> > 1998  61  0  428.
>> > 1998  62  0  401.
>> > 1998  63  0  369.
>> > 1998  64  0  343.
>> > 1998  65  0  330.
>> > 1998  66  0  317.
>> > 1998  67  0  296.
>> > 1998  68  0  282.
>> > 1998  69  0  404.
>> > 1998  70  0  530.
>> > 1998  71  0  525.
>> > 1998  72  0  484.
>> > 1998  73  0  430.
>> > 1998  74  0  388.
>> > 1998  75  0  347.
>> > 1998  76  0  337.
>> > 1998  77  0  342.
>> > 1998  78  0  305.
>> > 1998  79  0  329.
>> > 1998  80  0  420.
>> > 1998  81  0  564.
>> > 1998  82  0  483.
>> > 1998  83  0  385.
>> > 1998  84  0  393.
>> > 1998  85  0  437.
>> > 1998  86  0  441.
>> > 1998  87  0  434.
>> > 1998  88  0  471.
>> > 1998  89  0  429.
>> > 1998  90  0  412.
>> > 1998  91  0  370.
>> > 1998  92  0  326.
>> > 1998  93  0  357.
>> > 1998  94  0  338.
>> > 1998  95  0  380.
>> > 1998  96  0  339.
>> > 1998  97  0  312.
>> > 1998  98  0  313.
>> > 1998  99  0  327.
>> > 1998 100  0  362.
>> > 1998 101  0  358.
>> > 1998 102  0  387.
>> > 1998 103  0  397.
>> > 1998 104  0  375.
>> > 1998 105  0  350.
>> > 1998 106  0  357.
>> > 1998 107  0  472.
>> > 1998 108  0  526.
>> > 1998 109  0  396.
>> > 1998 110  0  374.
>> > 1998 111  0  376.
>> > 1998 112  0  355.
>> > 1998 113  0  343.
>> > 1998 114  0  425.
>> > 1998 115  0  426.
>> > 1998 116  0  479.
>> > 1998 117  0  469.
>> > 1998 118  0  425.
>> > 1998 119  0  344.
>> > 1998 120  0  341.
>> > 1998 121  0  426.
>> > 1998 122  0  601.
>> > 1998 123  0  476.
>> > 1998 124  0  670.
>> > 1998 125  0  585.
>> > 1998 126  0  496.
>> > 1998 127  0  479.
>> > 1998 128  0  569.
>> > 1998 129  0  531.
>> > 1998 130  0  489.
>> > 1998 131  0  484.
>> > 1998 132  0  480.
>> > 1998 133  0  393.
>> > 1998 134  0  332.
>> > 1998 135  0  327.
>> > 1998 136  0  493.
>> > 1998 137  0  493.
>> > 1998 138  0  430.
>> > 1998 139  0  396.
>> > 1998 140  0  408.
>> > 1998 141  0  416.
>> > 1998 142  0  376.
>> > 1998 143  0  375.
>> > 1998 144  0  415.
>> > 1998 145  0  407.
>> > 1998 146  0  398.
>> > 1998 147  0  352.
>> > 1998 148  0  349.
>> > 1998 149  0  517.
>> > 1998 150  0  597.
>> > 1998 151  0  480.
>> > 1998 152  0  435.
>> > 1998 153  0  408.
>> > 1998 154  0  441.
>> > 1998 155  0  397.
>> > 1998 156  0  374.
>> > 1998 157  0  413.
>> > 1998 158  0  582.
>> > 1998 159  0  513.
>> > 1998 160  0  459.
>> > 1998 161  0  466.
>> > 1998 162  0  414.
>> > 1998 163  0  354.
>> > 1998 164  0  341.
>> > 1998 165  0  343.
>> > 1998 166  0  369.
>> > 1998 167  0  411.
>> > 1998 168  0  355.
>> > Thanks
>> > Jibrin
>> >
>> > On Fri, Jan 15, 2021 at 7:15 PM Rui Barradas <ruipbarradas at sapo.pt
>> > <mailto:ruipbarradas at sapo.pt>> wrote:
>> >
>> >     Hello,
>> >
>> >     No dataset was attached. Like the posting guide says,
>> >
>> >     No binary attachments except for PS, PDF, and some image and
>archive
>> >     formats (others are automatically stripped off because they can
>> contain
>> >     malicious software). Files in other formats and larger ones
>should
>> >     rather be put on the web and have only their URLs posted. This
>way a
>> >     reader has the option to download them or not.
>> >
>> >
>> >     Can you post sample data? Please post the output of `dput(df)`.
>Or,
>> if
>> >     it is too big the output of `dput(head(df, 20))`. (`df` is the
>name
>> of
>> >     your dataset.)
>> >
>> >     Hope this helps,
>> >
>> >     Rui Barradas
>> >
>> >     ?s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
>> >      > Dear R users,
>> >      > I am very new to R software. I have solar wind speed data
>needed
>> >     for my
>> >      > work. How do I convert day in the year to year, month, and
>day
>> with R
>> >      > software? I have used this code
>> >      > as.Date(0, origin = "1998-01-01")
>> >      > but it can only convert one day of the year at a time.
>Meanwhile,
>> >     I have up
>> >      > to the 1998-2002 data set. Attached is my data.
>> >      > Kindly help, please.
>> >      > Jibrin Alhassan
>> >      > ______________________________________________
>> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>list
>> >     -- To UNSUBSCRIBE and more, see
>> >      > https://stat.ethz.ch/mailman/listinfo/r-help
>> >      > PLEASE do read the posting guide
>> >     http://www.R-project.org/posting-guide.html
>> >      > and provide commented, minimal, self-contained, reproducible
>code.
>> >      >
>> >
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun Jan 17 21:08:30 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 17 Jan 2021 20:08:30 +0000 (UTC)
Subject: [R] Error in UseMethod("predict")
In-Reply-To: <CAGgJW774d-LkJJP-ZxYH8ynNdgvZMuQkzZRzuTVotqDwuZ_81g@mail.gmail.com>
References: <1991372792.4918972.1610878767028.ref@mail.yahoo.com>
 <1991372792.4918972.1610878767028@mail.yahoo.com>
 <CAGgJW75aPdXvbr8GRhqivvgZE5Ct2TnBx2H7hFpLRE30rDzHFA@mail.gmail.com>
 <1101877080.256550.1610889746695@mail.yahoo.com>
 <CAGgJW774d-LkJJP-ZxYH8ynNdgvZMuQkzZRzuTVotqDwuZ_81g@mail.gmail.com>
Message-ID: <298840224.266376.1610914110122@mail.yahoo.com>

Eric,

No problem. Let's see if somebody else has a solution. I have changed the smooth basis from P-splines ('ps') to thin plate ('tp'). It still does not work, but this time I get another error message.


##########################
#Data
y=c(34000,45000,19000,48900,65000,67000,78000,90000,51000,32000,54000,85000,38000,76345,87654,90990,78654,67894,56789,65432,18998,78987,67543,45678,76543,67876)
x=c(345,543,543,456,432,378,543,579,432,254,346,564,611,543,542,632,345,468,476,487,453,356,490,499,567,532)

Dataset=data.frame(y,x)

#Plot
plot(x,y)

#Robust GAM
library(robustgam)
true.family <- poisson()
fit=robustgam(x,y, sp=2424,family=true.family,smooth.basis='tp')
x.new <- seq(range(x)[1], range(x)[2])
robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
lines(x.new, robustfit.new, col="green", lwd=2)

# To find the ? sp ? to include in the fit function here above
robustfit.gic<-robustgam.GIC.optim(x,y,family=true.family,p=3,c=1.6,show.msg=FALSE,smooth.basis="ps", method="L-BFGS-B")

## CROSS VALIDATION REPLICATIONS MSE ROBUST GAM

# Create a list to store the results
lst<-list()

# This statement does the repetitions (looping)
for(i in 1 :1000)
{

n=dim(Dataset)[1]
p=0.667
sam=sample(1 :n,floor(p*n),replace=FALSE)
Training =Dataset [sam,]
Testing = Dataset [-sam,]

fit18<-robustgam(x,y, sp=2424,family=true.family,smooth.basis='tp')

ypred=pred.robustgam(fit18,data.frame(X=Testing))
MSE = mean((y-ypred)^2)
MSE
lst[i]<-MSE
}
mean(unlist(lst))
####################################





Le dimanche 17 janvier 2021 ? 15:02:45 UTC+1, Eric Berger <ericjberger at gmail.com> a ?crit : 





Hi Sacha,?
I took a quick look. Sorry, I don't see immediately what is causing the problem.
Maybe someone else can help.



> Dear Eric,
> 
> Many thanks, I correct your 2 points and now I get another error message (Error in splineDesign(knots, x, ord, derivs, outer.ok = outer.ok, sparse = sparse) :
> ? empty 'derivs'). 
> I have googleized and found some hints like (outer.ok=TRUE) but no one seems to work.
> 
> https://r.789695.n4.nabble.com/mgcv-gam-predict-problem-td3411006.html 
> 
> Any idea to make my code work would be appreciated.
> 
> Here below my new R code :
> 
> ##########################
> #Data
> y=c(34000,45000,19000,48900,65000,67000,78000,90000,51000,32000,54000,85000,38000,76345,87654,90990,78654,67894,56789,65432,18998,78987,67543,45678,76543,67876)
> x=c(345,543,543,456,432,378,543,579,432,254,346,564,611,543,542,632,345,468,476,487,453,356,490,499,567,532)
> 
> Dataset=data.frame(y,x)
> 
> #Plot
> plot(x,y)
> 
> #Robust GAM
> library(robustgam)
> true.family <- poisson()
> fit=robustgam(x,y, sp=2424,family=true.family,smooth.basis='ps',K=3)
> x.new <- seq(range(x)[1], range(x)[2])
> robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
> lines(x.new, robustfit.new, col="green", lwd=2)
> 
> # To find the ??sp?? to include in the fit function here above
> robustfit.gic<-robustgam.GIC.optim(x,y,family=true.family,p=3,c=1.6,show.msg=FALSE,smooth.basis="ps", method="L-BFGS-B")
> 
> ## CROSS VALIDATION REPLICATIONS MSE ROBUST GAM
> install.packages("ISLR")
> library(ISLR)
> 
> # Create a list to store the results
> lst<-list()
> 
> # This statement does the repetitions (looping)
> for(i in 1?:1000)
> {
> 
> n=dim(Dataset)[1]
> p=0.667
> sam=sample(1?:n,floor(p*n),replace=FALSE)
> Training =Dataset [sam,]
> Testing = Dataset [-sam,] 
> 
> fit18<-robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
> 
> ypred=pred.robustgam(fit18,data.frame(X=Testing))
> MSE = mean((y-ypred)^2)
> MSE
> lst[i]<-MSE
> }
> mean(unlist(lst))
> ####################################
> 
> 
> 
> ?Le dimanche 17 janvier 2021 ? 11:41:49 UTC+1, Eric Berger <ericjberger at gmail.com> a ?crit : 
> 
> 
> Hi Sacha,
> I never used these packages before but I installed them and tried your code. I have a few observations that may help.
> 
> 1. the statement
> ? ? ypred = predict(fit18,newdata=Testing)
> ? ? is wrong. Checkout the help page (?robustgam)? which shows in the Examples section at the bottom to use something like
> ? ? ypred = pred.robustgam( fit18, data.frame(X=Testing)
> 
> 2. your logic is wrong. You define the vectors x and y at the top. They should?remain untouched during your program.
> ? ? However in the loop you redefine y and then use the redefined y as an argument to robustgam() the next time through
> ? ? the loop. This looks like a serious error.
> 
> HTH,
> Eric
> 
> 
> On Sun, Jan 17, 2021 at 12:20 PM varin sacha via R-help <r-help at r-project.org> wrote:
>> Dear R-experts,
>> 
>> Here below my reproducible R code. I get an error message (end of code) I can't solve.
>> Many thanks for your help.
>> 
>> ##########################
>> #Data
>> y=c(34000,45000,19000,48900,65000,67000,78000,90000,51000,32000,54000,85000,38000,76345,87654,90990,78654,67894,56789,65432,18998,78987,67543,45678,76543,67876)
>> x=c(345,543,543,456,432,378,543,579,432,254,346,564,611,543,542,632,345,468,476,487,453,356,490,499,567,532)
>> 
>> Dataset=data.frame(y,x)
>> 
>> #Plot
>> plot(x,y)
>> 
>> #Robust GAM
>> library(robustgam)
>> true.family <- poisson()
>> fit=robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
>> x.new <- seq(range(x)[1], range(x)[2])
>> robustfit.new <- pred.robustgam(fit, data.frame(X=x.new))$predict.values
>> lines(x.new, robustfit.new, col="green", lwd=2)
>> 
>> # To find the ??sp?? to include in the fit function here above
>> robustfit.gic<-robustgam.GIC.optim(x,y,family=true.family,p=3,c=1.6,show.msg=FALSE,smooth.basis="tp", method="L-BFGS-B")
>> 
>> ## CROSS VALIDATION REPLICATIONS MSE ROBUST GAM
>> install.packages("ISLR")
>> library(ISLR)
>> 
>> # Create a list to store the results
>> lst<-list()
>> 
>> # This statement does the repetitions (looping)
>> for(i in 1?:1000)
>> {
>> 
>> n=dim(Dataset)[1]
>> p=0.667
>> sam=sample(1?:n,floor(p*n),replace=FALSE)
>> Training =Dataset [sam,]
>> Testing = Dataset [-sam,]
>> 
>> fit18<-robustgam(x,y, sp=4356,family=true.family,smooth.basis='ps',K=3)
>> 
>> ypred=predict(fit18,newdata=Testing)
>> y=Dataset[-sam,]$y
>> MSE = mean((y-ypred)^2)
>> MSE
>> lst[i]<-MSE
>> }
>> mean(unlist(lst))
>> ####################################
>> ?
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Sun Jan 17 21:15:38 2021
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard McGarvey)
Date: Sun, 17 Jan 2021 15:15:38 -0500 (EST)
Subject: [R] Summarizing select columns in a data frame
Message-ID: <1191259992.151759.1610914538690@connect.xfinity.com>

I have a data frame that consists of several factor columns say A, B, C, D, and E and several columns containing numerical data, say X1, X2, .... X10. I would like to create statistics of some of the numerical columns by some of the factor columns. For example,

Calculate the mean, min, and max of variables X1 and X7, by factors A, and E. The results should look like the table below:

Factor A Factor E     mean(X1) min(x1) max(X1) mean(X7) min(x7) max(X7) mean(X10) min(x10) max(X10)
A1        E1
A1        E2
A1        E3
A2        E1
A2        E2
A2        E3

I would like the results to be returned to a data frame or other object that I can write out using the write.csv function. I have looked at the summarize and numSummary functions but they do not appear to be flexible enough to do the above.

Any help would be appreciated,

Thanks

Bernard McGarvey
Director, Fort Myers Beach Lions Foundation, Inc.
Retired (Lilly Engineering Fellow).


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jan 17 21:48:35 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 17 Jan 2021 12:48:35 -0800
Subject: [R] Summarizing select columns in a data frame
In-Reply-To: <1191259992.151759.1610914538690@connect.xfinity.com>
References: <1191259992.151759.1610914538690@connect.xfinity.com>
Message-ID: <CAGxFJbRjJuTyGbfSP6JNhrt81U4XBONmr8FtOggv2U-z3UCNTg@mail.gmail.com>

There are literally tons of ways to do this sort of thing in R.

In base R ?tapply and friends, especially ?ave and ?by that may be close to
what you want.
But there is a whole parallel universe -- the so-called "tidyverse set of
packages -- that many folks prefer.
This link takes you down that rabbit hole: https://dplyr.tidyverse.org/

There are still others (e.g. the data.table package). You should expect to
invest a little time in learning whichever you choose. You may wish to also
search a bit for tutorials on your choice -- there are many good ones out
there.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 17, 2021 at 12:18 PM Bernard McGarvey <
mcgarvey.bernard at comcast.net> wrote:

> I have a data frame that consists of several factor columns say A, B, C,
> D, and E and several columns containing numerical data, say X1, X2, ....
> X10. I would like to create statistics of some of the numerical columns by
> some of the factor columns. For example,
>
> Calculate the mean, min, and max of variables X1 and X7, by factors A, and
> E. The results should look like the table below:
>
> Factor A Factor E     mean(X1) min(x1) max(X1) mean(X7) min(x7) max(X7)
> mean(X10) min(x10) max(X10)
> A1        E1
> A1        E2
> A1        E3
> A2        E1
> A2        E2
> A2        E3
>
> I would like the results to be returned to a data frame or other object
> that I can write out using the write.csv function. I have looked at the
> summarize and numSummary functions but they do not appear to be flexible
> enough to do the above.
>
> Any help would be appreciated,
>
> Thanks
>
> Bernard McGarvey
> Director, Fort Myers Beach Lions Foundation, Inc.
> Retired (Lilly Engineering Fellow).
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@edehk205 @end|ng |rom gm@||@com  Sun Jan 17 12:10:48 2021
From: m@edehk205 @end|ng |rom gm@||@com (Maedeh Kamali)
Date: Sun, 17 Jan 2021 19:10:48 +0800
Subject: [R] A question regarding 749 R[21525:2855847] Warning
In-Reply-To: <3A8F43E8-118D-423F-84CB-D83C7F1F1919@me.com>
References: <2EC1A46E-0A8A-4CB7-8C22-69D20DD59A28@gmail.com>
 <3A8F43E8-118D-423F-84CB-D83C7F1F1919@me.com>
Message-ID: <CAMN+Yrdhi16XrzrpcPmuNa2FfmymM7QbdKGvTg6xr_NsWcbyLg@mail.gmail.com>

Dear Gregory Coast,

Thanks for your reply.
I searched so much regarding how to fix this problem. Unfortunately, it
stems from Bug Sur 11.0.1 and we should wait for its new version in which
the problem has been fixed.

Best,
Maedeh Kamali

On Sat, 16 Jan 2021, 08:18 Gregory Coats, <gregcoats at me.com> wrote:

> I reported this behavior on Thu Jan 7, 2021.
> You did nothing wrong.
> No fix has been issued.
>
> This evening, I upgraded from R 4.0.2 to the Duke University R 4.0.3 for
> Apple Mac. Now all I can get from R 4.0.3 is this red error message (that
> means nothing to me). Is there an easy fix? Greg
>
> 2021-01-07 22:58:42.997 R[8311:37566]
> Warning: Expected min height of view:
> (<NSPopoverTouchBarItemButton: 0x7fcb6c592570>)
> to be less than or equal to 30 but got a height of 32.000000. This error
> will be logged once per view in violation.
>
> On Jan 14, 2021, at 11:28 PM, maedeh kamali <maedehk205 at gmail.com> wrote:
>
> Dear Sir/Madam,
>
> After installing R package version 4.0.3 and launching the R Console for
> the first time, below warning message appeared:
>
> 021-01-15 11:52:28.749 R[21525:2855847] Warning: Expected min height of
> view: (<NSPopoverTouchBarItemButton: 0x7fdae3418d80>) to be less than or
> equal to 30 but got a height of 32.000000. This error will be logged once
> per view in violation.
>
> Could you please guide me how to fix it.
>
> Best,
> Maedeh KAMALI
> [[alternative HTML version deleted]]
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Sun Jan 17 22:21:44 2021
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Sun, 17 Jan 2021 16:21:44 -0500
Subject: [R] Summarizing select columns in a data frame
In-Reply-To: <CAGxFJbRjJuTyGbfSP6JNhrt81U4XBONmr8FtOggv2U-z3UCNTg@mail.gmail.com>
References: <CAGxFJbRjJuTyGbfSP6JNhrt81U4XBONmr8FtOggv2U-z3UCNTg@mail.gmail.com>
Message-ID: <0B49DFD2-B0EB-4EA1-B406-AA81B471B8D1@comcast.net>

Thanks Bert

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Jan 17, 2021, at 3:48 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ?
> There are literally tons of ways to do this sort of thing in R.
> 
> In base R ?tapply and friends, especially ?ave and ?by that may be close to what you want.
> But there is a whole parallel universe -- the so-called "tidyverse set of packages -- that many folks prefer.
> This link takes you down that rabbit hole: https://dplyr.tidyverse.org/
> 
> There are still others (e.g. the data.table package). You should expect to invest a little time in learning whichever you choose. You may wish to also search a bit for tutorials on your choice -- there are many good ones out there.
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
>> On Sun, Jan 17, 2021 at 12:18 PM Bernard McGarvey <mcgarvey.bernard at comcast.net> wrote:
>> I have a data frame that consists of several factor columns say A, B, C, D, and E and several columns containing numerical data, say X1, X2, .... X10. I would like to create statistics of some of the numerical columns by some of the factor columns. For example,
>> 
>> Calculate the mean, min, and max of variables X1 and X7, by factors A, and E. The results should look like the table below:
>> 
>> Factor A Factor E     mean(X1) min(x1) max(X1) mean(X7) min(x7) max(X7) mean(X10) min(x10) max(X10)
>> A1        E1
>> A1        E2
>> A1        E3
>> A2        E1
>> A2        E2
>> A2        E3
>> 
>> I would like the results to be returned to a data frame or other object that I can write out using the write.csv function. I have looked at the summarize and numSummary functions but they do not appear to be flexible enough to do the above.
>> 
>> Any help would be appreciated,
>> 
>> Thanks
>> 
>> Bernard McGarvey
>> Director, Fort Myers Beach Lions Foundation, Inc.
>> Retired (Lilly Engineering Fellow).
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sun Jan 17 22:28:37 2021
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sun, 17 Jan 2021 22:28:37 +0100
Subject: [R] How can we get median MAE in caret
Message-ID: <CA+nrPnvEbJqN68ONU-iCmE0wDGvtkMsmq3FfUDN7r9Ka7FCS2Q@mail.gmail.com>

Hi, If I am using caret and MAE metric, how can we get median of MAE in
easy manner.

cart <-train(Result ~ ., data = tr,
method = "rf",
metric = "MAE",
preProc = c("center", "scale", "nzv"),
trControl = ctr)

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jan 17 23:59:20 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 17 Jan 2021 14:59:20 -0800
Subject: [R] Summarizing select columns in a data frame
In-Reply-To: <1191259992.151759.1610914538690@connect.xfinity.com>
References: <1191259992.151759.1610914538690@connect.xfinity.com>
Message-ID: <6b7ee99a-a952-972a-3135-2f1596fcbf0f@comcast.net>


On 1/17/21 12:15 PM, Bernard McGarvey wrote:
> I have a data frame that consists of several factor columns say A, B, C, D, and E and several columns containing numerical data, say X1, X2, .... X10. I would like to create statistics of some of the numerical columns by some of the factor columns. For example,
>
> Calculate the mean, min, and max of variables X1 and X7, by factors A, and E. The results should look like the table below:
>
> Factor A Factor E     mean(X1) min(x1) max(X1) mean(X7) min(x7) max(X7) mean(X10) min(x10) max(X10)
> A1        E1
> A1        E2
> A1        E3
> A2        E1
> A2        E2
> A2        E3
>
> I would like the results to be returned to a data frame or other object that I can write out using the write.csv function. I have looked at the summarize and numSummary functions but they do not appear to be flexible enough to do the above.


The `aggregate` function will do the subsetting and function application.

 > dfrm <- cbind(dfrm, matrix(rnorm(600), ncol=10 ) ); names(dfrm)[3:12] 
<- paste0("X", 1:10)
 > str(dfrm)
'data.frame':??? 60 obs. of? 12 variables:
 ?$ Factor_A: Factor w/ 2 levels "A1","A2": 1 1 1 2 2 2 1 1 1 2 ...
 ?$ Factor_B: Factor w/ 3 levels "E1","E2","E3": 1 2 3 1 2 3 1 2 3 1 ...
 ?$ X1????? : num? -0.02116 -0.00049 0.12875 -0.05412 0.51886 ...
 ?$ X2????? : num? 1.6799 -0.0963 -0.5727 -0.3638 -0.322 ...
 ?$ X3????? : num? -0.349 0.267 -0.666 -0.329 0.902 ...
 ?$ X4????? : num? 0.1125 -0.5384 0.0924 0.6849 -0.4194 ...
 ?$ X5????? : num? -0.421 0.372 1.316 1.323 -0.03 ...
 ?$ X6????? : num? -0.0767 1.4972 0.1967 -0.7092 -1.0943 ...
 ?$ X7????? : num? 0.1771 -0.2136 -1.0818 -0.0671 2.0015 ...
 ?$ X8????? : num? 1.456 -0.383 -0.47 0.965 0.569 ...
 ?$ X9????? : num? -1.795 -0.4546 0.0069 1.2245 -0.395 ...
 ?$ X10???? : num? -1.931 1.708 0.274 0.73 -0.995 ...



 ?aggregate(? dfrm[ ,? c("X1", "X7", "X10")],??? # columns to analyze

 ? ? ? ? ? ? ? ? ? ? ? dfrm[ c("Factor_A", "Factor_B")],? # classifying 
columns

 ????????????????????? FUN=function (x) c(mn =mean(x), min=min(x), 
max=max(x) ) )? # desired "summarizers"

#--- result----

 ? Factor_A Factor_B??????? X1.mn?????? X1.min?????? X1.max X7.mn????? 
X7.min????? X7.max
1?????? A1?????? E1? 0.187513792 -0.866094155? 2.310960164 0.22489729 
-0.91442493? 1.94095786
2?????? A2?????? E1? 0.078361707 -1.515410191? 1.382420050 -0.51309155 
-1.67026123? 0.70869034
3?????? A1?????? E2 -0.267416858 -1.995131138? 1.392115793 -0.04772929 
-2.45426692? 2.02225946
4?????? A2?????? E2 -0.069807208 -0.703073589? 1.879448658 -0.37770923 
-2.66221239? 2.00152154
5?????? A1?????? E3 -0.007800886 -1.297561250? 1.216627848 -0.30395411 
-1.08181218? 1.09764895
6?????? A2?????? E3 -0.054466856 -1.577891927? 1.674719118 0.35594015 
-1.20865279? 2.25765422
 ????? X10.mn??? X10.min??? X10.max
1 -0.3458888 -2.0312811? 1.1483179
2 -0.1021727 -1.3230372? 0.8045472
3? 0.3514645 -3.2334010? 1.7075298
4 -0.4988984 -2.1091311? 0.5857192
5? 0.2297461 -1.1336967? 0.8483935

6? 0.3700621 -1.5609424? 2.2792024


-- 

David

>
> Any help would be appreciated,
>
> Thanks
>
> Bernard McGarvey
> Director, Fort Myers Beach Lions Foundation, Inc.
> Retired (Lilly Engineering Fellow).
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jan 18 00:13:54 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 17 Jan 2021 23:13:54 +0000
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAEGeL+HOZT_AzYS1cVB9wGC7OFvH7EM=U_n02y-sP1HZFs02wg@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
 <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
 <fc104a3c-6d2f-062a-d79e-42ec7c7811b3@sapo.pt>
 <CAEGeL+HOZT_AzYS1cVB9wGC7OFvH7EM=U_n02y-sP1HZFs02wg@mail.gmail.com>
Message-ID: <7bd6831b-f839-f59f-85a4-9aa74c9eedf1@sapo.pt>

Hello,

My code didn't produce only 6 rows, it displayed only 6 rows. But all 
rows now have a date column.

As for the first question,

df2 <- df1[c("SWS", "date")]


selects the columns with those names. I didn't rewrite the original df1, 
but if you want to, assign to df1, without creating df2.

Hope this helps,

Rui Barradas

?s 15:12 de 17/01/21, Jibrin Alhassan escreveu:
> Hi Barradas,
> Thanks for your assistance. It has brought me closer to what I am 
> looking for. I tried your code as shown below:
>  > df1 <- read.table("SWSdata_1998_2002", header = TRUE)
>  > df1$date <- as.Date(paste(df1$year, df1$day),format = "%Y %j",origin 
> = "1998-01-01")
>  > head(df1)
>  ? year day Hr SWS ? ? ? date
> 1 1998 ? 1 ?0 344 1998-01-01
> 2 1998 ? 2 ?0 346 1998-01-02
> 3 1998 ? 3 ?0 356 1998-01-03
> 4 1998 ? 4 ?0 332 1998-01-04
> 5 1998 ? 5 ?0 302 1998-01-05
> 6 1998 ? 6 ?0 329 1998-01-06
> What I need is the last two columns only (SWS, date). The first 3 
> columns (year, day Hr should go). Your code produced only 6 datasets. My 
> dataset is 1,826 from 1998 to 2002. How do I generate this at once?
> Many many thanks for your time. I have pasted below a section of my 
> dataset for your guidance, please.
> Jibrin
> year ? day Hr SWS
> 1998 ? 1 ?0 ?344.
> 1998 ? 2 ?0 ?346.
> 1998 ? 3 ?0 ?356.
> 1998 ? 4 ?0 ?332.
> 1998 ? 5 ?0 ?302.
> 1998 ? 6 ?0 ?329.
> 1998 ? 7 ?0 ?395.
> 1998 ? 8 ?0 ?359.
> 1998 ? 9 ?0 ?471.
> 1998 ?10 ?0 ?392.
> 1998 ?11 ?0 ?346.
> 1998 ?12 ?0 ?387.
> 1998 ?13 ?0 ?393.
> 1998 ?14 ?0 ?367.
> 1998 ?15 ?0 ?320.
> 1998 ?16 ?0 ?309.
> 1998 ?17 ?0 ?341.
> 1998 ?18 ?0 ?329.
> 1998 ?19 ?0 ?322.
> 1998 ?20 ?0 ?429.
> 1998 ?21 ?0 ?433.
> 1998 ?22 ?0 ?398.
> 1998 ?23 ?0 ?393.
> 1998 ?24 ?0 ?393.
> 1998 ?25 ?0 ?423.
> 1998 ?26 ?0 ?426.
> 1998 ?27 ?0 ?429.
> 1998 ?28 ?0 ?386.
> 1998 ?29 ?0 ?381.
> 1998 ?30 ?0 ?375.
> 1998 ?31 ?0 ?365.
> 1998 ?32 ?0 ?450.
> 1998 ?33 ?0 ?381.
> 1998 ?34 ?0 ?316.
> 1998 ?35 ?0 ?351.
> 1998 ?36 ?0 ?306.
> 1998 ?37 ?0 ?312.
> 1998 ?38 ?0 ?320.
> 1998 ?39 ?0 ?339.
> 1998 ?40 ?0 ?395.
> 1998 ?41 ?0 ?429.
> 1998 ?42 ?0 ?479.
> 1998 ?43 ?0 ?495.
> 1998 ?44 ?0 ?407.
> 1998 ?45 ?0 ?358.
> 1998 ?46 ?0 ?360.
> 1998 ?47 ?0 ?382.
> 1998 ?48 ?0 ?394.
> 1998 ?49 ?0 ?393.
> 1998 ?50 ?0 ?435.
> 1998 ?51 ?0 ?408.
> 1998 ?52 ?0 ?360.
> 1998 ?53 ?0 ?372.
> 1998 ?54 ?0 ?376.
> 1998 ?55 ?0 ?379.
> 1998 ?56 ?0 ?361.
> 1998 ?57 ?0 ?333.
> 1998 ?58 ?0 ?321.
> 1998 ?59 ?0 ?344.
> 1998 ?60 ?0 ?412.
> 1998 ?61 ?0 ?428.
> 1998 ?62 ?0 ?401.
> 1998 ?63 ?0 ?369.
> 1998 ?64 ?0 ?343.
> 1998 ?65 ?0 ?330.
> 1998 ?66 ?0 ?317.
> 1998 ?67 ?0 ?296.
> 1998 ?68 ?0 ?282.
> 1998 ?69 ?0 ?404.
> 1998 ?70 ?0 ?530.
> 1998 ?71 ?0 ?525.
> 1998 ?72 ?0 ?484.
> 1998 ?73 ?0 ?430.
> 1998 ?74 ?0 ?388.
> 1998 ?75 ?0 ?347.
> 1998 ?76 ?0 ?337.
> 1998 ?77 ?0 ?342.
> 1998 ?78 ?0 ?305.
> 1998 ?79 ?0 ?329.
> 1998 ?80 ?0 ?420.
> 1998 ?81 ?0 ?564.
> 1998 ?82 ?0 ?483.
> 1998 ?83 ?0 ?385.
> 1998 ?84 ?0 ?393.
> 1998 ?85 ?0 ?437.
> 1998 ?86 ?0 ?441.
> 1998 ?87 ?0 ?434.
> 1998 ?88 ?0 ?471.
> 1998 ?89 ?0 ?429.
> 1998 ?90 ?0 ?412.
> 1998 ?91 ?0 ?370.
> 1998 ?92 ?0 ?326.
> 1998 ?93 ?0 ?357.
> 1998 ?94 ?0 ?338.
> 1998 ?95 ?0 ?380.
> 1998 ?96 ?0 ?339.
> 1998 ?97 ?0 ?312.
> 1998 ?98 ?0 ?313.
> 1998 ?99 ?0 ?327.
> 1998 100 ?0 ?362.
> 1998 101 ?0 ?358.
> 1998 102 ?0 ?387.
> 1998 103 ?0 ?397.
> 1998 104 ?0 ?375.
> 1998 105 ?0 ?350.
> 1998 106 ?0 ?357.
> 1998 107 ?0 ?472.
> 1998 108 ?0 ?526.
> 1998 109 ?0 ?396.
> 1998 110 ?0 ?374.
> 1998 111 ?0 ?376.
> 1998 112 ?0 ?355.
> 1998 113 ?0 ?343.
> 1998 114 ?0 ?425.
> 1998 115 ?0 ?426.
> 1998 116 ?0 ?479.
> 1998 117 ?0 ?469.
> 1998 118 ?0 ?425.
> 1998 119 ?0 ?344.
> 1998 120 ?0 ?341.
> 1998 121 ?0 ?426.
> 1998 122 ?0 ?601.
> 1998 123 ?0 ?476.
> 1998 124 ?0 ?670.
> 1998 125 ?0 ?585.
> 1998 126 ?0 ?496.
> 1998 127 ?0 ?479.
> 1998 128 ?0 ?569.
> 1998 129 ?0 ?531.
> 1998 130 ?0 ?489.
> 1998 131 ?0 ?484.
> 1998 132 ?0 ?480.
> 1998 133 ?0 ?393.
> 1998 134 ?0 ?332.
> 1998 135 ?0 ?327.
> 1998 136 ?0 ?493.
> 1998 137 ?0 ?493.
> 1998 138 ?0 ?430.
> 1998 139 ?0 ?396.
> 1998 140 ?0 ?408.
> 1998 141 ?0 ?416.
> 1998 142 ?0 ?376.
> 1998 143 ?0 ?375.
> 1998 144 ?0 ?415.
> 1998 145 ?0 ?407.
> 1998 146 ?0 ?398.
> 1998 147 ?0 ?352.
> 1998 148 ?0 ?349.
> 1998 149 ?0 ?517.
> 1998 150 ?0 ?597.
> 1998 151 ?0 ?480.
> 1998 152 ?0 ?435.
> 1998 153 ?0 ?408.
> 1998 154 ?0 ?441.
> 1998 155 ?0 ?397.
> 1998 156 ?0 ?374.
> 1998 157 ?0 ?413.
> 1998 158 ?0 ?582.
> 1998 159 ?0 ?513.
> 1998 160 ?0 ?459.
> 1998 161 ?0 ?466.
> 1998 162 ?0 ?414.
> 1998 163 ?0 ?354.
> 1998 164 ?0 ?341.
> 1998 165 ?0 ?343.
> 1998 166 ?0 ?369.
> 1998 167 ?0 ?411.
> 1998 168 ?0 ?355.
> 1998 169 ?0 ?333.
> 1998 170 ?0 ?443.
> 1998 171 ?0 ?426.
> 1998 172 ?0 ?419.
> 1998 173 ?0 ?404.
> 1998 174 ?0 ?387.
> 1998 175 ?0 ?460.
> 1998 176 ?0 ?447.
> 1998 177 ?0 ?469.
> 1998 178 ?0 ?447.
> 1998 179 ?0 ?389.
> 1998 180 ?0 ?375.
> 1998 181 ?0 ?354.
> 1998 182 ?0 ?316.
> 1998 183 ?0 ?369.
> 1998 184 ?0 ?410.
> 1998 185 ?0 ?406.
> 1998 186 ?0 ?477.
> 1998 187 ?0 ?583.
> 1998 188 ?0 ?458.
> 1998 189 ?0 ?386.
> 1998 190 ?0 ?342.
> 1998 191 ?0 ?333.
> 1998 192 ?0 ?369.
> 1998 193 ?0 ?406.
> 1998 194 ?0 ?375.
> 1998 195 ?0 ?332.
> 1998 196 ?0 ?310.
> 1998 197 ?0 ?528.
> 1998 198 ?0 ?530.
> 1998 199 ?0 ?387.
> 1998 200 ?0 ?385.
> 1998 201 ?0 ?349.
> 1998 202 ?0 ?409.
> 1998 203 ?0 ?399.
> 1998 204 ?0 ?619.
> 1998 205 ?0 ?658.
> 1998 206 ?0 ?581.
> 1998 207 ?0 ?445.
> 1998 208 ?0 ?370.
> 1998 209 ?0 ?326.
> 1998 210 ?0 ?334.
> 1998 211 ?0 ?384.
> 1998 212 ?0 ?423.
> 1998 213 ?0 ?412.
> 1998 214 ?0 ?404.
> 1998 215 ?0 ?370.
> 1998 216 ?0 ?384.
> 1998 217 ?0 ?383.
> 1998 218 ?0 ?378.
> 1998 219 ?0 ?461.
> 1998 220 ?0 ?460.
> 1998 221 ?0 ?400.
> 1998 222 ?0 ?447.
> 1998 223 ?0 ?373.
> 1998 224 ?0 ?379.
> 1998 225 ?0 ?374.
> 1998 226 ?0 ?374.
> 1998 227 ?0 ?391.
> 1998 228 ?0 ?348.
> 1998 229 ?0 ?303.
> 1998 230 ?0 ?279.
> 1998 231 ?0 ?312.
> 1998 232 ?0 ?331.
> 1998 233 ?0 ?298.
> 1998 234 ?0 ?341.
> 1998 235 ?0 ?493.
> 1998 236 ?0 ?436.
> 1998 237 ?0 ?400.
> 1998 238 ?0 ?633.
> 1998 239 ?0 ?630.
> 1998 240 ?0 ?583.
> 1998 241 ?0 ?547.
> 1998 242 ?0 ?550.
> 1998 243 ?0 ?499.
> 1998 244 ?0 ?444.
> 1998 245 ?0 ?427.
> 1998 246 ?0 ?401.
> 
> On Sat, Jan 16, 2021 at 8:01 AM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     Thanks for the data, it makes things easier.
> 
>     df1 <- read.table("Jibrin_data.txt", header = TRUE)
>     #'data.frame':? 168 obs. of? 4 variables:
>     # $ year: int? 1998 1998 1998 1998 1998 1998 1998 1998 1998 1998 ...
>     # $ day : int? 1 2 3 4 5 6 7 8 9 10 ...
>     # $ Hr? : int? 0 0 0 0 0 0 0 0 0 0 ...
>     # $ SWS : num? 344 346 356 332 302 329 395 359 471 392 ...
> 
>     Here is a simple way of converting the year and day of year columns
>     to a
>     column of class "Date".
>     Like others have said, there are also CRAN packages to handle date/time
>     data, my favorite being package lubridate, but base R can do it.
> 
> 
>     df1$date <- as.Date(paste(df1$year, df1$day),
>      ? ? ? ? ? ? ? ? ? ? ?format = "%Y %j",
>      ? ? ? ? ? ? ? ? ? ? ?origin = "1998-01-01")
> 
>     head(df1)
>     #? year day Hr SWS? ? ? ?date
>     #1 1998? ?1? 0 344 1998-01-01
>     #2 1998? ?2? 0 346 1998-01-02
>     #3 1998? ?3? 0 356 1998-01-03
>     #4 1998? ?4? 0 332 1998-01-04
>     #5 1998? ?5? 0 302 1998-01-05
>     #6 1998? ?6? 0 329 1998-01-06
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
> 
>     ?s 06:48 de 16/01/21, Jibrin Alhassan escreveu:
>      > Hi Barradas
>      >? ?Sorry for the delay. Below is a section of my data. I have up
>     to 1826
>      > covering 1998 to 2002
>      > year ? day Hr SWS
>      > 1998 ? 1 ?0 ?344.
>      > 1998 ? 2 ?0 ?346.
>      > 1998 ? 3 ?0 ?356.
>      > 1998 ? 4 ?0 ?332.
>      > 1998 ? 5 ?0 ?302.
>      > 1998 ? 6 ?0 ?329.
>      > 1998 ? 7 ?0 ?395.
>      > 1998 ? 8 ?0 ?359.
>      > 1998 ? 9 ?0 ?471.
>      > 1998 ?10 ?0 ?392.
>      > 1998 ?11 ?0 ?346.
>      > 1998 ?12 ?0 ?387.
>      > 1998 ?13 ?0 ?393.
>      > 1998 ?14 ?0 ?367.
>      > 1998 ?15 ?0 ?320.
>      > 1998 ?16 ?0 ?309.
>      > 1998 ?17 ?0 ?341.
>      > 1998 ?18 ?0 ?329.
>      > 1998 ?19 ?0 ?322.
>      > 1998 ?20 ?0 ?429.
>      > 1998 ?21 ?0 ?433.
>      > 1998 ?22 ?0 ?398.
>      > 1998 ?23 ?0 ?393.
>      > 1998 ?24 ?0 ?393.
>      > 1998 ?25 ?0 ?423.
>      > 1998 ?26 ?0 ?426.
>      > 1998 ?27 ?0 ?429.
>      > 1998 ?28 ?0 ?386.
>      > 1998 ?29 ?0 ?381.
>      > 1998 ?30 ?0 ?375.
>      > 1998 ?31 ?0 ?365.
>      > 1998 ?32 ?0 ?450.
>      > 1998 ?33 ?0 ?381.
>      > 1998 ?34 ?0 ?316.
>      > 1998 ?35 ?0 ?351.
>      > 1998 ?36 ?0 ?306.
>      > 1998 ?37 ?0 ?312.
>      > 1998 ?38 ?0 ?320.
>      > 1998 ?39 ?0 ?339.
>      > 1998 ?40 ?0 ?395.
>      > 1998 ?41 ?0 ?429.
>      > 1998 ?42 ?0 ?479.
>      > 1998 ?43 ?0 ?495.
>      > 1998 ?44 ?0 ?407.
>      > 1998 ?45 ?0 ?358.
>      > 1998 ?46 ?0 ?360.
>      > 1998 ?47 ?0 ?382.
>      > 1998 ?48 ?0 ?394.
>      > 1998 ?49 ?0 ?393.
>      > 1998 ?50 ?0 ?435.
>      > 1998 ?51 ?0 ?408.
>      > 1998 ?52 ?0 ?360.
>      > 1998 ?53 ?0 ?372.
>      > 1998 ?54 ?0 ?376.
>      > 1998 ?55 ?0 ?379.
>      > 1998 ?56 ?0 ?361.
>      > 1998 ?57 ?0 ?333.
>      > 1998 ?58 ?0 ?321.
>      > 1998 ?59 ?0 ?344.
>      > 1998 ?60 ?0 ?412.
>      > 1998 ?61 ?0 ?428.
>      > 1998 ?62 ?0 ?401.
>      > 1998 ?63 ?0 ?369.
>      > 1998 ?64 ?0 ?343.
>      > 1998 ?65 ?0 ?330.
>      > 1998 ?66 ?0 ?317.
>      > 1998 ?67 ?0 ?296.
>      > 1998 ?68 ?0 ?282.
>      > 1998 ?69 ?0 ?404.
>      > 1998 ?70 ?0 ?530.
>      > 1998 ?71 ?0 ?525.
>      > 1998 ?72 ?0 ?484.
>      > 1998 ?73 ?0 ?430.
>      > 1998 ?74 ?0 ?388.
>      > 1998 ?75 ?0 ?347.
>      > 1998 ?76 ?0 ?337.
>      > 1998 ?77 ?0 ?342.
>      > 1998 ?78 ?0 ?305.
>      > 1998 ?79 ?0 ?329.
>      > 1998 ?80 ?0 ?420.
>      > 1998 ?81 ?0 ?564.
>      > 1998 ?82 ?0 ?483.
>      > 1998 ?83 ?0 ?385.
>      > 1998 ?84 ?0 ?393.
>      > 1998 ?85 ?0 ?437.
>      > 1998 ?86 ?0 ?441.
>      > 1998 ?87 ?0 ?434.
>      > 1998 ?88 ?0 ?471.
>      > 1998 ?89 ?0 ?429.
>      > 1998 ?90 ?0 ?412.
>      > 1998 ?91 ?0 ?370.
>      > 1998 ?92 ?0 ?326.
>      > 1998 ?93 ?0 ?357.
>      > 1998 ?94 ?0 ?338.
>      > 1998 ?95 ?0 ?380.
>      > 1998 ?96 ?0 ?339.
>      > 1998 ?97 ?0 ?312.
>      > 1998 ?98 ?0 ?313.
>      > 1998 ?99 ?0 ?327.
>      > 1998 100 ?0 ?362.
>      > 1998 101 ?0 ?358.
>      > 1998 102 ?0 ?387.
>      > 1998 103 ?0 ?397.
>      > 1998 104 ?0 ?375.
>      > 1998 105 ?0 ?350.
>      > 1998 106 ?0 ?357.
>      > 1998 107 ?0 ?472.
>      > 1998 108 ?0 ?526.
>      > 1998 109 ?0 ?396.
>      > 1998 110 ?0 ?374.
>      > 1998 111 ?0 ?376.
>      > 1998 112 ?0 ?355.
>      > 1998 113 ?0 ?343.
>      > 1998 114 ?0 ?425.
>      > 1998 115 ?0 ?426.
>      > 1998 116 ?0 ?479.
>      > 1998 117 ?0 ?469.
>      > 1998 118 ?0 ?425.
>      > 1998 119 ?0 ?344.
>      > 1998 120 ?0 ?341.
>      > 1998 121 ?0 ?426.
>      > 1998 122 ?0 ?601.
>      > 1998 123 ?0 ?476.
>      > 1998 124 ?0 ?670.
>      > 1998 125 ?0 ?585.
>      > 1998 126 ?0 ?496.
>      > 1998 127 ?0 ?479.
>      > 1998 128 ?0 ?569.
>      > 1998 129 ?0 ?531.
>      > 1998 130 ?0 ?489.
>      > 1998 131 ?0 ?484.
>      > 1998 132 ?0 ?480.
>      > 1998 133 ?0 ?393.
>      > 1998 134 ?0 ?332.
>      > 1998 135 ?0 ?327.
>      > 1998 136 ?0 ?493.
>      > 1998 137 ?0 ?493.
>      > 1998 138 ?0 ?430.
>      > 1998 139 ?0 ?396.
>      > 1998 140 ?0 ?408.
>      > 1998 141 ?0 ?416.
>      > 1998 142 ?0 ?376.
>      > 1998 143 ?0 ?375.
>      > 1998 144 ?0 ?415.
>      > 1998 145 ?0 ?407.
>      > 1998 146 ?0 ?398.
>      > 1998 147 ?0 ?352.
>      > 1998 148 ?0 ?349.
>      > 1998 149 ?0 ?517.
>      > 1998 150 ?0 ?597.
>      > 1998 151 ?0 ?480.
>      > 1998 152 ?0 ?435.
>      > 1998 153 ?0 ?408.
>      > 1998 154 ?0 ?441.
>      > 1998 155 ?0 ?397.
>      > 1998 156 ?0 ?374.
>      > 1998 157 ?0 ?413.
>      > 1998 158 ?0 ?582.
>      > 1998 159 ?0 ?513.
>      > 1998 160 ?0 ?459.
>      > 1998 161 ?0 ?466.
>      > 1998 162 ?0 ?414.
>      > 1998 163 ?0 ?354.
>      > 1998 164 ?0 ?341.
>      > 1998 165 ?0 ?343.
>      > 1998 166 ?0 ?369.
>      > 1998 167 ?0 ?411.
>      > 1998 168 ?0 ?355.
>      > Thanks
>      > Jibrin
>      >
>      > On Fri, Jan 15, 2021 at 7:15 PM Rui Barradas
>     <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
>      > <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>> wrote:
>      >
>      >? ? ?Hello,
>      >
>      >? ? ?No dataset was attached. Like the posting guide says,
>      >
>      >? ? ?No binary attachments except for PS, PDF, and some image and
>     archive
>      >? ? ?formats (others are automatically stripped off because they
>     can contain
>      >? ? ?malicious software). Files in other formats and larger ones
>     should
>      >? ? ?rather be put on the web and have only their URLs posted.
>     This way a
>      >? ? ?reader has the option to download them or not.
>      >
>      >
>      >? ? ?Can you post sample data? Please post the output of
>     `dput(df)`. Or, if
>      >? ? ?it is too big the output of `dput(head(df, 20))`. (`df` is
>     the name of
>      >? ? ?your dataset.)
>      >
>      >? ? ?Hope this helps,
>      >
>      >? ? ?Rui Barradas
>      >
>      >? ? ??s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
>      >? ? ? > Dear R users,
>      >? ? ? > I am very new to R software. I have solar wind speed data
>     needed
>      >? ? ?for my
>      >? ? ? > work. How do I convert day in the year to year, month, and
>     day with R
>      >? ? ? > software? I have used this code
>      >? ? ? > as.Date(0, origin = "1998-01-01")
>      >? ? ? > but it can only convert one day of the year at a time.
>     Meanwhile,
>      >? ? ?I have up
>      >? ? ? > to the 1998-2002 data set. Attached is my data.
>      >? ? ? > Kindly help, please.
>      >? ? ? > Jibrin Alhassan
>      >? ? ? > ______________________________________________
>      >? ? ? > R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list
>      >? ? ?-- To UNSUBSCRIBE and more, see
>      >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-help
>      >? ? ? > PLEASE do read the posting guide
>      > http://www.R-project.org/posting-guide.html
>      >? ? ? > and provide commented, minimal, self-contained,
>     reproducible code.
>      >? ? ? >
>      >
>


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Mon Jan 18 00:19:30 2021
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Sun, 17 Jan 2021 18:19:30 -0500
Subject: [R] Summarizing select columns in a data frame
In-Reply-To: <6b7ee99a-a952-972a-3135-2f1596fcbf0f@comcast.net>
References: <6b7ee99a-a952-972a-3135-2f1596fcbf0f@comcast.net>
Message-ID: <4FEB57A9-6907-4ABA-B098-9B8EEA609181@comcast.net>

Thanks David

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Jan 17, 2021, at 5:59 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> ?
>> On 1/17/21 12:15 PM, Bernard McGarvey wrote:
>> I have a data frame that consists of several factor columns say A, B, C, D, and E and several columns containing numerical data, say X1, X2, .... X10. I would like to create statistics of some of the numerical columns by some of the factor columns. For example,
>> 
>> Calculate the mean, min, and max of variables X1 and X7, by factors A, and E. The results should look like the table below:
>> 
>> Factor A Factor E     mean(X1) min(x1) max(X1) mean(X7) min(x7) max(X7) mean(X10) min(x10) max(X10)
>> A1        E1
>> A1        E2
>> A1        E3
>> A2        E1
>> A2        E2
>> A2        E3
>> 
>> I would like the results to be returned to a data frame or other object that I can write out using the write.csv function. I have looked at the summarize and numSummary functions but they do not appear to be flexible enough to do the above.
> 
> 
> The `aggregate` function will do the subsetting and function application.
> 
> > dfrm <- cbind(dfrm, matrix(rnorm(600), ncol=10 ) ); names(dfrm)[3:12] <- paste0("X", 1:10)
> > str(dfrm)
> 'data.frame':    60 obs. of  12 variables:
>  $ Factor_A: Factor w/ 2 levels "A1","A2": 1 1 1 2 2 2 1 1 1 2 ...
>  $ Factor_B: Factor w/ 3 levels "E1","E2","E3": 1 2 3 1 2 3 1 2 3 1 ...
>  $ X1      : num  -0.02116 -0.00049 0.12875 -0.05412 0.51886 ...
>  $ X2      : num  1.6799 -0.0963 -0.5727 -0.3638 -0.322 ...
>  $ X3      : num  -0.349 0.267 -0.666 -0.329 0.902 ...
>  $ X4      : num  0.1125 -0.5384 0.0924 0.6849 -0.4194 ...
>  $ X5      : num  -0.421 0.372 1.316 1.323 -0.03 ...
>  $ X6      : num  -0.0767 1.4972 0.1967 -0.7092 -1.0943 ...
>  $ X7      : num  0.1771 -0.2136 -1.0818 -0.0671 2.0015 ...
>  $ X8      : num  1.456 -0.383 -0.47 0.965 0.569 ...
>  $ X9      : num  -1.795 -0.4546 0.0069 1.2245 -0.395 ...
>  $ X10     : num  -1.931 1.708 0.274 0.73 -0.995 ...
> 
> 
> 
>  aggregate(  dfrm[ ,  c("X1", "X7", "X10")],    # columns to analyze
> 
>                       dfrm[ c("Factor_A", "Factor_B")],  # classifying columns
> 
>                       FUN=function (x) c(mn =mean(x), min=min(x), max=max(x) ) )  # desired "summarizers"
> 
> #--- result----
> 
>   Factor_A Factor_B        X1.mn       X1.min       X1.max X7.mn      X7.min      X7.max
> 1       A1       E1  0.187513792 -0.866094155  2.310960164 0.22489729 -0.91442493  1.94095786
> 2       A2       E1  0.078361707 -1.515410191  1.382420050 -0.51309155 -1.67026123  0.70869034
> 3       A1       E2 -0.267416858 -1.995131138  1.392115793 -0.04772929 -2.45426692  2.02225946
> 4       A2       E2 -0.069807208 -0.703073589  1.879448658 -0.37770923 -2.66221239  2.00152154
> 5       A1       E3 -0.007800886 -1.297561250  1.216627848 -0.30395411 -1.08181218  1.09764895
> 6       A2       E3 -0.054466856 -1.577891927  1.674719118 0.35594015 -1.20865279  2.25765422
>       X10.mn    X10.min    X10.max
> 1 -0.3458888 -2.0312811  1.1483179
> 2 -0.1021727 -1.3230372  0.8045472
> 3  0.3514645 -3.2334010  1.7075298
> 4 -0.4988984 -2.1091311  0.5857192
> 5  0.2297461 -1.1336967  0.8483935
> 
> 6  0.3700621 -1.5609424  2.2792024
> 
> 
> -- 
> 
> David
> 
>> 
>> Any help would be appreciated,
>> 
>> Thanks
>> 
>> Bernard McGarvey
>> Director, Fort Myers Beach Lions Foundation, Inc.
>> Retired (Lilly Engineering Fellow).
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Mon Jan 18 00:45:43 2021
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Mon, 18 Jan 2021 00:45:43 +0100
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <7bd6831b-f839-f59f-85a4-9aa74c9eedf1@sapo.pt>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
 <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
 <fc104a3c-6d2f-062a-d79e-42ec7c7811b3@sapo.pt>
 <CAEGeL+HOZT_AzYS1cVB9wGC7OFvH7EM=U_n02y-sP1HZFs02wg@mail.gmail.com>
 <7bd6831b-f839-f59f-85a4-9aa74c9eedf1@sapo.pt>
Message-ID: <CAEGeL+H3pfD3PkkLwNY-8hpcjeNws_xo1J786PCH6M9kT7MvWw@mail.gmail.com>

Hellow Rui,
The code helped.
I am very grateful.
Jibrin

On Mon, Jan 18, 2021 at 12:14 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> My code didn't produce only 6 rows, it displayed only 6 rows. But all
> rows now have a date column.
>
> As for the first question,
>
> df2 <- df1[c("SWS", "date")]
>
>
> selects the columns with those names. I didn't rewrite the original df1,
> but if you want to, assign to df1, without creating df2.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 15:12 de 17/01/21, Jibrin Alhassan escreveu:
> > Hi Barradas,
> > Thanks for your assistance. It has brought me closer to what I am
> > looking for. I tried your code as shown below:
> >  > df1 <- read.table("SWSdata_1998_2002", header = TRUE)
> >  > df1$date <- as.Date(paste(df1$year, df1$day),format = "%Y %j",origin
> > = "1998-01-01")
> >  > head(df1)
> >    year day Hr SWS       date
> > 1 1998   1  0 344 1998-01-01
> > 2 1998   2  0 346 1998-01-02
> > 3 1998   3  0 356 1998-01-03
> > 4 1998   4  0 332 1998-01-04
> > 5 1998   5  0 302 1998-01-05
> > 6 1998   6  0 329 1998-01-06
> > What I need is the last two columns only (SWS, date). The first 3
> > columns (year, day Hr should go). Your code produced only 6 datasets. My
> > dataset is 1,826 from 1998 to 2002. How do I generate this at once?
> > Many many thanks for your time. I have pasted below a section of my
> > dataset for your guidance, please.
> > Jibrin
> > year   day Hr SWS
> > 1998   1  0  344.
> > 1998   2  0  346.
> > 1998   3  0  356.
> > 1998   4  0  332.
> > 1998   5  0  302.
> > 1998   6  0  329.
> > 1998   7  0  395.
> > 1998   8  0  359.
> > 1998   9  0  471.
> > 1998  10  0  392.
> > 1998  11  0  346.
> > 1998  12  0  387.
> > 1998  13  0  393.
> > 1998  14  0  367.
> > 1998  15  0  320.
> > 1998  16  0  309.
> > 1998  17  0  341.
> > 1998  18  0  329.
> > 1998  19  0  322.
> > 1998  20  0  429.
> > 1998  21  0  433.
> > 1998  22  0  398.
> > 1998  23  0  393.
> > 1998  24  0  393.
> > 1998  25  0  423.
> > 1998  26  0  426.
> > 1998  27  0  429.
> > 1998  28  0  386.
> > 1998  29  0  381.
> > 1998  30  0  375.
> > 1998  31  0  365.
> > 1998  32  0  450.
> > 1998  33  0  381.
> > 1998  34  0  316.
> > 1998  35  0  351.
> > 1998  36  0  306.
> > 1998  37  0  312.
> > 1998  38  0  320.
> > 1998  39  0  339.
> > 1998  40  0  395.
> > 1998  41  0  429.
> > 1998  42  0  479.
> > 1998  43  0  495.
> > 1998  44  0  407.
> > 1998  45  0  358.
> > 1998  46  0  360.
> > 1998  47  0  382.
> > 1998  48  0  394.
> > 1998  49  0  393.
> > 1998  50  0  435.
> > 1998  51  0  408.
> > 1998  52  0  360.
> > 1998  53  0  372.
> > 1998  54  0  376.
> > 1998  55  0  379.
> > 1998  56  0  361.
> > 1998  57  0  333.
> > 1998  58  0  321.
> > 1998  59  0  344.
> > 1998  60  0  412.
> > 1998  61  0  428.
> > 1998  62  0  401.
> > 1998  63  0  369.
> > 1998  64  0  343.
> > 1998  65  0  330.
> > 1998  66  0  317.
> > 1998  67  0  296.
> > 1998  68  0  282.
> > 1998  69  0  404.
> > 1998  70  0  530.
> > 1998  71  0  525.
> > 1998  72  0  484.
> > 1998  73  0  430.
> > 1998  74  0  388.
> > 1998  75  0  347.
> > 1998  76  0  337.
> > 1998  77  0  342.
> > 1998  78  0  305.
> > 1998  79  0  329.
> > 1998  80  0  420.
> > 1998  81  0  564.
> > 1998  82  0  483.
> > 1998  83  0  385.
> > 1998  84  0  393.
> > 1998  85  0  437.
> > 1998  86  0  441.
> > 1998  87  0  434.
> > 1998  88  0  471.
> > 1998  89  0  429.
> > 1998  90  0  412.
> > 1998  91  0  370.
> > 1998  92  0  326.
> > 1998  93  0  357.
> > 1998  94  0  338.
> > 1998  95  0  380.
> > 1998  96  0  339.
> > 1998  97  0  312.
> > 1998  98  0  313.
> > 1998  99  0  327.
> > 1998 100  0  362.
> > 1998 101  0  358.
> > 1998 102  0  387.
> > 1998 103  0  397.
> > 1998 104  0  375.
> > 1998 105  0  350.
> > 1998 106  0  357.
> > 1998 107  0  472.
> > 1998 108  0  526.
> > 1998 109  0  396.
> > 1998 110  0  374.
> > 1998 111  0  376.
> > 1998 112  0  355.
> > 1998 113  0  343.
> > 1998 114  0  425.
> > 1998 115  0  426.
> > 1998 116  0  479.
> > 1998 117  0  469.
> > 1998 118  0  425.
> > 1998 119  0  344.
> > 1998 120  0  341.
> > 1998 121  0  426.
> > 1998 122  0  601.
> > 1998 123  0  476.
> > 1998 124  0  670.
> > 1998 125  0  585.
> > 1998 126  0  496.
> > 1998 127  0  479.
> > 1998 128  0  569.
> > 1998 129  0  531.
> > 1998 130  0  489.
> > 1998 131  0  484.
> > 1998 132  0  480.
> > 1998 133  0  393.
> > 1998 134  0  332.
> > 1998 135  0  327.
> > 1998 136  0  493.
> > 1998 137  0  493.
> > 1998 138  0  430.
> > 1998 139  0  396.
> > 1998 140  0  408.
> > 1998 141  0  416.
> > 1998 142  0  376.
> > 1998 143  0  375.
> > 1998 144  0  415.
> > 1998 145  0  407.
> > 1998 146  0  398.
> > 1998 147  0  352.
> > 1998 148  0  349.
> > 1998 149  0  517.
> > 1998 150  0  597.
> > 1998 151  0  480.
> > 1998 152  0  435.
> > 1998 153  0  408.
> > 1998 154  0  441.
> > 1998 155  0  397.
> > 1998 156  0  374.
> > 1998 157  0  413.
> > 1998 158  0  582.
> > 1998 159  0  513.
> > 1998 160  0  459.
> > 1998 161  0  466.
> > 1998 162  0  414.
> > 1998 163  0  354.
> > 1998 164  0  341.
> > 1998 165  0  343.
> > 1998 166  0  369.
> > 1998 167  0  411.
> > 1998 168  0  355.
> > 1998 169  0  333.
> > 1998 170  0  443.
> > 1998 171  0  426.
> > 1998 172  0  419.
> > 1998 173  0  404.
> > 1998 174  0  387.
> > 1998 175  0  460.
> > 1998 176  0  447.
> > 1998 177  0  469.
> > 1998 178  0  447.
> > 1998 179  0  389.
> > 1998 180  0  375.
> > 1998 181  0  354.
> > 1998 182  0  316.
> > 1998 183  0  369.
> > 1998 184  0  410.
> > 1998 185  0  406.
> > 1998 186  0  477.
> > 1998 187  0  583.
> > 1998 188  0  458.
> > 1998 189  0  386.
> > 1998 190  0  342.
> > 1998 191  0  333.
> > 1998 192  0  369.
> > 1998 193  0  406.
> > 1998 194  0  375.
> > 1998 195  0  332.
> > 1998 196  0  310.
> > 1998 197  0  528.
> > 1998 198  0  530.
> > 1998 199  0  387.
> > 1998 200  0  385.
> > 1998 201  0  349.
> > 1998 202  0  409.
> > 1998 203  0  399.
> > 1998 204  0  619.
> > 1998 205  0  658.
> > 1998 206  0  581.
> > 1998 207  0  445.
> > 1998 208  0  370.
> > 1998 209  0  326.
> > 1998 210  0  334.
> > 1998 211  0  384.
> > 1998 212  0  423.
> > 1998 213  0  412.
> > 1998 214  0  404.
> > 1998 215  0  370.
> > 1998 216  0  384.
> > 1998 217  0  383.
> > 1998 218  0  378.
> > 1998 219  0  461.
> > 1998 220  0  460.
> > 1998 221  0  400.
> > 1998 222  0  447.
> > 1998 223  0  373.
> > 1998 224  0  379.
> > 1998 225  0  374.
> > 1998 226  0  374.
> > 1998 227  0  391.
> > 1998 228  0  348.
> > 1998 229  0  303.
> > 1998 230  0  279.
> > 1998 231  0  312.
> > 1998 232  0  331.
> > 1998 233  0  298.
> > 1998 234  0  341.
> > 1998 235  0  493.
> > 1998 236  0  436.
> > 1998 237  0  400.
> > 1998 238  0  633.
> > 1998 239  0  630.
> > 1998 240  0  583.
> > 1998 241  0  547.
> > 1998 242  0  550.
> > 1998 243  0  499.
> > 1998 244  0  444.
> > 1998 245  0  427.
> > 1998 246  0  401.
> >
> > On Sat, Jan 16, 2021 at 8:01 AM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     Thanks for the data, it makes things easier.
> >
> >     df1 <- read.table("Jibrin_data.txt", header = TRUE)
> >     #'data.frame':  168 obs. of  4 variables:
> >     # $ year: int  1998 1998 1998 1998 1998 1998 1998 1998 1998 1998 ...
> >     # $ day : int  1 2 3 4 5 6 7 8 9 10 ...
> >     # $ Hr  : int  0 0 0 0 0 0 0 0 0 0 ...
> >     # $ SWS : num  344 346 356 332 302 329 395 359 471 392 ...
> >
> >     Here is a simple way of converting the year and day of year columns
> >     to a
> >     column of class "Date".
> >     Like others have said, there are also CRAN packages to handle
> date/time
> >     data, my favorite being package lubridate, but base R can do it.
> >
> >
> >     df1$date <- as.Date(paste(df1$year, df1$day),
> >                           format = "%Y %j",
> >                           origin = "1998-01-01")
> >
> >     head(df1)
> >     #  year day Hr SWS       date
> >     #1 1998   1  0 344 1998-01-01
> >     #2 1998   2  0 346 1998-01-02
> >     #3 1998   3  0 356 1998-01-03
> >     #4 1998   4  0 332 1998-01-04
> >     #5 1998   5  0 302 1998-01-05
> >     #6 1998   6  0 329 1998-01-06
> >
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >
> >     ?s 06:48 de 16/01/21, Jibrin Alhassan escreveu:
> >      > Hi Barradas
> >      >   Sorry for the delay. Below is a section of my data. I have up
> >     to 1826
> >      > covering 1998 to 2002
> >      > year   day Hr SWS
> >      > 1998   1  0  344.
> >      > 1998   2  0  346.
> >      > 1998   3  0  356.
> >      > 1998   4  0  332.
> >      > 1998   5  0  302.
> >      > 1998   6  0  329.
> >      > 1998   7  0  395.
> >      > 1998   8  0  359.
> >      > 1998   9  0  471.
> >      > 1998  10  0  392.
> >      > 1998  11  0  346.
> >      > 1998  12  0  387.
> >      > 1998  13  0  393.
> >      > 1998  14  0  367.
> >      > 1998  15  0  320.
> >      > 1998  16  0  309.
> >      > 1998  17  0  341.
> >      > 1998  18  0  329.
> >      > 1998  19  0  322.
> >      > 1998  20  0  429.
> >      > 1998  21  0  433.
> >      > 1998  22  0  398.
> >      > 1998  23  0  393.
> >      > 1998  24  0  393.
> >      > 1998  25  0  423.
> >      > 1998  26  0  426.
> >      > 1998  27  0  429.
> >      > 1998  28  0  386.
> >      > 1998  29  0  381.
> >      > 1998  30  0  375.
> >      > 1998  31  0  365.
> >      > 1998  32  0  450.
> >      > 1998  33  0  381.
> >      > 1998  34  0  316.
> >      > 1998  35  0  351.
> >      > 1998  36  0  306.
> >      > 1998  37  0  312.
> >      > 1998  38  0  320.
> >      > 1998  39  0  339.
> >      > 1998  40  0  395.
> >      > 1998  41  0  429.
> >      > 1998  42  0  479.
> >      > 1998  43  0  495.
> >      > 1998  44  0  407.
> >      > 1998  45  0  358.
> >      > 1998  46  0  360.
> >      > 1998  47  0  382.
> >      > 1998  48  0  394.
> >      > 1998  49  0  393.
> >      > 1998  50  0  435.
> >      > 1998  51  0  408.
> >      > 1998  52  0  360.
> >      > 1998  53  0  372.
> >      > 1998  54  0  376.
> >      > 1998  55  0  379.
> >      > 1998  56  0  361.
> >      > 1998  57  0  333.
> >      > 1998  58  0  321.
> >      > 1998  59  0  344.
> >      > 1998  60  0  412.
> >      > 1998  61  0  428.
> >      > 1998  62  0  401.
> >      > 1998  63  0  369.
> >      > 1998  64  0  343.
> >      > 1998  65  0  330.
> >      > 1998  66  0  317.
> >      > 1998  67  0  296.
> >      > 1998  68  0  282.
> >      > 1998  69  0  404.
> >      > 1998  70  0  530.
> >      > 1998  71  0  525.
> >      > 1998  72  0  484.
> >      > 1998  73  0  430.
> >      > 1998  74  0  388.
> >      > 1998  75  0  347.
> >      > 1998  76  0  337.
> >      > 1998  77  0  342.
> >      > 1998  78  0  305.
> >      > 1998  79  0  329.
> >      > 1998  80  0  420.
> >      > 1998  81  0  564.
> >      > 1998  82  0  483.
> >      > 1998  83  0  385.
> >      > 1998  84  0  393.
> >      > 1998  85  0  437.
> >      > 1998  86  0  441.
> >      > 1998  87  0  434.
> >      > 1998  88  0  471.
> >      > 1998  89  0  429.
> >      > 1998  90  0  412.
> >      > 1998  91  0  370.
> >      > 1998  92  0  326.
> >      > 1998  93  0  357.
> >      > 1998  94  0  338.
> >      > 1998  95  0  380.
> >      > 1998  96  0  339.
> >      > 1998  97  0  312.
> >      > 1998  98  0  313.
> >      > 1998  99  0  327.
> >      > 1998 100  0  362.
> >      > 1998 101  0  358.
> >      > 1998 102  0  387.
> >      > 1998 103  0  397.
> >      > 1998 104  0  375.
> >      > 1998 105  0  350.
> >      > 1998 106  0  357.
> >      > 1998 107  0  472.
> >      > 1998 108  0  526.
> >      > 1998 109  0  396.
> >      > 1998 110  0  374.
> >      > 1998 111  0  376.
> >      > 1998 112  0  355.
> >      > 1998 113  0  343.
> >      > 1998 114  0  425.
> >      > 1998 115  0  426.
> >      > 1998 116  0  479.
> >      > 1998 117  0  469.
> >      > 1998 118  0  425.
> >      > 1998 119  0  344.
> >      > 1998 120  0  341.
> >      > 1998 121  0  426.
> >      > 1998 122  0  601.
> >      > 1998 123  0  476.
> >      > 1998 124  0  670.
> >      > 1998 125  0  585.
> >      > 1998 126  0  496.
> >      > 1998 127  0  479.
> >      > 1998 128  0  569.
> >      > 1998 129  0  531.
> >      > 1998 130  0  489.
> >      > 1998 131  0  484.
> >      > 1998 132  0  480.
> >      > 1998 133  0  393.
> >      > 1998 134  0  332.
> >      > 1998 135  0  327.
> >      > 1998 136  0  493.
> >      > 1998 137  0  493.
> >      > 1998 138  0  430.
> >      > 1998 139  0  396.
> >      > 1998 140  0  408.
> >      > 1998 141  0  416.
> >      > 1998 142  0  376.
> >      > 1998 143  0  375.
> >      > 1998 144  0  415.
> >      > 1998 145  0  407.
> >      > 1998 146  0  398.
> >      > 1998 147  0  352.
> >      > 1998 148  0  349.
> >      > 1998 149  0  517.
> >      > 1998 150  0  597.
> >      > 1998 151  0  480.
> >      > 1998 152  0  435.
> >      > 1998 153  0  408.
> >      > 1998 154  0  441.
> >      > 1998 155  0  397.
> >      > 1998 156  0  374.
> >      > 1998 157  0  413.
> >      > 1998 158  0  582.
> >      > 1998 159  0  513.
> >      > 1998 160  0  459.
> >      > 1998 161  0  466.
> >      > 1998 162  0  414.
> >      > 1998 163  0  354.
> >      > 1998 164  0  341.
> >      > 1998 165  0  343.
> >      > 1998 166  0  369.
> >      > 1998 167  0  411.
> >      > 1998 168  0  355.
> >      > Thanks
> >      > Jibrin
> >      >
> >      > On Fri, Jan 15, 2021 at 7:15 PM Rui Barradas
> >     <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
> >      > <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>>
> wrote:
> >      >
> >      >     Hello,
> >      >
> >      >     No dataset was attached. Like the posting guide says,
> >      >
> >      >     No binary attachments except for PS, PDF, and some image and
> >     archive
> >      >     formats (others are automatically stripped off because they
> >     can contain
> >      >     malicious software). Files in other formats and larger ones
> >     should
> >      >     rather be put on the web and have only their URLs posted.
> >     This way a
> >      >     reader has the option to download them or not.
> >      >
> >      >
> >      >     Can you post sample data? Please post the output of
> >     `dput(df)`. Or, if
> >      >     it is too big the output of `dput(head(df, 20))`. (`df` is
> >     the name of
> >      >     your dataset.)
> >      >
> >      >     Hope this helps,
> >      >
> >      >     Rui Barradas
> >      >
> >      >     ?s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
> >      >      > Dear R users,
> >      >      > I am very new to R software. I have solar wind speed data
> >     needed
> >      >     for my
> >      >      > work. How do I convert day in the year to year, month, and
> >     day with R
> >      >      > software? I have used this code
> >      >      > as.Date(0, origin = "1998-01-01")
> >      >      > but it can only convert one day of the year at a time.
> >     Meanwhile,
> >      >     I have up
> >      >      > to the 1998-2002 data set. Attached is my data.
> >      >      > Kindly help, please.
> >      >      > Jibrin Alhassan
> >      >      > ______________________________________________
> >      >      > R-help at r-project.org <mailto:R-help at r-project.org>
> >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing
> list
> >      >     -- To UNSUBSCRIBE and more, see
> >      >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      >      > PLEASE do read the posting guide
> >      > http://www.R-project.org/posting-guide.html
> >      >      > and provide commented, minimal, self-contained,
> >     reproducible code.
> >      >      >
> >      >
> >
>

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Mon Jan 18 13:52:56 2021
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Mon, 18 Jan 2021 07:52:56 -0500
Subject: [R] A question regarding 749 R[21525:2855847] Warning
In-Reply-To: <CAMN+Yrdhi16XrzrpcPmuNa2FfmymM7QbdKGvTg6xr_NsWcbyLg@mail.gmail.com>
References: <2EC1A46E-0A8A-4CB7-8C22-69D20DD59A28@gmail.com>
 <3A8F43E8-118D-423F-84CB-D83C7F1F1919@me.com>
 <CAMN+Yrdhi16XrzrpcPmuNa2FfmymM7QbdKGvTg6xr_NsWcbyLg@mail.gmail.com>
Message-ID: <CAJc=yOEfUVTy4W539j5CP1owAOU8M2=mHaEvJ8JYw5L3BugiKA@mail.gmail.com>

The current version of Big Sur is 11.1, with 11.2 in public beta. So
this may have been fixed. Maedeh, are you able to check?

On Sun, Jan 17, 2021 at 4:10 PM Maedeh Kamali <maedehk205 at gmail.com> wrote:
>
> Dear Gregory Coast,
>
> Thanks for your reply.
> I searched so much regarding how to fix this problem. Unfortunately, it
> stems from Bug Sur 11.0.1 and we should wait for its new version in which
> the problem has been fixed.
>
> Best,
> Maedeh Kamali
>
> On Sat, 16 Jan 2021, 08:18 Gregory Coats, <gregcoats at me.com> wrote:
>
> > I reported this behavior on Thu Jan 7, 2021.
> > You did nothing wrong.
> > No fix has been issued.
> >
> > This evening, I upgraded from R 4.0.2 to the Duke University R 4.0.3 for
> > Apple Mac. Now all I can get from R 4.0.3 is this red error message (that
> > means nothing to me). Is there an easy fix? Greg
> >
> > 2021-01-07 22:58:42.997 R[8311:37566]
> > Warning: Expected min height of view:
> > (<NSPopoverTouchBarItemButton: 0x7fcb6c592570>)
> > to be less than or equal to 30 but got a height of 32.000000. This error
> > will be logged once per view in violation.
> >
> > On Jan 14, 2021, at 11:28 PM, maedeh kamali <maedehk205 at gmail.com> wrote:
> >
> > Dear Sir/Madam,
> >
> > After installing R package version 4.0.3 and launching the R Console for
> > the first time, below warning message appeared:
> >
> > 021-01-15 11:52:28.749 R[21525:2855847] Warning: Expected min height of
> > view: (<NSPopoverTouchBarItemButton: 0x7fdae3418d80>) to be less than or
> > equal to 30 but got a height of 32.000000. This error will be logged once
> > per view in violation.
> >
> > Could you please guide me how to fix it.
> >
> > Best,
> > Maedeh KAMALI
> > [[alternative HTML version deleted]]
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Mon Jan 18 13:56:56 2021
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Mon, 18 Jan 2021 07:56:56 -0500
Subject: [R] A question regarding 749 R[21525:2855847] Warning
In-Reply-To: <CAJc=yOEfUVTy4W539j5CP1owAOU8M2=mHaEvJ8JYw5L3BugiKA@mail.gmail.com>
References: <2EC1A46E-0A8A-4CB7-8C22-69D20DD59A28@gmail.com>
 <3A8F43E8-118D-423F-84CB-D83C7F1F1919@me.com>
 <CAMN+Yrdhi16XrzrpcPmuNa2FfmymM7QbdKGvTg6xr_NsWcbyLg@mail.gmail.com>
 <CAJc=yOEfUVTy4W539j5CP1owAOU8M2=mHaEvJ8JYw5L3BugiKA@mail.gmail.com>
Message-ID: <CAJc=yOEMsC4Gw=bwj6m2OStUpEauLUa7uPELLgMdKY0B60uBCA@mail.gmail.com>

Checked R-Sig-Mac, which I should have done before posting, then
leaving this alone on R-help. Seems to be a solved problem:
*********
The Mac R GUI: "R-GUI-7903-4.0-high-sierra-Debug" works fine.
Those warnings disappeared with this R GUI (with a 16-inch MacBook Pro
2019, Big Sur 11.0.1 operating system and R 4.0.3).

You can download the last R GUI at this address:
https://mac.r-project.org/

The last version is now the 7905. It will probably work fine too.
*********

On Mon, Jan 18, 2021 at 7:52 AM Patrick (Malone Quantitative)
<malone at malonequantitative.com> wrote:
>
> The current version of Big Sur is 11.1, with 11.2 in public beta. So
> this may have been fixed. Maedeh, are you able to check?
>
> On Sun, Jan 17, 2021 at 4:10 PM Maedeh Kamali <maedehk205 at gmail.com> wrote:
> >
> > Dear Gregory Coast,
> >
> > Thanks for your reply.
> > I searched so much regarding how to fix this problem. Unfortunately, it
> > stems from Bug Sur 11.0.1 and we should wait for its new version in which
> > the problem has been fixed.
> >
> > Best,
> > Maedeh Kamali
> >
> > On Sat, 16 Jan 2021, 08:18 Gregory Coats, <gregcoats at me.com> wrote:
> >
> > > I reported this behavior on Thu Jan 7, 2021.
> > > You did nothing wrong.
> > > No fix has been issued.
> > >
> > > This evening, I upgraded from R 4.0.2 to the Duke University R 4.0.3 for
> > > Apple Mac. Now all I can get from R 4.0.3 is this red error message (that
> > > means nothing to me). Is there an easy fix? Greg
> > >
> > > 2021-01-07 22:58:42.997 R[8311:37566]
> > > Warning: Expected min height of view:
> > > (<NSPopoverTouchBarItemButton: 0x7fcb6c592570>)
> > > to be less than or equal to 30 but got a height of 32.000000. This error
> > > will be logged once per view in violation.
> > >
> > > On Jan 14, 2021, at 11:28 PM, maedeh kamali <maedehk205 at gmail.com> wrote:
> > >
> > > Dear Sir/Madam,
> > >
> > > After installing R package version 4.0.3 and launching the R Console for
> > > the first time, below warning message appeared:
> > >
> > > 021-01-15 11:52:28.749 R[21525:2855847] Warning: Expected min height of
> > > view: (<NSPopoverTouchBarItemButton: 0x7fdae3418d80>) to be less than or
> > > equal to 30 but got a height of 32.000000. This error will be logged once
> > > per view in violation.
> > >
> > > Could you please guide me how to fix it.
> > >
> > > Best,
> > > Maedeh KAMALI
> > > [[alternative HTML version deleted]]
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Patrick S. Malone, Ph.D., Malone Quantitative
> NEW Service Models: http://malonequantitative.com
>
> He/Him/His



-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His


From @zwj|08 @end|ng |rom gm@||@com  Mon Jan 18 15:44:58 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Mon, 18 Jan 2021 22:44:58 +0800
Subject: [R] parallel: socket connection behind a NAT router
Message-ID: <CAGiFhPP58v8vJs01tRM4OxRn-9CVm0nSjSDiEg41jopnQc+HHQ@mail.gmail.com>

Hi all,

I have a few cloud instances and I want to use them to do parallel
computing. I would like to create a socket cluster on my local machine to
control the remote instances. Here is my network setup:

local machine -- NAT -- Internet -- cloud instances

In the parallel package, the server needs to call `makeCluster()` and
listens to the connection from the workers. In my case, the server is the
local machine and the workers are the cloud instances. However, since the
local machine is hidden behind the NAT, it does not have a public address
and the worker cannot connect to it. Therefore, `makeCluster()` will never
be able to see the connection from the workers and hang forever.

One solution for letting the external machine to access the device inside
the NAT is to use port forwarding. However, this would not work for my case
as the NAT is set by the network provider(not my home router) so I do not
have access to the router. As the cloud instances have public addresses,
I'll wonder if there is any way to build the cluster by letting the server
connect to the cloud? I have checked `?parallel::makeCluster` and
`?snow::makeSOCKcluster` but I found no result. The only promising solution
I can see now is to use TCP hole punching, but it is quite complicated and
may not work for every case. Since building a connection from local to the
remote is super easy, I would like to know if there exists any simple
solution. I have searched it on Google for a week but find no answer. I'll
appreciate it if you can provide me any suggestions!

Best,
Jiefei

	[[alternative HTML version deleted]]


From p@ych@o||u @end|ng |rom gm@||@com  Mon Jan 18 16:55:04 2021
From: p@ych@o||u @end|ng |rom gm@||@com (Chao Liu)
Date: Mon, 18 Jan 2021 10:55:04 -0500
Subject: [R] Print out progress reports of add1()
Message-ID: <CACCU-vO_T51PztWddB_UppFjrDTgUJYES6GpgdLa3s7Qi2nfSg@mail.gmail.com>

I have a few questions about using add1(). First of all, according to the R
document of add1(), the trace = TRUE function prints out progress reports
but my attempts to do this have failed several times. So how do we print
out the progress reports of adding terms to the model so as to test for
improved fit (or not)? Also, why the LRT (likelihood-ratio test) value is
not in the output? Any help is greatly appreciated! Example as follows:

require(graphics); require(utils)
lm1 <- lm(Fertility ~ ., data = swiss)
add1(lm1, scope = .~. + .^2, test="Chisq", trace = TRUE)

#It seems that no progress report has been printed. Also `LRT` is missing
Single term additions

Model:
Fertility ~ Agriculture + Examination + Education + Catholic +
    Infant.Mortality
                             Df Sum of Sq  RSS AIC Pr(>Chi)
<none>                                    2105 191
Agriculture:Examination       1      10.7 2094 192   0.6251
Agriculture:Education         1       1.8 2103 193   0.8399
Agriculture:Catholic          1      75.0 2030 191   0.1915
Agriculture:Infant.Mortality  1       4.4 2101 193   0.7528
Examination:Education         1      48.7 2056 192   0.2943
Examination:Catholic          1      40.8 2064 192   0.3378
Examination:Infant.Mortality  1      65.9 2039 191   0.2216
Education:Catholic            1     278.2 1827 186   0.0099 **
Education:Infant.Mortality    1      93.0 2012 191   0.1451
Catholic:Infant.Mortality     1       2.4 2103 193   0.8184
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Best,

Chao

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Jan 18 17:58:02 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 18 Jan 2021 11:58:02 -0500
Subject: [R] Print out progress reports of add1()
In-Reply-To: <CACCU-vO_T51PztWddB_UppFjrDTgUJYES6GpgdLa3s7Qi2nfSg@mail.gmail.com>
References: <CACCU-vO_T51PztWddB_UppFjrDTgUJYES6GpgdLa3s7Qi2nfSg@mail.gmail.com>
Message-ID: <eabbd4df-41b3-a574-9c80-262b2abc076a@gmail.com>

You are using add1 on an "lm" object, and add1.lm doesn't have a trace 
parameter.

Duncan Murdoch

On 18/01/2021 10:55 a.m., Chao Liu wrote:
> I have a few questions about using add1(). First of all, according to the R
> document of add1(), the trace = TRUE function prints out progress reports
> but my attempts to do this have failed several times. So how do we print
> out the progress reports of adding terms to the model so as to test for
> improved fit (or not)? Also, why the LRT (likelihood-ratio test) value is
> not in the output? Any help is greatly appreciated! Example as follows:
> 
> require(graphics); require(utils)
> lm1 <- lm(Fertility ~ ., data = swiss)
> add1(lm1, scope = .~. + .^2, test="Chisq", trace = TRUE)
> 
> #It seems that no progress report has been printed. Also `LRT` is missing
> Single term additions
> 
> Model:
> Fertility ~ Agriculture + Examination + Education + Catholic +
>      Infant.Mortality
>                               Df Sum of Sq  RSS AIC Pr(>Chi)
> <none>                                    2105 191
> Agriculture:Examination       1      10.7 2094 192   0.6251
> Agriculture:Education         1       1.8 2103 193   0.8399
> Agriculture:Catholic          1      75.0 2030 191   0.1915
> Agriculture:Infant.Mortality  1       4.4 2101 193   0.7528
> Examination:Education         1      48.7 2056 192   0.2943
> Examination:Catholic          1      40.8 2064 192   0.3378
> Examination:Infant.Mortality  1      65.9 2039 191   0.2216
> Education:Catholic            1     278.2 1827 186   0.0099 **
> Education:Infant.Mortality    1      93.0 2012 191   0.1451
> Catholic:Infant.Mortality     1       2.4 2103 193   0.8184
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Best,
> 
> Chao
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p@ych@o||u @end|ng |rom gm@||@com  Mon Jan 18 18:08:57 2021
From: p@ych@o||u @end|ng |rom gm@||@com (Chao Liu)
Date: Mon, 18 Jan 2021 12:08:57 -0500
Subject: [R] Print out progress reports of add1()
In-Reply-To: <eabbd4df-41b3-a574-9c80-262b2abc076a@gmail.com>
References: <CACCU-vO_T51PztWddB_UppFjrDTgUJYES6GpgdLa3s7Qi2nfSg@mail.gmail.com>
 <eabbd4df-41b3-a574-9c80-262b2abc076a@gmail.com>
Message-ID: <CACCU-vMvzOqRZinGdT5DyhsTiyJENB2KRBRpTxZPNN4wgvBn5A@mail.gmail.com>

Thank you Duncan. Do you by chance know any way around this?

On Mon, Jan 18, 2021 at 11:58 AM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> You are using add1 on an "lm" object, and add1.lm doesn't have a trace
> parameter.
>
> Duncan Murdoch
>
> On 18/01/2021 10:55 a.m., Chao Liu wrote:
> > I have a few questions about using add1(). First of all, according to
> the R
> > document of add1(), the trace = TRUE function prints out progress reports
> > but my attempts to do this have failed several times. So how do we print
> > out the progress reports of adding terms to the model so as to test for
> > improved fit (or not)? Also, why the LRT (likelihood-ratio test) value is
> > not in the output? Any help is greatly appreciated! Example as follows:
> >
> > require(graphics); require(utils)
> > lm1 <- lm(Fertility ~ ., data = swiss)
> > add1(lm1, scope = .~. + .^2, test="Chisq", trace = TRUE)
> >
> > #It seems that no progress report has been printed. Also `LRT` is missing
> > Single term additions
> >
> > Model:
> > Fertility ~ Agriculture + Examination + Education + Catholic +
> >      Infant.Mortality
> >                               Df Sum of Sq  RSS AIC Pr(>Chi)
> > <none>                                    2105 191
> > Agriculture:Examination       1      10.7 2094 192   0.6251
> > Agriculture:Education         1       1.8 2103 193   0.8399
> > Agriculture:Catholic          1      75.0 2030 191   0.1915
> > Agriculture:Infant.Mortality  1       4.4 2101 193   0.7528
> > Examination:Education         1      48.7 2056 192   0.2943
> > Examination:Catholic          1      40.8 2064 192   0.3378
> > Examination:Infant.Mortality  1      65.9 2039 191   0.2216
> > Education:Catholic            1     278.2 1827 186   0.0099 **
> > Education:Infant.Mortality    1      93.0 2012 191   0.1451
> > Catholic:Infant.Mortality     1       2.4 2103 193   0.8184
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Best,
> >
> > Chao
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From henr|k@bengt@@on @end|ng |rom gm@||@com  Mon Jan 18 18:22:17 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Mon, 18 Jan 2021 09:22:17 -0800
Subject: [R] parallel: socket connection behind a NAT router
In-Reply-To: <CAGiFhPP58v8vJs01tRM4OxRn-9CVm0nSjSDiEg41jopnQc+HHQ@mail.gmail.com>
References: <CAGiFhPP58v8vJs01tRM4OxRn-9CVm0nSjSDiEg41jopnQc+HHQ@mail.gmail.com>
Message-ID: <CAFDcVCRS=O-Zg=R5s9rU70oDAmpLEnuHe2m=F-c65VNzaT6RLg@mail.gmail.com>

If you have SSH access to the workers, then

workers <- c("machine1.example.org", "machine2.example.org")
cl <- parallelly::makeClusterPSOCK(workers)

should do it.  It does this without admin rights and port forwarding.
See also the README in https://cran.r-project.org/package=parallelly.

/Henrik

On Mon, Jan 18, 2021 at 6:45 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
>
> Hi all,
>
> I have a few cloud instances and I want to use them to do parallel
> computing. I would like to create a socket cluster on my local machine to
> control the remote instances. Here is my network setup:
>
> local machine -- NAT -- Internet -- cloud instances
>
> In the parallel package, the server needs to call `makeCluster()` and
> listens to the connection from the workers. In my case, the server is the
> local machine and the workers are the cloud instances. However, since the
> local machine is hidden behind the NAT, it does not have a public address
> and the worker cannot connect to it. Therefore, `makeCluster()` will never
> be able to see the connection from the workers and hang forever.
>
> One solution for letting the external machine to access the device inside
> the NAT is to use port forwarding. However, this would not work for my case
> as the NAT is set by the network provider(not my home router) so I do not
> have access to the router. As the cloud instances have public addresses,
> I'll wonder if there is any way to build the cluster by letting the server
> connect to the cloud? I have checked `?parallel::makeCluster` and
> `?snow::makeSOCKcluster` but I found no result. The only promising solution
> I can see now is to use TCP hole punching, but it is quite complicated and
> may not work for every case. Since building a connection from local to the
> remote is super easy, I would like to know if there exists any simple
> solution. I have searched it on Google for a week but find no answer. I'll
> appreciate it if you can provide me any suggestions!
>
> Best,
> Jiefei
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Jan 18 20:34:45 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 18 Jan 2021 14:34:45 -0500
Subject: [R] Print out progress reports of add1()
In-Reply-To: <CACCU-vMvzOqRZinGdT5DyhsTiyJENB2KRBRpTxZPNN4wgvBn5A@mail.gmail.com>
References: <CACCU-vO_T51PztWddB_UppFjrDTgUJYES6GpgdLa3s7Qi2nfSg@mail.gmail.com>
 <eabbd4df-41b3-a574-9c80-262b2abc076a@gmail.com>
 <CACCU-vMvzOqRZinGdT5DyhsTiyJENB2KRBRpTxZPNN4wgvBn5A@mail.gmail.com>
Message-ID: <a86a994c-d525-a7f1-660c-4b11a574309b@gmail.com>

On 18/01/2021 12:08 p.m., Chao Liu wrote:
> Thank you Duncan. Do you by chance know any way around?this?

I don't see any need for a trace when there's only one fit being done. 
The tests that are shown are all you need.

Duncan Murdoch


> 
> On Mon, Jan 18, 2021 at 11:58 AM Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     You are using add1 on an "lm" object, and add1.lm doesn't have a trace
>     parameter.
> 
>     Duncan Murdoch
> 
>     On 18/01/2021 10:55 a.m., Chao Liu wrote:
>      > I have a few questions about using add1(). First of all,
>     according to the R
>      > document of add1(), the trace = TRUE function prints out progress
>     reports
>      > but my attempts to do this have failed several times. So how do
>     we print
>      > out the progress reports of adding terms to the model so as to
>     test for
>      > improved fit (or not)? Also, why the LRT (likelihood-ratio test)
>     value is
>      > not in the output? Any help is greatly appreciated! Example as
>     follows:
>      >
>      > require(graphics); require(utils)
>      > lm1 <- lm(Fertility ~ ., data = swiss)
>      > add1(lm1, scope = .~. + .^2, test="Chisq", trace = TRUE)
>      >
>      > #It seems that no progress report has been printed. Also `LRT` is
>     missing
>      > Single term additions
>      >
>      > Model:
>      > Fertility ~ Agriculture + Examination + Education + Catholic +
>      >? ? ? Infant.Mortality
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Df Sum of Sq? RSS AIC Pr(>Chi)
>      > <none>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2105 191
>      > Agriculture:Examination? ? ? ?1? ? ? 10.7 2094 192? ?0.6251
>      > Agriculture:Education? ? ? ? ?1? ? ? ?1.8 2103 193? ?0.8399
>      > Agriculture:Catholic? ? ? ? ? 1? ? ? 75.0 2030 191? ?0.1915
>      > Agriculture:Infant.Mortality? 1? ? ? ?4.4 2101 193? ?0.7528
>      > Examination:Education? ? ? ? ?1? ? ? 48.7 2056 192? ?0.2943
>      > Examination:Catholic? ? ? ? ? 1? ? ? 40.8 2064 192? ?0.3378
>      > Examination:Infant.Mortality? 1? ? ? 65.9 2039 191? ?0.2216
>      > Education:Catholic? ? ? ? ? ? 1? ? ?278.2 1827 186? ?0.0099 **
>      > Education:Infant.Mortality? ? 1? ? ? 93.0 2012 191? ?0.1451
>      > Catholic:Infant.Mortality? ? ?1? ? ? ?2.4 2103 193? ?0.8184
>      > ---
>      > Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>      >
>      > Best,
>      >
>      > Chao
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Mon Jan 18 18:26:57 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Mon, 18 Jan 2021 17:26:57 +0000 (UTC)
Subject: [R] Different results on running Wilcoxon Rank Sum test in R and
 SPSS
References: <1910812922.2261308.1610990817343.ref@mail.yahoo.com>
Message-ID: <1910812922.2261308.1610990817343@mail.yahoo.com>

Hello,?
On running the Wilcoxon Rank Sum test in R and SPSS, I am getting the following discrepancies which I am unable to explain.
Q1 In the attached data set, I was trying to compare freq4w_n in those with drug_code 0 vs 1. SPSS gives a P value 0.031 vs R gives a P value 0.001779.?
The code I used in R is as follows -?
wilcox.test(freq4w_n, drug_code, conf.int = T)


Q2 Similarly, in the same data set, when trying to compare PFD_n in those with drug_code 0 vs 1, SPSS gives a P value 0.038 vs R gives a P value?< 2.2e-16.?
The code I used in R is as follows -?
wilcox.test(PFD_n, drug_code, mu = 0, alternative = "two.sided", correct = TRUE, paired = FALSE, conf.int = TRUE)


I have tried searching on Google and watching some Youtube tutorials, I cannot find an answer, Any help will be really appreciated, Thank you!?

From biii m@iii@g oii de@@ey@ws  Tue Jan 19 02:59:41 2021
From: biii m@iii@g oii de@@ey@ws (biii m@iii@g oii de@@ey@ws)
Date: Mon, 18 Jan 2021 20:59:41 -0500
Subject: [R] Errors and OS Differences with as.POSIXct and as.POSIXlt
Message-ID: <005f01d6ee06$c0376a80$40a63f80$@denney.ws>

Hello,

 

Dates created with as.POSIXct differ between Windows/Mac and Linux.
Specifically this time that is during a gap when the hour does not exist due
to daylight savings time:

 

as.POSIXct("2018-03-11 02:09:36", tz="America/New_York")

 

Gives on Windows:

[1] "2018-03-11 EST"

Gives on Linux (Ubuntu 20.04):

[1] "2018-03-11 01:09:36 EST"

 

Another issue and difference is that with as.POSIXlt on Linux, the invalid
time is presented:

 

as.POSIXlt("2018-03-11 02:09", tz="America/New_York")

 

Gives on Windows:

[1] "2018-03-11 EST"

Gives on Linux:

[1] "2018-03-11 02:09:00 EDT"

 

(Note that the time provided on Linux does not exist due to daylight savings
time.)

 

I think that for any invalid time, the result should be the same as an
invalid date:  NA is returned.

 

What is the intended, appropriate time, and what is the best way to fix
this?

 

Thanks,

 

Bill


	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Tue Jan 19 06:42:22 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Tue, 19 Jan 2021 13:42:22 +0800
Subject: [R] parallel: socket connection behind a NAT router
In-Reply-To: <CAFDcVCRS=O-Zg=R5s9rU70oDAmpLEnuHe2m=F-c65VNzaT6RLg@mail.gmail.com>
References: <CAGiFhPP58v8vJs01tRM4OxRn-9CVm0nSjSDiEg41jopnQc+HHQ@mail.gmail.com>
 <CAFDcVCRS=O-Zg=R5s9rU70oDAmpLEnuHe2m=F-c65VNzaT6RLg@mail.gmail.com>
Message-ID: <CAGiFhPP=bULzpc9EZ57H_Y70iMWB8se=cdicr49pKwGcdhSs7g@mail.gmail.com>

Thanks for introducing this interesting package to me! it is great to know
a new powerful tool, but it seems like this method does not work in my
environment. ` parallelly::makeClusterPSOCK` will hang until timeout.

I checked the verbose output and it looks like the parallelly package also
depends on `parallel:::.slaveRSOCK` on the remote instance to build the
connection. This explains why it failed for the local machine does not have
a public IP and the remote does not know how to build the connection.

I see in README the package states it works with "remote clusters without
knowing public IP". I think this might be where the confusion is, it may
mean the remote machine does not have a public IP, but the server machine
does. I'm in the opposite situation, the server does not have a public IP,
but the remote does. I'm not sure if this package can handle my case, but
it looks very powerful and I appreciate your help!

Best,
Jiefei





On Tue, Jan 19, 2021 at 1:22 AM Henrik Bengtsson <henrik.bengtsson at gmail.com>
wrote:

> If you have SSH access to the workers, then
>
> workers <- c("machine1.example.org", "machine2.example.org")
> cl <- parallelly::makeClusterPSOCK(workers)
>
> should do it.  It does this without admin rights and port forwarding.
> See also the README in https://cran.r-project.org/package=parallelly.
>
> /Henrik
>
> On Mon, Jan 18, 2021 at 6:45 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
> >
> > Hi all,
> >
> > I have a few cloud instances and I want to use them to do parallel
> > computing. I would like to create a socket cluster on my local machine to
> > control the remote instances. Here is my network setup:
> >
> > local machine -- NAT -- Internet -- cloud instances
> >
> > In the parallel package, the server needs to call `makeCluster()` and
> > listens to the connection from the workers. In my case, the server is the
> > local machine and the workers are the cloud instances. However, since the
> > local machine is hidden behind the NAT, it does not have a public address
> > and the worker cannot connect to it. Therefore, `makeCluster()` will
> never
> > be able to see the connection from the workers and hang forever.
> >
> > One solution for letting the external machine to access the device inside
> > the NAT is to use port forwarding. However, this would not work for my
> case
> > as the NAT is set by the network provider(not my home router) so I do not
> > have access to the router. As the cloud instances have public addresses,
> > I'll wonder if there is any way to build the cluster by letting the
> server
> > connect to the cloud? I have checked `?parallel::makeCluster` and
> > `?snow::makeSOCKcluster` but I found no result. The only promising
> solution
> > I can see now is to use TCP hole punching, but it is quite complicated
> and
> > may not work for every case. Since building a connection from local to
> the
> > remote is super easy, I would like to know if there exists any simple
> > solution. I have searched it on Google for a week but find no answer.
> I'll
> > appreciate it if you can provide me any suggestions!
> >
> > Best,
> > Jiefei
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From henr|k@bengt@@on @end|ng |rom gm@||@com  Tue Jan 19 07:50:03 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Mon, 18 Jan 2021 22:50:03 -0800
Subject: [R] parallel: socket connection behind a NAT router
In-Reply-To: <CAGiFhPP=bULzpc9EZ57H_Y70iMWB8se=cdicr49pKwGcdhSs7g@mail.gmail.com>
References: <CAGiFhPP58v8vJs01tRM4OxRn-9CVm0nSjSDiEg41jopnQc+HHQ@mail.gmail.com>
 <CAFDcVCRS=O-Zg=R5s9rU70oDAmpLEnuHe2m=F-c65VNzaT6RLg@mail.gmail.com>
 <CAGiFhPP=bULzpc9EZ57H_Y70iMWB8se=cdicr49pKwGcdhSs7g@mail.gmail.com>
Message-ID: <CAFDcVCT5uoqN6_uUG1F9YDUR6-TN4hXLdG6vQs1mUaB0Ldkx8A@mail.gmail.com>

On Mon, Jan 18, 2021 at 9:42 PM Jiefei Wang <szwjf08 at gmail.com> wrote:
>
> Thanks for introducing this interesting package to me! it is great to know a new powerful tool, but it seems like this method does not work in my environment. ` parallelly::makeClusterPSOCK` will hang until timeout.
>
> I checked the verbose output and it looks like the parallelly package also depends on `parallel:::.slaveRSOCK` on the remote instance to build the connection. This explains why it failed for the local machine does not have a public IP and the remote does not know how to build the connection.

It's correct that the worker does attempt to connect back to the
parent R process that runs on your local machine.  However, it does
*not* do so by your local machines public IP address but it does it by
connecting to a port on its own machine - a port that was set up by
SSH.  More specifically, when parallelly::makeClusterPSOCK() connects
to the remote machine over SSH it also sets up a so-called reverse SSH
tunnel with a certain port on your local machine and certain port of
your remote machine.  This is what happens:

> cl <- parallelly::makeClusterPSOCK("machine1.example.org", verbose=TRUE)
[local output] Workers: [n = 1] 'machine1.example.org'
[local output] Base port: 11019
...
[local output] Starting worker #1 on 'machine1.example.org':
'/usr/bin/ssh' -R 11068:localhost:11068 machine1.example.org
"'Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods
-e 'workRSOCK <- tryCatch(parallel:::.slaveRSOCK, error=function(e)
parallel:::.workRSOCK); workRSOCK()' MASTER=localhost PORT=11068
OUT=/dev/null TIMEOUT=2592000 XDR=FALSE"
[local output] - Exit code of system() call: 0
[local output] Waiting for worker #1 on 'machine1.example.org' to
connect back  '/usr/bin/ssh' -R 11019:localhost:11019
machine1.example.org "'Rscript'
--default-packages=datasets,utils,grDevices,graphics,stats,methods -e
'workRSOCK <- tryCatch(parallel:::.slaveRSOCK, error=function(e)
parallel:::.workRSOCK); workRSOCK()' MASTER=localhost PORT=11019
OUT=/dev/null TIMEOUT=2592000 XDR=FALSE"

All the magic is in that SSH option '-R 11068:localhost:11068' SSH
options, which allow the parent R process on your local machine to
communicate with the remote worker R process on its own port 11068,
and vice versa, the worker R process will communicate with the parent
R process as if it was running on MASTER=localhost PORT=11068.
Basically, for all that the worker R process' knows, the parent R
process runs on the same machine as itself.

You haven't said what operating system you're running on your local
machine, but if it's MS Windows, know that the 'ssh' client that comes
with Windows 10 has some bugs in its reverse tunneling.  See
?parallelly::makeClusterPSOCK for lots of details.  You also haven't
said what OS the cloud workers run, but I assume it's Linux.

So, my guesses on your setup is, the above "should work" for you.  For
your troubleshooting, you can also set argument outfile=NULL.  Then
you'll also see output from the worker R process.  There are
additional troubleshooting suggestions in Section 'Failing to set up
remote workers' of ?parallelly::makeClusterPSOCK that will help you
figure out what the problem is.

>
> I see in README the package states it works with "remote clusters without knowing public IP". I think this might be where the confusion is, it may mean the remote machine does not have a public IP, but the server machine does. I'm in the opposite situation, the server does not have a public IP, but the remote does. I'm not sure if this package can handle my case, but it looks very powerful and I appreciate your help!

Thanks. I've updated the text to "remote clusters without knowing
[local] public IP".

/Henrik

>
> Best,
> Jiefei
>
>
>
>
>
> On Tue, Jan 19, 2021 at 1:22 AM Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>
>> If you have SSH access to the workers, then
>>
>> workers <- c("machine1.example.org", "machine2.example.org")
>> cl <- parallelly::makeClusterPSOCK(workers)
>>
>> should do it.  It does this without admin rights and port forwarding.
>> See also the README in https://cran.r-project.org/package=parallelly.
>>
>> /Henrik
>>
>> On Mon, Jan 18, 2021 at 6:45 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
>> >
>> > Hi all,
>> >
>> > I have a few cloud instances and I want to use them to do parallel
>> > computing. I would like to create a socket cluster on my local machine to
>> > control the remote instances. Here is my network setup:
>> >
>> > local machine -- NAT -- Internet -- cloud instances
>> >
>> > In the parallel package, the server needs to call `makeCluster()` and
>> > listens to the connection from the workers. In my case, the server is the
>> > local machine and the workers are the cloud instances. However, since the
>> > local machine is hidden behind the NAT, it does not have a public address
>> > and the worker cannot connect to it. Therefore, `makeCluster()` will never
>> > be able to see the connection from the workers and hang forever.
>> >
>> > One solution for letting the external machine to access the device inside
>> > the NAT is to use port forwarding. However, this would not work for my case
>> > as the NAT is set by the network provider(not my home router) so I do not
>> > have access to the router. As the cloud instances have public addresses,
>> > I'll wonder if there is any way to build the cluster by letting the server
>> > connect to the cloud? I have checked `?parallel::makeCluster` and
>> > `?snow::makeSOCKcluster` but I found no result. The only promising solution
>> > I can see now is to use TCP hole punching, but it is quite complicated and
>> > may not work for every case. Since building a connection from local to the
>> > remote is super easy, I would like to know if there exists any simple
>> > solution. I have searched it on Google for a week but find no answer. I'll
>> > appreciate it if you can provide me any suggestions!
>> >
>> > Best,
>> > Jiefei
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Tue Jan 19 08:11:49 2021
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Tue, 19 Jan 2021 07:11:49 +0000
Subject: [R] parallel: socket connection behind a NAT router
In-Reply-To: <CAFDcVCT5uoqN6_uUG1F9YDUR6-TN4hXLdG6vQs1mUaB0Ldkx8A@mail.gmail.com>
References: <CAGiFhPP58v8vJs01tRM4OxRn-9CVm0nSjSDiEg41jopnQc+HHQ@mail.gmail.com>
 <CAFDcVCRS=O-Zg=R5s9rU70oDAmpLEnuHe2m=F-c65VNzaT6RLg@mail.gmail.com>
 <CAGiFhPP=bULzpc9EZ57H_Y70iMWB8se=cdicr49pKwGcdhSs7g@mail.gmail.com>
 <CAFDcVCT5uoqN6_uUG1F9YDUR6-TN4hXLdG6vQs1mUaB0Ldkx8A@mail.gmail.com>
Message-ID: <DM6PR04MB6624D8842000DEA4EA00AF19F9A30@DM6PR04MB6624.namprd04.prod.outlook.com>

A different approach uses doRedis https://CRAN.R-project.org/package=doRedis (currently archived, but actively developed) for use with the foreach package, or RedisParam https://github.com/mtmorgan/RedisParam (not released) for use with Bioconductor's BiocParallel package.

These use a redis server https://redis.io/ to communicate -- the manager submits jobs / obtains results from the redis server, the workers retrieve jobs / submit results to the redis server. Manager and worker need to know the (http) address of the server, etc, but there are no other ports involved.

Redis servers are easy to establish in a cloud environment, using e.g., existing AWS or docker images. The README for doRedis https://github.com/bwlewis/doRedis probably provides the easiest introduction.

The (not mature) k8sredis Kubernetes / helm chart https://github.com/Bioconductor/k8sredis illustrates a complete system using RedisParam, deploying manager and workers locally or in the google cloud; the app could be modified to only start the workers in the cloud, exposing the redis server for access by a local 'manager'; this would be cool.

Martin 

?On 1/19/21, 1:50 AM, "R-help on behalf of Henrik Bengtsson" <r-help-bounces at r-project.org on behalf of henrik.bengtsson at gmail.com> wrote:

    On Mon, Jan 18, 2021 at 9:42 PM Jiefei Wang <szwjf08 at gmail.com> wrote:
    >
    > Thanks for introducing this interesting package to me! it is great to know a new powerful tool, but it seems like this method does not work in my environment. ` parallelly::makeClusterPSOCK` will hang until timeout.
    >
    > I checked the verbose output and it looks like the parallelly package also depends on `parallel:::.slaveRSOCK` on the remote instance to build the connection. This explains why it failed for the local machine does not have a public IP and the remote does not know how to build the connection.

    It's correct that the worker does attempt to connect back to the
    parent R process that runs on your local machine.  However, it does
    *not* do so by your local machines public IP address but it does it by
    connecting to a port on its own machine - a port that was set up by
    SSH.  More specifically, when parallelly::makeClusterPSOCK() connects
    to the remote machine over SSH it also sets up a so-called reverse SSH
    tunnel with a certain port on your local machine and certain port of
    your remote machine.  This is what happens:

    > cl <- parallelly::makeClusterPSOCK("machine1.example.org", verbose=TRUE)
    [local output] Workers: [n = 1] 'machine1.example.org'
    [local output] Base port: 11019
    ...
    [local output] Starting worker #1 on 'machine1.example.org':
    '/usr/bin/ssh' -R 11068:localhost:11068 machine1.example.org
    "'Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods
    -e 'workRSOCK <- tryCatch(parallel:::.slaveRSOCK, error=function(e)
    parallel:::.workRSOCK); workRSOCK()' MASTER=localhost PORT=11068
    OUT=/dev/null TIMEOUT=2592000 XDR=FALSE"
    [local output] - Exit code of system() call: 0
    [local output] Waiting for worker #1 on 'machine1.example.org' to
    connect back  '/usr/bin/ssh' -R 11019:localhost:11019
    machine1.example.org "'Rscript'
    --default-packages=datasets,utils,grDevices,graphics,stats,methods -e
    'workRSOCK <- tryCatch(parallel:::.slaveRSOCK, error=function(e)
    parallel:::.workRSOCK); workRSOCK()' MASTER=localhost PORT=11019
    OUT=/dev/null TIMEOUT=2592000 XDR=FALSE"

    All the magic is in that SSH option '-R 11068:localhost:11068' SSH
    options, which allow the parent R process on your local machine to
    communicate with the remote worker R process on its own port 11068,
    and vice versa, the worker R process will communicate with the parent
    R process as if it was running on MASTER=localhost PORT=11068.
    Basically, for all that the worker R process' knows, the parent R
    process runs on the same machine as itself.

    You haven't said what operating system you're running on your local
    machine, but if it's MS Windows, know that the 'ssh' client that comes
    with Windows 10 has some bugs in its reverse tunneling.  See
    ?parallelly::makeClusterPSOCK for lots of details.  You also haven't
    said what OS the cloud workers run, but I assume it's Linux.

    So, my guesses on your setup is, the above "should work" for you.  For
    your troubleshooting, you can also set argument outfile=NULL.  Then
    you'll also see output from the worker R process.  There are
    additional troubleshooting suggestions in Section 'Failing to set up
    remote workers' of ?parallelly::makeClusterPSOCK that will help you
    figure out what the problem is.

    >
    > I see in README the package states it works with "remote clusters without knowing public IP". I think this might be where the confusion is, it may mean the remote machine does not have a public IP, but the server machine does. I'm in the opposite situation, the server does not have a public IP, but the remote does. I'm not sure if this package can handle my case, but it looks very powerful and I appreciate your help!

    Thanks. I've updated the text to "remote clusters without knowing
    [local] public IP".

    /Henrik

    >
    > Best,
    > Jiefei
    >
    >
    >
    >
    >
    > On Tue, Jan 19, 2021 at 1:22 AM Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
    >>
    >> If you have SSH access to the workers, then
    >>
    >> workers <- c("machine1.example.org", "machine2.example.org")
    >> cl <- parallelly::makeClusterPSOCK(workers)
    >>
    >> should do it.  It does this without admin rights and port forwarding.
    >> See also the README in https://cran.r-project.org/package=parallelly.
    >>
    >> /Henrik
    >>
    >> On Mon, Jan 18, 2021 at 6:45 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
    >> >
    >> > Hi all,
    >> >
    >> > I have a few cloud instances and I want to use them to do parallel
    >> > computing. I would like to create a socket cluster on my local machine to
    >> > control the remote instances. Here is my network setup:
    >> >
    >> > local machine -- NAT -- Internet -- cloud instances
    >> >
    >> > In the parallel package, the server needs to call `makeCluster()` and
    >> > listens to the connection from the workers. In my case, the server is the
    >> > local machine and the workers are the cloud instances. However, since the
    >> > local machine is hidden behind the NAT, it does not have a public address
    >> > and the worker cannot connect to it. Therefore, `makeCluster()` will never
    >> > be able to see the connection from the workers and hang forever.
    >> >
    >> > One solution for letting the external machine to access the device inside
    >> > the NAT is to use port forwarding. However, this would not work for my case
    >> > as the NAT is set by the network provider(not my home router) so I do not
    >> > have access to the router. As the cloud instances have public addresses,
    >> > I'll wonder if there is any way to build the cluster by letting the server
    >> > connect to the cloud? I have checked `?parallel::makeCluster` and
    >> > `?snow::makeSOCKcluster` but I found no result. The only promising solution
    >> > I can see now is to use TCP hole punching, but it is quite complicated and
    >> > may not work for every case. Since building a connection from local to the
    >> > remote is super easy, I would like to know if there exists any simple
    >> > solution. I have searched it on Google for a week but find no answer. I'll
    >> > appreciate it if you can provide me any suggestions!
    >> >
    >> > Best,
    >> > Jiefei
    >> >
    >> >         [[alternative HTML version deleted]]
    >> >
    >> > ______________________________________________
    >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> > https://stat.ethz.ch/mailman/listinfo/r-help
    >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> > and provide commented, minimal, self-contained, reproducible code.

    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.

From wdenney @end|ng |rom hum@npred|ct|on@@com  Tue Jan 19 02:56:11 2021
From: wdenney @end|ng |rom hum@npred|ct|on@@com (Bill Denney)
Date: Mon, 18 Jan 2021 20:56:11 -0500
Subject: [R] Errors and OS Differences with as.POSIXct and as.POSIXlt
Message-ID: <8c89a507cc1de32aecf720ffacc36673@mail.gmail.com>

Hello,



Dates created with as.POSIXct differ between Windows/Mac and Linux.
Specifically this time that is during a gap when the hour does not exist
due to daylight savings time:



as.POSIXct("2018-03-11 02:09:36", tz="America/New_York")



Gives on Windows:

[1] "2018-03-11 EST"

Gives on Linux (Ubuntu 20.04):

[1] "2018-03-11 01:09:36 EST"



Since the time does not exist, and I think that NA should be returned.



Another issue and difference is that with as.POSIXlt on Linux, the invalid
time is presented:



as.POSIXlt("2018-03-11 02:09", tz="America/New_York")



Gives on Windows:

[1] "2018-03-11 EST"

Gives on Linux:

[1] "2018-03-11 02:09:00 EDT"



(Note that the time provided on Linux does not exist due to daylight
savings time.)



I think that for any invalid time, the result should be the same as an
invalid date:  NA is returned.



What is the intended, appropriate time, and what is the best way to fix
this?



Thanks,



Bill

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 19 09:57:53 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 19 Jan 2021 00:57:53 -0800
Subject: [R] Errors and OS Differences with as.POSIXct and as.POSIXlt
In-Reply-To: <8c89a507cc1de32aecf720ffacc36673@mail.gmail.com>
References: <8c89a507cc1de32aecf720ffacc36673@mail.gmail.com>
Message-ID: <4ED60B39-4D04-46A5-BDC0-4BB6E84CC916@dcn.davis.ca.us>

This is as described in the documentation, due to OS differences, e.g
 [1].

[1] https://stat.ethz.ch/R-manual/R-devel/library/base/html/strptime.html

On January 18, 2021 5:56:11 PM PST, Bill Denney <wdenney at humanpredictions.com> wrote:
>Hello,
>
>
>
>Dates created with as.POSIXct differ between Windows/Mac and Linux.
>Specifically this time that is during a gap when the hour does not
>exist
>due to daylight savings time:
>
>
>
>as.POSIXct("2018-03-11 02:09:36", tz="America/New_York")
>
>
>
>Gives on Windows:
>
>[1] "2018-03-11 EST"
>
>Gives on Linux (Ubuntu 20.04):
>
>[1] "2018-03-11 01:09:36 EST"
>
>
>
>Since the time does not exist, and I think that NA should be returned.
>
>
>
>Another issue and difference is that with as.POSIXlt on Linux, the
>invalid
>time is presented:
>
>
>
>as.POSIXlt("2018-03-11 02:09", tz="America/New_York")
>
>
>
>Gives on Windows:
>
>[1] "2018-03-11 EST"
>
>Gives on Linux:
>
>[1] "2018-03-11 02:09:00 EDT"
>
>
>
>(Note that the time provided on Linux does not exist due to daylight
>savings time.)
>
>
>
>I think that for any invalid time, the result should be the same as an
>invalid date:  NA is returned.
>
>
>
>What is the intended, appropriate time, and what is the best way to fix
>this?
>
>
>
>Thanks,
>
>
>
>Bill
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Jan 19 11:14:01 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 19 Jan 2021 10:14:01 +0000
Subject: [R] Errors and OS Differences with as.POSIXct and as.POSIXlt
In-Reply-To: <8c89a507cc1de32aecf720ffacc36673@mail.gmail.com>
References: <8c89a507cc1de32aecf720ffacc36673@mail.gmail.com>
Message-ID: <cb9eae41-283c-d3e4-fe00-5e6bc97f7727@sapo.pt>

Hello,

R 4.0.3 on Ubuntu 20.04, sessionInfo() below.

A fix is to use as.POSIXct instead:

rui at rui:~$ Rscript --vanilla -e 'as.POSIXlt("2018-03-11 02:09", 
tz="America/New_York")'
#[1] "2018-03-11 02:09:00 EDT"
rui at rui:~$ Rscript --vanilla -e 'as.POSIXct("2018-03-11 02:09", 
tz="America/New_York")'
#[1] "2018-03-11 01:09:00 EST"


rui at rui:~$ Rscript --vanilla -e 'sessionInfo()'
R version 4.0.3 (2020-10-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.1 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
  [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
  [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
  [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.3


Hope this helps,

Rui Barradas
?s 01:56 de 19/01/21, Bill Denney escreveu:
> Hello,
> 
> 
> 
> Dates created with as.POSIXct differ between Windows/Mac and Linux.
> Specifically this time that is during a gap when the hour does not exist
> due to daylight savings time:
> 
> 
> 
> as.POSIXct("2018-03-11 02:09:36", tz="America/New_York")
> 
> 
> 
> Gives on Windows:
> 
> [1] "2018-03-11 EST"
> 
> Gives on Linux (Ubuntu 20.04):
> 
> [1] "2018-03-11 01:09:36 EST"
> 
> 
> 
> Since the time does not exist, and I think that NA should be returned.
> 
> 
> 
> Another issue and difference is that with as.POSIXlt on Linux, the invalid
> time is presented:
> 
> 
> 
> as.POSIXlt("2018-03-11 02:09", tz="America/New_York")
> 
> 
> 
> Gives on Windows:
> 
> [1] "2018-03-11 EST"
> 
> Gives on Linux:
> 
> [1] "2018-03-11 02:09:00 EDT"
> 
> 
> 
> (Note that the time provided on Linux does not exist due to daylight
> savings time.)
> 
> 
> 
> I think that for any invalid time, the result should be the same as an
> invalid date:  NA is returned.
> 
> 
> 
> What is the intended, appropriate time, and what is the best way to fix
> this?
> 
> 
> 
> Thanks,
> 
> 
> 
> Bill
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Jan 19 11:23:19 2021
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 19 Jan 2021 10:23:19 +0000
Subject: [R] 
 Different results on running Wilcoxon Rank Sum test in R and SPSS
In-Reply-To: <1910812922.2261308.1610990817343@mail.yahoo.com>
References: <1910812922.2261308.1610990817343.ref@mail.yahoo.com>
 <1910812922.2261308.1610990817343@mail.yahoo.com>
Message-ID: <e9902222-0459-16a4-1d86-4411f93f6c7c@dewey.myzen.co.uk>

Unfortunately your data did not come through. Try using dput() and then 
pasting that into the body of your e-mail message.

On 18/01/2021 17:26, bharat rawlley via R-help wrote:
> Hello,
> On running the Wilcoxon Rank Sum test in R and SPSS, I am getting the following discrepancies which I am unable to explain.
> Q1 In the attached data set, I was trying to compare freq4w_n in those with drug_code 0 vs 1. SPSS gives a P value 0.031 vs R gives a P value 0.001779.
> The code I used in R is as follows -
> wilcox.test(freq4w_n, drug_code, conf.int = T)
> 
> 
> Q2 Similarly, in the same data set, when trying to compare PFD_n in those with drug_code 0 vs 1, SPSS gives a P value 0.038 vs R gives a P value?< 2.2e-16.
> The code I used in R is as follows -
> wilcox.test(PFD_n, drug_code, mu = 0, alternative = "two.sided", correct = TRUE, paired = FALSE, conf.int = TRUE)
> 
> 
> I have tried searching on Google and watching some Youtube tutorials, I cannot find an answer, Any help will be really appreciated, Thank you!
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Tue Jan 19 11:46:25 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Tue, 19 Jan 2021 10:46:25 +0000 (UTC)
Subject: [R] 
 Different results on running Wilcoxon Rank Sum test in R and SPSS
In-Reply-To: <e9902222-0459-16a4-1d86-4411f93f6c7c@dewey.myzen.co.uk>
References: <1910812922.2261308.1610990817343.ref@mail.yahoo.com>
 <1910812922.2261308.1610990817343@mail.yahoo.com>
 <e9902222-0459-16a4-1d86-4411f93f6c7c@dewey.myzen.co.uk>
Message-ID: <448702623.708494.1611053185609@mail.yahoo.com>

 Thank you for the reply and suggestion, Michael!?
I used dput() and this is the output I can share with you. Simply explained, I have 3 columns namely, drug_code, freq4w_n and PFD_n. Each column has 132 values (including NA). The problem with the Wilcoxon Rank Sum test has been described in my first email.?
Please do let me know if you need any further clarification from my side! Thanks a lot for your time!??
structure(list(drug_code = c(0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,?1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,?0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,?1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,?0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,?1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,?1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0), freq4w_n = c(1,?NA, NA, 0, NA, 4, NA, 10, NA, 0, 6, NA, NA, NA, NA, NA, 10, NA,?0, NA, NA, NA, NA, 0, NA, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA,?NA, NA, NA, NA, NA, 0, 0, 12, 0, NA, 1, 2, 1, 2, 2, NA, 28, 0,?NA, 4, NA, 1, NA, NA, NA, NA, NA, 0, 3, 1, NA, NA, NA, NA, 4,?28, NA, NA, 0, 2, 12, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA, NA,?NA, NA, NA, NA, NA, 3, NA, NA, NA, NA, NA, NA, 6, 1, NA, NA,?NA, 0, NA, NA, NA, 0, 0, NA, 0, NA, 2, 8, 3, NA, NA, NA, 0, NA,?NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA), PFD_n = c(27, NA,?NA, 28, NA, 26, NA, 20, NA, 30, 24, NA, NA, NA, NA, NA, 18, NA,?28, NA, NA, NA, NA, 28, NA, 28, NA, NA, NA, 28, NA, 28, NA, NA,?NA, NA, NA, NA, NA, NA, 28, 28, 16, 28, NA, 27, 26, 27, 26, 26,?NA, 0, 30, NA, 24, NA, 27, NA, NA, NA, NA, NA, 28, 25, 27, NA,?NA, NA, NA, 26, 0, NA, NA, 28, 26, 16, 28, NA, NA, NA, 28, NA,?28, NA, NA, NA, NA, NA, NA, NA, NA, NA, 25, NA, NA, NA, NA, NA,?NA, 22, 27, NA, NA, NA, 28, NA, NA, NA, 28, 28, NA, 28, NA, 26,?20, 25, NA, NA, NA, 30, NA, NA, NA, 19, NA, NA, NA, NA, NA, NA,?NA, NA)), row.names = c(NA, -132L), class = c("tbl_df", "tbl",?"data.frame"))

Yours sincerely?Bharat Rawlley    On Tuesday, 19 January, 2021, 03:53:27 pm IST, Michael Dewey <lists at dewey.myzen.co.uk> wrote:  
 
 Unfortunately your data did not come through. Try using dput() and then 
pasting that into the body of your e-mail message.

On 18/01/2021 17:26, bharat rawlley via R-help wrote:
> Hello,
> On running the Wilcoxon Rank Sum test in R and SPSS, I am getting the following discrepancies which I am unable to explain.
> Q1 In the attached data set, I was trying to compare freq4w_n in those with drug_code 0 vs 1. SPSS gives a P value 0.031 vs R gives a P value 0.001779.
> The code I used in R is as follows -
> wilcox.test(freq4w_n, drug_code, conf.int = T)
> 
> 
> Q2 Similarly, in the same data set, when trying to compare PFD_n in those with drug_code 0 vs 1, SPSS gives a P value 0.038 vs R gives a P value?< 2.2e-16.
> The code I used in R is as follows -
> wilcox.test(PFD_n, drug_code, mu = 0, alternative = "two.sided", correct = TRUE, paired = FALSE, conf.int = TRUE)
> 
> 
> I have tried searching on Google and watching some Youtube tutorials, I cannot find an answer, Any help will be really appreciated, Thank you!
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html
  
	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Tue Jan 19 13:57:11 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Tue, 19 Jan 2021 20:57:11 +0800
Subject: [R] parallel: socket connection behind a NAT router
In-Reply-To: <CAFDcVCT5uoqN6_uUG1F9YDUR6-TN4hXLdG6vQs1mUaB0Ldkx8A@mail.gmail.com>
References: <CAGiFhPP58v8vJs01tRM4OxRn-9CVm0nSjSDiEg41jopnQc+HHQ@mail.gmail.com>
 <CAFDcVCRS=O-Zg=R5s9rU70oDAmpLEnuHe2m=F-c65VNzaT6RLg@mail.gmail.com>
 <CAGiFhPP=bULzpc9EZ57H_Y70iMWB8se=cdicr49pKwGcdhSs7g@mail.gmail.com>
 <CAFDcVCT5uoqN6_uUG1F9YDUR6-TN4hXLdG6vQs1mUaB0Ldkx8A@mail.gmail.com>
Message-ID: <CAGiFhPPaVvApFZ+Sy5C9yQPbCttGeUM5+okrb8qEvh8prtg+Hw@mail.gmail.com>

Thank you! It works now!!

Your guess is correct, I'm using windows so the default ssh does not work.
Sadly the bug hasn't been fixed yet. The PuTTY solution works like a charm.
Glad to know the ssh tunneling trick. This is much simpler than using port
hole punching. This package is awesome! Many thanks for your help!!!

Best,
Jiefei

On Tue, Jan 19, 2021 at 2:50 PM Henrik Bengtsson <henrik.bengtsson at gmail.com>
wrote:

> On Mon, Jan 18, 2021 at 9:42 PM Jiefei Wang <szwjf08 at gmail.com> wrote:
> >
> > Thanks for introducing this interesting package to me! it is great to
> know a new powerful tool, but it seems like this method does not work in my
> environment. ` parallelly::makeClusterPSOCK` will hang until timeout.
> >
> > I checked the verbose output and it looks like the parallelly package
> also depends on `parallel:::.slaveRSOCK` on the remote instance to build
> the connection. This explains why it failed for the local machine does not
> have a public IP and the remote does not know how to build the connection.
>
> It's correct that the worker does attempt to connect back to the
> parent R process that runs on your local machine.  However, it does
> *not* do so by your local machines public IP address but it does it by
> connecting to a port on its own machine - a port that was set up by
> SSH.  More specifically, when parallelly::makeClusterPSOCK() connects
> to the remote machine over SSH it also sets up a so-called reverse SSH
> tunnel with a certain port on your local machine and certain port of
> your remote machine.  This is what happens:
>
> > cl <- parallelly::makeClusterPSOCK("machine1.example.org", verbose=TRUE)
> [local output] Workers: [n = 1] 'machine1.example.org'
> [local output] Base port: 11019
> ...
> [local output] Starting worker #1 on 'machine1.example.org':
> '/usr/bin/ssh' -R 11068:localhost:11068 machine1.example.org
> "'Rscript'
> --default-packages=datasets,utils,grDevices,graphics,stats,methods
> -e 'workRSOCK <- tryCatch(parallel:::.slaveRSOCK, error=function(e)
> parallel:::.workRSOCK); workRSOCK()' MASTER=localhost PORT=11068
> OUT=/dev/null TIMEOUT=2592000 XDR=FALSE"
> [local output] - Exit code of system() call: 0
> [local output] Waiting for worker #1 on 'machine1.example.org' to
> connect back  '/usr/bin/ssh' -R 11019:localhost:11019
> machine1.example.org "'Rscript'
> --default-packages=datasets,utils,grDevices,graphics,stats,methods -e
> 'workRSOCK <- tryCatch(parallel:::.slaveRSOCK, error=function(e)
> parallel:::.workRSOCK); workRSOCK()' MASTER=localhost PORT=11019
> OUT=/dev/null TIMEOUT=2592000 XDR=FALSE"
>
> All the magic is in that SSH option '-R 11068:localhost:11068' SSH
> options, which allow the parent R process on your local machine to
> communicate with the remote worker R process on its own port 11068,
> and vice versa, the worker R process will communicate with the parent
> R process as if it was running on MASTER=localhost PORT=11068.
> Basically, for all that the worker R process' knows, the parent R
> process runs on the same machine as itself.
>
> You haven't said what operating system you're running on your local
> machine, but if it's MS Windows, know that the 'ssh' client that comes
> with Windows 10 has some bugs in its reverse tunneling.  See
> ?parallelly::makeClusterPSOCK for lots of details.  You also haven't
> said what OS the cloud workers run, but I assume it's Linux.
>
> So, my guesses on your setup is, the above "should work" for you.  For
> your troubleshooting, you can also set argument outfile=NULL.  Then
> you'll also see output from the worker R process.  There are
> additional troubleshooting suggestions in Section 'Failing to set up
> remote workers' of ?parallelly::makeClusterPSOCK that will help you
> figure out what the problem is.
>
> >
> > I see in README the package states it works with "remote clusters
> without knowing public IP". I think this might be where the confusion is,
> it may mean the remote machine does not have a public IP, but the server
> machine does. I'm in the opposite situation, the server does not have a
> public IP, but the remote does. I'm not sure if this package can handle my
> case, but it looks very powerful and I appreciate your help!
>
> Thanks. I've updated the text to "remote clusters without knowing
> [local] public IP".
>
> /Henrik
>
> >
> > Best,
> > Jiefei
> >
> >
> >
> >
> >
> > On Tue, Jan 19, 2021 at 1:22 AM Henrik Bengtsson <
> henrik.bengtsson at gmail.com> wrote:
> >>
> >> If you have SSH access to the workers, then
> >>
> >> workers <- c("machine1.example.org", "machine2.example.org")
> >> cl <- parallelly::makeClusterPSOCK(workers)
> >>
> >> should do it.  It does this without admin rights and port forwarding.
> >> See also the README in https://cran.r-project.org/package=parallelly.
> >>
> >> /Henrik
> >>
> >> On Mon, Jan 18, 2021 at 6:45 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
> >> >
> >> > Hi all,
> >> >
> >> > I have a few cloud instances and I want to use them to do parallel
> >> > computing. I would like to create a socket cluster on my local
> machine to
> >> > control the remote instances. Here is my network setup:
> >> >
> >> > local machine -- NAT -- Internet -- cloud instances
> >> >
> >> > In the parallel package, the server needs to call `makeCluster()` and
> >> > listens to the connection from the workers. In my case, the server is
> the
> >> > local machine and the workers are the cloud instances. However, since
> the
> >> > local machine is hidden behind the NAT, it does not have a public
> address
> >> > and the worker cannot connect to it. Therefore, `makeCluster()` will
> never
> >> > be able to see the connection from the workers and hang forever.
> >> >
> >> > One solution for letting the external machine to access the device
> inside
> >> > the NAT is to use port forwarding. However, this would not work for
> my case
> >> > as the NAT is set by the network provider(not my home router) so I do
> not
> >> > have access to the router. As the cloud instances have public
> addresses,
> >> > I'll wonder if there is any way to build the cluster by letting the
> server
> >> > connect to the cloud? I have checked `?parallel::makeCluster` and
> >> > `?snow::makeSOCKcluster` but I found no result. The only promising
> solution
> >> > I can see now is to use TCP hole punching, but it is quite
> complicated and
> >> > may not work for every case. Since building a connection from local
> to the
> >> > remote is super easy, I would like to know if there exists any simple
> >> > solution. I have searched it on Google for a week but find no answer.
> I'll
> >> > appreciate it if you can provide me any suggestions!
> >> >
> >> > Best,
> >> > Jiefei
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Tue Jan 19 14:24:25 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Tue, 19 Jan 2021 21:24:25 +0800
Subject: [R] parallel: socket connection behind a NAT router
In-Reply-To: <DM6PR04MB6624D8842000DEA4EA00AF19F9A30@DM6PR04MB6624.namprd04.prod.outlook.com>
References: <CAGiFhPP58v8vJs01tRM4OxRn-9CVm0nSjSDiEg41jopnQc+HHQ@mail.gmail.com>
 <CAFDcVCRS=O-Zg=R5s9rU70oDAmpLEnuHe2m=F-c65VNzaT6RLg@mail.gmail.com>
 <CAGiFhPP=bULzpc9EZ57H_Y70iMWB8se=cdicr49pKwGcdhSs7g@mail.gmail.com>
 <CAFDcVCT5uoqN6_uUG1F9YDUR6-TN4hXLdG6vQs1mUaB0Ldkx8A@mail.gmail.com>
 <DM6PR04MB6624D8842000DEA4EA00AF19F9A30@DM6PR04MB6624.namprd04.prod.outlook.com>
Message-ID: <CAGiFhPMtEAMC4bApiX1CQNrSZi6uk01y58Bn0TAvSnTyEmYhLg@mail.gmail.com>

Thanks! This solution also looks promising. It should be more stable than
using ssh tunneling. I will also explore this method.

Best,
Jiefei

On Tue, Jan 19, 2021 at 3:11 PM Martin Morgan <mtmorgan.bioc at gmail.com>
wrote:

> A different approach uses doRedis
> https://CRAN.R-project.org/package=doRedis (currently archived, but
> actively developed) for use with the foreach package, or RedisParam
> https://github.com/mtmorgan/RedisParam (not released) for use with
> Bioconductor's BiocParallel package.
>
> These use a redis server https://redis.io/ to communicate -- the manager
> submits jobs / obtains results from the redis server, the workers retrieve
> jobs / submit results to the redis server. Manager and worker need to know
> the (http) address of the server, etc, but there are no other ports
> involved.
>
> Redis servers are easy to establish in a cloud environment, using e.g.,
> existing AWS or docker images. The README for doRedis
> https://github.com/bwlewis/doRedis probably provides the easiest
> introduction.
>
> The (not mature) k8sredis Kubernetes / helm chart
> https://github.com/Bioconductor/k8sredis illustrates a complete system
> using RedisParam, deploying manager and workers locally or in the google
> cloud; the app could be modified to only start the workers in the cloud,
> exposing the redis server for access by a local 'manager'; this would be
> cool.
>
> Martin
>
> ?On 1/19/21, 1:50 AM, "R-help on behalf of Henrik Bengtsson" <
> r-help-bounces at r-project.org on behalf of henrik.bengtsson at gmail.com>
> wrote:
>
>     On Mon, Jan 18, 2021 at 9:42 PM Jiefei Wang <szwjf08 at gmail.com> wrote:
>     >
>     > Thanks for introducing this interesting package to me! it is great
> to know a new powerful tool, but it seems like this method does not work in
> my environment. ` parallelly::makeClusterPSOCK` will hang until timeout.
>     >
>     > I checked the verbose output and it looks like the parallelly
> package also depends on `parallel:::.slaveRSOCK` on the remote instance to
> build the connection. This explains why it failed for the local machine
> does not have a public IP and the remote does not know how to build the
> connection.
>
>     It's correct that the worker does attempt to connect back to the
>     parent R process that runs on your local machine.  However, it does
>     *not* do so by your local machines public IP address but it does it by
>     connecting to a port on its own machine - a port that was set up by
>     SSH.  More specifically, when parallelly::makeClusterPSOCK() connects
>     to the remote machine over SSH it also sets up a so-called reverse SSH
>     tunnel with a certain port on your local machine and certain port of
>     your remote machine.  This is what happens:
>
>     > cl <- parallelly::makeClusterPSOCK("machine1.example.org",
> verbose=TRUE)
>     [local output] Workers: [n = 1] 'machine1.example.org'
>     [local output] Base port: 11019
>     ...
>     [local output] Starting worker #1 on 'machine1.example.org':
>     '/usr/bin/ssh' -R 11068:localhost:11068 machine1.example.org
>     "'Rscript'
> --default-packages=datasets,utils,grDevices,graphics,stats,methods
>     -e 'workRSOCK <- tryCatch(parallel:::.slaveRSOCK, error=function(e)
>     parallel:::.workRSOCK); workRSOCK()' MASTER=localhost PORT=11068
>     OUT=/dev/null TIMEOUT=2592000 XDR=FALSE"
>     [local output] - Exit code of system() call: 0
>     [local output] Waiting for worker #1 on 'machine1.example.org' to
>     connect back  '/usr/bin/ssh' -R 11019:localhost:11019
>     machine1.example.org "'Rscript'
>     --default-packages=datasets,utils,grDevices,graphics,stats,methods -e
>     'workRSOCK <- tryCatch(parallel:::.slaveRSOCK, error=function(e)
>     parallel:::.workRSOCK); workRSOCK()' MASTER=localhost PORT=11019
>     OUT=/dev/null TIMEOUT=2592000 XDR=FALSE"
>
>     All the magic is in that SSH option '-R 11068:localhost:11068' SSH
>     options, which allow the parent R process on your local machine to
>     communicate with the remote worker R process on its own port 11068,
>     and vice versa, the worker R process will communicate with the parent
>     R process as if it was running on MASTER=localhost PORT=11068.
>     Basically, for all that the worker R process' knows, the parent R
>     process runs on the same machine as itself.
>
>     You haven't said what operating system you're running on your local
>     machine, but if it's MS Windows, know that the 'ssh' client that comes
>     with Windows 10 has some bugs in its reverse tunneling.  See
>     ?parallelly::makeClusterPSOCK for lots of details.  You also haven't
>     said what OS the cloud workers run, but I assume it's Linux.
>
>     So, my guesses on your setup is, the above "should work" for you.  For
>     your troubleshooting, you can also set argument outfile=NULL.  Then
>     you'll also see output from the worker R process.  There are
>     additional troubleshooting suggestions in Section 'Failing to set up
>     remote workers' of ?parallelly::makeClusterPSOCK that will help you
>     figure out what the problem is.
>
>     >
>     > I see in README the package states it works with "remote clusters
> without knowing public IP". I think this might be where the confusion is,
> it may mean the remote machine does not have a public IP, but the server
> machine does. I'm in the opposite situation, the server does not have a
> public IP, but the remote does. I'm not sure if this package can handle my
> case, but it looks very powerful and I appreciate your help!
>
>     Thanks. I've updated the text to "remote clusters without knowing
>     [local] public IP".
>
>     /Henrik
>
>     >
>     > Best,
>     > Jiefei
>     >
>     >
>     >
>     >
>     >
>     > On Tue, Jan 19, 2021 at 1:22 AM Henrik Bengtsson <
> henrik.bengtsson at gmail.com> wrote:
>     >>
>     >> If you have SSH access to the workers, then
>     >>
>     >> workers <- c("machine1.example.org", "machine2.example.org")
>     >> cl <- parallelly::makeClusterPSOCK(workers)
>     >>
>     >> should do it.  It does this without admin rights and port
> forwarding.
>     >> See also the README in
> https://cran.r-project.org/package=parallelly.
>     >>
>     >> /Henrik
>     >>
>     >> On Mon, Jan 18, 2021 at 6:45 AM Jiefei Wang <szwjf08 at gmail.com>
> wrote:
>     >> >
>     >> > Hi all,
>     >> >
>     >> > I have a few cloud instances and I want to use them to do parallel
>     >> > computing. I would like to create a socket cluster on my local
> machine to
>     >> > control the remote instances. Here is my network setup:
>     >> >
>     >> > local machine -- NAT -- Internet -- cloud instances
>     >> >
>     >> > In the parallel package, the server needs to call `makeCluster()`
> and
>     >> > listens to the connection from the workers. In my case, the
> server is the
>     >> > local machine and the workers are the cloud instances. However,
> since the
>     >> > local machine is hidden behind the NAT, it does not have a public
> address
>     >> > and the worker cannot connect to it. Therefore, `makeCluster()`
> will never
>     >> > be able to see the connection from the workers and hang forever.
>     >> >
>     >> > One solution for letting the external machine to access the
> device inside
>     >> > the NAT is to use port forwarding. However, this would not work
> for my case
>     >> > as the NAT is set by the network provider(not my home router) so
> I do not
>     >> > have access to the router. As the cloud instances have public
> addresses,
>     >> > I'll wonder if there is any way to build the cluster by letting
> the server
>     >> > connect to the cloud? I have checked `?parallel::makeCluster` and
>     >> > `?snow::makeSOCKcluster` but I found no result. The only
> promising solution
>     >> > I can see now is to use TCP hole punching, but it is quite
> complicated and
>     >> > may not work for every case. Since building a connection from
> local to the
>     >> > remote is super easy, I would like to know if there exists any
> simple
>     >> > solution. I have searched it on Google for a week but find no
> answer. I'll
>     >> > appreciate it if you can provide me any suggestions!
>     >> >
>     >> > Best,
>     >> > Jiefei
>     >> >
>     >> >         [[alternative HTML version deleted]]
>     >> >
>     >> > ______________________________________________
>     >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> > https://stat.ethz.ch/mailman/listinfo/r-help
>     >> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     >> > and provide commented, minimal, self-contained, reproducible code.
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdenney @end|ng |rom hum@npred|ct|on@@com  Tue Jan 19 13:11:39 2021
From: wdenney @end|ng |rom hum@npred|ct|on@@com (Bill Denney)
Date: Tue, 19 Jan 2021 07:11:39 -0500
Subject: [R] Errors and OS Differences with as.POSIXct and as.POSIXlt
In-Reply-To: <4ED60B39-4D04-46A5-BDC0-4BB6E84CC916@dcn.davis.ca.us>
References: <8c89a507cc1de32aecf720ffacc36673@mail.gmail.com>
 <4ED60B39-4D04-46A5-BDC0-4BB6E84CC916@dcn.davis.ca.us>
Message-ID: <CAGgUAxR5VMnP+1E_Py6K8Ow_WJSbtv0wpjDEYFbYWz4UcbHwZQ@mail.gmail.com>

There are many caveats about OS specificity on the strptime help page, but
most of them have to do with formatting and fewer with validation.  My
reading of the strptime page indicates that conversion with as.POSIXct()
will validate daylight savings times which the examples I gave indicate it
is not validating.

as.POSIXct on windows gives the expected value based on the help (the date
part is valid, so it exists, but the time part is invalid, so it does not
exist).  On Linux, it makes an inaccurate conversion (as shown in my
original message and in Rui's).

If the results from as.POSIXct do not guarantee valid time conversion, only
approximate conversion, then that should be made clearer in the help page.
If valid time conversion is intended as a guarantee from as.POSIXct and
as.POSIXlt, then this is a bug.

From strptime help:

Remember that in most time zones some times do not occur and some occur
twice because of transitions to/from ?daylight saving? (also known as
?summer?) time. strptime does not validate such times (it does not assume a
specific time zone), but conversion by as.POSIXct
<https://stat.ethz.ch/R-manual/R-devel/library/base/help/as.POSIXct.html> will
do so.

On Tue, Jan 19, 2021, 3:57 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This is as described in the documentation, due to OS differences, e.g
>  [1].
>
> [1] https://stat.ethz.ch/R-manual/R-devel/library/base/html/strptime.html
>
> On January 18, 2021 5:56:11 PM PST, Bill Denney <
> wdenney at humanpredictions.com> wrote:
> >Hello,
> >
> >
> >
> >Dates created with as.POSIXct differ between Windows/Mac and Linux.
> >Specifically this time that is during a gap when the hour does not
> >exist
> >due to daylight savings time:
> >
> >
> >
> >as.POSIXct("2018-03-11 02:09:36", tz="America/New_York")
> >
> >
> >
> >Gives on Windows:
> >
> >[1] "2018-03-11 EST"
> >
> >Gives on Linux (Ubuntu 20.04):
> >
> >[1] "2018-03-11 01:09:36 EST"
> >
> >
> >
> >Since the time does not exist, and I think that NA should be returned.
> >
> >
> >
> >Another issue and difference is that with as.POSIXlt on Linux, the
> >invalid
> >time is presented:
> >
> >
> >
> >as.POSIXlt("2018-03-11 02:09", tz="America/New_York")
> >
> >
> >
> >Gives on Windows:
> >
> >[1] "2018-03-11 EST"
> >
> >Gives on Linux:
> >
> >[1] "2018-03-11 02:09:00 EDT"
> >
> >
> >
> >(Note that the time provided on Linux does not exist due to daylight
> >savings time.)
> >
> >
> >
> >I think that for any invalid time, the result should be the same as an
> >invalid date:  NA is returned.
> >
> >
> >
> >What is the intended, appropriate time, and what is the best way to fix
> >this?
> >
> >
> >
> >Thanks,
> >
> >
> >
> >Bill
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Jan 19 15:48:23 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Tue, 19 Jan 2021 14:48:23 +0000
Subject: [R] Monospaced font not shown correctly (Xubuntu 20.04)
Message-ID: <9ff5a0f4427745d78c23935fa26f0911@UM-MAIL3213.unimaas.nl>

Hi all,

On my system (Xubuntu 20.04), using par(family="mono") is not rendered correctly. The same issue was raised here:

https://stackoverflow.com/questions/64207220/rendering-plot-in-r-with-mono-spaced-family-font-does-not-display-characters-any

Using par(family="monospace") does work:

par(mfrow=c(1,2))
par(family="mono")
plot(1)
par(family="monospace")
plot(1)

Also, when saving to pdf, it works fine:

pdf("plot.pdf"); par(family="mono"); plot(1); dev.off()

I have forced a refresh of the font cache:

fc-cache -r --verbose --really-force

And Courier is available:

> fc-list | grep Courier

/usr/share/fonts/X11/Type1/c0419bt_.pfb: Courier 10 Pitch:style=Regular
/usr/share/fonts/type1/texlive-fonts-recommended/pcrb8a.pfb: Courier:style=Bold
/usr/share/fonts/X11/Type1/c0611bt_.pfb: Courier 10 Pitch:style=Bold Italic
/usr/share/fonts/type1/texlive-fonts-recommended/pcrr8a.pfb: Courier:style=Regular
/usr/share/fonts/X11/Type1/c0582bt_.pfb: Courier 10 Pitch:style=Italic
/usr/share/fonts/X11/Type1/c0583bt_.pfb: Courier 10 Pitch:style=Bold
/usr/share/fonts/type1/texlive-fonts-recommended/pcrro8a.pfb: Courier:style=Italic
/usr/share/fonts/type1/texlive-fonts-recommended/pcrbo8a.pfb: Courier:style=Bold Italic

Any other ideas how to fix this?

Best,
Wolfgang

(happy to move this to R-SIG-Debian if this would be more appropriate)

> sessionInfo()
R version 4.0.3 (2020-10-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.1 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=C               LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_4.0.3 tools_4.0.3   

> X11Fonts()
$serif
[1] "-*-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"

$sans
[1] "-*-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"

$mono
[1] "-*-courier-%s-%s-*-*-%d-*-*-*-*-*-*-*"

$Times
[1] "-adobe-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"

$Helvetica
[1] "-adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"

$CyrTimes
[1] "-cronyx-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"

$CyrHelvetica
[1] "-cronyx-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"

$Arial
[1] "-monotype-arial-%s-%s-*-*-%d-*-*-*-*-*-*-*"

$Mincho
[1] "-*-mincho-%s-%s-*-*-%d-*-*-*-*-*-*-*"


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Jan 19 16:17:41 2021
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 19 Jan 2021 15:17:41 +0000
Subject: [R] 
 [SPAM] Re: Different results on running Wilcoxon Rank Sum test
 in R and SPSS
In-Reply-To: <448702623.708494.1611053185609@mail.yahoo.com>
References: <1910812922.2261308.1610990817343.ref@mail.yahoo.com>
 <1910812922.2261308.1610990817343@mail.yahoo.com>
 <e9902222-0459-16a4-1d86-4411f93f6c7c@dewey.myzen.co.uk>
 <448702623.708494.1611053185609@mail.yahoo.com>
Message-ID: <46d47c49-b24d-1e34-d0e3-db516b81bd54@dewey.myzen.co.uk>

See comments inline

On 19/01/2021 10:46, bharat rawlley wrote:
> Thank you for the reply and suggestion, Michael!
> 
> I used dput() and this is the output I can share with you. Simply 
> explained, I have 3 columns namely, drug_code, freq4w_n and PFD_n. Each 
> column has 132 values (including NA). The problem with the Wilcoxon Rank 
> Sum test has been described in my first email.
> 
> Please do let me know if you need any further clarification from my 
> side! Thanks a lot for your time!
> 
> structure(list(drug_code = c(0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,
> 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,
> 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,
> 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,
> 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,
> 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,
> 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0), freq4w_n = c(1,
> NA, NA, 0, NA, 4, NA, 10, NA, 0, 6, NA, NA, NA, NA, NA, 10, NA,
> 0, NA, NA, NA, NA, 0, NA, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA,
> NA, NA, NA, NA, NA, 0, 0, 12, 0, NA, 1, 2, 1, 2, 2, NA, 28, 0,
> NA, 4, NA, 1, NA, NA, NA, NA, NA, 0, 3, 1, NA, NA, NA, NA, 4,
> 28, NA, NA, 0, 2, 12, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 3, NA, NA, NA, NA, NA, NA, 6, 1, NA, NA,
> NA, 0, NA, NA, NA, 0, 0, NA, 0, NA, 2, 8, 3, NA, NA, NA, 0, NA,
> NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA), PFD_n = c(27, NA,
> NA, 28, NA, 26, NA, 20, NA, 30, 24, NA, NA, NA, NA, NA, 18, NA,
> 28, NA, NA, NA, NA, 28, NA, 28, NA, NA, NA, 28, NA, 28, NA, NA,
> NA, NA, NA, NA, NA, NA, 28, 28, 16, 28, NA, 27, 26, 27, 26, 26,
> NA, 0, 30, NA, 24, NA, 27, NA, NA, NA, NA, NA, 28, 25, 27, NA,
> NA, NA, NA, 26, 0, NA, NA, 28, 26, 16, 28, NA, NA, NA, 28, NA,
> 28, NA, NA, NA, NA, NA, NA, NA, NA, NA, 25, NA, NA, NA, NA, NA,
> NA, 22, 27, NA, NA, NA, 28, NA, NA, NA, 28, 28, NA, 28, NA, 26,
> 20, 25, NA, NA, NA, 30, NA, NA, NA, 19, NA, NA, NA, NA, NA, NA,
> NA, NA)), row.names = c(NA, -132L), class = c("tbl_df", "tbl",
> "data.frame"))
> 
> 
> Yours sincerely
> Bharat Rawlley
> On Tuesday, 19 January, 2021, 03:53:27 pm IST, Michael Dewey 
> <lists at dewey.myzen.co.uk> wrote:
> 
> 
> Unfortunately your data did not come through. Try using dput() and then
> pasting that into the body of your e-mail message.
> 
> On 18/01/2021 17:26, bharat rawlley via R-help wrote:
>  > Hello,
>  > On running the Wilcoxon Rank Sum test in R and SPSS, I am getting the 
> following discrepancies which I am unable to explain.
>  > Q1 In the attached data set, I was trying to compare freq4w_n in 
> those with drug_code 0 vs 1. SPSS gives a P value 0.031 vs R gives a P 
> value 0.001779.
>  > The code I used in R is as follows -
>  > wilcox.test(freq4w_n, drug_code, conf.int = T)

If I store your data in dat and then go

wilcox.test(freq4w_n ~ drug_code, dat)

I get a p-value of 0.031 agreeing with SPSS

The reason you are getting something different is that you are not 
specifying the first two parameters to wilcox.test() correctly.

>  >
>  >
>  > Q2 Similarly, in the same data set, when trying to compare PFD_n in 
> those with drug_code 0 vs 1, SPSS gives a P value 0.038 vs R gives a P 
> value?< 2.2e-16.
>  > The code I used in R is as follows -
>  > wilcox.test(PFD_n, drug_code, mu = 0, alternative = "two.sided", 
> correct = TRUE, paired = FALSE, conf.int = TRUE)
>  >
>  >
>  > I have tried searching on Google and watching some Youtube tutorials, 
> I cannot find an answer, Any help will be really appreciated, Thank you!
> 
>  > ______________________________________________
>  > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>
>  > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>
>  > and provide commented, minimal, self-contained, reproducible code.
>  >
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html 
> <http://www.dewey.myzen.co.uk/home.html>
> 
> 
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> 
> 	Virus-free. www.avg.com 
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> 
> 
> 
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From @jr|g@tt| @end|ng |rom gm@||@com  Tue Jan 19 16:50:29 2021
From: @jr|g@tt| @end|ng |rom gm@||@com (Steven Rigatti)
Date: Tue, 19 Jan 2021 10:50:29 -0500
Subject: [R] writing a function to work with dplyr::mutate()
Message-ID: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>

I am having some problems with what seems like a pretty simple issue. I
have some data where I want to convert numbers. Specifically, this is
cancer data and the size of tumors is encoded using millimeter
measurements. However, if the actual measurement is not available the
coding may imply a less specific range of sizes. For instance numbers 0-89
may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to 15, etc.

I have many such tables so I would like to be able to write a function
which takes as input a threshold over which new values need to be looked
up, and the new lookup table, returning the new values.

I successfully wrote the function:

translate_seer_numeric <- function(var, upper, lookup) {
    names(lookup) <- c('old','new')
    names(var) <- 'old'
    var <- as.data.frame(var)
    lookup2 <- data.frame(old = c(1:upper),
                          new = c(1:upper))
    lookup3 <- rbind(lookup, lookup2)
 print(var)
    res <- left_join(var, lookup3, by = 'old') %>%
         select(new)

    res

}

test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif = c(93, 95, 99),
                  new = c(3, 5, NA))
translate_seer_numeric(test1, 90, lup)

The above test generates the desired output:

  old1  992  953  934   8
  new1  NA2   53   34   8

My problem comes when I try to put this in line with pipes and the mutate
function:

test1 %>%
     mutate(varb = translate_seer_numeric(var = old, 90, lup))####
 Error: Problem with `mutate()` input `varb`.
x Join columns must be present in data.
x Problem with `old`.
i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.

Thoughts??

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jan 19 19:33:59 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 19 Jan 2021 10:33:59 -0800
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
References: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
Message-ID: <CAGxFJbQrOireRzq4QknCDczkUoY9a-gT8_3X1_J7Kuqd7x=YSA@mail.gmail.com>

If you are willing to entertain another approach, have a look at ?cut. By
defining the 'breaks' argument appropriately, you can easily create a
factor that tells you which values should be looked up and which accepted
as is. If I understand correctly, this seems to be what you want. If I have
not, just ignore and wait for a more useful reply.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 19, 2021 at 10:24 AM Steven Rigatti <sjrigatti at gmail.com> wrote:

> I am having some problems with what seems like a pretty simple issue. I
> have some data where I want to convert numbers. Specifically, this is
> cancer data and the size of tumors is encoded using millimeter
> measurements. However, if the actual measurement is not available the
> coding may imply a less specific range of sizes. For instance numbers 0-89
> may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to 15,
> etc.
>
> I have many such tables so I would like to be able to write a function
> which takes as input a threshold over which new values need to be looked
> up, and the new lookup table, returning the new values.
>
> I successfully wrote the function:
>
> translate_seer_numeric <- function(var, upper, lookup) {
>     names(lookup) <- c('old','new')
>     names(var) <- 'old'
>     var <- as.data.frame(var)
>     lookup2 <- data.frame(old = c(1:upper),
>                           new = c(1:upper))
>     lookup3 <- rbind(lookup, lookup2)
>  print(var)
>     res <- left_join(var, lookup3, by = 'old') %>%
>          select(new)
>
>     res
>
> }
>
> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif = c(93, 95,
> 99),
>                   new = c(3, 5, NA))
> translate_seer_numeric(test1, 90, lup)
>
> The above test generates the desired output:
>
>   old1  992  953  934   8
>   new1  NA2   53   34   8
>
> My problem comes when I try to put this in line with pipes and the mutate
> function:
>
> test1 %>%
>      mutate(varb = translate_seer_numeric(var = old, 90, lup))####
>  Error: Problem with `mutate()` input `varb`.
> x Join columns must be present in data.
> x Problem with `old`.
> i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.
>
> Thoughts??
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jan 19 20:02:02 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 19 Jan 2021 11:02:02 -0800
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
References: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
Message-ID: <42b28799-3803-0472-7d43-18c6630e3cae@comcast.net>


On 1/19/21 7:50 AM, Steven Rigatti wrote:
> I am having some problems with what seems like a pretty simple issue. I
> have some data where I want to convert numbers. Specifically, this is
> cancer data and the size of tumors is encoded using millimeter
> measurements. However, if the actual measurement is not available the
> coding may imply a less specific range of sizes. For instance numbers 0-89
> may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to 15, etc.
>
> I have many such tables so I would like to be able to write a function
> which takes as input a threshold over which new values need to be looked
> up, and the new lookup table, returning the new values.
>
> I successfully wrote the function:
>
> translate_seer_numeric <- function(var, upper, lookup) {
>      names(lookup) <- c('old','new')
>      names(var) <- 'old'
>      var <- as.data.frame(var)
>      lookup2 <- data.frame(old = c(1:upper),
>                            new = c(1:upper))
>      lookup3 <- rbind(lookup, lookup2)
>   print(var)
>      res <- left_join(var, lookup3, by = 'old') %>%
>           select(new)
>
>      res
>
> }
>
> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif = c(93, 95, 99),


This throws an error when copy-pasted, since you posted in html and 
there was no line separator.


>                    new = c(3, 5, NA))
> translate_seer_numeric(test1, 90, lup)
>
> The above test generates the desired output:
>
>    old1  992  953  934   8
>    new1  NA2   53   34   8
>
> My problem comes when I try to put this in line with pipes and the mutate
> function:
>
> test1 %>%
>       mutate(varb = translate_seer_numeric(var = old, 90, lup))####


#Added:

library(tidyverse)?? # since many people on rhelp are not particularly 
"tidy".

>   Error: Problem with `mutate()` input `varb`.
> x Join columns must be present in data.
> x Problem with `old`.
> i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.


I think I got useful results with this although you might need to 
extract the "new" column from the dataframe result.


test1 %>% ?? mutate(varb = translate_seer_numeric( . , 90, lup))

#----------

 ? old
1? 99
2? 95
3? 93
4?? 8
 ? old new
1? 99? NA
2? 95?? 5
3? 93?? 3
4?? 8?? 8

 ?When you want to refer to the prior result in a piped chain you use a 
dot ("."). I'm guessing you know this. But what I saw was that your 
successful test case was using a dataframe as the input to the first 
parameter of translate_seer_numeric, but you were apparently passing a 
column name when it was being used in a pipe.


The error message wasn't particularly helpful to me, but maybe that's 
because I don't have enough experience in that non-standard universe. It 
did tell us that the there was a problem with "varb" and that was 
probably because that was the wrong parameter name. However even 
changing the call to just `var=old` would probably have failed as well 
because you didn't write the function to accept a variable name as the 
first parameter.

Best;

David.

>
> Thoughts??
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @jr|g@tt| @end|ng |rom gm@||@com  Tue Jan 19 20:11:15 2021
From: @jr|g@tt| @end|ng |rom gm@||@com (Steven Rigatti)
Date: Tue, 19 Jan 2021 14:11:15 -0500
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <CAGxFJbQrOireRzq4QknCDczkUoY9a-gT8_3X1_J7Kuqd7x=YSA@mail.gmail.com>
References: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
 <CAGxFJbQrOireRzq4QknCDczkUoY9a-gT8_3X1_J7Kuqd7x=YSA@mail.gmail.com>
Message-ID: <CAPq4BeO_=qt7Vq1PE6=PqCRNQRvE7EGbgiku=29QthX4Asdk3w@mail.gmail.com>

It's not that I can't get the output I want. I was able to do that.
It is just that I can't make it pipeable - I get that weird error message
that I don't understand.

On Tue, Jan 19, 2021 at 1:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> If you are willing to entertain another approach, have a look at ?cut. By
> defining the 'breaks' argument appropriately, you can easily create a
> factor that tells you which values should be looked up and which accepted
> as is. If I understand correctly, this seems to be what you want. If I have
> not, just ignore and wait for a more useful reply.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Jan 19, 2021 at 10:24 AM Steven Rigatti <sjrigatti at gmail.com>
> wrote:
>
>> I am having some problems with what seems like a pretty simple issue. I
>> have some data where I want to convert numbers. Specifically, this is
>> cancer data and the size of tumors is encoded using millimeter
>> measurements. However, if the actual measurement is not available the
>> coding may imply a less specific range of sizes. For instance numbers 0-89
>> may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
>> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to 15,
>> etc.
>>
>> I have many such tables so I would like to be able to write a function
>> which takes as input a threshold over which new values need to be looked
>> up, and the new lookup table, returning the new values.
>>
>> I successfully wrote the function:
>>
>> translate_seer_numeric <- function(var, upper, lookup) {
>>     names(lookup) <- c('old','new')
>>     names(var) <- 'old'
>>     var <- as.data.frame(var)
>>     lookup2 <- data.frame(old = c(1:upper),
>>                           new = c(1:upper))
>>     lookup3 <- rbind(lookup, lookup2)
>>  print(var)
>>     res <- left_join(var, lookup3, by = 'old') %>%
>>          select(new)
>>
>>     res
>>
>> }
>>
>> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif = c(93,
>> 95, 99),
>>                   new = c(3, 5, NA))
>> translate_seer_numeric(test1, 90, lup)
>>
>> The above test generates the desired output:
>>
>>   old1  992  953  934   8
>>   new1  NA2   53   34   8
>>
>> My problem comes when I try to put this in line with pipes and the mutate
>> function:
>>
>> test1 %>%
>>      mutate(varb = translate_seer_numeric(var = old, 90, lup))####
>>  Error: Problem with `mutate()` input `varb`.
>> x Join columns must be present in data.
>> x Problem with `old`.
>> i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.
>>
>> Thoughts??
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Tue Jan 19 20:17:58 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 19 Jan 2021 11:17:58 -0800
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
References: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
Message-ID: <CAHqSRuT1tvJV2BZJPNGwSJ4-K6-L=aKP1EmSUuEp2Y6k1Ztfxg@mail.gmail.com>

Your translate... function seems unnecessarily complicated and reusing the
name 'var' for both the input and the data.frame containing the input makes
it confusing to me.  The following replacement, f, uses your algorithm but
I think gets the answer you want.

f <-
function(var, upper, lookup) {
    names(lookup) <- c('old','new')
    var_df <- data.frame(old = var)
    lookup2 <- data.frame(old = c(1:upper),
                          new = c(1:upper))
    lookup3 <- rbind(lookup, lookup2)
    res <- left_join(var_df, lookup3, by = 'old')
    res$new # return a vector, not a data.frame or tibble.
}
E.g.,
> data.frame(XXX=c(95,93,10,20), YYY=c(55,66,93,98)) %>% mutate( YYY_mm =
f(YYY, 90, lup))
  XXX YYY YYY_mm
1  95  55     55
2  93  66     66
3  10  93      3
4  20  98     NA

You can modify this so that it names the output column based on the name of
the input column (by returning a data.frame/tibble instead of a numeric
vector):

f1 <-
function(var, upper, lookup,  new_varname =
paste0(deparse1(substitute(var)), "_mm")) {
    names(lookup) <- c('old',new_varname)
    var_df <- data.frame(old = var)
    lookup2 <- data.frame(old = c(1:upper),
                          new = c(1:upper))
    names(lookup2)[2] <- new_varname
    lookup3 <- rbind(lookup, lookup2)
    res <- left_join(var_df, lookup3, by = 'old')[2]
    res
}
E.g.,
> data.frame(XXX=c(95,93,10,20), YYY=c(55,66,93,98)) %>% mutate( f1(YYY,
90, lup))
  XXX YYY YYY_mm
1  95  55     55
2  93  66     66
3  10  93      3
4  20  98     NA

-Bill

On Tue, Jan 19, 2021 at 10:24 AM Steven Rigatti <sjrigatti at gmail.com> wrote:

> I am having some problems with what seems like a pretty simple issue. I
> have some data where I want to convert numbers. Specifically, this is
> cancer data and the size of tumors is encoded using millimeter
> measurements. However, if the actual measurement is not available the
> coding may imply a less specific range of sizes. For instance numbers 0-89
> may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to 15,
> etc.
>
> I have many such tables so I would like to be able to write a function
> which takes as input a threshold over which new values need to be looked
> up, and the new lookup table, returning the new values.
>
> I successfully wrote the function:
>
> translate_seer_numeric <- function(var, upper, lookup) {
>     names(lookup) <- c('old','new')
>     names(var) <- 'old'
>     var <- as.data.frame(var)
>     lookup2 <- data.frame(old = c(1:upper),
>                           new = c(1:upper))
>     lookup3 <- rbind(lookup, lookup2)
>  print(var)
>     res <- left_join(var, lookup3, by = 'old') %>%
>          select(new)
>
>     res
>
> }
>
> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif = c(93, 95,
> 99),
>                   new = c(3, 5, NA))
> translate_seer_numeric(test1, 90, lup)
>
> The above test generates the desired output:
>
>   old1  992  953  934   8
>   new1  NA2   53   34   8
>
> My problem comes when I try to put this in line with pipes and the mutate
> function:
>
> test1 %>%
>      mutate(varb = translate_seer_numeric(var = old, 90, lup))####
>  Error: Problem with `mutate()` input `varb`.
> x Join columns must be present in data.
> x Problem with `old`.
> i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.
>
> Thoughts??
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jan 19 21:13:23 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 19 Jan 2021 12:13:23 -0800
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <CAHqSRuT1tvJV2BZJPNGwSJ4-K6-L=aKP1EmSUuEp2Y6k1Ztfxg@mail.gmail.com>
References: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
 <CAHqSRuT1tvJV2BZJPNGwSJ4-K6-L=aKP1EmSUuEp2Y6k1Ztfxg@mail.gmail.com>
Message-ID: <9271241b-8c55-3454-36f2-88c284e66e9b@comcast.net>


On 1/19/21 11:17 AM, Bill Dunlap wrote:
> Your translate... function seems unnecessarily complicated and reusing the
> name 'var' for both the input and the data.frame containing the input makes
> it confusing to me.  The following replacement, f, uses your algorithm but
> I think gets the answer you want.


I was thinking that the tidyverse might already have a recode-like 
operation. But the dplyr::recode appears to be deprecated and you get 
referred to case_when. Perhaps following an example from the `case_when` 
help page:


case_SEER_tsize <- function(tsize, upper, exceptions){

 ??? case_when(tsize <=upper ~tsize,

 ????????????? tsize %in% exceptions$bif ~ exceptions$new[match(tsize, 
exceptions$bif)])}


I'm guessing that my lack of tidyversatility means there's probably a 
`match`-equivalent that I'm not familiar with.


 > test1 <- data.frame(old = c(99,95,93, 8));lup <- data.frame(bif = 
c(93, 95, 99),
+??????????????????????????????????????????????????????????? new = c(3, 
5, NA))
 >
 > test1 %>%
+???? mutate(varb = case_SEER_tsize(.$old, 90, lup))
 ? old varb
1? 99?? NA
2? 95??? 5
3? 93??? 3
4?? 8??? 8

-- 

David.

>
> f <-
> function(var, upper, lookup) {
>      names(lookup) <- c('old','new')
>      var_df <- data.frame(old = var)
>      lookup2 <- data.frame(old = c(1:upper),
>                            new = c(1:upper))
>      lookup3 <- rbind(lookup, lookup2)
>      res <- left_join(var_df, lookup3, by = 'old')
>      res$new # return a vector, not a data.frame or tibble.
> }
> E.g.,
>> data.frame(XXX=c(95,93,10,20), YYY=c(55,66,93,98)) %>% mutate( YYY_mm =
> f(YYY, 90, lup))
>    XXX YYY YYY_mm
> 1  95  55     55
> 2  93  66     66
> 3  10  93      3
> 4  20  98     NA
>
> You can modify this so that it names the output column based on the name of
> the input column (by returning a data.frame/tibble instead of a numeric
> vector):
>
> f1 <-
> function(var, upper, lookup,  new_varname =
> paste0(deparse1(substitute(var)), "_mm")) {
>      names(lookup) <- c('old',new_varname)
>      var_df <- data.frame(old = var)
>      lookup2 <- data.frame(old = c(1:upper),
>                            new = c(1:upper))
>      names(lookup2)[2] <- new_varname
>      lookup3 <- rbind(lookup, lookup2)
>      res <- left_join(var_df, lookup3, by = 'old')[2]
>      res
> }
> E.g.,
>> data.frame(XXX=c(95,93,10,20), YYY=c(55,66,93,98)) %>% mutate( f1(YYY,
> 90, lup))
>    XXX YYY YYY_mm
> 1  95  55     55
> 2  93  66     66
> 3  10  93      3
> 4  20  98     NA
>
> -Bill
>
> On Tue, Jan 19, 2021 at 10:24 AM Steven Rigatti <sjrigatti at gmail.com> wrote:
>
>> I am having some problems with what seems like a pretty simple issue. I
>> have some data where I want to convert numbers. Specifically, this is
>> cancer data and the size of tumors is encoded using millimeter
>> measurements. However, if the actual measurement is not available the
>> coding may imply a less specific range of sizes. For instance numbers 0-89
>> may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
>> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to 15,
>> etc.
>>
>> I have many such tables so I would like to be able to write a function
>> which takes as input a threshold over which new values need to be looked
>> up, and the new lookup table, returning the new values.
>>
>> I successfully wrote the function:
>>
>> translate_seer_numeric <- function(var, upper, lookup) {
>>      names(lookup) <- c('old','new')
>>      names(var) <- 'old'
>>      var <- as.data.frame(var)
>>      lookup2 <- data.frame(old = c(1:upper),
>>                            new = c(1:upper))
>>      lookup3 <- rbind(lookup, lookup2)
>>   print(var)
>>      res <- left_join(var, lookup3, by = 'old') %>%
>>           select(new)
>>
>>      res
>>
>> }
>>
>> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif = c(93, 95,
>> 99),
>>                    new = c(3, 5, NA))
>> translate_seer_numeric(test1, 90, lup)
>>
>> The above test generates the desired output:
>>
>>    old1  992  953  934   8
>>    new1  NA2   53   34   8
>>
>> My problem comes when I try to put this in line with pipes and the mutate
>> function:
>>
>> test1 %>%
>>       mutate(varb = translate_seer_numeric(var = old, 90, lup))####
>>   Error: Problem with `mutate()` input `varb`.
>> x Join columns must be present in data.
>> x Problem with `old`.
>> i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.
>>
>> Thoughts??
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 19 21:48:48 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 19 Jan 2021 12:48:48 -0800
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <CAGxFJbQrOireRzq4QknCDczkUoY9a-gT8_3X1_J7Kuqd7x=YSA@mail.gmail.com>
References: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
 <CAGxFJbQrOireRzq4QknCDczkUoY9a-gT8_3X1_J7Kuqd7x=YSA@mail.gmail.com>
Message-ID: <166C1539-31B8-4ED9-953A-65493A1B4F9A@dcn.davis.ca.us>

Second this. There is also the findInterval function, which omits the factor attributes and just returns integers that can be used in lookup tables.

On January 19, 2021 10:33:59 AM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>If you are willing to entertain another approach, have a look at ?cut.
>By
>defining the 'breaks' argument appropriately, you can easily create a
>factor that tells you which values should be looked up and which
>accepted
>as is. If I understand correctly, this seems to be what you want. If I
>have
>not, just ignore and wait for a more useful reply.
>
>Cheers,
>Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Tue, Jan 19, 2021 at 10:24 AM Steven Rigatti <sjrigatti at gmail.com>
>wrote:
>
>> I am having some problems with what seems like a pretty simple issue.
>I
>> have some data where I want to convert numbers. Specifically, this is
>> cancer data and the size of tumors is encoded using millimeter
>> measurements. However, if the actual measurement is not available the
>> coding may imply a less specific range of sizes. For instance numbers
>0-89
>> may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
>> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to
>15,
>> etc.
>>
>> I have many such tables so I would like to be able to write a
>function
>> which takes as input a threshold over which new values need to be
>looked
>> up, and the new lookup table, returning the new values.
>>
>> I successfully wrote the function:
>>
>> translate_seer_numeric <- function(var, upper, lookup) {
>>     names(lookup) <- c('old','new')
>>     names(var) <- 'old'
>>     var <- as.data.frame(var)
>>     lookup2 <- data.frame(old = c(1:upper),
>>                           new = c(1:upper))
>>     lookup3 <- rbind(lookup, lookup2)
>>  print(var)
>>     res <- left_join(var, lookup3, by = 'old') %>%
>>          select(new)
>>
>>     res
>>
>> }
>>
>> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif =
>c(93, 95,
>> 99),
>>                   new = c(3, 5, NA))
>> translate_seer_numeric(test1, 90, lup)
>>
>> The above test generates the desired output:
>>
>>   old1  992  953  934   8
>>   new1  NA2   53   34   8
>>
>> My problem comes when I try to put this in line with pipes and the
>mutate
>> function:
>>
>> test1 %>%
>>      mutate(varb = translate_seer_numeric(var = old, 90, lup))####
>>  Error: Problem with `mutate()` input `varb`.
>> x Join columns must be present in data.
>> x Problem with `old`.
>> i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.
>>
>> Thoughts??
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @jr|g@tt| @end|ng |rom gm@||@com  Tue Jan 19 22:51:17 2021
From: @jr|g@tt| @end|ng |rom gm@||@com (Steven Rigatti)
Date: Tue, 19 Jan 2021 16:51:17 -0500
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <166C1539-31B8-4ED9-953A-65493A1B4F9A@dcn.davis.ca.us>
References: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
 <CAGxFJbQrOireRzq4QknCDczkUoY9a-gT8_3X1_J7Kuqd7x=YSA@mail.gmail.com>
 <166C1539-31B8-4ED9-953A-65493A1B4F9A@dcn.davis.ca.us>
Message-ID: <CAPq4BePQp6mTEwxKPNOyfVrOVNQG=kzD9CpUnvNtt4pL=5mXhg@mail.gmail.com>

I use case_when a lot - but I have a lot of dynamic tables to treat this
way and case_when has to be hard-coded.

On Tue, Jan 19, 2021 at 3:48 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Second this. There is also the findInterval function, which omits the
> factor attributes and just returns integers that can be used in lookup
> tables.
>
> On January 19, 2021 10:33:59 AM PST, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >If you are willing to entertain another approach, have a look at ?cut.
> >By
> >defining the 'breaks' argument appropriately, you can easily create a
> >factor that tells you which values should be looked up and which
> >accepted
> >as is. If I understand correctly, this seems to be what you want. If I
> >have
> >not, just ignore and wait for a more useful reply.
> >
> >Cheers,
> >Bert
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Tue, Jan 19, 2021 at 10:24 AM Steven Rigatti <sjrigatti at gmail.com>
> >wrote:
> >
> >> I am having some problems with what seems like a pretty simple issue.
> >I
> >> have some data where I want to convert numbers. Specifically, this is
> >> cancer data and the size of tumors is encoded using millimeter
> >> measurements. However, if the actual measurement is not available the
> >> coding may imply a less specific range of sizes. For instance numbers
> >0-89
> >> may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
> >> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to
> >15,
> >> etc.
> >>
> >> I have many such tables so I would like to be able to write a
> >function
> >> which takes as input a threshold over which new values need to be
> >looked
> >> up, and the new lookup table, returning the new values.
> >>
> >> I successfully wrote the function:
> >>
> >> translate_seer_numeric <- function(var, upper, lookup) {
> >>     names(lookup) <- c('old','new')
> >>     names(var) <- 'old'
> >>     var <- as.data.frame(var)
> >>     lookup2 <- data.frame(old = c(1:upper),
> >>                           new = c(1:upper))
> >>     lookup3 <- rbind(lookup, lookup2)
> >>  print(var)
> >>     res <- left_join(var, lookup3, by = 'old') %>%
> >>          select(new)
> >>
> >>     res
> >>
> >> }
> >>
> >> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif =
> >c(93, 95,
> >> 99),
> >>                   new = c(3, 5, NA))
> >> translate_seer_numeric(test1, 90, lup)
> >>
> >> The above test generates the desired output:
> >>
> >>   old1  992  953  934   8
> >>   new1  NA2   53   34   8
> >>
> >> My problem comes when I try to put this in line with pipes and the
> >mutate
> >> function:
> >>
> >> test1 %>%
> >>      mutate(varb = translate_seer_numeric(var = old, 90, lup))####
> >>  Error: Problem with `mutate()` input `varb`.
> >> x Join columns must be present in data.
> >> x Problem with `old`.
> >> i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.
> >>
> >> Thoughts??
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jan 19 23:46:31 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 19 Jan 2021 14:46:31 -0800
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <CAPq4BePQp6mTEwxKPNOyfVrOVNQG=kzD9CpUnvNtt4pL=5mXhg@mail.gmail.com>
References: <CAPq4BePQp6mTEwxKPNOyfVrOVNQG=kzD9CpUnvNtt4pL=5mXhg@mail.gmail.com>
Message-ID: <39208A4A-AEE8-436D-9A3E-FF4043F90505@comcast.net>



Sent from my iPhone

> On Jan 19, 2021, at 1:52 PM, Steven Rigatti <sjrigatti at gmail.com> wrote:
> 
> ?I use case_when a lot - but I have a lot of dynamic tables to treat this
> way and case_when has to be hard-coded.

But, but, but .... my case_when-based illustration let you pass a parameter dataframe that contains a translation table.

? 
David. 
> 
>> On Tue, Jan 19, 2021 at 3:48 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> 
>> Second this. There is also the findInterval function, which omits the
>> factor attributes and just returns integers that can be used in lookup
>> tables.
>> 
>>> On January 19, 2021 10:33:59 AM PST, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> If you are willing to entertain another approach, have a look at ?cut.
>>> By
>>> defining the 'breaks' argument appropriately, you can easily create a
>>> factor that tells you which values should be looked up and which
>>> accepted
>>> as is. If I understand correctly, this seems to be what you want. If I
>>> have
>>> not, just ignore and wait for a more useful reply.
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Tue, Jan 19, 2021 at 10:24 AM Steven Rigatti <sjrigatti at gmail.com>
>>> wrote:
>>> 
>>>> I am having some problems with what seems like a pretty simple issue.
>>> I
>>>> have some data where I want to convert numbers. Specifically, this is
>>>> cancer data and the size of tumors is encoded using millimeter
>>>> measurements. However, if the actual measurement is not available the
>>>> coding may imply a less specific range of sizes. For instance numbers
>>> 0-89
>>>> may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
>>>> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to
>>> 15,
>>>> etc.
>>>> 
>>>> I have many such tables so I would like to be able to write a
>>> function
>>>> which takes as input a threshold over which new values need to be
>>> looked
>>>> up, and the new lookup table, returning the new values.
>>>> 
>>>> I successfully wrote the function:
>>>> 
>>>> translate_seer_numeric <- function(var, upper, lookup) {
>>>>    names(lookup) <- c('old','new')
>>>>    names(var) <- 'old'
>>>>    var <- as.data.frame(var)
>>>>    lookup2 <- data.frame(old = c(1:upper),
>>>>                          new = c(1:upper))
>>>>    lookup3 <- rbind(lookup, lookup2)
>>>> print(var)
>>>>    res <- left_join(var, lookup3, by = 'old') %>%
>>>>         select(new)
>>>> 
>>>>    res
>>>> 
>>>> }
>>>> 
>>>> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif =
>>> c(93, 95,
>>>> 99),
>>>>                  new = c(3, 5, NA))
>>>> translate_seer_numeric(test1, 90, lup)
>>>> 
>>>> The above test generates the desired output:
>>>> 
>>>>  old1  992  953  934   8
>>>>  new1  NA2   53   34   8
>>>> 
>>>> My problem comes when I try to put this in line with pipes and the
>>> mutate
>>>> function:
>>>> 
>>>> test1 %>%
>>>>     mutate(varb = translate_seer_numeric(var = old, 90, lup))####
>>>> Error: Problem with `mutate()` input `varb`.
>>>> x Join columns must be present in data.
>>>> x Problem with `old`.
>>>> i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.
>>>> 
>>>> Thoughts??
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chr|@||oyd2 @end|ng |rom y@hoo@co@uk  Tue Jan 19 21:22:07 2021
From: chr|@||oyd2 @end|ng |rom y@hoo@co@uk (Christopher Lloyd)
Date: Tue, 19 Jan 2021 20:22:07 +0000 (UTC)
Subject: [R] Error: cons memory exhausted (limit reached?): Memory
 Management?
References: <1210311363.929868.1611087727445.ref@mail.yahoo.com>
Message-ID: <1210311363.929868.1611087727445@mail.yahoo.com>

Hi all, I think this is only the second time that I have posted so I apologise if my etiquette isn't quite correct.
I'm loading a large (~30GB) geojson file into R using readOGR on a HPC. I am also loading a small shapefile, and then trying to undertake some processing on the large geojson using gBuffer from the rgeos package.

I believe that the HPC is running?Red Hat Enterprise Linux 7.4, and it certainly has?around 750 GB free for user jobs. I have allocated the full amount of ram to the job.
I previously used the following modules to undertake this task and it ran successfully, although only after tweaking the settings that I detail below - otherwise I had the same error:

module load proj/5.0.0
module load gdal/2.3.1
module load geos/3.6.2
module load gcc/6.4.0
module load R/3.5.2
module load python? # python 3 by default
module load numpy/1.14.0 # requires module load python

Settings at linux command line that previously allowed a successful run:
R_MAX_VSIZE=720G
R_GC_MEM_GROW=0

--min-nsize=50000k --min-vsize=12M --max-ppsize=500000 (when executing the R script from command line)

However, the modules have now been updated on the HPC, and so I am now using:
module load proj/6.1.1
module load R/3.6.2
(other modules remain the same)

I get the following error whilst processing (loading the file into R is ok), with gcinfo() turned on:

Garbage collection 144 = 86+22+36 (level 0) ...?
288541.3 Mbytes of cons cells used (66%)
55320.1 Mbytes of vectors used (98%)
Garbage collection 145 = 86+23+36 (level 1) ...?
66679.3 Mbytes of cons cells used (15%)
56447.7 Mbytes of vectors used (100%)
Garbage collection 146 = 86+23+37 (level 2) ...?
39852.3 Mbytes of cons cells used (11%)
49032.4 Mbytes of vectors used (72%)
Garbage collection 147 = 87+23+37 (level 0) ...?
124935.0 Mbytes of cons cells used (36%)
64961.0 Mbytes of vectors used (95%)
Garbage collection 148 = 87+24+37 (level 1) ...?
985162418403226.2 Mbytes of cons cells used (-2147483648%)
35274.8 Mbytes of vectors used (52%)

Error: cons memory exhausted (limit reached?)
In addition: Warning message:
Garbage collection 149 = 88+24+37 (level 0) ...?
985162418403226.2 Mbytes of cons cells used (-2147483648%)
35274.8 Mbytes of vectors used (52%)
Lost warning messages
Execution halted
Garbage collection 150 = 89+24+37 (level 0) ...?
985162418403226.2 Mbytes of cons cells used (-2147483648%)
35274.8 Mbytes of vectors used (52%)

Error: cons memory exhausted (limit reached?)

The job halts with Memory Utilized: 411.29 GB

I cannot understand why the job worked previously (just) but now does not when seemingly the only change is an updated proj and R version (3.5.2 to 3.6.2).

Might anyone have any suggestions as to why this is the case? And/or how to alter the memory management so that memory is not exhausted so easily?

Many thanks, Chris

	[[alternative HTML version deleted]]


From jrkr|de@u @end|ng |rom gm@||@com  Wed Jan 20 00:07:36 2021
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Tue, 19 Jan 2021 18:07:36 -0500
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <9271241b-8c55-3454-36f2-88c284e66e9b@comcast.net>
References: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
 <CAHqSRuT1tvJV2BZJPNGwSJ4-K6-L=aKP1EmSUuEp2Y6k1Ztfxg@mail.gmail.com>
 <9271241b-8c55-3454-36f2-88c284e66e9b@comcast.net>
Message-ID: <CAKZQJMAaNPCS_S1wg7x+w9df4eM2ok0rXgND3Tvg7+9fBevbYg@mail.gmail.com>

David
library(tidyverse)
char_vec <- sample(c("a", "b", "c"), 10, replace = TRUE)
recode(char_vec, a = "Apple")

works for me.

On Tue, 19 Jan 2021 at 15:13, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 1/19/21 11:17 AM, Bill Dunlap wrote:
> > Your translate... function seems unnecessarily complicated and reusing
> the
> > name 'var' for both the input and the data.frame containing the input
> makes
> > it confusing to me.  The following replacement, f, uses your algorithm
> but
> > I think gets the answer you want.
>
>
> I was thinking that the tidyverse might already have a recode-like
> operation. But the dplyr::recode appears to be deprecated and you get
> referred to case_when. Perhaps following an example from the `case_when`
> help page:
>
>
> case_SEER_tsize <- function(tsize, upper, exceptions){
>
>      case_when(tsize <=upper ~tsize,
>
>                tsize %in% exceptions$bif ~ exceptions$new[match(tsize,
> exceptions$bif)])}
>
>
> I'm guessing that my lack of tidyversatility means there's probably a
> `match`-equivalent that I'm not familiar with.
>
>
>  > test1 <- data.frame(old = c(99,95,93, 8));lup <- data.frame(bif =
> c(93, 95, 99),
> +                                                            new = c(3,
> 5, NA))
>  >
>  > test1 %>%
> +     mutate(varb = case_SEER_tsize(.$old, 90, lup))
>    old varb
> 1  99   NA
> 2  95    5
> 3  93    3
> 4   8    8
>
> --
>
> David.
>
> >
> > f <-
> > function(var, upper, lookup) {
> >      names(lookup) <- c('old','new')
> >      var_df <- data.frame(old = var)
> >      lookup2 <- data.frame(old = c(1:upper),
> >                            new = c(1:upper))
> >      lookup3 <- rbind(lookup, lookup2)
> >      res <- left_join(var_df, lookup3, by = 'old')
> >      res$new # return a vector, not a data.frame or tibble.
> > }
> > E.g.,
> >> data.frame(XXX=c(95,93,10,20), YYY=c(55,66,93,98)) %>% mutate( YYY_mm =
> > f(YYY, 90, lup))
> >    XXX YYY YYY_mm
> > 1  95  55     55
> > 2  93  66     66
> > 3  10  93      3
> > 4  20  98     NA
> >
> > You can modify this so that it names the output column based on the name
> of
> > the input column (by returning a data.frame/tibble instead of a numeric
> > vector):
> >
> > f1 <-
> > function(var, upper, lookup,  new_varname =
> > paste0(deparse1(substitute(var)), "_mm")) {
> >      names(lookup) <- c('old',new_varname)
> >      var_df <- data.frame(old = var)
> >      lookup2 <- data.frame(old = c(1:upper),
> >                            new = c(1:upper))
> >      names(lookup2)[2] <- new_varname
> >      lookup3 <- rbind(lookup, lookup2)
> >      res <- left_join(var_df, lookup3, by = 'old')[2]
> >      res
> > }
> > E.g.,
> >> data.frame(XXX=c(95,93,10,20), YYY=c(55,66,93,98)) %>% mutate( f1(YYY,
> > 90, lup))
> >    XXX YYY YYY_mm
> > 1  95  55     55
> > 2  93  66     66
> > 3  10  93      3
> > 4  20  98     NA
> >
> > -Bill
> >
> > On Tue, Jan 19, 2021 at 10:24 AM Steven Rigatti <sjrigatti at gmail.com>
> wrote:
> >
> >> I am having some problems with what seems like a pretty simple issue. I
> >> have some data where I want to convert numbers. Specifically, this is
> >> cancer data and the size of tumors is encoded using millimeter
> >> measurements. However, if the actual measurement is not available the
> >> coding may imply a less specific range of sizes. For instance numbers
> 0-89
> >> may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
> >> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to 15,
> >> etc.
> >>
> >> I have many such tables so I would like to be able to write a function
> >> which takes as input a threshold over which new values need to be looked
> >> up, and the new lookup table, returning the new values.
> >>
> >> I successfully wrote the function:
> >>
> >> translate_seer_numeric <- function(var, upper, lookup) {
> >>      names(lookup) <- c('old','new')
> >>      names(var) <- 'old'
> >>      var <- as.data.frame(var)
> >>      lookup2 <- data.frame(old = c(1:upper),
> >>                            new = c(1:upper))
> >>      lookup3 <- rbind(lookup, lookup2)
> >>   print(var)
> >>      res <- left_join(var, lookup3, by = 'old') %>%
> >>           select(new)
> >>
> >>      res
> >>
> >> }
> >>
> >> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif = c(93,
> 95,
> >> 99),
> >>                    new = c(3, 5, NA))
> >> translate_seer_numeric(test1, 90, lup)
> >>
> >> The above test generates the desired output:
> >>
> >>    old1  992  953  934   8
> >>    new1  NA2   53   34   8
> >>
> >> My problem comes when I try to put this in line with pipes and the
> mutate
> >> function:
> >>
> >> test1 %>%
> >>       mutate(varb = translate_seer_numeric(var = old, 90, lup))####
> >>   Error: Problem with `mutate()` input `varb`.
> >> x Join columns must be present in data.
> >> x Problem with `old`.
> >> i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.
> >>
> >> Thoughts??
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Wed Jan 20 00:17:16 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 19 Jan 2021 18:17:16 -0500
Subject: [R] 
 Different results on running Wilcoxon Rank Sum test in R and SPSS
In-Reply-To: <4804_1611053260_10JAlcrd019890_448702623.708494.1611053185609@mail.yahoo.com>
References: <1910812922.2261308.1610990817343.ref@mail.yahoo.com>
 <1910812922.2261308.1610990817343@mail.yahoo.com>
 <e9902222-0459-16a4-1d86-4411f93f6c7c@dewey.myzen.co.uk>
 <4804_1611053260_10JAlcrd019890_448702623.708494.1611053185609@mail.yahoo.com>
Message-ID: <96078961-067c-d301-8e3a-7f3cabee4c16@mcmaster.ca>

Dear Bharat Rawlley,

What you tried to do appears to be nonsense. That is, you're treating 
PFD_n and drug_code as if they were scores for two different groups.

I assume that what you really want to do is to treat PFD_n as a vector 
of scores and drug_code as defining two groups. If that's correct, and 
with your data into Data, you can try the following:

------snip ------

 > wilcox.test(PFD_n ~ drug_code, data=Data, conf.int=TRUE)

	Wilcoxon rank sum test with continuity correction

data:  PFD_n by drug_code
W = 197, p-value = 0.05563
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
  -2.000014e+00  5.037654e-05
sample estimates:
difference in location
              -1.000019

Warning messages:
1: In wilcox.test.default(x = c(27, 26, 20, 24, 28, 28, 27, 27, 26,  :
   cannot compute exact p-value with ties
2: In wilcox.test.default(x = c(27, 26, 20, 24, 28, 28, 27, 27, 26,  :
   cannot compute exact confidence intervals with ties

------snip ------

You can get an approximate confidence interval by specifying exact=FALSE:

------snip ------

 > wilcox.test(PFD_n ~ drug_code, data=Data, conf.int=TRUE, exact=FALSE)

	Wilcoxon rank sum test with continuity correction

data:  PFD_n by drug_code
W = 197, p-value = 0.05563
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
  -2.000014e+00  5.037654e-05
sample estimates:
difference in location
              -1.000019

------snip ------

As it turns out, your data are highly discrete and have a lot of ties 
(see in particular PFD_n = 28):

------snip ------

 > xtabs(~ PFD_n + drug_code, data=Data)

      drug_code
PFD_n  0  1
    0   2  0
    16  1  1
    18  0  1
    19  0  1
    20  2  0
    22  0  1
    24  2  0
    25  1  2
    26  5  2
    27  4  2
    28  5 13
    30  1  2

------snip ------

I'm no expert in nonparametric inference, but I doubt whether the 
approximate p-value will be very accurate for data like these.

I don't know why wilcox.test() (correctly used) and SPSS are giving you 
slightly different results -- assuming that you're actually doing the 
same thing in both cases. I couldn't help but notice that most of your 
data are missing. Are you getting the same value of the test statistic 
and different p-values, or is the test statistic different as well?

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-01-19 5:46 a.m., bharat rawlley via R-help wrote:
>   Thank you for the reply and suggestion, Michael!
> I used dput() and this is the output I can share with you. Simply explained, I have 3 columns namely, drug_code, freq4w_n and PFD_n. Each column has 132 values (including NA). The problem with the Wilcoxon Rank Sum test has been described in my first email.
> Please do let me know if you need any further clarification from my side! Thanks a lot for your time!
> structure(list(drug_code = c(0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,?1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,?0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,?1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,?0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,?1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,?1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0), freq4w_n = c(1,?NA, NA, 0, NA, 4, NA, 10, NA, 0, 6, NA, NA, NA, NA, NA, 10, NA,?0, NA, NA, NA, NA, 0, NA, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA,?NA, NA, NA, NA, NA, 0, 0, 12, 0, NA, 1, 2, 1, 2, 2, NA, 28, 0,?NA, 4, NA, 1, NA, NA, NA, NA, NA, 0, 3, 1, NA, NA, NA, NA, 4,?28, NA, NA, 0, 2, 12, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA, NA,?NA, NA, NA, NA, NA, 3, NA, NA, NA, NA, NA, NA, 6, 1, NA, NA,?NA, 0, NA, NA, NA, 0, 0, NA, 0, NA, 2, 8, 3, NA, NA, NA, 0, NA,?NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA), PFD_n = c(27, NA,?NA, 28, NA, 26, NA, 20, NA, 30, 24, NA, NA, NA, NA, NA, 18, NA,?28, NA, NA, NA, NA, 28, NA, 28, NA, NA, NA, 28, NA, 28, NA, NA,?NA, NA, NA, NA, NA, NA, 28, 28, 16, 28, NA, 27, 26, 27, 26, 26,?NA, 0, 30, NA, 24, NA, 27, NA, NA, NA, NA, NA, 28, 25, 27, NA,?NA, NA, NA, 26, 0, NA, NA, 28, 26, 16, 28, NA, NA, NA, 28, NA,?28, NA, NA, NA, NA, NA, NA, NA, NA, NA, 25, NA, NA, NA, NA, NA,?NA, 22, 27, NA, NA, NA, 28, NA, NA, NA, 28, 28, NA, 28, NA, 26,?20, 25, NA, NA, NA, 30, NA, NA, NA, 19, NA, NA, NA, NA, NA, NA,?NA, NA)), row.names = c(NA, -132L), class = c("tbl_df", "tbl",?"data.frame"))
> 
> Yours sincerely?Bharat Rawlley    On Tuesday, 19 January, 2021, 03:53:27 pm IST, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>   
>   Unfortunately your data did not come through. Try using dput() and then
> pasting that into the body of your e-mail message.
> 
> On 18/01/2021 17:26, bharat rawlley via R-help wrote:
>> Hello,
>> On running the Wilcoxon Rank Sum test in R and SPSS, I am getting the following discrepancies which I am unable to explain.
>> Q1 In the attached data set, I was trying to compare freq4w_n in those with drug_code 0 vs 1. SPSS gives a P value 0.031 vs R gives a P value 0.001779.
>> The code I used in R is as follows -
>> wilcox.test(freq4w_n, drug_code, conf.int = T)
>>
>>
>> Q2 Similarly, in the same data set, when trying to compare PFD_n in those with drug_code 0 vs 1, SPSS gives a P value 0.038 vs R gives a P value?< 2.2e-16.
>> The code I used in R is as follows -
>> wilcox.test(PFD_n, drug_code, mu = 0, alternative = "two.sided", correct = TRUE, paired = FALSE, conf.int = TRUE)
>>
>>
>> I have tried searching on Google and watching some Youtube tutorials, I cannot find an answer, Any help will be really appreciated, Thank you!
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 

From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Wed Jan 20 00:36:45 2021
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Wed, 20 Jan 2021 12:36:45 +1300
Subject: [R] Monospaced font not shown correctly (Xubuntu 20.04)
In-Reply-To: <9ff5a0f4427745d78c23935fa26f0911@UM-MAIL3213.unimaas.nl>
References: <9ff5a0f4427745d78c23935fa26f0911@UM-MAIL3213.unimaas.nl>
Message-ID: <bc925dcd-5d4b-569e-bfb0-a99112b83d12@stat.auckland.ac.nz>

Hi

The switch to XUbunutu 20.04 may mean a switch to Pango > 1.44 (it does 
on Ubuntu 20.04), which means loss of support for Type 1 fonts (on 
Cairo-based graphics devices).

The Courier fonts (the default for "mono" on Cairo-based devices) that 
you found are all Type 1 (.pfb) fonts.

What does this give you (the matches for the default "sans" and "serif" 
on Cairo-based devices) ... ?

fc-match Times
fc-match Helvetica

If those are .ttf or .otf fonts then that would explain why "sans" and 
"serif" still work.

A workaround is to specify the family name for a non-Type-1 monospaced 
font, e.g., "Courier New" (?), or install a non-Type-1 Courier 
replacement (and specify that).

Hope that helps.

Paul

On 20/01/21 3:48 am, Viechtbauer, Wolfgang (SP) wrote:
> Hi all,
> 
> On my system (Xubuntu 20.04), using par(family="mono") is not rendered 
> correctly. The same issue was raised here:
> 
> https://stackoverflow.com/questions/64207220/rendering-plot-in-r-with-mono-spaced-family-font-does-not-display-characters-any 
> <https://stackoverflow.com/questions/64207220/rendering-plot-in-r-with-mono-spaced-family-font-does-not-display-characters-any>
> 
> Using par(family="monospace") does work:
> 
> par(mfrow=c(1,2))
> par(family="mono")
> plot(1)
> par(family="monospace")
> plot(1)
> 
> Also, when saving to pdf, it works fine:
> 
> pdf("plot.pdf"); par(family="mono"); plot(1); dev.off()
> 
> I have forced a refresh of the font cache:
> 
> fc-cache -r --verbose --really-force
> 
> And Courier is available:
> 
>  > fc-list | grep Courier
> 
> /usr/share/fonts/X11/Type1/c0419bt_.pfb: Courier 10 Pitch:style=Regular
> /usr/share/fonts/type1/texlive-fonts-recommended/pcrb8a.pfb: 
> Courier:style=Bold
> /usr/share/fonts/X11/Type1/c0611bt_.pfb: Courier 10 Pitch:style=Bold Italic
> /usr/share/fonts/type1/texlive-fonts-recommended/pcrr8a.pfb: 
> Courier:style=Regular
> /usr/share/fonts/X11/Type1/c0582bt_.pfb: Courier 10 Pitch:style=Italic
> /usr/share/fonts/X11/Type1/c0583bt_.pfb: Courier 10 Pitch:style=Bold
> /usr/share/fonts/type1/texlive-fonts-recommended/pcrro8a.pfb: 
> Courier:style=Italic
> /usr/share/fonts/type1/texlive-fonts-recommended/pcrbo8a.pfb: 
> Courier:style=Bold Italic
> 
> Any other ideas how to fix this?
> 
> Best,
> Wolfgang
> 
> (happy to move this to R-SIG-Debian if this would be more appropriate)
> 
>  > sessionInfo()
> R version 4.0.3 (2020-10-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 20.04.1 LTS
> 
> Matrix products: default
> BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8
> [4] LC_COLLATE=C LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C
> [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
> 
> loaded via a namespace (and not attached):
> [1] compiler_4.0.3 tools_4.0.3
> 
>  > X11Fonts()
> $serif
> [1] "-*-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
> 
> $sans
> [1] "-*-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
> 
> $mono
> [1] "-*-courier-%s-%s-*-*-%d-*-*-*-*-*-*-*"
> 
> $Times
> [1] "-adobe-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
> 
> $Helvetica
> [1] "-adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
> 
> $CyrTimes
> [1] "-cronyx-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
> 
> $CyrHelvetica
> [1] "-cronyx-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
> 
> $Arial
> [1] "-monotype-arial-%s-%s-*-*-%d-*-*-*-*-*-*-*"
> 
> $Mincho
> [1] "-*-mincho-%s-%s-*-*-%d-*-*-*-*-*-*-*"
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From m||uj|@b @end|ng |rom gm@||@com  Wed Jan 20 00:45:53 2021
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Wed, 20 Jan 2021 00:45:53 +0100
Subject: [R] rbind common header to file list
Message-ID: <CAMLwc7OfUM_BztsCwqG7=arHK8J6TzD1dUpApD32o0iBnqy04Q@mail.gmail.com>

Dear all,

I have more than 200 text files in a folder without header - example below.
I would like to read, add a common date header to all the files, and write
(replace) the files.

## Read files
filelist = list.files(pattern = ".*.txt")
datalist = lapply(filelist, function(x)read.table(x, header=F))

## What I want to add
date <- 20000101
datalist _new <- lapply(datalist, function(x) rbind(x, date))

How do I add this date as a common header and replace the files? Any help
will be highly appreciated. Thank you.

Best,

Milu

## Sample data
xy <- dput(head(x,6))
structure(list(V1 = c("-5.28082885742185,-0.509039307",
"-6.09873046874998,-0.349584961",
"-2.07150878906248,6.264276123", "-1.11102905273435,6.365716553",
"2.37749633789065,14.57106934", "4.9619079589844,18.91350708"
)), row.names = c(NA, 6L), class = "data.frame")

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan 20 01:14:31 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 19 Jan 2021 16:14:31 -0800
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <CAPq4BePQp6mTEwxKPNOyfVrOVNQG=kzD9CpUnvNtt4pL=5mXhg@mail.gmail.com>
References: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
 <CAGxFJbQrOireRzq4QknCDczkUoY9a-gT8_3X1_J7Kuqd7x=YSA@mail.gmail.com>
 <166C1539-31B8-4ED9-953A-65493A1B4F9A@dcn.davis.ca.us>
 <CAPq4BePQp6mTEwxKPNOyfVrOVNQG=kzD9CpUnvNtt4pL=5mXhg@mail.gmail.com>
Message-ID: <909997E8-27F2-4A23-B950-6091A3E31CBD@dcn.davis.ca.us>

I avoid case_when, so don't complain to me about it. Bert and I both suggested standard evaluation approaches that are very amenable to using lookup tables.

On January 19, 2021 1:51:17 PM PST, Steven Rigatti <sjrigatti at gmail.com> wrote:
>I use case_when a lot - but I have a lot of dynamic tables to treat
>this
>way and case_when has to be hard-coded.
>
>On Tue, Jan 19, 2021 at 3:48 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Second this. There is also the findInterval function, which omits the
>> factor attributes and just returns integers that can be used in
>lookup
>> tables.
>>
>> On January 19, 2021 10:33:59 AM PST, Bert Gunter
><bgunter.4567 at gmail.com>
>> wrote:
>> >If you are willing to entertain another approach, have a look at
>?cut.
>> >By
>> >defining the 'breaks' argument appropriately, you can easily create
>a
>> >factor that tells you which values should be looked up and which
>> >accepted
>> >as is. If I understand correctly, this seems to be what you want. If
>I
>> >have
>> >not, just ignore and wait for a more useful reply.
>> >
>> >Cheers,
>> >Bert
>> >
>> >Bert Gunter
>> >
>> >"The trouble with having an open mind is that people keep coming
>along
>> >and
>> >sticking things into it."
>> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> >On Tue, Jan 19, 2021 at 10:24 AM Steven Rigatti
><sjrigatti at gmail.com>
>> >wrote:
>> >
>> >> I am having some problems with what seems like a pretty simple
>issue.
>> >I
>> >> have some data where I want to convert numbers. Specifically, this
>is
>> >> cancer data and the size of tumors is encoded using millimeter
>> >> measurements. However, if the actual measurement is not available
>the
>> >> coding may imply a less specific range of sizes. For instance
>numbers
>> >0-89
>> >> may indicate size in mm, but 90 indicates "greater than 90 mm" ,
>91
>> >> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92
>to
>> >15,
>> >> etc.
>> >>
>> >> I have many such tables so I would like to be able to write a
>> >function
>> >> which takes as input a threshold over which new values need to be
>> >looked
>> >> up, and the new lookup table, returning the new values.
>> >>
>> >> I successfully wrote the function:
>> >>
>> >> translate_seer_numeric <- function(var, upper, lookup) {
>> >>     names(lookup) <- c('old','new')
>> >>     names(var) <- 'old'
>> >>     var <- as.data.frame(var)
>> >>     lookup2 <- data.frame(old = c(1:upper),
>> >>                           new = c(1:upper))
>> >>     lookup3 <- rbind(lookup, lookup2)
>> >>  print(var)
>> >>     res <- left_join(var, lookup3, by = 'old') %>%
>> >>          select(new)
>> >>
>> >>     res
>> >>
>> >> }
>> >>
>> >> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif =
>> >c(93, 95,
>> >> 99),
>> >>                   new = c(3, 5, NA))
>> >> translate_seer_numeric(test1, 90, lup)
>> >>
>> >> The above test generates the desired output:
>> >>
>> >>   old1  992  953  934   8
>> >>   new1  NA2   53   34   8
>> >>
>> >> My problem comes when I try to put this in line with pipes and the
>> >mutate
>> >> function:
>> >>
>> >> test1 %>%
>> >>      mutate(varb = translate_seer_numeric(var = old, 90, lup))####
>> >>  Error: Problem with `mutate()` input `varb`.
>> >> x Join columns must be present in data.
>> >> x Problem with `old`.
>> >> i Input `varb` is `translate_seer_numeric(var = test1$old, 90,
>lup)`.
>> >>
>> >> Thoughts??
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jan 20 01:35:14 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 19 Jan 2021 16:35:14 -0800
Subject: [R] Error: cons memory exhausted (limit reached?): Memory
 Management?
In-Reply-To: <1210311363.929868.1611087727445@mail.yahoo.com>
References: <1210311363.929868.1611087727445.ref@mail.yahoo.com>
 <1210311363.929868.1611087727445@mail.yahoo.com>
Message-ID: <CAGxFJbSaMTLkzwPfY+08TGSH-WM6jMAFr8das9+kMDeFcXDwhg@mail.gmail.com>

You might do better posting this on r-sig-geo -- I believe you will more
likely find the expertise you seek there. Could be wrong of course.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 19, 2021 at 3:01 PM Christopher Lloyd via R-help <
r-help at r-project.org> wrote:

> Hi all, I think this is only the second time that I have posted so I
> apologise if my etiquette isn't quite correct.
> I'm loading a large (~30GB) geojson file into R using readOGR on a HPC. I
> am also loading a small shapefile, and then trying to undertake some
> processing on the large geojson using gBuffer from the rgeos package.
>
> I believe that the HPC is running Red Hat Enterprise Linux 7.4, and it
> certainly has around 750 GB free for user jobs. I have allocated the full
> amount of ram to the job.
> I previously used the following modules to undertake this task and it ran
> successfully, although only after tweaking the settings that I detail below
> - otherwise I had the same error:
>
> module load proj/5.0.0
> module load gdal/2.3.1
> module load geos/3.6.2
> module load gcc/6.4.0
> module load R/3.5.2
> module load python  # python 3 by default
> module load numpy/1.14.0 # requires module load python
>
> Settings at linux command line that previously allowed a successful run:
> R_MAX_VSIZE=720G
> R_GC_MEM_GROW=0
>
> --min-nsize=50000k --min-vsize=12M --max-ppsize=500000 (when executing the
> R script from command line)
>
> However, the modules have now been updated on the HPC, and so I am now
> using:
> module load proj/6.1.1
> module load R/3.6.2
> (other modules remain the same)
>
> I get the following error whilst processing (loading the file into R is
> ok), with gcinfo() turned on:
>
> Garbage collection 144 = 86+22+36 (level 0) ...
> 288541.3 Mbytes of cons cells used (66%)
> 55320.1 Mbytes of vectors used (98%)
> Garbage collection 145 = 86+23+36 (level 1) ...
> 66679.3 Mbytes of cons cells used (15%)
> 56447.7 Mbytes of vectors used (100%)
> Garbage collection 146 = 86+23+37 (level 2) ...
> 39852.3 Mbytes of cons cells used (11%)
> 49032.4 Mbytes of vectors used (72%)
> Garbage collection 147 = 87+23+37 (level 0) ...
> 124935.0 Mbytes of cons cells used (36%)
> 64961.0 Mbytes of vectors used (95%)
> Garbage collection 148 = 87+24+37 (level 1) ...
> 985162418403226.2 Mbytes of cons cells used (-2147483648%)
> 35274.8 Mbytes of vectors used (52%)
>
> Error: cons memory exhausted (limit reached?)
> In addition: Warning message:
> Garbage collection 149 = 88+24+37 (level 0) ...
> 985162418403226.2 Mbytes of cons cells used (-2147483648%)
> 35274.8 Mbytes of vectors used (52%)
> Lost warning messages
> Execution halted
> Garbage collection 150 = 89+24+37 (level 0) ...
> 985162418403226.2 Mbytes of cons cells used (-2147483648%)
> 35274.8 Mbytes of vectors used (52%)
>
> Error: cons memory exhausted (limit reached?)
>
> The job halts with Memory Utilized: 411.29 GB
>
> I cannot understand why the job worked previously (just) but now does not
> when seemingly the only change is an updated proj and R version (3.5.2 to
> 3.6.2).
>
> Might anyone have any suggestions as to why this is the case? And/or how
> to alter the memory management so that memory is not exhausted so easily?
>
> Many thanks, Chris
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chr|@||oyd2 @end|ng |rom y@hoo@co@uk  Wed Jan 20 01:53:54 2021
From: chr|@||oyd2 @end|ng |rom y@hoo@co@uk (Christopher Lloyd)
Date: Wed, 20 Jan 2021 00:53:54 +0000 (UTC)
Subject: [R] Error: cons memory exhausted (limit reached?): Memory
 Management?
In-Reply-To: <CAGxFJbSaMTLkzwPfY+08TGSH-WM6jMAFr8das9+kMDeFcXDwhg@mail.gmail.com>
References: <1210311363.929868.1611087727445.ref@mail.yahoo.com>
 <1210311363.929868.1611087727445@mail.yahoo.com>
 <CAGxFJbSaMTLkzwPfY+08TGSH-WM6jMAFr8das9+kMDeFcXDwhg@mail.gmail.com>
Message-ID: <1851213965.3454921.1611104034695@mail.yahoo.com>

 Cheers Bert, Will do. Best wishes, Chris
    On Wednesday, 20 January 2021, 00:35:26 GMT, Bert Gunter <bgunter.4567 at gmail.com> wrote:  
 
 You might do better posting this on r-sig-geo -- I believe you will more likely find the expertise you seek there. Could be wrong of course.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 19, 2021 at 3:01 PM Christopher Lloyd via R-help <r-help at r-project.org> wrote:

Hi all, I think this is only the second time that I have posted so I apologise if my etiquette isn't quite correct.
I'm loading a large (~30GB) geojson file into R using readOGR on a HPC. I am also loading a small shapefile, and then trying to undertake some processing on the large geojson using gBuffer from the rgeos package.

I believe that the HPC is running?Red Hat Enterprise Linux 7.4, and it certainly has?around 750 GB free for user jobs. I have allocated the full amount of ram to the job.
I previously used the following modules to undertake this task and it ran successfully, although only after tweaking the settings that I detail below - otherwise I had the same error:

module load proj/5.0.0
module load gdal/2.3.1
module load geos/3.6.2
module load gcc/6.4.0
module load R/3.5.2
module load python? # python 3 by default
module load numpy/1.14.0 # requires module load python

Settings at linux command line that previously allowed a successful run:
R_MAX_VSIZE=720G
R_GC_MEM_GROW=0

--min-nsize=50000k --min-vsize=12M --max-ppsize=500000 (when executing the R script from command line)

However, the modules have now been updated on the HPC, and so I am now using:
module load proj/6.1.1
module load R/3.6.2
(other modules remain the same)

I get the following error whilst processing (loading the file into R is ok), with gcinfo() turned on:

Garbage collection 144 = 86+22+36 (level 0) ...?
288541.3 Mbytes of cons cells used (66%)
55320.1 Mbytes of vectors used (98%)
Garbage collection 145 = 86+23+36 (level 1) ...?
66679.3 Mbytes of cons cells used (15%)
56447.7 Mbytes of vectors used (100%)
Garbage collection 146 = 86+23+37 (level 2) ...?
39852.3 Mbytes of cons cells used (11%)
49032.4 Mbytes of vectors used (72%)
Garbage collection 147 = 87+23+37 (level 0) ...?
124935.0 Mbytes of cons cells used (36%)
64961.0 Mbytes of vectors used (95%)
Garbage collection 148 = 87+24+37 (level 1) ...?
985162418403226.2 Mbytes of cons cells used (-2147483648%)
35274.8 Mbytes of vectors used (52%)

Error: cons memory exhausted (limit reached?)
In addition: Warning message:
Garbage collection 149 = 88+24+37 (level 0) ...?
985162418403226.2 Mbytes of cons cells used (-2147483648%)
35274.8 Mbytes of vectors used (52%)
Lost warning messages
Execution halted
Garbage collection 150 = 89+24+37 (level 0) ...?
985162418403226.2 Mbytes of cons cells used (-2147483648%)
35274.8 Mbytes of vectors used (52%)

Error: cons memory exhausted (limit reached?)

The job halts with Memory Utilized: 411.29 GB

I cannot understand why the job worked previously (just) but now does not when seemingly the only change is an updated proj and R version (3.5.2 to 3.6.2).

Might anyone have any suggestions as to why this is the case? And/or how to alter the memory management so that memory is not exhausted so easily?

Many thanks, Chris

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan 20 05:27:34 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 19 Jan 2021 20:27:34 -0800
Subject: [R] rbind common header to file list
In-Reply-To: <CAMLwc7OfUM_BztsCwqG7=arHK8J6TzD1dUpApD32o0iBnqy04Q@mail.gmail.com>
References: <CAMLwc7OfUM_BztsCwqG7=arHK8J6TzD1dUpApD32o0iBnqy04Q@mail.gmail.com>
Message-ID: <1765296F-2250-446F-85BB-721376F7B305@dcn.davis.ca.us>

a) I recommend _not_ overwriting the input files. Very difficult to debug/recover if anything goes wrong.

b) I recommend making a function that takes the file name, source directory, and destination directory, and reads the file, makes the change, and writes it to the output directory.

c) Your life may be easier if you use readLines() and writeLines rather than a more sophisticated parsing function like read.table(). Adding a new string to a vector of strings is straightforward.

On January 19, 2021 3:45:53 PM PST, Miluji Sb <milujisb at gmail.com> wrote:
>Dear all,
>
>I have more than 200 text files in a folder without header - example
>below.
>I would like to read, add a common date header to all the files, and
>write
>(replace) the files.
>
>## Read files
>filelist = list.files(pattern = ".*.txt")
>datalist = lapply(filelist, function(x)read.table(x, header=F))
>
>## What I want to add
>date <- 20000101
>datalist _new <- lapply(datalist, function(x) rbind(x, date))
>
>How do I add this date as a common header and replace the files? Any
>help
>will be highly appreciated. Thank you.
>
>Best,
>
>Milu
>
>## Sample data
>xy <- dput(head(x,6))
>structure(list(V1 = c("-5.28082885742185,-0.509039307",
>"-6.09873046874998,-0.349584961",
>"-2.07150878906248,6.264276123", "-1.11102905273435,6.365716553",
>"2.37749633789065,14.57106934", "4.9619079589844,18.91350708"
>)), row.names = c(NA, 6L), class = "data.frame")
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Wed Jan 20 09:44:01 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Wed, 20 Jan 2021 08:44:01 +0000
Subject: [R] Monospaced font not shown correctly (Xubuntu 20.04)
In-Reply-To: <bc925dcd-5d4b-569e-bfb0-a99112b83d12@stat.auckland.ac.nz>
References: <9ff5a0f4427745d78c23935fa26f0911@UM-MAIL3213.unimaas.nl>
 <bc925dcd-5d4b-569e-bfb0-a99112b83d12@stat.auckland.ac.nz>
Message-ID: <4070585cf404443c93aae45e0569929c@UM-MAIL3213.unimaas.nl>

Dear Paul,

Thanks for the helpful reply. Indeed:

> fc-match Times
NimbusRoman-Regular.otf: "Nimbus Roman" "Regular"
> fc-match Helvetica
NimbusSans-Regular.otf: "Nimbus Sans" "Regular"

are OpenType fonts. Also:

X11(type="Xlib", family="mono")
plot(1)

works. So does

X11(family="Courier New") # type="cairo" by default
plot(1)

or

X11(family="Inconsolata")
plot(1)

Can I not override what is specified under X11Fonts() with? Because this does not work:

X11Fonts(mono="-*-inconsolata-%s-%s-*-*-%d-*-*-*-*-*-*-*")
X11(family="mono")
plot(1)

Best,
Wolfgang

>-----Original Message-----
>From: Paul Murrell [mailto:paul at stat.auckland.ac.nz]
>Sent: Wednesday, 20 January, 2021 0:37
>To: Viechtbauer, Wolfgang (SP); r-help at r-project.org
>Subject: Re: [R] Monospaced font not shown correctly (Xubuntu 20.04)
>
>Hi
>
>The switch to XUbunutu 20.04 may mean a switch to Pango > 1.44 (it does
>on Ubuntu 20.04), which means loss of support for Type 1 fonts (on
>Cairo-based graphics devices).
>
>The Courier fonts (the default for "mono" on Cairo-based devices) that
>you found are all Type 1 (.pfb) fonts.
>
>What does this give you (the matches for the default "sans" and "serif"
>on Cairo-based devices) ... ?
>
>fc-match Times
>fc-match Helvetica
>
>If those are .ttf or .otf fonts then that would explain why "sans" and
>"serif" still work.
>
>A workaround is to specify the family name for a non-Type-1 monospaced
>font, e.g., "Courier New" (?), or install a non-Type-1 Courier
>replacement (and specify that).
>
>Hope that helps.
>
>Paul
>
>On 20/01/21 3:48 am, Viechtbauer, Wolfgang (SP) wrote:
>> Hi all,
>>
>> On my system (Xubuntu 20.04), using par(family="mono") is not rendered
>> correctly. The same issue was raised here:
>>
>> https://stackoverflow.com/questions/64207220/rendering-plot-in-r-with-
>mono-spaced-family-font-does-not-display-characters-any
>> <https://stackoverflow.com/questions/64207220/rendering-plot-in-r-with-
>mono-spaced-family-font-does-not-display-characters-any>
>>
>> Using par(family="monospace") does work:
>>
>> par(mfrow=c(1,2))
>> par(family="mono")
>> plot(1)
>> par(family="monospace")
>> plot(1)
>>
>> Also, when saving to pdf, it works fine:
>>
>> pdf("plot.pdf"); par(family="mono"); plot(1); dev.off()
>>
>> I have forced a refresh of the font cache:
>>
>> fc-cache -r --verbose --really-force
>>
>> And Courier is available:
>>
>>  > fc-list | grep Courier
>>
>> /usr/share/fonts/X11/Type1/c0419bt_.pfb: Courier 10 Pitch:style=Regular
>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrb8a.pfb:
>> Courier:style=Bold
>> /usr/share/fonts/X11/Type1/c0611bt_.pfb: Courier 10 Pitch:style=Bold
>Italic
>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrr8a.pfb:
>> Courier:style=Regular
>> /usr/share/fonts/X11/Type1/c0582bt_.pfb: Courier 10 Pitch:style=Italic
>> /usr/share/fonts/X11/Type1/c0583bt_.pfb: Courier 10 Pitch:style=Bold
>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrro8a.pfb:
>> Courier:style=Italic
>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrbo8a.pfb:
>> Courier:style=Bold Italic
>>
>> Any other ideas how to fix this?
>>
>> Best,
>> Wolfgang
>>
>> (happy to move this to R-SIG-Debian if this would be more appropriate)
>>
>>  > sessionInfo()
>> R version 4.0.3 (2020-10-10)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 20.04.1 LTS
>>
>> Matrix products: default
>> BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
>> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3
>>
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8
>> [4] LC_COLLATE=C LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C
>> [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_4.0.3 tools_4.0.3
>>
>>  > X11Fonts()
>> $serif
>> [1] "-*-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>
>> $sans
>> [1] "-*-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>
>> $mono
>> [1] "-*-courier-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>
>> $Times
>> [1] "-adobe-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>
>> $Helvetica
>> [1] "-adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>
>> $CyrTimes
>> [1] "-cronyx-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>
>> $CyrHelvetica
>> [1] "-cronyx-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>
>> $Arial
>> [1] "-monotype-arial-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>
>> $Mincho
>> [1] "-*-mincho-%s-%s-*-*-%d-*-*-*-*-*-*-*"


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Wed Jan 20 10:10:18 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Wed, 20 Jan 2021 09:10:18 +0000
Subject: [R] Monospaced font not shown correctly (Xubuntu 20.04)
In-Reply-To: <4070585cf404443c93aae45e0569929c@UM-MAIL3213.unimaas.nl>
References: <9ff5a0f4427745d78c23935fa26f0911@UM-MAIL3213.unimaas.nl>
 <bc925dcd-5d4b-569e-bfb0-a99112b83d12@stat.auckland.ac.nz>
 <4070585cf404443c93aae45e0569929c@UM-MAIL3213.unimaas.nl>
Message-ID: <f8435eb79c3542288c208447394d88a1@UM-MAIL3213.unimaas.nl>

Ah, nevermind. X11Fonts() is only for Xlib.

I'll see if I can figure out how to get 'fc-match Courier' to point to a otf/ttf font. I guess this is explained here: https://www.freedesktop.org/software/fontconfig/fontconfig-user.html

Best,
Wolfgang

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Viechtbauer,
>Wolfgang (SP)
>Sent: Wednesday, 20 January, 2021 9:44
>To: Paul Murrell; r-help at r-project.org
>Subject: Re: [R] Monospaced font not shown correctly (Xubuntu 20.04)
>
>Dear Paul,
>
>Thanks for the helpful reply. Indeed:
>
>> fc-match Times
>NimbusRoman-Regular.otf: "Nimbus Roman" "Regular"
>> fc-match Helvetica
>NimbusSans-Regular.otf: "Nimbus Sans" "Regular"
>
>are OpenType fonts. Also:
>
>X11(type="Xlib", family="mono")
>plot(1)
>
>works. So does
>
>X11(family="Courier New") # type="cairo" by default
>plot(1)
>
>or
>
>X11(family="Inconsolata")
>plot(1)
>
>Can I not override what is specified under X11Fonts() with? Because this
>does not work:
>
>X11Fonts(mono="-*-inconsolata-%s-%s-*-*-%d-*-*-*-*-*-*-*")
>X11(family="mono")
>plot(1)
>
>Best,
>Wolfgang
>
>>-----Original Message-----
>>From: Paul Murrell [mailto:paul at stat.auckland.ac.nz]
>>Sent: Wednesday, 20 January, 2021 0:37
>>To: Viechtbauer, Wolfgang (SP); r-help at r-project.org
>>Subject: Re: [R] Monospaced font not shown correctly (Xubuntu 20.04)
>>
>>Hi
>>
>>The switch to XUbunutu 20.04 may mean a switch to Pango > 1.44 (it does
>>on Ubuntu 20.04), which means loss of support for Type 1 fonts (on
>>Cairo-based graphics devices).
>>
>>The Courier fonts (the default for "mono" on Cairo-based devices) that
>>you found are all Type 1 (.pfb) fonts.
>>
>>What does this give you (the matches for the default "sans" and "serif"
>>on Cairo-based devices) ... ?
>>
>>fc-match Times
>>fc-match Helvetica
>>
>>If those are .ttf or .otf fonts then that would explain why "sans" and
>>"serif" still work.
>>
>>A workaround is to specify the family name for a non-Type-1 monospaced
>>font, e.g., "Courier New" (?), or install a non-Type-1 Courier
>>replacement (and specify that).
>>
>>Hope that helps.
>>
>>Paul
>>
>>On 20/01/21 3:48 am, Viechtbauer, Wolfgang (SP) wrote:
>>> Hi all,
>>>
>>> On my system (Xubuntu 20.04), using par(family="mono") is not rendered
>>> correctly. The same issue was raised here:
>>>
>>> https://stackoverflow.com/questions/64207220/rendering-plot-in-r-with-
>>mono-spaced-family-font-does-not-display-characters-any
>>> <https://stackoverflow.com/questions/64207220/rendering-plot-in-r-with-
>>mono-spaced-family-font-does-not-display-characters-any>
>>>
>>> Using par(family="monospace") does work:
>>>
>>> par(mfrow=c(1,2))
>>> par(family="mono")
>>> plot(1)
>>> par(family="monospace")
>>> plot(1)
>>>
>>> Also, when saving to pdf, it works fine:
>>>
>>> pdf("plot.pdf"); par(family="mono"); plot(1); dev.off()
>>>
>>> I have forced a refresh of the font cache:
>>>
>>> fc-cache -r --verbose --really-force
>>>
>>> And Courier is available:
>>>
>>>  > fc-list | grep Courier
>>>
>>> /usr/share/fonts/X11/Type1/c0419bt_.pfb: Courier 10 Pitch:style=Regular
>>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrb8a.pfb:
>>> Courier:style=Bold
>>> /usr/share/fonts/X11/Type1/c0611bt_.pfb: Courier 10 Pitch:style=Bold
>>Italic
>>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrr8a.pfb:
>>> Courier:style=Regular
>>> /usr/share/fonts/X11/Type1/c0582bt_.pfb: Courier 10 Pitch:style=Italic
>>> /usr/share/fonts/X11/Type1/c0583bt_.pfb: Courier 10 Pitch:style=Bold
>>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrro8a.pfb:
>>> Courier:style=Italic
>>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrbo8a.pfb:
>>> Courier:style=Bold Italic
>>>
>>> Any other ideas how to fix this?
>>>
>>> Best,
>>> Wolfgang
>>>
>>> (happy to move this to R-SIG-Debian if this would be more appropriate)
>>>
>>>  > sessionInfo()
>>> R version 4.0.3 (2020-10-10)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 20.04.1 LTS
>>>
>>> Matrix products: default
>>> BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
>>> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3
>>>
>>> locale:
>>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8
>>> [4] LC_COLLATE=C LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
>>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C
>>> [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_4.0.3 tools_4.0.3
>>>
>>>  > X11Fonts()
>>> $serif
>>> [1] "-*-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>
>>> $sans
>>> [1] "-*-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>
>>> $mono
>>> [1] "-*-courier-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>
>>> $Times
>>> [1] "-adobe-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>
>>> $Helvetica
>>> [1] "-adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>
>>> $CyrTimes
>>> [1] "-cronyx-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>
>>> $CyrHelvetica
>>> [1] "-cronyx-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>
>>> $Arial
>>> [1] "-monotype-arial-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>
>>> $Mincho
>>> [1] "-*-mincho-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Wed Jan 20 10:45:06 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Wed, 20 Jan 2021 09:45:06 +0000
Subject: [R] Monospaced font not shown correctly (Xubuntu 20.04)
In-Reply-To: <f8435eb79c3542288c208447394d88a1@UM-MAIL3213.unimaas.nl>
References: <9ff5a0f4427745d78c23935fa26f0911@UM-MAIL3213.unimaas.nl>
 <bc925dcd-5d4b-569e-bfb0-a99112b83d12@stat.auckland.ac.nz>
 <4070585cf404443c93aae45e0569929c@UM-MAIL3213.unimaas.nl>
 <f8435eb79c3542288c208447394d88a1@UM-MAIL3213.unimaas.nl>
Message-ID: <0689951371574a939e735fef6d4c1810@UM-MAIL3213.unimaas.nl>

And to conclude this little saga (that nobody is probably reading, but at least then there is a solution in the archives):

Adding the following to ~/.config/fontconfig/fonts.conf worked for me:

<?xml version="1.0"?>
<!DOCTYPE fontconfig SYSTEM "fonts.dtd">
<fontconfig>
    <match>
        <test name="family">
            <string>Courier</string>
        </test>
        <edit mode="assign" name="file">
            <string>/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf</string>
        </edit>
    </match>
</fontconfig>

Substitute your favorite (ttf/otf) monospaced font above.

Best,
Wolfgang

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Viechtbauer,
>Wolfgang (SP)
>Sent: Wednesday, 20 January, 2021 10:10
>To: Paul Murrell; r-help at r-project.org
>Subject: Re: [R] Monospaced font not shown correctly (Xubuntu 20.04)
>
>Ah, nevermind. X11Fonts() is only for Xlib.
>
>I'll see if I can figure out how to get 'fc-match Courier' to point to a
>otf/ttf font. I guess this is explained here:
>https://www.freedesktop.org/software/fontconfig/fontconfig-user.html
>
>Best,
>Wolfgang
>
>>-----Original Message-----
>>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>Viechtbauer,
>>Wolfgang (SP)
>>Sent: Wednesday, 20 January, 2021 9:44
>>To: Paul Murrell; r-help at r-project.org
>>Subject: Re: [R] Monospaced font not shown correctly (Xubuntu 20.04)
>>
>>Dear Paul,
>>
>>Thanks for the helpful reply. Indeed:
>>
>>> fc-match Times
>>NimbusRoman-Regular.otf: "Nimbus Roman" "Regular"
>>> fc-match Helvetica
>>NimbusSans-Regular.otf: "Nimbus Sans" "Regular"
>>
>>are OpenType fonts. Also:
>>
>>X11(type="Xlib", family="mono")
>>plot(1)
>>
>>works. So does
>>
>>X11(family="Courier New") # type="cairo" by default
>>plot(1)
>>
>>or
>>
>>X11(family="Inconsolata")
>>plot(1)
>>
>>Can I not override what is specified under X11Fonts() with? Because this
>>does not work:
>>
>>X11Fonts(mono="-*-inconsolata-%s-%s-*-*-%d-*-*-*-*-*-*-*")
>>X11(family="mono")
>>plot(1)
>>
>>Best,
>>Wolfgang
>>
>>>-----Original Message-----
>>>From: Paul Murrell [mailto:paul at stat.auckland.ac.nz]
>>>Sent: Wednesday, 20 January, 2021 0:37
>>>To: Viechtbauer, Wolfgang (SP); r-help at r-project.org
>>>Subject: Re: [R] Monospaced font not shown correctly (Xubuntu 20.04)
>>>
>>>Hi
>>>
>>>The switch to XUbunutu 20.04 may mean a switch to Pango > 1.44 (it does
>>>on Ubuntu 20.04), which means loss of support for Type 1 fonts (on
>>>Cairo-based graphics devices).
>>>
>>>The Courier fonts (the default for "mono" on Cairo-based devices) that
>>>you found are all Type 1 (.pfb) fonts.
>>>
>>>What does this give you (the matches for the default "sans" and "serif"
>>>on Cairo-based devices) ... ?
>>>
>>>fc-match Times
>>>fc-match Helvetica
>>>
>>>If those are .ttf or .otf fonts then that would explain why "sans" and
>>>"serif" still work.
>>>
>>>A workaround is to specify the family name for a non-Type-1 monospaced
>>>font, e.g., "Courier New" (?), or install a non-Type-1 Courier
>>>replacement (and specify that).
>>>
>>>Hope that helps.
>>>
>>>Paul
>>>
>>>On 20/01/21 3:48 am, Viechtbauer, Wolfgang (SP) wrote:
>>>> Hi all,
>>>>
>>>> On my system (Xubuntu 20.04), using par(family="mono") is not rendered
>>>> correctly. The same issue was raised here:
>>>>
>>>> https://stackoverflow.com/questions/64207220/rendering-plot-in-r-with-
>>>mono-spaced-family-font-does-not-display-characters-any
>>>> <https://stackoverflow.com/questions/64207220/rendering-plot-in-r-with-
>>>mono-spaced-family-font-does-not-display-characters-any>
>>>>
>>>> Using par(family="monospace") does work:
>>>>
>>>> par(mfrow=c(1,2))
>>>> par(family="mono")
>>>> plot(1)
>>>> par(family="monospace")
>>>> plot(1)
>>>>
>>>> Also, when saving to pdf, it works fine:
>>>>
>>>> pdf("plot.pdf"); par(family="mono"); plot(1); dev.off()
>>>>
>>>> I have forced a refresh of the font cache:
>>>>
>>>> fc-cache -r --verbose --really-force
>>>>
>>>> And Courier is available:
>>>>
>>>>  > fc-list | grep Courier
>>>>
>>>> /usr/share/fonts/X11/Type1/c0419bt_.pfb: Courier 10 Pitch:style=Regular
>>>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrb8a.pfb:
>>>> Courier:style=Bold
>>>> /usr/share/fonts/X11/Type1/c0611bt_.pfb: Courier 10 Pitch:style=Bold
>>>Italic
>>>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrr8a.pfb:
>>>> Courier:style=Regular
>>>> /usr/share/fonts/X11/Type1/c0582bt_.pfb: Courier 10 Pitch:style=Italic
>>>> /usr/share/fonts/X11/Type1/c0583bt_.pfb: Courier 10 Pitch:style=Bold
>>>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrro8a.pfb:
>>>> Courier:style=Italic
>>>> /usr/share/fonts/type1/texlive-fonts-recommended/pcrbo8a.pfb:
>>>> Courier:style=Bold Italic
>>>>
>>>> Any other ideas how to fix this?
>>>>
>>>> Best,
>>>> Wolfgang
>>>>
>>>> (happy to move this to R-SIG-Debian if this would be more appropriate)
>>>>
>>>>  > sessionInfo()
>>>> R version 4.0.3 (2020-10-10)
>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>> Running under: Ubuntu 20.04.1 LTS
>>>>
>>>> Matrix products: default
>>>> BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
>>>> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3
>>>>
>>>> locale:
>>>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8
>>>> [4] LC_COLLATE=C LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
>>>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C
>>>> [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats graphics grDevices utils datasets methods base
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] compiler_4.0.3 tools_4.0.3
>>>>
>>>>  > X11Fonts()
>>>> $serif
>>>> [1] "-*-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>>
>>>> $sans
>>>> [1] "-*-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>>
>>>> $mono
>>>> [1] "-*-courier-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>>
>>>> $Times
>>>> [1] "-adobe-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>>
>>>> $Helvetica
>>>> [1] "-adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>>
>>>> $CyrTimes
>>>> [1] "-cronyx-times-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>>
>>>> $CyrHelvetica
>>>> [1] "-cronyx-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>>
>>>> $Arial
>>>> [1] "-monotype-arial-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>>>
>>>> $Mincho
>>>> [1] "-*-mincho-%s-%s-*-*-%d-*-*-*-*-*-*-*"
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-
>guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Wed Jan 20 11:21:20 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed, 20 Jan 2021 11:21:20 +0100
Subject: [R] Monospaced font not shown correctly (Xubuntu 20.04)
In-Reply-To: <0689951371574a939e735fef6d4c1810@UM-MAIL3213.unimaas.nl>
References: <9ff5a0f4427745d78c23935fa26f0911@UM-MAIL3213.unimaas.nl>
 <bc925dcd-5d4b-569e-bfb0-a99112b83d12@stat.auckland.ac.nz>
 <4070585cf404443c93aae45e0569929c@UM-MAIL3213.unimaas.nl>
 <f8435eb79c3542288c208447394d88a1@UM-MAIL3213.unimaas.nl>
 <0689951371574a939e735fef6d4c1810@UM-MAIL3213.unimaas.nl>
Message-ID: <YAgEIK3IbqTEf5ch@posteo.no>

On 2021-01-20 09:45 +0000, Viechtbauer, Wolfgang (SP) wrote:
> And to conclude this little saga (that nobody is probably reading, but at least then there is a solution in the archives):
> 
> Adding the following to ~/.config/fontconfig/fonts.conf worked for me:
> 
> <?xml version="1.0"?>
> <!DOCTYPE fontconfig SYSTEM "fonts.dtd">
> <fontconfig>
>     <match>
>         <test name="family">
>             <string>Courier</string>
>         </test>
>         <edit mode="assign" name="file">
>             <string>/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf</string>
>         </edit>
>     </match>
> </fontconfig>
> 
> Substitute your favorite (ttf/otf) monospaced font above.
> 
> Best,
> Wolfgang

Glad you got to the bottom of this!  

I have this in my ~/.fonts.conf:

	<?xml version='1.0'?>
	<!DOCTYPE fontconfig SYSTEM 'fonts.dtd'>
	<fontconfig>
	
	    <alias>
	        <family>serif</family>
	        <prefer>
	            <family>XITS</family>
	            <family>Times New Roman</family>
	            <family>DejaVu Serif</family>
	            <family>Linux Libertine</family>
	            <family>JoyPixels</family>
	        </prefer>
	    </alias>
	    <alias>
	        <family>sans-serif</family>
	        <prefer>
	            <family>DejaVu Sans</family>
	            <family>Droid Sans</family>
	            <family>ProFontIIx</family>
	        </prefer>
	    </alias>
	    <alias>
	        <family>sans</family>
	        <prefer>
	            <family>DejaVu Sans</family>
	            <family>Liberation</family>
	            <family>Droid Sans</family>
	            <family>JoyPixels</family>
	        </prefer>
	    </alias>
	    <alias>
	        <family>monospace</family>
	        <prefer>
	            <family>DejaVu Sans Mono</family>
	            <family>Liberation Mono</family>
	            <family>Droid Sans Mono</family>
	            <family>Inconsolata</family>
	            <family>JoyPixels</family>
	        </prefer>
	    </alias>
	    <alias>
	        <family>mono</family>
	        <prefer>
	            <family>DejaVu Sans Mono</family>
	            <family>Liberation Mono</family>
	            <family>Droid Sans Mono</family>
	            <family>Inconsolata</family>
	            <family>JoyPixels</family>
	        </prefer>
	    </alias>
	
	    <match target="pattern">
	        <test name="prgname" qual="any">
	            <string>rofi</string>
	        </test>
	        <edit name="family" mode="prepend_first">
	            <string>Noto Color Emoji</string>
	        </edit>
	    </match>
	   
	    <match target="pattern">
	        <test name="prgname" qual="any">
	            <string>geany</string>
	        </test>
	        <edit name="family" mode="prepend_first">
	            <string>Noto Color Emoji</string>
	        </edit>
	    </match>
	
	</fontconfig>

Best,
Rasmus


From m||uj|@b @end|ng |rom gm@||@com  Wed Jan 20 13:20:47 2021
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Wed, 20 Jan 2021 13:20:47 +0100
Subject: [R] rbind common header to file list
In-Reply-To: <297d9757-73b9-4e1d-a238-9d1685206252@email.android.com>
References: <CAMLwc7OfUM_BztsCwqG7=arHK8J6TzD1dUpApD32o0iBnqy04Q@mail.gmail.com>
 <297d9757-73b9-4e1d-a238-9d1685206252@email.android.com>
Message-ID: <CAMLwc7McBuhuPtszGY=KRA=qivs_bWphfpX6bkUBcy+jrsKWeA@mail.gmail.com>

Thank you for your reply and the solution. Yes, I would like the date to be
the column header for all the files in the list.

This is what tried following your suggestion;

filelist = list.files(pattern = ".*.txt")
date <- 20000101

for (file %in% filelist){
  datalist <- read.table(file)
  write.table(datalist, file= file, col.names= date)
  }

However, I get the following error

Error: unexpected SPECIAL in "for (file %in%"


Is it something silly I am missing? Thank you again!

Best,

Milu

On Wed, Jan 20, 2021 at 1:29 AM <cpolwart at chemo.org.uk> wrote:

> I'd use a for loop. But I may be misunderstanding the q!
>
>
> filelist = list.files(pattern = ".*.txt")
> date <- 20000101
>
> for (file %in% filelist) {
>
> datalist <- read.table(file)
>
> write.table( datalist, file= file, col.names= date)
>
> }
>
> Does what I think you want.
> I would actually write to a new filename (sub folder?) To avoid disaster!
>
>
>
>
>
> On 19 Jan 2021 23:45, Miluji Sb <milujisb at gmail.com> wrote:
>
> Dear all,
>
> I have more than 200 text files in a folder without header - example
> below.
> I would like to read, add a common date header to all the files, and write
> (replace) the files.
>
> ## Read files
> filelist = list.files(pattern = ".*.txt")
> datalist = lapply(filelist, function(x)read.table(x, header=F))
>
> ## What I want to add
> date <- 20000101
> datalist _new <- lapply(datalist, function(x) rbind(x, date))
>
> How do I add this date as a common header and replace the files? Any help
> will be highly appreciated. Thank you.
>
> Best,
>
> Milu
>
> ## Sample data
> xy <- dput(head(x,6))
> structure(list(V1 = c("-5.28082885742185,-0.509039307",
> "-6.09873046874998,-0.349584961",
> "-2.07150878906248,6.264276123", "-1.11102905273435,6.365716553",
> "2.37749633789065,14.57106934", "4.9619079589844,18.91350708"
> )), row.names = c(NA, 6L), class = "data.frame")
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Wed Jan 20 13:26:01 2021
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Wed, 20 Jan 2021 13:26:01 +0100
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAGxFJbT7ad6ku_jySd26PkZuiVGCaPyMStA=fLXPGEATX1AxwQ@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <CAGxFJbT7ad6ku_jySd26PkZuiVGCaPyMStA=fLXPGEATX1AxwQ@mail.gmail.com>
Message-ID: <CAEGeL+Es5WbBFihLxAWJB3vFD_MoWSQ0s=0Q_uU6i+kFUv3TtA@mail.gmail.com>

Hi Bert,
Thanks for your time. I will check some relevant tutorias. I am very
grateful.
Jibrin
Th

On Fri, Jan 15, 2021 at 7:49 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> There are many good tutorials for R. As a "newbie", you need to avail
> yourself of them. Although this forum is meant to "help", it is not
> designed to provide tutorials. Understanding basic R functionality is
> largely assumed here.
>
> Searching on "tutorials on date-time data in R" brought up many
> possibilities. Choose one or more that best suits your needs.
>
> As for your specific query, you seem not to understand R's "vectorization"
> behavior: your statement, "it can only convert one day of the year at a
> time", is false. Again, search for a tutorial on "vectorization in R." But
> note that the "Intro to R" tutorial that ships with R already has this.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Jan 15, 2021 at 9:55 AM Jibrin Alhassan <
> jibrin.alhassan at unn.edu.ng> wrote:
>
>> Dear R users,
>> I am very new to R software. I have solar wind speed data needed for my
>> work. How do I convert day in the year to year, month, and day with R
>> software? I have used this code
>> as.Date(0, origin = "1998-01-01")
>> but it can only convert one day of the year at a time. Meanwhile, I have
>> up
>> to the 1998-2002 data set. Attached is my data.
>> Kindly help, please.
>> Jibrin Alhassan
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Jan 20 13:32:41 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 20 Jan 2021 14:32:41 +0200
Subject: [R] rbind common header to file list
In-Reply-To: <CAMLwc7McBuhuPtszGY=KRA=qivs_bWphfpX6bkUBcy+jrsKWeA@mail.gmail.com>
References: <CAMLwc7OfUM_BztsCwqG7=arHK8J6TzD1dUpApD32o0iBnqy04Q@mail.gmail.com>
 <297d9757-73b9-4e1d-a238-9d1685206252@email.android.com>
 <CAMLwc7McBuhuPtszGY=KRA=qivs_bWphfpX6bkUBcy+jrsKWeA@mail.gmail.com>
Message-ID: <CAGgJW76zb2JLNEF-3r-qJg93uj7TXSx1RH_GLw5_NZs4TPqJWw@mail.gmail.com>

for ( file in filelist )



On Wed, Jan 20, 2021 at 2:21 PM Miluji Sb <milujisb at gmail.com> wrote:

> Thank you for your reply and the solution. Yes, I would like the date to be
> the column header for all the files in the list.
>
> This is what tried following your suggestion;
>
> filelist = list.files(pattern = ".*.txt")
> date <- 20000101
>
> for (file %in% filelist){
>   datalist <- read.table(file)
>   write.table(datalist, file= file, col.names= date)
>   }
>
> However, I get the following error
>
> Error: unexpected SPECIAL in "for (file %in%"
>
>
> Is it something silly I am missing? Thank you again!
>
> Best,
>
> Milu
>
> On Wed, Jan 20, 2021 at 1:29 AM <cpolwart at chemo.org.uk> wrote:
>
> > I'd use a for loop. But I may be misunderstanding the q!
> >
> >
> > filelist = list.files(pattern = ".*.txt")
> > date <- 20000101
> >
> > for (file %in% filelist) {
> >
> > datalist <- read.table(file)
> >
> > write.table( datalist, file= file, col.names= date)
> >
> > }
> >
> > Does what I think you want.
> > I would actually write to a new filename (sub folder?) To avoid disaster!
> >
> >
> >
> >
> >
> > On 19 Jan 2021 23:45, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Dear all,
> >
> > I have more than 200 text files in a folder without header - example
> > below.
> > I would like to read, add a common date header to all the files, and
> write
> > (replace) the files.
> >
> > ## Read files
> > filelist = list.files(pattern = ".*.txt")
> > datalist = lapply(filelist, function(x)read.table(x, header=F))
> >
> > ## What I want to add
> > date <- 20000101
> > datalist _new <- lapply(datalist, function(x) rbind(x, date))
> >
> > How do I add this date as a common header and replace the files? Any help
> > will be highly appreciated. Thank you.
> >
> > Best,
> >
> > Milu
> >
> > ## Sample data
> > xy <- dput(head(x,6))
> > structure(list(V1 = c("-5.28082885742185,-0.509039307",
> > "-6.09873046874998,-0.349584961",
> > "-2.07150878906248,6.264276123", "-1.11102905273435,6.365716553",
> > "2.37749633789065,14.57106934", "4.9619079589844,18.91350708"
> > )), row.names = c(NA, 6L), class = "data.frame")
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Wed Jan 20 13:34:24 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed, 20 Jan 2021 13:34:24 +0100
Subject: [R] Monospaced font not shown correctly (Xubuntu 20.04)
In-Reply-To: <alpine.DEB.2.22.394.2101201225360.63013@wv-x5>
References: <9ff5a0f4427745d78c23935fa26f0911@UM-MAIL3213.unimaas.nl>
 <bc925dcd-5d4b-569e-bfb0-a99112b83d12@stat.auckland.ac.nz>
 <4070585cf404443c93aae45e0569929c@UM-MAIL3213.unimaas.nl>
 <f8435eb79c3542288c208447394d88a1@UM-MAIL3213.unimaas.nl>
 <0689951371574a939e735fef6d4c1810@UM-MAIL3213.unimaas.nl>
 <YAgEIK3IbqTEf5ch@posteo.no>
 <alpine.DEB.2.22.394.2101201225360.63013@wv-x5>
Message-ID: <YAgjUN2GDGe5mBMR@posteo.no>

On 2021-01-20 12:29 +0100, Wolfgang Viechtbauer wrote:
> 
> That looks like a more elegant solution, not requiring hardcoding paths.
> Thanks for the suggestion!

Thanks, no problem

R


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Wed Jan 20 13:48:58 2021
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Wed, 20 Jan 2021 13:48:58 +0100
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <A9758BCD-BC41-479F-933E-CB9958647078@gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
 <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
 <A9758BCD-BC41-479F-933E-CB9958647078@gmail.com>
Message-ID: <CAEGeL+F4vS30eK-H_ptRpWfCPfimkatX-HFv5CVvP8hLfFB_Og@mail.gmail.com>

Hello Peter,
Thanks for your input. What I need runs like this.
df1 <- read.table("SWSdata_1998_2002", header = TRUE)
> df1$date <- as.Date(paste(df1$year, df1$day),
+ Error: unexpected end of input
> df1$date <- as.Date(paste(df1$year, df1$day),format = "%Y %j",origin =
"1998-01-01")
> df2 <- df1[c("date", "SWS")]
> head(df2)
        date SWS
1 1998-01-01 344
2 1998-01-02 346
3 1998-01-03 356
4 1998-01-04 332
5 1998-01-05 302
6 1998-01-06 329
I need to display 1,826 rows and not 6 rows. Copied below is a section of
my data for your kind help.
year   day Hr SWS
1998   1  0  344.
1998   2  0  346.
1998   3  0  356.
1998   4  0  332.
1998   5  0  302.
1998   6  0  329.
1998   7  0  395.
1998   8  0  359.
1998   9  0  471.
1998  10  0  392.
1998  11  0  346.
1998  12  0  387.
1998  13  0  393.
1998  14  0  367.
1998  15  0  320.
1998  16  0  309.
1998  17  0  341.
1998  18  0  329.
1998  19  0  322.
1998  20  0  429.
1998  21  0  433.
1998  22  0  398.
1998  23  0  393.
1998  24  0  393.
1998  25  0  423.
1998  26  0  426.
1998  27  0  429.
1998  28  0  386.
1998  29  0  381.
1998  30  0  375.
1998  31  0  365.
1998  32  0  450.
1998  33  0  381.
1998  34  0  316.
1998  35  0  351.
1998  36  0  306.
1998  37  0  312.
1998  38  0  320.
1998  39  0  339.
1998  40  0  395.
1998  41  0  429.
1998  42  0  479.
1998  43  0  495.
1998  44  0  407.
1998  45  0  358.
1998  46  0  360.
1998  47  0  382.
1998  48  0  394.
1998  49  0  393.
1998  50  0  435.
1998  51  0  408.
1998  52  0  360.
1998  53  0  372.
1998  54  0  376.
1998  55  0  379.
1998  56  0  361.
1998  57  0  333.
1998  58  0  321.
1998  59  0  344.
1998  60  0  412.
1998  61  0  428.
1998  62  0  401.
1998  63  0  369.
1998  64  0  343.
1998  65  0  330.
1998  66  0  317.
1998  67  0  296.
1998  68  0  282.
1998  69  0  404.
1998  70  0  530.
1998  71  0  525.
1998  72  0  484.
1998  73  0  430.
1998  74  0  388.
1998  75  0  347.
1998  76  0  337.
1998  77  0  342.
1998  78  0  305.
1998  79  0  329.
1998  80  0  420.
1998  81  0  564.
1998  82  0  483.
1998  83  0  385.
1998  84  0  393.
1998  85  0  437.
1998  86  0  441.
1998  87  0  434.
1998  88  0  471.
1998  89  0  429.
1998  90  0  412.
1998  91  0  370.
1998  92  0  326.
1998  93  0  357.
1998  94  0  338.
1998  95  0  380.
1998  96  0  339.
1998  97  0  312.
1998  98  0  313.
1998  99  0  327.
1998 100  0  362.
1998 101  0  358.
1998 102  0  387.
1998 103  0  397.
1998 104  0  375.
1998 105  0  350.
1998 106  0  357.
1998 107  0  472.
1998 108  0  526.
1998 109  0  396.
1998 110  0  374.
1998 111  0  376.
1998 112  0  355.
1998 113  0  343.
1998 114  0  425.
1998 115  0  426.
1998 116  0  479.
1998 117  0  469.
1998 118  0  425.
1998 119  0  344.
1998 120  0  341.
1998 121  0  426.
1998 122  0  601.
1998 123  0  476.
1998 124  0  670.
1998 125  0  585.
1998 126  0  496.
1998 127  0  479.
1998 128  0  569.
1998 129  0  531.
1998 130  0  489.
1998 131  0  484.
1998 132  0  480.
1998 133  0  393.
1998 134  0  332.
1998 135  0  327.
1998 136  0  493.
1998 137  0  493.
1998 138  0  430.
1998 139  0  396.
1998 140  0  408.
1998 141  0  416.
1998 142  0  376.
1998 143  0  375.
1998 144  0  415.
1998 145  0  407.
1998 146  0  398.
1998 147  0  352.
1998 148  0  349.
1998 149  0  517.
1998 150  0  597.
1998 151  0  480.
1998 152  0  435.
1998 153  0  408.
1998 154  0  441.
1998 155  0  397.
1998 156  0  374.
1998 157  0  413.
1998 158  0  582.
1998 159  0  513.
1998 160  0  459.
1998 161  0  466.
1998 162  0  414.
1998 163  0  354.
1998 164  0  341.
1998 165  0  343.
1998 166  0  369.
1998 167  0  411.
1998 168  0  355.
1998 169  0  333.
1998 170  0  443.
1998 171  0  426.
1998 172  0  419.
1998 173  0  404.
1998 174  0  387.
1998 175  0  460.
1998 176  0  447.
1998 177  0  469.
1998 178  0  447.
1998 179  0  389.
1998 180  0  375.
1998 181  0  354.
1998 182  0  316.
1998 183  0  369.
1998 184  0  410.
1998 185  0  406.
1998 186  0  477.
1998 187  0  583.
1998 188  0  458.
1998 189  0  386.
1998 190  0  342.
1998 191  0  333.
1998 192  0  369.
1998 193  0  406.
1998 194  0  375.
1998 195  0  332.
1998 196  0  310.
1998 197  0  528.
1998 198  0  530.
1998 199  0  387.
1998 200  0  385.
1998 201  0  349.
1998 202  0  409.
1998 203  0  399.
1998 204  0  619.
1998 205  0  658.
1998 206  0  581.
1998 207  0  445.
1998 208  0  370.
1998 209  0  326.
1998 210  0  334.
1998 211  0  384.
1998 212  0  423.
1998 213  0  412.
1998 214  0  404.
1998 215  0  370.
1998 216  0  384.
1998 217  0  383.
1998 218  0  378.
1998 219  0  461.
1998 220  0  460.
1998 221  0  400.
1998 222  0  447.
1998 223  0  373.
1998 224  0  379.
1998 225  0  374.
1998 226  0  374.
1998 227  0  391.
1998 228  0  348.
1998 229  0  303.
1998 230  0  279.
1998 231  0  312.
1998 232  0  331.
1998 233  0  298.
1998 234  0  341.
1998 235  0  493.
1998 236  0  436.
1998 237  0  400.
1998 238  0  633.
1998 239  0  630.
1998 240  0  583.
1998 241  0  547.
1998 242  0  550.
1998 243  0  499.
1998 244  0  444.
1998 245  0  427.
1998 246  0  401.
1998 247  0  382.
1998 248  0  336.
1998 249  0  344.
1998 250  0  327.
1998 251  0  334.
1998 252  0  360.
1998 253  0  361.
1998 254  0  346.
1998 255  0  422.
1998 256  0  424.
1998 257  0  380.
1998 258  0  309.
1998 259  0  291.
1998 260  0  311.
1998 261  0  392.
1998 262  0  416.
1998 263  0  371.
1998 264  0  370.
1998 265  0  397.
1998 266  0  412.
1998 267  0  471.
1998 268  0  713.
1998 269  0  586.
1998 270  0  533.
1998 271  0  499.
1998 272  0  419.
1998 273  0  437.
1998 274  0  510.
1998 275  0  608.
1998 276  0  561.
1998 277  0  451.
1998 278  0  416.
1998 279  0  363.
1998 280  0  440.
1998 281  0  521.
1998 282  0  459.
1998 283  0  431.
1998 284  0  399.
1998 285  0  348.
1998 286  0  309.
1998 287  0  304.
1998 288  0  369.
1998 289  0  395.
1998 290  0  386.
1998 291  0  348.
1998 292  0  397.
1998 293  0  439.
1998 294  0  542.
1998 295  0  617.
1998 296  0  541.
1998 297  0  479.
1998 298  0  425.
1998 299  0  404.
1998 300  0  414.
1998 301  0  519.
1998 302  0  575.
1998 303  0  509.
1998 304  0  411.
1998 305  0  387.
1998 306  0  388.
1998 307  0  403.
1998 308  0  371.
1998 309  0  388.
1998 310  0  400.
1998 311  0  467.
1998 312  0  539.
1998 313  0  455.
1998 314  0  417.
1998 315  0  351.
1998 316  0  345.
1998 317  0  385.
1998 318  0  389.
1998 319  0  443.
1998 320  0  511.
1998 321  0  441.
1998 322  0  381.
1998 323  0  375.
1998 324  0  418.
1998 325  0  417.
1998 326  0  385.
1998 327  0  386.
1998 328  0  475.
1998 329  0  459.
1998 330  0  474.
1998 331  0  424.
1998 332  0  426.
1998 333  0  414.
1998 334  0  429.
1998 335  0  465.
1998 336  0  429.
1998 337  0  448.
1998 338  0  478.
1998 339  0  473.
1998 340  0  425.
1998 341  0  414.
1998 342  0  415.
1998 343  0  412.
1998 344  0  363.
1998 345  0  364.
1998 346  0  381.
1998 347  0  385.
1998 348  0  404.
1998 349  0  372.
1998 350  0  468.
1998 351  0  365.
1998 352  0  323.
1998 353  0  343.
1998 354  0  422.
1998 355  0  351.
1998 356  0  350.
1998 357  0  343.
1998 358  0  332.
1998 359  0  422.
1998 360  0  468.
1998 361  0  380.
1998 362  0  378.
1998 363  0  405.
1998 364  0  410.
1998 365  0  389.
1999   1  0  421.
1999   2  0  397.
1999   3  0  354.
1999   4  0  341.
1999   5  0  330.
1999   6  0  378.
1999   7  0  476.
1999   8  0  453.
1999   9  0  435.
1999  10  0  406.
1999  11  0  429.
1999  12  0  373.
1999  13  0  382.
1999  14  0  461.
1999  15  0  554.
1999  16  0  498.
1999  17  0  413.
1999  18  0  355.
1999  19  0  371.
1999  20  0  375.
1999  21  0  471.
1999  22  0  514.
1999  23  0  572.
1999  24  0  517.
1999  25  0  463.
1999  26  0  388.
1999  27  0  372.
Many thanks,
Jibrin

On Sat, Jan 16, 2021 at 6:24 PM peter dalgaard <pdalgd at gmail.com> wrote:

> Something like this?
>
> > as.Date(ISOdate(1998,1,1))+(1:100)-1
>   [1] "1998-01-01" "1998-01-02" "1998-01-03" "1998-01-04" "1998-01-05"
>   [6] "1998-01-06" "1998-01-07" "1998-01-08" "1998-01-09" "1998-01-10"
>  [11] "1998-01-11" "1998-01-12" "1998-01-13" "1998-01-14" "1998-01-15"
>  [16] "1998-01-16" "1998-01-17" "1998-01-18" "1998-01-19" "1998-01-20"
>  [21] "1998-01-21" "1998-01-22" "1998-01-23" "1998-01-24" "1998-01-25"
>  [26] "1998-01-26" "1998-01-27" "1998-01-28" "1998-01-29" "1998-01-30"
>  [31] "1998-01-31" "1998-02-01" "1998-02-02" "1998-02-03" "1998-02-04"
>  [36] "1998-02-05" "1998-02-06" "1998-02-07" "1998-02-08" "1998-02-09"
>  [41] "1998-02-10" "1998-02-11" "1998-02-12" "1998-02-13" "1998-02-14"
>  [46] "1998-02-15" "1998-02-16" "1998-02-17" "1998-02-18" "1998-02-19"
>  [51] "1998-02-20" "1998-02-21" "1998-02-22" "1998-02-23" "1998-02-24"
>  [56] "1998-02-25" "1998-02-26" "1998-02-27" "1998-02-28" "1998-03-01"
>  [61] "1998-03-02" "1998-03-03" "1998-03-04" "1998-03-05" "1998-03-06"
>  [66] "1998-03-07" "1998-03-08" "1998-03-09" "1998-03-10" "1998-03-11"
>  [71] "1998-03-12" "1998-03-13" "1998-03-14" "1998-03-15" "1998-03-16"
>  [76] "1998-03-17" "1998-03-18" "1998-03-19" "1998-03-20" "1998-03-21"
>  [81] "1998-03-22" "1998-03-23" "1998-03-24" "1998-03-25" "1998-03-26"
>  [86] "1998-03-27" "1998-03-28" "1998-03-29" "1998-03-30" "1998-03-31"
>  [91] "1998-04-01" "1998-04-02" "1998-04-03" "1998-04-04" "1998-04-05"
>  [96] "1998-04-06" "1998-04-07" "1998-04-08" "1998-04-09" "1998-04-10"
>
> Or, if you want month numbers and day of month as numerics:
>
> > as.POSIXlt(as.Date(ISOdate(1998,1,1))+(1:100)-1)$mon
>   [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1
> 1 1 1
>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
> 2 2 2
>  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3
> > as.POSIXlt(as.Date(ISOdate(1998,1,1))+(1:100)-1)$mday
>   [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
> 24 25
>  [26] 26 27 28 29 30 31  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17
> 18 19
>  [51] 20 21 22 23 24 25 26 27 28  1  2  3  4  5  6  7  8  9 10 11 12 13 14
> 15 16
>  [76] 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  1  2  3  4  5  6  7
> 8  9 10
>
> -pd
>
> > On 16 Jan 2021, at 07:48 , Jibrin Alhassan <jibrin.alhassan at unn.edu.ng>
> wrote:
> >
> > Hi Barradas
> > Sorry for the delay. Below is a section of my data. I have up to 1826
> > covering 1998 to 2002
> > year   day Hr SWS
> > 1998   1  0  344.
> > 1998   2  0  346.
> > 1998   3  0  356.
> > 1998   4  0  332.
> > 1998   5  0  302.
> > 1998   6  0  329.
> > 1998   7  0  395.
> > 1998   8  0  359.
> > 1998   9  0  471.
> > 1998  10  0  392.
> > 1998  11  0  346.
> > 1998  12  0  387.
> > 1998  13  0  393.
> > 1998  14  0  367.
> > 1998  15  0  320.
> > 1998  16  0  309.
> > 1998  17  0  341.
> > 1998  18  0  329.
> > 1998  19  0  322.
> > 1998  20  0  429.
> > 1998  21  0  433.
> > 1998  22  0  398.
> > 1998  23  0  393.
> > 1998  24  0  393.
> > 1998  25  0  423.
> > 1998  26  0  426.
> > 1998  27  0  429.
> > 1998  28  0  386.
> > 1998  29  0  381.
> > 1998  30  0  375.
> > 1998  31  0  365.
> > 1998  32  0  450.
> > 1998  33  0  381.
> > 1998  34  0  316.
> > 1998  35  0  351.
> > 1998  36  0  306.
> > 1998  37  0  312.
> > 1998  38  0  320.
> > 1998  39  0  339.
> > 1998  40  0  395.
> > 1998  41  0  429.
> > 1998  42  0  479.
> > 1998  43  0  495.
> > 1998  44  0  407.
> > 1998  45  0  358.
> > 1998  46  0  360.
> > 1998  47  0  382.
> > 1998  48  0  394.
> > 1998  49  0  393.
> > 1998  50  0  435.
> > 1998  51  0  408.
> > 1998  52  0  360.
> > 1998  53  0  372.
> > 1998  54  0  376.
> > 1998  55  0  379.
> > 1998  56  0  361.
> > 1998  57  0  333.
> > 1998  58  0  321.
> > 1998  59  0  344.
> > 1998  60  0  412.
> > 1998  61  0  428.
> > 1998  62  0  401.
> > 1998  63  0  369.
> > 1998  64  0  343.
> > 1998  65  0  330.
> > 1998  66  0  317.
> > 1998  67  0  296.
> > 1998  68  0  282.
> > 1998  69  0  404.
> > 1998  70  0  530.
> > 1998  71  0  525.
> > 1998  72  0  484.
> > 1998  73  0  430.
> > 1998  74  0  388.
> > 1998  75  0  347.
> > 1998  76  0  337.
> > 1998  77  0  342.
> > 1998  78  0  305.
> > 1998  79  0  329.
> > 1998  80  0  420.
> > 1998  81  0  564.
> > 1998  82  0  483.
> > 1998  83  0  385.
> > 1998  84  0  393.
> > 1998  85  0  437.
> > 1998  86  0  441.
> > 1998  87  0  434.
> > 1998  88  0  471.
> > 1998  89  0  429.
> > 1998  90  0  412.
> > 1998  91  0  370.
> > 1998  92  0  326.
> > 1998  93  0  357.
> > 1998  94  0  338.
> > 1998  95  0  380.
> > 1998  96  0  339.
> > 1998  97  0  312.
> > 1998  98  0  313.
> > 1998  99  0  327.
> > 1998 100  0  362.
> > 1998 101  0  358.
> > 1998 102  0  387.
> > 1998 103  0  397.
> > 1998 104  0  375.
> > 1998 105  0  350.
> > 1998 106  0  357.
> > 1998 107  0  472.
> > 1998 108  0  526.
> > 1998 109  0  396.
> > 1998 110  0  374.
> > 1998 111  0  376.
> > 1998 112  0  355.
> > 1998 113  0  343.
> > 1998 114  0  425.
> > 1998 115  0  426.
> > 1998 116  0  479.
> > 1998 117  0  469.
> > 1998 118  0  425.
> > 1998 119  0  344.
> > 1998 120  0  341.
> > 1998 121  0  426.
> > 1998 122  0  601.
> > 1998 123  0  476.
> > 1998 124  0  670.
> > 1998 125  0  585.
> > 1998 126  0  496.
> > 1998 127  0  479.
> > 1998 128  0  569.
> > 1998 129  0  531.
> > 1998 130  0  489.
> > 1998 131  0  484.
> > 1998 132  0  480.
> > 1998 133  0  393.
> > 1998 134  0  332.
> > 1998 135  0  327.
> > 1998 136  0  493.
> > 1998 137  0  493.
> > 1998 138  0  430.
> > 1998 139  0  396.
> > 1998 140  0  408.
> > 1998 141  0  416.
> > 1998 142  0  376.
> > 1998 143  0  375.
> > 1998 144  0  415.
> > 1998 145  0  407.
> > 1998 146  0  398.
> > 1998 147  0  352.
> > 1998 148  0  349.
> > 1998 149  0  517.
> > 1998 150  0  597.
> > 1998 151  0  480.
> > 1998 152  0  435.
> > 1998 153  0  408.
> > 1998 154  0  441.
> > 1998 155  0  397.
> > 1998 156  0  374.
> > 1998 157  0  413.
> > 1998 158  0  582.
> > 1998 159  0  513.
> > 1998 160  0  459.
> > 1998 161  0  466.
> > 1998 162  0  414.
> > 1998 163  0  354.
> > 1998 164  0  341.
> > 1998 165  0  343.
> > 1998 166  0  369.
> > 1998 167  0  411.
> > 1998 168  0  355.
> > Thanks
> > Jibrin
> >
> > On Fri, Jan 15, 2021 at 7:15 PM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> >> Hello,
> >>
> >> No dataset was attached. Like the posting guide says,
> >>
> >> No binary attachments except for PS, PDF, and some image and archive
> >> formats (others are automatically stripped off because they can contain
> >> malicious software). Files in other formats and larger ones should
> >> rather be put on the web and have only their URLs posted. This way a
> >> reader has the option to download them or not.
> >>
> >>
> >> Can you post sample data? Please post the output of `dput(df)`. Or, if
> >> it is too big the output of `dput(head(df, 20))`. (`df` is the name of
> >> your dataset.)
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >> ?s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
> >>> Dear R users,
> >>> I am very new to R software. I have solar wind speed data needed for my
> >>> work. How do I convert day in the year to year, month, and day with R
> >>> software? I have used this code
> >>> as.Date(0, origin = "1998-01-01")
> >>> but it can only convert one day of the year at a time. Meanwhile, I
> have
> >> up
> >>> to the 1998-2002 data set. Attached is my data.
> >>> Kindly help, please.
> >>> Jibrin Alhassan
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Wed Jan 20 13:52:16 2021
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Wed, 20 Jan 2021 13:52:16 +0100
Subject: [R] Converting "day of year" to "year", "month" and "day"
In-Reply-To: <97590CFB-BF19-4751-9562-829FC373C2ED@dcn.davis.ca.us>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
 <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
 <fc104a3c-6d2f-062a-d79e-42ec7c7811b3@sapo.pt>
 <CAEGeL+HOZT_AzYS1cVB9wGC7OFvH7EM=U_n02y-sP1HZFs02wg@mail.gmail.com>
 <97590CFB-BF19-4751-9562-829FC373C2ED@dcn.davis.ca.us>
Message-ID: <CAEGeL+HPct+SRCa51yLrdtZncwm7Nd7gt_ZYONB0M2GdSq49+g@mail.gmail.com>

Jeff,
Thank you so much for the challenge. It is inspiring.
Jibrin

On Sun, Jan 17, 2021 at 7:04 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This is an opportunity for you to think for yourself (r-help) instead of
> expecting solutions neatly wrapped and delivered (r-do-my-work-for-me).
> Remove the no-longer-needed columns once the desired columns are available.
>
> On January 17, 2021 7:12:28 AM PST, Jibrin Alhassan <
> jibrin.alhassan at unn.edu.ng> wrote:
> >Hi Barradas,
> >Thanks for your assistance. It has brought me closer to what I am
> >looking
> >for. I tried your code as shown below:
> >> df1 <- read.table("SWSdata_1998_2002", header = TRUE)
> >> df1$date <- as.Date(paste(df1$year, df1$day),format = "%Y %j",origin
> >=
> >"1998-01-01")
> >> head(df1)
> >  year day Hr SWS       date
> >1 1998   1  0 344 1998-01-01
> >2 1998   2  0 346 1998-01-02
> >3 1998   3  0 356 1998-01-03
> >4 1998   4  0 332 1998-01-04
> >5 1998   5  0 302 1998-01-05
> >6 1998   6  0 329 1998-01-06
> >What I need is the last two columns only (SWS, date). The first 3
> >columns
> >(year, day Hr should go). Your code produced only 6 datasets. My
> >dataset is
> >1,826 from 1998 to 2002. How do I generate this at once?
> >Many many thanks for your time. I have pasted below a section of my
> >dataset
> >for your guidance, please.
> >Jibrin
> >year   day Hr SWS
> >1998   1  0  344.
> >1998   2  0  346.
> >1998   3  0  356.
> >1998   4  0  332.
> >1998   5  0  302.
> >1998   6  0  329.
> >1998   7  0  395.
> >1998   8  0  359.
> >1998   9  0  471.
> >1998  10  0  392.
> >1998  11  0  346.
> >1998  12  0  387.
> >1998  13  0  393.
> >1998  14  0  367.
> >1998  15  0  320.
> >1998  16  0  309.
> >1998  17  0  341.
> >1998  18  0  329.
> >1998  19  0  322.
> >1998  20  0  429.
> >1998  21  0  433.
> >1998  22  0  398.
> >1998  23  0  393.
> >1998  24  0  393.
> >1998  25  0  423.
> >1998  26  0  426.
> >1998  27  0  429.
> >1998  28  0  386.
> >1998  29  0  381.
> >1998  30  0  375.
> >1998  31  0  365.
> >1998  32  0  450.
> >1998  33  0  381.
> >1998  34  0  316.
> >1998  35  0  351.
> >1998  36  0  306.
> >1998  37  0  312.
> >1998  38  0  320.
> >1998  39  0  339.
> >1998  40  0  395.
> >1998  41  0  429.
> >1998  42  0  479.
> >1998  43  0  495.
> >1998  44  0  407.
> >1998  45  0  358.
> >1998  46  0  360.
> >1998  47  0  382.
> >1998  48  0  394.
> >1998  49  0  393.
> >1998  50  0  435.
> >1998  51  0  408.
> >1998  52  0  360.
> >1998  53  0  372.
> >1998  54  0  376.
> >1998  55  0  379.
> >1998  56  0  361.
> >1998  57  0  333.
> >1998  58  0  321.
> >1998  59  0  344.
> >1998  60  0  412.
> >1998  61  0  428.
> >1998  62  0  401.
> >1998  63  0  369.
> >1998  64  0  343.
> >1998  65  0  330.
> >1998  66  0  317.
> >1998  67  0  296.
> >1998  68  0  282.
> >1998  69  0  404.
> >1998  70  0  530.
> >1998  71  0  525.
> >1998  72  0  484.
> >1998  73  0  430.
> >1998  74  0  388.
> >1998  75  0  347.
> >1998  76  0  337.
> >1998  77  0  342.
> >1998  78  0  305.
> >1998  79  0  329.
> >1998  80  0  420.
> >1998  81  0  564.
> >1998  82  0  483.
> >1998  83  0  385.
> >1998  84  0  393.
> >1998  85  0  437.
> >1998  86  0  441.
> >1998  87  0  434.
> >1998  88  0  471.
> >1998  89  0  429.
> >1998  90  0  412.
> >1998  91  0  370.
> >1998  92  0  326.
> >1998  93  0  357.
> >1998  94  0  338.
> >1998  95  0  380.
> >1998  96  0  339.
> >1998  97  0  312.
> >1998  98  0  313.
> >1998  99  0  327.
> >1998 100  0  362.
> >1998 101  0  358.
> >1998 102  0  387.
> >1998 103  0  397.
> >1998 104  0  375.
> >1998 105  0  350.
> >1998 106  0  357.
> >1998 107  0  472.
> >1998 108  0  526.
> >1998 109  0  396.
> >1998 110  0  374.
> >1998 111  0  376.
> >1998 112  0  355.
> >1998 113  0  343.
> >1998 114  0  425.
> >1998 115  0  426.
> >1998 116  0  479.
> >1998 117  0  469.
> >1998 118  0  425.
> >1998 119  0  344.
> >1998 120  0  341.
> >1998 121  0  426.
> >1998 122  0  601.
> >1998 123  0  476.
> >1998 124  0  670.
> >1998 125  0  585.
> >1998 126  0  496.
> >1998 127  0  479.
> >1998 128  0  569.
> >1998 129  0  531.
> >1998 130  0  489.
> >1998 131  0  484.
> >1998 132  0  480.
> >1998 133  0  393.
> >1998 134  0  332.
> >1998 135  0  327.
> >1998 136  0  493.
> >1998 137  0  493.
> >1998 138  0  430.
> >1998 139  0  396.
> >1998 140  0  408.
> >1998 141  0  416.
> >1998 142  0  376.
> >1998 143  0  375.
> >1998 144  0  415.
> >1998 145  0  407.
> >1998 146  0  398.
> >1998 147  0  352.
> >1998 148  0  349.
> >1998 149  0  517.
> >1998 150  0  597.
> >1998 151  0  480.
> >1998 152  0  435.
> >1998 153  0  408.
> >1998 154  0  441.
> >1998 155  0  397.
> >1998 156  0  374.
> >1998 157  0  413.
> >1998 158  0  582.
> >1998 159  0  513.
> >1998 160  0  459.
> >1998 161  0  466.
> >1998 162  0  414.
> >1998 163  0  354.
> >1998 164  0  341.
> >1998 165  0  343.
> >1998 166  0  369.
> >1998 167  0  411.
> >1998 168  0  355.
> >1998 169  0  333.
> >1998 170  0  443.
> >1998 171  0  426.
> >1998 172  0  419.
> >1998 173  0  404.
> >1998 174  0  387.
> >1998 175  0  460.
> >1998 176  0  447.
> >1998 177  0  469.
> >1998 178  0  447.
> >1998 179  0  389.
> >1998 180  0  375.
> >1998 181  0  354.
> >1998 182  0  316.
> >1998 183  0  369.
> >1998 184  0  410.
> >1998 185  0  406.
> >1998 186  0  477.
> >1998 187  0  583.
> >1998 188  0  458.
> >1998 189  0  386.
> >1998 190  0  342.
> >1998 191  0  333.
> >1998 192  0  369.
> >1998 193  0  406.
> >1998 194  0  375.
> >1998 195  0  332.
> >1998 196  0  310.
> >1998 197  0  528.
> >1998 198  0  530.
> >1998 199  0  387.
> >1998 200  0  385.
> >1998 201  0  349.
> >1998 202  0  409.
> >1998 203  0  399.
> >1998 204  0  619.
> >1998 205  0  658.
> >1998 206  0  581.
> >1998 207  0  445.
> >1998 208  0  370.
> >1998 209  0  326.
> >1998 210  0  334.
> >1998 211  0  384.
> >1998 212  0  423.
> >1998 213  0  412.
> >1998 214  0  404.
> >1998 215  0  370.
> >1998 216  0  384.
> >1998 217  0  383.
> >1998 218  0  378.
> >1998 219  0  461.
> >1998 220  0  460.
> >1998 221  0  400.
> >1998 222  0  447.
> >1998 223  0  373.
> >1998 224  0  379.
> >1998 225  0  374.
> >1998 226  0  374.
> >1998 227  0  391.
> >1998 228  0  348.
> >1998 229  0  303.
> >1998 230  0  279.
> >1998 231  0  312.
> >1998 232  0  331.
> >1998 233  0  298.
> >1998 234  0  341.
> >1998 235  0  493.
> >1998 236  0  436.
> >1998 237  0  400.
> >1998 238  0  633.
> >1998 239  0  630.
> >1998 240  0  583.
> >1998 241  0  547.
> >1998 242  0  550.
> >1998 243  0  499.
> >1998 244  0  444.
> >1998 245  0  427.
> >1998 246  0  401.
> >
> >On Sat, Jan 16, 2021 at 8:01 AM Rui Barradas <ruipbarradas at sapo.pt>
> >wrote:
> >
> >> Hello,
> >>
> >> Thanks for the data, it makes things easier.
> >>
> >> df1 <- read.table("Jibrin_data.txt", header = TRUE)
> >> #'data.frame':  168 obs. of  4 variables:
> >> # $ year: int  1998 1998 1998 1998 1998 1998 1998 1998 1998 1998 ...
> >> # $ day : int  1 2 3 4 5 6 7 8 9 10 ...
> >> # $ Hr  : int  0 0 0 0 0 0 0 0 0 0 ...
> >> # $ SWS : num  344 346 356 332 302 329 395 359 471 392 ...
> >>
> >> Here is a simple way of converting the year and day of year columns
> >to a
> >> column of class "Date".
> >> Like others have said, there are also CRAN packages to handle
> >date/time
> >> data, my favorite being package lubridate, but base R can do it.
> >>
> >>
> >> df1$date <- as.Date(paste(df1$year, df1$day),
> >>                      format = "%Y %j",
> >>                      origin = "1998-01-01")
> >>
> >> head(df1)
> >> #  year day Hr SWS       date
> >> #1 1998   1  0 344 1998-01-01
> >> #2 1998   2  0 346 1998-01-02
> >> #3 1998   3  0 356 1998-01-03
> >> #4 1998   4  0 332 1998-01-04
> >> #5 1998   5  0 302 1998-01-05
> >> #6 1998   6  0 329 1998-01-06
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >> ?s 06:48 de 16/01/21, Jibrin Alhassan escreveu:
> >> > Hi Barradas
> >> >   Sorry for the delay. Below is a section of my data. I have up to
> >1826
> >> > covering 1998 to 2002
> >> > year   day Hr SWS
> >> > 1998   1  0  344.
> >> > 1998   2  0  346.
> >> > 1998   3  0  356.
> >> > 1998   4  0  332.
> >> > 1998   5  0  302.
> >> > 1998   6  0  329.
> >> > 1998   7  0  395.
> >> > 1998   8  0  359.
> >> > 1998   9  0  471.
> >> > 1998  10  0  392.
> >> > 1998  11  0  346.
> >> > 1998  12  0  387.
> >> > 1998  13  0  393.
> >> > 1998  14  0  367.
> >> > 1998  15  0  320.
> >> > 1998  16  0  309.
> >> > 1998  17  0  341.
> >> > 1998  18  0  329.
> >> > 1998  19  0  322.
> >> > 1998  20  0  429.
> >> > 1998  21  0  433.
> >> > 1998  22  0  398.
> >> > 1998  23  0  393.
> >> > 1998  24  0  393.
> >> > 1998  25  0  423.
> >> > 1998  26  0  426.
> >> > 1998  27  0  429.
> >> > 1998  28  0  386.
> >> > 1998  29  0  381.
> >> > 1998  30  0  375.
> >> > 1998  31  0  365.
> >> > 1998  32  0  450.
> >> > 1998  33  0  381.
> >> > 1998  34  0  316.
> >> > 1998  35  0  351.
> >> > 1998  36  0  306.
> >> > 1998  37  0  312.
> >> > 1998  38  0  320.
> >> > 1998  39  0  339.
> >> > 1998  40  0  395.
> >> > 1998  41  0  429.
> >> > 1998  42  0  479.
> >> > 1998  43  0  495.
> >> > 1998  44  0  407.
> >> > 1998  45  0  358.
> >> > 1998  46  0  360.
> >> > 1998  47  0  382.
> >> > 1998  48  0  394.
> >> > 1998  49  0  393.
> >> > 1998  50  0  435.
> >> > 1998  51  0  408.
> >> > 1998  52  0  360.
> >> > 1998  53  0  372.
> >> > 1998  54  0  376.
> >> > 1998  55  0  379.
> >> > 1998  56  0  361.
> >> > 1998  57  0  333.
> >> > 1998  58  0  321.
> >> > 1998  59  0  344.
> >> > 1998  60  0  412.
> >> > 1998  61  0  428.
> >> > 1998  62  0  401.
> >> > 1998  63  0  369.
> >> > 1998  64  0  343.
> >> > 1998  65  0  330.
> >> > 1998  66  0  317.
> >> > 1998  67  0  296.
> >> > 1998  68  0  282.
> >> > 1998  69  0  404.
> >> > 1998  70  0  530.
> >> > 1998  71  0  525.
> >> > 1998  72  0  484.
> >> > 1998  73  0  430.
> >> > 1998  74  0  388.
> >> > 1998  75  0  347.
> >> > 1998  76  0  337.
> >> > 1998  77  0  342.
> >> > 1998  78  0  305.
> >> > 1998  79  0  329.
> >> > 1998  80  0  420.
> >> > 1998  81  0  564.
> >> > 1998  82  0  483.
> >> > 1998  83  0  385.
> >> > 1998  84  0  393.
> >> > 1998  85  0  437.
> >> > 1998  86  0  441.
> >> > 1998  87  0  434.
> >> > 1998  88  0  471.
> >> > 1998  89  0  429.
> >> > 1998  90  0  412.
> >> > 1998  91  0  370.
> >> > 1998  92  0  326.
> >> > 1998  93  0  357.
> >> > 1998  94  0  338.
> >> > 1998  95  0  380.
> >> > 1998  96  0  339.
> >> > 1998  97  0  312.
> >> > 1998  98  0  313.
> >> > 1998  99  0  327.
> >> > 1998 100  0  362.
> >> > 1998 101  0  358.
> >> > 1998 102  0  387.
> >> > 1998 103  0  397.
> >> > 1998 104  0  375.
> >> > 1998 105  0  350.
> >> > 1998 106  0  357.
> >> > 1998 107  0  472.
> >> > 1998 108  0  526.
> >> > 1998 109  0  396.
> >> > 1998 110  0  374.
> >> > 1998 111  0  376.
> >> > 1998 112  0  355.
> >> > 1998 113  0  343.
> >> > 1998 114  0  425.
> >> > 1998 115  0  426.
> >> > 1998 116  0  479.
> >> > 1998 117  0  469.
> >> > 1998 118  0  425.
> >> > 1998 119  0  344.
> >> > 1998 120  0  341.
> >> > 1998 121  0  426.
> >> > 1998 122  0  601.
> >> > 1998 123  0  476.
> >> > 1998 124  0  670.
> >> > 1998 125  0  585.
> >> > 1998 126  0  496.
> >> > 1998 127  0  479.
> >> > 1998 128  0  569.
> >> > 1998 129  0  531.
> >> > 1998 130  0  489.
> >> > 1998 131  0  484.
> >> > 1998 132  0  480.
> >> > 1998 133  0  393.
> >> > 1998 134  0  332.
> >> > 1998 135  0  327.
> >> > 1998 136  0  493.
> >> > 1998 137  0  493.
> >> > 1998 138  0  430.
> >> > 1998 139  0  396.
> >> > 1998 140  0  408.
> >> > 1998 141  0  416.
> >> > 1998 142  0  376.
> >> > 1998 143  0  375.
> >> > 1998 144  0  415.
> >> > 1998 145  0  407.
> >> > 1998 146  0  398.
> >> > 1998 147  0  352.
> >> > 1998 148  0  349.
> >> > 1998 149  0  517.
> >> > 1998 150  0  597.
> >> > 1998 151  0  480.
> >> > 1998 152  0  435.
> >> > 1998 153  0  408.
> >> > 1998 154  0  441.
> >> > 1998 155  0  397.
> >> > 1998 156  0  374.
> >> > 1998 157  0  413.
> >> > 1998 158  0  582.
> >> > 1998 159  0  513.
> >> > 1998 160  0  459.
> >> > 1998 161  0  466.
> >> > 1998 162  0  414.
> >> > 1998 163  0  354.
> >> > 1998 164  0  341.
> >> > 1998 165  0  343.
> >> > 1998 166  0  369.
> >> > 1998 167  0  411.
> >> > 1998 168  0  355.
> >> > Thanks
> >> > Jibrin
> >> >
> >> > On Fri, Jan 15, 2021 at 7:15 PM Rui Barradas <ruipbarradas at sapo.pt
> >> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >> >
> >> >     Hello,
> >> >
> >> >     No dataset was attached. Like the posting guide says,
> >> >
> >> >     No binary attachments except for PS, PDF, and some image and
> >archive
> >> >     formats (others are automatically stripped off because they can
> >> contain
> >> >     malicious software). Files in other formats and larger ones
> >should
> >> >     rather be put on the web and have only their URLs posted. This
> >way a
> >> >     reader has the option to download them or not.
> >> >
> >> >
> >> >     Can you post sample data? Please post the output of `dput(df)`.
> >Or,
> >> if
> >> >     it is too big the output of `dput(head(df, 20))`. (`df` is the
> >name
> >> of
> >> >     your dataset.)
> >> >
> >> >     Hope this helps,
> >> >
> >> >     Rui Barradas
> >> >
> >> >     ?s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
> >> >      > Dear R users,
> >> >      > I am very new to R software. I have solar wind speed data
> >needed
> >> >     for my
> >> >      > work. How do I convert day in the year to year, month, and
> >day
> >> with R
> >> >      > software? I have used this code
> >> >      > as.Date(0, origin = "1998-01-01")
> >> >      > but it can only convert one day of the year at a time.
> >Meanwhile,
> >> >     I have up
> >> >      > to the 1998-2002 data set. Attached is my data.
> >> >      > Kindly help, please.
> >> >      > Jibrin Alhassan
> >> >      > ______________________________________________
> >> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing
> >list
> >> >     -- To UNSUBSCRIBE and more, see
> >> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >      > PLEASE do read the posting guide
> >> >     http://www.R-project.org/posting-guide.html
> >> >      > and provide commented, minimal, self-contained, reproducible
> >code.
> >> >      >
> >> >
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Wed Jan 20 14:18:51 2021
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Wed, 20 Jan 2021 14:18:51 +0100
Subject: [R] Fwd:  Converting "day of year" to "year", "month" and "day"
In-Reply-To: <CAEGeL+HEASfBA=Y7CQj=QCa6D-9jvOrh9GKAwnrJunf+DiFSew@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
 <85892412-1cc2-8e1a-43b1-26db9384e9d9@sapo.pt>
 <CAEGeL+EFE5pfU_133h_j7d74maMaBDJEHoxe9QdiGxyBt5kgmA@mail.gmail.com>
 <fc104a3c-6d2f-062a-d79e-42ec7c7811b3@sapo.pt>
 <CAEGeL+HOZT_AzYS1cVB9wGC7OFvH7EM=U_n02y-sP1HZFs02wg@mail.gmail.com>
 <7bd6831b-f839-f59f-85a4-9aa74c9eedf1@sapo.pt>
 <CAEGeL+GidHidyg=rOF9W3DcJSnFFfBb7-FpDWtijfRqNTuDVQA@mail.gmail.com>
 <5249e565-50af-6d85-f418-72b4cef6cb0e@sapo.pt>
 <CAEGeL+HEASfBA=Y7CQj=QCa6D-9jvOrh9GKAwnrJunf+DiFSew@mail.gmail.com>
Message-ID: <CAEGeL+Ft5qr3sr+6T1yKs6AJNXGZ2LadahVCtNTf-gnUHzfEbA@mail.gmail.com>

---------- Forwarded message ---------
From: Jibrin Alhassan <jibrin.alhassan at unn.edu.ng>
Date: Wed, Jan 20, 2021 at 2:18 PM
Subject: Re: [R] Converting "day of year" to "year", "month" and "day"
To: Rui Barradas <ruipbarradas at sapo.pt>


Rui,
I am grateful. All the 1826 rows have been displayed. My sincere
appreciation to all for your time and inputs in solving the problem I
posted. It has now been solved.
Jibrin Alhassan

On Wed, Jan 20, 2021 at 2:00 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I'm not seeing how the code I've posted can stop you from displaying
> more than 6 rows.
>
> The following instructions are for display only, they do not change the
> dataframes.
>
> head(df1)
> head(df2)
>
>
> To display the entire df's, try
>
> print(df1)
> print(df2)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 12:56 de 20/01/21, Jibrin Alhassan escreveu:
> > Rui,
> > I am very much grateful for your time and inputs.  I have tried to check
> > how to display all the 1,826 rows. I have not found a solution yet.
> > Further help please.
> > Jibrin
> >
> > On Mon, Jan 18, 2021 at 12:14 AM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     My code didn't produce only 6 rows, it displayed only 6 rows. But all
> >     rows now have a date column.
> >
> >     As for the first question,
> >
> >     df2 <- df1[c("SWS", "date")]
> >
> >
> >     selects the columns with those names. I didn't rewrite the original
> >     df1,
> >     but if you want to, assign to df1, without creating df2.
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >     ?s 15:12 de 17/01/21, Jibrin Alhassan escreveu:
> >      > Hi Barradas,
> >      > Thanks for your assistance. It has brought me closer to what I am
> >      > looking for. I tried your code as shown below:
> >      >  > df1 <- read.table("SWSdata_1998_2002", header = TRUE)
> >      >  > df1$date <- as.Date(paste(df1$year, df1$day),format = "%Y
> >     %j",origin
> >      > = "1998-01-01")
> >      >  > head(df1)
> >      >    year day Hr SWS       date
> >      > 1 1998   1  0 344 1998-01-01
> >      > 2 1998   2  0 346 1998-01-02
> >      > 3 1998   3  0 356 1998-01-03
> >      > 4 1998   4  0 332 1998-01-04
> >      > 5 1998   5  0 302 1998-01-05
> >      > 6 1998   6  0 329 1998-01-06
> >      > What I need is the last two columns only (SWS, date). The first 3
> >      > columns (year, day Hr should go). Your code produced only 6
> >     datasets. My
> >      > dataset is 1,826 from 1998 to 2002. How do I generate this at
> once?
> >      > Many many thanks for your time. I have pasted below a section of
> my
> >      > dataset for your guidance, please.
> >      > Jibrin
> >      > year   day Hr SWS
> >      > 1998   1  0  344.
> >      > 1998   2  0  346.
> >      > 1998   3  0  356.
> >      > 1998   4  0  332.
> >      > 1998   5  0  302.
> >      > 1998   6  0  329.
> >      > 1998   7  0  395.
> >      > 1998   8  0  359.
> >      > 1998   9  0  471.
> >      > 1998  10  0  392.
> >      > 1998  11  0  346.
> >      > 1998  12  0  387.
> >      > 1998  13  0  393.
> >      > 1998  14  0  367.
> >      > 1998  15  0  320.
> >      > 1998  16  0  309.
> >      > 1998  17  0  341.
> >      > 1998  18  0  329.
> >      > 1998  19  0  322.
> >      > 1998  20  0  429.
> >      > 1998  21  0  433.
> >      > 1998  22  0  398.
> >      > 1998  23  0  393.
> >      > 1998  24  0  393.
> >      > 1998  25  0  423.
> >      > 1998  26  0  426.
> >      > 1998  27  0  429.
> >      > 1998  28  0  386.
> >      > 1998  29  0  381.
> >      > 1998  30  0  375.
> >      > 1998  31  0  365.
> >      > 1998  32  0  450.
> >      > 1998  33  0  381.
> >      > 1998  34  0  316.
> >      > 1998  35  0  351.
> >      > 1998  36  0  306.
> >      > 1998  37  0  312.
> >      > 1998  38  0  320.
> >      > 1998  39  0  339.
> >      > 1998  40  0  395.
> >      > 1998  41  0  429.
> >      > 1998  42  0  479.
> >      > 1998  43  0  495.
> >      > 1998  44  0  407.
> >      > 1998  45  0  358.
> >      > 1998  46  0  360.
> >      > 1998  47  0  382.
> >      > 1998  48  0  394.
> >      > 1998  49  0  393.
> >      > 1998  50  0  435.
> >      > 1998  51  0  408.
> >      > 1998  52  0  360.
> >      > 1998  53  0  372.
> >      > 1998  54  0  376.
> >      > 1998  55  0  379.
> >      > 1998  56  0  361.
> >      > 1998  57  0  333.
> >      > 1998  58  0  321.
> >      > 1998  59  0  344.
> >      > 1998  60  0  412.
> >      > 1998  61  0  428.
> >      > 1998  62  0  401.
> >      > 1998  63  0  369.
> >      > 1998  64  0  343.
> >      > 1998  65  0  330.
> >      > 1998  66  0  317.
> >      > 1998  67  0  296.
> >      > 1998  68  0  282.
> >      > 1998  69  0  404.
> >      > 1998  70  0  530.
> >      > 1998  71  0  525.
> >      > 1998  72  0  484.
> >      > 1998  73  0  430.
> >      > 1998  74  0  388.
> >      > 1998  75  0  347.
> >      > 1998  76  0  337.
> >      > 1998  77  0  342.
> >      > 1998  78  0  305.
> >      > 1998  79  0  329.
> >      > 1998  80  0  420.
> >      > 1998  81  0  564.
> >      > 1998  82  0  483.
> >      > 1998  83  0  385.
> >      > 1998  84  0  393.
> >      > 1998  85  0  437.
> >      > 1998  86  0  441.
> >      > 1998  87  0  434.
> >      > 1998  88  0  471.
> >      > 1998  89  0  429.
> >      > 1998  90  0  412.
> >      > 1998  91  0  370.
> >      > 1998  92  0  326.
> >      > 1998  93  0  357.
> >      > 1998  94  0  338.
> >      > 1998  95  0  380.
> >      > 1998  96  0  339.
> >      > 1998  97  0  312.
> >      > 1998  98  0  313.
> >      > 1998  99  0  327.
> >      > 1998 100  0  362.
> >      > 1998 101  0  358.
> >      > 1998 102  0  387.
> >      > 1998 103  0  397.
> >      > 1998 104  0  375.
> >      > 1998 105  0  350.
> >      > 1998 106  0  357.
> >      > 1998 107  0  472.
> >      > 1998 108  0  526.
> >      > 1998 109  0  396.
> >      > 1998 110  0  374.
> >      > 1998 111  0  376.
> >      > 1998 112  0  355.
> >      > 1998 113  0  343.
> >      > 1998 114  0  425.
> >      > 1998 115  0  426.
> >      > 1998 116  0  479.
> >      > 1998 117  0  469.
> >      > 1998 118  0  425.
> >      > 1998 119  0  344.
> >      > 1998 120  0  341.
> >      > 1998 121  0  426.
> >      > 1998 122  0  601.
> >      > 1998 123  0  476.
> >      > 1998 124  0  670.
> >      > 1998 125  0  585.
> >      > 1998 126  0  496.
> >      > 1998 127  0  479.
> >      > 1998 128  0  569.
> >      > 1998 129  0  531.
> >      > 1998 130  0  489.
> >      > 1998 131  0  484.
> >      > 1998 132  0  480.
> >      > 1998 133  0  393.
> >      > 1998 134  0  332.
> >      > 1998 135  0  327.
> >      > 1998 136  0  493.
> >      > 1998 137  0  493.
> >      > 1998 138  0  430.
> >      > 1998 139  0  396.
> >      > 1998 140  0  408.
> >      > 1998 141  0  416.
> >      > 1998 142  0  376.
> >      > 1998 143  0  375.
> >      > 1998 144  0  415.
> >      > 1998 145  0  407.
> >      > 1998 146  0  398.
> >      > 1998 147  0  352.
> >      > 1998 148  0  349.
> >      > 1998 149  0  517.
> >      > 1998 150  0  597.
> >      > 1998 151  0  480.
> >      > 1998 152  0  435.
> >      > 1998 153  0  408.
> >      > 1998 154  0  441.
> >      > 1998 155  0  397.
> >      > 1998 156  0  374.
> >      > 1998 157  0  413.
> >      > 1998 158  0  582.
> >      > 1998 159  0  513.
> >      > 1998 160  0  459.
> >      > 1998 161  0  466.
> >      > 1998 162  0  414.
> >      > 1998 163  0  354.
> >      > 1998 164  0  341.
> >      > 1998 165  0  343.
> >      > 1998 166  0  369.
> >      > 1998 167  0  411.
> >      > 1998 168  0  355.
> >      > 1998 169  0  333.
> >      > 1998 170  0  443.
> >      > 1998 171  0  426.
> >      > 1998 172  0  419.
> >      > 1998 173  0  404.
> >      > 1998 174  0  387.
> >      > 1998 175  0  460.
> >      > 1998 176  0  447.
> >      > 1998 177  0  469.
> >      > 1998 178  0  447.
> >      > 1998 179  0  389.
> >      > 1998 180  0  375.
> >      > 1998 181  0  354.
> >      > 1998 182  0  316.
> >      > 1998 183  0  369.
> >      > 1998 184  0  410.
> >      > 1998 185  0  406.
> >      > 1998 186  0  477.
> >      > 1998 187  0  583.
> >      > 1998 188  0  458.
> >      > 1998 189  0  386.
> >      > 1998 190  0  342.
> >      > 1998 191  0  333.
> >      > 1998 192  0  369.
> >      > 1998 193  0  406.
> >      > 1998 194  0  375.
> >      > 1998 195  0  332.
> >      > 1998 196  0  310.
> >      > 1998 197  0  528.
> >      > 1998 198  0  530.
> >      > 1998 199  0  387.
> >      > 1998 200  0  385.
> >      > 1998 201  0  349.
> >      > 1998 202  0  409.
> >      > 1998 203  0  399.
> >      > 1998 204  0  619.
> >      > 1998 205  0  658.
> >      > 1998 206  0  581.
> >      > 1998 207  0  445.
> >      > 1998 208  0  370.
> >      > 1998 209  0  326.
> >      > 1998 210  0  334.
> >      > 1998 211  0  384.
> >      > 1998 212  0  423.
> >      > 1998 213  0  412.
> >      > 1998 214  0  404.
> >      > 1998 215  0  370.
> >      > 1998 216  0  384.
> >      > 1998 217  0  383.
> >      > 1998 218  0  378.
> >      > 1998 219  0  461.
> >      > 1998 220  0  460.
> >      > 1998 221  0  400.
> >      > 1998 222  0  447.
> >      > 1998 223  0  373.
> >      > 1998 224  0  379.
> >      > 1998 225  0  374.
> >      > 1998 226  0  374.
> >      > 1998 227  0  391.
> >      > 1998 228  0  348.
> >      > 1998 229  0  303.
> >      > 1998 230  0  279.
> >      > 1998 231  0  312.
> >      > 1998 232  0  331.
> >      > 1998 233  0  298.
> >      > 1998 234  0  341.
> >      > 1998 235  0  493.
> >      > 1998 236  0  436.
> >      > 1998 237  0  400.
> >      > 1998 238  0  633.
> >      > 1998 239  0  630.
> >      > 1998 240  0  583.
> >      > 1998 241  0  547.
> >      > 1998 242  0  550.
> >      > 1998 243  0  499.
> >      > 1998 244  0  444.
> >      > 1998 245  0  427.
> >      > 1998 246  0  401.
> >      >
> >      > On Sat, Jan 16, 2021 at 8:01 AM Rui Barradas
> >     <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
> >      > <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>>
> wrote:
> >      >
> >      >     Hello,
> >      >
> >      >     Thanks for the data, it makes things easier.
> >      >
> >      >     df1 <- read.table("Jibrin_data.txt", header = TRUE)
> >      >     #'data.frame':  168 obs. of  4 variables:
> >      >     # $ year: int  1998 1998 1998 1998 1998 1998 1998 1998 1998
> >     1998 ...
> >      >     # $ day : int  1 2 3 4 5 6 7 8 9 10 ...
> >      >     # $ Hr  : int  0 0 0 0 0 0 0 0 0 0 ...
> >      >     # $ SWS : num  344 346 356 332 302 329 395 359 471 392 ...
> >      >
> >      >     Here is a simple way of converting the year and day of year
> >     columns
> >      >     to a
> >      >     column of class "Date".
> >      >     Like others have said, there are also CRAN packages to handle
> >     date/time
> >      >     data, my favorite being package lubridate, but base R can do
> it.
> >      >
> >      >
> >      >     df1$date <- as.Date(paste(df1$year, df1$day),
> >      >                           format = "%Y %j",
> >      >                           origin = "1998-01-01")
> >      >
> >      >     head(df1)
> >      >     #  year day Hr SWS       date
> >      >     #1 1998   1  0 344 1998-01-01
> >      >     #2 1998   2  0 346 1998-01-02
> >      >     #3 1998   3  0 356 1998-01-03
> >      >     #4 1998   4  0 332 1998-01-04
> >      >     #5 1998   5  0 302 1998-01-05
> >      >     #6 1998   6  0 329 1998-01-06
> >      >
> >      >
> >      >     Hope this helps,
> >      >
> >      >     Rui Barradas
> >      >
> >      >
> >      >     ?s 06:48 de 16/01/21, Jibrin Alhassan escreveu:
> >      >      > Hi Barradas
> >      >      >   Sorry for the delay. Below is a section of my data. I
> >     have up
> >      >     to 1826
> >      >      > covering 1998 to 2002
> >      >      > year   day Hr SWS
> >      >      > 1998   1  0  344.
> >      >      > 1998   2  0  346.
> >      >      > 1998   3  0  356.
> >      >      > 1998   4  0  332.
> >      >      > 1998   5  0  302.
> >      >      > 1998   6  0  329.
> >      >      > 1998   7  0  395.
> >      >      > 1998   8  0  359.
> >      >      > 1998   9  0  471.
> >      >      > 1998  10  0  392.
> >      >      > 1998  11  0  346.
> >      >      > 1998  12  0  387.
> >      >      > 1998  13  0  393.
> >      >      > 1998  14  0  367.
> >      >      > 1998  15  0  320.
> >      >      > 1998  16  0  309.
> >      >      > 1998  17  0  341.
> >      >      > 1998  18  0  329.
> >      >      > 1998  19  0  322.
> >      >      > 1998  20  0  429.
> >      >      > 1998  21  0  433.
> >      >      > 1998  22  0  398.
> >      >      > 1998  23  0  393.
> >      >      > 1998  24  0  393.
> >      >      > 1998  25  0  423.
> >      >      > 1998  26  0  426.
> >      >      > 1998  27  0  429.
> >      >      > 1998  28  0  386.
> >      >      > 1998  29  0  381.
> >      >      > 1998  30  0  375.
> >      >      > 1998  31  0  365.
> >      >      > 1998  32  0  450.
> >      >      > 1998  33  0  381.
> >      >      > 1998  34  0  316.
> >      >      > 1998  35  0  351.
> >      >      > 1998  36  0  306.
> >      >      > 1998  37  0  312.
> >      >      > 1998  38  0  320.
> >      >      > 1998  39  0  339.
> >      >      > 1998  40  0  395.
> >      >      > 1998  41  0  429.
> >      >      > 1998  42  0  479.
> >      >      > 1998  43  0  495.
> >      >      > 1998  44  0  407.
> >      >      > 1998  45  0  358.
> >      >      > 1998  46  0  360.
> >      >      > 1998  47  0  382.
> >      >      > 1998  48  0  394.
> >      >      > 1998  49  0  393.
> >      >      > 1998  50  0  435.
> >      >      > 1998  51  0  408.
> >      >      > 1998  52  0  360.
> >      >      > 1998  53  0  372.
> >      >      > 1998  54  0  376.
> >      >      > 1998  55  0  379.
> >      >      > 1998  56  0  361.
> >      >      > 1998  57  0  333.
> >      >      > 1998  58  0  321.
> >      >      > 1998  59  0  344.
> >      >      > 1998  60  0  412.
> >      >      > 1998  61  0  428.
> >      >      > 1998  62  0  401.
> >      >      > 1998  63  0  369.
> >      >      > 1998  64  0  343.
> >      >      > 1998  65  0  330.
> >      >      > 1998  66  0  317.
> >      >      > 1998  67  0  296.
> >      >      > 1998  68  0  282.
> >      >      > 1998  69  0  404.
> >      >      > 1998  70  0  530.
> >      >      > 1998  71  0  525.
> >      >      > 1998  72  0  484.
> >      >      > 1998  73  0  430.
> >      >      > 1998  74  0  388.
> >      >      > 1998  75  0  347.
> >      >      > 1998  76  0  337.
> >      >      > 1998  77  0  342.
> >      >      > 1998  78  0  305.
> >      >      > 1998  79  0  329.
> >      >      > 1998  80  0  420.
> >      >      > 1998  81  0  564.
> >      >      > 1998  82  0  483.
> >      >      > 1998  83  0  385.
> >      >      > 1998  84  0  393.
> >      >      > 1998  85  0  437.
> >      >      > 1998  86  0  441.
> >      >      > 1998  87  0  434.
> >      >      > 1998  88  0  471.
> >      >      > 1998  89  0  429.
> >      >      > 1998  90  0  412.
> >      >      > 1998  91  0  370.
> >      >      > 1998  92  0  326.
> >      >      > 1998  93  0  357.
> >      >      > 1998  94  0  338.
> >      >      > 1998  95  0  380.
> >      >      > 1998  96  0  339.
> >      >      > 1998  97  0  312.
> >      >      > 1998  98  0  313.
> >      >      > 1998  99  0  327.
> >      >      > 1998 100  0  362.
> >      >      > 1998 101  0  358.
> >      >      > 1998 102  0  387.
> >      >      > 1998 103  0  397.
> >      >      > 1998 104  0  375.
> >      >      > 1998 105  0  350.
> >      >      > 1998 106  0  357.
> >      >      > 1998 107  0  472.
> >      >      > 1998 108  0  526.
> >      >      > 1998 109  0  396.
> >      >      > 1998 110  0  374.
> >      >      > 1998 111  0  376.
> >      >      > 1998 112  0  355.
> >      >      > 1998 113  0  343.
> >      >      > 1998 114  0  425.
> >      >      > 1998 115  0  426.
> >      >      > 1998 116  0  479.
> >      >      > 1998 117  0  469.
> >      >      > 1998 118  0  425.
> >      >      > 1998 119  0  344.
> >      >      > 1998 120  0  341.
> >      >      > 1998 121  0  426.
> >      >      > 1998 122  0  601.
> >      >      > 1998 123  0  476.
> >      >      > 1998 124  0  670.
> >      >      > 1998 125  0  585.
> >      >      > 1998 126  0  496.
> >      >      > 1998 127  0  479.
> >      >      > 1998 128  0  569.
> >      >      > 1998 129  0  531.
> >      >      > 1998 130  0  489.
> >      >      > 1998 131  0  484.
> >      >      > 1998 132  0  480.
> >      >      > 1998 133  0  393.
> >      >      > 1998 134  0  332.
> >      >      > 1998 135  0  327.
> >      >      > 1998 136  0  493.
> >      >      > 1998 137  0  493.
> >      >      > 1998 138  0  430.
> >      >      > 1998 139  0  396.
> >      >      > 1998 140  0  408.
> >      >      > 1998 141  0  416.
> >      >      > 1998 142  0  376.
> >      >      > 1998 143  0  375.
> >      >      > 1998 144  0  415.
> >      >      > 1998 145  0  407.
> >      >      > 1998 146  0  398.
> >      >      > 1998 147  0  352.
> >      >      > 1998 148  0  349.
> >      >      > 1998 149  0  517.
> >      >      > 1998 150  0  597.
> >      >      > 1998 151  0  480.
> >      >      > 1998 152  0  435.
> >      >      > 1998 153  0  408.
> >      >      > 1998 154  0  441.
> >      >      > 1998 155  0  397.
> >      >      > 1998 156  0  374.
> >      >      > 1998 157  0  413.
> >      >      > 1998 158  0  582.
> >      >      > 1998 159  0  513.
> >      >      > 1998 160  0  459.
> >      >      > 1998 161  0  466.
> >      >      > 1998 162  0  414.
> >      >      > 1998 163  0  354.
> >      >      > 1998 164  0  341.
> >      >      > 1998 165  0  343.
> >      >      > 1998 166  0  369.
> >      >      > 1998 167  0  411.
> >      >      > 1998 168  0  355.
> >      >      > Thanks
> >      >      > Jibrin
> >      >      >
> >      >      > On Fri, Jan 15, 2021 at 7:15 PM Rui Barradas
> >      >     <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
> >     <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>
> >      >      > <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
> >     <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>>> wrote:
> >      >      >
> >      >      >     Hello,
> >      >      >
> >      >      >     No dataset was attached. Like the posting guide says,
> >      >      >
> >      >      >     No binary attachments except for PS, PDF, and some
> >     image and
> >      >     archive
> >      >      >     formats (others are automatically stripped off because
> >     they
> >      >     can contain
> >      >      >     malicious software). Files in other formats and larger
> >     ones
> >      >     should
> >      >      >     rather be put on the web and have only their URLs
> posted.
> >      >     This way a
> >      >      >     reader has the option to download them or not.
> >      >      >
> >      >      >
> >      >      >     Can you post sample data? Please post the output of
> >      >     `dput(df)`. Or, if
> >      >      >     it is too big the output of `dput(head(df, 20))`.
> (`df` is
> >      >     the name of
> >      >      >     your dataset.)
> >      >      >
> >      >      >     Hope this helps,
> >      >      >
> >      >      >     Rui Barradas
> >      >      >
> >      >      >     ?s 11:30 de 15/01/21, Jibrin Alhassan escreveu:
> >      >      >      > Dear R users,
> >      >      >      > I am very new to R software. I have solar wind
> >     speed data
> >      >     needed
> >      >      >     for my
> >      >      >      > work. How do I convert day in the year to year,
> >     month, and
> >      >     day with R
> >      >      >      > software? I have used this code
> >      >      >      > as.Date(0, origin = "1998-01-01")
> >      >      >      > but it can only convert one day of the year at a
> time.
> >      >     Meanwhile,
> >      >      >     I have up
> >      >      >      > to the 1998-2002 data set. Attached is my data.
> >      >      >      > Kindly help, please.
> >      >      >      > Jibrin Alhassan
> >      >      >      > ______________________________________________
> >      >      >      > R-help at r-project.org <mailto:R-help at r-project.org>
> >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
> >      >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>
> >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>> mailing
> >     list
> >      >      >     -- To UNSUBSCRIBE and more, see
> >      >      >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      >      >      > PLEASE do read the posting guide
> >      >      > http://www.R-project.org/posting-guide.html
> >      >      >      > and provide commented, minimal, self-contained,
> >      >     reproducible code.
> >      >      >      >
> >      >      >
> >      >
> >
>

	[[alternative HTML version deleted]]


From jov@n|@ouz@5 @end|ng |rom gm@||@com  Wed Jan 20 15:46:04 2021
From: jov@n|@ouz@5 @end|ng |rom gm@||@com (Jovani T. de Souza)
Date: Wed, 20 Jan 2021 11:46:04 -0300
Subject: [R] Find the number of clusters using clusGAP function in R
Message-ID: <CADs2LWRATiiZ6pyFOfSUSuUAjnBJPNKY8iPUdxnmM4Y+1LtJZQ@mail.gmail.com>

Could you help me find the ideal number of clusters using the `clusGap
`function? There is a similar example in this link:
https://www.rdocumentation.org/packages/factoextra/versions/1.0.7/topics/fviz_nbclust

 But I would like to do it for my case. My code is below:

    library(cluster)

    df <- structure(
    list(Propertie = c(1,2,3,4,5,6,7,8), Latitude = c(-24.779225,
-24.789635, -24.763461, -24.794394,
-24.747102,-24.781307,-24.761081,-24.761084),
    Longitude = c(-49.934816, -49.922324, -49.911616, -49.906262,
-49.890796,-49.8875254,-49.8875254,-49.922244),
    waste = c(526, 350, 526, 469, 285, 433, 456,825)),class = "data.frame",
row.names = c(NA, -8L))

    df<-scale(df)

    hcluster = clusGap(df, FUN = hcut, K.max = 100, B = 50)
    Clustering k = 1,2,..., K.max (= 100): .. Error in sil.obj[, 1:3] :
incorrect number of dimensions


[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Remetente
notificado por
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
20/01/21
11:45:50

	[[alternative HTML version deleted]]


From jrkr|de@u @end|ng |rom gm@||@com  Wed Jan 20 15:50:02 2021
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Wed, 20 Jan 2021 09:50:02 -0500
Subject: [R] Find the number of clusters using clusGAP function in R
In-Reply-To: <CADs2LWRATiiZ6pyFOfSUSuUAjnBJPNKY8iPUdxnmM4Y+1LtJZQ@mail.gmail.com>
References: <CADs2LWRATiiZ6pyFOfSUSuUAjnBJPNKY8iPUdxnmM4Y+1LtJZQ@mail.gmail.com>
Message-ID: <CAKZQJMA=i0Jb-pSeLH1g6+xhfQWW=j=4ubhFYTXefZp=HE-G2A@mail.gmail.com>

Crossposted at
https://community.rstudio.com/t/find-the-number-of-clusters-using-clusgap-function-in-r/93586

There is nothing wrong with crossposting but one should mention it to help
avoid duplication of effort

On Wed, 20 Jan 2021 at 09:46, Jovani T. de Souza <jovanisouza5 at gmail.com>
wrote:

> Could you help me find the ideal number of clusters using the `clusGap
> `function? There is a similar example in this link:
>
> https://www.rdocumentation.org/packages/factoextra/versions/1.0.7/topics/fviz_nbclust
>
>  But I would like to do it for my case. My code is below:
>
>     library(cluster)
>
>     df <- structure(
>     list(Propertie = c(1,2,3,4,5,6,7,8), Latitude = c(-24.779225,
> -24.789635, -24.763461, -24.794394,
> -24.747102,-24.781307,-24.761081,-24.761084),
>     Longitude = c(-49.934816, -49.922324, -49.911616, -49.906262,
> -49.890796,-49.8875254,-49.8875254,-49.922244),
>     waste = c(526, 350, 526, 469, 285, 433, 456,825)),class = "data.frame",
> row.names = c(NA, -8L))
>
>     df<-scale(df)
>
>     hcluster = clusGap(df, FUN = hcut, K.max = 100, B = 50)
>     Clustering k = 1,2,..., K.max (= 100): .. Error in sil.obj[, 1:3] :
> incorrect number of dimensions
>
>
> [image: Mailtrack]
> <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> Remetente
> notificado por
> Mailtrack
> <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> 20/01/21
> 11:45:50
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From @jr|g@tt| @end|ng |rom gm@||@com  Wed Jan 20 16:41:16 2021
From: @jr|g@tt| @end|ng |rom gm@||@com (Steven Rigatti)
Date: Wed, 20 Jan 2021 10:41:16 -0500
Subject: [R] writing a function to work with dplyr::mutate()
In-Reply-To: <CAHqSRuT1tvJV2BZJPNGwSJ4-K6-L=aKP1EmSUuEp2Y6k1Ztfxg@mail.gmail.com>
References: <CAPq4BeNsu6=NNAUwsdqzSKtA3O=7Ji6R03HyQXHesMvgWUtxew@mail.gmail.com>
 <CAHqSRuT1tvJV2BZJPNGwSJ4-K6-L=aKP1EmSUuEp2Y6k1Ztfxg@mail.gmail.com>
Message-ID: <CAPq4BeNKRJKW9xFseoC599HBPLkYK-Um7-=QrXTdoPEJiOHu5g@mail.gmail.com>

This works perfectly. Ah, just needed a vector as output instead of a
1-column df.
Thank you!!!

On Tue, Jan 19, 2021 at 2:18 PM Bill Dunlap <williamwdunlap at gmail.com>
wrote:

> Your translate... function seems unnecessarily complicated and reusing the
> name 'var' for both the input and the data.frame containing the input makes
> it confusing to me.  The following replacement, f, uses your algorithm but
> I think gets the answer you want.
>
> f <-
> function(var, upper, lookup) {
>     names(lookup) <- c('old','new')
>     var_df <- data.frame(old = var)
>     lookup2 <- data.frame(old = c(1:upper),
>                           new = c(1:upper))
>     lookup3 <- rbind(lookup, lookup2)
>     res <- left_join(var_df, lookup3, by = 'old')
>     res$new # return a vector, not a data.frame or tibble.
> }
> E.g.,
> > data.frame(XXX=c(95,93,10,20), YYY=c(55,66,93,98)) %>% mutate( YYY_mm =
> f(YYY, 90, lup))
>   XXX YYY YYY_mm
> 1  95  55     55
> 2  93  66     66
> 3  10  93      3
> 4  20  98     NA
>
> You can modify this so that it names the output column based on the name
> of the input column (by returning a data.frame/tibble instead of a numeric
> vector):
>
> f1 <-
> function(var, upper, lookup,  new_varname =
> paste0(deparse1(substitute(var)), "_mm")) {
>     names(lookup) <- c('old',new_varname)
>     var_df <- data.frame(old = var)
>     lookup2 <- data.frame(old = c(1:upper),
>                           new = c(1:upper))
>     names(lookup2)[2] <- new_varname
>     lookup3 <- rbind(lookup, lookup2)
>     res <- left_join(var_df, lookup3, by = 'old')[2]
>     res
> }
> E.g.,
> > data.frame(XXX=c(95,93,10,20), YYY=c(55,66,93,98)) %>% mutate( f1(YYY,
> 90, lup))
>   XXX YYY YYY_mm
> 1  95  55     55
> 2  93  66     66
> 3  10  93      3
> 4  20  98     NA
>
> -Bill
>
> On Tue, Jan 19, 2021 at 10:24 AM Steven Rigatti <sjrigatti at gmail.com>
> wrote:
>
>> I am having some problems with what seems like a pretty simple issue. I
>> have some data where I want to convert numbers. Specifically, this is
>> cancer data and the size of tumors is encoded using millimeter
>> measurements. However, if the actual measurement is not available the
>> coding may imply a less specific range of sizes. For instance numbers 0-89
>> may indicate size in mm, but 90 indicates "greater than 90 mm" , 91
>> indicates "1 to 2 cm", etc. So, I want to translate 91 to 90, 92 to 15,
>> etc.
>>
>> I have many such tables so I would like to be able to write a function
>> which takes as input a threshold over which new values need to be looked
>> up, and the new lookup table, returning the new values.
>>
>> I successfully wrote the function:
>>
>> translate_seer_numeric <- function(var, upper, lookup) {
>>     names(lookup) <- c('old','new')
>>     names(var) <- 'old'
>>     var <- as.data.frame(var)
>>     lookup2 <- data.frame(old = c(1:upper),
>>                           new = c(1:upper))
>>     lookup3 <- rbind(lookup, lookup2)
>>  print(var)
>>     res <- left_join(var, lookup3, by = 'old') %>%
>>          select(new)
>>
>>     res
>>
>> }
>>
>> test1 <- data.frame(old = c(99,95,93, 8))lup <- data.frame(bif = c(93,
>> 95, 99),
>>                   new = c(3, 5, NA))
>> translate_seer_numeric(test1, 90, lup)
>>
>> The above test generates the desired output:
>>
>>   old1  992  953  934   8
>>   new1  NA2   53   34   8
>>
>> My problem comes when I try to put this in line with pipes and the mutate
>> function:
>>
>> test1 %>%
>>      mutate(varb = translate_seer_numeric(var = old, 90, lup))####
>>  Error: Problem with `mutate()` input `varb`.
>> x Join columns must be present in data.
>> x Problem with `old`.
>> i Input `varb` is `translate_seer_numeric(var = test1$old, 90, lup)`.
>>
>> Thoughts??
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From |mr@n@h|m@nto69 @end|ng |rom gm@||@com  Wed Jan 20 17:00:34 2021
From: |mr@n@h|m@nto69 @end|ng |rom gm@||@com (Imran Shimanto)
Date: Wed, 20 Jan 2021 08:00:34 -0800
Subject: [R] help post
Message-ID: <CAB6JLg5L=6y4+EY4VnwUSTcwxPF98c61fWvK23jzRn-t0tk84g@mail.gmail.com>

Dear Sir,
How can i find the save workplace what i was practiced on parrot os
terminal?
How can i save program on parrot terminal and how i can find the saved file
??
I am learning R from W3schools.com and i am enjoying that. After that how
can i learn advance R ?

	[[alternative HTML version deleted]]


From kr|@@|evdh @end|ng |rom gm@||@com  Wed Jan 20 17:08:33 2021
From: kr|@@|evdh @end|ng |rom gm@||@com (krissievdh)
Date: Wed, 20 Jan 2021 17:08:33 +0100
Subject: [R] Help with changing date format in R
Message-ID: <CAJTGnjkvdLrLM4QuFZCyMD0tV+4aQgZC1=udJe-ZSj3ia0xZYw@mail.gmail.com>

Hi,

I have a big database where one-third of the data is in a different date
format than the rest. I'll add an example table to show you.

| plot         | observer          | date            |
| 1             | K                      | 31012020  |
| 2             | K                      | 07022020  |
| 3             | B                      | 01282020  |
| 4             | B                      | 01292020  |
So I have two different date formats; the first is in d m y while the other
one is in m d y.

My question is how can I change all the date data into the same format?
Preferably in dd/mm/yy. (31-01-2020)
I know I could use:
d$date <- as.Date(d$date, format = "%d%m%Y")
d$date <- as.Date(d$date, format = "%m%d%Y")

but I can only do one and then it doesn't work. Is there a way i can use
the first line for the date of observer K and the other line for the date
of observer B?

Thanks

	[[alternative HTML version deleted]]


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Wed Jan 20 19:45:36 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Wed, 20 Jan 2021 18:45:36 +0000 (UTC)
Subject: [R] 
 Different results on running Wilcoxon Rank Sum test in R and SPSS
In-Reply-To: <96078961-067c-d301-8e3a-7f3cabee4c16@mcmaster.ca>
References: <1910812922.2261308.1610990817343.ref@mail.yahoo.com>
 <1910812922.2261308.1610990817343@mail.yahoo.com>
 <e9902222-0459-16a4-1d86-4411f93f6c7c@dewey.myzen.co.uk>
 <4804_1611053260_10JAlcrd019890_448702623.708494.1611053185609@mail.yahoo.com>
 <96078961-067c-d301-8e3a-7f3cabee4c16@mcmaster.ca>
Message-ID: <935783767.1030737.1611168336100@mail.yahoo.com>

 Dear Professor John,?
Thank you very much for your reply!?
I agree with you that the non-parametric tests I mentioned in my previous email (Moods median test and Median test) do not make sense in this situation as they treat PFD_n and drug_code as different groups. As you correctly said, I want to use PFD_n as a vector of scores and drug_code to make two groups out of it. This is exactly what the Independent samples median test does in SPSS. I wish to perform the same test in R and am unable to do so.
Simply put, I am asking how to perform the Independent samples median test in R just like it is performed in SPSS??

Secondly, for the question you are asking about the test statistic, I have not performed the Wilcoxon Rank sum test in SPSS for the PFD_n and drug_code data. I have said something to the contrary in my first email, I apologize for that.?
Thank you very much for your time!?
Yours sincerelyBharat Rawlley    On Wednesday, 20 January, 2021, 04:47:21 am IST, John Fox <jfox at mcmaster.ca> wrote:  
 
 Dear Bharat Rawlley,

What you tried to do appears to be nonsense. That is, you're treating 
PFD_n and drug_code as if they were scores for two different groups.

I assume that what you really want to do is to treat PFD_n as a vector 
of scores and drug_code as defining two groups. If that's correct, and 
with your data into Data, you can try the following:

------snip ------

 > wilcox.test(PFD_n ~ drug_code, data=Data, conf.int=TRUE)

??? Wilcoxon rank sum test with continuity correction

data:? PFD_n by drug_code
W = 197, p-value = 0.05563
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
? -2.000014e+00? 5.037654e-05
sample estimates:
difference in location
? ? ? ? ? ? ? -1.000019

Warning messages:
1: In wilcox.test.default(x = c(27, 26, 20, 24, 28, 28, 27, 27, 26,? :
? cannot compute exact p-value with ties
2: In wilcox.test.default(x = c(27, 26, 20, 24, 28, 28, 27, 27, 26,? :
? cannot compute exact confidence intervals with ties

------snip ------

You can get an approximate confidence interval by specifying exact=FALSE:

------snip ------

 > wilcox.test(PFD_n ~ drug_code, data=Data, conf.int=TRUE, exact=FALSE)

??? Wilcoxon rank sum test with continuity correction

data:? PFD_n by drug_code
W = 197, p-value = 0.05563
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
? -2.000014e+00? 5.037654e-05
sample estimates:
difference in location
? ? ? ? ? ? ? -1.000019

------snip ------

As it turns out, your data are highly discrete and have a lot of ties 
(see in particular PFD_n = 28):

------snip ------

 > xtabs(~ PFD_n + drug_code, data=Data)

? ? ? drug_code
PFD_n? 0? 1
? ? 0? 2? 0
? ? 16? 1? 1
? ? 18? 0? 1
? ? 19? 0? 1
? ? 20? 2? 0
? ? 22? 0? 1
? ? 24? 2? 0
? ? 25? 1? 2
? ? 26? 5? 2
? ? 27? 4? 2
? ? 28? 5 13
? ? 30? 1? 2

------snip ------

I'm no expert in nonparametric inference, but I doubt whether the 
approximate p-value will be very accurate for data like these.

I don't know why wilcox.test() (correctly used) and SPSS are giving you 
slightly different results -- assuming that you're actually doing the 
same thing in both cases. I couldn't help but notice that most of your 
data are missing. Are you getting the same value of the test statistic 
and different p-values, or is the test statistic different as well?

I hope this helps,
? John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-01-19 5:46 a.m., bharat rawlley via R-help wrote:
>? Thank you for the reply and suggestion, Michael!
> I used dput() and this is the output I can share with you. Simply explained, I have 3 columns namely, drug_code, freq4w_n and PFD_n. Each column has 132 values (including NA). The problem with the Wilcoxon Rank Sum test has been described in my first email.
> Please do let me know if you need any further clarification from my side! Thanks a lot for your time!
> structure(list(drug_code = c(0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,?1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,?0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,?1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,?0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,?1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,?1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0), freq4w_n = c(1,?NA, NA, 0, NA, 4, NA, 10, NA, 0, 6, NA, NA, NA, NA, NA, 10, NA,?0, NA, NA, NA, NA, 0, NA, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA,?NA, NA, NA, NA, NA, 0, 0, 12, 0, NA, 1, 2, 1, 2, 2, NA, 28, 0,?NA, 4, NA, 1, NA, NA, NA, NA, NA, 0, 3, 1, NA, NA, NA, NA, 4,?28, NA, NA, 0, 2, 12, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA, NA,?NA, NA, NA, NA, NA, 3, NA, NA, NA, NA, NA, NA, 6, 1, NA, NA,?NA, 0, NA, NA, NA, 0, 0, NA, 0, NA, 2, 8, 3, NA, NA, NA, 0, NA,?NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA), PFD_n = c(27, NA,?NA, 28, NA, 26, NA, 20, NA, 30, 24, NA, NA, NA, NA, NA, 18, NA,?28, NA, NA, NA, NA, 28, NA, 28, NA, NA, NA, 28, NA, 28, NA, NA,?NA, NA, NA, NA, NA, NA, 28, 28, 16, 28, NA, 27, 26, 27, 26, 26,?NA, 0, 30, NA, 24, NA, 27, NA, NA, NA, NA, NA, 28, 25, 27, NA,?NA, NA, NA, 26, 0, NA, NA, 28, 26, 16, 28, NA, NA, NA, 28, NA,?28, NA, NA, NA, NA, NA, NA, NA, NA, NA, 25, NA, NA, NA, NA, NA,?NA, 22, 27, NA, NA, NA, 28, NA, NA, NA, 28, 28, NA, 28, NA, 26,?20, 25, NA, NA, NA, 30, NA, NA, NA, 19, NA, NA, NA, NA, NA, NA,?NA, NA)), row.names = c(NA, -132L), class = c("tbl_df", "tbl",?"data.frame"))
> 
> Yours sincerely?Bharat Rawlley? ? On Tuesday, 19 January, 2021, 03:53:27 pm IST, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>? 
>? Unfortunately your data did not come through. Try using dput() and then
> pasting that into the body of your e-mail message.
> 
> On 18/01/2021 17:26, bharat rawlley via R-help wrote:
>> Hello,
>> On running the Wilcoxon Rank Sum test in R and SPSS, I am getting the following discrepancies which I am unable to explain.
>> Q1 In the attached data set, I was trying to compare freq4w_n in those with drug_code 0 vs 1. SPSS gives a P value 0.031 vs R gives a P value 0.001779.
>> The code I used in R is as follows -
>> wilcox.test(freq4w_n, drug_code, conf.int = T)
>>
>>
>> Q2 Similarly, in the same data set, when trying to compare PFD_n in those with drug_code 0 vs 1, SPSS gives a P value 0.038 vs R gives a P value?< 2.2e-16.
>> The code I used in R is as follows -
>> wilcox.test(PFD_n, drug_code, mu = 0, alternative = "two.sided", correct = TRUE, paired = FALSE, conf.int = TRUE)
>>
>>
>> I have tried searching on Google and watching some Youtube tutorials, I cannot find an answer, Any help will be really appreciated, Thank you!
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
  
	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Jan 20 19:47:40 2021
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 20 Jan 2021 13:47:40 -0500
Subject: [R] Help with changing date format in R
In-Reply-To: <CAJTGnjkvdLrLM4QuFZCyMD0tV+4aQgZC1=udJe-ZSj3ia0xZYw@mail.gmail.com>
References: <CAJTGnjkvdLrLM4QuFZCyMD0tV+4aQgZC1=udJe-ZSj3ia0xZYw@mail.gmail.com>
Message-ID: <CAM_vjunFR+gkp9riBOLMGWePKY2SN36fpTx++7XtnNY-OigkYw@mail.gmail.com>

Hi,

If the date format is determined by observer, you could for instance
use subset to divide it into two data frames, fix the dates and
recombine, or use ifelse to use the correct format based on observer.
This is a basic data manipulation task, and there are lots of ways
approach it.

Sarah

On Wed, Jan 20, 2021 at 1:32 PM krissievdh <krissievdh at gmail.com> wrote:
>
> Hi,
>
> I have a big database where one-third of the data is in a different date
> format than the rest. I'll add an example table to show you.
>
> | plot         | observer          | date            |
> | 1             | K                      | 31012020  |
> | 2             | K                      | 07022020  |
> | 3             | B                      | 01282020  |
> | 4             | B                      | 01292020  |
> So I have two different date formats; the first is in d m y while the other
> one is in m d y.
>
> My question is how can I change all the date data into the same format?
> Preferably in dd/mm/yy. (31-01-2020)
> I know I could use:
> d$date <- as.Date(d$date, format = "%d%m%Y")
> d$date <- as.Date(d$date, format = "%m%d%Y")
>
> but I can only do one and then it doesn't work. Is there a way i can use
> the first line for the date of observer K and the other line for the date
> of observer B?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan 20 19:49:07 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 20 Jan 2021 10:49:07 -0800
Subject: [R] Help with changing date format in R
In-Reply-To: <CAJTGnjkvdLrLM4QuFZCyMD0tV+4aQgZC1=udJe-ZSj3ia0xZYw@mail.gmail.com>
References: <CAJTGnjkvdLrLM4QuFZCyMD0tV+4aQgZC1=udJe-ZSj3ia0xZYw@mail.gmail.com>
Message-ID: <4D684E26-1375-4B18-A41B-6FD7AFA4ACF5@dcn.davis.ca.us>

Perhaps

d$date <- as.Date(d$date, format = ifelse("K"==d$observer, "%d%m%Y", "%m%d%Y"  ))

On January 20, 2021 8:08:33 AM PST, krissievdh <krissievdh at gmail.com> wrote:
>Hi,
>
>I have a big database where one-third of the data is in a different
>date
>format than the rest. I'll add an example table to show you.
>
>| plot         | observer          | date            |
>| 1             | K                      | 31012020  |
>| 2             | K                      | 07022020  |
>| 3             | B                      | 01282020  |
>| 4             | B                      | 01292020  |
>So I have two different date formats; the first is in d m y while the
>other
>one is in m d y.
>
>My question is how can I change all the date data into the same format?
>Preferably in dd/mm/yy. (31-01-2020)
>I know I could use:
>d$date <- as.Date(d$date, format = "%d%m%Y")
>d$date <- as.Date(d$date, format = "%m%d%Y")
>
>but I can only do one and then it doesn't work. Is there a way i can
>use
>the first line for the date of observer K and the other line for the
>date
>of observer B?
>
>Thanks
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@rc_@chw@rtz @end|ng |rom me@com  Wed Jan 20 20:01:52 2021
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 20 Jan 2021 14:01:52 -0500
Subject: [R] Help with changing date format in R
In-Reply-To: <CAJTGnjkvdLrLM4QuFZCyMD0tV+4aQgZC1=udJe-ZSj3ia0xZYw@mail.gmail.com>
References: <CAJTGnjkvdLrLM4QuFZCyMD0tV+4aQgZC1=udJe-ZSj3ia0xZYw@mail.gmail.com>
Message-ID: <39F4C245-2DA7-4E48-B70B-73E5E8B9BD79@me.com>

Hi,

Internally, once you have a Date class object in R, the "printed" output displayed will be the default, which I believe is influenced by your locale. See ?format.Date.

That being said, in your example data below, 07022020, could be either July 2, 2020, or February 7, 2020. How do you know which one is correct, since both are legal conversions?

Thus, you need some other flag value to determine which conversion is correct.

Can you use the observer values as a flag?

If so, then you can use a conditional statement (e.g. ?ifelse) to make the conversion.

For example:

  d$date <- ifelse(d$observer %in% c(vector, of, observers), 
                   as.Date(d$date, format = "%d%m%Y"),
                   as.Date(d$date, format = "%m%d%Y"))

Also, you might not want to overwrite the original values, and create a new column, in the case of errors.

Regards,

Marc Schwartz


> On Jan 20, 2021, at 11:08 AM, krissievdh <krissievdh at gmail.com> wrote:
> 
> Hi,
> 
> I have a big database where one-third of the data is in a different date
> format than the rest. I'll add an example table to show you.
> 
> | plot         | observer          | date            |
> | 1             | K                      | 31012020  |
> | 2             | K                      | 07022020  |
> | 3             | B                      | 01282020  |
> | 4             | B                      | 01292020  |
> So I have two different date formats; the first is in d m y while the other
> one is in m d y.
> 
> My question is how can I change all the date data into the same format?
> Preferably in dd/mm/yy. (31-01-2020)
> I know I could use:
> d$date <- as.Date(d$date, format = "%d%m%Y")
> d$date <- as.Date(d$date, format = "%m%d%Y")
> 
> but I can only do one and then it doesn't work. Is there a way i can use
> the first line for the date of observer K and the other line for the date
> of observer B?
> 
> Thanks


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jan 20 22:03:00 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 20 Jan 2021 13:03:00 -0800
Subject: [R] help post
In-Reply-To: <CAB6JLg5L=6y4+EY4VnwUSTcwxPF98c61fWvK23jzRn-t0tk84g@mail.gmail.com>
References: <CAB6JLg5L=6y4+EY4VnwUSTcwxPF98c61fWvK23jzRn-t0tk84g@mail.gmail.com>
Message-ID: <d1c59f13-3769-f1e5-aa7f-57f034fbc631@comcast.net>


On 1/20/21 8:00 AM, Imran Shimanto wrote:
> Dear Sir,
> How can i find the save workplace what i was practiced on parrot os
> terminal?
# execute at your console

?save.image


> How can i save program on parrot terminal and how i can find the saved file
> ??


You should contact the people who maintain that website.

> I am learning R from W3schools.com and i am enjoying that. After that how
> can i learn advance R ?
>
> 	[[alternative HTML version deleted]]

You should read the Posting Guide be fore any further posts to Rhalp.

-- 

David.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Thu Jan 21 00:10:39 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Wed, 20 Jan 2021 18:10:39 -0500
Subject: [R] 
 Different results on running Wilcoxon Rank Sum test in R and SPSS
In-Reply-To: <22722_1611168756_10KIqYij027846_935783767.1030737.1611168336100@mail.yahoo.com>
References: <1910812922.2261308.1610990817343.ref@mail.yahoo.com>
 <1910812922.2261308.1610990817343@mail.yahoo.com>
 <e9902222-0459-16a4-1d86-4411f93f6c7c@dewey.myzen.co.uk>
 <4804_1611053260_10JAlcrd019890_448702623.708494.1611053185609@mail.yahoo.com>
 <96078961-067c-d301-8e3a-7f3cabee4c16@mcmaster.ca>
 <22722_1611168756_10KIqYij027846_935783767.1030737.1611168336100@mail.yahoo.com>
Message-ID: <e00f1f66-5d4c-db73-8615-aa030ecb79d3@mcmaster.ca>

Dear Bharat Rawlley,

On 2021-01-20 1:45 p.m., bharat rawlley via R-help wrote:
>   Dear Professor John,
> Thank you very much for your reply!
> I agree with you that the non-parametric tests I mentioned in my previous email (Moods median test and Median test) do not make sense in this situation as they treat PFD_n and drug_code as different groups. As you correctly said, I want to use PFD_n as a vector of scores and drug_code to make two groups out of it. This is exactly what the Independent samples median test does in SPSS. I wish to perform the same test in R and am unable to do so.
> Simply put, I am asking how to perform the Independent samples median test in R just like it is performed in SPSS?

I'm afraid that I'm the wrong person to ask, since I haven't used SPSS 
in perhaps 30 years and have no idea what it does to test for 
differences in medians. A Google search for "independent samples median 
test in R" turns up a number of hits.

> 
> Secondly, for the question you are asking about the test statistic, I have not performed the Wilcoxon Rank sum test in SPSS for the PFD_n and drug_code data. I have said something to the contrary in my first email, I apologize for that.

For continuous data, the Wilcoxon test is, I believe, a reasonable 
choice, but not when there are so many ties. If SPSS doesn't perform a 
Wilcoxon test for a difference in medians, then there's of course no 
reason to expect that the p-values would be the same.

Best,
  John

> Thank you very much for your time!
> Yours sincerelyBharat Rawlley    On Wednesday, 20 January, 2021, 04:47:21 am IST, John Fox <jfox at mcmaster.ca> wrote:
>   
>   Dear Bharat Rawlley,
> 
> What you tried to do appears to be nonsense. That is, you're treating
> PFD_n and drug_code as if they were scores for two different groups.
> 
> I assume that what you really want to do is to treat PFD_n as a vector
> of scores and drug_code as defining two groups. If that's correct, and
> with your data into Data, you can try the following:
> 
> ------snip ------
> 
>   > wilcox.test(PFD_n ~ drug_code, data=Data, conf.int=TRUE)
> 
>  ??? Wilcoxon rank sum test with continuity correction
> 
> data:? PFD_n by drug_code
> W = 197, p-value = 0.05563
> alternative hypothesis: true location shift is not equal to 0
> 95 percent confidence interval:
>  ? -2.000014e+00? 5.037654e-05
> sample estimates:
> difference in location
>  ? ? ? ? ? ? ? -1.000019
> 
> Warning messages:
> 1: In wilcox.test.default(x = c(27, 26, 20, 24, 28, 28, 27, 27, 26,? :
>  ? cannot compute exact p-value with ties
> 2: In wilcox.test.default(x = c(27, 26, 20, 24, 28, 28, 27, 27, 26,? :
>  ? cannot compute exact confidence intervals with ties
> 
> ------snip ------
> 
> You can get an approximate confidence interval by specifying exact=FALSE:
> 
> ------snip ------
> 
>   > wilcox.test(PFD_n ~ drug_code, data=Data, conf.int=TRUE, exact=FALSE)
> 
>  ??? Wilcoxon rank sum test with continuity correction
> 
> data:? PFD_n by drug_code
> W = 197, p-value = 0.05563
> alternative hypothesis: true location shift is not equal to 0
> 95 percent confidence interval:
>  ? -2.000014e+00? 5.037654e-05
> sample estimates:
> difference in location
>  ? ? ? ? ? ? ? -1.000019
> 
> ------snip ------
> 
> As it turns out, your data are highly discrete and have a lot of ties
> (see in particular PFD_n = 28):
> 
> ------snip ------
> 
>   > xtabs(~ PFD_n + drug_code, data=Data)
> 
>  ? ? ? drug_code
> PFD_n? 0? 1
>  ? ? 0? 2? 0
>  ? ? 16? 1? 1
>  ? ? 18? 0? 1
>  ? ? 19? 0? 1
>  ? ? 20? 2? 0
>  ? ? 22? 0? 1
>  ? ? 24? 2? 0
>  ? ? 25? 1? 2
>  ? ? 26? 5? 2
>  ? ? 27? 4? 2
>  ? ? 28? 5 13
>  ? ? 30? 1? 2
> 
> ------snip ------
> 
> I'm no expert in nonparametric inference, but I doubt whether the
> approximate p-value will be very accurate for data like these.
> 
> I don't know why wilcox.test() (correctly used) and SPSS are giving you
> slightly different results -- assuming that you're actually doing the
> same thing in both cases. I couldn't help but notice that most of your
> data are missing. Are you getting the same value of the test statistic
> and different p-values, or is the test statistic different as well?
> 
> I hope this helps,
>  ? John
> 
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
> 
> On 2021-01-19 5:46 a.m., bharat rawlley via R-help wrote:
>>  ? Thank you for the reply and suggestion, Michael!
>> I used dput() and this is the output I can share with you. Simply explained, I have 3 columns namely, drug_code, freq4w_n and PFD_n. Each column has 132 values (including NA). The problem with the Wilcoxon Rank Sum test has been described in my first email.
>> Please do let me know if you need any further clarification from my side! Thanks a lot for your time!
>> structure(list(drug_code = c(0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,?1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,?0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,?1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,?0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,?1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,?1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0), freq4w_n = c(1,?NA, NA, 0, NA, 4, NA, 10, NA, 0, 6, NA, NA, NA, NA, NA, 10, NA,?0, NA, NA, NA, NA, 0, NA, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA,?NA, NA, NA, NA, NA, 0, 0, 12, 0, NA, 1, 2, 1, 2, 2, NA, 28, 0,?NA, 4, NA, 1, NA, NA, NA, NA, NA, 0, 3, 1, NA, NA, NA, NA, 4,?28, NA, NA, 0, 2, 12, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA, NA,?NA, NA, NA, NA, NA, 3, NA, NA, NA, NA, NA, NA, 6, 1, NA, NA,?NA, 0, NA, NA, NA, 0, 0, NA, 0, NA, 2, 8, 3, NA, NA, NA, 0, NA,?NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA), PFD_n = c(27, NA,?NA, 28, NA, 26, NA, 20, NA, 30, 24, NA, NA, NA, NA, NA, 18, NA,?28, NA, NA, NA, NA, 28, NA, 28, NA, NA, NA, 28, NA, 28, NA, NA,?NA, NA, NA, NA, NA, NA, 28, 28, 16, 28, NA, 27, 26, 27, 26, 26,?NA, 0, 30, NA, 24, NA, 27, NA, NA, NA, NA, NA, 28, 25, 27, NA,?NA, NA, NA, 26, 0, NA, NA, 28, 26, 16, 28, NA, NA, NA, 28, NA,?28, NA, NA, NA, NA, NA, NA, NA, NA, NA, 25, NA, NA, NA, NA, NA,?NA, 22, 27, NA, NA, NA, 28, NA, NA, NA, 28, 28, NA, 28, NA, 26,?20, 25, NA, NA, NA, 30, NA, NA, NA, 19, NA, NA, NA, NA, NA, NA,?NA, NA)), row.names = c(NA, -132L), class = c("tbl_df", "tbl",?"data.frame"))
>>
>> Yours sincerely?Bharat Rawlley? ? On Tuesday, 19 January, 2021, 03:53:27 pm IST, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>>    
>>  ? Unfortunately your data did not come through. Try using dput() and then
>> pasting that into the body of your e-mail message.
>>
>> On 18/01/2021 17:26, bharat rawlley via R-help wrote:
>>> Hello,
>>> On running the Wilcoxon Rank Sum test in R and SPSS, I am getting the following discrepancies which I am unable to explain.
>>> Q1 In the attached data set, I was trying to compare freq4w_n in those with drug_code 0 vs 1. SPSS gives a P value 0.031 vs R gives a P value 0.001779.
>>> The code I used in R is as follows -
>>> wilcox.test(freq4w_n, drug_code, conf.int = T)
>>>
>>>
>>> Q2 Similarly, in the same data set, when trying to compare PFD_n in those with drug_code 0 vs 1, SPSS gives a P value 0.038 vs R gives a P value?< 2.2e-16.
>>> The code I used in R is as follows -
>>> wilcox.test(PFD_n, drug_code, mu = 0, alternative = "two.sided", correct = TRUE, paired = FALSE, conf.int = TRUE)
>>>
>>>
>>> I have tried searching on Google and watching some Youtube tutorials, I cannot find an answer, Any help will be really appreciated, Thank you!
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>    
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jan 21 02:58:26 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 20 Jan 2021 17:58:26 -0800
Subject: [R] help post
In-Reply-To: <CAB6JLg5L=6y4+EY4VnwUSTcwxPF98c61fWvK23jzRn-t0tk84g@mail.gmail.com>
References: <CAB6JLg5L=6y4+EY4VnwUSTcwxPF98c61fWvK23jzRn-t0tk84g@mail.gmail.com>
Message-ID: <B43F926A-BE49-4A85-A5CE-1EF30629B3FE@dcn.davis.ca.us>

I think Parrot is a distribution of Linux, which would likely use the bash command shell.

The saved workspace would be in a file named ".RData" in whatever the current directory was when you quit R. Many experienced users of R avoid creating such files as mistakes from old sessions can come back to haunt you.

Most users of R use a plain text editor to edit R scripts. Saving R scripts from within R is not a typical use pattern. You can execute your R script from the R prompt using the source() function. Many people these days use RStudio to simplify this interaction.

It is encouraging to hear that you are enjoying your experience with w3schools.com. Do rely on their support for learning R, as there is a no homework policy on this mailing list. (Do read the Posting Guide mentioned below, which warns you that this list is plain text only and sending HTML can make your email very nearly unreadable in some cases.)

To learn advanced R, a very good book by that name written by Hadley Wickham exists also as a free website, so search for it. Note that most "advanced" users of R have expertise in science and/or statistics to support their calculation choices in R, so do try to augment your R education with other disciplines as well.

On January 20, 2021 8:00:34 AM PST, Imran Shimanto <imranshimanto69 at gmail.com> wrote:
>Dear Sir,
>How can i find the save workplace what i was practiced on parrot os
>terminal?
>How can i save program on parrot terminal and how i can find the saved
>file
>??
>I am learning R from W3schools.com and i am enjoying that. After that
>how
>can i learn advance R ?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Thu Jan 21 05:19:53 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Thu, 21 Jan 2021 04:19:53 +0000 (UTC)
Subject: [R] 
 Different results on running Wilcoxon Rank Sum test in R and SPSS
In-Reply-To: <e00f1f66-5d4c-db73-8615-aa030ecb79d3@mcmaster.ca>
References: <1910812922.2261308.1610990817343.ref@mail.yahoo.com>
 <1910812922.2261308.1610990817343@mail.yahoo.com>
 <e9902222-0459-16a4-1d86-4411f93f6c7c@dewey.myzen.co.uk>
 <4804_1611053260_10JAlcrd019890_448702623.708494.1611053185609@mail.yahoo.com>
 <96078961-067c-d301-8e3a-7f3cabee4c16@mcmaster.ca>
 <22722_1611168756_10KIqYij027846_935783767.1030737.1611168336100@mail.yahoo.com>
 <e00f1f66-5d4c-db73-8615-aa030ecb79d3@mcmaster.ca>
Message-ID: <145249930.921496.1611202793469@mail.yahoo.com>

Thank you for your time, Professor John! Much appreciated!?
Yours sincerely?Bharat Rawlley?



Sent from Yahoo Mail on Android 
 
  On Thu, 21 Jan 2021 at 4:40 AM, John Fox<jfox at mcmaster.ca> wrote:   Dear Bharat Rawlley,

On 2021-01-20 1:45 p.m., bharat rawlley via R-help wrote:
>? Dear Professor John,
> Thank you very much for your reply!
> I agree with you that the non-parametric tests I mentioned in my previous email (Moods median test and Median test) do not make sense in this situation as they treat PFD_n and drug_code as different groups. As you correctly said, I want to use PFD_n as a vector of scores and drug_code to make two groups out of it. This is exactly what the Independent samples median test does in SPSS. I wish to perform the same test in R and am unable to do so.
> Simply put, I am asking how to perform the Independent samples median test in R just like it is performed in SPSS?

I'm afraid that I'm the wrong person to ask, since I haven't used SPSS 
in perhaps 30 years and have no idea what it does to test for 
differences in medians. A Google search for "independent samples median 
test in R" turns up a number of hits.

> 
> Secondly, for the question you are asking about the test statistic, I have not performed the Wilcoxon Rank sum test in SPSS for the PFD_n and drug_code data. I have said something to the contrary in my first email, I apologize for that.

For continuous data, the Wilcoxon test is, I believe, a reasonable 
choice, but not when there are so many ties. If SPSS doesn't perform a 
Wilcoxon test for a difference in medians, then there's of course no 
reason to expect that the p-values would be the same.

Best,
? John

> Thank you very much for your time!
> Yours sincerelyBharat Rawlley? ? On Wednesday, 20 January, 2021, 04:47:21 am IST, John Fox <jfox at mcmaster.ca> wrote:
>? 
>? Dear Bharat Rawlley,
> 
> What you tried to do appears to be nonsense. That is, you're treating
> PFD_n and drug_code as if they were scores for two different groups.
> 
> I assume that what you really want to do is to treat PFD_n as a vector
> of scores and drug_code as defining two groups. If that's correct, and
> with your data into Data, you can try the following:
> 
> ------snip ------
> 
>? > wilcox.test(PFD_n ~ drug_code, data=Data, conf.int=TRUE)
> 
>? ??? Wilcoxon rank sum test with continuity correction
> 
> data:? PFD_n by drug_code
> W = 197, p-value = 0.05563
> alternative hypothesis: true location shift is not equal to 0
> 95 percent confidence interval:
>? ? -2.000014e+00? 5.037654e-05
> sample estimates:
> difference in location
>? ? ? ? ? ? ? ? -1.000019
> 
> Warning messages:
> 1: In wilcox.test.default(x = c(27, 26, 20, 24, 28, 28, 27, 27, 26,? :
>? ? cannot compute exact p-value with ties
> 2: In wilcox.test.default(x = c(27, 26, 20, 24, 28, 28, 27, 27, 26,? :
>? ? cannot compute exact confidence intervals with ties
> 
> ------snip ------
> 
> You can get an approximate confidence interval by specifying exact=FALSE:
> 
> ------snip ------
> 
>? > wilcox.test(PFD_n ~ drug_code, data=Data, conf.int=TRUE, exact=FALSE)
> 
>? ??? Wilcoxon rank sum test with continuity correction
> 
> data:? PFD_n by drug_code
> W = 197, p-value = 0.05563
> alternative hypothesis: true location shift is not equal to 0
> 95 percent confidence interval:
>? ? -2.000014e+00? 5.037654e-05
> sample estimates:
> difference in location
>? ? ? ? ? ? ? ? -1.000019
> 
> ------snip ------
> 
> As it turns out, your data are highly discrete and have a lot of ties
> (see in particular PFD_n = 28):
> 
> ------snip ------
> 
>? > xtabs(~ PFD_n + drug_code, data=Data)
> 
>? ? ? ? drug_code
> PFD_n? 0? 1
>? ? ? 0? 2? 0
>? ? ? 16? 1? 1
>? ? ? 18? 0? 1
>? ? ? 19? 0? 1
>? ? ? 20? 2? 0
>? ? ? 22? 0? 1
>? ? ? 24? 2? 0
>? ? ? 25? 1? 2
>? ? ? 26? 5? 2
>? ? ? 27? 4? 2
>? ? ? 28? 5 13
>? ? ? 30? 1? 2
> 
> ------snip ------
> 
> I'm no expert in nonparametric inference, but I doubt whether the
> approximate p-value will be very accurate for data like these.
> 
> I don't know why wilcox.test() (correctly used) and SPSS are giving you
> slightly different results -- assuming that you're actually doing the
> same thing in both cases. I couldn't help but notice that most of your
> data are missing. Are you getting the same value of the test statistic
> and different p-values, or is the test statistic different as well?
> 
> I hope this helps,
>? ? John
> 
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
> 
> On 2021-01-19 5:46 a.m., bharat rawlley via R-help wrote:
>>? ? Thank you for the reply and suggestion, Michael!
>> I used dput() and this is the output I can share with you. Simply explained, I have 3 columns namely, drug_code, freq4w_n and PFD_n. Each column has 132 values (including NA). The problem with the Wilcoxon Rank Sum test has been described in my first email.
>> Please do let me know if you need any further clarification from my side! Thanks a lot for your time!
>> structure(list(drug_code = c(0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,?1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,?0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,?1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,?0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,?1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,?1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0), freq4w_n = c(1,?NA, NA, 0, NA, 4, NA, 10, NA, 0, 6, NA, NA, NA, NA, NA, 10, NA,?0, NA, NA, NA, NA, 0, NA, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA,?NA, NA, NA, NA, NA, 0, 0, 12, 0, NA, 1, 2, 1, 2, 2, NA, 28, 0,?NA, 4, NA, 1, NA, NA, NA, NA, NA, 0, 3, 1, NA, NA, NA, NA, 4,?28, NA, NA, 0, 2, 12, 0, NA, NA, NA, 0, NA, 0, NA, NA, NA, NA,?NA, NA, NA, NA, NA, 3, NA, NA, NA, NA, NA, NA, 6, 1, NA, NA,?NA, 0, NA, NA, NA, 0, 0, NA, 0, NA, 2, 8, 3, NA, NA, NA, 0, NA,?NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA), PFD_n = c(27, NA,?NA, 28, NA, 26, NA, 20, NA, 30, 24, NA, NA, NA, NA, NA, 18, NA,?28, NA, NA, NA, NA, 28, NA, 28, NA, NA, NA, 28, NA, 28, NA, NA,?NA, NA, NA, NA, NA, NA, 28, 28, 16, 28, NA, 27, 26, 27, 26, 26,?NA, 0, 30, NA, 24, NA, 27, NA, NA, NA, NA, NA, 28, 25, 27, NA,?NA, NA, NA, 26, 0, NA, NA, 28, 26, 16, 28, NA, NA, NA, 28, NA,?28, NA, NA, NA, NA, NA, NA, NA, NA, NA, 25, NA, NA, NA, NA, NA,?NA, 22, 27, NA, NA, NA, 28, NA, NA, NA, 28, 28, NA, 28, NA, 26,?20, 25, NA, NA, NA, 30, NA, NA, NA, 19, NA, NA, NA, NA, NA, NA,?NA, NA)), row.names = c(NA, -132L), class = c("tbl_df", "tbl",?"data.frame"))
>>
>> Yours sincerely?Bharat Rawlley? ? On Tuesday, 19 January, 2021, 03:53:27 pm IST, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>>? ? 
>>? ? Unfortunately your data did not come through. Try using dput() and then
>> pasting that into the body of your e-mail message.
>>
>> On 18/01/2021 17:26, bharat rawlley via R-help wrote:
>>> Hello,
>>> On running the Wilcoxon Rank Sum test in R and SPSS, I am getting the following discrepancies which I am unable to explain.
>>> Q1 In the attached data set, I was trying to compare freq4w_n in those with drug_code 0 vs 1. SPSS gives a P value 0.031 vs R gives a P value 0.001779.
>>> The code I used in R is as follows -
>>> wilcox.test(freq4w_n, drug_code, conf.int = T)
>>>
>>>
>>> Q2 Similarly, in the same data set, when trying to compare PFD_n in those with drug_code 0 vs 1, SPSS gives a P value 0.038 vs R gives a P value?< 2.2e-16.
>>> The code I used in R is as follows -
>>> wilcox.test(PFD_n, drug_code, mu = 0, alternative = "two.sided", correct = TRUE, paired = FALSE, conf.int = TRUE)
>>>
>>>
>>> I have tried searching on Google and watching some Youtube tutorials, I cannot find an answer, Any help will be really appreciated, Thank you!
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>? ? 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/
  

	[[alternative HTML version deleted]]


From @d@m@dr@gu|@1998 @end|ng |rom gm@||@com  Wed Jan 20 22:45:45 2021
From: @d@m@dr@gu|@1998 @end|ng |rom gm@||@com (Adam Dragula)
Date: Wed, 20 Jan 2021 22:45:45 +0100
Subject: [R] Runs of at least 5 days with certain value in a rasterbrick in R
Message-ID: <CAPn=Di75dWx1HAK4g4V3P=jyhWJ=s9tQxPxyp5r1V9-Y8xzwCg@mail.gmail.com>

Dear R users,

I am  working with a rasterbrick named X, which has got 6300 time layers.
Those 6300 time layers represent every winter day since 1.1.1950 till
31.12. I dropped all 29th of february so that I had 90 time layers for
every season. Values throughout the whole domain are between 0.5 and 1.5. I
successfully made a function, which creates a rasterlayer, which contains
amount of runs of at least 5 days with values greater than 1.0. So for
every grid point, I have got amount of events I am looking for. The
function is following:

ff<-function(x,na.rm=TRUE){
y<-x > 1
n<- ave(y,cumsum(y == 0), FUN = cumsum)
sum(n >= 5)
}

This works very well, however, there is a problem. After layer which
represents 28.2., 1.12., 2.12. and so on.. follows. It means, that event
starting 28.2. may be detected if the criterion is satisfied throughout the
first four days of following december. Of course I dont wanna detect such
events as those are two distinct seasons. So I tried something like this
(to somehow divide it into 70 seasons and calculate function ff for them):

indices<-rep(1:70,each=90)
XX<-stackApply(X,indices,fun=ff)

At first sight, this works and no error is written. However, results are
miscounted and there is too much events detected, for example 20 events are
detected in the first layer at maximum, which doesnt make any sense
(20x5=100, there is just 90 days per season). Other fact is, that this
works perfectly fine, if I dont divide the whole series and use the
criterion through original brick X without any indices.
I cant see where the problem is, so every help is deeply appreciated, maybe
another way could be more efficient.

Adam Dragula



<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Bez
vir?. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Jan 21 10:57:23 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 21 Jan 2021 09:57:23 +0000
Subject: [R] 
 Runs of at least 5 days with certain value in a rasterbrick in R
In-Reply-To: <CAPn=Di75dWx1HAK4g4V3P=jyhWJ=s9tQxPxyp5r1V9-Y8xzwCg@mail.gmail.com>
References: <CAPn=Di75dWx1HAK4g4V3P=jyhWJ=s9tQxPxyp5r1V9-Y8xzwCg@mail.gmail.com>
Message-ID: <eb084e337e694cb5a8048ec1c25f0952@SRVEXCHCM1302.precheza.cz>

Hallo

I do not know anything about rasterbrick but what about splitting it to list according to season. If you have dates starting 1.12. and ending 28.2 as one season, diff should be 1day for each season. If you manage to correctly split your data, you can cycle through list or use lapply to get desired result.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Adam Dragula
> Sent: Wednesday, January 20, 2021 10:46 PM
> To: R-help at r-project.org
> Subject: [R] Runs of at least 5 days with certain value in a rasterbrick in R
> 
> Dear R users,
> 
> I am  working with a rasterbrick named X, which has got 6300 time layers.
> Those 6300 time layers represent every winter day since 1.1.1950 till 31.12. I
> dropped all 29th of february so that I had 90 time layers for every season.
> Values throughout the whole domain are between 0.5 and 1.5. I successfully
> made a function, which creates a rasterlayer, which contains amount of runs
> of at least 5 days with values greater than 1.0. So for every grid point, I have
> got amount of events I am looking for. The function is following:
> 
> ff<-function(x,na.rm=TRUE){
> y<-x > 1
> n<- ave(y,cumsum(y == 0), FUN = cumsum)
> sum(n >= 5)
> }
> 
> This works very well, however, there is a problem. After layer which
> represents 28.2., 1.12., 2.12. and so on.. follows. It means, that event starting
> 28.2. may be detected if the criterion is satisfied throughout the first four
> days of following december. Of course I dont wanna detect such events as
> those are two distinct seasons. So I tried something like this (to somehow
> divide it into 70 seasons and calculate function ff for them):
> 
> indices<-rep(1:70,each=90)
> XX<-stackApply(X,indices,fun=ff)
> 
> At first sight, this works and no error is written. However, results are
> miscounted and there is too much events detected, for example 20 events
> are detected in the first layer at maximum, which doesnt make any sense
> (20x5=100, there is just 90 days per season). Other fact is, that this works
> perfectly fine, if I dont divide the whole series and use the criterion through
> original brick X without any indices.
> I cant see where the problem is, so every help is deeply appreciated, maybe
> another way could be more efficient.
> 
> Adam Dragula
> 
> 
> 
> <https://www.avast.com/sig-
> email?utm_medium=email&utm_source=link&utm_campaign=sig-
> email&utm_content=webmail>
> Bez
> vir?. www.avast.com
> <https://www.avast.com/sig-
> email?utm_medium=email&utm_source=link&utm_campaign=sig-
> email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Thu Jan 21 11:42:55 2021
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Thu, 21 Jan 2021 11:42:55 +0100
Subject: [R] Problem on Converting "day of year" to "year",
 "month" and "day" has been solved
In-Reply-To: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
References: <CAEGeL+G-iwf386CUUb9Ao_11kk_5e1iCoeZNbvYx0YKC8Le0mg@mail.gmail.com>
Message-ID: <CAEGeL+E90bPYsE4JhNfEFyWnMoau2TSBSCr4jeGi_Vf_YRi1XQ@mail.gmail.com>

Dear R users,
> I want to thank you all for your contributions to the problem I posted. It
> has been solved. Find below the code that solved the problem.
>
df1 <- read.table("SWS1998_2002", header = TRUE)
df1$date <- as.Date(paste(df1$year, df1$day),
 format = "%Y %j",
origin = "1998-01-01")
df2 <- df1[c("date", "Dst")]
head(df2)
#To display all the rows
 print(df2
Thanks,
Jibrin Alhassan

	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Thu Jan 21 11:59:07 2021
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Thu, 21 Jan 2021 10:59:07 +0000
Subject: [R] [Rd] R 4.0.4 scheduled for February 15
Message-ID: <DE870AF7-6083-4D2F-8046-6C73E3D1D936@cbs.dk>

Full schedule is available on https://developer.r-project.org (or https://svn.r-project.org/R-dev-web/trunk/index.html for the impatient).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From |eroy @end|ng |rom |cmpe@cnr@@|r  Thu Jan 21 12:54:14 2021
From: |eroy @end|ng |rom |cmpe@cnr@@|r (Eric Leroy)
Date: Thu, 21 Jan 2021 12:54:14 +0100
Subject: [R] Plot histogram and lognormal fit on the same time
Message-ID: <b69fa66f-1701-1af1-4b0a-ac472e0200ff@icmpe.cnrs.fr>

Hi,

I would like to plot the histogram of data and fit it with a lognormal 
distribution.

The ideal, would be to superimpose the fit on the histogram and write 
the results of the fit on the figure.

Right now, I was able to plot the histogram and fit the density with a 
lognormal, but I can't combine all together.

Here is the code I wrote :

histdata <- hist(dataframe$data)

library(MASS)

fitdistr(histdata$density, "lognormal")

Can you help me ?

Best regards,

-- 

*Eric Leroy*

/Responsable de la plateforme microscopie ?lectronique/

/Correspondant S?curit? des Syst?mes Informatiques de l'ICMPE/

ICMPE - UMR 7182 - CNRS - UPEC

2/8, rue Henri Dunant

94320 Thiais

T?l : 01.49.78.12.09

Fax : 01.49.78.12.03

courriel : leroy at icmpe.cnrs.fr <mailto:leroy at icmpe.cnrs.fr>

Page Web : : http://www.icmpe.cnrs.fr <http://www.icmpe.cnrs.fr>


From m@rc_grt @end|ng |rom y@hoo@|r  Thu Jan 21 14:12:16 2021
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Thu, 21 Jan 2021 14:12:16 +0100
Subject: [R] Plot histogram and lognormal fit on the same time
In-Reply-To: <b69fa66f-1701-1af1-4b0a-ac472e0200ff@icmpe.cnrs.fr>
References: <b69fa66f-1701-1af1-4b0a-ac472e0200ff@icmpe.cnrs.fr>
Message-ID: <5a4ff6bb-29b9-efa9-45bd-7809d5707505@yahoo.fr>

Two solutions not exactly equivalent ;

data <- rlnorm(100, meanlog = 1, sdlog = 1)
histdata <- hist(data, ylim=c(0, 100))
library(MASS)

f <- fitdistr(data, "lognormal")

f$estimate

lines(x=seq(from=0, to=50, by=0.1),
 ? y=dlnorm(x=seq(from=0, to=50, by=0.1), meanlog = 
f$estimate["meanlog"], sdlog = f$estimate["sdlog"])*400
)

library(HelpersMG)

m <- modeled.hist(breaks=histdata$breaks, FUN=plnorm,
 ????????????????????????????? meanlog = f$estimate["meanlog"], sdlog = 
f$estimate["sdlog"], sum = 100)

points(m$x, m$y, pch=19, col="red")

Marc Girondot

Le 21/01/2021 ? 12:54, Eric Leroy a ?crit?:
> Hi,
>
> I would like to plot the histogram of data and fit it with a lognormal 
> distribution.
>
> The ideal, would be to superimpose the fit on the histogram and write 
> the results of the fit on the figure.
>
> Right now, I was able to plot the histogram and fit the density with a 
> lognormal, but I can't combine all together.
>
> Here is the code I wrote :
>
> histdata <- hist(dataframe$data)
>
> library(MASS)
>
> fitdistr(histdata$density, "lognormal")
>
> Can you help me ?
>
> Best regards,
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jan 21 17:13:44 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 21 Jan 2021 08:13:44 -0800
Subject: [R] Plot histogram and lognormal fit on the same time
In-Reply-To: <b69fa66f-1701-1af1-4b0a-ac472e0200ff@icmpe.cnrs.fr>
References: <b69fa66f-1701-1af1-4b0a-ac472e0200ff@icmpe.cnrs.fr>
Message-ID: <CAGxFJbQqaWX-crtqQL7oppe=Xyf+T-EC=+yf2k+tTW=8Frz3KA@mail.gmail.com>

In future, you should try to search before posting. I realize that getting
good search terms can sometimes be tricky, but not in this case: 'plot
density with histogram in R' or similar on rseek.org or just on your usual
search platform brought up several ways to do it.

As a (slightly offtopic) side issue, be careful with this: both histograms
and smooth density estimates are just that: density **estimates** that
depend on both the data and various parameters, e.g. the location of the
bins for histograms and kernel for kernel density estimates. You may
therefore get plots where the two do not appear to "match" when you use the
defaults for each.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 21, 2021 at 3:54 AM Eric Leroy <leroy at icmpe.cnrs.fr> wrote:

> Hi,
>
> I would like to plot the histogram of data and fit it with a lognormal
> distribution.
>
> The ideal, would be to superimpose the fit on the histogram and write
> the results of the fit on the figure.
>
> Right now, I was able to plot the histogram and fit the density with a
> lognormal, but I can't combine all together.
>
> Here is the code I wrote :
>
> histdata <- hist(dataframe$data)
>
> library(MASS)
>
> fitdistr(histdata$density, "lognormal")
>
> Can you help me ?
>
> Best regards,
>
> --
>
> *Eric Leroy*
>
> /Responsable de la plateforme microscopie ?lectronique/
>
> /Correspondant S?curit? des Syst?mes Informatiques de l'ICMPE/
>
> ICMPE - UMR 7182 - CNRS - UPEC
>
> 2/8, rue Henri Dunant
>
> 94320 Thiais
>
> T?l : 01.49.78.12.09
>
> Fax : 01.49.78.12.03
>
> courriel : leroy at icmpe.cnrs.fr <mailto:leroy at icmpe.cnrs.fr>
>
> Page Web : : http://www.icmpe.cnrs.fr <http://www.icmpe.cnrs.fr>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jan 21 18:16:58 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 21 Jan 2021 17:16:58 +0000
Subject: [R] Plot histogram and lognormal fit on the same time
In-Reply-To: <5a4ff6bb-29b9-efa9-45bd-7809d5707505@yahoo.fr>
References: <b69fa66f-1701-1af1-4b0a-ac472e0200ff@icmpe.cnrs.fr>
 <5a4ff6bb-29b9-efa9-45bd-7809d5707505@yahoo.fr>
Message-ID: <153f9384-1122-69e1-83dc-97b38d6bda1b@sapo.pt>

Hello,

A solution based on Marc's first one, maybe easier? (It doesn't rely on 
multiplying the dlnorm values by 400 since it plots the histogram with 
freq = FALSE.)


set.seed(2020)
data <- rlnorm(100, meanlog = 1, sdlog = 1)

library(MASS)

f <- fitdistr(data, "lognormal")
f$estimate

p <- pretty(range(data))
x <- seq(from = min(p), to = max(p), by = 0.1)

hist(data, freq = FALSE)
lines(x, y = dlnorm(x,
                     meanlog = f$estimate["meanlog"],
                     sdlog = f$estimate["sdlog"])
)


Hope this helps,

Rui Barradas


?s 13:12 de 21/01/21, Marc Girondot via R-help escreveu:
> Two solutions not exactly equivalent ;
> 
> data <- rlnorm(100, meanlog = 1, sdlog = 1)
> histdata <- hist(data, ylim=c(0, 100))
> library(MASS)
> 
> f <- fitdistr(data, "lognormal")
> 
> f$estimate
> 
> lines(x=seq(from=0, to=50, by=0.1),
>   ? y=dlnorm(x=seq(from=0, to=50, by=0.1), meanlog =
> f$estimate["meanlog"], sdlog = f$estimate["sdlog"])*400
> )
> 
> library(HelpersMG)
> 
> m <- modeled.hist(breaks=histdata$breaks, FUN=plnorm,
>   ????????????????????????????? meanlog = f$estimate["meanlog"], sdlog =
> f$estimate["sdlog"], sum = 100)
> 
> points(m$x, m$y, pch=19, col="red")
> 
> Marc Girondot
> 
> Le 21/01/2021 ? 12:54, Eric Leroy a ?crit?:
>> Hi,
>>
>> I would like to plot the histogram of data and fit it with a lognormal
>> distribution.
>>
>> The ideal, would be to superimpose the fit on the histogram and write
>> the results of the fit on the figure.
>>
>> Right now, I was able to plot the histogram and fit the density with a
>> lognormal, but I can't combine all together.
>>
>> Here is the code I wrote :
>>
>> histdata <- hist(dataframe$data)
>>
>> library(MASS)
>>
>> fitdistr(histdata$density, "lognormal")
>>
>> Can you help me ?
>>
>> Best regards,
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @@mue|| @end|ng |rom ||||no|@@edu  Wed Jan 20 18:18:00 2021
From: @@mue|| @end|ng |rom ||||no|@@edu (Bonfim Fernandes, Samuel)
Date: Wed, 20 Jan 2021 17:18:00 +0000
Subject: [R] [R-pkgs] simplePHENOTYPES v1.3.0
Message-ID: <4D51D79E-F197-4D31-A4B7-6396F1B2DD00@illinois.edu>

Hi All,

I hope this message finds you well.

We have released simplePHENOTYPES v1.3.0.  Our package simulates single and multiple (correlated) traits in a wide range of scenarios, including additive, dominance, and epistatic (AxA, AxAxA, ...) models.

Some of the new features include:
- The option to specify what markers will be used as QTNs
- Implemented the parameter "ld_max" and ?ld_min? for simulating spurious pleiotropy
- Implemented the option for simulating more than two-way epistatic interactions
- Included the parameter 'mean', so traits can be simulated with the desired mean (intercept) value.

Please check it our here:
https://cran.r-project.org/package=simplePHENOTYPES
Vignettes for the most common scenarios one would want to simulate may be found here:
https://cran.r-project.org/web/packages/simplePHENOTYPES/vignettes/simplePHENOTYPES.html

Best regards,
Samuel Fernandes


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From bgunter@4567 @end|ng |rom gm@||@com  Thu Jan 21 20:04:44 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 21 Jan 2021 11:04:44 -0800
Subject: [R] New Package: memify
Message-ID: <CAGxFJbSU2UWeRa_3pD1kp-0nD+aNS5aCMgAmUsXPuYrZZuqxHA@mail.gmail.com>

The new package, memify,  provides a simple way to construct and maintain
functions that keep state i.e. remember their argument lists. This can be
useful when one needs to repeatedly invoke the same function with only a
small number of argument changes at each invocation.

The package is tiny -- basically only a single function, memify() -- and
trivial to use. The examples in the help files should suffice to show how
it works, so if you think this functionality might be useful to you, just
download the package and try it out.

I welcome feedback, either positive or negative, as well as any suggestions
for changes or improvements. Please address any of these to me
**personally** and **not** to this list.

Cheers to all and stay well,

Bert Gunter

	[[alternative HTML version deleted]]


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Thu Jan 21 21:58:44 2021
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard McGarvey)
Date: Thu, 21 Jan 2021 15:58:44 -0500 (EST)
Subject: [R] Col names in a data frame
Message-ID: <1773683712.164705.1611262724834@connect.xfinity.com>

Here is an example piece of code to illustrate an issue:

rm(list=ls()) # Clear Workspace
#
Data1 <- matrix(data=rnorm(9,0,1),nrow=3,ncol=3)
Colnames1 <- c("(A)","(B)","(C)")
colnames(Data1) <- Colnames1
print(Data1)
DataFrame1 <- data.frame(Data1)
print(DataFrame1)
colnames(DataFrame1) <- Colnames1
print(DataFrame1)

The results I get are:

            (A)        (B)        (C)
[1,]  0.4739417  1.3138868  0.4262165
[2,] -2.1288083  1.0333770  1.1543404
[3,] -0.3401786 -0.7023236 -0.2336880
        X.A.       X.B.       X.C.
1  0.4739417  1.3138868  0.4262165
2 -2.1288083  1.0333770  1.1543404
3 -0.3401786 -0.7023236 -0.2336880
         (A)        (B)        (C)
1  0.4739417  1.3138868  0.4262165
2 -2.1288083  1.0333770  1.1543404
3 -0.3401786 -0.7023236 -0.2336880

so that when I make the matrix with headings the parentheses are replaced by periods but I can add them after creating the data frame and the column headings are correct. 

Any ideas on why this occurs?

Thanks


Bernard McGarvey
Director, Fort Myers Beach Lions Foundation, Inc.
Retired (Lilly Engineering Fellow).


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jan 21 22:14:01 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 21 Jan 2021 13:14:01 -0800
Subject: [R] Col names in a data frame
In-Reply-To: <1773683712.164705.1611262724834@connect.xfinity.com>
References: <1773683712.164705.1611262724834@connect.xfinity.com>
Message-ID: <52C2449D-0D95-4745-BD2F-2D85A25D0180@dcn.davis.ca.us>

rm(list=ls()) is a bad practice... especially when posting examples. It doesn't clean out everything and it removes objects created by the user.

Read ?data.frame, particularly regarding the check.names parameter. The intent is to make it easier to use DF$A notation, though DF$`(A)` is usable if you are somewhat experienced with R.

On January 21, 2021 12:58:44 PM PST, Bernard McGarvey <mcgarvey.bernard at comcast.net> wrote:
>Here is an example piece of code to illustrate an issue:
>
>rm(list=ls()) # Clear Workspace
>#
>Data1 <- matrix(data=rnorm(9,0,1),nrow=3,ncol=3)
>Colnames1 <- c("(A)","(B)","(C)")
>colnames(Data1) <- Colnames1
>print(Data1)
>DataFrame1 <- data.frame(Data1)
>print(DataFrame1)
>colnames(DataFrame1) <- Colnames1
>print(DataFrame1)
>
>The results I get are:
>
>            (A)        (B)        (C)
>[1,]  0.4739417  1.3138868  0.4262165
>[2,] -2.1288083  1.0333770  1.1543404
>[3,] -0.3401786 -0.7023236 -0.2336880
>        X.A.       X.B.       X.C.
>1  0.4739417  1.3138868  0.4262165
>2 -2.1288083  1.0333770  1.1543404
>3 -0.3401786 -0.7023236 -0.2336880
>         (A)        (B)        (C)
>1  0.4739417  1.3138868  0.4262165
>2 -2.1288083  1.0333770  1.1543404
>3 -0.3401786 -0.7023236 -0.2336880
>
>so that when I make the matrix with headings the parentheses are
>replaced by periods but I can add them after creating the data frame
>and the column headings are correct. 
>
>Any ideas on why this occurs?
>
>Thanks
>
>
>Bernard McGarvey
>Director, Fort Myers Beach Lions Foundation, Inc.
>Retired (Lilly Engineering Fellow).
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Jan 21 22:14:25 2021
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 21 Jan 2021 16:14:25 -0500
Subject: [R] Col names in a data frame
In-Reply-To: <1773683712.164705.1611262724834@connect.xfinity.com>
References: <1773683712.164705.1611262724834@connect.xfinity.com>
Message-ID: <CAM_vjumQmD2=HKrYYy5zChiLb4c-K+_mA0hBEuG5t_JwHanqRg@mail.gmail.com>

Hi,

data.frame() checks names by default to ensure that column names are
legal, but there's an argument to change that.

>From ?data.frame()


check.names: logical.  If ?TRUE? then the names of the variables in the
          data frame are checked to ensure that they are syntactically
          valid variable names and are not duplicated.  If necessary
          they are adjusted (by ?make.names?) so that they are.

Sarah

On Thu, Jan 21, 2021 at 3:59 PM Bernard McGarvey
<mcgarvey.bernard at comcast.net> wrote:
>
> Here is an example piece of code to illustrate an issue:
>
> rm(list=ls()) # Clear Workspace
> #
> Data1 <- matrix(data=rnorm(9,0,1),nrow=3,ncol=3)
> Colnames1 <- c("(A)","(B)","(C)")
> colnames(Data1) <- Colnames1
> print(Data1)
> DataFrame1 <- data.frame(Data1)
> print(DataFrame1)
> colnames(DataFrame1) <- Colnames1
> print(DataFrame1)
>
> The results I get are:
>
>             (A)        (B)        (C)
> [1,]  0.4739417  1.3138868  0.4262165
> [2,] -2.1288083  1.0333770  1.1543404
> [3,] -0.3401786 -0.7023236 -0.2336880
>         X.A.       X.B.       X.C.
> 1  0.4739417  1.3138868  0.4262165
> 2 -2.1288083  1.0333770  1.1543404
> 3 -0.3401786 -0.7023236 -0.2336880
>          (A)        (B)        (C)
> 1  0.4739417  1.3138868  0.4262165
> 2 -2.1288083  1.0333770  1.1543404
> 3 -0.3401786 -0.7023236 -0.2336880
>
> so that when I make the matrix with headings the parentheses are replaced by periods but I can add them after creating the data frame and the column headings are correct.
>
> Any ideas on why this occurs?
>
> Thanks
>
>
> Bernard McGarvey
> Director, Fort Myers Beach Lions Foundation, Inc.
> Retired (Lilly Engineering Fellow).
>

-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jan 21 22:14:33 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 21 Jan 2021 16:14:33 -0500
Subject: [R] Col names in a data frame
In-Reply-To: <1773683712.164705.1611262724834@connect.xfinity.com>
References: <1773683712.164705.1611262724834@connect.xfinity.com>
Message-ID: <cce96486-5f35-fdc2-8677-376bf3c9778d@gmail.com>

On 21/01/2021 3:58 p.m., Bernard McGarvey wrote:
> Here is an example piece of code to illustrate an issue:
> 
> rm(list=ls()) # Clear Workspace
> #
> Data1 <- matrix(data=rnorm(9,0,1),nrow=3,ncol=3)
> Colnames1 <- c("(A)","(B)","(C)")
> colnames(Data1) <- Colnames1
> print(Data1)
> DataFrame1 <- data.frame(Data1)
> print(DataFrame1)
> colnames(DataFrame1) <- Colnames1
> print(DataFrame1)
> 
> The results I get are:
> 
>              (A)        (B)        (C)
> [1,]  0.4739417  1.3138868  0.4262165
> [2,] -2.1288083  1.0333770  1.1543404
> [3,] -0.3401786 -0.7023236 -0.2336880
>          X.A.       X.B.       X.C.
> 1  0.4739417  1.3138868  0.4262165
> 2 -2.1288083  1.0333770  1.1543404
> 3 -0.3401786 -0.7023236 -0.2336880
>           (A)        (B)        (C)
> 1  0.4739417  1.3138868  0.4262165
> 2 -2.1288083  1.0333770  1.1543404
> 3 -0.3401786 -0.7023236 -0.2336880
> 
> so that when I make the matrix with headings the parentheses are replaced by periods but I can add them after creating the data frame and the column headings are correct.
> 
> Any ideas on why this occurs?

By default, data.frame() uses names that are legal variable names, so 
you can do things like Data1$X.A. You can stop this change by saying

DataFrame1 <- data.frame(Data1, check.names=FALSE)

Duncan Murdoch


From jttk|m @end|ng |rom goog|em@||@com  Thu Jan 21 22:44:38 2021
From: jttk|m @end|ng |rom goog|em@||@com (Jan T. Kim)
Date: Thu, 21 Jan 2021 21:44:38 +0000
Subject: [R] Col names in a data frame
In-Reply-To: <1773683712.164705.1611262724834@connect.xfinity.com>
References: <1773683712.164705.1611262724834@connect.xfinity.com>
Message-ID: <20210121214438.GV22962@titania>

it looks to me that the names are cranked through make.names for
data frames case while that doesn't happen for matrices. Peeking
into the `colnames<-` code supports this idea, but that in turn
uses `names<-` which is a primitive and so defies further easy
peeking.

The data.frame function provides the check.names parameter to
switch this on / off, but for other classes this checking doesn't
seem to be provided.

Perhaps the idea behind this discrepancy is to enable the use of
the $ operator to access columns of the data frame, while that's
not possible for matrices anyway. (Personally, I don't find the
results of make.names that useful, though, and I tend to sanitise
them myself when working with data frames with unwieldy column
names).

Best regards, Jan


On Thu, Jan 21, 2021 at 03:58:44PM -0500, Bernard McGarvey wrote:
> Here is an example piece of code to illustrate an issue:
> 
> rm(list=ls()) # Clear Workspace
> #
> Data1 <- matrix(data=rnorm(9,0,1),nrow=3,ncol=3)
> Colnames1 <- c("(A)","(B)","(C)")
> colnames(Data1) <- Colnames1
> print(Data1)
> DataFrame1 <- data.frame(Data1)
> print(DataFrame1)
> colnames(DataFrame1) <- Colnames1
> print(DataFrame1)
> 
> The results I get are:
> 
>             (A)        (B)        (C)
> [1,]  0.4739417  1.3138868  0.4262165
> [2,] -2.1288083  1.0333770  1.1543404
> [3,] -0.3401786 -0.7023236 -0.2336880
>         X.A.       X.B.       X.C.
> 1  0.4739417  1.3138868  0.4262165
> 2 -2.1288083  1.0333770  1.1543404
> 3 -0.3401786 -0.7023236 -0.2336880
>          (A)        (B)        (C)
> 1  0.4739417  1.3138868  0.4262165
> 2 -2.1288083  1.0333770  1.1543404
> 3 -0.3401786 -0.7023236 -0.2336880
> 
> so that when I make the matrix with headings the parentheses are replaced by periods but I can add them after creating the data frame and the column headings are correct. 
> 
> Any ideas on why this occurs?
> 
> Thanks
> 
> 
> Bernard McGarvey
> Director, Fort Myers Beach Lions Foundation, Inc.
> Retired (Lilly Engineering Fellow).
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Thu Jan 21 22:45:05 2021
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Thu, 21 Jan 2021 16:45:05 -0500
Subject: [R] Col names in a data frame
In-Reply-To: <cce96486-5f35-fdc2-8677-376bf3c9778d@gmail.com>
References: <cce96486-5f35-fdc2-8677-376bf3c9778d@gmail.com>
Message-ID: <9E2ED26D-5A02-4537-90BB-FDE19F6DACCA@comcast.net>

Thanks - I had seen that parameter but did not think the ( would be illegal but now I understand why it considers it illegal.

Thanks again

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Jan 21, 2021, at 4:14 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> ?On 21/01/2021 3:58 p.m., Bernard McGarvey wrote:
>> Here is an example piece of code to illustrate an issue:
>> rm(list=ls()) # Clear Workspace
>> #
>> Data1 <- matrix(data=rnorm(9,0,1),nrow=3,ncol=3)
>> Colnames1 <- c("(A)","(B)","(C)")
>> colnames(Data1) <- Colnames1
>> print(Data1)
>> DataFrame1 <- data.frame(Data1)
>> print(DataFrame1)
>> colnames(DataFrame1) <- Colnames1
>> print(DataFrame1)
>> The results I get are:
>>             (A)        (B)        (C)
>> [1,]  0.4739417  1.3138868  0.4262165
>> [2,] -2.1288083  1.0333770  1.1543404
>> [3,] -0.3401786 -0.7023236 -0.2336880
>>         X.A.       X.B.       X.C.
>> 1  0.4739417  1.3138868  0.4262165
>> 2 -2.1288083  1.0333770  1.1543404
>> 3 -0.3401786 -0.7023236 -0.2336880
>>          (A)        (B)        (C)
>> 1  0.4739417  1.3138868  0.4262165
>> 2 -2.1288083  1.0333770  1.1543404
>> 3 -0.3401786 -0.7023236 -0.2336880
>> so that when I make the matrix with headings the parentheses are replaced by periods but I can add them after creating the data frame and the column headings are correct.
>> Any ideas on why this occurs?
> 
> By default, data.frame() uses names that are legal variable names, so you can do things like Data1$X.A. You can stop this change by saying
> 
> DataFrame1 <- data.frame(Data1, check.names=FALSE)
> 
> Duncan Murdoch


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Thu Jan 21 22:45:20 2021
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Thu, 21 Jan 2021 16:45:20 -0500
Subject: [R] Col names in a data frame
Message-ID: <8C3830A5-F16D-4E5F-B012-C08450EB834D@comcast.net>

?Thanks - I had seen that parameter but did not think the ( would be illegal but now I understand why it considers it illegal.

Thanks again

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Jan 21, 2021, at 4:14 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> ?On 21/01/2021 3:58 p.m., Bernard McGarvey wrote:
>> Here is an example piece of code to illustrate an issue:
>> rm(list=ls()) # Clear Workspace
>> #
>> Data1 <- matrix(data=rnorm(9,0,1),nrow=3,ncol=3)
>> Colnames1 <- c("(A)","(B)","(C)")
>> colnames(Data1) <- Colnames1
>> print(Data1)
>> DataFrame1 <- data.frame(Data1)
>> print(DataFrame1)
>> colnames(DataFrame1) <- Colnames1
>> print(DataFrame1)
>> The results I get are:
>>            (A)        (B)        (C)
>> [1,]  0.4739417  1.3138868  0.4262165
>> [2,] -2.1288083  1.0333770  1.1543404
>> [3,] -0.3401786 -0.7023236 -0.2336880
>>        X.A.       X.B.       X.C.
>> 1  0.4739417  1.3138868  0.4262165
>> 2 -2.1288083  1.0333770  1.1543404
>> 3 -0.3401786 -0.7023236 -0.2336880
>>         (A)        (B)        (C)
>> 1  0.4739417  1.3138868  0.4262165
>> 2 -2.1288083  1.0333770  1.1543404
>> 3 -0.3401786 -0.7023236 -0.2336880
>> so that when I make the matrix with headings the parentheses are replaced by periods but I can add them after creating the data frame and the column headings are correct.
>> Any ideas on why this occurs?
> 
> By default, data.frame() uses names that are legal variable names, so you can do things like Data1$X.A. You can stop this change by saying
> 
> DataFrame1 <- data.frame(Data1, check.names=FALSE)
> 
> Duncan Murdoch


From pro|jcn@@h @end|ng |rom gm@||@com  Thu Jan 21 23:20:55 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Thu, 21 Jan 2021 17:20:55 -0500
Subject: [R] Why is rm(list=ls()) bad practice?
In-Reply-To: <52C2449D-0D95-4745-BD2F-2D85A25D0180@dcn.davis.ca.us>
References: <1773683712.164705.1611262724834@connect.xfinity.com>
 <52C2449D-0D95-4745-BD2F-2D85A25D0180@dcn.davis.ca.us>
Message-ID: <338857e8-f4f4-7d75-477c-80ec295af2e9@gmail.com>

In a separate thread Jeff Newmiller wrote:
> rm(list=ls()) is a bad practice... especially when posting examples. It doesn't clean out everything and it removes objects created by the user.

This query is to ask

1) Why is it bad practice to clear the workspace when presenting an example?
I'm assuming here that people who will try R-help examples will not run them in the
middle of something else, which I agree would be unfortunates. However, one of the
not very nice aspects of R is that it is VERY easy to have stuff hanging around (including
overloaded functions and operators) that get you into trouble, and indeed make it harder
to reproduce those important "minimal reproducible examples".  This includes the .RData
contents. (For information, I can understand the attraction, but I seem to have been
burned much more often than I've benefited from a pre-warmed oven.)

2) Is there a good command that really does leave a blank workspace? For testing
purposes, it would be useful to have an assured blank canvas.

This post is definitely not to start an argument, but to try to find ways to reduce
the possibilities for unanticipated outcomes in examples.

Cheers, JN


From m||uj|@b @end|ng |rom gm@||@com  Thu Jan 21 23:24:08 2021
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Thu, 21 Jan 2021 23:24:08 +0100
Subject: [R] rbind common header to file list
In-Reply-To: <CAGgJW76zb2JLNEF-3r-qJg93uj7TXSx1RH_GLw5_NZs4TPqJWw@mail.gmail.com>
References: <CAMLwc7OfUM_BztsCwqG7=arHK8J6TzD1dUpApD32o0iBnqy04Q@mail.gmail.com>
 <297d9757-73b9-4e1d-a238-9d1685206252@email.android.com>
 <CAMLwc7McBuhuPtszGY=KRA=qivs_bWphfpX6bkUBcy+jrsKWeA@mail.gmail.com>
 <CAGgJW76zb2JLNEF-3r-qJg93uj7TXSx1RH_GLw5_NZs4TPqJWw@mail.gmail.com>
Message-ID: <CAMLwc7O8thHDopXxhUkKtxLs+JjCwNRaqOwE7HCVZiJpF++4Aw@mail.gmail.com>

Thank you, that was it.

Best,

Milu

On Wed, Jan 20, 2021 at 1:33 PM Eric Berger <ericjberger at gmail.com> wrote:

> for ( file in filelist )
>
>
>
> On Wed, Jan 20, 2021 at 2:21 PM Miluji Sb <milujisb at gmail.com> wrote:
>
>> Thank you for your reply and the solution. Yes, I would like the date to
>> be
>> the column header for all the files in the list.
>>
>> This is what tried following your suggestion;
>>
>> filelist = list.files(pattern = ".*.txt")
>> date <- 20000101
>>
>> for (file %in% filelist){
>>   datalist <- read.table(file)
>>   write.table(datalist, file= file, col.names= date)
>>   }
>>
>> However, I get the following error
>>
>> Error: unexpected SPECIAL in "for (file %in%"
>>
>>
>> Is it something silly I am missing? Thank you again!
>>
>> Best,
>>
>> Milu
>>
>> On Wed, Jan 20, 2021 at 1:29 AM <cpolwart at chemo.org.uk> wrote:
>>
>> > I'd use a for loop. But I may be misunderstanding the q!
>> >
>> >
>> > filelist = list.files(pattern = ".*.txt")
>> > date <- 20000101
>> >
>> > for (file %in% filelist) {
>> >
>> > datalist <- read.table(file)
>> >
>> > write.table( datalist, file= file, col.names= date)
>> >
>> > }
>> >
>> > Does what I think you want.
>> > I would actually write to a new filename (sub folder?) To avoid
>> disaster!
>> >
>> >
>> >
>> >
>> >
>> > On 19 Jan 2021 23:45, Miluji Sb <milujisb at gmail.com> wrote:
>> >
>> > Dear all,
>> >
>> > I have more than 200 text files in a folder without header - example
>> > below.
>> > I would like to read, add a common date header to all the files, and
>> write
>> > (replace) the files.
>> >
>> > ## Read files
>> > filelist = list.files(pattern = ".*.txt")
>> > datalist = lapply(filelist, function(x)read.table(x, header=F))
>> >
>> > ## What I want to add
>> > date <- 20000101
>> > datalist _new <- lapply(datalist, function(x) rbind(x, date))
>> >
>> > How do I add this date as a common header and replace the files? Any
>> help
>> > will be highly appreciated. Thank you.
>> >
>> > Best,
>> >
>> > Milu
>> >
>> > ## Sample data
>> > xy <- dput(head(x,6))
>> > structure(list(V1 = c("-5.28082885742185,-0.509039307",
>> > "-6.09873046874998,-0.349584961",
>> > "-2.07150878906248,6.264276123", "-1.11102905273435,6.365716553",
>> > "2.37749633789065,14.57106934", "4.9619079589844,18.91350708"
>> > )), row.names = c(NA, 6L), class = "data.frame")
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jan 21 23:34:22 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 21 Jan 2021 14:34:22 -0800
Subject: [R] Why is rm(list=ls()) bad practice?
In-Reply-To: <338857e8-f4f4-7d75-477c-80ec295af2e9@gmail.com>
References: <1773683712.164705.1611262724834@connect.xfinity.com>
 <52C2449D-0D95-4745-BD2F-2D85A25D0180@dcn.davis.ca.us>
 <338857e8-f4f4-7d75-477c-80ec295af2e9@gmail.com>
Message-ID: <CAGxFJbRtByJFJsXSNWm9DNTq3ZASdy3a6OudzVdJ7NYmZr0Hag@mail.gmail.com>

Do you mean:
rm(list = ls(all = TRUE))
?
... or something else?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 21, 2021 at 2:21 PM J C Nash <profjcnash at gmail.com> wrote:

> In a separate thread Jeff Newmiller wrote:
> > rm(list=ls()) is a bad practice... especially when posting examples. It
> doesn't clean out everything and it removes objects created by the user.
>
> This query is to ask
>
> 1) Why is it bad practice to clear the workspace when presenting an
> example?
> I'm assuming here that people who will try R-help examples will not run
> them in the
> middle of something else, which I agree would be unfortunates. However,
> one of the
> not very nice aspects of R is that it is VERY easy to have stuff hanging
> around (including
> overloaded functions and operators) that get you into trouble, and indeed
> make it harder
> to reproduce those important "minimal reproducible examples".  This
> includes the .RData
> contents. (For information, I can understand the attraction, but I seem to
> have been
> burned much more often than I've benefited from a pre-warmed oven.)
>
> 2) Is there a good command that really does leave a blank workspace? For
> testing
> purposes, it would be useful to have an assured blank canvas.
>
> This post is definitely not to start an argument, but to try to find ways
> to reduce
> the possibilities for unanticipated outcomes in examples.
>
> Cheers, JN
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Jan 22 00:05:04 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 21 Jan 2021 18:05:04 -0500
Subject: [R] Why is rm(list=ls()) bad practice?
In-Reply-To: <338857e8-f4f4-7d75-477c-80ec295af2e9@gmail.com>
References: <1773683712.164705.1611262724834@connect.xfinity.com>
 <52C2449D-0D95-4745-BD2F-2D85A25D0180@dcn.davis.ca.us>
 <338857e8-f4f4-7d75-477c-80ec295af2e9@gmail.com>
Message-ID: <dc01448f-2de2-34cd-4215-ebb676f22fdb@gmail.com>

On 21/01/2021 5:20 p.m., J C Nash wrote:
> In a separate thread Jeff Newmiller wrote:
>> rm(list=ls()) is a bad practice... especially when posting examples. It doesn't clean out everything and it removes objects created by the user.
> 
> This query is to ask
> 
> 1) Why is it bad practice to clear the workspace when presenting an example?
> I'm assuming here that people who will try R-help examples will not run them in the
> middle of something else, which I agree would be unfortunates. 

I think that's exactly the concern.  I doubt it would have happened in 
this instance, but in other cases, people might copy and paste a 
complete example before reading it.  It's safer to say:  "Run this code 
in a clean workspace:", rather than cleaning it out yourself.

Duncan Murdoch


However, one of the
> not very nice aspects of R is that it is VERY easy to have stuff hanging around (including
> overloaded functions and operators) that get you into trouble, and indeed make it harder
> to reproduce those important "minimal reproducible examples".  This includes the .RData
> contents. (For information, I can understand the attraction, but I seem to have been
> burned much more often than I've benefited from a pre-warmed oven.)
> 
> 2) Is there a good command that really does leave a blank workspace? For testing
> purposes, it would be useful to have an assured blank canvas.

Yes, start R with

   R --vanilla

Duncan Murdoch

> 
> This post is definitely not to start an argument, but to try to find ways to reduce
> the possibilities for unanticipated outcomes in examples.
> 
> Cheers, JN
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gpd@be+r @end|ng |rom m@||box@org  Fri Jan 22 07:49:17 2021
From: gpd@be+r @end|ng |rom m@||box@org (Georgios)
Date: Fri, 22 Jan 2021 08:49:17 +0200
Subject: [R] rmarkdown and source call to R file.
Message-ID: <6d335981e3edce1e9e596a73bcab6d715084d0d4.camel@mailbox.org>

Hi!
I'm new in R and this list.
I made a shiny app using R studio.
my files are:
   -server.R
   -ui.R
   -helper.R
   -Report.Rmd.

All the files are on the same directory and helper.R is a file that
contains a lot of functions used in Report.Rmd and server.R

for some reason I cant call from Report.Rmd the file helper.R

My code in Report.Rmd is

   ## Summarize table
   ```{r, echo=FALSE}
   library(knitr)
   source("helper.R", local = knitr::knit_global())
   summarized_table<-give_table(params$ldf_summary)
   kable(summarized_table,"simple")
   ```
If I use absolute path it works but since I want to upload it to 
https://www.shinyapps.io/ I must make it work with relative path.

The message I get is:

   processing file: Report.Rmd
    
   |..........................                                         
                                        |  25%
     ordinary text without R code

    
   |....................................................               
                                        |  50%
   label: unnamed-chunk-1 (with options) 
   List of 1
    $ echo: logi FALSE

   Quitting from lines 13-17 (Report.Rmd) 

   Warning: Error in file: cannot open the connection
     [No stack trace available]


The funny thing is that if I put the cursor inside "" at the beginning
and I press tab I get the option to choose helper.R. So Im guessing
that I'm on the right directory.
Any ideas what I'm missing?

I'm stuck on this lines of code 2 days now.
I would really appreciate
any ideas.


Thanks in advance for your help!!!


ps. I tried all the combinations in Tools->Global Options-> "Evaluate
chunks in directory" with no luck.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jan 22 08:57:29 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 21 Jan 2021 23:57:29 -0800
Subject: [R] rmarkdown and source call to R file.
In-Reply-To: <6d335981e3edce1e9e596a73bcab6d715084d0d4.camel@mailbox.org>
References: <6d335981e3edce1e9e596a73bcab6d715084d0d4.camel@mailbox.org>
Message-ID: <C33DBFC2-740E-4B8B-ADFE-D789BBCFB657@dcn.davis.ca.us>

This is off topic here... please read the Posting Guide about getting help on contributed packages.  Check out the RStudio forums.

FWIW you should also look carefully at ?knitr::knit_global ... I don't think it does what you seem to think it does.

On January 21, 2021 10:49:17 PM PST, Georgios via R-help <r-help at r-project.org> wrote:
>Hi!
>I'm new in R and this list.
>I made a shiny app using R studio.
>my files are:
>   -server.R
>   -ui.R
>   -helper.R
>   -Report.Rmd.
>
>All the files are on the same directory and helper.R is a file that
>contains a lot of functions used in Report.Rmd and server.R
>
>for some reason I cant call from Report.Rmd the file helper.R
>
>My code in Report.Rmd is
>
>   ## Summarize table
>   ```{r, echo=FALSE}
>   library(knitr)
>   source("helper.R", local = knitr::knit_global())
>   summarized_table<-give_table(params$ldf_summary)
>   kable(summarized_table,"simple")
>   ```
>If I use absolute path it works but since I want to upload it to 
>https://www.shinyapps.io/ I must make it work with relative path.
>
>The message I get is:
>
>   processing file: Report.Rmd
>    
>   |..........................                                         
>                                        |  25%
>     ordinary text without R code
>
>    
>   |....................................................               
>                                        |  50%
>   label: unnamed-chunk-1 (with options) 
>   List of 1
>    $ echo: logi FALSE
>
>   Quitting from lines 13-17 (Report.Rmd) 
>
>   Warning: Error in file: cannot open the connection
>     [No stack trace available]
>
>
>The funny thing is that if I put the cursor inside "" at the beginning
>and I press tab I get the option to choose helper.R. So Im guessing
>that I'm on the right directory.
>Any ideas what I'm missing?
>
>I'm stuck on this lines of code 2 days now.
>I would really appreciate
>any ideas.
>
>
>Thanks in advance for your help!!!
>
>
>ps. I tried all the combinations in Tools->Global Options-> "Evaluate
>chunks in directory" with no luck.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jrkr|de@u @end|ng |rom gm@||@com  Fri Jan 22 16:05:38 2021
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Fri, 22 Jan 2021 10:05:38 -0500
Subject: [R] rmarkdown and source call to R file.
In-Reply-To: <6d335981e3edce1e9e596a73bcab6d715084d0d4.camel@mailbox.org>
References: <6d335981e3edce1e9e596a73bcab6d715084d0d4.camel@mailbox.org>
Message-ID: <CAKZQJMAgDiv4uEpLRXG18PbNH_Z3e=oAYSGdWFEgEgPeRPrjbQ@mail.gmail.com>

You would be better to try https://community.rstudio.com. Shiny is
basically Tidyverse/Rstudio item and there will be a lot more expertise
there.

On Fri, 22 Jan 2021 at 02:02, Georgios via R-help <r-help at r-project.org>
wrote:

> Hi!
> I'm new in R and this list.
> I made a shiny app using R studio.
> my files are:
>    -server.R
>    -ui.R
>    -helper.R
>    -Report.Rmd.
>
> All the files are on the same directory and helper.R is a file that
> contains a lot of functions used in Report.Rmd and server.R
>
> for some reason I cant call from Report.Rmd the file helper.R
>
> My code in Report.Rmd is
>
>    ## Summarize table
>    ```{r, echo=FALSE}
>    library(knitr)
>    source("helper.R", local = knitr::knit_global())
>    summarized_table<-give_table(params$ldf_summary)
>    kable(summarized_table,"simple")
>    ```
> If I use absolute path it works but since I want to upload it to
> https://www.shinyapps.io/ I must make it work with relative path.
>
> The message I get is:
>
>    processing file: Report.Rmd
>
>    |..........................
>                                         |  25%
>      ordinary text without R code
>
>
>    |....................................................
>                                         |  50%
>    label: unnamed-chunk-1 (with options)
>    List of 1
>     $ echo: logi FALSE
>
>    Quitting from lines 13-17 (Report.Rmd)
>
>    Warning: Error in file: cannot open the connection
>      [No stack trace available]
>
>
> The funny thing is that if I put the cursor inside "" at the beginning
> and I press tab I get the option to choose helper.R. So Im guessing
> that I'm on the right directory.
> Any ideas what I'm missing?
>
> I'm stuck on this lines of code 2 days now.
> I would really appreciate
> any ideas.
>
>
> Thanks in advance for your help!!!
>
>
> ps. I tried all the combinations in Tools->Global Options-> "Evaluate
> chunks in directory" with no luck.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From x|e @end|ng |rom y|hu|@n@me  Fri Jan 22 16:17:53 2021
From: x|e @end|ng |rom y|hu|@n@me (Yihui Xie)
Date: Fri, 22 Jan 2021 09:17:53 -0600
Subject: [R] rmarkdown and source call to R file.
In-Reply-To: <6d335981e3edce1e9e596a73bcab6d715084d0d4.camel@mailbox.org>
References: <6d335981e3edce1e9e596a73bcab6d715084d0d4.camel@mailbox.org>
Message-ID: <CANROs4dVctmcfLKKOEMRzce-tMamvJePB5L-OK=Ymm_4DM+=xg@mail.gmail.com>

I don't know the answer (there are multiple possible reasons for the
file not being found), but as the first step to debug the problem, you
may replace this chunk

```{r, echo=FALSE}
   library(knitr)
   source("helper.R", local = knitr::knit_global())
   summarized_table<-give_table(params$ldf_summary)
   kable(summarized_table,"simple")
```

with

```{r}
getwd()
list.files()
```

and see what the working directory is, and which files are available.

Regards,
Yihui


On Fri, Jan 22, 2021 at 1:02 AM Georgios via R-help
<r-help at r-project.org> wrote:
>
> Hi!
> I'm new in R and this list.
> I made a shiny app using R studio.
> my files are:
>    -server.R
>    -ui.R
>    -helper.R
>    -Report.Rmd.
>
> All the files are on the same directory and helper.R is a file that
> contains a lot of functions used in Report.Rmd and server.R
>
> for some reason I cant call from Report.Rmd the file helper.R
>
> My code in Report.Rmd is
>
>    ## Summarize table
>    ```{r, echo=FALSE}
>    library(knitr)
>    source("helper.R", local = knitr::knit_global())
>    summarized_table<-give_table(params$ldf_summary)
>    kable(summarized_table,"simple")
>    ```
> If I use absolute path it works but since I want to upload it to
> https://www.shinyapps.io/ I must make it work with relative path.
>
> The message I get is:
>
>    processing file: Report.Rmd
>
>    |..........................
>                                         |  25%
>      ordinary text without R code
>
>
>    |....................................................
>                                         |  50%
>    label: unnamed-chunk-1 (with options)
>    List of 1
>     $ echo: logi FALSE
>
>    Quitting from lines 13-17 (Report.Rmd)
>
>    Warning: Error in file: cannot open the connection
>      [No stack trace available]
>
>
> The funny thing is that if I put the cursor inside "" at the beginning
> and I press tab I get the option to choose helper.R. So Im guessing
> that I'm on the right directory.
> Any ideas what I'm missing?
>
> I'm stuck on this lines of code 2 days now.
> I would really appreciate
> any ideas.
>
>
> Thanks in advance for your help!!!
>
>
> ps. I tried all the combinations in Tools->Global Options-> "Evaluate
> chunks in directory" with no luck.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pro|jcn@@h @end|ng |rom gm@||@com  Fri Jan 22 16:37:37 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Fri, 22 Jan 2021 10:37:37 -0500
Subject: [R] Why is rm(list=ls()) bad practice?
In-Reply-To: <dc01448f-2de2-34cd-4215-ebb676f22fdb@gmail.com>
References: <1773683712.164705.1611262724834@connect.xfinity.com>
 <52C2449D-0D95-4745-BD2F-2D85A25D0180@dcn.davis.ca.us>
 <338857e8-f4f4-7d75-477c-80ec295af2e9@gmail.com>
 <dc01448f-2de2-34cd-4215-ebb676f22fdb@gmail.com>
Message-ID: <febd5295-3c69-4967-98a5-fa76dfc46ddf@gmail.com>

Thanks Duncan for a clear argument about the "why".

The suggestion of R --vanilla started a train of thought that one could do something like

 clearws <- function(){ # Try to clear workspace
   tmp <- readline("Are you sure you want to clear the workspace? ")
   print(tmp)
   if ( substr(toupper(tmp),1,1) != "Y" ){
       return(0)
   }
   #  rm(tmp)
   tgt<-parent.env(environment())
   print(ls(tgt))
   rm(list = ls(tgt, all.names = TRUE),envir=tgt) #will clear all objects includes hidden objects.
   gc() #free up memrory and report the memory usage.
   # What should we return?
   # Can we offer interactive control?
   # How about packages?
 }

and call clearws() at the start of an example.

Contact me off-list if you have suggestions for improving this. I'd like to be able to preface
examples with such a function that would render the session "vanilla" but from inside. That means
removing packages that might have altered / replaced / masked standard functions. That might not
be possible, but the idea is attractive to me as someone who mostly uses R in tests of tools that
get used by others.

Best, JN


On 2021-01-21 6:05 p.m., Duncan Murdoch wrote:
> On 21/01/2021 5:20 p.m., J C Nash wrote:
>> In a separate thread Jeff Newmiller wrote:
>>> rm(list=ls()) is a bad practice... especially when posting examples. It doesn't clean out everything and it removes
>>> objects created by the user.
>>
>> This query is to ask
>>
>> 1) Why is it bad practice to clear the workspace when presenting an example?
>> I'm assuming here that people who will try R-help examples will not run them in the
>> middle of something else, which I agree would be unfortunates. 
> 
> I think that's exactly the concern.? I doubt it would have happened in this instance, but in other cases, people might
> copy and paste a complete example before reading it.? It's safer to say:? "Run this code in a clean workspace:", rather
> than cleaning it out yourself.
> 
> Duncan Murdoch
> 
> 
> However, one of the
>> not very nice aspects of R is that it is VERY easy to have stuff hanging around (including
>> overloaded functions and operators) that get you into trouble, and indeed make it harder
>> to reproduce those important "minimal reproducible examples".? This includes the .RData
>> contents. (For information, I can understand the attraction, but I seem to have been
>> burned much more often than I've benefited from a pre-warmed oven.)
>>
>> 2) Is there a good command that really does leave a blank workspace? For testing
>> purposes, it would be useful to have an assured blank canvas.
> 
> Yes, start R with
> 
> ? R --vanilla
> 
> Duncan Murdoch
> 
>>
>> This post is definitely not to start an argument, but to try to find ways to reduce
>> the possibilities for unanticipated outcomes in examples.
>>
>> Cheers, JN
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Jan 22 16:50:37 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 22 Jan 2021 10:50:37 -0500
Subject: [R] Why is rm(list=ls()) bad practice?
In-Reply-To: <febd5295-3c69-4967-98a5-fa76dfc46ddf@gmail.com>
References: <1773683712.164705.1611262724834@connect.xfinity.com>
 <52C2449D-0D95-4745-BD2F-2D85A25D0180@dcn.davis.ca.us>
 <338857e8-f4f4-7d75-477c-80ec295af2e9@gmail.com>
 <dc01448f-2de2-34cd-4215-ebb676f22fdb@gmail.com>
 <febd5295-3c69-4967-98a5-fa76dfc46ddf@gmail.com>
Message-ID: <4d6d2019-6e31-bcd9-08ca-fba2e776c16f@gmail.com>

I think it's always difficult and sometimes impossible to take an 
existing session and convert it to the vanilla state, but it's very easy 
to run a new instance of R from an existing one.

So instead of a clearws() function, I'd suggest a "runInVanilla" 
function, that takes some code as input, starts up a vanilla session and 
collects the output.

This is quite similar to what reprex::reprex does, maybe not different 
at all.

Duncan Murdoch

On 22/01/2021 10:37 a.m., J C Nash wrote:
> Thanks Duncan for a clear argument about the "why".
> 
> The suggestion of R --vanilla started a train of thought that one could do something like
> 
>   clearws <- function(){ # Try to clear workspace
>     tmp <- readline("Are you sure you want to clear the workspace? ")
>     print(tmp)
>     if ( substr(toupper(tmp),1,1) != "Y" ){
>         return(0)
>     }
>     #  rm(tmp)
>     tgt<-parent.env(environment())
>     print(ls(tgt))
>     rm(list = ls(tgt, all.names = TRUE),envir=tgt) #will clear all objects includes hidden objects.
>     gc() #free up memrory and report the memory usage.
>     # What should we return?
>     # Can we offer interactive control?
>     # How about packages?
>   }
> 
> and call clearws() at the start of an example.
> 
> Contact me off-list if you have suggestions for improving this. I'd like to be able to preface
> examples with such a function that would render the session "vanilla" but from inside. That means
> removing packages that might have altered / replaced / masked standard functions. That might not
> be possible, but the idea is attractive to me as someone who mostly uses R in tests of tools that
> get used by others.
> 
> Best, JN
> 
> 
> On 2021-01-21 6:05 p.m., Duncan Murdoch wrote:
>> On 21/01/2021 5:20 p.m., J C Nash wrote:
>>> In a separate thread Jeff Newmiller wrote:
>>>> rm(list=ls()) is a bad practice... especially when posting examples. It doesn't clean out everything and it removes
>>>> objects created by the user.
>>>
>>> This query is to ask
>>>
>>> 1) Why is it bad practice to clear the workspace when presenting an example?
>>> I'm assuming here that people who will try R-help examples will not run them in the
>>> middle of something else, which I agree would be unfortunates.
>>
>> I think that's exactly the concern.? I doubt it would have happened in this instance, but in other cases, people might
>> copy and paste a complete example before reading it.? It's safer to say:? "Run this code in a clean workspace:", rather
>> than cleaning it out yourself.
>>
>> Duncan Murdoch
>>
>>
>> However, one of the
>>> not very nice aspects of R is that it is VERY easy to have stuff hanging around (including
>>> overloaded functions and operators) that get you into trouble, and indeed make it harder
>>> to reproduce those important "minimal reproducible examples".? This includes the .RData
>>> contents. (For information, I can understand the attraction, but I seem to have been
>>> burned much more often than I've benefited from a pre-warmed oven.)
>>>
>>> 2) Is there a good command that really does leave a blank workspace? For testing
>>> purposes, it would be useful to have an assured blank canvas.
>>
>> Yes, start R with
>>
>>  ? R --vanilla
>>
>> Duncan Murdoch
>>
>>>
>>> This post is definitely not to start an argument, but to try to find ways to reduce
>>> the possibilities for unanticipated outcomes in examples.
>>>
>>> Cheers, JN
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>


From v@d|k||chuk01 @end|ng |rom gm@||@com  Fri Jan 22 12:38:57 2021
From: v@d|k||chuk01 @end|ng |rom gm@||@com (Wadim iLchuk)
Date: Fri, 22 Jan 2021 13:38:57 +0200
Subject: [R] pgmm function errors in R
Message-ID: <CAH_32a5Db5HUy29o6_=w-NjjtF_Fb0oRgRj_wMiRB9-a2W0CWw@mail.gmail.com>

Hello everyone, My name is Vadym, I am a last-year student at Stockholm
School of Economics in Riga, currently working on my Bachelor's Thesis (so
still learning R). For my research, I need a GMM estimator (preferable
Arellano and Bond, 1991). I have been searching for a solution to my issue
for about 2 months already, yet still, no solutions have been found.

The data set could be found here:
https://drive.google.com/file/d/1uMmZTBDCaq1YoKO8KXU1L8EiqcKVe5V3/view?usp=sharing
Dataset is firm-level data.

The main model for my topic is:
deltaTFPt+1   = lag(deltaTFPt) + deltadebtt + finfrictiont +
deltadebt*finfriction + age + ta + deltasales.

Where, deltaTFP - growth in productivity of the firm from t to t+1,
deltadebt - growth in debt of the company, finfriction is my main variable
of interest - namely financial friction for the company, age is the age of
the company, ta is total assets, deltasales - growth in sales.

I need to estimate coefficients by using GMM

My code is the following for doing so by using pgmm function:
###############
PLVData_A <- pdata.frame(LVData_A, index = c("ID","Year")) z1 <-
pgmm(domegaACF_A ~ lag(domegaACF_A, 1) + ddebt + ff1 + ff1:ddebt + Age + ta
+ dsales | lag(domegaACF_A, 2), data = PLVData_A, effect = "twoways", model
= "onestep", transformation = "d")
summary(z1, robust = TRUE)
#################

Bearing in mind that I have been struggling with this for 2-3
months already I have tried to change everything I could in the model, but
constantly receive these types of errors:

Error in solve.default(crossprod(WX, t(crossprod(WX, A1)))) :
  Lapack routine dgesv: system is exactly singular: U[5,5] = 0
In addition: Warning message:
In pgmm(domegaACF_A ~ lag(domegaACF_A, 1) + lag(ddebt, 0:1) + ff1 +  :
  the first-step matrix is singular, a general inverse is used


Error in solve.default(crossprod(WX, t(crossprod(WX, A1)))) :
  system is computationally singular: reciprocal condition number =
4.26304e-27
In addition: Warning message:
In pgmm(domegaACF_A ~ lag(domegaACF_A, 1) + lag(ddebt, 0:1) + ff1 +  :
  the first-step matrix is singular, a general inverse is used


Error in cbind(yX1[[i]], V1) :
  number of rows of matrices must match (see arg 2)


Error in cbind(W2[[i]], V2) :
  number of rows of matrices must match (see arg 2)
In addition: There were 50 or more warnings (use warnings() to see the
first 50)


I would really appreciate any of your support or ideas since I have no clue
of how to solve the issue. Thank you in advance!

	[[alternative HTML version deleted]]


From dev||n@ch|oe @end|ng |rom y@hoo@co@uk  Fri Jan 22 13:15:25 2021
From: dev||n@ch|oe @end|ng |rom y@hoo@co@uk (devlin.chloe)
Date: Fri, 22 Jan 2021 12:15:25 +0000
Subject: [R] GAM
References: <6BEBD50D-E8DA-4C88-A513-0402E7CE44F3.ref@yahoo.co.uk>
Message-ID: <6BEBD50D-E8DA-4C88-A513-0402E7CE44F3@yahoo.co.uk>

Hi,
I?m currently using R studio to analyse data - I have 3 data sets consisting of months beginning in 02/2005-02/2020 with numbers of internet searches for 3 different countries. I have used a GAM to analyse this data and see if there are any significant differences or trends, but I am unsure a) if this is the correct method and b) how to interpret the results. If anyone could help with this it would be much appreciated

Thanks

From gpd@be+r @end|ng |rom m@||box@org  Fri Jan 22 20:14:11 2021
From: gpd@be+r @end|ng |rom m@||box@org (Georgios)
Date: Fri, 22 Jan 2021 21:14:11 +0200
Subject: [R] rmarkdown and source call to R file.
In-Reply-To: <CANROs4dVctmcfLKKOEMRzce-tMamvJePB5L-OK=Ymm_4DM+=xg@mail.gmail.com>
References: <6d335981e3edce1e9e596a73bcab6d715084d0d4.camel@mailbox.org>
 <CANROs4dVctmcfLKKOEMRzce-tMamvJePB5L-OK=Ymm_4DM+=xg@mail.gmail.com>
Message-ID: <7f00c9f72056a87fbaf30e8ec8976b26ca0e9457.camel@mailbox.org>

Thanks all of you for your answers. 
I managed to solve it after all. I was looking at the wrong place. It
was an argument on the server.R.

On Fri, 2021-01-22 at 09:17 -0600, Yihui Xie wrote:
> I don't know the answer (there are multiple possible reasons for the
> file not being found), but as the first step to debug the problem,
> you
> may replace this chunk
> 
> ```{r, echo=FALSE}
>    library(knitr)
>    source("helper.R", local = knitr::knit_global())
>    summarized_table<-give_table(params$ldf_summary)
>    kable(summarized_table,"simple")
> ```
> 
> with
> 
> ```{r}
> getwd()
> list.files()
> ```
> 
> and see what the working directory is, and which files are available.
> 
> Regards,
> Yihui
> 
> 
> On Fri, Jan 22, 2021 at 1:02 AM Georgios via R-help
> <r-help at r-project.org> wrote:
> > Hi!
> > I'm new in R and this list.
> > I made a shiny app using R studio.
> > my files are:
> >    -server.R
> >    -ui.R
> >    -helper.R
> >    -Report.Rmd.
> > 
> > All the files are on the same directory and helper.R is a file that
> > contains a lot of functions used in Report.Rmd and server.R
> > 
> > for some reason I cant call from Report.Rmd the file helper.R
> > 
> > My code in Report.Rmd is
> > 
> >    ## Summarize table
> >    ```{r, echo=FALSE}
> >    library(knitr)
> >    source("helper.R", local = knitr::knit_global())
> >    summarized_table<-give_table(params$ldf_summary)
> >    kable(summarized_table,"simple")
> >    ```
> > If I use absolute path it works but since I want to upload it to
> > https://www.shinyapps.io/ I must make it work with relative path.
> > 
> > The message I get is:
> > 
> >    processing file: Report.Rmd
> > 
> >    |..........................
> >                                         |  25%
> >      ordinary text without R code
> > 
> > 
> >    |....................................................
> >                                         |  50%
> >    label: unnamed-chunk-1 (with options)
> >    List of 1
> >     $ echo: logi FALSE
> > 
> >    Quitting from lines 13-17 (Report.Rmd)
> > 
> >    Warning: Error in file: cannot open the connection
> >      [No stack trace available]
> > 
> > 
> > The funny thing is that if I put the cursor inside "" at the
> > beginning
> > and I press tab I get the option to choose helper.R. So Im guessing
> > that I'm on the right directory.
> > Any ideas what I'm missing?
> > 
> > I'm stuck on this lines of code 2 days now.
> > I would really appreciate
> > any ideas.
> > 
> > 
> > Thanks in advance for your help!!!
> > 
> > 
> > ps. I tried all the combinations in Tools->Global Options->
> > "Evaluate
> > chunks in directory" with no luck.
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jan 22 22:23:48 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 22 Jan 2021 13:23:48 -0800
Subject: [R] pgmm function errors in R
In-Reply-To: <CAH_32a5Db5HUy29o6_=w-NjjtF_Fb0oRgRj_wMiRB9-a2W0CWw@mail.gmail.com>
References: <CAH_32a5Db5HUy29o6_=w-NjjtF_Fb0oRgRj_wMiRB9-a2W0CWw@mail.gmail.com>
Message-ID: <CAGxFJbRZDwPVLmMG4_Zy1rCzk-bz14Hj79WC6f0e6CvVKRGiTw@mail.gmail.com>

1. Please read the posting guide. Statistical questions and questions on
non-standard (not shipped with standard R distro) packages are largely off
topic here.

2.  This CRAN task view might be of interest to you:
https://cran.r-project.org/web/views/Econometrics.html

3. But as a general comment, perhaps completely useless, singularity in
linear-type model fits are often due to overfitting. Have no idea what that
might mean in your context.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 22, 2021 at 1:08 PM Wadim iLchuk <vadikilchuk01 at gmail.com>
wrote:

> Hello everyone, My name is Vadym, I am a last-year student at Stockholm
> School of Economics in Riga, currently working on my Bachelor's Thesis (so
> still learning R). For my research, I need a GMM estimator (preferable
> Arellano and Bond, 1991). I have been searching for a solution to my issue
> for about 2 months already, yet still, no solutions have been found.
>
> The data set could be found here:
>
> https://drive.google.com/file/d/1uMmZTBDCaq1YoKO8KXU1L8EiqcKVe5V3/view?usp=sharing
> Dataset is firm-level data.
>
> The main model for my topic is:
> deltaTFPt+1   = lag(deltaTFPt) + deltadebtt + finfrictiont +
> deltadebt*finfriction + age + ta + deltasales.
>
> Where, deltaTFP - growth in productivity of the firm from t to t+1,
> deltadebt - growth in debt of the company, finfriction is my main variable
> of interest - namely financial friction for the company, age is the age of
> the company, ta is total assets, deltasales - growth in sales.
>
> I need to estimate coefficients by using GMM
>
> My code is the following for doing so by using pgmm function:
> ###############
> PLVData_A <- pdata.frame(LVData_A, index = c("ID","Year")) z1 <-
> pgmm(domegaACF_A ~ lag(domegaACF_A, 1) + ddebt + ff1 + ff1:ddebt + Age + ta
> + dsales | lag(domegaACF_A, 2), data = PLVData_A, effect = "twoways", model
> = "onestep", transformation = "d")
> summary(z1, robust = TRUE)
> #################
>
> Bearing in mind that I have been struggling with this for 2-3
> months already I have tried to change everything I could in the model, but
> constantly receive these types of errors:
>
> Error in solve.default(crossprod(WX, t(crossprod(WX, A1)))) :
>   Lapack routine dgesv: system is exactly singular: U[5,5] = 0
> In addition: Warning message:
> In pgmm(domegaACF_A ~ lag(domegaACF_A, 1) + lag(ddebt, 0:1) + ff1 +  :
>   the first-step matrix is singular, a general inverse is used
>
>
> Error in solve.default(crossprod(WX, t(crossprod(WX, A1)))) :
>   system is computationally singular: reciprocal condition number =
> 4.26304e-27
> In addition: Warning message:
> In pgmm(domegaACF_A ~ lag(domegaACF_A, 1) + lag(ddebt, 0:1) + ff1 +  :
>   the first-step matrix is singular, a general inverse is used
>
>
> Error in cbind(yX1[[i]], V1) :
>   number of rows of matrices must match (see arg 2)
>
>
> Error in cbind(W2[[i]], V2) :
>   number of rows of matrices must match (see arg 2)
> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
>
>
> I would really appreciate any of your support or ideas since I have no clue
> of how to solve the issue. Thank you in advance!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Fri Jan 22 22:57:44 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Fri, 22 Jan 2021 13:57:44 -0800
Subject: [R] How to generate SE for the proportion value using a
 randomization process in R?
Message-ID: <CAMwU6B0JkZ-wZY6bbcwBjJ5VpjGMePnc-KOmR2n+G6zoCHFA+w@mail.gmail.com>

Hi All,
I was trying to estimate standard error (SE) for the proportion value using
some kind of randomization process (bootstrapping or jackknifing) in R, but
I could not figure it out.

Is there any way to generate SE for the proportion?

The example of the data and the code I am using is attached for your
reference. I would like to generate the value of proportion with a SE using
a 1000 times randomization.

dat<-structure(list(Sample = structure(c(1L, 12L, 13L, 14L, 15L, 16L,
17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L), .Label = c("id1",
"id10", "id11", "id12", "id13", "id14", "id15", "id16", "id17",
"id18", "id19", "Id2", "id3", "id4", "id5", "id6", "id7", "id8",
"id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L), Time2 = c(1L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class = "data.frame",
row.names = c(NA,
-19L))
daT<-data.frame(dat %>%
  mutate(Time1.but.not.in.Time2 = case_when(
            Time1 %in% "1" & Time2 %in% "0"  ~ "1"),
Time2.but.not.in.Time1 = case_when(
            Time1 %in% "0" & Time2 %in% "1"  ~ "1"),
 BothTimes = case_when(
            Time1 %in% "1" & Time2 %in% "1"  ~ "1")))
 daT
 summary(daT)

cols.num <- c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
"BothTimes")
daT[cols.num] <- sapply(daT[cols.num],as.numeric)
summary(daT)
ProportionValue<-sum(daT$BothTimes, na.rm=T)/sum(daT$Time1, na.rm=T)
ProportionValue
standard error??

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jan 23 00:07:05 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 22 Jan 2021 23:07:05 +0000
Subject: [R] How to generate SE for the proportion value using a
 randomization process in R?
In-Reply-To: <CAMwU6B0JkZ-wZY6bbcwBjJ5VpjGMePnc-KOmR2n+G6zoCHFA+w@mail.gmail.com>
References: <CAMwU6B0JkZ-wZY6bbcwBjJ5VpjGMePnc-KOmR2n+G6zoCHFA+w@mail.gmail.com>
Message-ID: <8face05f-dc69-a286-9961-a0ebf6fd3502@sapo.pt>

Hello,

Something like this, using base package boot?


library(boot)

bootprop <- function(data, index){
   d <- data[index, ]
   sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
}

R <- 1e3
set.seed(2020)
b <- boot(daT, bootprop, R)
b
b$t0     # original
sd(b$t)  # bootstrapped estimate of the SE of the sample prop.
hist(b$t, freq = FALSE)


Hope this helps,

Rui Barradas

?s 21:57 de 22/01/21, Marna Wagley escreveu:
> Hi All,
> I was trying to estimate standard error (SE) for the proportion value using
> some kind of randomization process (bootstrapping or jackknifing) in R, but
> I could not figure it out.
> 
> Is there any way to generate SE for the proportion?
> 
> The example of the data and the code I am using is attached for your
> reference. I would like to generate the value of proportion with a SE using
> a 1000 times randomization.
> 
> dat<-structure(list(Sample = structure(c(1L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L), .Label = c("id1",
> "id10", "id11", "id12", "id13", "id14", "id15", "id16", "id17",
> "id18", "id19", "Id2", "id3", "id4", "id5", "id6", "id7", "id8",
> "id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L, 0L, 0L,
> 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L), Time2 = c(1L,
> 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
> 1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class = "data.frame",
> row.names = c(NA,
> -19L))
> daT<-data.frame(dat %>%
>    mutate(Time1.but.not.in.Time2 = case_when(
>              Time1 %in% "1" & Time2 %in% "0"  ~ "1"),
> Time2.but.not.in.Time1 = case_when(
>              Time1 %in% "0" & Time2 %in% "1"  ~ "1"),
>   BothTimes = case_when(
>              Time1 %in% "1" & Time2 %in% "1"  ~ "1")))
>   daT
>   summary(daT)
> 
> cols.num <- c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
> "BothTimes")
> daT[cols.num] <- sapply(daT[cols.num],as.numeric)
> summary(daT)
> ProportionValue<-sum(daT$BothTimes, na.rm=T)/sum(daT$Time1, na.rm=T)
> ProportionValue
> standard error??
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jennc@m| @end|ng |rom hotm@||@com  Fri Jan 22 22:58:59 2021
From: jennc@m| @end|ng |rom hotm@||@com (Jenn Russell)
Date: Fri, 22 Jan 2021 21:58:59 +0000
Subject: [R] Help with Krippendorff's Alpha
Message-ID: <CY4PR1401MB19754BF247D08EB1E6DDC89BC6A00@CY4PR1401MB1975.namprd14.prod.outlook.com>

Hello!

I am requesting help for a data set in which I have 6 evaluators (I've called them 'Trainers'), each of which took a questionnaire with 180 questions. The possible answers to the questions are ordinal numbers. I am looking to test inter-rater reliability of the questionnaire using Krippendorff's alpha. I have already run this in R, however when I get the output it seems the matrix is inverted. While it seems like it should be an easy problem to fix I don't see how I would be able to create my matrix the other way without typing out all 180 scores manually. For reference, I'm using the irr package to use kripp.alpha().

> Trainers<-matrix(c(Trainer_1,Trainer_2, Trainer_3, Trainer_5, Trainer_6, Trainer_12), ncol=6)
> kripp.alpha(Trainers, method=c("ordinal"))
Krippendorff's alpha
Subjects = 6
Raters = 180
alpha = -0.00149

While I'm getting an output - shouldn't my raters be 6 and my subjects be 180?

Appreciate the help!

JR

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jan 23 00:53:38 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 22 Jan 2021 15:53:38 -0800
Subject: [R] Help with Krippendorff's Alpha
In-Reply-To: <CY4PR1401MB19754BF247D08EB1E6DDC89BC6A00@CY4PR1401MB1975.namprd14.prod.outlook.com>
References: <CY4PR1401MB19754BF247D08EB1E6DDC89BC6A00@CY4PR1401MB1975.namprd14.prod.outlook.com>
Message-ID: <CAGxFJbT7TLagz4M0OKZkDrUw6eMJJVhH3_yO72d93qdkBWWg-A@mail.gmail.com>

Well,....

"Appreciate the help!"

Indeed, you should for any that you receive. But do note per the posting
guide linked below:

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<http://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.
If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

So while optimism is often a virtue, don't be disappointed if it is not
rewarded here. For context, there are in excess of 20,000 R packages out
there, so expectations of help on any of them is a long shot.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 22, 2021 at 3:24 PM Jenn Russell <jenncami at hotmail.com> wrote:

> Hello!
>
> I am requesting help for a data set in which I have 6 evaluators (I've
> called them 'Trainers'), each of which took a questionnaire with 180
> questions. The possible answers to the questions are ordinal numbers. I am
> looking to test inter-rater reliability of the questionnaire using
> Krippendorff's alpha. I have already run this in R, however when I get the
> output it seems the matrix is inverted. While it seems like it should be an
> easy problem to fix I don't see how I would be able to create my matrix the
> other way without typing out all 180 scores manually. For reference, I'm
> using the irr package to use kripp.alpha().
>
> > Trainers<-matrix(c(Trainer_1,Trainer_2, Trainer_3, Trainer_5, Trainer_6,
> Trainer_12), ncol=6)
> > kripp.alpha(Trainers, method=c("ordinal"))
> Krippendorff's alpha
> Subjects = 6
> Raters = 180
> alpha = -0.00149
>
> While I'm getting an output - shouldn't my raters be 6 and my subjects be
> 180?
>
> Appreciate the help!
>
> JR
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sat Jan 23 00:58:38 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 23 Jan 2021 10:58:38 +1100
Subject: [R] Help with Krippendorff's Alpha
In-Reply-To: <CY4PR1401MB19754BF247D08EB1E6DDC89BC6A00@CY4PR1401MB1975.namprd14.prod.outlook.com>
References: <CY4PR1401MB19754BF247D08EB1E6DDC89BC6A00@CY4PR1401MB1975.namprd14.prod.outlook.com>
Message-ID: <CA+8X3fUbz8E0CbKZu=+HL9tcaXN7S2jCMmrUeAY78T9yEVeWtQ@mail.gmail.com>

Hi Jean,
kripp.alpha expects a classifier by object (in your case, score)
matrix as the first argument. If I read your code correctly you are
getting the scores zigzagging across six columns when you want a 6 x
180 matrix. My guess is that you want:

Trainers<-matrix(c(Trainer_1,Trainer_2, Trainer_3, Trainer_5,
Trainer_6, Trainer_12),
 nrow=6,byrow=TRUE)

Jim


On Sat, Jan 23, 2021 at 10:24 AM Jenn Russell <jenncami at hotmail.com> wrote:
>
> Hello!
>
> I am requesting help for a data set in which I have 6 evaluators (I've called them 'Trainers'), each of which took a questionnaire with 180 questions. The possible answers to the questions are ordinal numbers. I am looking to test inter-rater reliability of the questionnaire using Krippendorff's alpha. I have already run this in R, however when I get the output it seems the matrix is inverted. While it seems like it should be an easy problem to fix I don't see how I would be able to create my matrix the other way without typing out all 180 scores manually. For reference, I'm using the irr package to use kripp.alpha().
>
> > Trainers<-matrix(c(Trainer_1,Trainer_2, Trainer_3, Trainer_5, Trainer_6, Trainer_12), ncol=6)
> > kripp.alpha(Trainers, method=c("ordinal"))
> Krippendorff's alpha
> Subjects = 6
> Raters = 180
> alpha = -0.00149
>
> While I'm getting an output - shouldn't my raters be 6 and my subjects be 180?
>
> Appreciate the help!
>
> JR
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Sat Jan 23 02:02:48 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 23 Jan 2021 14:02:48 +1300
Subject: [R] Plot histogram and lognormal fit on the same time
In-Reply-To: <CAGxFJbQqaWX-crtqQL7oppe=Xyf+T-EC=+yf2k+tTW=8Frz3KA@mail.gmail.com>
References: <b69fa66f-1701-1af1-4b0a-ac472e0200ff@icmpe.cnrs.fr>
 <CAGxFJbQqaWX-crtqQL7oppe=Xyf+T-EC=+yf2k+tTW=8Frz3KA@mail.gmail.com>
Message-ID: <CAB8pepwuL2U+jhqkAFm==4=SUsJoFg7hZcHP6NW5UH=_Az0-Bw@mail.gmail.com>

Sorry, Bert.
The fitdistr function estimates parameters via maximum likelihood.
(i.e. The "lognormal" part of this, is not a kernel).


On Fri, Jan 22, 2021 at 5:14 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> In future, you should try to search before posting. I realize that getting
> good search terms can sometimes be tricky, but not in this case: 'plot
> density with histogram in R' or similar on rseek.org or just on your usual
> search platform brought up several ways to do it.
>
> As a (slightly offtopic) side issue, be careful with this: both histograms
> and smooth density estimates are just that: density **estimates** that
> depend on both the data and various parameters, e.g. the location of the
> bins for histograms and kernel for kernel density estimates. You may
> therefore get plots where the two do not appear to "match" when you use the
> defaults for each.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Jan 21, 2021 at 3:54 AM Eric Leroy <leroy at icmpe.cnrs.fr> wrote:
>
> > Hi,
> >
> > I would like to plot the histogram of data and fit it with a lognormal
> > distribution.
> >
> > The ideal, would be to superimpose the fit on the histogram and write
> > the results of the fit on the figure.
> >
> > Right now, I was able to plot the histogram and fit the density with a
> > lognormal, but I can't combine all together.
> >
> > Here is the code I wrote :
> >
> > histdata <- hist(dataframe$data)
> >
> > library(MASS)
> >
> > fitdistr(histdata$density, "lognormal")
> >
> > Can you help me ?
> >
> > Best regards,
> >
> > --
> >
> > *Eric Leroy*
> >
> > /Responsable de la plateforme microscopie ?lectronique/
> >
> > /Correspondant S?curit? des Syst?mes Informatiques de l'ICMPE/
> >
> > ICMPE - UMR 7182 - CNRS - UPEC
> >
> > 2/8, rue Henri Dunant
> >
> > 94320 Thiais
> >
> > T?l : 01.49.78.12.09
> >
> > Fax : 01.49.78.12.03
> >
> > courriel : leroy at icmpe.cnrs.fr <mailto:leroy at icmpe.cnrs.fr>
> >
> > Page Web : : http://www.icmpe.cnrs.fr <http://www.icmpe.cnrs.fr>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jan 23 03:50:42 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 22 Jan 2021 18:50:42 -0800
Subject: [R] Plot histogram and lognormal fit on the same time
In-Reply-To: <CAB8pepwuL2U+jhqkAFm==4=SUsJoFg7hZcHP6NW5UH=_Az0-Bw@mail.gmail.com>
References: <b69fa66f-1701-1af1-4b0a-ac472e0200ff@icmpe.cnrs.fr>
 <CAGxFJbQqaWX-crtqQL7oppe=Xyf+T-EC=+yf2k+tTW=8Frz3KA@mail.gmail.com>
 <CAB8pepwuL2U+jhqkAFm==4=SUsJoFg7hZcHP6NW5UH=_Az0-Bw@mail.gmail.com>
Message-ID: <CAGxFJbQHMg0jzuC1Vr3WRiAGUGBeSgiEBjmFQL97MAVOOjvBYw@mail.gmail.com>

OK, but that's not the point of my comment.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 22, 2021 at 5:03 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> Sorry, Bert.
> The fitdistr function estimates parameters via maximum likelihood.
> (i.e. The "lognormal" part of this, is not a kernel).
>
>
> On Fri, Jan 22, 2021 at 5:14 AM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > In future, you should try to search before posting. I realize that
> getting
> > good search terms can sometimes be tricky, but not in this case: 'plot
> > density with histogram in R' or similar on rseek.org or just on your
> usual
> > search platform brought up several ways to do it.
> >
> > As a (slightly offtopic) side issue, be careful with this: both
> histograms
> > and smooth density estimates are just that: density **estimates** that
> > depend on both the data and various parameters, e.g. the location of the
> > bins for histograms and kernel for kernel density estimates. You may
> > therefore get plots where the two do not appear to "match" when you use
> the
> > defaults for each.
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Thu, Jan 21, 2021 at 3:54 AM Eric Leroy <leroy at icmpe.cnrs.fr> wrote:
> >
> > > Hi,
> > >
> > > I would like to plot the histogram of data and fit it with a lognormal
> > > distribution.
> > >
> > > The ideal, would be to superimpose the fit on the histogram and write
> > > the results of the fit on the figure.
> > >
> > > Right now, I was able to plot the histogram and fit the density with a
> > > lognormal, but I can't combine all together.
> > >
> > > Here is the code I wrote :
> > >
> > > histdata <- hist(dataframe$data)
> > >
> > > library(MASS)
> > >
> > > fitdistr(histdata$density, "lognormal")
> > >
> > > Can you help me ?
> > >
> > > Best regards,
> > >
> > > --
> > >
> > > *Eric Leroy*
> > >
> > > /Responsable de la plateforme microscopie ?lectronique/
> > >
> > > /Correspondant S?curit? des Syst?mes Informatiques de l'ICMPE/
> > >
> > > ICMPE - UMR 7182 - CNRS - UPEC
> > >
> > > 2/8, rue Henri Dunant
> > >
> > > 94320 Thiais
> > >
> > > T?l : 01.49.78.12.09
> > >
> > > Fax : 01.49.78.12.03
> > >
> > > courriel : leroy at icmpe.cnrs.fr <mailto:leroy at icmpe.cnrs.fr>
> > >
> > > Page Web : : http://www.icmpe.cnrs.fr <http://www.icmpe.cnrs.fr>
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Sat Jan 23 08:47:54 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Fri, 22 Jan 2021 23:47:54 -0800
Subject: [R] How to generate SE for the proportion value using a
 randomization process in R?
In-Reply-To: <8face05f-dc69-a286-9961-a0ebf6fd3502@sapo.pt>
References: <CAMwU6B0JkZ-wZY6bbcwBjJ5VpjGMePnc-KOmR2n+G6zoCHFA+w@mail.gmail.com>
 <8face05f-dc69-a286-9961-a0ebf6fd3502@sapo.pt>
Message-ID: <CAMwU6B0meFyOvCnzn2DEMrU+LUoejL_x6RMW6aszxuq-2r+=TA@mail.gmail.com>

Dear Rui,
I was wondering whether we have to square root of SD to find SE, right?

bootprop <- function(data, index){
   d <- data[index, ]
   sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
}

R <- 1e3
set.seed(2020)
b <- boot(daT, bootprop, R)
b
b$t0     # original
sd(b$t)  # bootstrapped estimate of the SE of the sample prop.
sd(b$t)/sqrt(1000)
pandit*(1-pandit)

hist(b$t, freq = FALSE)




On Fri, Jan 22, 2021 at 3:07 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Something like this, using base package boot?
>
>
> library(boot)
>
> bootprop <- function(data, index){
>    d <- data[index, ]
>    sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
> }
>
> R <- 1e3
> set.seed(2020)
> b <- boot(daT, bootprop, R)
> b
> b$t0     # original
> sd(b$t)  # bootstrapped estimate of the SE of the sample prop.
> hist(b$t, freq = FALSE)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 21:57 de 22/01/21, Marna Wagley escreveu:
> > Hi All,
> > I was trying to estimate standard error (SE) for the proportion value
> using
> > some kind of randomization process (bootstrapping or jackknifing) in R,
> but
> > I could not figure it out.
> >
> > Is there any way to generate SE for the proportion?
> >
> > The example of the data and the code I am using is attached for your
> > reference. I would like to generate the value of proportion with a SE
> using
> > a 1000 times randomization.
> >
> > dat<-structure(list(Sample = structure(c(1L, 12L, 13L, 14L, 15L, 16L,
> > 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L), .Label =
> c("id1",
> > "id10", "id11", "id12", "id13", "id14", "id15", "id16", "id17",
> > "id18", "id19", "Id2", "id3", "id4", "id5", "id6", "id7", "id8",
> > "id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L, 0L, 0L,
> > 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L), Time2 = c(1L,
> > 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
> > 1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class = "data.frame",
> > row.names = c(NA,
> > -19L))
> > daT<-data.frame(dat %>%
> >    mutate(Time1.but.not.in.Time2 = case_when(
> >              Time1 %in% "1" & Time2 %in% "0"  ~ "1"),
> > Time2.but.not.in.Time1 = case_when(
> >              Time1 %in% "0" & Time2 %in% "1"  ~ "1"),
> >   BothTimes = case_when(
> >              Time1 %in% "1" & Time2 %in% "1"  ~ "1")))
> >   daT
> >   summary(daT)
> >
> > cols.num <- c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
> > "BothTimes")
> > daT[cols.num] <- sapply(daT[cols.num],as.numeric)
> > summary(daT)
> > ProportionValue<-sum(daT$BothTimes, na.rm=T)/sum(daT$Time1, na.rm=T)
> > ProportionValue
> > standard error??
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jan 23 09:28:38 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 23 Jan 2021 08:28:38 +0000
Subject: [R] How to generate SE for the proportion value using a
 randomization process in R?
In-Reply-To: <CAMwU6B0meFyOvCnzn2DEMrU+LUoejL_x6RMW6aszxuq-2r+=TA@mail.gmail.com>
References: <CAMwU6B0JkZ-wZY6bbcwBjJ5VpjGMePnc-KOmR2n+G6zoCHFA+w@mail.gmail.com>
 <8face05f-dc69-a286-9961-a0ebf6fd3502@sapo.pt>
 <CAMwU6B0meFyOvCnzn2DEMrU+LUoejL_x6RMW6aszxuq-2r+=TA@mail.gmail.com>
Message-ID: <27a6ab72-c392-c87a-ef64-82a209ce6134@sapo.pt>

Hello,

Inline.

?s 07:47 de 23/01/21, Marna Wagley escreveu:
> Dear Rui,
> I was wondering whether we have to square root of SD to find SE, right?

No, we don't. var already divides by n, don't divide again.
This is the code, that can be seen by running the function name at a 
command line.


sd
#function (x, na.rm = FALSE)
#sqrt(var(if (is.vector(x) || is.factor(x)) x else as.double(x),
#    na.rm = na.rm))
#<bytecode: 0x55f3ce900848>
#<environment: namespace:stats>



> 
> bootprop <- function(data, index){
>  ? ?d <- data[index, ]
>  ? ?sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
> }
> 
> R <- 1e3
> set.seed(2020)
> b <- boot(daT, bootprop, R)
> b
> b$t0? ? ?# original
> sd(b$t)? # bootstrapped estimate of the SE of the sample prop.
> sd(b$t)/sqrt(1000)
> pandit*(1-pandit)
> 
> hist(b$t, freq = FALSE)


Try plotting the normal densities for both cases, the red line is 
clearly wrong.


f <- function(x, xbar, s){
   dnorm(x, mean = xbar, sd = s)
}

hist(b$t, freq = FALSE)
curve(f(x, xbar = b$t0, s = sd(b$t)), from = 0, to = 1, col = "blue", 
add = TRUE)
curve(f(x, xbar = b$t0, s = sd(b$t)/sqrt(R)), from = 0, to = 1, col = 
"red", add = TRUE)


Hope this helps,

Rui Barradas

> 
> 
> 
> 
> On Fri, Jan 22, 2021 at 3:07 PM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     Something like this, using base package boot?
> 
> 
>     library(boot)
> 
>     bootprop <- function(data, index){
>      ? ?d <- data[index, ]
>      ? ?sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
>     }
> 
>     R <- 1e3
>     set.seed(2020)
>     b <- boot(daT, bootprop, R)
>     b
>     b$t0? ? ?# original
>     sd(b$t)? # bootstrapped estimate of the SE of the sample prop.
>     hist(b$t, freq = FALSE)
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 21:57 de 22/01/21, Marna Wagley escreveu:
>      > Hi All,
>      > I was trying to estimate standard error (SE) for the proportion
>     value using
>      > some kind of randomization process (bootstrapping or jackknifing)
>     in R, but
>      > I could not figure it out.
>      >
>      > Is there any way to generate SE for the proportion?
>      >
>      > The example of the data and the code I am using is attached for your
>      > reference. I would like to generate the value of proportion with
>     a SE using
>      > a 1000 times randomization.
>      >
>      > dat<-structure(list(Sample = structure(c(1L, 12L, 13L, 14L, 15L, 16L,
>      > 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L), .Label
>     = c("id1",
>      > "id10", "id11", "id12", "id13", "id14", "id15", "id16", "id17",
>      > "id18", "id19", "Id2", "id3", "id4", "id5", "id6", "id7", "id8",
>      > "id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L, 0L, 0L,
>      > 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L), Time2 = c(1L,
>      > 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
>      > 1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class =
>     "data.frame",
>      > row.names = c(NA,
>      > -19L))
>      > daT<-data.frame(dat %>%
>      >? ? mutate(Time1.but.not.in.Time2 = case_when(
>      >? ? ? ? ? ? ? Time1 %in% "1" & Time2 %in% "0"? ~ "1"),
>      > Time2.but.not.in.Time1 = case_when(
>      >? ? ? ? ? ? ? Time1 %in% "0" & Time2 %in% "1"? ~ "1"),
>      >? ?BothTimes = case_when(
>      >? ? ? ? ? ? ? Time1 %in% "1" & Time2 %in% "1"? ~ "1")))
>      >? ?daT
>      >? ?summary(daT)
>      >
>      > cols.num <- c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
>      > "BothTimes")
>      > daT[cols.num] <- sapply(daT[cols.num],as.numeric)
>      > summary(daT)
>      > ProportionValue<-sum(daT$BothTimes, na.rm=T)/sum(daT$Time1, na.rm=T)
>      > ProportionValue
>      > standard error??
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Sat Jan 23 09:36:31 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Sat, 23 Jan 2021 00:36:31 -0800
Subject: [R] How to generate SE for the proportion value using a
 randomization process in R?
In-Reply-To: <27a6ab72-c392-c87a-ef64-82a209ce6134@sapo.pt>
References: <CAMwU6B0JkZ-wZY6bbcwBjJ5VpjGMePnc-KOmR2n+G6zoCHFA+w@mail.gmail.com>
 <8face05f-dc69-a286-9961-a0ebf6fd3502@sapo.pt>
 <CAMwU6B0meFyOvCnzn2DEMrU+LUoejL_x6RMW6aszxuq-2r+=TA@mail.gmail.com>
 <27a6ab72-c392-c87a-ef64-82a209ce6134@sapo.pt>
Message-ID: <CAMwU6B1GyXio9bJUNhUbuHFYt6fuZ+9jZ1Nm85cUhAs1KuJ9sA@mail.gmail.com>

Yes Rui, I can see we don't need to divide by square root of sample size.
The example is great to understand it.
Thank you.
Marna


On Sat, Jan 23, 2021 at 12:28 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Inline.
>
> ?s 07:47 de 23/01/21, Marna Wagley escreveu:
> > Dear Rui,
> > I was wondering whether we have to square root of SD to find SE, right?
>
> No, we don't. var already divides by n, don't divide again.
> This is the code, that can be seen by running the function name at a
> command line.
>
>
> sd
> #function (x, na.rm = FALSE)
> #sqrt(var(if (is.vector(x) || is.factor(x)) x else as.double(x),
> #    na.rm = na.rm))
> #<bytecode: 0x55f3ce900848>
> #<environment: namespace:stats>
>
>
>
> >
> > bootprop <- function(data, index){
> >     d <- data[index, ]
> >     sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
> > }
> >
> > R <- 1e3
> > set.seed(2020)
> > b <- boot(daT, bootprop, R)
> > b
> > b$t0     # original
> > sd(b$t)  # bootstrapped estimate of the SE of the sample prop.
> > sd(b$t)/sqrt(1000)
> > pandit*(1-pandit)
> >
> > hist(b$t, freq = FALSE)
>
>
> Try plotting the normal densities for both cases, the red line is
> clearly wrong.
>
>
> f <- function(x, xbar, s){
>    dnorm(x, mean = xbar, sd = s)
> }
>
> hist(b$t, freq = FALSE)
> curve(f(x, xbar = b$t0, s = sd(b$t)), from = 0, to = 1, col = "blue",
> add = TRUE)
> curve(f(x, xbar = b$t0, s = sd(b$t)/sqrt(R)), from = 0, to = 1, col =
> "red", add = TRUE)
>
>
> Hope this helps,
>
> Rui Barradas
>
> >
> >
> >
> >
> > On Fri, Jan 22, 2021 at 3:07 PM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     Something like this, using base package boot?
> >
> >
> >     library(boot)
> >
> >     bootprop <- function(data, index){
> >         d <- data[index, ]
> >         sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm =
> TRUE)
> >     }
> >
> >     R <- 1e3
> >     set.seed(2020)
> >     b <- boot(daT, bootprop, R)
> >     b
> >     b$t0     # original
> >     sd(b$t)  # bootstrapped estimate of the SE of the sample prop.
> >     hist(b$t, freq = FALSE)
> >
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >     ?s 21:57 de 22/01/21, Marna Wagley escreveu:
> >      > Hi All,
> >      > I was trying to estimate standard error (SE) for the proportion
> >     value using
> >      > some kind of randomization process (bootstrapping or jackknifing)
> >     in R, but
> >      > I could not figure it out.
> >      >
> >      > Is there any way to generate SE for the proportion?
> >      >
> >      > The example of the data and the code I am using is attached for
> your
> >      > reference. I would like to generate the value of proportion with
> >     a SE using
> >      > a 1000 times randomization.
> >      >
> >      > dat<-structure(list(Sample = structure(c(1L, 12L, 13L, 14L, 15L,
> 16L,
> >      > 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L), .Label
> >     = c("id1",
> >      > "id10", "id11", "id12", "id13", "id14", "id15", "id16", "id17",
> >      > "id18", "id19", "Id2", "id3", "id4", "id5", "id6", "id7", "id8",
> >      > "id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L, 0L, 0L,
> >      > 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L), Time2 = c(1L,
> >      > 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
> >      > 1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class =
> >     "data.frame",
> >      > row.names = c(NA,
> >      > -19L))
> >      > daT<-data.frame(dat %>%
> >      >    mutate(Time1.but.not.in.Time2 = case_when(
> >      >              Time1 %in% "1" & Time2 %in% "0"  ~ "1"),
> >      > Time2.but.not.in.Time1 = case_when(
> >      >              Time1 %in% "0" & Time2 %in% "1"  ~ "1"),
> >      >   BothTimes = case_when(
> >      >              Time1 %in% "1" & Time2 %in% "1"  ~ "1")))
> >      >   daT
> >      >   summary(daT)
> >      >
> >      > cols.num <- c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
> >      > "BothTimes")
> >      > daT[cols.num] <- sapply(daT[cols.num],as.numeric)
> >      > summary(daT)
> >      > ProportionValue<-sum(daT$BothTimes, na.rm=T)/sum(daT$Time1,
> na.rm=T)
> >      > ProportionValue
> >      > standard error??
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >      > and provide commented, minimal, self-contained, reproducible code.
> >      >
> >
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Jan 24 15:48:16 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 24 Jan 2021 15:48:16 +0100
Subject: [R] Plot dataframe with color based on a column value
Message-ID: <CAMk+s2QoKDC7Wj1o8+FAMpj8+JO+-gJ5nR78dsHO3vSpvnRCuA@mail.gmail.com>

Hello
is it possible to color the data of a dataframe according to the
values of one column?
I have a dataframe that OI have subdivided into X and Y, with a third
Z with the sample number. I would like to plot Y~X but coloring using
Z. But I would like to use base R and not lines.
Is that possible?
Thank you

```
d <- 2
K <- 10^13
A1_0 <- 1
A2_0 <- 100
A3_0 <- 500
A4_0 <- 10000
PCR <- function(initCopy, dupRate, Carry) {
  ROI_T = initCopy
  A = array()
  for (i in 1:45) {
    ROI_TplusOne <- ROI_T * dupRate * (1 - ROI_T/Carry)
    A[i] <- ROI_TplusOne
    ROI_T <- ROI_TplusOne
  }
  return(A)
}
A1 <- PCR(A1_0, d, K)
A2 <- PCR(A2_0, d, K)
A3 <- PCR(A3_0, d, K)
A4 <- PCR(A4_0, d, K)
# store results and plot
Z <- c(rep(1, 45), rep(2, 45), rep(3, 45), rep(4, 45))
X = rep(1:45,4)
Y = c(A1, A2, A3, A4)
ROI <- data.frame(Z, X, Y)
plot(Y ~ X, data = ROI, type = "l", lwd = 3)
```


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jan 24 17:41:33 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 24 Jan 2021 08:41:33 -0800
Subject: [R] Plot dataframe with color based on a column value
In-Reply-To: <CAMk+s2QoKDC7Wj1o8+FAMpj8+JO+-gJ5nR78dsHO3vSpvnRCuA@mail.gmail.com>
References: <CAMk+s2QoKDC7Wj1o8+FAMpj8+JO+-gJ5nR78dsHO3vSpvnRCuA@mail.gmail.com>
Message-ID: <CAGxFJbQSxBRuD4MWDVhZMBPGLrvwCwDqwgBNV2=Y8gSjdiwMxg@mail.gmail.com>

1. lines() *is* base R.

2. See the col argument of ?plot.default.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 24, 2021 at 6:48 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello
> is it possible to color the data of a dataframe according to the
> values of one column?
> I have a dataframe that OI have subdivided into X and Y, with a third
> Z with the sample number. I would like to plot Y~X but coloring using
> Z. But I would like to use base R and not lines.
> Is that possible?
> Thank you
>
> ```
> d <- 2
> K <- 10^13
> A1_0 <- 1
> A2_0 <- 100
> A3_0 <- 500
> A4_0 <- 10000
> PCR <- function(initCopy, dupRate, Carry) {
>   ROI_T = initCopy
>   A = array()
>   for (i in 1:45) {
>     ROI_TplusOne <- ROI_T * dupRate * (1 - ROI_T/Carry)
>     A[i] <- ROI_TplusOne
>     ROI_T <- ROI_TplusOne
>   }
>   return(A)
> }
> A1 <- PCR(A1_0, d, K)
> A2 <- PCR(A2_0, d, K)
> A3 <- PCR(A3_0, d, K)
> A4 <- PCR(A4_0, d, K)
> # store results and plot
> Z <- c(rep(1, 45), rep(2, 45), rep(3, 45), rep(4, 45))
> X = rep(1:45,4)
> Y = c(A1, A2, A3, A4)
> ROI <- data.frame(Z, X, Y)
> plot(Y ~ X, data = ROI, type = "l", lwd = 3)
> ```
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jan 24 18:20:50 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 24 Jan 2021 09:20:50 -0800
Subject: [R] Plot dataframe with color based on a column value
In-Reply-To: <CAGxFJbQSxBRuD4MWDVhZMBPGLrvwCwDqwgBNV2=Y8gSjdiwMxg@mail.gmail.com>
References: <CAMk+s2QoKDC7Wj1o8+FAMpj8+JO+-gJ5nR78dsHO3vSpvnRCuA@mail.gmail.com>
 <CAGxFJbQSxBRuD4MWDVhZMBPGLrvwCwDqwgBNV2=Y8gSjdiwMxg@mail.gmail.com>
Message-ID: <CAGxFJbTngHVsJ-EAVJsEteT9yrk_3L7t1-qZ7y3JLAtX-EYMGQ@mail.gmail.com>

No. I was wrong. ?plot.default says only one line color (the first) will be
used. So it appears that you need to use lines().

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 24, 2021 at 8:41 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> 1. lines() *is* base R.
>
> 2. See the col argument of ?plot.default.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Jan 24, 2021 at 6:48 AM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
>
>> Hello
>> is it possible to color the data of a dataframe according to the
>> values of one column?
>> I have a dataframe that OI have subdivided into X and Y, with a third
>> Z with the sample number. I would like to plot Y~X but coloring using
>> Z. But I would like to use base R and not lines.
>> Is that possible?
>> Thank you
>>
>> ```
>> d <- 2
>> K <- 10^13
>> A1_0 <- 1
>> A2_0 <- 100
>> A3_0 <- 500
>> A4_0 <- 10000
>> PCR <- function(initCopy, dupRate, Carry) {
>>   ROI_T = initCopy
>>   A = array()
>>   for (i in 1:45) {
>>     ROI_TplusOne <- ROI_T * dupRate * (1 - ROI_T/Carry)
>>     A[i] <- ROI_TplusOne
>>     ROI_T <- ROI_TplusOne
>>   }
>>   return(A)
>> }
>> A1 <- PCR(A1_0, d, K)
>> A2 <- PCR(A2_0, d, K)
>> A3 <- PCR(A3_0, d, K)
>> A4 <- PCR(A4_0, d, K)
>> # store results and plot
>> Z <- c(rep(1, 45), rep(2, 45), rep(3, 45), rep(4, 45))
>> X = rep(1:45,4)
>> Y = c(A1, A2, A3, A4)
>> ROI <- data.frame(Z, X, Y)
>> plot(Y ~ X, data = ROI, type = "l", lwd = 3)
>> ```
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jan 24 18:45:26 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 24 Jan 2021 17:45:26 +0000
Subject: [R] Plot dataframe with color based on a column value
In-Reply-To: <CAMk+s2QoKDC7Wj1o8+FAMpj8+JO+-gJ5nR78dsHO3vSpvnRCuA@mail.gmail.com>
References: <CAMk+s2QoKDC7Wj1o8+FAMpj8+JO+-gJ5nR78dsHO3vSpvnRCuA@mail.gmail.com>
Message-ID: <21557594-a274-185b-b5eb-c411470be0b3@sapo.pt>

Hello,

Base R:

colrs <- rainbow(length(unique(ROI$Z)))
roi_wide <- reshape(ROI, v.names = "Y", timevar = "Z", idvar = "X", 
direction = "wide")
matplot(roi_wide, type = "l", lwd = 3, lty = "solid", col = colrs)


Hope this helps,

Rui Barradas

?s 14:48 de 24/01/21, Luigi Marongiu escreveu:
> Hello
> is it possible to color the data of a dataframe according to the
> values of one column?
> I have a dataframe that OI have subdivided into X and Y, with a third
> Z with the sample number. I would like to plot Y~X but coloring using
> Z. But I would like to use base R and not lines.
> Is that possible?
> Thank you
> 
> ```
> d <- 2
> K <- 10^13
> A1_0 <- 1
> A2_0 <- 100
> A3_0 <- 500
> A4_0 <- 10000
> PCR <- function(initCopy, dupRate, Carry) {
>    ROI_T = initCopy
>    A = array()
>    for (i in 1:45) {
>      ROI_TplusOne <- ROI_T * dupRate * (1 - ROI_T/Carry)
>      A[i] <- ROI_TplusOne
>      ROI_T <- ROI_TplusOne
>    }
>    return(A)
> }
> A1 <- PCR(A1_0, d, K)
> A2 <- PCR(A2_0, d, K)
> A3 <- PCR(A3_0, d, K)
> A4 <- PCR(A4_0, d, K)
> # store results and plot
> Z <- c(rep(1, 45), rep(2, 45), rep(3, 45), rep(4, 45))
> X = rep(1:45,4)
> Y = c(A1, A2, A3, A4)
> ROI <- data.frame(Z, X, Y)
> plot(Y ~ X, data = ROI, type = "l", lwd = 3)
> ```
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Jan 24 20:27:17 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 24 Jan 2021 20:27:17 +0100
Subject: [R] Plot dataframe with color based on a column value
In-Reply-To: <21557594-a274-185b-b5eb-c411470be0b3@sapo.pt>
References: <CAMk+s2QoKDC7Wj1o8+FAMpj8+JO+-gJ5nR78dsHO3vSpvnRCuA@mail.gmail.com>
 <21557594-a274-185b-b5eb-c411470be0b3@sapo.pt>
Message-ID: <CAMk+s2RoLJU=C5RsASBrME_OSPr-soF6WSwcUuOYDeMQYOqNZg@mail.gmail.com>

I did not know about matplot, but it did the work. using lines is my
default procedure but it can be time-consuming. Thank you all.

On Sun, Jan 24, 2021 at 6:45 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Base R:
>
> colrs <- rainbow(length(unique(ROI$Z)))
> roi_wide <- reshape(ROI, v.names = "Y", timevar = "Z", idvar = "X",
> direction = "wide")
> matplot(roi_wide, type = "l", lwd = 3, lty = "solid", col = colrs)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 14:48 de 24/01/21, Luigi Marongiu escreveu:
> > Hello
> > is it possible to color the data of a dataframe according to the
> > values of one column?
> > I have a dataframe that OI have subdivided into X and Y, with a third
> > Z with the sample number. I would like to plot Y~X but coloring using
> > Z. But I would like to use base R and not lines.
> > Is that possible?
> > Thank you
> >
> > ```
> > d <- 2
> > K <- 10^13
> > A1_0 <- 1
> > A2_0 <- 100
> > A3_0 <- 500
> > A4_0 <- 10000
> > PCR <- function(initCopy, dupRate, Carry) {
> >    ROI_T = initCopy
> >    A = array()
> >    for (i in 1:45) {
> >      ROI_TplusOne <- ROI_T * dupRate * (1 - ROI_T/Carry)
> >      A[i] <- ROI_TplusOne
> >      ROI_T <- ROI_TplusOne
> >    }
> >    return(A)
> > }
> > A1 <- PCR(A1_0, d, K)
> > A2 <- PCR(A2_0, d, K)
> > A3 <- PCR(A3_0, d, K)
> > A4 <- PCR(A4_0, d, K)
> > # store results and plot
> > Z <- c(rep(1, 45), rep(2, 45), rep(3, 45), rep(4, 45))
> > X = rep(1:45,4)
> > Y = c(A1, A2, A3, A4)
> > ROI <- data.frame(Z, X, Y)
> > plot(Y ~ X, data = ROI, type = "l", lwd = 3)
> > ```
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Jan 24 20:57:58 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 24 Jan 2021 20:57:58 +0100
Subject: [R] How to find when a value is reached given a function?
Message-ID: <CAMk+s2SkC8k24XvB_1=dx0xXEdTwAjYJK8++8YLuHu8WCvRtbA@mail.gmail.com>

Hello
I am trying to simulate a PCR by running a logistic equation. So I set
the function:
```
PCR <- function(initCopy, dupRate, Carry) {
  ROI_T = initCopy
  A = array()
  for (i in 1:45) {
    ROI_TplusOne <- ROI_T * dupRate * (1 - ROI_T/Carry)
    A[i] <- ROI_TplusOne
    ROI_T <- ROI_TplusOne
  }
  return(A)
}
```
Which returns an array that follows the logistic shape, for instance
```
d <- 2
K <- 10^13
A_0 <- 10000
PCR_array <- PCR(A_0, d, K)
plot(PCR_array)
```
Given the formula `ROI_TplusOne <- ROI_T * dupRate * (1 -
ROI_T/Carry)`, is it possible to determine at what time point `i` a
given threshold is reached? For instance, what fractional value of i
returns 1000 000 copies?
Thank you


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jan 24 21:40:06 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 24 Jan 2021 15:40:06 -0500
Subject: [R] How to find when a value is reached given a function?
In-Reply-To: <CAMk+s2SkC8k24XvB_1=dx0xXEdTwAjYJK8++8YLuHu8WCvRtbA@mail.gmail.com>
References: <CAMk+s2SkC8k24XvB_1=dx0xXEdTwAjYJK8++8YLuHu8WCvRtbA@mail.gmail.com>
Message-ID: <bb2d9d58-ed78-b73c-18ce-69017f71b4ad@gmail.com>

On 24/01/2021 2:57 p.m., Luigi Marongiu wrote:
> Hello
> I am trying to simulate a PCR by running a logistic equation. So I set
> the function:
> ```
> PCR <- function(initCopy, dupRate, Carry) {
>    ROI_T = initCopy
>    A = array()
>    for (i in 1:45) {
>      ROI_TplusOne <- ROI_T * dupRate * (1 - ROI_T/Carry)
>      A[i] <- ROI_TplusOne
>      ROI_T <- ROI_TplusOne
>    }
>    return(A)
> }
> ```
> Which returns an array that follows the logistic shape, for instance
> ```
> d <- 2
> K <- 10^13
> A_0 <- 10000
> PCR_array <- PCR(A_0, d, K)
> plot(PCR_array)
> ```
> Given the formula `ROI_TplusOne <- ROI_T * dupRate * (1 -
> ROI_T/Carry)`, is it possible to determine at what time point `i` a
> given threshold is reached? For instance, what fractional value of i
> returns 1000 000 copies?

There are two answers:

The brute force answer is just to try it and count how far you need to 
go.  This is really simple, but really inefficient.

The faster and more elegant way is to solve the recursive relation for 
an explicit solution.  You've got a quadratic recurrence relation; 
there's no general solution to those, but there are solutions in special 
cases.  See https://math.stackexchange.com/q/3179834 and links therein 
for some hints.

Duncan Murdoch


From @tyen @end|ng |rom ntu@edu@tw  Mon Jan 25 07:14:46 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 25 Jan 2021 14:14:46 +0800
Subject: [R] Calling procedures
Message-ID: <abc834b6-d33a-7a66-b6a5-db62088816be@ntu.edu.tw>

Dear All

Below are calls to functions to calculate bivariate and univariate 
logistic probabilities.It works for the following sample program (with 
results p1=p2 and p3=p4), but similar calls in a more elaborated program 
produced unpredicted results.

My question is whether I am doing something bad (which I should avoid) 
in my calls to mycdf2 and mycdf to obtain p2 and p3, respectively. Thank 
you.

Steven Yen

pbivlogis <- function(x,y,rho){
# *********************************************
# Bivariate logistic CDF
# *********************************************
 ? p<-(1+exp(-x)+exp(-y)+(1-rho)*exp(-x-y))^(-1)
return(p)
}

mycdf <- function(q,logistic=FALSE){
# *********************************************
# Univariate CDF: normal or logistic
# *********************************************
 ? if(!logistic){
 ??? p<-pnorm(q)
 ? } else {
 ??? p<-plogis(q)
 ? }
return(p)
}

mycdf2 <- function(x,y,rho,logistic=FALSE){
# *********************************************
# Calling bivariate CDF: normal or logistic
# *********************************************
 ? if(!logistic){
 ??? p<-pbivnorm(x,y,rho,recycle=T)
 ? } else {
 ??? p<-pbivlogis(x,y,rho)
 ? }
return(p)
}

set.seed(123)
x<-runif(n=5,min=-3,max=3)
y<-runif(n=5,min=-2,max=4)
rho<-0.5

p1<-pbivlogis(x,y,rho); p1
p2<-mycdf2(x,y,rho,logistic=TRUE); p2

p3<-mycdf(x,logistic=T); p3
p4<-plogis(x); p4

Results

 > set.seed(123)
 > x<-runif(n=5,min=-3,max=3)
 > y<-runif(n=5,min=-2,max=4)
 > rho<-0.5
 > p1<-pbivlogis(x,y,rho); p1
[1] 0.04937376 0.65977865 0.35821101 0.72243120 0.63881214
 > p2<-mycdf2(x,y,rho,logistic=TRUE); p2
[1] 0.04937376 0.65977865 0.35821101 0.72243120 0.63881214
 > p3<-mycdf(x,logistic=T); p3
[1] 0.2184819 0.8493908 0.3667608 0.9087199 0.9335661
 > p4<-plogis(x); p4
[1] 0.2184819 0.8493908 0.3667608 0.9087199 0.9335661
 >


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jan 25 09:59:43 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 25 Jan 2021 08:59:43 +0000
Subject: [R] Calling procedures
In-Reply-To: <abc834b6-d33a-7a66-b6a5-db62088816be@ntu.edu.tw>
References: <abc834b6-d33a-7a66-b6a5-db62088816be@ntu.edu.tw>
Message-ID: <1bd5119a-f71d-3287-445e-3838ed9ee25b@sapo.pt>

Hello,

I am not seeing errors, except that you haven't posted the code for 
pbivnorm. Do you have a variable named T somewhere? Don't abbreviate 
TRUE to T in more complex code. Or FALSE to F.

And both functions mycdf and mycdf2 could be simplified.


mycdf <- function(q,logistic=FALSE){
   # *********************************************
   # Univariate CDF: normal or logistic
   # *********************************************
   if(!logistic){
     pnorm(q)
   } else {
     plogis(q)
   }
}

mycdf2 <- function(x,y,rho,logistic=FALSE){
   # *********************************************
   # Calling bivariate CDF: normal or logistic
   # *********************************************
   if(!logistic){
     pbivnorm(x,y,rho,recycle=TRUE)
   } else {
     pbivlogis(x,y,rho)
   }
}

As one-liners:


mycdf <- function(q,logistic=FALSE){
   # *********************************************
   # Univariate CDF: normal or logistic
   # *********************************************
   if(logistic) plogis(q) else pnorm(q)
}

mycdf2 <- function(x,y,rho,logistic=FALSE){
   # *********************************************
   # Calling bivariate CDF: normal or logistic
   # *********************************************
   if(logistic) pbivlogis(x,y,rho) else pbivnorm(x,y,rho,recycle=TRUE)
}


Hope this helps,

Rui Barradas

?s 06:14 de 25/01/21, Steven Yen escreveu:
> Dear All
> 
> Below are calls to functions to calculate bivariate and univariate 
> logistic probabilities.It works for the following sample program (with 
> results p1=p2 and p3=p4), but similar calls in a more elaborated program 
> produced unpredicted results.
> 
> My question is whether I am doing something bad (which I should avoid) 
> in my calls to mycdf2 and mycdf to obtain p2 and p3, respectively. Thank 
> you.
> 
> Steven Yen
> 
> pbivlogis <- function(x,y,rho){
> # *********************************************
> # Bivariate logistic CDF
> # *********************************************
>  ? p<-(1+exp(-x)+exp(-y)+(1-rho)*exp(-x-y))^(-1)
> return(p)
> }
> 
> mycdf <- function(q,logistic=FALSE){
> # *********************************************
> # Univariate CDF: normal or logistic
> # *********************************************
>  ? if(!logistic){
>  ??? p<-pnorm(q)
>  ? } else {
>  ??? p<-plogis(q)
>  ? }
> return(p)
> }
> 
> mycdf2 <- function(x,y,rho,logistic=FALSE){
> # *********************************************
> # Calling bivariate CDF: normal or logistic
> # *********************************************
>  ? if(!logistic){
>  ??? p<-pbivnorm(x,y,rho,recycle=T)
>  ? } else {
>  ??? p<-pbivlogis(x,y,rho)
>  ? }
> return(p)
> }
> 
> set.seed(123)
> x<-runif(n=5,min=-3,max=3)
> y<-runif(n=5,min=-2,max=4)
> rho<-0.5
> 
> p1<-pbivlogis(x,y,rho); p1
> p2<-mycdf2(x,y,rho,logistic=TRUE); p2
> 
> p3<-mycdf(x,logistic=T); p3
> p4<-plogis(x); p4
> 
> Results
> 
>  > set.seed(123)
>  > x<-runif(n=5,min=-3,max=3)
>  > y<-runif(n=5,min=-2,max=4)
>  > rho<-0.5
>  > p1<-pbivlogis(x,y,rho); p1
> [1] 0.04937376 0.65977865 0.35821101 0.72243120 0.63881214
>  > p2<-mycdf2(x,y,rho,logistic=TRUE); p2
> [1] 0.04937376 0.65977865 0.35821101 0.72243120 0.63881214
>  > p3<-mycdf(x,logistic=T); p3
> [1] 0.2184819 0.8493908 0.3667608 0.9087199 0.9335661
>  > p4<-plogis(x); p4
> [1] 0.2184819 0.8493908 0.3667608 0.9087199 0.9335661
>  >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kr|@@|evdh @end|ng |rom gm@||@com  Mon Jan 25 14:57:18 2021
From: kr|@@|evdh @end|ng |rom gm@||@com (krissievdh)
Date: Mon, 25 Jan 2021 14:57:18 +0100
Subject: [R] make new collumns with conditions
Message-ID: <CAJTGnj=prpgqdXL0Hgwj_qOpr+aOau6oS0CVihdDcgMcR0Qzbg@mail.gmail.com>

Hi,

I have a dataset (d_vigi)with this kind of data:
behavior type duration(s) observation nr species
Non-vigilant 5 1 red deer
Vigilant 2 1 red deer
Vigilant 2 1 red deer
Non-vigilant 3 1 red deer
Vigilant 7 2 red deer
Vigilant 2 2 red deer
Non-vigilant 1 2 red deer
Unkown  2 2 red deer
Now I have to calculate the percentage of vigilant behavior spent per
observation.

So eventually I will need to end up with something like this:
Observation nr Species vigilant(s) total (s) percentage of vigilant (%)
1 red deer 4 12 33
2 red deer 9 12 75


Now I know how to calculate the total amount of seconds per observation.
But I don't know how I get to the total seconds of vigilant behavior per
observation (red numbers). If I could get there I will know how to
calculate the percentage.


I calculated the total duration per observation this way:
for(id in d_vigi$Obs.nr){

d_vigi$t.duration[d_vigi$Obs.nr==id]<-sum(d_vigi$'Duration.(s).x'[d_vigi$Obs.nr==id])
}

this does work and gives me the total (s) but i don't know how to get to
the sum of the seconds just for the vigilant per observation number. Is
there anyone who could help me?

Thanks,
Krissie

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Jan 25 15:05:29 2021
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 25 Jan 2021 14:05:29 +0000
Subject: [R] make new collumns with conditions
In-Reply-To: <CAJTGnj=prpgqdXL0Hgwj_qOpr+aOau6oS0CVihdDcgMcR0Qzbg@mail.gmail.com>
References: <CAJTGnj=prpgqdXL0Hgwj_qOpr+aOau6oS0CVihdDcgMcR0Qzbg@mail.gmail.com>
Message-ID: <8ef2263d-bee3-6e08-7623-fb2154416efc@dewey.myzen.co.uk>

Dear Krissie

I think you may be looking for the aggregate command.

Note that this is a plain text list so if you post in HTML we do not see 
what you see. In this case we did not see any red numbers.

Michael

On 25/01/2021 13:57, krissievdh wrote:
> Hi,
> 
> I have a dataset (d_vigi)with this kind of data:
> behavior type duration(s) observation nr species
> Non-vigilant 5 1 red deer
> Vigilant 2 1 red deer
> Vigilant 2 1 red deer
> Non-vigilant 3 1 red deer
> Vigilant 7 2 red deer
> Vigilant 2 2 red deer
> Non-vigilant 1 2 red deer
> Unkown  2 2 red deer
> Now I have to calculate the percentage of vigilant behavior spent per
> observation.
> 
> So eventually I will need to end up with something like this:
> Observation nr Species vigilant(s) total (s) percentage of vigilant (%)
> 1 red deer 4 12 33
> 2 red deer 9 12 75
> 
> 
> Now I know how to calculate the total amount of seconds per observation.
> But I don't know how I get to the total seconds of vigilant behavior per
> observation (red numbers). If I could get there I will know how to
> calculate the percentage.
> 
> 
> I calculated the total duration per observation this way:
> for(id in d_vigi$Obs.nr){
> 
> d_vigi$t.duration[d_vigi$Obs.nr==id]<-sum(d_vigi$'Duration.(s).x'[d_vigi$Obs.nr==id])
> }
> 
> this does work and gives me the total (s) but i don't know how to get to
> the sum of the seconds just for the vigilant per observation number. Is
> there anyone who could help me?
> 
> Thanks,
> Krissie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Jan 25 15:20:50 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 25 Jan 2021 15:20:50 +0100
Subject: [R] How to find when a value is reached given a function?
In-Reply-To: <bb2d9d58-ed78-b73c-18ce-69017f71b4ad@gmail.com>
References: <CAMk+s2SkC8k24XvB_1=dx0xXEdTwAjYJK8++8YLuHu8WCvRtbA@mail.gmail.com>
 <bb2d9d58-ed78-b73c-18ce-69017f71b4ad@gmail.com>
Message-ID: <CAMk+s2T8ZTe5eSURcNw1rxeNvnmWj_iQTrWtHohFWJvtQeQHHg@mail.gmail.com>

Thanks, I'll check it out. I ran the simulation and I got:
```

t = 1, N = 20,000
t = 2, N = 40,000
t = 3, N = 80,000
t = 4, N = 160,000
t = 5, N = 320,000
t = 6, N = 640,000
t = 7, N = 1,280,000
```
Hence the answer is t=6.{...} but the problem is to get that
fractional value. Would be possible to use some kind of interpolation?
I have the known Xs (the t values), the known Ys (the Nt), I need to
get x when y is 10?

On Sun, Jan 24, 2021 at 9:40 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 24/01/2021 2:57 p.m., Luigi Marongiu wrote:
> > Hello
> > I am trying to simulate a PCR by running a logistic equation. So I set
> > the function:
> > ```
> > PCR <- function(initCopy, dupRate, Carry) {
> >    ROI_T = initCopy
> >    A = array()
> >    for (i in 1:45) {
> >      ROI_TplusOne <- ROI_T * dupRate * (1 - ROI_T/Carry)
> >      A[i] <- ROI_TplusOne
> >      ROI_T <- ROI_TplusOne
> >    }
> >    return(A)
> > }
> > ```
> > Which returns an array that follows the logistic shape, for instance
> > ```
> > d <- 2
> > K <- 10^13
> > A_0 <- 10000
> > PCR_array <- PCR(A_0, d, K)
> > plot(PCR_array)
> > ```
> > Given the formula `ROI_TplusOne <- ROI_T * dupRate * (1 -
> > ROI_T/Carry)`, is it possible to determine at what time point `i` a
> > given threshold is reached? For instance, what fractional value of i
> > returns 1000 000 copies?
>
> There are two answers:
>
> The brute force answer is just to try it and count how far you need to
> go.  This is really simple, but really inefficient.
>
> The faster and more elegant way is to solve the recursive relation for
> an explicit solution.  You've got a quadratic recurrence relation;
> there's no general solution to those, but there are solutions in special
> cases.  See https://math.stackexchange.com/q/3179834 and links therein
> for some hints.
>
> Duncan Murdoch



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Jan 25 15:46:32 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 25 Jan 2021 15:46:32 +0100
Subject: [R] How to find when a value is reached given a function?
In-Reply-To: <CAMk+s2T8ZTe5eSURcNw1rxeNvnmWj_iQTrWtHohFWJvtQeQHHg@mail.gmail.com>
References: <CAMk+s2SkC8k24XvB_1=dx0xXEdTwAjYJK8++8YLuHu8WCvRtbA@mail.gmail.com>
 <bb2d9d58-ed78-b73c-18ce-69017f71b4ad@gmail.com>
 <CAMk+s2T8ZTe5eSURcNw1rxeNvnmWj_iQTrWtHohFWJvtQeQHHg@mail.gmail.com>
Message-ID: <CAMk+s2Sd=f4YKa+cJJasKSh5KqeVX4KUSknimvfSeo80N=+FJQ@mail.gmail.com>

If I run this:
```
Y = c(10000, 20000, 40000, 80000, 160000, 320000, 640000, 1280000)
X = 0:7
plot(Y~X, log='y')
model <- lm(log10(Y) ~ X)
abline(model)
predict(model, data.frame(Y=log10(1000000)))
```
I get a funny answer:
```
      1       2       3       4       5       6       7       8
4.00000 4.30103 4.60206 4.90309 5.20412 5.50515 5.80618 6.10721
Warning message:
'newdata' had 1 row but variables found have 8 rows
```
but:
```
> data.frame(Y=log10(1000000))
  Y
1 6
```
What is the correct use?
Thank you

On Mon, Jan 25, 2021 at 3:20 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Thanks, I'll check it out. I ran the simulation and I got:
> ```
>
> t = 1, N = 20,000
> t = 2, N = 40,000
> t = 3, N = 80,000
> t = 4, N = 160,000
> t = 5, N = 320,000
> t = 6, N = 640,000
> t = 7, N = 1,280,000
> ```
> Hence the answer is t=6.{...} but the problem is to get that
> fractional value. Would be possible to use some kind of interpolation?
> I have the known Xs (the t values), the known Ys (the Nt), I need to
> get x when y is 10?
>
> On Sun, Jan 24, 2021 at 9:40 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >
> > On 24/01/2021 2:57 p.m., Luigi Marongiu wrote:
> > > Hello
> > > I am trying to simulate a PCR by running a logistic equation. So I set
> > > the function:
> > > ```
> > > PCR <- function(initCopy, dupRate, Carry) {
> > >    ROI_T = initCopy
> > >    A = array()
> > >    for (i in 1:45) {
> > >      ROI_TplusOne <- ROI_T * dupRate * (1 - ROI_T/Carry)
> > >      A[i] <- ROI_TplusOne
> > >      ROI_T <- ROI_TplusOne
> > >    }
> > >    return(A)
> > > }
> > > ```
> > > Which returns an array that follows the logistic shape, for instance
> > > ```
> > > d <- 2
> > > K <- 10^13
> > > A_0 <- 10000
> > > PCR_array <- PCR(A_0, d, K)
> > > plot(PCR_array)
> > > ```
> > > Given the formula `ROI_TplusOne <- ROI_T * dupRate * (1 -
> > > ROI_T/Carry)`, is it possible to determine at what time point `i` a
> > > given threshold is reached? For instance, what fractional value of i
> > > returns 1000 000 copies?
> >
> > There are two answers:
> >
> > The brute force answer is just to try it and count how far you need to
> > go.  This is really simple, but really inefficient.
> >
> > The faster and more elegant way is to solve the recursive relation for
> > an explicit solution.  You've got a quadratic recurrence relation;
> > there's no general solution to those, but there are solutions in special
> > cases.  See https://math.stackexchange.com/q/3179834 and links therein
> > for some hints.
> >
> > Duncan Murdoch
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jan 25 16:37:48 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 25 Jan 2021 15:37:48 +0000
Subject: [R] make new collumns with conditions
In-Reply-To: <CAJTGnj=prpgqdXL0Hgwj_qOpr+aOau6oS0CVihdDcgMcR0Qzbg@mail.gmail.com>
References: <CAJTGnj=prpgqdXL0Hgwj_qOpr+aOau6oS0CVihdDcgMcR0Qzbg@mail.gmail.com>
Message-ID: <c5abe229-4857-8383-38a5-d36473756edd@sapo.pt>

Hello,

Try the following.
First aggregate the data, then get the totals, then the percentages.
Finally, put the species in the result.


agg <- aggregate(formula = `duration(s)` ~ `observation nr` + `behavior 
type`,
                  data = d_vigi,
                  FUN = sum,
                  subset = `behavior type` == 'Vigilant')
agg$total <- tapply(d_vigi$`duration(s)`, d_vigi$`observation nr`, FUN = 
sum)
agg$percent <- round(100 * agg$`duration(s)`/agg$total)

res <- merge(agg, d_vigi[c(1, 3:4)])
res[!duplicated(res), ]


Data in dput format:


d_vigi <-
structure(list(`behavior type` = c("Non-vigilant", "Vigilant",
"Vigilant", "Non-vigilant", "Vigilant", "Vigilant", "Non-vigilant",
"Unkown"), `duration(s)` = c(5L, 2L, 2L, 3L, 7L, 2L, 1L, 2L),
     `observation nr` = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), species = 
c("red deer",
     "red deer", "red deer", "red deer", "red deer", "red deer",
     "red deer", "red deer")), class = "data.frame", row.names = c(NA,
-8L))


Hope this helps,

Rui Barradas

?s 13:57 de 25/01/21, krissievdh escreveu:
> Hi,
> 
> I have a dataset (d_vigi)with this kind of data:
> behavior type duration(s) observation nr species
> Non-vigilant 5 1 red deer
> Vigilant 2 1 red deer
> Vigilant 2 1 red deer
> Non-vigilant 3 1 red deer
> Vigilant 7 2 red deer
> Vigilant 2 2 red deer
> Non-vigilant 1 2 red deer
> Unkown  2 2 red deer
> Now I have to calculate the percentage of vigilant behavior spent per
> observation.
> 
> So eventually I will need to end up with something like this:
> Observation nr Species vigilant(s) total (s) percentage of vigilant (%)
> 1 red deer 4 12 33
> 2 red deer 9 12 75
> 
> 
> Now I know how to calculate the total amount of seconds per observation.
> But I don't know how I get to the total seconds of vigilant behavior per
> observation (red numbers). If I could get there I will know how to
> calculate the percentage.
> 
> 
> I calculated the total duration per observation this way:
> for(id in d_vigi$Obs.nr){
> 
> d_vigi$t.duration[d_vigi$Obs.nr==id]<-sum(d_vigi$'Duration.(s).x'[d_vigi$Obs.nr==id])
> }
> 
> this does work and gives me the total (s) but i don't know how to get to
> the sum of the seconds just for the vigilant per observation number. Is
> there anyone who could help me?
> 
> Thanks,
> Krissie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kr|@@|evdh @end|ng |rom gm@||@com  Mon Jan 25 17:01:54 2021
From: kr|@@|evdh @end|ng |rom gm@||@com (krissievdh)
Date: Mon, 25 Jan 2021 17:01:54 +0100
Subject: [R] make new collumns with conditions
In-Reply-To: <c5abe229-4857-8383-38a5-d36473756edd@sapo.pt>
References: <CAJTGnj=prpgqdXL0Hgwj_qOpr+aOau6oS0CVihdDcgMcR0Qzbg@mail.gmail.com>
 <c5abe229-4857-8383-38a5-d36473756edd@sapo.pt>
Message-ID: <CAJTGnjn06S0ofJJAHOo=fBXtLbeg05WQw0HByPG9BG-pdTAGnA@mail.gmail.com>

Hi,
Thanks for your response.

I do get what you're doing. However, the table I sent is just a small piece
of the complete database. So for me to have to add in everything with
structure list (c ......) by hand would be too much work.
Just to give you an idea, the database is around 16000 rows and has 40
columns with other variables that I do want to keep. So I  kind of want to
find a way to keep everything and just add a couple of columns with the
calculated time for vigilant behavior and the percentage.

Still thanks for thinking with me. I am looking into the aggregate
function. Hopefully, this could be a solution.

krissie






Op ma 25 jan. 2021 16:44 schreef Rui Barradas <ruipbarradas at sapo.pt>:

> Hello,
>
> Try the following.
> First aggregate the data, then get the totals, then the percentages.
> Finally, put the species in the result.
>
>
> agg <- aggregate(formula = `duration(s)` ~ `observation nr` + `behavior
> type`,
>                   data = d_vigi,
>                   FUN = sum,
>                   subset = `behavior type` == 'Vigilant')
> agg$total <- tapply(d_vigi$`duration(s)`, d_vigi$`observation nr`, FUN =
> sum)
> agg$percent <- round(100 * agg$`duration(s)`/agg$total)
>
> res <- merge(agg, d_vigi[c(1, 3:4)])
> res[!duplicated(res), ]
>
>
> Data in dput format:
>
>
> d_vigi <-
> structure(list(`behavior type` = c("Non-vigilant", "Vigilant",
> "Vigilant", "Non-vigilant", "Vigilant", "Vigilant", "Non-vigilant",
> "Unkown"), `duration(s)` = c(5L, 2L, 2L, 3L, 7L, 2L, 1L, 2L),
>      `observation nr` = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), species =
> c("red deer",
>      "red deer", "red deer", "red deer", "red deer", "red deer",
>      "red deer", "red deer")), class = "data.frame", row.names = c(NA,
> -8L))
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 13:57 de 25/01/21, krissievdh escreveu:
> > Hi,
> >
> > I have a dataset (d_vigi)with this kind of data:
> > behavior type duration(s) observation nr species
> > Non-vigilant 5 1 red deer
> > Vigilant 2 1 red deer
> > Vigilant 2 1 red deer
> > Non-vigilant 3 1 red deer
> > Vigilant 7 2 red deer
> > Vigilant 2 2 red deer
> > Non-vigilant 1 2 red deer
> > Unkown  2 2 red deer
> > Now I have to calculate the percentage of vigilant behavior spent per
> > observation.
> >
> > So eventually I will need to end up with something like this:
> > Observation nr Species vigilant(s) total (s) percentage of vigilant (%)
> > 1 red deer 4 12 33
> > 2 red deer 9 12 75
> >
> >
> > Now I know how to calculate the total amount of seconds per observation.
> > But I don't know how I get to the total seconds of vigilant behavior per
> > observation (red numbers). If I could get there I will know how to
> > calculate the percentage.
> >
> >
> > I calculated the total duration per observation this way:
> > for(id in d_vigi$Obs.nr){
> >
> >
> d_vigi$t.duration[d_vigi$Obs.nr==id]<-sum(d_vigi$'Duration.(s).x'[d_vigi$Obs.nr==id])
> > }
> >
> > this does work and gives me the total (s) but i don't know how to get to
> > the sum of the seconds just for the vigilant per observation number. Is
> > there anyone who could help me?
> >
> > Thanks,
> > Krissie
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From kr|@@|evdh @end|ng |rom gm@||@com  Mon Jan 25 17:29:41 2021
From: kr|@@|evdh @end|ng |rom gm@||@com (krissievdh)
Date: Mon, 25 Jan 2021 17:29:41 +0100
Subject: [R] make new collumns with conditions
In-Reply-To: <CAJTGnjn06S0ofJJAHOo=fBXtLbeg05WQw0HByPG9BG-pdTAGnA@mail.gmail.com>
References: <CAJTGnj=prpgqdXL0Hgwj_qOpr+aOau6oS0CVihdDcgMcR0Qzbg@mail.gmail.com>
 <c5abe229-4857-8383-38a5-d36473756edd@sapo.pt>
 <CAJTGnjn06S0ofJJAHOo=fBXtLbeg05WQw0HByPG9BG-pdTAGnA@mail.gmail.com>
Message-ID: <CAJTGnjnuwPg=M+0Eag46Px=w-Bj2=oOFFpq4YXqL17ifmbsDcA@mail.gmail.com>

Hi,

So one thing i could manage to do was this:

d_vigi$combi <- paste(d_vigi$Behavioral.category, d_vigi$Obs.nr, sep = "-")

This created a new column with a combination of the category and the
observation number.
Afterwards I did this:
for(id in d_vigi$combi){

d_vigi$durationpercat[d_vigi$combi==id]<-sum(d_vigi$'Duration.(s).x'[d_vigi$combi==id])
}

So this created another new column with the correct duration per category.
So that means that I have this:
behavior Behavioral category  Duration Obs nr species combi durationpercat
Non-vigilant 5 1 red deer Non-vigilant-1 8
Vigilant 2 1 red deer Vigilant-1 4
Vigilant 2 1 red deer Vigilant-1 4
Non-vigilant 3 1 red deer Non-vigilant-1 8
Vigilant 7 2 red deer Vigilant-2 9
Vigilant 2 2 red deer Vigilant-2 9
Non-vigilant 1 2 red deer Non-vigilant-2 1
Unknown  2 2 red deer Unknown-2 2
However, this doesn't work for me further along the line. I have to have
the duration for vigilant behaviour in a separate column. I really don't
know how to get there.

Hopefully, you understand where my problem lies. So I kinda need to have
three columns for vigilant, non-vigilant and unknown. That way I could add
in zero's for the observations where there weren't any vigilant behaviour.

Krissie

Op ma 25 jan. 2021 om 17:01 schreef krissievdh <krissievdh at gmail.com>:

> Hi,
> Thanks for your response.
>
> I do get what you're doing. However, the table I sent is just a small
> piece of the complete database. So for me to have to add in everything with
> structure list (c ......) by hand would be too much work.
> Just to give you an idea, the database is around 16000 rows and has 40
> columns with other variables that I do want to keep. So I  kind of want to
> find a way to keep everything and just add a couple of columns with the
> calculated time for vigilant behavior and the percentage.
>
> Still thanks for thinking with me. I am looking into the aggregate
> function. Hopefully, this could be a solution.
>
> krissie
>
>
>
>
>
>
> Op ma 25 jan. 2021 16:44 schreef Rui Barradas <ruipbarradas at sapo.pt>:
>
>> Hello,
>>
>> Try the following.
>> First aggregate the data, then get the totals, then the percentages.
>> Finally, put the species in the result.
>>
>>
>> agg <- aggregate(formula = `duration(s)` ~ `observation nr` + `behavior
>> type`,
>>                   data = d_vigi,
>>                   FUN = sum,
>>                   subset = `behavior type` == 'Vigilant')
>> agg$total <- tapply(d_vigi$`duration(s)`, d_vigi$`observation nr`, FUN =
>> sum)
>> agg$percent <- round(100 * agg$`duration(s)`/agg$total)
>>
>> res <- merge(agg, d_vigi[c(1, 3:4)])
>> res[!duplicated(res), ]
>>
>>
>> Data in dput format:
>>
>>
>> d_vigi <-
>> structure(list(`behavior type` = c("Non-vigilant", "Vigilant",
>> "Vigilant", "Non-vigilant", "Vigilant", "Vigilant", "Non-vigilant",
>> "Unkown"), `duration(s)` = c(5L, 2L, 2L, 3L, 7L, 2L, 1L, 2L),
>>      `observation nr` = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), species =
>> c("red deer",
>>      "red deer", "red deer", "red deer", "red deer", "red deer",
>>      "red deer", "red deer")), class = "data.frame", row.names = c(NA,
>> -8L))
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 13:57 de 25/01/21, krissievdh escreveu:
>> > Hi,
>> >
>> > I have a dataset (d_vigi)with this kind of data:
>> > behavior type duration(s) observation nr species
>> > Non-vigilant 5 1 red deer
>> > Vigilant 2 1 red deer
>> > Vigilant 2 1 red deer
>> > Non-vigilant 3 1 red deer
>> > Vigilant 7 2 red deer
>> > Vigilant 2 2 red deer
>> > Non-vigilant 1 2 red deer
>> > Unkown  2 2 red deer
>> > Now I have to calculate the percentage of vigilant behavior spent per
>> > observation.
>> >
>> > So eventually I will need to end up with something like this:
>> > Observation nr Species vigilant(s) total (s) percentage of vigilant (%)
>> > 1 red deer 4 12 33
>> > 2 red deer 9 12 75
>> >
>> >
>> > Now I know how to calculate the total amount of seconds per observation.
>> > But I don't know how I get to the total seconds of vigilant behavior per
>> > observation (red numbers). If I could get there I will know how to
>> > calculate the percentage.
>> >
>> >
>> > I calculated the total duration per observation this way:
>> > for(id in d_vigi$Obs.nr){
>> >
>> >
>> d_vigi$t.duration[d_vigi$Obs.nr==id]<-sum(d_vigi$'Duration.(s).x'[d_vigi$Obs.nr==id])
>> > }
>> >
>> > this does work and gives me the total (s) but i don't know how to get to
>> > the sum of the seconds just for the vigilant per observation number. Is
>> > there anyone who could help me?
>> >
>> > Thanks,
>> > Krissie
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Jan 25 18:33:03 2021
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 25 Jan 2021 17:33:03 +0000
Subject: [R] make new collumns with conditions
In-Reply-To: <CAJTGnjn06S0ofJJAHOo=fBXtLbeg05WQw0HByPG9BG-pdTAGnA@mail.gmail.com>
References: <CAJTGnj=prpgqdXL0Hgwj_qOpr+aOau6oS0CVihdDcgMcR0Qzbg@mail.gmail.com>
 <c5abe229-4857-8383-38a5-d36473756edd@sapo.pt>
 <CAJTGnjn06S0ofJJAHOo=fBXtLbeg05WQw0HByPG9BG-pdTAGnA@mail.gmail.com>
Message-ID: <62667abc-e20a-7946-8773-d8d2e3c39f6f@dewey.myzen.co.uk>

Dear Krissie

I think you misunderstood Rui's response. He was generating some fake 
data to test the code not suggesting you rebuild your data frame.

Michael

On 25/01/2021 16:01, krissievdh wrote:
> Hi,
> Thanks for your response.
> 
> I do get what you're doing. However, the table I sent is just a small piece
> of the complete database. So for me to have to add in everything with
> structure list (c ......) by hand would be too much work.
> Just to give you an idea, the database is around 16000 rows and has 40
> columns with other variables that I do want to keep. So I  kind of want to
> find a way to keep everything and just add a couple of columns with the
> calculated time for vigilant behavior and the percentage.
> 
> Still thanks for thinking with me. I am looking into the aggregate
> function. Hopefully, this could be a solution.
> 
> krissie
> 
> 
> 
> 
> 
> 
> Op ma 25 jan. 2021 16:44 schreef Rui Barradas <ruipbarradas at sapo.pt>:
> 
>> Hello,
>>
>> Try the following.
>> First aggregate the data, then get the totals, then the percentages.
>> Finally, put the species in the result.
>>
>>
>> agg <- aggregate(formula = `duration(s)` ~ `observation nr` + `behavior
>> type`,
>>                    data = d_vigi,
>>                    FUN = sum,
>>                    subset = `behavior type` == 'Vigilant')
>> agg$total <- tapply(d_vigi$`duration(s)`, d_vigi$`observation nr`, FUN =
>> sum)
>> agg$percent <- round(100 * agg$`duration(s)`/agg$total)
>>
>> res <- merge(agg, d_vigi[c(1, 3:4)])
>> res[!duplicated(res), ]
>>
>>
>> Data in dput format:
>>
>>
>> d_vigi <-
>> structure(list(`behavior type` = c("Non-vigilant", "Vigilant",
>> "Vigilant", "Non-vigilant", "Vigilant", "Vigilant", "Non-vigilant",
>> "Unkown"), `duration(s)` = c(5L, 2L, 2L, 3L, 7L, 2L, 1L, 2L),
>>       `observation nr` = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), species =
>> c("red deer",
>>       "red deer", "red deer", "red deer", "red deer", "red deer",
>>       "red deer", "red deer")), class = "data.frame", row.names = c(NA,
>> -8L))
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 13:57 de 25/01/21, krissievdh escreveu:
>>> Hi,
>>>
>>> I have a dataset (d_vigi)with this kind of data:
>>> behavior type duration(s) observation nr species
>>> Non-vigilant 5 1 red deer
>>> Vigilant 2 1 red deer
>>> Vigilant 2 1 red deer
>>> Non-vigilant 3 1 red deer
>>> Vigilant 7 2 red deer
>>> Vigilant 2 2 red deer
>>> Non-vigilant 1 2 red deer
>>> Unkown  2 2 red deer
>>> Now I have to calculate the percentage of vigilant behavior spent per
>>> observation.
>>>
>>> So eventually I will need to end up with something like this:
>>> Observation nr Species vigilant(s) total (s) percentage of vigilant (%)
>>> 1 red deer 4 12 33
>>> 2 red deer 9 12 75
>>>
>>>
>>> Now I know how to calculate the total amount of seconds per observation.
>>> But I don't know how I get to the total seconds of vigilant behavior per
>>> observation (red numbers). If I could get there I will know how to
>>> calculate the percentage.
>>>
>>>
>>> I calculated the total duration per observation this way:
>>> for(id in d_vigi$Obs.nr){
>>>
>>>
>> d_vigi$t.duration[d_vigi$Obs.nr==id]<-sum(d_vigi$'Duration.(s).x'[d_vigi$Obs.nr==id])
>>> }
>>>
>>> this does work and gives me the total (s) but i don't know how to get to
>>> the sum of the seconds just for the vigilant per observation number. Is
>>> there anyone who could help me?
>>>
>>> Thanks,
>>> Krissie
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jan 25 18:59:01 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 25 Jan 2021 17:59:01 +0000
Subject: [R] make new collumns with conditions
In-Reply-To: <62667abc-e20a-7946-8773-d8d2e3c39f6f@dewey.myzen.co.uk>
References: <CAJTGnj=prpgqdXL0Hgwj_qOpr+aOau6oS0CVihdDcgMcR0Qzbg@mail.gmail.com>
 <c5abe229-4857-8383-38a5-d36473756edd@sapo.pt>
 <CAJTGnjn06S0ofJJAHOo=fBXtLbeg05WQw0HByPG9BG-pdTAGnA@mail.gmail.com>
 <62667abc-e20a-7946-8773-d8d2e3c39f6f@dewey.myzen.co.uk>
Message-ID: <de0d721b-9ce0-9866-6353-975407cdb7d2@sapo.pt>

Hello,

Michael, you're is almost right. I copy&pasted the OP's data but with so 
many blank spaces I had to put single quotes around those values and 
column names. Then, when I wrote the answer, I also posted the output of

dput(d_vigi)

so that others that might want to give it a try would have their job 
made easier.

To the OP: the code before "Data in dput format:" is a proposed 
solution, not the structure(list(etc)), like Michael says.
If you run that statement, you will see the data as you've posted it, 
even with the original column names.

Hope this helps,

Rui Barradas


?s 17:33 de 25/01/21, Michael Dewey escreveu:
> Dear Krissie
> 
> I think you misunderstood Rui's response. He was generating some fake 
> data to test the code not suggesting you rebuild your data frame.
> 
> Michael
> 
> On 25/01/2021 16:01, krissievdh wrote:
>> Hi,
>> Thanks for your response.
>>
>> I do get what you're doing. However, the table I sent is just a small 
>> piece
>> of the complete database. So for me to have to add in everything with
>> structure list (c ......) by hand would be too much work.
>> Just to give you an idea, the database is around 16000 rows and has 40
>> columns with other variables that I do want to keep. So I? kind of 
>> want to
>> find a way to keep everything and just add a couple of columns with the
>> calculated time for vigilant behavior and the percentage.
>>
>> Still thanks for thinking with me. I am looking into the aggregate
>> function. Hopefully, this could be a solution.
>>
>> krissie
>>
>>
>>
>>
>>
>>
>> Op ma 25 jan. 2021 16:44 schreef Rui Barradas <ruipbarradas at sapo.pt>:
>>
>>> Hello,
>>>
>>> Try the following.
>>> First aggregate the data, then get the totals, then the percentages.
>>> Finally, put the species in the result.
>>>
>>>
>>> agg <- aggregate(formula = `duration(s)` ~ `observation nr` + `behavior
>>> type`,
>>> ?????????????????? data = d_vigi,
>>> ?????????????????? FUN = sum,
>>> ?????????????????? subset = `behavior type` == 'Vigilant')
>>> agg$total <- tapply(d_vigi$`duration(s)`, d_vigi$`observation nr`, FUN =
>>> sum)
>>> agg$percent <- round(100 * agg$`duration(s)`/agg$total)
>>>
>>> res <- merge(agg, d_vigi[c(1, 3:4)])
>>> res[!duplicated(res), ]
>>>
>>>
>>> Data in dput format:
>>>
>>>
>>> d_vigi <-
>>> structure(list(`behavior type` = c("Non-vigilant", "Vigilant",
>>> "Vigilant", "Non-vigilant", "Vigilant", "Vigilant", "Non-vigilant",
>>> "Unkown"), `duration(s)` = c(5L, 2L, 2L, 3L, 7L, 2L, 1L, 2L),
>>> ????? `observation nr` = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), species =
>>> c("red deer",
>>> ????? "red deer", "red deer", "red deer", "red deer", "red deer",
>>> ????? "red deer", "red deer")), class = "data.frame", row.names = c(NA,
>>> -8L))
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> ?s 13:57 de 25/01/21, krissievdh escreveu:
>>>> Hi,
>>>>
>>>> I have a dataset (d_vigi)with this kind of data:
>>>> behavior type duration(s) observation nr species
>>>> Non-vigilant 5 1 red deer
>>>> Vigilant 2 1 red deer
>>>> Vigilant 2 1 red deer
>>>> Non-vigilant 3 1 red deer
>>>> Vigilant 7 2 red deer
>>>> Vigilant 2 2 red deer
>>>> Non-vigilant 1 2 red deer
>>>> Unkown? 2 2 red deer
>>>> Now I have to calculate the percentage of vigilant behavior spent per
>>>> observation.
>>>>
>>>> So eventually I will need to end up with something like this:
>>>> Observation nr Species vigilant(s) total (s) percentage of vigilant (%)
>>>> 1 red deer 4 12 33
>>>> 2 red deer 9 12 75
>>>>
>>>>
>>>> Now I know how to calculate the total amount of seconds per 
>>>> observation.
>>>> But I don't know how I get to the total seconds of vigilant behavior 
>>>> per
>>>> observation (red numbers). If I could get there I will know how to
>>>> calculate the percentage.
>>>>
>>>>
>>>> I calculated the total duration per observation this way:
>>>> for(id in d_vigi$Obs.nr){
>>>>
>>>>
>>> d_vigi$t.duration[d_vigi$Obs.nr==id]<-sum(d_vigi$'Duration.(s).x'[d_vigi$Obs.nr==id]) 
>>>
>>>> }
>>>>
>>>> this does work and gives me the total (s) but i don't know how to 
>>>> get to
>>>> the sum of the seconds just for the vigilant per observation number. Is
>>>> there anyone who could help me?
>>>>
>>>> Thanks,
>>>> Krissie
>>>>
>>>> ?????? [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From c@ghpm @end|ng |rom gm@||@com  Mon Jan 25 23:40:45 2021
From: c@ghpm @end|ng |rom gm@||@com (Carlos Gonzalez)
Date: Mon, 25 Jan 2021 19:40:45 -0300
Subject: [R] problem installing R and RStudio
Message-ID: <CAGa55hQAOBEXX6fXL=Usjn+N=CS_SDYN0+2gKKpVEBNfVn4UKw@mail.gmail.com>

Dear,

I've just installed R and RStudio. Opening RStudio the following appears in
the console.


R version 4.0.3 (2020-10-10) -- "Bunny-Wunnies Freak Out"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Error: package or namespace load failed for ?stats? in inDL(x,
as.logical(local), as.logical(now), ...):
 unable to load shared object 'C:/Program
Files/R/R-4.0.3/library/stats/libs/x64/stats.dll':
  LoadLibrary failure:  The specified module could not be found.

During startup - Warning message:
package ?stats? in options("defaultPackages") was not found
Error in inDL(x, as.logical(local), as.logical(now), ...) :
  unable to load shared object 'C:/Program
Files/R/R-4.0.3/library/stats/libs/x64/stats.dll':
  LoadLibrary failure:  The specified module could not be found.
>
I would very much appreciate it if you could help solving this problem.

Saludos / Regards

Carlos A. Gonzalez
Mobile +598 94 234 653
caghpm at gmail.com

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 26 01:42:34 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 25 Jan 2021 16:42:34 -0800
Subject: [R] problem installing R and RStudio
In-Reply-To: <CAGa55hQAOBEXX6fXL=Usjn+N=CS_SDYN0+2gKKpVEBNfVn4UKw@mail.gmail.com>
References: <CAGa55hQAOBEXX6fXL=Usjn+N=CS_SDYN0+2gKKpVEBNfVn4UKw@mail.gmail.com>
Message-ID: <2422CF04-32DF-4EE2-B406-3CFEEA00B806@dcn.davis.ca.us>

Your installation of R seems broken. Since RStudio sometimes tries to simplify things and sometimes misses and we aren't typically up to speed with their latest procedures, please describe what you did to install R in terms related to the instructions on CRAN [1] and its install program. When you can run R from RGui or the CMD prompt then you may get lucky and RStudio will just work. If you aren't lucky connecting your working R to RStudio  then you will probably need to ask them [2] for assistance.

Also, the Posting Guide points out that this is a plain text mailing list... sending HTML email through this list is erratic... if you want to insure we get your message as you sent it, set your email client to send plain text format.

[1] https://cran.r-project.org/bin/windows/base/
[2] https://community.rstudio.com/

On January 25, 2021 2:40:45 PM PST, Carlos Gonzalez <caghpm at gmail.com> wrote:
>Dear,
>
>I've just installed R and RStudio. Opening RStudio the following
>appears in
>the console.
>
>
>R version 4.0.3 (2020-10-10) -- "Bunny-Wunnies Freak Out"
>Copyright (C) 2020 The R Foundation for Statistical Computing
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>R is free software and comes with ABSOLUTELY NO WARRANTY.
>You are welcome to redistribute it under certain conditions.
>Type 'license()' or 'licence()' for distribution details.
>
>  Natural language support but running in an English locale
>
>R is a collaborative project with many contributors.
>Type 'contributors()' for more information and
>'citation()' on how to cite R or R packages in publications.
>
>Type 'demo()' for some demos, 'help()' for on-line help, or
>'help.start()' for an HTML browser interface to help.
>Type 'q()' to quit R.
>
>Error: package or namespace load failed for ?stats? in inDL(x,
>as.logical(local), as.logical(now), ...):
> unable to load shared object 'C:/Program
>Files/R/R-4.0.3/library/stats/libs/x64/stats.dll':
>  LoadLibrary failure:  The specified module could not be found.
>
>During startup - Warning message:
>package ?stats? in options("defaultPackages") was not found
>Error in inDL(x, as.logical(local), as.logical(now), ...) :
>  unable to load shared object 'C:/Program
>Files/R/R-4.0.3/library/stats/libs/x64/stats.dll':
>  LoadLibrary failure:  The specified module could not be found.
>>
>I would very much appreciate it if you could help solving this problem.
>
>Saludos / Regards
>
>Carlos A. Gonzalez
>Mobile +598 94 234 653
>caghpm at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Tue Jan 26 01:52:43 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 26 Jan 2021 13:52:43 +1300
Subject: [R] How to find when a value is reached given a function?
In-Reply-To: <CAMk+s2SkC8k24XvB_1=dx0xXEdTwAjYJK8++8YLuHu8WCvRtbA@mail.gmail.com>
References: <CAMk+s2SkC8k24XvB_1=dx0xXEdTwAjYJK8++8YLuHu8WCvRtbA@mail.gmail.com>
Message-ID: <CAB8pepy-9Waj5skNyv8VDUBVbrVyPzCy3G7j0upbJwexPMH_LA@mail.gmail.com>

You could use a spline to interpolate the points.
(And I'd consider increasing the number of points if possible, say to 200).

Then use a root finder, such as uniroot(), to solve for
f(i) - k
Where, k (a constant), would be 1e6, based on your example.

There are a number of variations on this approach.
My kubik package provides a solve method, and can impose some constraints.

----
library (kubik)
f <- chs (1:45, round (PCR_array),
    constraints = chs.constraints (increasing=TRUE) )
plot (f)

sol <- solve (f, 1e6)
abline (v=sol, lty=2)
sol
----

Note that I had to round the values, in order to impose a
non-decreasing constraint.

Also note that I've just used the 45 points.
But re-iterating, you should increase the number of points, if possible.


On Mon, Jan 25, 2021 at 8:58 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello
> I am trying to simulate a PCR by running a logistic equation. So I set
> the function:
> ```
> PCR <- function(initCopy, dupRate, Carry) {
>   ROI_T = initCopy
>   A = array()
>   for (i in 1:45) {
>     ROI_TplusOne <- ROI_T * dupRate * (1 - ROI_T/Carry)
>     A[i] <- ROI_TplusOne
>     ROI_T <- ROI_TplusOne
>   }
>   return(A)
> }
> ```
> Which returns an array that follows the logistic shape, for instance
> ```
> d <- 2
> K <- 10^13
> A_0 <- 10000
> PCR_array <- PCR(A_0, d, K)
> plot(PCR_array)
> ```
> Given the formula `ROI_TplusOne <- ROI_T * dupRate * (1 -
> ROI_T/Carry)`, is it possible to determine at what time point `i` a
> given threshold is reached? For instance, what fractional value of i
> returns 1000 000 copies?
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rce| @end|ng |rom coeurd@rt|ch@ut@ch  Tue Jan 26 08:55:48 2021
From: m@rce| @end|ng |rom coeurd@rt|ch@ut@ch (Marcel Baumgartner)
Date: Tue, 26 Jan 2021 08:55:48 +0100
Subject: [R] Error when calling R from Python
Message-ID: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>

Dear all,

my colleague posted our issue on stackoverflow:

Calling R script from Python does not save log file in version 4 -
Stack Overflow
[https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]

It is about this kind of call to R:

R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1".

The issue is that the log.txt file is not created when running R
4.x.x. The same code works perfectly fine with R 3.6.x. 

Any idea what's going wrong as of version 4? Regards Marcel?



	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jan 26 10:11:39 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 26 Jan 2021 10:11:39 +0100
Subject: [R] How to predict/interpolate new Y given knwon Xs and Ys?
Message-ID: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>

Hello,
I have a series of x/y and a model. I can interpolate a new value of x
using this model, but I get funny results if I give the y and look for
the correspondent x:
```
> x = 1:10
> y = 2*x+15
> model <- lm(y~x)
> predict(model, data.frame(x=7.5))
 1
30
> predict(model, data.frame(y=26))
 1  2  3  4  5  6  7  8  9 10
17 19 21 23 25 27 29 31 33 35
Warning message:
'newdata' had 1 row but variables found have 10 rows
> data.frame(x=7.5)
    x
1 7.5
> data.frame(y=26)
   y
1 26
```
what is the correct syntax?
Thank you
Luigi


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 26 10:20:20 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 26 Jan 2021 01:20:20 -0800
Subject: [R] How to predict/interpolate new Y given knwon Xs and Ys?
In-Reply-To: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>
References: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>
Message-ID: <8799A845-AA66-4DFF-ADB1-55B24229936D@dcn.davis.ca.us>

model2 <- lm( x~y )
predict(model2, data.frame(y=26))

model2 is however not the inverse of model... if you need that then you need to handle that some other way than using predict, such as an invertible monotonic spline (or in this case a little algebra).

On January 26, 2021 1:11:39 AM PST, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>Hello,
>I have a series of x/y and a model. I can interpolate a new value of x
>using this model, but I get funny results if I give the y and look for
>the correspondent x:
>```
>> x = 1:10
>> y = 2*x+15
>> model <- lm(y~x)
>> predict(model, data.frame(x=7.5))
> 1
>30
>> predict(model, data.frame(y=26))
> 1  2  3  4  5  6  7  8  9 10
>17 19 21 23 25 27 29 31 33 35
>Warning message:
>'newdata' had 1 row but variables found have 10 rows
>> data.frame(x=7.5)
>    x
>1 7.5
>> data.frame(y=26)
>   y
>1 26
>```
>what is the correct syntax?
>Thank you
>Luigi
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jan 26 10:47:31 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 26 Jan 2021 10:47:31 +0100
Subject: [R] How to predict/interpolate new Y given knwon Xs and Ys?
In-Reply-To: <8799A845-AA66-4DFF-ADB1-55B24229936D@dcn.davis.ca.us>
References: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>
 <8799A845-AA66-4DFF-ADB1-55B24229936D@dcn.davis.ca.us>
Message-ID: <CAMk+s2Tkz25XVxSZQGZ3P7YGpMxnsJmDPSN8A_Hw0Z2wEkQOcg@mail.gmail.com>

I see, so predict is mono-directional: only gives x with a know y but
not the other way round. Thank you

On Tue, Jan 26, 2021 at 10:20 AM Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
>
> model2 <- lm( x~y )
> predict(model2, data.frame(y=26))
>
> model2 is however not the inverse of model... if you need that then you need to handle that some other way than using predict, such as an invertible monotonic spline (or in this case a little algebra).
>
> On January 26, 2021 1:11:39 AM PST, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >Hello,
> >I have a series of x/y and a model. I can interpolate a new value of x
> >using this model, but I get funny results if I give the y and look for
> >the correspondent x:
> >```
> >> x = 1:10
> >> y = 2*x+15
> >> model <- lm(y~x)
> >> predict(model, data.frame(x=7.5))
> > 1
> >30
> >> predict(model, data.frame(y=26))
> > 1  2  3  4  5  6  7  8  9 10
> >17 19 21 23 25 27 29 31 33 35
> >Warning message:
> >'newdata' had 1 row but variables found have 10 rows
> >> data.frame(x=7.5)
> >    x
> >1 7.5
> >> data.frame(y=26)
> >   y
> >1 26
> >```
> >what is the correct syntax?
> >Thank you
> >Luigi
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.



-- 
Best regards,
Luigi


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Jan 26 10:50:25 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 26 Jan 2021 09:50:25 +0000
Subject: [R] How to predict/interpolate new Y given knwon Xs and Ys?
In-Reply-To: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>
References: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>
Message-ID: <d1e79ca8-ffca-28f1-770e-390132c3fb5f@sapo.pt>

Hello,

You can predict y on x, not the other way around, like you are doing in 
the second call to predict.lm.

The 10 values you are getting are the predicted values on the original x 
values, just see that x=7.5 gives ypred=30, right in the middle of x=7 
and x=8 -> ypred=29 and ypred=31.

As for the inverse regression, how do you account for the errors? In 
linear regression the only rv is the errors vector, the inverse of

y = a + b*x + e

is not

x = (y - a)/b

though you can write a function that computes this value:

pred_x <- function(model, newdata){
   beta <- coef(model)
   y <- newdata[[1]]
   x <- (y - beta[1])/beta[2]
   unname(x)
}
pred_x(model, data.frame(y = 26))
#[1] 5.5


There is a CRAN package, investr that computes the standard errors:

investr::calibrate(model, y0 = 26)
#estimate    lower    upper
#     5.5      5.5      5.5


See the decumentation in [1]

[1] https://CRAN.R-project.org/package=investr


Hope this helps,

Rui Barradas

?s 09:11 de 26/01/21, Luigi Marongiu escreveu:
> Hello,
> I have a series of x/y and a model. I can interpolate a new value of x
> using this model, but I get funny results if I give the y and look for
> the correspondent x:
> ```
>> x = 1:10
>> y = 2*x+15
>> model <- lm(y~x)
>> predict(model, data.frame(x=7.5))
>   1
> 30
>> predict(model, data.frame(y=26))
>   1  2  3  4  5  6  7  8  9 10
> 17 19 21 23 25 27 29 31 33 35
> Warning message:
> 'newdata' had 1 row but variables found have 10 rows
>> data.frame(x=7.5)
>      x
> 1 7.5
>> data.frame(y=26)
>     y
> 1 26
> ```
> what is the correct syntax?
> Thank you
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Jan 26 12:37:58 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 26 Jan 2021 12:37:58 +0100
Subject: [R] Error when calling R from Python
In-Reply-To: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
Message-ID: <24591.65302.527022.733577@stat.math.ethz.ch>

>>>>> Marcel Baumgartner 
>>>>>     on Tue, 26 Jan 2021 08:55:48 +0100 writes:

    > Dear all, my colleague posted our issue on stackoverflow:

    > Calling R script from Python does not save log file in
    > version 4 - Stack Overflow
    > [https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]

    > It is about this kind of call to R:

    > R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1".

    > The issue is that the log.txt file is not created when
    > running R 4.x.x. The same code works perfectly fine with R
    > 3.6.x.

    > Any idea what's going wrong as of version 4? Regards
    > Marcel?

Dear Marcel,
I think the solution is embarrassingly simple:

>From the SO post, where she showed a bit more detail than you
show here, it's clear  you have confused
'R.exe' and 'Rscript.exe' and what you say above is not true:

'R.exe' was used for R 3.6.0  but for R 4.0.3, you/she used
'Rscript.exe' instead.

... as you've noticed now, they do behave differently, indeed!

Avec meilleures salutations,
Martin


From jrkr|de@u @end|ng |rom gm@||@com  Tue Jan 26 20:50:49 2021
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Tue, 26 Jan 2021 14:50:49 -0500
Subject: [R] problem installing R and RStudio
In-Reply-To: <2422CF04-32DF-4EE2-B406-3CFEEA00B806@dcn.davis.ca.us>
References: <CAGa55hQAOBEXX6fXL=Usjn+N=CS_SDYN0+2gKKpVEBNfVn4UKw@mail.gmail.com>
 <2422CF04-32DF-4EE2-B406-3CFEEA00B806@dcn.davis.ca.us>
Message-ID: <CAKZQJMAr-DF6yAsJMFwFDXL4aHtHcg86r8K+Lo7uDKa0jB-UJw@mail.gmail.com>

A couple of Window solutions
https://community.rstudio.com/t/problems-with-r-4-0-0-windows-error-package-or-namespace-load-failed-for-stats-in-indl-x-as-logical-local-as-logical-now/62958

https://github.com/rdotnet/rdotnet/issues/62

No idea if they are of any use.

On Mon, 25 Jan 2021 at 19:43, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Your installation of R seems broken. Since RStudio sometimes tries to
> simplify things and sometimes misses and we aren't typically up to speed
> with their latest procedures, please describe what you did to install R in
> terms related to the instructions on CRAN [1] and its install program. When
> you can run R from RGui or the CMD prompt then you may get lucky and
> RStudio will just work. If you aren't lucky connecting your working R to
> RStudio  then you will probably need to ask them [2] for assistance.
>
> Also, the Posting Guide points out that this is a plain text mailing
> list... sending HTML email through this list is erratic... if you want to
> insure we get your message as you sent it, set your email client to send
> plain text format.
>
> [1] https://cran.r-project.org/bin/windows/base/
> [2] https://community.rstudio.com/
>
> On January 25, 2021 2:40:45 PM PST, Carlos Gonzalez <caghpm at gmail.com>
> wrote:
> >Dear,
> >
> >I've just installed R and RStudio. Opening RStudio the following
> >appears in
> >the console.
> >
> >
> >R version 4.0.3 (2020-10-10) -- "Bunny-Wunnies Freak Out"
> >Copyright (C) 2020 The R Foundation for Statistical Computing
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
> >
> >R is free software and comes with ABSOLUTELY NO WARRANTY.
> >You are welcome to redistribute it under certain conditions.
> >Type 'license()' or 'licence()' for distribution details.
> >
> >  Natural language support but running in an English locale
> >
> >R is a collaborative project with many contributors.
> >Type 'contributors()' for more information and
> >'citation()' on how to cite R or R packages in publications.
> >
> >Type 'demo()' for some demos, 'help()' for on-line help, or
> >'help.start()' for an HTML browser interface to help.
> >Type 'q()' to quit R.
> >
> >Error: package or namespace load failed for ?stats? in inDL(x,
> >as.logical(local), as.logical(now), ...):
> > unable to load shared object 'C:/Program
> >Files/R/R-4.0.3/library/stats/libs/x64/stats.dll':
> >  LoadLibrary failure:  The specified module could not be found.
> >
> >During startup - Warning message:
> >package ?stats? in options("defaultPackages") was not found
> >Error in inDL(x, as.logical(local), as.logical(now), ...) :
> >  unable to load shared object 'C:/Program
> >Files/R/R-4.0.3/library/stats/libs/x64/stats.dll':
> >  LoadLibrary failure:  The specified module could not be found.
> >>
> >I would very much appreciate it if you could help solving this problem.
> >
> >Saludos / Regards
> >
> >Carlos A. Gonzalez
> >Mobile +598 94 234 653
> >caghpm at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From tmr@g11 @end|ng |rom gm@||@com  Tue Jan 26 20:29:22 2021
From: tmr@g11 @end|ng |rom gm@||@com (C W)
Date: Tue, 26 Jan 2021 14:29:22 -0500
Subject: [R] Is there anyone who uses both R and Python here? How do you
 debug? Perhaps in RStudio?
Message-ID: <CAE2FW2=TEemXH_vgZXuYXSURFGdQoMBNRnqm9rq-7udmXZDMCw@mail.gmail.com>

Hello all,

I'm a long time R user, but recently also using Python. I noticed that
RStudio rolled out Python through reticulate. It's great so far!

My question is, how do you debug in Python?

In R, I simply step through the code script in my console with cmd+enter.
But you can't do that with Python, some of them are objects.

Here's my example.
class person:
     def __init__(self, id, created_at, name, attend_date, distance):
          """Create a new `person`.
          """
          self._id = id
          self.created_at = created_at
          self.name = name
          self.attend_date = attend_date
          self.distance = distance

     @classmethod
          def get_person(self, employee):
          """Find and return a person by.
          """
          return person(employee['created_at'],
               employee['id'],
               employee['name'],
               employee['attend_date'],
               employee['distance']
               )

The error message says self._id was 'str', but expecting an 'int'. I can't
do:
> self._id = 5
I guess it's "hidden". Can't really assign and test like that.

It seems hardcore Python programmers just use a debugger, and do not
understand the greatness of interactive IDE and console. I'd still like to
stay in IDE, hopefully.

So, how are the R users coping with object classes? Do you just instantiate
every time? What if you got 10 of these class person objects to debug?

I know this may be a Python question. But, I really wanted to see from a R
user's working experience.

Thanks a lot,

Mike

	[[alternative HTML version deleted]]


From den|@@|r@nc|@c| @end|ng |rom gm@||@com  Wed Jan 27 09:03:15 2021
From: den|@@|r@nc|@c| @end|ng |rom gm@||@com (Denis Francisci)
Date: Wed, 27 Jan 2021 09:03:15 +0100
Subject: [R] random numbers with constraints
Message-ID: <CAJMcJMBf=rYNc5FYB1oW5n1t7bo62_=gvbhhvd5D7Dqa_YTNFA@mail.gmail.com>

Hi,
I would like to generate random numbers in R with some constraints:
- my vector of numbers must contain 410 values;
- min value must be 9.6 and max value must be 11.6;
- sum of vector's values must be 4200.
Is there a way to do this in R?
And is it possible to generate this series in such a way that it follows a
specific distribution form (for example exponential)?
Thank you in advance,

D.

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Jan 27 09:38:34 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 27 Jan 2021 09:38:34 +0100
Subject: [R] Error when calling (R 4.0.x on Windows) from Python
In-Reply-To: <24591.65302.527022.733577@stat.math.ethz.ch>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
 <24591.65302.527022.733577@stat.math.ethz.ch>
Message-ID: <24593.9866.492194.548636@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Tue, 26 Jan 2021 12:37:58 +0100 writes:

>>>>> Marcel Baumgartner 
>>>>>     on Tue, 26 Jan 2021 08:55:48 +0100 writes:

    >> Dear all, my colleague posted our issue on stackoverflow:

    >> Calling R script from Python does not save log file in
    >> version 4 - Stack Overflow
    >> [https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]

    >> It is about this kind of call to R:

    >> R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1".

    >> The issue is that the log.txt file is not created when
    >> running R 4.x.x. The same code works perfectly fine with
    >> R 3.6.x.

    >> Any idea what's going wrong as of version 4? Regards
    >> Marcel?

    > Dear Marcel, I think the solution is embarrassingly
    > simple:

    >> From the SO post, where she showed a bit more detail than you
    > show here, it's clear you have confused 'R.exe' and
    > 'Rscript.exe' and what you say above is not true:

    > 'R.exe' was used for R 3.6.0 but for R 4.0.3, you/she used
    > 'Rscript.exe' instead.


    > ... as you've noticed now, they do behave differently,
    > indeed!

Well, this was not the solution to their -- Windows-only -- problem.
The problem *is* indeed visible if they only use  R.exe  (also
for R 4.0.3).

I've commented more on the SO issue (see above),
notably asking for a *minimal* repr.ex. (reproducible example),
and one *not* using "<YOUR PATH>" and setwd() ..

Martin


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jan 27 10:30:00 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 27 Jan 2021 10:30:00 +0100
Subject: [R] How to predict/interpolate new Y given knwon Xs and Ys?
In-Reply-To: <8799A845-AA66-4DFF-ADB1-55B24229936D@dcn.davis.ca.us>
References: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>
 <8799A845-AA66-4DFF-ADB1-55B24229936D@dcn.davis.ca.us>
Message-ID: <CAMk+s2S2KmC7rE=5FU_6O1FCxhi8naEZ+fAqBpFvOA4DpG9dCw@mail.gmail.com>

Dear Jeff,
I am not sure if I understood the procedure properly but it looks like it works:
```
Y <-c(1.301030,  1.602060,  1.903090,  2.204120,  2.505150,  2.806180,
 3.107210,  3.408240,  3.709270,
4.010300,  4.311330,  4.612360,  4.913390,  5.214420,  5.515450,
5.816480,  6.117510,  6.418540,
6.719570,  7.020599,  7.321629,  7.622658,  7.923686,  8.224713,
8.525735,  8.826751,  9.127752,
9.428723,  9.729637, 10.030434, 10.330998, 10.631096, 10.930265,
11.227580, 11.521213, 11.807577,
12.079787, 12.325217, 12.523074, 12.647915, 12.693594, 12.698904,
12.698970, 12.698970, 12.698970)
X <- 1:45
plot(Y~X)
raw_value <- predict(lm(X[1:39]~Y[1:39]), newdata = data.frame(Y=6))
x <- unname(raw_value[!is.na(raw_value)]) # x= 16.62995
points(x, 6, pch = 16)
```
Here I used the points 1:39 because afterward there is a bend. But I
am not clear why I need to use `lm(X~Y),` instead of `lm(Y~X)`.
Thank you

On Tue, Jan 26, 2021 at 10:20 AM Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
>
> model2 <- lm( x~y )
> predict(model2, data.frame(y=26))
>
> model2 is however not the inverse of model... if you need that then you need to handle that some other way than using predict, such as an invertible monotonic spline (or in this case a little algebra).
>
> On January 26, 2021 1:11:39 AM PST, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >Hello,
> >I have a series of x/y and a model. I can interpolate a new value of x
> >using this model, but I get funny results if I give the y and look for
> >the correspondent x:
> >```
> >> x = 1:10
> >> y = 2*x+15
> >> model <- lm(y~x)
> >> predict(model, data.frame(x=7.5))
> > 1
> >30
> >> predict(model, data.frame(y=26))
> > 1  2  3  4  5  6  7  8  9 10
> >17 19 21 23 25 27 29 31 33 35
> >Warning message:
> >'newdata' had 1 row but variables found have 10 rows
> >> data.frame(x=7.5)
> >    x
> >1 7.5
> >> data.frame(y=26)
> >   y
> >1 26
> >```
> >what is the correct syntax?
> >Thank you
> >Luigi
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.



-- 
Best regards,
Luigi


From r_goertz @end|ng |rom web@de  Wed Jan 27 10:50:14 2021
From: r_goertz @end|ng |rom web@de (Ralf Goertz)
Date: Wed, 27 Jan 2021 10:50:14 +0100
Subject: [R] random numbers with constraints
In-Reply-To: <CAJMcJMBf=rYNc5FYB1oW5n1t7bo62_=gvbhhvd5D7Dqa_YTNFA@mail.gmail.com>
References: <CAJMcJMBf=rYNc5FYB1oW5n1t7bo62_=gvbhhvd5D7Dqa_YTNFA@mail.gmail.com>
Message-ID: <20210127105014.17a178cd@delli.fritz.box>

Am Wed, 27 Jan 2021 09:03:15 +0100
schrieb Denis Francisci <denis.francisci at gmail.com>:

> Hi,
> I would like to generate random numbers in R with some constraints:
> - my vector of numbers must contain 410 values;
> - min value must be 9.6 and max value must be 11.6;
> - sum of vector's values must be 4200.
> Is there a way to do this in R?
> And is it possible to generate this series in such a way that it
> follows a specific distribution form (for example exponential)?
> Thank you in advance,

In principle it should be possible. But I guess you are asking too much
with three given values considering that you only have one paramter for
the exponential distribution. For instance, if you only had given min
and max, and wanted a normal distribution then you could have just taken
410 random values from a standard normal: x=rnorm(410) then centered it:
x=x-mean(x) then scaled it so its span equals the one for your given max
(M) and min (m) values: x=x*(M-m)/(max(x)-min(x)) and finally shift it
such that the mininum becomes m: x=x-min(x)+m. Note however, that the
things you are allowed to do with your vector of random numbers depend
on the distribution if you want the result to still follow that type of
distribution.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jan 27 10:57:47 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 27 Jan 2021 22:57:47 +1300
Subject: [R] random numbers with constraints
In-Reply-To: <CAJMcJMBf=rYNc5FYB1oW5n1t7bo62_=gvbhhvd5D7Dqa_YTNFA@mail.gmail.com>
References: <CAJMcJMBf=rYNc5FYB1oW5n1t7bo62_=gvbhhvd5D7Dqa_YTNFA@mail.gmail.com>
Message-ID: <CAB8pepwZB0TfF5ewdfjUDjBU_Md95j4npANU9k1rpVyTp0rivg@mail.gmail.com>

u <- runif (410)
u <- (u - min (u) ) / diff (range (u) )

constrained.sample <- function (rate)
{   plim <- pexp (c (9.6, 11.6), rate)
    p <- plim [1] + diff (plim) * u
    qexp (p, rate)
}

diff.sum <- function (rate)
    sum (constrained.sample (rate) ) - 4200

rate <- uniroot (diff.sum, c (1, 2) )$root
q <- constrained.sample (rate)

length (q)
range (q)
sum (q)


On Wed, Jan 27, 2021 at 9:03 PM Denis Francisci
<denis.francisci at gmail.com> wrote:
>
> Hi,
> I would like to generate random numbers in R with some constraints:
> - my vector of numbers must contain 410 values;
> - min value must be 9.6 and max value must be 11.6;
> - sum of vector's values must be 4200.
> Is there a way to do this in R?
> And is it possible to generate this series in such a way that it follows a
> specific distribution form (for example exponential)?
> Thank you in advance,
>
> D.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jan 27 11:32:08 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 27 Jan 2021 23:32:08 +1300
Subject: [R] How to predict/interpolate new Y given knwon Xs and Ys?
In-Reply-To: <CAMk+s2S2KmC7rE=5FU_6O1FCxhi8naEZ+fAqBpFvOA4DpG9dCw@mail.gmail.com>
References: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>
 <8799A845-AA66-4DFF-ADB1-55B24229936D@dcn.davis.ca.us>
 <CAMk+s2S2KmC7rE=5FU_6O1FCxhi8naEZ+fAqBpFvOA4DpG9dCw@mail.gmail.com>
Message-ID: <CAB8pepwTHxVPjpvqmFT+kdtw3ZsZ8OuT9F3nFsY2mH7emk5N6w@mail.gmail.com>

I got 16.60964.
Your curve is not linear up to the 39th point.
And as your points appear to be deterministic and nonlinear, splines
are likely to be easier to use.

Here's a base-only solution (if you don't like my kubik suggestion):

g <- splinefun (X, Y)
f <- function (x) g (x) - 6
uniroot (f, c (1, 45) )$root


On Wed, Jan 27, 2021 at 10:30 PM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> Dear Jeff,
> I am not sure if I understood the procedure properly but it looks like it works:
> ```
> Y <-c(1.301030,  1.602060,  1.903090,  2.204120,  2.505150,  2.806180,
>  3.107210,  3.408240,  3.709270,
> 4.010300,  4.311330,  4.612360,  4.913390,  5.214420,  5.515450,
> 5.816480,  6.117510,  6.418540,
> 6.719570,  7.020599,  7.321629,  7.622658,  7.923686,  8.224713,
> 8.525735,  8.826751,  9.127752,
> 9.428723,  9.729637, 10.030434, 10.330998, 10.631096, 10.930265,
> 11.227580, 11.521213, 11.807577,
> 12.079787, 12.325217, 12.523074, 12.647915, 12.693594, 12.698904,
> 12.698970, 12.698970, 12.698970)
> X <- 1:45
> plot(Y~X)
> raw_value <- predict(lm(X[1:39]~Y[1:39]), newdata = data.frame(Y=6))
> x <- unname(raw_value[!is.na(raw_value)]) # x= 16.62995
> points(x, 6, pch = 16)
> ```
> Here I used the points 1:39 because afterward there is a bend. But I
> am not clear why I need to use `lm(X~Y),` instead of `lm(Y~X)`.
> Thank you
>
> On Tue, Jan 26, 2021 at 10:20 AM Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
> >
> > model2 <- lm( x~y )
> > predict(model2, data.frame(y=26))
> >
> > model2 is however not the inverse of model... if you need that then you need to handle that some other way than using predict, such as an invertible monotonic spline (or in this case a little algebra).
> >
> > On January 26, 2021 1:11:39 AM PST, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >Hello,
> > >I have a series of x/y and a model. I can interpolate a new value of x
> > >using this model, but I get funny results if I give the y and look for
> > >the correspondent x:
> > >```
> > >> x = 1:10
> > >> y = 2*x+15
> > >> model <- lm(y~x)
> > >> predict(model, data.frame(x=7.5))
> > > 1
> > >30
> > >> predict(model, data.frame(y=26))
> > > 1  2  3  4  5  6  7  8  9 10
> > >17 19 21 23 25 27 29 31 33 35
> > >Warning message:
> > >'newdata' had 1 row but variables found have 10 rows
> > >> data.frame(x=7.5)
> > >    x
> > >1 7.5
> > >> data.frame(y=26)
> > >   y
> > >1 26
> > >```
> > >what is the correct syntax?
> > >Thank you
> > >Luigi
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jan 27 11:46:40 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 27 Jan 2021 11:46:40 +0100
Subject: [R] How to predict/interpolate new Y given knwon Xs and Ys?
In-Reply-To: <CAB8pepwTHxVPjpvqmFT+kdtw3ZsZ8OuT9F3nFsY2mH7emk5N6w@mail.gmail.com>
References: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>
 <8799A845-AA66-4DFF-ADB1-55B24229936D@dcn.davis.ca.us>
 <CAMk+s2S2KmC7rE=5FU_6O1FCxhi8naEZ+fAqBpFvOA4DpG9dCw@mail.gmail.com>
 <CAB8pepwTHxVPjpvqmFT+kdtw3ZsZ8OuT9F3nFsY2mH7emk5N6w@mail.gmail.com>
Message-ID: <CAMk+s2QiUDq5BToWtkefskgZLrOfuWgE2Guu7Vk6Ra-wyRp21w@mail.gmail.com>

That is right, I removed the points above 39, and also got 16.60964,
which looks good to me. Splines is good and I will use it for
non-linear interpolation. For now I used linear conversion to keep it
simple but looks to me it is getting out of hand. I simply need to do
the following interpolation:
```
Y <-c(1.301030,  1.602060,  1.903090,  2.204120,  2.505150,  2.806180,
# log transformation of the original data
        3.107210,  3.408240,  3.709270,
       4.010300,  4.311330,  4.612360,  4.913390,  5.214420,  5.515450,
       5.816480,  6.117510,  6.418540,
       6.719570,  7.020599,  7.321629,  7.622658,  7.923686,  8.224713,
       8.525735,  8.826751,  9.127752,
       9.428723,  9.729637, 10.030434, 10.330998, 10.631096, 10.930265,
       11.227580, 11.521213, 11.807577,
       12.079787, 12.325217, 12.523074, 12.647915, 12.693594, 12.698904,
       12.698970, 12.698970, 12.698970)
X <- 1:45
plot(Y~X)
points(16.60964, 6, pch=16)
segments(0, 6, 16.60964, 6)
arrows(16.60964, 6, 16.60964, 1)
# given Y find X
```
How shall I use predict then? The use of other packages when predict
can do it would be overkill...
Thank you

On Wed, Jan 27, 2021 at 11:32 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I got 16.60964.
> Your curve is not linear up to the 39th point.
> And as your points appear to be deterministic and nonlinear, splines
> are likely to be easier to use.
>
> Here's a base-only solution (if you don't like my kubik suggestion):
>
> g <- splinefun (X, Y)
> f <- function (x) g (x) - 6
> uniroot (f, c (1, 45) )$root
>
>
> On Wed, Jan 27, 2021 at 10:30 PM Luigi Marongiu
> <marongiu.luigi at gmail.com> wrote:
> >
> > Dear Jeff,
> > I am not sure if I understood the procedure properly but it looks like it works:
> > ```
> > Y <-c(1.301030,  1.602060,  1.903090,  2.204120,  2.505150,  2.806180,
> >  3.107210,  3.408240,  3.709270,
> > 4.010300,  4.311330,  4.612360,  4.913390,  5.214420,  5.515450,
> > 5.816480,  6.117510,  6.418540,
> > 6.719570,  7.020599,  7.321629,  7.622658,  7.923686,  8.224713,
> > 8.525735,  8.826751,  9.127752,
> > 9.428723,  9.729637, 10.030434, 10.330998, 10.631096, 10.930265,
> > 11.227580, 11.521213, 11.807577,
> > 12.079787, 12.325217, 12.523074, 12.647915, 12.693594, 12.698904,
> > 12.698970, 12.698970, 12.698970)
> > X <- 1:45
> > plot(Y~X)
> > raw_value <- predict(lm(X[1:39]~Y[1:39]), newdata = data.frame(Y=6))
> > x <- unname(raw_value[!is.na(raw_value)]) # x= 16.62995
> > points(x, 6, pch = 16)
> > ```
> > Here I used the points 1:39 because afterward there is a bend. But I
> > am not clear why I need to use `lm(X~Y),` instead of `lm(Y~X)`.
> > Thank you
> >
> > On Tue, Jan 26, 2021 at 10:20 AM Jeff Newmiller
> > <jdnewmil at dcn.davis.ca.us> wrote:
> > >
> > > model2 <- lm( x~y )
> > > predict(model2, data.frame(y=26))
> > >
> > > model2 is however not the inverse of model... if you need that then you need to handle that some other way than using predict, such as an invertible monotonic spline (or in this case a little algebra).
> > >
> > > On January 26, 2021 1:11:39 AM PST, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > >Hello,
> > > >I have a series of x/y and a model. I can interpolate a new value of x
> > > >using this model, but I get funny results if I give the y and look for
> > > >the correspondent x:
> > > >```
> > > >> x = 1:10
> > > >> y = 2*x+15
> > > >> model <- lm(y~x)
> > > >> predict(model, data.frame(x=7.5))
> > > > 1
> > > >30
> > > >> predict(model, data.frame(y=26))
> > > > 1  2  3  4  5  6  7  8  9 10
> > > >17 19 21 23 25 27 29 31 33 35
> > > >Warning message:
> > > >'newdata' had 1 row but variables found have 10 rows
> > > >> data.frame(x=7.5)
> > > >    x
> > > >1 7.5
> > > >> data.frame(y=26)
> > > >   y
> > > >1 26
> > > >```
> > > >what is the correct syntax?
> > > >Thank you
> > > >Luigi
> > > >
> > > >______________________________________________
> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >https://stat.ethz.ch/mailman/listinfo/r-help
> > > >PLEASE do read the posting guide
> > > >http://www.R-project.org/posting-guide.html
> > > >and provide commented, minimal, self-contained, reproducible code.
> > >
> > > --
> > > Sent from my phone. Please excuse my brevity.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan 27 15:32:01 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 27 Jan 2021 06:32:01 -0800
Subject: [R] How to predict/interpolate new Y given knwon Xs and Ys?
In-Reply-To: <CAMk+s2QiUDq5BToWtkefskgZLrOfuWgE2Guu7Vk6Ra-wyRp21w@mail.gmail.com>
References: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>
 <8799A845-AA66-4DFF-ADB1-55B24229936D@dcn.davis.ca.us>
 <CAMk+s2S2KmC7rE=5FU_6O1FCxhi8naEZ+fAqBpFvOA4DpG9dCw@mail.gmail.com>
 <CAB8pepwTHxVPjpvqmFT+kdtw3ZsZ8OuT9F3nFsY2mH7emk5N6w@mail.gmail.com>
 <CAMk+s2QiUDq5BToWtkefskgZLrOfuWgE2Guu7Vk6Ra-wyRp21w@mail.gmail.com>
Message-ID: <A6519465-145E-4154-B0DD-8EC8073C09EE@dcn.davis.ca.us>

Your piecewise-linear function Y(X) is not invertible as a whole so there is no general solution per algebra.

You keep saying predict can do this, but as I pointed out and Rui ventured to expand the math on, predict cannot calculate an inverse even if you swap the inputs. And as Abby pointed out, you are abusing lm by applying it to data with systematic errors (negligible random residuals).

If you know which portion of the curve you want a result in, you can use a subset of your data to create an invertible piecewise linear function::

approx( Y[1:39], X[1:39], 6 )$y

On January 27, 2021 2:46:40 AM PST, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>That is right, I removed the points above 39, and also got 16.60964,
>which looks good to me. Splines is good and I will use it for
>non-linear interpolation. For now I used linear conversion to keep it
>simple but looks to me it is getting out of hand. I simply need to do
>the following interpolation:
>```
>Y <-c(1.301030,  1.602060,  1.903090,  2.204120,  2.505150,  2.806180,
># log transformation of the original data
>        3.107210,  3.408240,  3.709270,
>       4.010300,  4.311330,  4.612360,  4.913390,  5.214420,  5.515450,
>       5.816480,  6.117510,  6.418540,
>       6.719570,  7.020599,  7.321629,  7.622658,  7.923686,  8.224713,
>       8.525735,  8.826751,  9.127752,
>       9.428723,  9.729637, 10.030434, 10.330998, 10.631096, 10.930265,
>       11.227580, 11.521213, 11.807577,
>      12.079787, 12.325217, 12.523074, 12.647915, 12.693594, 12.698904,
>       12.698970, 12.698970, 12.698970)
>X <- 1:45
>plot(Y~X)
>points(16.60964, 6, pch=16)
>segments(0, 6, 16.60964, 6)
>arrows(16.60964, 6, 16.60964, 1)
># given Y find X
>```
>How shall I use predict then? The use of other packages when predict
>can do it would be overkill...
>Thank you
>
>On Wed, Jan 27, 2021 at 11:32 AM Abby Spurdle <spurdle.a at gmail.com>
>wrote:
>>
>> I got 16.60964.
>> Your curve is not linear up to the 39th point.
>> And as your points appear to be deterministic and nonlinear, splines
>> are likely to be easier to use.
>>
>> Here's a base-only solution (if you don't like my kubik suggestion):
>>
>> g <- splinefun (X, Y)
>> f <- function (x) g (x) - 6
>> uniroot (f, c (1, 45) )$root
>>
>>
>> On Wed, Jan 27, 2021 at 10:30 PM Luigi Marongiu
>> <marongiu.luigi at gmail.com> wrote:
>> >
>> > Dear Jeff,
>> > I am not sure if I understood the procedure properly but it looks
>like it works:
>> > ```
>> > Y <-c(1.301030,  1.602060,  1.903090,  2.204120,  2.505150, 
>2.806180,
>> >  3.107210,  3.408240,  3.709270,
>> > 4.010300,  4.311330,  4.612360,  4.913390,  5.214420,  5.515450,
>> > 5.816480,  6.117510,  6.418540,
>> > 6.719570,  7.020599,  7.321629,  7.622658,  7.923686,  8.224713,
>> > 8.525735,  8.826751,  9.127752,
>> > 9.428723,  9.729637, 10.030434, 10.330998, 10.631096, 10.930265,
>> > 11.227580, 11.521213, 11.807577,
>> > 12.079787, 12.325217, 12.523074, 12.647915, 12.693594, 12.698904,
>> > 12.698970, 12.698970, 12.698970)
>> > X <- 1:45
>> > plot(Y~X)
>> > raw_value <- predict(lm(X[1:39]~Y[1:39]), newdata =
>data.frame(Y=6))
>> > x <- unname(raw_value[!is.na(raw_value)]) # x= 16.62995
>> > points(x, 6, pch = 16)
>> > ```
>> > Here I used the points 1:39 because afterward there is a bend. But
>I
>> > am not clear why I need to use `lm(X~Y),` instead of `lm(Y~X)`.
>> > Thank you
>> >
>> > On Tue, Jan 26, 2021 at 10:20 AM Jeff Newmiller
>> > <jdnewmil at dcn.davis.ca.us> wrote:
>> > >
>> > > model2 <- lm( x~y )
>> > > predict(model2, data.frame(y=26))
>> > >
>> > > model2 is however not the inverse of model... if you need that
>then you need to handle that some other way than using predict, such as
>an invertible monotonic spline (or in this case a little algebra).
>> > >
>> > > On January 26, 2021 1:11:39 AM PST, Luigi Marongiu
><marongiu.luigi at gmail.com> wrote:
>> > > >Hello,
>> > > >I have a series of x/y and a model. I can interpolate a new
>value of x
>> > > >using this model, but I get funny results if I give the y and
>look for
>> > > >the correspondent x:
>> > > >```
>> > > >> x = 1:10
>> > > >> y = 2*x+15
>> > > >> model <- lm(y~x)
>> > > >> predict(model, data.frame(x=7.5))
>> > > > 1
>> > > >30
>> > > >> predict(model, data.frame(y=26))
>> > > > 1  2  3  4  5  6  7  8  9 10
>> > > >17 19 21 23 25 27 29 31 33 35
>> > > >Warning message:
>> > > >'newdata' had 1 row but variables found have 10 rows
>> > > >> data.frame(x=7.5)
>> > > >    x
>> > > >1 7.5
>> > > >> data.frame(y=26)
>> > > >   y
>> > > >1 26
>> > > >```
>> > > >what is the correct syntax?
>> > > >Thank you
>> > > >Luigi
>> > > >
>> > > >______________________________________________
>> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> > > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >PLEASE do read the posting guide
>> > > >http://www.R-project.org/posting-guide.html
>> > > >and provide commented, minimal, self-contained, reproducible
>code.
>> > >
>> > > --
>> > > Sent from my phone. Please excuse my brevity.
>> >
>> >
>> >
>> > --
>> > Best regards,
>> > Luigi
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jan 27 15:34:49 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 27 Jan 2021 15:34:49 +0100
Subject: [R] How to predict/interpolate new Y given knwon Xs and Ys?
In-Reply-To: <A6519465-145E-4154-B0DD-8EC8073C09EE@dcn.davis.ca.us>
References: <CAMk+s2RK991ida126rsGnAi-yDw_c85n1_tRi-GrJt4F9vNdxQ@mail.gmail.com>
 <8799A845-AA66-4DFF-ADB1-55B24229936D@dcn.davis.ca.us>
 <CAMk+s2S2KmC7rE=5FU_6O1FCxhi8naEZ+fAqBpFvOA4DpG9dCw@mail.gmail.com>
 <CAB8pepwTHxVPjpvqmFT+kdtw3ZsZ8OuT9F3nFsY2mH7emk5N6w@mail.gmail.com>
 <CAMk+s2QiUDq5BToWtkefskgZLrOfuWgE2Guu7Vk6Ra-wyRp21w@mail.gmail.com>
 <A6519465-145E-4154-B0DD-8EC8073C09EE@dcn.davis.ca.us>
Message-ID: <CAMk+s2Rf3v_ZVpi8myyusL2OicYcTYL+UayOZR3+fegVuKDBxQ@mail.gmail.com>

Thank you for the clarification.

On Wed, Jan 27, 2021 at 3:32 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Your piecewise-linear function Y(X) is not invertible as a whole so there is no general solution per algebra.
>
> You keep saying predict can do this, but as I pointed out and Rui ventured to expand the math on, predict cannot calculate an inverse even if you swap the inputs. And as Abby pointed out, you are abusing lm by applying it to data with systematic errors (negligible random residuals).
>
> If you know which portion of the curve you want a result in, you can use a subset of your data to create an invertible piecewise linear function::
>
> approx( Y[1:39], X[1:39], 6 )$y
>
> On January 27, 2021 2:46:40 AM PST, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >That is right, I removed the points above 39, and also got 16.60964,
> >which looks good to me. Splines is good and I will use it for
> >non-linear interpolation. For now I used linear conversion to keep it
> >simple but looks to me it is getting out of hand. I simply need to do
> >the following interpolation:
> >```
> >Y <-c(1.301030,  1.602060,  1.903090,  2.204120,  2.505150,  2.806180,
> ># log transformation of the original data
> >        3.107210,  3.408240,  3.709270,
> >       4.010300,  4.311330,  4.612360,  4.913390,  5.214420,  5.515450,
> >       5.816480,  6.117510,  6.418540,
> >       6.719570,  7.020599,  7.321629,  7.622658,  7.923686,  8.224713,
> >       8.525735,  8.826751,  9.127752,
> >       9.428723,  9.729637, 10.030434, 10.330998, 10.631096, 10.930265,
> >       11.227580, 11.521213, 11.807577,
> >      12.079787, 12.325217, 12.523074, 12.647915, 12.693594, 12.698904,
> >       12.698970, 12.698970, 12.698970)
> >X <- 1:45
> >plot(Y~X)
> >points(16.60964, 6, pch=16)
> >segments(0, 6, 16.60964, 6)
> >arrows(16.60964, 6, 16.60964, 1)
> ># given Y find X
> >```
> >How shall I use predict then? The use of other packages when predict
> >can do it would be overkill...
> >Thank you
> >
> >On Wed, Jan 27, 2021 at 11:32 AM Abby Spurdle <spurdle.a at gmail.com>
> >wrote:
> >>
> >> I got 16.60964.
> >> Your curve is not linear up to the 39th point.
> >> And as your points appear to be deterministic and nonlinear, splines
> >> are likely to be easier to use.
> >>
> >> Here's a base-only solution (if you don't like my kubik suggestion):
> >>
> >> g <- splinefun (X, Y)
> >> f <- function (x) g (x) - 6
> >> uniroot (f, c (1, 45) )$root
> >>
> >>
> >> On Wed, Jan 27, 2021 at 10:30 PM Luigi Marongiu
> >> <marongiu.luigi at gmail.com> wrote:
> >> >
> >> > Dear Jeff,
> >> > I am not sure if I understood the procedure properly but it looks
> >like it works:
> >> > ```
> >> > Y <-c(1.301030,  1.602060,  1.903090,  2.204120,  2.505150,
> >2.806180,
> >> >  3.107210,  3.408240,  3.709270,
> >> > 4.010300,  4.311330,  4.612360,  4.913390,  5.214420,  5.515450,
> >> > 5.816480,  6.117510,  6.418540,
> >> > 6.719570,  7.020599,  7.321629,  7.622658,  7.923686,  8.224713,
> >> > 8.525735,  8.826751,  9.127752,
> >> > 9.428723,  9.729637, 10.030434, 10.330998, 10.631096, 10.930265,
> >> > 11.227580, 11.521213, 11.807577,
> >> > 12.079787, 12.325217, 12.523074, 12.647915, 12.693594, 12.698904,
> >> > 12.698970, 12.698970, 12.698970)
> >> > X <- 1:45
> >> > plot(Y~X)
> >> > raw_value <- predict(lm(X[1:39]~Y[1:39]), newdata =
> >data.frame(Y=6))
> >> > x <- unname(raw_value[!is.na(raw_value)]) # x= 16.62995
> >> > points(x, 6, pch = 16)
> >> > ```
> >> > Here I used the points 1:39 because afterward there is a bend. But
> >I
> >> > am not clear why I need to use `lm(X~Y),` instead of `lm(Y~X)`.
> >> > Thank you
> >> >
> >> > On Tue, Jan 26, 2021 at 10:20 AM Jeff Newmiller
> >> > <jdnewmil at dcn.davis.ca.us> wrote:
> >> > >
> >> > > model2 <- lm( x~y )
> >> > > predict(model2, data.frame(y=26))
> >> > >
> >> > > model2 is however not the inverse of model... if you need that
> >then you need to handle that some other way than using predict, such as
> >an invertible monotonic spline (or in this case a little algebra).
> >> > >
> >> > > On January 26, 2021 1:11:39 AM PST, Luigi Marongiu
> ><marongiu.luigi at gmail.com> wrote:
> >> > > >Hello,
> >> > > >I have a series of x/y and a model. I can interpolate a new
> >value of x
> >> > > >using this model, but I get funny results if I give the y and
> >look for
> >> > > >the correspondent x:
> >> > > >```
> >> > > >> x = 1:10
> >> > > >> y = 2*x+15
> >> > > >> model <- lm(y~x)
> >> > > >> predict(model, data.frame(x=7.5))
> >> > > > 1
> >> > > >30
> >> > > >> predict(model, data.frame(y=26))
> >> > > > 1  2  3  4  5  6  7  8  9 10
> >> > > >17 19 21 23 25 27 29 31 33 35
> >> > > >Warning message:
> >> > > >'newdata' had 1 row but variables found have 10 rows
> >> > > >> data.frame(x=7.5)
> >> > > >    x
> >> > > >1 7.5
> >> > > >> data.frame(y=26)
> >> > > >   y
> >> > > >1 26
> >> > > >```
> >> > > >what is the correct syntax?
> >> > > >Thank you
> >> > > >Luigi
> >> > > >
> >> > > >______________________________________________
> >> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >> > > >https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > >PLEASE do read the posting guide
> >> > > >http://www.R-project.org/posting-guide.html
> >> > > >and provide commented, minimal, self-contained, reproducible
> >code.
> >> > >
> >> > > --
> >> > > Sent from my phone. Please excuse my brevity.
> >> >
> >> >
> >> >
> >> > --
> >> > Best regards,
> >> > Luigi
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.



-- 
Best regards,
Luigi


From c@ghpm @end|ng |rom gm@||@com  Wed Jan 27 16:49:14 2021
From: c@ghpm @end|ng |rom gm@||@com (Carlos Gonzalez)
Date: Wed, 27 Jan 2021 12:49:14 -0300
Subject: [R] problem installing R and RStudio
In-Reply-To: <CAKZQJMAr-DF6yAsJMFwFDXL4aHtHcg86r8K+Lo7uDKa0jB-UJw@mail.gmail.com>
References: <CAGa55hQAOBEXX6fXL=Usjn+N=CS_SDYN0+2gKKpVEBNfVn4UKw@mail.gmail.com>
 <2422CF04-32DF-4EE2-B406-3CFEEA00B806@dcn.davis.ca.us>
 <CAKZQJMAr-DF6yAsJMFwFDXL4aHtHcg86r8K+Lo7uDKa0jB-UJw@mail.gmail.com>
Message-ID: <CAGa55hTBJVJkcmedPS0+-T3p3UXyKHvt2+_EqAbf8y5XttR0jA@mail.gmail.com>

Thank you @LucyNjoki!!! Everything runs ok now.

El mar, 26 de ene. de 2021 a la(s) 16:51, John Kane (jrkrideau at gmail.com)
escribi?:

> A couple of Window solutions
>
> https://community.rstudio.com/t/problems-with-r-4-0-0-windows-error-package-or-namespace-load-failed-for-stats-in-indl-x-as-logical-local-as-logical-now/62958
>
> https://github.com/rdotnet/rdotnet/issues/62
>
> No idea if they are of any use.
>
> On Mon, 25 Jan 2021 at 19:43, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> Your installation of R seems broken. Since RStudio sometimes tries to
>> simplify things and sometimes misses and we aren't typically up to speed
>> with their latest procedures, please describe what you did to install R in
>> terms related to the instructions on CRAN [1] and its install program. When
>> you can run R from RGui or the CMD prompt then you may get lucky and
>> RStudio will just work. If you aren't lucky connecting your working R to
>> RStudio  then you will probably need to ask them [2] for assistance.
>>
>> Also, the Posting Guide points out that this is a plain text mailing
>> list... sending HTML email through this list is erratic... if you want to
>> insure we get your message as you sent it, set your email client to send
>> plain text format.
>>
>> [1] https://cran.r-project.org/bin/windows/base/
>> [2] https://community.rstudio.com/
>>
>> On January 25, 2021 2:40:45 PM PST, Carlos Gonzalez <caghpm at gmail.com>
>> wrote:
>> >Dear,
>> >
>> >I've just installed R and RStudio. Opening RStudio the following
>> >appears in
>> >the console.
>> >
>> >
>> >R version 4.0.3 (2020-10-10) -- "Bunny-Wunnies Freak Out"
>> >Copyright (C) 2020 The R Foundation for Statistical Computing
>> >Platform: x86_64-w64-mingw32/x64 (64-bit)
>> >
>> >R is free software and comes with ABSOLUTELY NO WARRANTY.
>> >You are welcome to redistribute it under certain conditions.
>> >Type 'license()' or 'licence()' for distribution details.
>> >
>> >  Natural language support but running in an English locale
>> >
>> >R is a collaborative project with many contributors.
>> >Type 'contributors()' for more information and
>> >'citation()' on how to cite R or R packages in publications.
>> >
>> >Type 'demo()' for some demos, 'help()' for on-line help, or
>> >'help.start()' for an HTML browser interface to help.
>> >Type 'q()' to quit R.
>> >
>> >Error: package or namespace load failed for ?stats? in inDL(x,
>> >as.logical(local), as.logical(now), ...):
>> > unable to load shared object 'C:/Program
>> >Files/R/R-4.0.3/library/stats/libs/x64/stats.dll':
>> >  LoadLibrary failure:  The specified module could not be found.
>> >
>> >During startup - Warning message:
>> >package ?stats? in options("defaultPackages") was not found
>> >Error in inDL(x, as.logical(local), as.logical(now), ...) :
>> >  unable to load shared object 'C:/Program
>> >Files/R/R-4.0.3/library/stats/libs/x64/stats.dll':
>> >  LoadLibrary failure:  The specified module could not be found.
>> >>
>> >I would very much appreciate it if you could help solving this problem.
>> >
>> >Saludos / Regards
>> >
>> >Carlos A. Gonzalez
>> >Mobile +598 94 234 653
>> >caghpm at gmail.com
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> John Kane
> Kingston ON Canada
>


-- 
Saludos / Regards

Carlos A. Gonzalez
Mobile +598 94 234 653
caghpm at gmail.com

	[[alternative HTML version deleted]]


From den|@@|r@nc|@c| @end|ng |rom gm@||@com  Wed Jan 27 17:02:25 2021
From: den|@@|r@nc|@c| @end|ng |rom gm@||@com (Denis Francisci)
Date: Wed, 27 Jan 2021 17:02:25 +0100
Subject: [R] random numbers with constraints
In-Reply-To: <CAB8pepwZB0TfF5ewdfjUDjBU_Md95j4npANU9k1rpVyTp0rivg@mail.gmail.com>
References: <CAJMcJMBf=rYNc5FYB1oW5n1t7bo62_=gvbhhvd5D7Dqa_YTNFA@mail.gmail.com>
 <CAB8pepwZB0TfF5ewdfjUDjBU_Md95j4npANU9k1rpVyTp0rivg@mail.gmail.com>
Message-ID: <CAJMcJMB_g4cHZS9HpHezbOhFjVavPhZEQzoA2zj9JE3KMoDUDw@mail.gmail.com>

Wonderful!
This is exactly what I need!
Thank you very much!!

Denis



Il giorno mer 27 gen 2021 alle ore 10:58 Abby Spurdle <spurdle.a at gmail.com>
ha scritto:

> u <- runif (410)
> u <- (u - min (u) ) / diff (range (u) )
>
> constrained.sample <- function (rate)
> {   plim <- pexp (c (9.6, 11.6), rate)
>     p <- plim [1] + diff (plim) * u
>     qexp (p, rate)
> }
>
> diff.sum <- function (rate)
>     sum (constrained.sample (rate) ) - 4200
>
> rate <- uniroot (diff.sum, c (1, 2) )$root
> q <- constrained.sample (rate)
>
> length (q)
> range (q)
> sum (q)
>
>
> On Wed, Jan 27, 2021 at 9:03 PM Denis Francisci
> <denis.francisci at gmail.com> wrote:
> >
> > Hi,
> > I would like to generate random numbers in R with some constraints:
> > - my vector of numbers must contain 410 values;
> > - min value must be 9.6 and max value must be 11.6;
> > - sum of vector's values must be 4200.
> > Is there a way to do this in R?
> > And is it possible to generate this series in such a way that it follows
> a
> > specific distribution form (for example exponential)?
> > Thank you in advance,
> >
> > D.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bobby@kn|ght @end|ng |rom gm@||@com  Wed Jan 27 17:31:53 2021
From: bobby@kn|ght @end|ng |rom gm@||@com (Robert Knight)
Date: Wed, 27 Jan 2021 10:31:53 -0600
Subject: [R] Is there anyone who uses both R and Python here? How do you
 debug? Perhaps in RStudio?
In-Reply-To: <CAE2FW2=TEemXH_vgZXuYXSURFGdQoMBNRnqm9rq-7udmXZDMCw@mail.gmail.com>
References: <CAE2FW2=TEemXH_vgZXuYXSURFGdQoMBNRnqm9rq-7udmXZDMCw@mail.gmail.com>
Message-ID: <CAKBFG3YOFuTJf6ULLVji152Li_7Qa_o=GGzd5PgUbj7EGLe=oQ@mail.gmail.com>

An iterative process works well. Python to get the data desired and then
Rscript script.r from a command line.   My process involves building a
script in R using, using Rstudio, Pycharm, VS Code, Kate, or some other
editor.  Then using data input built with Python as input to Rscript. The R
scripts produce excel files or CSV data for other use   RStudio is amazing
for some slow pace academic work.  The "expected a numeric but got a char"
error appeared to often for my needs and so the workflows wound up with
Python building data that's already cleaned for use in R to avoid data
import troubles.  My code use a functional paradigm rather than object
oriented paradigm.  Python does more than just munge my data since it
handled many mathematic operations on it, but it's ultimate purpose is to
clean large amounts of data to avoid import errors in R.

On Wed, Jan 27, 2021, 1:49 AM C W <tmrsg11 at gmail.com> wrote:

> Hello all,
>
> I'm a long time R user, but recently also using Python. I noticed that
> RStudio rolled out Python through reticulate. It's great so far!
>
> My question is, how do you debug in Python?
>
> In R, I simply step through the code script in my console with cmd+enter.
> But you can't do that with Python, some of them are objects.
>
> Here's my example.
> class person:
>      def __init__(self, id, created_at, name, attend_date, distance):
>           """Create a new `person`.
>           """
>           self._id = id
>           self.created_at = created_at
>           self.name = name
>           self.attend_date = attend_date
>           self.distance = distance
>
>      @classmethod
>           def get_person(self, employee):
>           """Find and return a person by.
>           """
>           return person(employee['created_at'],
>                employee['id'],
>                employee['name'],
>                employee['attend_date'],
>                employee['distance']
>                )
>
> The error message says self._id was 'str', but expecting an 'int'. I can't
> do:
> > self._id = 5
> I guess it's "hidden". Can't really assign and test like that.
>
> It seems hardcore Python programmers just use a debugger, and do not
> understand the greatness of interactive IDE and console. I'd still like to
> stay in IDE, hopefully.
>
> So, how are the R users coping with object classes? Do you just instantiate
> every time? What if you got 10 of these class person objects to debug?
>
> I know this may be a Python question. But, I really wanted to see from a R
> user's working experience.
>
> Thanks a lot,
>
> Mike
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Wed Jan 27 17:38:26 2021
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Wed, 27 Jan 2021 10:38:26 -0600
Subject: [R] Is there anyone who uses both R and Python here? How do you
 debug? Perhaps in RStudio?
In-Reply-To: <CAKBFG3YOFuTJf6ULLVji152Li_7Qa_o=GGzd5PgUbj7EGLe=oQ@mail.gmail.com>
References: <CAE2FW2=TEemXH_vgZXuYXSURFGdQoMBNRnqm9rq-7udmXZDMCw@mail.gmail.com>
 <CAKBFG3YOFuTJf6ULLVji152Li_7Qa_o=GGzd5PgUbj7EGLe=oQ@mail.gmail.com>
Message-ID: <87cf9a9f-8852-e5f6-f87b-8fbb7770eb61@effectivedefense.org>

You can mix R and Python code in the same R Markdown vignette.  See:


https://bookdown.org/yihui/rmarkdown/language-engines.html


```{r "RcodeChunk"}
# R code
```

```{python "PythonCodeChunk"}
# Python code
```

	  I did this a couple of years ago.  I haven't used Python since. 
However, this is described in the book Xie, Allaire, and Grolemund 
(2020) R Markdown: The Definitive Guide (Chapman & Hall and available 
for free at the above link).


	  Spencer Graves


On 2021-01-27 10:31, Robert Knight wrote:
> An iterative process works well. Python to get the data desired and then
> Rscript script.r from a command line.   My process involves building a
> script in R using, using Rstudio, Pycharm, VS Code, Kate, or some other
> editor.  Then using data input built with Python as input to Rscript. The R
> scripts produce excel files or CSV data for other use   RStudio is amazing
> for some slow pace academic work.  The "expected a numeric but got a char"
> error appeared to often for my needs and so the workflows wound up with
> Python building data that's already cleaned for use in R to avoid data
> import troubles.  My code use a functional paradigm rather than object
> oriented paradigm.  Python does more than just munge my data since it
> handled many mathematic operations on it, but it's ultimate purpose is to
> clean large amounts of data to avoid import errors in R.
> 
> On Wed, Jan 27, 2021, 1:49 AM C W <tmrsg11 at gmail.com> wrote:
> 
>> Hello all,
>>
>> I'm a long time R user, but recently also using Python. I noticed that
>> RStudio rolled out Python through reticulate. It's great so far!
>>
>> My question is, how do you debug in Python?
>>
>> In R, I simply step through the code script in my console with cmd+enter.
>> But you can't do that with Python, some of them are objects.
>>
>> Here's my example.
>> class person:
>>       def __init__(self, id, created_at, name, attend_date, distance):
>>            """Create a new `person`.
>>            """
>>            self._id = id
>>            self.created_at = created_at
>>            self.name = name
>>            self.attend_date = attend_date
>>            self.distance = distance
>>
>>       @classmethod
>>            def get_person(self, employee):
>>            """Find and return a person by.
>>            """
>>            return person(employee['created_at'],
>>                 employee['id'],
>>                 employee['name'],
>>                 employee['attend_date'],
>>                 employee['distance']
>>                 )
>>
>> The error message says self._id was 'str', but expecting an 'int'. I can't
>> do:
>>> self._id = 5
>> I guess it's "hidden". Can't really assign and test like that.
>>
>> It seems hardcore Python programmers just use a debugger, and do not
>> understand the greatness of interactive IDE and console. I'd still like to
>> stay in IDE, hopefully.
>>
>> So, how are the R users coping with object classes? Do you just instantiate
>> every time? What if you got 10 of these class person objects to debug?
>>
>> I know this may be a Python question. But, I really wanted to see from a R
>> user's working experience.
>>
>> Thanks a lot,
>>
>> Mike
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From c@ghpm @end|ng |rom gm@||@com  Wed Jan 27 18:16:12 2021
From: c@ghpm @end|ng |rom gm@||@com (Carlos Gonzalez)
Date: Wed, 27 Jan 2021 14:16:12 -0300
Subject: [R] problem when loading tidyverse
Message-ID: <CAGa55hRsWS=rgcpWUBcyYFWkH6X25y5KAw+rY9rD2jgtH5Xtew@mail.gmail.com>

Why when loading tidyverse shows the following:

-- Conflicts ------------------------------------------
tidyverse_conflicts() --
x dplyr::filter() masks stats::filter()
x dplyr::lag()    masks stats::lag()

-- 
Saludos / Regards

Carlos A. Gonzalez
Mobile +598 94 234 653
caghpm at gmail.com

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan 27 18:29:43 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 27 Jan 2021 09:29:43 -0800
Subject: [R] problem when loading tidyverse
In-Reply-To: <CAGa55hRsWS=rgcpWUBcyYFWkH6X25y5KAw+rY9rD2jgtH5Xtew@mail.gmail.com>
References: <CAGa55hRsWS=rgcpWUBcyYFWkH6X25y5KAw+rY9rD2jgtH5Xtew@mail.gmail.com>
Message-ID: <DC018D24-4BEE-4D0D-AB94-63399C082C6A@dcn.davis.ca.us>

These are not errors, they are informational, and the Posting Guide points out that details of how to use contributed packages such as tidyverse are off topic (too many of them for one list).

If you want to use the versions of the functions that tidyverse is overriding, specify the desired package along with the function when you call it.

On January 27, 2021 9:16:12 AM PST, Carlos Gonzalez <caghpm at gmail.com> wrote:
>Why when loading tidyverse shows the following:
>
>-- Conflicts ------------------------------------------
>tidyverse_conflicts() --
>x dplyr::filter() masks stats::filter()
>x dplyr::lag()    masks stats::lag()

-- 
Sent from my phone. Please excuse my brevity.


From c@ghpm @end|ng |rom gm@||@com  Wed Jan 27 18:39:00 2021
From: c@ghpm @end|ng |rom gm@||@com (Carlos Gonzalez)
Date: Wed, 27 Jan 2021 14:39:00 -0300
Subject: [R] problem when loading tidyverse
In-Reply-To: <DC018D24-4BEE-4D0D-AB94-63399C082C6A@dcn.davis.ca.us>
References: <CAGa55hRsWS=rgcpWUBcyYFWkH6X25y5KAw+rY9rD2jgtH5Xtew@mail.gmail.com>
 <DC018D24-4BEE-4D0D-AB94-63399C082C6A@dcn.davis.ca.us>
Message-ID: <CAGa55hTcA8AvqPb+7CHKvcdtJxk49e==r5CoX6W5TK1d6RzomQ@mail.gmail.com>

Many thanks, Jeff. Very clear

El mi?, 27 de ene. de 2021 a la(s) 14:29, Jeff Newmiller (
jdnewmil at dcn.davis.ca.us) escribi?:

> These are not errors, they are informational, and the Posting Guide points
> out that details of how to use contributed packages such as tidyverse are
> off topic (too many of them for one list).
>
> If you want to use the versions of the functions that tidyverse is
> overriding, specify the desired package along with the function when you
> call it.
>
> On January 27, 2021 9:16:12 AM PST, Carlos Gonzalez <caghpm at gmail.com>
> wrote:
> >Why when loading tidyverse shows the following:
> >
> >-- Conflicts ------------------------------------------
> >tidyverse_conflicts() --
> >x dplyr::filter() masks stats::filter()
> >x dplyr::lag()    masks stats::lag()
>
> --
> Sent from my phone. Please excuse my brevity.
>


-- 
Saludos / Regards

Carlos A. Gonzalez
Mobile +598 94 234 653
caghpm at gmail.com

	[[alternative HTML version deleted]]


From v@|kremk @end|ng |rom gm@||@com  Wed Jan 27 18:42:28 2021
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Wed, 27 Jan 2021 12:42:28 -0500
Subject: [R] create
Message-ID: <CAJOiR6ZMHG3Cn4RY+tigud8RKbAQRMWw1XdVME3QSBFR8QsAfQ@mail.gmail.com>

Hi all, I have a sample of data as shown below,

 dt <-read.table(text="name Item check
 A  DESK      NORF
 B  RANGE   GARRA
 C  CLOCK    PALM
 D  DESK      RR
 E  ALARM    DESPRF
 H  DESK       RF
 K  DESK      CORR
 K  WARF     CORR
 G  NONE      RF ",header=TRUE, fill=T)

I want create  another  column (flag2) and assign a value  0 or 1
if the check column values are  within  code2 list  and Item is DESK
then flag2 =1 otherwise 0

code2=c("RR","RF")
index2=grep(paste(code2,collapse="|"),dt$check)

dt$flag2=0
dt$flag2[index2]=1
How can I add the second condition?


Desired output  is  shown below
     name Item        check        flag2
1    A       DESK     NORF          0
2    B       RANGE  GARRA       0
3    C       CLOCK  PALM          0
4    D      DESK      RR              1
5    E      ALARM   DESPRF      0
6    H      DESK      RF               1
7    K     DESK      CORR          0
8    K     WARF     CORR          0
9    G     NONE      RF               0

Thank you,


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jan 27 19:27:22 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 27 Jan 2021 10:27:22 -0800
Subject: [R] create
In-Reply-To: <CAJOiR6ZMHG3Cn4RY+tigud8RKbAQRMWw1XdVME3QSBFR8QsAfQ@mail.gmail.com>
References: <CAJOiR6ZMHG3Cn4RY+tigud8RKbAQRMWw1XdVME3QSBFR8QsAfQ@mail.gmail.com>
Message-ID: <CAGxFJbTu=UOLN4fdrpcW5zBJapSnd02UpvjOG_c5LU7K+VqU4Q@mail.gmail.com>

Thanks for the reprex. I think this is one way to do what you want:
dt$flag2 <- 0 + with(dt,Item == "DESK" & check %in% code2)

> dt$flag2 <- 0 + with(dt,Item == "DESK" & check %in% code2)
> dt
  name  Item  check flag2
1    A  DESK   NORF     0
2    B RANGE  GARRA     0
3    C CLOCK   PALM     0
4    D  DESK     RR     1
5    E ALARM DESPRF     0
6    H  DESK     RF     1
7    K  DESK   CORR     0
8    K  WARF   CORR     0
9    G  NONE     RF     0

This uses:
1) logical coerced to numeric by 0 + ... construction , which is probably
unnecessary: leave it as logical
2) ?"%in%"
3) ?with

The first two are fairly basic and should be covered in most decent basic R
tutorials. Spending some time with one or more will probably save you a lot
of time and aggravation later. The with() function is somewhat more
advanced, but can save lazy people (= me) a lot of typing hassle.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 27, 2021 at 9:48 AM Val <valkremk at gmail.com> wrote:

> Hi all, I have a sample of data as shown below,
>
>  dt <-read.table(text="name Item check
>  A  DESK      NORF
>  B  RANGE   GARRA
>  C  CLOCK    PALM
>  D  DESK      RR
>  E  ALARM    DESPRF
>  H  DESK       RF
>  K  DESK      CORR
>  K  WARF     CORR
>  G  NONE      RF ",header=TRUE, fill=T)
>
> I want create  another  column (flag2) and assign a value  0 or 1
> if the check column values are  within  code2 list  and Item is DESK
> then flag2 =1 otherwise 0
>
> code2=c("RR","RF")
> index2=grep(paste(code2,collapse="|"),dt$check)
>
> dt$flag2=0
> dt$flag2[index2]=1
> How can I add the second condition?
>
>
> Desired output  is  shown below
>      name Item        check        flag2
> 1    A       DESK     NORF          0
> 2    B       RANGE  GARRA       0
> 3    C       CLOCK  PALM          0
> 4    D      DESK      RR              1
> 5    E      ALARM   DESPRF      0
> 6    H      DESK      RF               1
> 7    K     DESK      CORR          0
> 8    K     WARF     CORR          0
> 9    G     NONE      RF               0
>
> Thank you,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Wed Jan 27 19:34:37 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Wed, 27 Jan 2021 10:34:37 -0800
Subject: [R] Error when calling (R 4.0.x on Windows) from Python
In-Reply-To: <24593.9866.492194.548636@stat.math.ethz.ch>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
 <24591.65302.527022.733577@stat.math.ethz.ch>
 <24593.9866.492194.548636@stat.math.ethz.ch>
Message-ID: <CAHqSRuSki0Dut15jMQUfwGCb_TFnV2o9MdKOv4+F76so_nSJbQ@mail.gmail.com>

Note that in R-3.6.3 commandArgs() does not include the arguments
intended to be processed by the shell, "1>", "arguments.txt", etc.,
but in R-4.0.3 it does include them.  It is as though an R shell()
command was replaced by a system() command so cmd.exe didn't get a
chance to process the command line.

-Bill

On Wed, Jan 27, 2021 at 12:39 AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Martin Maechler
> >>>>>     on Tue, 26 Jan 2021 12:37:58 +0100 writes:
>
> >>>>> Marcel Baumgartner
> >>>>>     on Tue, 26 Jan 2021 08:55:48 +0100 writes:
>
>     >> Dear all, my colleague posted our issue on stackoverflow:
>
>     >> Calling R script from Python does not save log file in
>     >> version 4 - Stack Overflow
>     >> [https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]
>
>     >> It is about this kind of call to R:
>
>     >> R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1".
>
>     >> The issue is that the log.txt file is not created when
>     >> running R 4.x.x. The same code works perfectly fine with
>     >> R 3.6.x.
>
>     >> Any idea what's going wrong as of version 4? Regards
>     >> Marcel
>
>     > Dear Marcel, I think the solution is embarrassingly
>     > simple:
>
>     >> From the SO post, where she showed a bit more detail than you
>     > show here, it's clear you have confused 'R.exe' and
>     > 'Rscript.exe' and what you say above is not true:
>
>     > 'R.exe' was used for R 3.6.0 but for R 4.0.3, you/she used
>     > 'Rscript.exe' instead.
>
>
>     > ... as you've noticed now, they do behave differently,
>     > indeed!
>
> Well, this was not the solution to their -- Windows-only -- problem.
> The problem *is* indeed visible if they only use  R.exe  (also
> for R 4.0.3).
>
> I've commented more on the SO issue (see above),
> notably asking for a *minimal* repr.ex. (reproducible example),
> and one *not* using "<YOUR PATH>" and setwd() ..
>
> Martin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Wed Jan 27 19:50:42 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Wed, 27 Jan 2021 10:50:42 -0800
Subject: [R] Error when calling (R 4.0.x on Windows) from Python
In-Reply-To: <CAHqSRuSki0Dut15jMQUfwGCb_TFnV2o9MdKOv4+F76so_nSJbQ@mail.gmail.com>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
 <24591.65302.527022.733577@stat.math.ethz.ch>
 <24593.9866.492194.548636@stat.math.ethz.ch>
 <CAHqSRuSki0Dut15jMQUfwGCb_TFnV2o9MdKOv4+F76so_nSJbQ@mail.gmail.com>
Message-ID: <CAHqSRuRRSm5e1M9uCmM=47WkqQhX50pMyLaAZcUSPJbtTX8eOw@mail.gmail.com>

I mistyped, 3.6.3 omits "1>", "log.txt" (not arguments.txt"), etc.  My
test was run in C:\tmp and used -e instead of -f and bin/R.exe instead
of bin/x64/R.exe, using the following python script:

import subprocess

cmd363 = " ".join(["C:/R/R-3.6.3/bin/R.exe", "--vanilla", "--quiet",
         # "-f", '"code.R"',
         "-e", '"commandArgs()"',
         "--args", '"' + 'arguments.txt"',"1>", '"' + 'log363.txt"', "2>&1"])
print(cmd363)
status363 = subprocess.call(cmd363)

cmd403 = " ".join(["C:/R/R-4.0.3/bin/R.exe", "--vanilla", "--quiet",
         # "-f", '"code.R"',
         "-e", '"commandArgs()"',
         "--args", '"' + 'arguments.txt"',"1>", '"' + 'log403.txt"', "2>&1"])
print(cmd403)
status403 = subprocess.call(cmd403)

This gave

>>> import subprocess
>>>
>>> cmd363 = " ".join(["C:/R/R-3.6.3/bin/R.exe", "--vanilla", "--quiet",
...          # "-f", '"code.R"',
...          "-e", '"commandArgs()"',
...          "--args", '"' + 'arguments.txt"',"1>", '"' +
'log363.txt"', "2>&1"])
>>> print(cmd363)
C:/R/R-3.6.3/bin/R.exe --vanilla --quiet -e "commandArgs()" --args
"arguments.txt" 1> "log363.txt" 2>&1
>>> status363 = subprocess.call(cmd363)
>>>
>>> cmd403 = " ".join(["C:/R/R-4.0.3/bin/R.exe", "--vanilla", "--quiet",
...          # "-f", '"code.R"',
...          "-e", '"commandArgs()"',
...          "--args", '"' + 'arguments.txt"',"1>", '"' +
'log403.txt"', "2>&1"])
>>> print(cmd403)
C:/R/R-4.0.3/bin/R.exe --vanilla --quiet -e "commandArgs()" --args
"arguments.txt" 1> "log403.txt" 2>&1
>>> status403 = subprocess.call(cmd403)
> commandArgs()
 [1] "C:\\R\\R-4.0.3/bin/x64/Rterm.exe" "--vanilla"
 [3] "--quiet"                          "-e"
 [5] "commandArgs()"                    "--args"
 [7] "arguments.txt"                    "1>"
 [9] "log403.txt"                       "2>&1"

After exiting python I log403.txt does not exist and log363.txt shows
the command arguments that R got:

C:\R\R-3.6.3>cat log403.txt
cat: log403.txt: No such file or directory

C:\R\R-3.6.3>cat log363.txt
> commandArgs()
[1] "C:\\R\\R-3.6.3/bin/x64/Rterm.exe" "--vanilla"
[3] "--quiet"                          "-e"
[5] "commandArgs()"                    "--args"
[7] "arguments.txt"

On Wed, Jan 27, 2021 at 10:34 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> Note that in R-3.6.3 commandArgs() does not include the arguments
> intended to be processed by the shell, "1>", "arguments.txt", etc.,
> but in R-4.0.3 it does include them.  It is as though an R shell()
> command was replaced by a system() command so cmd.exe didn't get a
> chance to process the command line.
>
> -Bill
>
> On Wed, Jan 27, 2021 at 12:39 AM Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
> >
> > >>>>> Martin Maechler
> > >>>>>     on Tue, 26 Jan 2021 12:37:58 +0100 writes:
> >
> > >>>>> Marcel Baumgartner
> > >>>>>     on Tue, 26 Jan 2021 08:55:48 +0100 writes:
> >
> >     >> Dear all, my colleague posted our issue on stackoverflow:
> >
> >     >> Calling R script from Python does not save log file in
> >     >> version 4 - Stack Overflow
> >     >> [https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]
> >
> >     >> It is about this kind of call to R:
> >
> >     >> R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1".
> >
> >     >> The issue is that the log.txt file is not created when
> >     >> running R 4.x.x. The same code works perfectly fine with
> >     >> R 3.6.x.
> >
> >     >> Any idea what's going wrong as of version 4? Regards
> >     >> Marcel
> >
> >     > Dear Marcel, I think the solution is embarrassingly
> >     > simple:
> >
> >     >> From the SO post, where she showed a bit more detail than you
> >     > show here, it's clear you have confused 'R.exe' and
> >     > 'Rscript.exe' and what you say above is not true:
> >
> >     > 'R.exe' was used for R 3.6.0 but for R 4.0.3, you/she used
> >     > 'Rscript.exe' instead.
> >
> >
> >     > ... as you've noticed now, they do behave differently,
> >     > indeed!
> >
> > Well, this was not the solution to their -- Windows-only -- problem.
> > The problem *is* indeed visible if they only use  R.exe  (also
> > for R 4.0.3).
> >
> > I've commented more on the SO issue (see above),
> > notably asking for a *minimal* repr.ex. (reproducible example),
> > and one *not* using "<YOUR PATH>" and setwd() ..
> >
> > Martin
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jan 27 20:48:06 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 28 Jan 2021 08:48:06 +1300
Subject: [R] random numbers with constraints
In-Reply-To: <CAJMcJMB_g4cHZS9HpHezbOhFjVavPhZEQzoA2zj9JE3KMoDUDw@mail.gmail.com>
References: <CAJMcJMBf=rYNc5FYB1oW5n1t7bo62_=gvbhhvd5D7Dqa_YTNFA@mail.gmail.com>
 <CAB8pepwZB0TfF5ewdfjUDjBU_Md95j4npANU9k1rpVyTp0rivg@mail.gmail.com>
 <CAJMcJMB_g4cHZS9HpHezbOhFjVavPhZEQzoA2zj9JE3KMoDUDw@mail.gmail.com>
Message-ID: <CAB8pepzpH3YshbF-jtqJ9o5zh2MSaMT2T=6j+mQqWH0j6nsVRQ@mail.gmail.com>

I note that there's a possibility of floating point errors.
If all values have one digit after the decimal point, you could replace:
qexp (p, rate) with round (qexp (p, rate), 1).

However, sometimes uniroot will fail, due to problems with input.

On Thu, Jan 28, 2021 at 5:02 AM Denis Francisci
<denis.francisci at gmail.com> wrote:
>
> Wonderful!
> This is exactly what I need!
> Thank you very much!!
>
> Denis
>
>
>
> Il giorno mer 27 gen 2021 alle ore 10:58 Abby Spurdle <spurdle.a at gmail.com> ha scritto:
>>
>> u <- runif (410)
>> u <- (u - min (u) ) / diff (range (u) )
>>
>> constrained.sample <- function (rate)
>> {   plim <- pexp (c (9.6, 11.6), rate)
>>     p <- plim [1] + diff (plim) * u
>>     qexp (p, rate)
>> }
>>
>> diff.sum <- function (rate)
>>     sum (constrained.sample (rate) ) - 4200
>>
>> rate <- uniroot (diff.sum, c (1, 2) )$root
>> q <- constrained.sample (rate)
>>
>> length (q)
>> range (q)
>> sum (q)
>>
>>
>> On Wed, Jan 27, 2021 at 9:03 PM Denis Francisci
>> <denis.francisci at gmail.com> wrote:
>> >
>> > Hi,
>> > I would like to generate random numbers in R with some constraints:
>> > - my vector of numbers must contain 410 values;
>> > - min value must be 9.6 and max value must be 11.6;
>> > - sum of vector's values must be 4200.
>> > Is there a way to do this in R?
>> > And is it possible to generate this series in such a way that it follows a
>> > specific distribution form (for example exponential)?
>> > Thank you in advance,
>> >
>> > D.
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jan 27 21:17:20 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 27 Jan 2021 15:17:20 -0500
Subject: [R] Error when calling (R 4.0.x on Windows) from Python
In-Reply-To: <24593.9866.492194.548636@stat.math.ethz.ch>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
 <24591.65302.527022.733577@stat.math.ethz.ch>
 <24593.9866.492194.548636@stat.math.ethz.ch>
Message-ID: <dce1a81a-a543-bbbc-24f3-54d64eae2b80@gmail.com>

On 27/01/2021 3:38 a.m., Martin Maechler wrote:
>>>>>> Martin Maechler
>>>>>>      on Tue, 26 Jan 2021 12:37:58 +0100 writes:
> 
>>>>>> Marcel Baumgartner
>>>>>>      on Tue, 26 Jan 2021 08:55:48 +0100 writes:
> 
>      >> Dear all, my colleague posted our issue on stackoverflow:
> 
>      >> Calling R script from Python does not save log file in
>      >> version 4 - Stack Overflow
>      >> [https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]
> 
>      >> It is about this kind of call to R:
> 
>      >> R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1".
> 
>      >> The issue is that the log.txt file is not created when
>      >> running R 4.x.x. The same code works perfectly fine with
>      >> R 3.6.x.
> 
>      >> Any idea what's going wrong as of version 4? Regards
>      >> Marcel
> 
>      > Dear Marcel, I think the solution is embarrassingly
>      > simple:
> 
>      >> From the SO post, where she showed a bit more detail than you
>      > show here, it's clear you have confused 'R.exe' and
>      > 'Rscript.exe' and what you say above is not true:
> 
>      > 'R.exe' was used for R 3.6.0 but for R 4.0.3, you/she used
>      > 'Rscript.exe' instead.
> 
> 
>      > ... as you've noticed now, they do behave differently,
>      > indeed!
> 
> Well, this was not the solution to their -- Windows-only -- problem.
> The problem *is* indeed visible if they only use  R.exe  (also
> for R 4.0.3).
> 
> I've commented more on the SO issue (see above),
> notably asking for a *minimal* repr.ex. (reproducible example),
> and one *not* using "<YOUR PATH>" and setwd() ..
> 

Isn't this purely a Python or user problem?  R shouldn't process 
redirection directives like

   1> "~/log.txt" 2>&1

because it's the shell's job to process those. If Python is acting as 
the shell, it needs to handle those things.  If R was handling the 
command via

Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jan 27 21:26:08 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 27 Jan 2021 15:26:08 -0500
Subject: [R] Error when calling (R 4.0.x on Windows) from Python
In-Reply-To: <dce1a81a-a543-bbbc-24f3-54d64eae2b80@gmail.com>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
 <24591.65302.527022.733577@stat.math.ethz.ch>
 <24593.9866.492194.548636@stat.math.ethz.ch>
 <dce1a81a-a543-bbbc-24f3-54d64eae2b80@gmail.com>
Message-ID: <aa6df17c-8684-3140-a545-65d217882c1b@gmail.com>

On 27/01/2021 3:17 p.m., Duncan Murdoch wrote:
> On 27/01/2021 3:38 a.m., Martin Maechler wrote:
>>>>>>> Martin Maechler
>>>>>>>       on Tue, 26 Jan 2021 12:37:58 +0100 writes:
>>
>>>>>>> Marcel Baumgartner
>>>>>>>       on Tue, 26 Jan 2021 08:55:48 +0100 writes:
>>
>>       >> Dear all, my colleague posted our issue on stackoverflow:
>>
>>       >> Calling R script from Python does not save log file in
>>       >> version 4 - Stack Overflow
>>       >> [https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]
>>
>>       >> It is about this kind of call to R:
>>
>>       >> R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1".
>>
>>       >> The issue is that the log.txt file is not created when
>>       >> running R 4.x.x. The same code works perfectly fine with
>>       >> R 3.6.x.
>>
>>       >> Any idea what's going wrong as of version 4? Regards
>>       >> Marcel
>>
>>       > Dear Marcel, I think the solution is embarrassingly
>>       > simple:
>>
>>       >> From the SO post, where she showed a bit more detail than you
>>       > show here, it's clear you have confused 'R.exe' and
>>       > 'Rscript.exe' and what you say above is not true:
>>
>>       > 'R.exe' was used for R 3.6.0 but for R 4.0.3, you/she used
>>       > 'Rscript.exe' instead.
>>
>>
>>       > ... as you've noticed now, they do behave differently,
>>       > indeed!
>>
>> Well, this was not the solution to their -- Windows-only -- problem.
>> The problem *is* indeed visible if they only use  R.exe  (also
>> for R 4.0.3).
>>
>> I've commented more on the SO issue (see above),
>> notably asking for a *minimal* repr.ex. (reproducible example),
>> and one *not* using "<YOUR PATH>" and setwd() ..
>>
> 
> Isn't this purely a Python or user problem?  R shouldn't process
> redirection directives like
> 
>     1> "~/log.txt" 2>&1
> 
> because it's the shell's job to process those. If Python is acting as
> the shell, it needs to handle those things.  If R was handling the
> command via

Oops, sent before finishing:

If R was handling the command via system() or system2(), it would handle 
redirection itself. If it was using the Windows-only shell(), it would 
call cmd.exe (by default) to handle redirection.  (This is a difference 
between R on Windows and R in Unix:  in Unix a shell is always used.)

Duncan Murdoch


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed Jan 27 21:35:23 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 27 Jan 2021 20:35:23 +0000 (UTC)
Subject: [R] Get 3 values not only 1
References: <804776724.983972.1611779723872.ref@mail.yahoo.com>
Message-ID: <804776724.983972.1611779723872@mail.yahoo.com>

Dear R-experts,

Here below my R code working but I would like to get 3 values not only 1. The value I get is, according to my R code, the variance value. My goal is to get 3 values : the bias value, the variance value and the MSE value. How to solve my problem ?

Many thanks.

####################
# Data
PIB.hab<-c(12000,34000,25000,43000,12500,32400,76320,45890,76345,90565,76580,45670,23450,34560,65430,65435,56755,87655,90755,45675)
ISQ.2018<-c(564,587,489,421,478,499,521,510,532,476,421,467,539,521,478,532,449,487,465,500)

Dataset=data.frame(ISQ.2018,PIB.hab) 

#plot
plot(ISQ.2018,PIB.hab)
plot(ISQ.2018,PIB.hab, main="Droite de r?gression lin?aire", xlab="Score ISQ 2018", ylab="PIB/hab")

#OLS fit
fit1<-lm(PIB.hab~ISQ.2018)
lines(ISQ.2018, fitted(fit1), col="blue", lwd=2)

# Create a list to store the results
lst<-list()

# This statement does the repetitions (looping)

for(i in 1?:1000)
{

n=dim(Dataset)[1]
p=0.667
sam<-sample(1?:n,floor(p*n),replace=FALSE)
Training <-Dataset [sam,]
Testing <- Dataset [-sam,]
fit2<-lm(PIB.hab~ISQ.2018) 
ypred<-predict(fit2,newdata=Testing)
y<-Dataset[-sam,]$PIB.hab
MSE <- mean((y-ypred)^2)
biais <- mean(ypred-y)
variance <-mean((ypred- mean(ypred))^2)

lst[i]<-MSE
lst[i]<-biais
lst[i]<-variance

}
mean(unlist(lst))
####################


From w||||@mwdun|@p @end|ng |rom gm@||@com  Wed Jan 27 21:40:50 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Wed, 27 Jan 2021 12:40:50 -0800
Subject: [R] Error when calling (R 4.0.x on Windows) from Python
In-Reply-To: <aa6df17c-8684-3140-a545-65d217882c1b@gmail.com>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
 <24591.65302.527022.733577@stat.math.ethz.ch>
 <24593.9866.492194.548636@stat.math.ethz.ch>
 <dce1a81a-a543-bbbc-24f3-54d64eae2b80@gmail.com>
 <aa6df17c-8684-3140-a545-65d217882c1b@gmail.com>
Message-ID: <CAHqSRuTFc8x=mox=55s7HZHpWeOdzaR_oMev6kv=Yp8XiNzsSQ@mail.gmail.com>

I believe the problem is from svn 77925 in gnuwin/front-ends/rcmdfn.c,
which was committed a few days after 3.6.3 was released.  Rterm used
to put double quotes around a command line argument only if it
contained a space, now it double quotes all arguments.  It sees shell
constructs like "1>" and the following file name as arguments and
double quoting them hides them from the shell, leading to this
problem.  I think we may have to rely on the user supplying quotes as
needed instead of blindly adding them.

-Bill

On Wed, Jan 27, 2021 at 12:28 PM Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>
> On 27/01/2021 3:17 p.m., Duncan Murdoch wrote:
> > On 27/01/2021 3:38 a.m., Martin Maechler wrote:
> >>>>>>> Martin Maechler
> >>>>>>>       on Tue, 26 Jan 2021 12:37:58 +0100 writes:
> >>
> >>>>>>> Marcel Baumgartner
> >>>>>>>       on Tue, 26 Jan 2021 08:55:48 +0100 writes:
> >>
> >>       >> Dear all, my colleague posted our issue on stackoverflow:
> >>
> >>       >> Calling R script from Python does not save log file in
> >>       >> version 4 - Stack Overflow
> >>       >> [https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]
> >>
> >>       >> It is about this kind of call to R:
> >>
> >>       >> R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1".
> >>
> >>       >> The issue is that the log.txt file is not created when
> >>       >> running R 4.x.x. The same code works perfectly fine with
> >>       >> R 3.6.x.
> >>
> >>       >> Any idea what's going wrong as of version 4? Regards
> >>       >> Marcel
> >>
> >>       > Dear Marcel, I think the solution is embarrassingly
> >>       > simple:
> >>
> >>       >> From the SO post, where she showed a bit more detail than you
> >>       > show here, it's clear you have confused 'R.exe' and
> >>       > 'Rscript.exe' and what you say above is not true:
> >>
> >>       > 'R.exe' was used for R 3.6.0 but for R 4.0.3, you/she used
> >>       > 'Rscript.exe' instead.
> >>
> >>
> >>       > ... as you've noticed now, they do behave differently,
> >>       > indeed!
> >>
> >> Well, this was not the solution to their -- Windows-only -- problem.
> >> The problem *is* indeed visible if they only use  R.exe  (also
> >> for R 4.0.3).
> >>
> >> I've commented more on the SO issue (see above),
> >> notably asking for a *minimal* repr.ex. (reproducible example),
> >> and one *not* using "<YOUR PATH>" and setwd() ..
> >>
> >
> > Isn't this purely a Python or user problem?  R shouldn't process
> > redirection directives like
> >
> >     1> "~/log.txt" 2>&1
> >
> > because it's the shell's job to process those. If Python is acting as
> > the shell, it needs to handle those things.  If R was handling the
> > command via
>
> Oops, sent before finishing:
>
> If R was handling the command via system() or system2(), it would handle
> redirection itself. If it was using the Windows-only shell(), it would
> call cmd.exe (by default) to handle redirection.  (This is a difference
> between R on Windows and R in Unix:  in Unix a shell is always used.)
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Jan 27 21:52:21 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 28 Jan 2021 07:52:21 +1100
Subject: [R] Get 3 values not only 1
In-Reply-To: <804776724.983972.1611779723872@mail.yahoo.com>
References: <804776724.983972.1611779723872.ref@mail.yahoo.com>
 <804776724.983972.1611779723872@mail.yahoo.com>
Message-ID: <CA+8X3fVcCKEF6i5paPh4mSErcTXdKo5hT4JpKfoG=MA-x-vOOw@mail.gmail.com>

Hi varin,
How about this:

Mbv<-data.frame(MSE=rep(NA,1000),
 biais=rep(NA,1000),variance=rep(NA,1000))
for(i in 1 :1000) {
 n<-dim(Dataset)[1]
 p<-0.667
 sam<-sample(1 :n,floor(p*n),replace=FALSE)
 Training <-Dataset [sam,]
Testing <- Dataset [-sam,]
 fit2<-lm(PIB.hab~ISQ.2018)
 ypred<-predict(fit2,newdata=Testing)
 y<-Dataset[-sam,]$PIB.hab
 Mbv$MSE[i] <- mean((y-ypred)^2)
 Mbv$biais[i] <- mean(ypred-y)
 Mbv$variance[i] <-mean((ypred- mean(ypred))^2)
}

You can then do what you wish to the data frame Mbv.

Jim

On Thu, Jan 28, 2021 at 7:37 AM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> Here below my R code working but I would like to get 3 values not only 1. The value I get is, according to my R code, the variance value. My goal is to get 3 values : the bias value, the variance value and the MSE value. How to solve my problem ?
>
> Many thanks.


From jho|tm@n @end|ng |rom gm@||@com  Wed Jan 27 21:58:58 2021
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Wed, 27 Jan 2021 12:58:58 -0800
Subject: [R] Get 3 values not only 1
In-Reply-To: <804776724.983972.1611779723872@mail.yahoo.com>
References: <804776724.983972.1611779723872.ref@mail.yahoo.com>
 <804776724.983972.1611779723872@mail.yahoo.com>
Message-ID: <CAAxdm-5o6sfvJdiz=qPgKfC7Q0kfYkxra5WdfK=-OKOpWgO9Rg@mail.gmail.com>

Is this what you are after?  You need to store a vector in the list:

> ####################
> # Data
> PIB.hab<-c(12000,34000,25000,43000,12500,32400,76320,45890,76345,90565,76580,45670,23450,34560,65430,65435,56755,87655,90755,45675)
> ISQ.2018<-c(564,587,489,421,478,499,521,510,532,476,421,467,539,521,478,532,449,487,465,500)
>
> Dataset=data.frame(ISQ.2018,PIB.hab)
>
> #plot
> plot(ISQ.2018,PIB.hab)
> plot(ISQ.2018,PIB.hab, main="Droite de r?gression lin?aire", xlab="Score ISQ 2018", ylab="PIB/hab")
>
> #OLS fit
> fit1<-lm(PIB.hab~ISQ.2018)
> lines(ISQ.2018, fitted(fit1), col="blue", lwd=2)
>
> # Create a list to store the results
> lst<-list()
>
> # This statement does the repetitions (looping)
>
> for(i in 1 :1000)
+ {
+
+   n=dim(Dataset)[1]
+   p=0.667
+   sam<-sample(1 :n,floor(p*n),replace=FALSE)
+   Training <-Dataset [sam,]
+   Testing <- Dataset [-sam,]
+   fit2<-lm(PIB.hab~ISQ.2018)
+   ypred<-predict(fit2,newdata=Testing)
+   y<-Dataset[-sam,]$PIB.hab
+   MSE <- mean((y-ypred)^2)
+   biais <- mean(ypred-y)
+   variance <-mean((ypred- mean(ypred))^2)
+
+   lst[[i]] <- c(MSE = MSE,
+                    biais = biais,
+                    variance = variance)
+   # lst[i]<-MSE
+   # lst[i]<-biais
+   # lst[i]<-variance
+
+ }
>
> # convert to a matrix
>
> x <- as.matrix(do.call(rbind, lst))
> colMeans(x)
           MSE         biais      variance
  5.418175e+08 -4.524548e+01  6.321856e+07
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Jan 27, 2021 at 12:37 PM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> Here below my R code working but I would like to get 3 values not only 1. The value I get is, according to my R code, the variance value. My goal is to get 3 values : the bias value, the variance value and the MSE value. How to solve my problem ?
>
> Many thanks.
>
> ####################
> # Data
> PIB.hab<-c(12000,34000,25000,43000,12500,32400,76320,45890,76345,90565,76580,45670,23450,34560,65430,65435,56755,87655,90755,45675)
> ISQ.2018<-c(564,587,489,421,478,499,521,510,532,476,421,467,539,521,478,532,449,487,465,500)
>
> Dataset=data.frame(ISQ.2018,PIB.hab)
>
> #plot
> plot(ISQ.2018,PIB.hab)
> plot(ISQ.2018,PIB.hab, main="Droite de r?gression lin?aire", xlab="Score ISQ 2018", ylab="PIB/hab")
>
> #OLS fit
> fit1<-lm(PIB.hab~ISQ.2018)
> lines(ISQ.2018, fitted(fit1), col="blue", lwd=2)
>
> # Create a list to store the results
> lst<-list()
>
> # This statement does the repetitions (looping)
>
> for(i in 1 :1000)
> {
>
> n=dim(Dataset)[1]
> p=0.667
> sam<-sample(1 :n,floor(p*n),replace=FALSE)
> Training <-Dataset [sam,]
> Testing <- Dataset [-sam,]
> fit2<-lm(PIB.hab~ISQ.2018)
> ypred<-predict(fit2,newdata=Testing)
> y<-Dataset[-sam,]$PIB.hab
> MSE <- mean((y-ypred)^2)
> biais <- mean(ypred-y)
> variance <-mean((ypred- mean(ypred))^2)
>
> lst[i]<-MSE
> lst[i]<-biais
> lst[i]<-variance
>
> }
> mean(unlist(lst))
> ####################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jan 27 22:25:08 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 27 Jan 2021 16:25:08 -0500
Subject: [R] Error when calling (R 4.0.x on Windows) from Python
In-Reply-To: <CAHqSRuTFc8x=mox=55s7HZHpWeOdzaR_oMev6kv=Yp8XiNzsSQ@mail.gmail.com>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
 <24591.65302.527022.733577@stat.math.ethz.ch>
 <24593.9866.492194.548636@stat.math.ethz.ch>
 <dce1a81a-a543-bbbc-24f3-54d64eae2b80@gmail.com>
 <aa6df17c-8684-3140-a545-65d217882c1b@gmail.com>
 <CAHqSRuTFc8x=mox=55s7HZHpWeOdzaR_oMev6kv=Yp8XiNzsSQ@mail.gmail.com>
Message-ID: <37bf94d0-873a-5bef-87ee-60bd572c8545@gmail.com>

On 27/01/2021 3:40 p.m., Bill Dunlap wrote:
> I believe the problem is from svn 77925 in gnuwin/front-ends/rcmdfn.c,
> which was committed a few days after 3.6.3 was released.  Rterm used
> to put double quotes around a command line argument only if it
> contained a space, now it double quotes all arguments.  It sees shell
> constructs like "1>" and the following file name as arguments and
> double quoting them hides them from the shell, leading to this
> problem.  I think we may have to rely on the user supplying quotes as
> needed instead of blindly adding them.

Okay, now I see what you mean.

If you invoke R using R.exe, it asks cmd.exe to run Rterm.exe, so it is 
possible that redirection would be handled.

If you invoke R directly using Rterm.exe, then my description down below 
would be correct.

Duncan Murdoch


> 
> -Bill
> 
> On Wed, Jan 27, 2021 at 12:28 PM Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>>
>> On 27/01/2021 3:17 p.m., Duncan Murdoch wrote:
>>> On 27/01/2021 3:38 a.m., Martin Maechler wrote:
>>>>>>>>> Martin Maechler
>>>>>>>>>        on Tue, 26 Jan 2021 12:37:58 +0100 writes:
>>>>
>>>>>>>>> Marcel Baumgartner
>>>>>>>>>        on Tue, 26 Jan 2021 08:55:48 +0100 writes:
>>>>
>>>>        >> Dear all, my colleague posted our issue on stackoverflow:
>>>>
>>>>        >> Calling R script from Python does not save log file in
>>>>        >> version 4 - Stack Overflow
>>>>        >> [https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]
>>>>
>>>>        >> It is about this kind of call to R:
>>>>
>>>>        >> R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1".
>>>>
>>>>        >> The issue is that the log.txt file is not created when
>>>>        >> running R 4.x.x. The same code works perfectly fine with
>>>>        >> R 3.6.x.
>>>>
>>>>        >> Any idea what's going wrong as of version 4? Regards
>>>>        >> Marcel
>>>>
>>>>        > Dear Marcel, I think the solution is embarrassingly
>>>>        > simple:
>>>>
>>>>        >> From the SO post, where she showed a bit more detail than you
>>>>        > show here, it's clear you have confused 'R.exe' and
>>>>        > 'Rscript.exe' and what you say above is not true:
>>>>
>>>>        > 'R.exe' was used for R 3.6.0 but for R 4.0.3, you/she used
>>>>        > 'Rscript.exe' instead.
>>>>
>>>>
>>>>        > ... as you've noticed now, they do behave differently,
>>>>        > indeed!
>>>>
>>>> Well, this was not the solution to their -- Windows-only -- problem.
>>>> The problem *is* indeed visible if they only use  R.exe  (also
>>>> for R 4.0.3).
>>>>
>>>> I've commented more on the SO issue (see above),
>>>> notably asking for a *minimal* repr.ex. (reproducible example),
>>>> and one *not* using "<YOUR PATH>" and setwd() ..
>>>>
>>>
>>> Isn't this purely a Python or user problem?  R shouldn't process
>>> redirection directives like
>>>
>>>      1> "~/log.txt" 2>&1
>>>
>>> because it's the shell's job to process those. If Python is acting as
>>> the shell, it needs to handle those things.  If R was handling the
>>> command via
>>
>> Oops, sent before finishing:
>>
>> If R was handling the command via system() or system2(), it would handle
>> redirection itself. If it was using the Windows-only shell(), it would
>> call cmd.exe (by default) to handle redirection.  (This is a difference
>> between R on Windows and R in Unix:  in Unix a shell is always used.)
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Wed Jan 27 23:14:36 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Wed, 27 Jan 2021 14:14:36 -0800
Subject: [R] Error when calling (R 4.0.x on Windows) from Python
In-Reply-To: <37bf94d0-873a-5bef-87ee-60bd572c8545@gmail.com>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
 <24591.65302.527022.733577@stat.math.ethz.ch>
 <24593.9866.492194.548636@stat.math.ethz.ch>
 <dce1a81a-a543-bbbc-24f3-54d64eae2b80@gmail.com>
 <aa6df17c-8684-3140-a545-65d217882c1b@gmail.com>
 <CAHqSRuTFc8x=mox=55s7HZHpWeOdzaR_oMev6kv=Yp8XiNzsSQ@mail.gmail.com>
 <37bf94d0-873a-5bef-87ee-60bd572c8545@gmail.com>
Message-ID: <CAHqSRuSOYk=aWzKg9Ub4LN+hXTZ8ptZDw7gzrxt67957kNDwXQ@mail.gmail.com>

I tried the following change, that adds quotes if the argument does
not include ">".
Index: front-ends/rcmdfn.c
===================================================================
--- front-ends/rcmdfn.c (revision 79883)
+++ front-ends/rcmdfn.c (working copy)
@@ -173,9 +173,13 @@
                fprintf(stderr, "command line too long\n");
                return(27);
            }
-           strcat(cmd, "\"");
+           if (!strchr(argv[i], '>')) {
+                strcat(cmd, "\"");
+            }
            strcat(cmd, argv[i]);
-           strcat(cmd, "\"");
+           if (!strchr(argv[i], '>')) {
+               strcat(cmd, "\"");
+            }
        }
        /* the outermost double quotes are needed for cmd.exe */
        strcat(cmd, "\"");

It lets the python example work.  I am not sure that quoting all the
arguments buys you much, as shQuote() is still needed for arguments
that include spaces.  E.g.,  with 3.6.3, 4.0.3, and my development
build with the above patch we get

> stopifnot(dir.create(dirname <- file.path(tempfile(), "A SPACE"), recursive=TRUE))
> logname <- file.path(dirname, "log.txt")
> unlink(logname)
> system(paste( "C:\\R\\R-3.6.3\\bin\\R.exe --quiet --vanilla -e \"commandArgs()\" 1>", logname))
ARGUMENT 'SPACE/log.txt' __ignored__

[1] 0
> tryCatch(readLines(logname), error=function(e)conditionMessage(e))
[1] "cannot open the connection"
Warning message:
In file(con, "r") :
  cannot open file
'C:\Users\willi\AppData\Local\Temp\RtmpM5tsC7\file1a1068734a49/A
SPACE/log.txt': No such file or directory
>
> system(paste( "C:\\R\\R-4.0.3\\bin\\R.exe --quiet --vanilla -e \"commandArgs()\" 1>", logname))
> commandArgs()
[1] "C:\\R\\R-40~1.3/bin/x64/Rterm.exe"
[2] "--quiet"
[3] "--vanilla"
[4] "-e"
[5] "commandArgs()"
[6] "1>"
[7] "C:\\Users\\willi\\AppData\\Local\\Temp\\RtmpM5tsC7\\file1a1068734a49/A"
[8] "SPACE/log.txt"
>
>
[1] 0
> tryCatch(readLines(logname), error=function(e)conditionMessage(e))
[1] "cannot open the connection"
Warning message:
In file(con, "r") :
  cannot open file
'C:\Users\willi\AppData\Local\Temp\RtmpM5tsC7\file1a1068734a49/A
SPACE/log.txt': No such file or directory
>
> unlink(logname)
> system(paste( "C:\\msys64\\home\\willi\\ucrt3\\r\\trunk\\bin\\R.exe --quiet --vanilla -e \"commandArgs()\" 1>", logname))
[1] 0
> tryCatch(readLines(logname), error=function(e)conditionMessage(e))
[1] "cannot open the connection"
Warning message:
In file(con, "r") :
  cannot open file
'C:\Users\willi\AppData\Local\Temp\RtmpM5tsC7\file1a1068734a49/A
SPACE/log.txt': No such file or directory
> tryCatch(readLines(sub(" .*$", "", logname)), error=function(e)conditionMessage(e))
[1] "> commandArgs()"
              "[1]
\"C:\\\\msys64\\\\home\\\\willi\\\\ucrt3\\\\r\\\\trunk/bin/x64/Rterm.exe\""
[3] "[2] \"--quiet\"
"             "[3] \"--vanilla\"
          "
[5] "[4] \"-e\"
"             "[5] \"commandArgs()\"
          "
[7] "[6] \"SPACE/log.txt\"
"             "> "
[9] "> "
>
> unlink(logname)
> system(paste( "C:\\msys64\\home\\willi\\ucrt3\\r\\trunk\\bin\\R.exe --quiet --vanilla -e \"commandArgs()\" 1>", shQuote(logname)))
[1] 0
> tryCatch(readLines(logname), error=function(e)conditionMessage(e))
[1] "> commandArgs()"
              "[1]
\"C:\\\\msys64\\\\home\\\\willi\\\\ucrt3\\\\r\\\\trunk/bin/x64/Rterm.exe\""
[3] "[2] \"--quiet\"
"             "[3] \"--vanilla\"
          "
[5] "[4] \"-e\"
"             "[5] \"commandArgs()\"
          "
[7] "> "
              "> "

-Bill

On Wed, Jan 27, 2021 at 1:25 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 27/01/2021 3:40 p.m., Bill Dunlap wrote:
> > I believe the problem is from svn 77925 in gnuwin/front-ends/rcmdfn.c,
> > which was committed a few days after 3.6.3 was released.  Rterm used
> > to put double quotes around a command line argument only if it
> > contained a space, now it double quotes all arguments.  It sees shell
> > constructs like "1>" and the following file name as arguments and
> > double quoting them hides them from the shell, leading to this
> > problem.  I think we may have to rely on the user supplying quotes as
> > needed instead of blindly adding them.
>
> Okay, now I see what you mean.
>
> If you invoke R using R.exe, it asks cmd.exe to run Rterm.exe, so it is
> possible that redirection would be handled.
>
> If you invoke R directly using Rterm.exe, then my description down below
> would be correct.
>
> Duncan Murdoch
>
>
> >
> > -Bill
> >
> > On Wed, Jan 27, 2021 at 12:28 PM Duncan Murdoch
> > <murdoch.duncan at gmail.com> wrote:
> >>
> >> On 27/01/2021 3:17 p.m., Duncan Murdoch wrote:
> >>> On 27/01/2021 3:38 a.m., Martin Maechler wrote:
> >>>>>>>>> Martin Maechler
> >>>>>>>>>        on Tue, 26 Jan 2021 12:37:58 +0100 writes:
> >>>>
> >>>>>>>>> Marcel Baumgartner
> >>>>>>>>>        on Tue, 26 Jan 2021 08:55:48 +0100 writes:
> >>>>
> >>>>        >> Dear all, my colleague posted our issue on stackoverflow:
> >>>>
> >>>>        >> Calling R script from Python does not save log file in
> >>>>        >> version 4 - Stack Overflow
> >>>>        >> [https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]
> >>>>
> >>>>        >> It is about this kind of call to R:
> >>>>
> >>>>        >> R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1".
> >>>>
> >>>>        >> The issue is that the log.txt file is not created when
> >>>>        >> running R 4.x.x. The same code works perfectly fine with
> >>>>        >> R 3.6.x.
> >>>>
> >>>>        >> Any idea what's going wrong as of version 4? Regards
> >>>>        >> Marcel
> >>>>
> >>>>        > Dear Marcel, I think the solution is embarrassingly
> >>>>        > simple:
> >>>>
> >>>>        >> From the SO post, where she showed a bit more detail than you
> >>>>        > show here, it's clear you have confused 'R.exe' and
> >>>>        > 'Rscript.exe' and what you say above is not true:
> >>>>
> >>>>        > 'R.exe' was used for R 3.6.0 but for R 4.0.3, you/she used
> >>>>        > 'Rscript.exe' instead.
> >>>>
> >>>>
> >>>>        > ... as you've noticed now, they do behave differently,
> >>>>        > indeed!
> >>>>
> >>>> Well, this was not the solution to their -- Windows-only -- problem.
> >>>> The problem *is* indeed visible if they only use  R.exe  (also
> >>>> for R 4.0.3).
> >>>>
> >>>> I've commented more on the SO issue (see above),
> >>>> notably asking for a *minimal* repr.ex. (reproducible example),
> >>>> and one *not* using "<YOUR PATH>" and setwd() ..
> >>>>
> >>>
> >>> Isn't this purely a Python or user problem?  R shouldn't process
> >>> redirection directives like
> >>>
> >>>      1> "~/log.txt" 2>&1
> >>>
> >>> because it's the shell's job to process those. If Python is acting as
> >>> the shell, it needs to handle those things.  If R was handling the
> >>> command via
> >>
> >> Oops, sent before finishing:
> >>
> >> If R was handling the command via system() or system2(), it would handle
> >> redirection itself. If it was using the Windows-only shell(), it would
> >> call cmd.exe (by default) to handle redirection.  (This is a difference
> >> between R on Windows and R in Unix:  in Unix a shell is always used.)
> >>
> >> Duncan Murdoch
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>


From den|@@|r@nc|@c| @end|ng |rom gm@||@com  Thu Jan 28 09:07:51 2021
From: den|@@|r@nc|@c| @end|ng |rom gm@||@com (Denis Francisci)
Date: Thu, 28 Jan 2021 09:07:51 +0100
Subject: [R] random numbers with constraints
In-Reply-To: <CAB8pepzpH3YshbF-jtqJ9o5zh2MSaMT2T=6j+mQqWH0j6nsVRQ@mail.gmail.com>
References: <CAJMcJMBf=rYNc5FYB1oW5n1t7bo62_=gvbhhvd5D7Dqa_YTNFA@mail.gmail.com>
 <CAB8pepwZB0TfF5ewdfjUDjBU_Md95j4npANU9k1rpVyTp0rivg@mail.gmail.com>
 <CAJMcJMB_g4cHZS9HpHezbOhFjVavPhZEQzoA2zj9JE3KMoDUDw@mail.gmail.com>
 <CAB8pepzpH3YshbF-jtqJ9o5zh2MSaMT2T=6j+mQqWH0j6nsVRQ@mail.gmail.com>
Message-ID: <CAJMcJMA2HW5LhBgKeEvr2C2MGvq_EDsZJ0j8hiSCDkGqX76zhw@mail.gmail.com>

Thanks again for your help,
One digit after the decimal point is enough for my purposes; so, I can
round the qexp function, even if possible errors in floating points are not
a problem.
Thank you very very much,

Denis




Il giorno mer 27 gen 2021 alle ore 20:48 Abby Spurdle <spurdle.a at gmail.com>
ha scritto:

> I note that there's a possibility of floating point errors.
> If all values have one digit after the decimal point, you could replace:
> qexp (p, rate) with round (qexp (p, rate), 1).
>
> However, sometimes uniroot will fail, due to problems with input.
>
> On Thu, Jan 28, 2021 at 5:02 AM Denis Francisci
> <denis.francisci at gmail.com> wrote:
> >
> > Wonderful!
> > This is exactly what I need!
> > Thank you very much!!
> >
> > Denis
> >
> >
> >
> > Il giorno mer 27 gen 2021 alle ore 10:58 Abby Spurdle <
> spurdle.a at gmail.com> ha scritto:
> >>
> >> u <- runif (410)
> >> u <- (u - min (u) ) / diff (range (u) )
> >>
> >> constrained.sample <- function (rate)
> >> {   plim <- pexp (c (9.6, 11.6), rate)
> >>     p <- plim [1] + diff (plim) * u
> >>     qexp (p, rate)
> >> }
> >>
> >> diff.sum <- function (rate)
> >>     sum (constrained.sample (rate) ) - 4200
> >>
> >> rate <- uniroot (diff.sum, c (1, 2) )$root
> >> q <- constrained.sample (rate)
> >>
> >> length (q)
> >> range (q)
> >> sum (q)
> >>
> >>
> >> On Wed, Jan 27, 2021 at 9:03 PM Denis Francisci
> >> <denis.francisci at gmail.com> wrote:
> >> >
> >> > Hi,
> >> > I would like to generate random numbers in R with some constraints:
> >> > - my vector of numbers must contain 410 values;
> >> > - min value must be 9.6 and max value must be 11.6;
> >> > - sum of vector's values must be 4200.
> >> > Is there a way to do this in R?
> >> > And is it possible to generate this series in such a way that it
> follows a
> >> > specific distribution form (for example exponential)?
> >> > Thank you in advance,
> >> >
> >> > D.
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ho@@@|nmm @end|ng |rom jun|v@edu  Thu Jan 28 13:13:13 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Thu, 28 Jan 2021 12:13:13 +0000
Subject: [R] Regarding fitted value
Message-ID: <CAO29qn7eZZjsBUtF1y+oZzhkiWi51+Yp46uEVUSAJZedOqtwQA@mail.gmail.com>

 Dear R-experts,

I hope that all of you are doing well. I got the filled value from the
ARIMA model.

I use the following working code. But I am not clear whether I got the
fitted value for each *corresponding time* of the original data point like
2000, 2001, 2020 or get a *one-step-ahead* fitted value. Please suggest me
any reference for further reading to my understanding.

########################
y<-c(120,340,250,430,125,324,763,458,763,905,765,456,234,345,654,654,567,876,907,456)
library(forecast)
library(tseries)
yy=ts(y, start=c(2000,1))

model1=Arima(yy,order=c(0,2,1), lambda = NULL,method='ML')
model1

f <- fitted( model1)
plot(yy)
plot(f)

Thanks in advance.

-- 
Best Regards,
Md. Moyazzem Hossain

	[[alternative HTML version deleted]]


From m|chv|@cont| @end|ng |rom gm@||@com  Wed Jan 27 13:30:27 2021
From: m|chv|@cont| @end|ng |rom gm@||@com (M Visconti)
Date: Wed, 27 Jan 2021 07:30:27 -0500
Subject: [R] Citing
Message-ID: <9F6ED9BC-A1FA-4119-B177-64A7057FFC1C@gmail.com>

Hi there,

Our statistician used R version 4.0.3 for a clinical project data analysis. I wanted to cite correctly using this below format (for a different example):

NCSS 10 Statistical Software [2015]; NCSS, LLC, Kaysville, UT

Can you please help me fill in the info after the semi colon for your R software?

Michael Visconti, DO


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Thu Jan 28 13:52:02 2021
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Thu, 28 Jan 2021 07:52:02 -0500
Subject: [R] Citing
In-Reply-To: <9F6ED9BC-A1FA-4119-B177-64A7057FFC1C@gmail.com>
References: <9F6ED9BC-A1FA-4119-B177-64A7057FFC1C@gmail.com>
Message-ID: <CAJc=yOGfRSBHPFob9cg9ci87vdfZichSKEhmgb7VRygo7+A8JQ@mail.gmail.com>

When you start up R, one of the opening messages is:

'citation()' on how to cite R or R packages in publications.

Since it sounds like you're not using R yourself, here are the results for
R, but you'd have to go one by one through packages.

R Core Team (2020). R: A language and environment for statistical
computing. R Foundation for Statistical Computing, Vienna, Austria. URL
https://www.R-project.org/.




On Thu, Jan 28, 2021 at 7:37 AM M Visconti <michvisconti at gmail.com> wrote:

> Hi there,
>
> Our statistician used R version 4.0.3 for a clinical project data
> analysis. I wanted to cite correctly using this below format (for a
> different example):
>
> NCSS 10 Statistical Software [2015]; NCSS, LLC, Kaysville, UT
>
> Can you please help me fill in the info after the semi colon for your R
> software?
>
> Michael Visconti, DO
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jan 28 16:31:52 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 28 Jan 2021 07:31:52 -0800
Subject: [R] Citing
In-Reply-To: <9F6ED9BC-A1FA-4119-B177-64A7057FFC1C@gmail.com>
References: <9F6ED9BC-A1FA-4119-B177-64A7057FFC1C@gmail.com>
Message-ID: <CAGxFJbR9Am9CnmAqYT6aiyBNn3QGDg5v+99X2anzkb33uDJjpg@mail.gmail.com>

?citation

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 28, 2021 at 4:37 AM M Visconti <michvisconti at gmail.com> wrote:

> Hi there,
>
> Our statistician used R version 4.0.3 for a clinical project data
> analysis. I wanted to cite correctly using this below format (for a
> different example):
>
> NCSS 10 Statistical Software [2015]; NCSS, LLC, Kaysville, UT
>
> Can you please help me fill in the info after the semi colon for your R
> software?
>
> Michael Visconti, DO
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Jan 28 16:42:25 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 28 Jan 2021 16:42:25 +0100
Subject: [R] random numbers with constraints
In-Reply-To: <CAB8pepzpH3YshbF-jtqJ9o5zh2MSaMT2T=6j+mQqWH0j6nsVRQ@mail.gmail.com>
References: <CAJMcJMBf=rYNc5FYB1oW5n1t7bo62_=gvbhhvd5D7Dqa_YTNFA@mail.gmail.com>
 <CAB8pepwZB0TfF5ewdfjUDjBU_Md95j4npANU9k1rpVyTp0rivg@mail.gmail.com>
 <CAJMcJMB_g4cHZS9HpHezbOhFjVavPhZEQzoA2zj9JE3KMoDUDw@mail.gmail.com>
 <CAB8pepzpH3YshbF-jtqJ9o5zh2MSaMT2T=6j+mQqWH0j6nsVRQ@mail.gmail.com>
Message-ID: <24594.56161.330127.478949@stat.math.ethz.ch>

>>>>> Abby Spurdle 
>>>>>     on Thu, 28 Jan 2021 08:48:06 +1300 writes:

    > I note that there's a possibility of floating point errors.
    > If all values have one digit after the decimal point, you could replace:
    > qexp (p, rate) with round (qexp (p, rate), 1).

    > However, sometimes uniroot will fail, due to problems with input.

I also think the  constrained.sample() function should not
depend on the global variable 'u',
but rather depend on 'n'   and construct 'u' from  runif(n).

Martin

    > On Thu, Jan 28, 2021 at 5:02 AM Denis Francisci
    > <denis.francisci at gmail.com> wrote:
    >> 
    >> Wonderful!
    >> This is exactly what I need!
    >> Thank you very much!!
    >> 
    >> Denis
    >> 
    >> 
    >> 
    >> Il giorno mer 27 gen 2021 alle ore 10:58 Abby Spurdle <spurdle.a at gmail.com> ha scritto:
    >>> 
    >>> u <- runif (410)
    >>> u <- (u - min (u) ) / diff (range (u) )
    >>> 
    >>> constrained.sample <- function (rate)
    >>> {   plim <- pexp (c (9.6, 11.6), rate)
    >>> p <- plim [1] + diff (plim) * u
    >>> qexp (p, rate)
    >>> }
    >>> 
    >>> diff.sum <- function (rate)
    >>> sum (constrained.sample (rate) ) - 4200
    >>> 
    >>> rate <- uniroot (diff.sum, c (1, 2) )$root
    >>> q <- constrained.sample (rate)
    >>> 
    >>> length (q)
    >>> range (q)
    >>> sum (q)
    >>> 
    >>> 
    >>> On Wed, Jan 27, 2021 at 9:03 PM Denis Francisci
    >>> <denis.francisci at gmail.com> wrote:
    >>> >
    >>> > Hi,
    >>> > I would like to generate random numbers in R with some constraints:
    >>> > - my vector of numbers must contain 410 values;
    >>> > - min value must be 9.6 and max value must be 11.6;
    >>> > - sum of vector's values must be 4200.
    >>> > Is there a way to do this in R?
    >>> > And is it possible to generate this series in such a way that it follows a
    >>> > specific distribution form (for example exponential)?
    >>> > Thank you in advance,
    >>> >
    >>> > D.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jan 28 17:47:47 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 28 Jan 2021 16:47:47 +0000
Subject: [R] Regarding fitted value
In-Reply-To: <CAO29qn7eZZjsBUtF1y+oZzhkiWi51+Yp46uEVUSAJZedOqtwQA@mail.gmail.com>
References: <CAO29qn7eZZjsBUtF1y+oZzhkiWi51+Yp46uEVUSAJZedOqtwQA@mail.gmail.com>
Message-ID: <03978895-a544-c325-ed23-97315e7fc4e1@sapo.pt>

Hello,

 From help('forecast::fitted.Arima'):

h	The number of steps to forecast ahead.


So you have the default h = 1 step ahead forecast for your model.


Hope this helps,

Rui Barradas

?s 12:13 de 28/01/21, Md. Moyazzem Hossain escreveu:
>   Dear R-experts,
> 
> I hope that all of you are doing well. I got the filled value from the
> ARIMA model.
> 
> I use the following working code. But I am not clear whether I got the
> fitted value for each *corresponding time* of the original data point like
> 2000, 2001, 2020 or get a *one-step-ahead* fitted value. Please suggest me
> any reference for further reading to my understanding.
> 
> ########################
> y<-c(120,340,250,430,125,324,763,458,763,905,765,456,234,345,654,654,567,876,907,456)
> library(forecast)
> library(tseries)
> yy=ts(y, start=c(2000,1))
> 
> model1=Arima(yy,order=c(0,2,1), lambda = NULL,method='ML')
> model1
> 
> f <- fitted( model1)
> plot(yy)
> plot(f)
> 
> Thanks in advance.
>


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Thu Jan 28 20:29:07 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Thu, 28 Jan 2021 11:29:07 -0800
Subject: [R] How to generate SE for the proportion value using a
 randomization process in R?
In-Reply-To: <CAMwU6B1GyXio9bJUNhUbuHFYt6fuZ+9jZ1Nm85cUhAs1KuJ9sA@mail.gmail.com>
References: <CAMwU6B0JkZ-wZY6bbcwBjJ5VpjGMePnc-KOmR2n+G6zoCHFA+w@mail.gmail.com>
 <8face05f-dc69-a286-9961-a0ebf6fd3502@sapo.pt>
 <CAMwU6B0meFyOvCnzn2DEMrU+LUoejL_x6RMW6aszxuq-2r+=TA@mail.gmail.com>
 <27a6ab72-c392-c87a-ef64-82a209ce6134@sapo.pt>
 <CAMwU6B1GyXio9bJUNhUbuHFYt6fuZ+9jZ1Nm85cUhAs1KuJ9sA@mail.gmail.com>
Message-ID: <CAMwU6B1JDpDn-dADBx1La8UnqJGRcwXcqzO809vunrvyhSD-Eg@mail.gmail.com>

Hi Rui,
I am sorry for asking you several questions.

In the given example, randomizations (reshuffle) were done 1000 times, and
its 1000 proportion values (results) are stored and it can be seen using
b$t; but I was wondering how the table was randomized (which rows have been
missed/or repeated in each randomizing procedure?).

Is there any way we can see the randomized table and its associated
results? Here in this example, I randomized (or bootstrapped) the table
into three times (R=3) so I would like to store these three tables and look
at them later to know which rows were repeated/missed. Is there any
possibility?
The example data and the code is given below.

Thank you for your help.

####
library(boot)
dat<-structure(list(Sample = structure(c(1L, 12L, 13L, 14L, 15L, 16L,
17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L), .Label = c("id1",
"id10", "id11", "id12", "id13", "id14", "id15", "id16", "id17",
"id18", "id19", "Id2", "id3", "id4", "id5", "id6", "id7", "id8",
"id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L), Time2 = c(1L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class = "data.frame",
row.names = c(NA,
-19L))
daT<-data.frame(dat %>%
  mutate(Time1.but.not.in.Time2 = case_when(
            Time1 %in% "1" & Time2 %in% "0"  ~ "1"),
Time2.but.not.in.Time1 = case_when(
            Time1 %in% "0" & Time2 %in% "1"  ~ "1"),
 BothTimes = case_when(
            Time1 %in% "1" & Time2 %in% "1"  ~ "1")))
cols.num <- c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
"BothTimes")
daT[cols.num] <- sapply(daT[cols.num],as.numeric)
summary(daT)

bootprop <- function(data, index){
   d <- data[index, ]
   sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
}

R <- 3
set.seed(2020)
b <- boot(daT, bootprop, R)
b
b$t0     # original
b$t
sd(b$t)  # bootstrapped estimate of the SE of the sample prop.
hist(b$t, freq = FALSE)

str(b)
b$data
b$seed
b$sim
b$strata
################


On Sat, Jan 23, 2021 at 12:36 AM Marna Wagley <marna.wagley at gmail.com>
wrote:

> Yes Rui, I can see we don't need to divide by square root of sample size.
> The example is great to understand it.
> Thank you.
> Marna
>
>
> On Sat, Jan 23, 2021 at 12:28 AM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
>
>> Hello,
>>
>> Inline.
>>
>> ?s 07:47 de 23/01/21, Marna Wagley escreveu:
>> > Dear Rui,
>> > I was wondering whether we have to square root of SD to find SE, right?
>>
>> No, we don't. var already divides by n, don't divide again.
>> This is the code, that can be seen by running the function name at a
>> command line.
>>
>>
>> sd
>> #function (x, na.rm = FALSE)
>> #sqrt(var(if (is.vector(x) || is.factor(x)) x else as.double(x),
>> #    na.rm = na.rm))
>> #<bytecode: 0x55f3ce900848>
>> #<environment: namespace:stats>
>>
>>
>>
>> >
>> > bootprop <- function(data, index){
>> >     d <- data[index, ]
>> >     sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
>> > }
>> >
>> > R <- 1e3
>> > set.seed(2020)
>> > b <- boot(daT, bootprop, R)
>> > b
>> > b$t0     # original
>> > sd(b$t)  # bootstrapped estimate of the SE of the sample prop.
>> > sd(b$t)/sqrt(1000)
>> > pandit*(1-pandit)
>> >
>> > hist(b$t, freq = FALSE)
>>
>>
>> Try plotting the normal densities for both cases, the red line is
>> clearly wrong.
>>
>>
>> f <- function(x, xbar, s){
>>    dnorm(x, mean = xbar, sd = s)
>> }
>>
>> hist(b$t, freq = FALSE)
>> curve(f(x, xbar = b$t0, s = sd(b$t)), from = 0, to = 1, col = "blue",
>> add = TRUE)
>> curve(f(x, xbar = b$t0, s = sd(b$t)/sqrt(R)), from = 0, to = 1, col =
>> "red", add = TRUE)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> >
>> >
>> >
>> >
>> > On Fri, Jan 22, 2021 at 3:07 PM Rui Barradas <ruipbarradas at sapo.pt
>> > <mailto:ruipbarradas at sapo.pt>> wrote:
>> >
>> >     Hello,
>> >
>> >     Something like this, using base package boot?
>> >
>> >
>> >     library(boot)
>> >
>> >     bootprop <- function(data, index){
>> >         d <- data[index, ]
>> >         sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm =
>> TRUE)
>> >     }
>> >
>> >     R <- 1e3
>> >     set.seed(2020)
>> >     b <- boot(daT, bootprop, R)
>> >     b
>> >     b$t0     # original
>> >     sd(b$t)  # bootstrapped estimate of the SE of the sample prop.
>> >     hist(b$t, freq = FALSE)
>> >
>> >
>> >     Hope this helps,
>> >
>> >     Rui Barradas
>> >
>> >     ?s 21:57 de 22/01/21, Marna Wagley escreveu:
>> >      > Hi All,
>> >      > I was trying to estimate standard error (SE) for the proportion
>> >     value using
>> >      > some kind of randomization process (bootstrapping or jackknifing)
>> >     in R, but
>> >      > I could not figure it out.
>> >      >
>> >      > Is there any way to generate SE for the proportion?
>> >      >
>> >      > The example of the data and the code I am using is attached for
>> your
>> >      > reference. I would like to generate the value of proportion with
>> >     a SE using
>> >      > a 1000 times randomization.
>> >      >
>> >      > dat<-structure(list(Sample = structure(c(1L, 12L, 13L, 14L, 15L,
>> 16L,
>> >      > 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L), .Label
>> >     = c("id1",
>> >      > "id10", "id11", "id12", "id13", "id14", "id15", "id16", "id17",
>> >      > "id18", "id19", "Id2", "id3", "id4", "id5", "id6", "id7", "id8",
>> >      > "id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L, 0L, 0L,
>> >      > 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L), Time2 =
>> c(1L,
>> >      > 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
>> >      > 1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class =
>> >     "data.frame",
>> >      > row.names = c(NA,
>> >      > -19L))
>> >      > daT<-data.frame(dat %>%
>> >      >    mutate(Time1.but.not.in.Time2 = case_when(
>> >      >              Time1 %in% "1" & Time2 %in% "0"  ~ "1"),
>> >      > Time2.but.not.in.Time1 = case_when(
>> >      >              Time1 %in% "0" & Time2 %in% "1"  ~ "1"),
>> >      >   BothTimes = case_when(
>> >      >              Time1 %in% "1" & Time2 %in% "1"  ~ "1")))
>> >      >   daT
>> >      >   summary(daT)
>> >      >
>> >      > cols.num <- c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
>> >      > "BothTimes")
>> >      > daT[cols.num] <- sapply(daT[cols.num],as.numeric)
>> >      > summary(daT)
>> >      > ProportionValue<-sum(daT$BothTimes, na.rm=T)/sum(daT$Time1,
>> na.rm=T)
>> >      > ProportionValue
>> >      > standard error??
>> >      >
>> >      >       [[alternative HTML version deleted]]
>> >      >
>> >      > ______________________________________________
>> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>> >     -- To UNSUBSCRIBE and more, see
>> >      > https://stat.ethz.ch/mailman/listinfo/r-help
>> >      > PLEASE do read the posting guide
>> >     http://www.R-project.org/posting-guide.html
>> >      > and provide commented, minimal, self-contained, reproducible
>> code.
>> >      >
>> >
>>
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Thu Jan 28 20:58:03 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 29 Jan 2021 08:58:03 +1300
Subject: [R] random numbers with constraints
In-Reply-To: <24594.56161.330127.478949@stat.math.ethz.ch>
References: <CAJMcJMBf=rYNc5FYB1oW5n1t7bo62_=gvbhhvd5D7Dqa_YTNFA@mail.gmail.com>
 <CAB8pepwZB0TfF5ewdfjUDjBU_Md95j4npANU9k1rpVyTp0rivg@mail.gmail.com>
 <CAJMcJMB_g4cHZS9HpHezbOhFjVavPhZEQzoA2zj9JE3KMoDUDw@mail.gmail.com>
 <CAB8pepzpH3YshbF-jtqJ9o5zh2MSaMT2T=6j+mQqWH0j6nsVRQ@mail.gmail.com>
 <24594.56161.330127.478949@stat.math.ethz.ch>
Message-ID: <CAB8pepyaaf+2+SPK4hTzSiaoh3QLG92zKrZpvgKNDMyjccTLtQ@mail.gmail.com>

I recognize the problems with global data.
And my code could certainly be improved.

However, I also note that the random numbers (ignoring
transformations), need to be constant, while computing the rate.
Otherwise, my algorithm wouldn't work well.

As it is, rounding operations can cause "jumps".
Generating random numbers for each value of rate, would make those jumps bigger.

I'm thinking a better solution would be to put the entire code inside
a single function.

Although, in saying all of that, the uniroot approach, is not the best here.
A more "robust" root finding algorithm (or solver) would be far
better, but I'm not sure what that would mean, exactly...

Given the possible relevance of generating constrained samples, a
discussion on what a robust solver means, could be interesting...
Although, I'll leave it to you to agree or disagree, and if in
agreement, to suggest the best forum for such a discussion.


On Fri, Jan 29, 2021 at 4:42 AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Abby Spurdle
> >>>>>     on Thu, 28 Jan 2021 08:48:06 +1300 writes:
>
>     > I note that there's a possibility of floating point errors.
>     > If all values have one digit after the decimal point, you could replace:
>     > qexp (p, rate) with round (qexp (p, rate), 1).
>
>     > However, sometimes uniroot will fail, due to problems with input.
>
> I also think the  constrained.sample() function should not
> depend on the global variable 'u',
> but rather depend on 'n'   and construct 'u' from  runif(n).
>
> Martin
>
>     > On Thu, Jan 28, 2021 at 5:02 AM Denis Francisci
>     > <denis.francisci at gmail.com> wrote:
>     >>
>     >> Wonderful!
>     >> This is exactly what I need!
>     >> Thank you very much!!
>     >>
>     >> Denis
>     >>
>     >>
>     >>
>     >> Il giorno mer 27 gen 2021 alle ore 10:58 Abby Spurdle <spurdle.a at gmail.com> ha scritto:
>     >>>
>     >>> u <- runif (410)
>     >>> u <- (u - min (u) ) / diff (range (u) )
>     >>>
>     >>> constrained.sample <- function (rate)
>     >>> {   plim <- pexp (c (9.6, 11.6), rate)
>     >>> p <- plim [1] + diff (plim) * u
>     >>> qexp (p, rate)
>     >>> }
>     >>>
>     >>> diff.sum <- function (rate)
>     >>> sum (constrained.sample (rate) ) - 4200
>     >>>
>     >>> rate <- uniroot (diff.sum, c (1, 2) )$root
>     >>> q <- constrained.sample (rate)
>     >>>
>     >>> length (q)
>     >>> range (q)
>     >>> sum (q)
>     >>>
>     >>>
>     >>> On Wed, Jan 27, 2021 at 9:03 PM Denis Francisci
>     >>> <denis.francisci at gmail.com> wrote:
>     >>> >
>     >>> > Hi,
>     >>> > I would like to generate random numbers in R with some constraints:
>     >>> > - my vector of numbers must contain 410 values;
>     >>> > - min value must be 9.6 and max value must be 11.6;
>     >>> > - sum of vector's values must be 4200.
>     >>> > Is there a way to do this in R?
>     >>> > And is it possible to generate this series in such a way that it follows a
>     >>> > specific distribution form (for example exponential)?
>     >>> > Thank you in advance,
>     >>> >
>     >>> > D.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jan 28 21:21:36 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 28 Jan 2021 20:21:36 +0000
Subject: [R] How to generate SE for the proportion value using a
 randomization process in R?
In-Reply-To: <CAMwU6B1JDpDn-dADBx1La8UnqJGRcwXcqzO809vunrvyhSD-Eg@mail.gmail.com>
References: <CAMwU6B0JkZ-wZY6bbcwBjJ5VpjGMePnc-KOmR2n+G6zoCHFA+w@mail.gmail.com>
 <8face05f-dc69-a286-9961-a0ebf6fd3502@sapo.pt>
 <CAMwU6B0meFyOvCnzn2DEMrU+LUoejL_x6RMW6aszxuq-2r+=TA@mail.gmail.com>
 <27a6ab72-c392-c87a-ef64-82a209ce6134@sapo.pt>
 <CAMwU6B1GyXio9bJUNhUbuHFYt6fuZ+9jZ1Nm85cUhAs1KuJ9sA@mail.gmail.com>
 <CAMwU6B1JDpDn-dADBx1La8UnqJGRcwXcqzO809vunrvyhSD-Eg@mail.gmail.com>
Message-ID: <34f71527-3341-326b-3b4c-8b84efef7b1c@sapo.pt>

Hello,

I don't know why you would need to see the indices but rewrite the 
function bootprop as

bootprop_ind <- function(data, index){
   d <- data[index, ]
   #sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
   index
}


and call in the same way. It will now return a matrix of indices with R 
= 1000 rows and 19 columns.

Hope this helps,

Rui Barradas


?s 19:29 de 28/01/21, Marna Wagley escreveu:
> Hi Rui,
> I am sorry for asking you several questions.
> 
> In the given example, randomizations (reshuffle) were done 1000 times, 
> and its 1000 proportion values (results) are stored and it can be seen 
> using b$t; but I was wondering how the table was randomized (which rows 
> have been missed/or repeated in each randomizing procedure?).
> 
> Is there any way we can see the randomized table and its associated 
> results? Here in this example, I randomized (or bootstrapped) the table 
> into three times (R=3) so I would like to store these three tables and 
> look at them later to know which rows were repeated/missed. Is there any 
> possibility?
> The example data and the code is given below.
> 
> Thank you for your help.
> 
> ####
> library(boot)
> dat<-structure(list(Sample = structure(c(1L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L), .Label = c("id1",
> "id10", "id11", "id12", "id13", "id14", "id15", "id16", "id17",
> "id18", "id19", "Id2", "id3", "id4", "id5", "id6", "id7", "id8",
> "id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L, 0L, 0L,
> 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L), Time2 = c(1L,
> 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
> 1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class = "data.frame", 
> row.names = c(NA,
> -19L))
> daT<-data.frame(dat %>%
>  ? mutate(Time1.but.not.in.Time2 = case_when(
>  ? ? ? ? ? ? Time1 %in% "1" & Time2 %in% "0" ?~ "1"),
> Time2.but.not.in.Time1 = case_when(
>  ? ? ? ? ? ? Time1 %in% "0" & Time2 %in% "1" ?~ "1"),
>  ?BothTimes = case_when(
>  ? ? ? ? ? ? Time1 %in% "1" & Time2 %in% "1" ?~ "1")))
> cols.num <- c("Time1.but.not.in.Time2","Time2.but.not.in.Time1", 
> "BothTimes")
> daT[cols.num] <- sapply(daT[cols.num],as.numeric)
> summary(daT)
> 
> bootprop <- function(data, index){
>  ? ?d <- data[index, ]
>  ? ?sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
> }
> 
> R <- 3
> set.seed(2020)
> b <- boot(daT, bootprop, R)
> b
> b$t0? ? ?# original
> b$t
> sd(b$t)? # bootstrapped estimate of the SE of the sample prop.
> hist(b$t, freq = FALSE)
> 
> str(b)
> b$data
> b$seed
> b$sim
> b$strata
> ################
> 
> 
> On Sat, Jan 23, 2021 at 12:36 AM Marna Wagley <marna.wagley at gmail.com 
> <mailto:marna.wagley at gmail.com>> wrote:
> 
>     Yes Rui, I can see we don't need to divide by square root of sample
>     size. The example is great to understand it.
>     Thank you.
>     Marna
> 
> 
>     On Sat, Jan 23, 2021 at 12:28 AM Rui Barradas <ruipbarradas at sapo.pt
>     <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>         Hello,
> 
>         Inline.
> 
>         ?s 07:47 de 23/01/21, Marna Wagley escreveu:
>          > Dear Rui,
>          > I was wondering whether we have to square root of SD to find
>         SE, right?
> 
>         No, we don't. var already divides by n, don't divide again.
>         This is the code, that can be seen by running the function name
>         at a
>         command line.
> 
> 
>         sd
>         #function (x, na.rm = FALSE)
>         #sqrt(var(if (is.vector(x) || is.factor(x)) x else as.double(x),
>         #? ? na.rm = na.rm))
>         #<bytecode: 0x55f3ce900848>
>         #<environment: namespace:stats>
> 
> 
> 
>          >
>          > bootprop <- function(data, index){
>          >? ? ?d <- data[index, ]
>          >? ? ?sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]],
>         na.rm = TRUE)
>          > }
>          >
>          > R <- 1e3
>          > set.seed(2020)
>          > b <- boot(daT, bootprop, R)
>          > b
>          > b$t0? ? ?# original
>          > sd(b$t)? # bootstrapped estimate of the SE of the sample prop.
>          > sd(b$t)/sqrt(1000)
>          > pandit*(1-pandit)
>          >
>          > hist(b$t, freq = FALSE)
> 
> 
>         Try plotting the normal densities for both cases, the red line is
>         clearly wrong.
> 
> 
>         f <- function(x, xbar, s){
>          ? ?dnorm(x, mean = xbar, sd = s)
>         }
> 
>         hist(b$t, freq = FALSE)
>         curve(f(x, xbar = b$t0, s = sd(b$t)), from = 0, to = 1, col =
>         "blue",
>         add = TRUE)
>         curve(f(x, xbar = b$t0, s = sd(b$t)/sqrt(R)), from = 0, to = 1,
>         col =
>         "red", add = TRUE)
> 
> 
>         Hope this helps,
> 
>         Rui Barradas
> 
>          >
>          >
>          >
>          >
>          > On Fri, Jan 22, 2021 at 3:07 PM Rui Barradas
>         <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
>          > <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>>
>         wrote:
>          >
>          >? ? ?Hello,
>          >
>          >? ? ?Something like this, using base package boot?
>          >
>          >
>          >? ? ?library(boot)
>          >
>          >? ? ?bootprop <- function(data, index){
>          >? ? ? ? ?d <- data[index, ]
>          >? ? ? ? ?sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]],
>         na.rm = TRUE)
>          >? ? ?}
>          >
>          >? ? ?R <- 1e3
>          >? ? ?set.seed(2020)
>          >? ? ?b <- boot(daT, bootprop, R)
>          >? ? ?b
>          >? ? ?b$t0? ? ?# original
>          >? ? ?sd(b$t)? # bootstrapped estimate of the SE of the sample
>         prop.
>          >? ? ?hist(b$t, freq = FALSE)
>          >
>          >
>          >? ? ?Hope this helps,
>          >
>          >? ? ?Rui Barradas
>          >
>          >? ? ??s 21:57 de 22/01/21, Marna Wagley escreveu:
>          >? ? ? > Hi All,
>          >? ? ? > I was trying to estimate standard error (SE) for the
>         proportion
>          >? ? ?value using
>          >? ? ? > some kind of randomization process (bootstrapping or
>         jackknifing)
>          >? ? ?in R, but
>          >? ? ? > I could not figure it out.
>          >? ? ? >
>          >? ? ? > Is there any way to generate SE for the proportion?
>          >? ? ? >
>          >? ? ? > The example of the data and the code I am using is
>         attached for your
>          >? ? ? > reference. I would like to generate the value of
>         proportion with
>          >? ? ?a SE using
>          >? ? ? > a 1000 times randomization.
>          >? ? ? >
>          >? ? ? > dat<-structure(list(Sample = structure(c(1L, 12L, 13L,
>         14L, 15L, 16L,
>          >? ? ? > 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
>         11L), .Label
>          >? ? ?= c("id1",
>          >? ? ? > "id10", "id11", "id12", "id13", "id14", "id15",
>         "id16", "id17",
>          >? ? ? > "id18", "id19", "Id2", "id3", "id4", "id5", "id6",
>         "id7", "id8",
>          >? ? ? > "id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L,
>         0L, 0L,
>          >? ? ? > 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L),
>         Time2 = c(1L,
>          >? ? ? > 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L,
>         0L, 1L, 0L,
>          >? ? ? > 1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class =
>          >? ? ?"data.frame",
>          >? ? ? > row.names = c(NA,
>          >? ? ? > -19L))
>          >? ? ? > daT<-data.frame(dat %>%
>          >? ? ? >? ? mutate(Time1.but.not.in.Time2 = case_when(
>          >? ? ? >? ? ? ? ? ? ? Time1 %in% "1" & Time2 %in% "0"? ~ "1"),
>          >? ? ? > Time2.but.not.in.Time1 = case_when(
>          >? ? ? >? ? ? ? ? ? ? Time1 %in% "0" & Time2 %in% "1"? ~ "1"),
>          >? ? ? >? ?BothTimes = case_when(
>          >? ? ? >? ? ? ? ? ? ? Time1 %in% "1" & Time2 %in% "1"? ~ "1")))
>          >? ? ? >? ?daT
>          >? ? ? >? ?summary(daT)
>          >? ? ? >
>          >? ? ? > cols.num <-
>         c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
>          >? ? ? > "BothTimes")
>          >? ? ? > daT[cols.num] <- sapply(daT[cols.num],as.numeric)
>          >? ? ? > summary(daT)
>          >? ? ? > ProportionValue<-sum(daT$BothTimes,
>         na.rm=T)/sum(daT$Time1, na.rm=T)
>          >? ? ? > ProportionValue
>          >? ? ? > standard error??
>          >? ? ? >
>          >? ? ? >? ? ? ?[[alternative HTML version deleted]]
>          >? ? ? >
>          >? ? ? > ______________________________________________
>          >? ? ? > R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>         mailing list
>          >? ? ?-- To UNSUBSCRIBE and more, see
>          >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-help
>          >? ? ? > PLEASE do read the posting guide
>          > http://www.R-project.org/posting-guide.html
>          >? ? ? > and provide commented, minimal, self-contained,
>         reproducible code.
>          >? ? ? >
>          >
>


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Thu Jan 28 21:29:27 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Thu, 28 Jan 2021 12:29:27 -0800
Subject: [R] How to generate SE for the proportion value using a
 randomization process in R?
In-Reply-To: <34f71527-3341-326b-3b4c-8b84efef7b1c@sapo.pt>
References: <CAMwU6B0JkZ-wZY6bbcwBjJ5VpjGMePnc-KOmR2n+G6zoCHFA+w@mail.gmail.com>
 <8face05f-dc69-a286-9961-a0ebf6fd3502@sapo.pt>
 <CAMwU6B0meFyOvCnzn2DEMrU+LUoejL_x6RMW6aszxuq-2r+=TA@mail.gmail.com>
 <27a6ab72-c392-c87a-ef64-82a209ce6134@sapo.pt>
 <CAMwU6B1GyXio9bJUNhUbuHFYt6fuZ+9jZ1Nm85cUhAs1KuJ9sA@mail.gmail.com>
 <CAMwU6B1JDpDn-dADBx1La8UnqJGRcwXcqzO809vunrvyhSD-Eg@mail.gmail.com>
 <34f71527-3341-326b-3b4c-8b84efef7b1c@sapo.pt>
Message-ID: <CAMwU6B0TQHynFXC1TchadXjG-drfq1cz+75TLatg0cE4B6A7yg@mail.gmail.com>

Thank you Rui,
This is great. How about the following?

SimilatedData<-boot.array(b, indices=T)

seems it is giving the rows ID which are used in the calculation, isn't it?




On Thu, Jan 28, 2021 at 12:21 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I don't know why you would need to see the indices but rewrite the
> function bootprop as
>
> bootprop_ind <- function(data, index){
>    d <- data[index, ]
>    #sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
>    index
> }
>
>
> and call in the same way. It will now return a matrix of indices with R
> = 1000 rows and 19 columns.
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 19:29 de 28/01/21, Marna Wagley escreveu:
> > Hi Rui,
> > I am sorry for asking you several questions.
> >
> > In the given example, randomizations (reshuffle) were done 1000 times,
> > and its 1000 proportion values (results) are stored and it can be seen
> > using b$t; but I was wondering how the table was randomized (which rows
> > have been missed/or repeated in each randomizing procedure?).
> >
> > Is there any way we can see the randomized table and its associated
> > results? Here in this example, I randomized (or bootstrapped) the table
> > into three times (R=3) so I would like to store these three tables and
> > look at them later to know which rows were repeated/missed. Is there any
> > possibility?
> > The example data and the code is given below.
> >
> > Thank you for your help.
> >
> > ####
> > library(boot)
> > dat<-structure(list(Sample = structure(c(1L, 12L, 13L, 14L, 15L, 16L,
> > 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L), .Label =
> c("id1",
> > "id10", "id11", "id12", "id13", "id14", "id15", "id16", "id17",
> > "id18", "id19", "Id2", "id3", "id4", "id5", "id6", "id7", "id8",
> > "id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L, 0L, 0L,
> > 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L), Time2 = c(1L,
> > 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
> > 1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class = "data.frame",
> > row.names = c(NA,
> > -19L))
> > daT<-data.frame(dat %>%
> >    mutate(Time1.but.not.in.Time2 = case_when(
> >              Time1 %in% "1" & Time2 %in% "0"  ~ "1"),
> > Time2.but.not.in.Time1 = case_when(
> >              Time1 %in% "0" & Time2 %in% "1"  ~ "1"),
> >   BothTimes = case_when(
> >              Time1 %in% "1" & Time2 %in% "1"  ~ "1")))
> > cols.num <- c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
> > "BothTimes")
> > daT[cols.num] <- sapply(daT[cols.num],as.numeric)
> > summary(daT)
> >
> > bootprop <- function(data, index){
> >     d <- data[index, ]
> >     sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
> > }
> >
> > R <- 3
> > set.seed(2020)
> > b <- boot(daT, bootprop, R)
> > b
> > b$t0     # original
> > b$t
> > sd(b$t)  # bootstrapped estimate of the SE of the sample prop.
> > hist(b$t, freq = FALSE)
> >
> > str(b)
> > b$data
> > b$seed
> > b$sim
> > b$strata
> > ################
> >
> >
> > On Sat, Jan 23, 2021 at 12:36 AM Marna Wagley <marna.wagley at gmail.com
> > <mailto:marna.wagley at gmail.com>> wrote:
> >
> >     Yes Rui, I can see we don't need to divide by square root of sample
> >     size. The example is great to understand it.
> >     Thank you.
> >     Marna
> >
> >
> >     On Sat, Jan 23, 2021 at 12:28 AM Rui Barradas <ruipbarradas at sapo.pt
> >     <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >         Hello,
> >
> >         Inline.
> >
> >         ?s 07:47 de 23/01/21, Marna Wagley escreveu:
> >          > Dear Rui,
> >          > I was wondering whether we have to square root of SD to find
> >         SE, right?
> >
> >         No, we don't. var already divides by n, don't divide again.
> >         This is the code, that can be seen by running the function name
> >         at a
> >         command line.
> >
> >
> >         sd
> >         #function (x, na.rm = FALSE)
> >         #sqrt(var(if (is.vector(x) || is.factor(x)) x else as.double(x),
> >         #    na.rm = na.rm))
> >         #<bytecode: 0x55f3ce900848>
> >         #<environment: namespace:stats>
> >
> >
> >
> >          >
> >          > bootprop <- function(data, index){
> >          >     d <- data[index, ]
> >          >     sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]],
> >         na.rm = TRUE)
> >          > }
> >          >
> >          > R <- 1e3
> >          > set.seed(2020)
> >          > b <- boot(daT, bootprop, R)
> >          > b
> >          > b$t0     # original
> >          > sd(b$t)  # bootstrapped estimate of the SE of the sample prop.
> >          > sd(b$t)/sqrt(1000)
> >          > pandit*(1-pandit)
> >          >
> >          > hist(b$t, freq = FALSE)
> >
> >
> >         Try plotting the normal densities for both cases, the red line is
> >         clearly wrong.
> >
> >
> >         f <- function(x, xbar, s){
> >             dnorm(x, mean = xbar, sd = s)
> >         }
> >
> >         hist(b$t, freq = FALSE)
> >         curve(f(x, xbar = b$t0, s = sd(b$t)), from = 0, to = 1, col =
> >         "blue",
> >         add = TRUE)
> >         curve(f(x, xbar = b$t0, s = sd(b$t)/sqrt(R)), from = 0, to = 1,
> >         col =
> >         "red", add = TRUE)
> >
> >
> >         Hope this helps,
> >
> >         Rui Barradas
> >
> >          >
> >          >
> >          >
> >          >
> >          > On Fri, Jan 22, 2021 at 3:07 PM Rui Barradas
> >         <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
> >          > <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>>
> >         wrote:
> >          >
> >          >     Hello,
> >          >
> >          >     Something like this, using base package boot?
> >          >
> >          >
> >          >     library(boot)
> >          >
> >          >     bootprop <- function(data, index){
> >          >         d <- data[index, ]
> >          >         sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]],
> >         na.rm = TRUE)
> >          >     }
> >          >
> >          >     R <- 1e3
> >          >     set.seed(2020)
> >          >     b <- boot(daT, bootprop, R)
> >          >     b
> >          >     b$t0     # original
> >          >     sd(b$t)  # bootstrapped estimate of the SE of the sample
> >         prop.
> >          >     hist(b$t, freq = FALSE)
> >          >
> >          >
> >          >     Hope this helps,
> >          >
> >          >     Rui Barradas
> >          >
> >          >     ?s 21:57 de 22/01/21, Marna Wagley escreveu:
> >          >      > Hi All,
> >          >      > I was trying to estimate standard error (SE) for the
> >         proportion
> >          >     value using
> >          >      > some kind of randomization process (bootstrapping or
> >         jackknifing)
> >          >     in R, but
> >          >      > I could not figure it out.
> >          >      >
> >          >      > Is there any way to generate SE for the proportion?
> >          >      >
> >          >      > The example of the data and the code I am using is
> >         attached for your
> >          >      > reference. I would like to generate the value of
> >         proportion with
> >          >     a SE using
> >          >      > a 1000 times randomization.
> >          >      >
> >          >      > dat<-structure(list(Sample = structure(c(1L, 12L, 13L,
> >         14L, 15L, 16L,
> >          >      > 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> >         11L), .Label
> >          >     = c("id1",
> >          >      > "id10", "id11", "id12", "id13", "id14", "id15",
> >         "id16", "id17",
> >          >      > "id18", "id19", "Id2", "id3", "id4", "id5", "id6",
> >         "id7", "id8",
> >          >      > "id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L,
> >         0L, 0L,
> >          >      > 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L),
> >         Time2 = c(1L,
> >          >      > 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L,
> >         0L, 1L, 0L,
> >          >      > 1L, 1L)), .Names = c("Sample", "Time1", "Time2"),
> class =
> >          >     "data.frame",
> >          >      > row.names = c(NA,
> >          >      > -19L))
> >          >      > daT<-data.frame(dat %>%
> >          >      >    mutate(Time1.but.not.in.Time2 = case_when(
> >          >      >              Time1 %in% "1" & Time2 %in% "0"  ~ "1"),
> >          >      > Time2.but.not.in.Time1 = case_when(
> >          >      >              Time1 %in% "0" & Time2 %in% "1"  ~ "1"),
> >          >      >   BothTimes = case_when(
> >          >      >              Time1 %in% "1" & Time2 %in% "1"  ~ "1")))
> >          >      >   daT
> >          >      >   summary(daT)
> >          >      >
> >          >      > cols.num <-
> >         c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
> >          >      > "BothTimes")
> >          >      > daT[cols.num] <- sapply(daT[cols.num],as.numeric)
> >          >      > summary(daT)
> >          >      > ProportionValue<-sum(daT$BothTimes,
> >         na.rm=T)/sum(daT$Time1, na.rm=T)
> >          >      > ProportionValue
> >          >      > standard error??
> >          >      >
> >          >      >       [[alternative HTML version deleted]]
> >          >      >
> >          >      > ______________________________________________
> >          >      > R-help at r-project.org <mailto:R-help at r-project.org>
> >         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
> >         mailing list
> >          >     -- To UNSUBSCRIBE and more, see
> >          >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >          >      > PLEASE do read the posting guide
> >          > http://www.R-project.org/posting-guide.html
> >          >      > and provide commented, minimal, self-contained,
> >         reproducible code.
> >          >      >
> >          >
> >
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jan 28 23:47:07 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 28 Jan 2021 22:47:07 +0000
Subject: [R] How to generate SE for the proportion value using a
 randomization process in R?
In-Reply-To: <CAMwU6B0TQHynFXC1TchadXjG-drfq1cz+75TLatg0cE4B6A7yg@mail.gmail.com>
References: <CAMwU6B0JkZ-wZY6bbcwBjJ5VpjGMePnc-KOmR2n+G6zoCHFA+w@mail.gmail.com>
 <8face05f-dc69-a286-9961-a0ebf6fd3502@sapo.pt>
 <CAMwU6B0meFyOvCnzn2DEMrU+LUoejL_x6RMW6aszxuq-2r+=TA@mail.gmail.com>
 <27a6ab72-c392-c87a-ef64-82a209ce6134@sapo.pt>
 <CAMwU6B1GyXio9bJUNhUbuHFYt6fuZ+9jZ1Nm85cUhAs1KuJ9sA@mail.gmail.com>
 <CAMwU6B1JDpDn-dADBx1La8UnqJGRcwXcqzO809vunrvyhSD-Eg@mail.gmail.com>
 <34f71527-3341-326b-3b4c-8b84efef7b1c@sapo.pt>
 <CAMwU6B0TQHynFXC1TchadXjG-drfq1cz+75TLatg0cE4B6A7yg@mail.gmail.com>
Message-ID: <5edbeefa-a673-1d0b-add3-30dfe891a262@sapo.pt>

Hello,

Yes, sorry for my previous post, I had forgotten about boot.array.
That's a much better solution for your problem.

Rui Barradas

?s 20:29 de 28/01/21, Marna Wagley escreveu:
> Thank you Rui,
> This is great. How about the following?
> 
> SimilatedData<-boot.array(b, indices=T)
> 
> seems it is giving the rows ID which are used in the calculation, isn't it?
> 
> 
> 
> 
> On Thu, Jan 28, 2021 at 12:21 PM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     I don't know why you would need to see the indices but rewrite the
>     function bootprop as
> 
>     bootprop_ind <- function(data, index){
>      ? ?d <- data[index, ]
>      ? ?#sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm = TRUE)
>      ? ?index
>     }
> 
> 
>     and call in the same way. It will now return a matrix of indices with R
>     = 1000 rows and 19 columns.
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
> 
>     ?s 19:29 de 28/01/21, Marna Wagley escreveu:
>      > Hi Rui,
>      > I am sorry for asking you several questions.
>      >
>      > In the given example, randomizations (reshuffle) were done 1000
>     times,
>      > and its 1000 proportion values (results) are stored and it can be
>     seen
>      > using b$t; but I was wondering how the table was randomized
>     (which rows
>      > have been missed/or repeated in each randomizing procedure?).
>      >
>      > Is there any way we can see the randomized table and its associated
>      > results? Here in this example, I randomized (or bootstrapped) the
>     table
>      > into three times (R=3) so I would like to store these three
>     tables and
>      > look at them later to know which rows were repeated/missed. Is
>     there any
>      > possibility?
>      > The example data and the code is given below.
>      >
>      > Thank you for your help.
>      >
>      > ####
>      > library(boot)
>      > dat<-structure(list(Sample = structure(c(1L, 12L, 13L, 14L, 15L, 16L,
>      > 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L), .Label
>     = c("id1",
>      > "id10", "id11", "id12", "id13", "id14", "id15", "id16", "id17",
>      > "id18", "id19", "Id2", "id3", "id4", "id5", "id6", "id7", "id8",
>      > "id9"), class = "factor"), Time1 = c(0L, 1L, 1L, 1L, 0L, 0L,
>      > 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L), Time2 = c(1L,
>      > 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
>      > 1L, 1L)), .Names = c("Sample", "Time1", "Time2"), class =
>     "data.frame",
>      > row.names = c(NA,
>      > -19L))
>      > daT<-data.frame(dat %>%
>      >? ? mutate(Time1.but.not.in.Time2 = case_when(
>      >? ? ? ? ? ? ? Time1 %in% "1" & Time2 %in% "0" ?~ "1"),
>      > Time2.but.not.in.Time1 = case_when(
>      >? ? ? ? ? ? ? Time1 %in% "0" & Time2 %in% "1" ?~ "1"),
>      >? ?BothTimes = case_when(
>      >? ? ? ? ? ? ? Time1 %in% "1" & Time2 %in% "1" ?~ "1")))
>      > cols.num <- c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
>      > "BothTimes")
>      > daT[cols.num] <- sapply(daT[cols.num],as.numeric)
>      > summary(daT)
>      >
>      > bootprop <- function(data, index){
>      >? ? ?d <- data[index, ]
>      >? ? ?sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]], na.rm =
>     TRUE)
>      > }
>      >
>      > R <- 3
>      > set.seed(2020)
>      > b <- boot(daT, bootprop, R)
>      > b
>      > b$t0? ? ?# original
>      > b$t
>      > sd(b$t)? # bootstrapped estimate of the SE of the sample prop.
>      > hist(b$t, freq = FALSE)
>      >
>      > str(b)
>      > b$data
>      > b$seed
>      > b$sim
>      > b$strata
>      > ################
>      >
>      >
>      > On Sat, Jan 23, 2021 at 12:36 AM Marna Wagley
>     <marna.wagley at gmail.com <mailto:marna.wagley at gmail.com>
>      > <mailto:marna.wagley at gmail.com <mailto:marna.wagley at gmail.com>>>
>     wrote:
>      >
>      >? ? ?Yes Rui, I can see we don't need to divide by square root of
>     sample
>      >? ? ?size. The example is great to understand it.
>      >? ? ?Thank you.
>      >? ? ?Marna
>      >
>      >
>      >? ? ?On Sat, Jan 23, 2021 at 12:28 AM Rui Barradas
>     <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
>      >? ? ?<mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>>
>     wrote:
>      >
>      >? ? ? ? ?Hello,
>      >
>      >? ? ? ? ?Inline.
>      >
>      >? ? ? ? ??s 07:47 de 23/01/21, Marna Wagley escreveu:
>      >? ? ? ? ? > Dear Rui,
>      >? ? ? ? ? > I was wondering whether we have to square root of SD
>     to find
>      >? ? ? ? ?SE, right?
>      >
>      >? ? ? ? ?No, we don't. var already divides by n, don't divide again.
>      >? ? ? ? ?This is the code, that can be seen by running the
>     function name
>      >? ? ? ? ?at a
>      >? ? ? ? ?command line.
>      >
>      >
>      >? ? ? ? ?sd
>      >? ? ? ? ?#function (x, na.rm = FALSE)
>      >? ? ? ? ?#sqrt(var(if (is.vector(x) || is.factor(x)) x else
>     as.double(x),
>      >? ? ? ? ?#? ? na.rm = na.rm))
>      >? ? ? ? ?#<bytecode: 0x55f3ce900848>
>      >? ? ? ? ?#<environment: namespace:stats>
>      >
>      >
>      >
>      >? ? ? ? ? >
>      >? ? ? ? ? > bootprop <- function(data, index){
>      >? ? ? ? ? >? ? ?d <- data[index, ]
>      >? ? ? ? ? >? ? ?sum(d[["BothTimes"]], na.rm = TRUE)/sum(d[["Time1"]],
>      >? ? ? ? ?na.rm = TRUE)
>      >? ? ? ? ? > }
>      >? ? ? ? ? >
>      >? ? ? ? ? > R <- 1e3
>      >? ? ? ? ? > set.seed(2020)
>      >? ? ? ? ? > b <- boot(daT, bootprop, R)
>      >? ? ? ? ? > b
>      >? ? ? ? ? > b$t0? ? ?# original
>      >? ? ? ? ? > sd(b$t)? # bootstrapped estimate of the SE of the
>     sample prop.
>      >? ? ? ? ? > sd(b$t)/sqrt(1000)
>      >? ? ? ? ? > pandit*(1-pandit)
>      >? ? ? ? ? >
>      >? ? ? ? ? > hist(b$t, freq = FALSE)
>      >
>      >
>      >? ? ? ? ?Try plotting the normal densities for both cases, the red
>     line is
>      >? ? ? ? ?clearly wrong.
>      >
>      >
>      >? ? ? ? ?f <- function(x, xbar, s){
>      >? ? ? ? ? ? ?dnorm(x, mean = xbar, sd = s)
>      >? ? ? ? ?}
>      >
>      >? ? ? ? ?hist(b$t, freq = FALSE)
>      >? ? ? ? ?curve(f(x, xbar = b$t0, s = sd(b$t)), from = 0, to = 1, col =
>      >? ? ? ? ?"blue",
>      >? ? ? ? ?add = TRUE)
>      >? ? ? ? ?curve(f(x, xbar = b$t0, s = sd(b$t)/sqrt(R)), from = 0,
>     to = 1,
>      >? ? ? ? ?col =
>      >? ? ? ? ?"red", add = TRUE)
>      >
>      >
>      >? ? ? ? ?Hope this helps,
>      >
>      >? ? ? ? ?Rui Barradas
>      >
>      >? ? ? ? ? >
>      >? ? ? ? ? >
>      >? ? ? ? ? >
>      >? ? ? ? ? >
>      >? ? ? ? ? > On Fri, Jan 22, 2021 at 3:07 PM Rui Barradas
>      >? ? ? ? ?<ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
>     <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>
>      >? ? ? ? ? > <mailto:ruipbarradas at sapo.pt
>     <mailto:ruipbarradas at sapo.pt> <mailto:ruipbarradas at sapo.pt
>     <mailto:ruipbarradas at sapo.pt>>>>
>      >? ? ? ? ?wrote:
>      >? ? ? ? ? >
>      >? ? ? ? ? >? ? ?Hello,
>      >? ? ? ? ? >
>      >? ? ? ? ? >? ? ?Something like this, using base package boot?
>      >? ? ? ? ? >
>      >? ? ? ? ? >
>      >? ? ? ? ? >? ? ?library(boot)
>      >? ? ? ? ? >
>      >? ? ? ? ? >? ? ?bootprop <- function(data, index){
>      >? ? ? ? ? >? ? ? ? ?d <- data[index, ]
>      >? ? ? ? ? >? ? ? ? ?sum(d[["BothTimes"]], na.rm =
>     TRUE)/sum(d[["Time1"]],
>      >? ? ? ? ?na.rm = TRUE)
>      >? ? ? ? ? >? ? ?}
>      >? ? ? ? ? >
>      >? ? ? ? ? >? ? ?R <- 1e3
>      >? ? ? ? ? >? ? ?set.seed(2020)
>      >? ? ? ? ? >? ? ?b <- boot(daT, bootprop, R)
>      >? ? ? ? ? >? ? ?b
>      >? ? ? ? ? >? ? ?b$t0? ? ?# original
>      >? ? ? ? ? >? ? ?sd(b$t)? # bootstrapped estimate of the SE of the
>     sample
>      >? ? ? ? ?prop.
>      >? ? ? ? ? >? ? ?hist(b$t, freq = FALSE)
>      >? ? ? ? ? >
>      >? ? ? ? ? >
>      >? ? ? ? ? >? ? ?Hope this helps,
>      >? ? ? ? ? >
>      >? ? ? ? ? >? ? ?Rui Barradas
>      >? ? ? ? ? >
>      >? ? ? ? ? >? ? ??s 21:57 de 22/01/21, Marna Wagley escreveu:
>      >? ? ? ? ? >? ? ? > Hi All,
>      >? ? ? ? ? >? ? ? > I was trying to estimate standard error (SE)
>     for the
>      >? ? ? ? ?proportion
>      >? ? ? ? ? >? ? ?value using
>      >? ? ? ? ? >? ? ? > some kind of randomization process
>     (bootstrapping or
>      >? ? ? ? ?jackknifing)
>      >? ? ? ? ? >? ? ?in R, but
>      >? ? ? ? ? >? ? ? > I could not figure it out.
>      >? ? ? ? ? >? ? ? >
>      >? ? ? ? ? >? ? ? > Is there any way to generate SE for the proportion?
>      >? ? ? ? ? >? ? ? >
>      >? ? ? ? ? >? ? ? > The example of the data and the code I am using is
>      >? ? ? ? ?attached for your
>      >? ? ? ? ? >? ? ? > reference. I would like to generate the value of
>      >? ? ? ? ?proportion with
>      >? ? ? ? ? >? ? ?a SE using
>      >? ? ? ? ? >? ? ? > a 1000 times randomization.
>      >? ? ? ? ? >? ? ? >
>      >? ? ? ? ? >? ? ? > dat<-structure(list(Sample = structure(c(1L,
>     12L, 13L,
>      >? ? ? ? ?14L, 15L, 16L,
>      >? ? ? ? ? >? ? ? > 17L, 18L, 19L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
>      >? ? ? ? ?11L), .Label
>      >? ? ? ? ? >? ? ?= c("id1",
>      >? ? ? ? ? >? ? ? > "id10", "id11", "id12", "id13", "id14", "id15",
>      >? ? ? ? ?"id16", "id17",
>      >? ? ? ? ? >? ? ? > "id18", "id19", "Id2", "id3", "id4", "id5", "id6",
>      >? ? ? ? ?"id7", "id8",
>      >? ? ? ? ? >? ? ? > "id9"), class = "factor"), Time1 = c(0L, 1L,
>     1L, 1L,
>      >? ? ? ? ?0L, 0L,
>      >? ? ? ? ? >? ? ? > 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L,
>     0L),
>      >? ? ? ? ?Time2 = c(1L,
>      >? ? ? ? ? >? ? ? > 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L,
>      >? ? ? ? ?0L, 1L, 0L,
>      >? ? ? ? ? >? ? ? > 1L, 1L)), .Names = c("Sample", "Time1",
>     "Time2"), class =
>      >? ? ? ? ? >? ? ?"data.frame",
>      >? ? ? ? ? >? ? ? > row.names = c(NA,
>      >? ? ? ? ? >? ? ? > -19L))
>      >? ? ? ? ? >? ? ? > daT<-data.frame(dat %>%
>      >? ? ? ? ? >? ? ? >? ? mutate(Time1.but.not.in.Time2 = case_when(
>      >? ? ? ? ? >? ? ? >? ? ? ? ? ? ? Time1 %in% "1" & Time2 %in% "0"? ~
>     "1"),
>      >? ? ? ? ? >? ? ? > Time2.but.not.in.Time1 = case_when(
>      >? ? ? ? ? >? ? ? >? ? ? ? ? ? ? Time1 %in% "0" & Time2 %in% "1"? ~
>     "1"),
>      >? ? ? ? ? >? ? ? >? ?BothTimes = case_when(
>      >? ? ? ? ? >? ? ? >? ? ? ? ? ? ? Time1 %in% "1" & Time2 %in% "1"? ~
>     "1")))
>      >? ? ? ? ? >? ? ? >? ?daT
>      >? ? ? ? ? >? ? ? >? ?summary(daT)
>      >? ? ? ? ? >? ? ? >
>      >? ? ? ? ? >? ? ? > cols.num <-
>      >? ? ? ? ?c("Time1.but.not.in.Time2","Time2.but.not.in.Time1",
>      >? ? ? ? ? >? ? ? > "BothTimes")
>      >? ? ? ? ? >? ? ? > daT[cols.num] <- sapply(daT[cols.num],as.numeric)
>      >? ? ? ? ? >? ? ? > summary(daT)
>      >? ? ? ? ? >? ? ? > ProportionValue<-sum(daT$BothTimes,
>      >? ? ? ? ?na.rm=T)/sum(daT$Time1, na.rm=T)
>      >? ? ? ? ? >? ? ? > ProportionValue
>      >? ? ? ? ? >? ? ? > standard error??
>      >? ? ? ? ? >? ? ? >
>      >? ? ? ? ? >? ? ? >? ? ? ?[[alternative HTML version deleted]]
>      >? ? ? ? ? >? ? ? >
>      >? ? ? ? ? >? ? ? > ______________________________________________
>      >? ? ? ? ? >? ? ? > R-help at r-project.org
>     <mailto:R-help at r-project.org> <mailto:R-help at r-project.org
>     <mailto:R-help at r-project.org>>
>      >? ? ? ? ?<mailto:R-help at r-project.org
>     <mailto:R-help at r-project.org> <mailto:R-help at r-project.org
>     <mailto:R-help at r-project.org>>>
>      >? ? ? ? ?mailing list
>      >? ? ? ? ? >? ? ?-- To UNSUBSCRIBE and more, see
>      >? ? ? ? ? >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-help
>      >? ? ? ? ? >? ? ? > PLEASE do read the posting guide
>      >? ? ? ? ? > http://www.R-project.org/posting-guide.html
>      >? ? ? ? ? >? ? ? > and provide commented, minimal, self-contained,
>      >? ? ? ? ?reproducible code.
>      >? ? ? ? ? >? ? ? >
>      >? ? ? ? ? >
>      >
>


From m@rce| @end|ng |rom coeurd@rt|ch@ut@ch  Fri Jan 29 09:57:07 2021
From: m@rce| @end|ng |rom coeurd@rt|ch@ut@ch (Marcel Baumgartner)
Date: Fri, 29 Jan 2021 09:57:07 +0100
Subject: [R] Error when calling (R 4.0.x on Windows) from Python
In-Reply-To: <CAHqSRuSOYk=aWzKg9Ub4LN+hXTZ8ptZDw7gzrxt67957kNDwXQ@mail.gmail.com>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
 <24591.65302.527022.733577@stat.math.ethz.ch>
 <24593.9866.492194.548636@stat.math.ethz.ch>
 <dce1a81a-a543-bbbc-24f3-54d64eae2b80@gmail.com>
 <aa6df17c-8684-3140-a545-65d217882c1b@gmail.com>
 <CAHqSRuTFc8x=mox=55s7HZHpWeOdzaR_oMev6kv=Yp8XiNzsSQ@mail.gmail.com>
 <37bf94d0-873a-5bef-87ee-60bd572c8545@gmail.com>
 <CAHqSRuSOYk=aWzKg9Ub4LN+hXTZ8ptZDw7gzrxt67957kNDwXQ@mail.gmail.com>
Message-ID: <25b589b25af628379c5a9ac502580552@mail.infomaniak.com>

Dear Bill, Duncan and Martin,

thanks for your investigation. Can you clarify on next steps? Is this
now an official bug, or have you found a workaround? For your
information: the issue showed up the first time when I called R 4.0.2
from within a software called "IDEA" (from Caseware Analytics), using
their scripting language (similar to Visual Basic). With my colleague
we then simply reproduce the error calling R from Python, so that we
could share it more easily. When we run this command directly on the
CMD in Windows, all works fine. The issue only happens when R is
called within another software.

Best regards

Marcel

Le 2021-01-27T23:14:36.000+01:00, Bill Dunlap
<williamwdunlap at gmail.com> a ?crit :

>?I?tried?the?following?change,?that?adds?quotes?if?the?argument?does
>?
>?not?include?">".
>?
>?Index:?front-ends/rcmdfn.c
>?
>?===================================================================
>?
>?---?front-ends/rcmdfn.c?(revision?79883)
>?
>?+++?front-ends/rcmdfn.c?(working?copy)
>?
>?@@?-173,9?+173,13?@@
>?
>?????????????????fprintf(stderr,?"command?line?too?long\n");
>?
>?????????????????return(27);
>?
>?????????????}
>?
>?-???????????strcat(cmd,?"\"");
>?
>?+???????????if?(!strchr(argv[i],?'>'))?{
>?
>?+????????????????strcat(cmd,?"\"");
>?
>?+????????????}
>?
>?????????????strcat(cmd,?argv[i]);
>?
>?-???????????strcat(cmd,?"\"");
>?
>?+???????????if?(!strchr(argv[i],?'>'))?{
>?
>?+???????????????strcat(cmd,?"\"");
>?
>?+????????????}
>?
>?????????}
>?
>?????????/*?the?outermost?double?quotes?are?needed?for?cmd.exe?*/
>?
>?????????strcat(cmd,?"\"");
>?
>?It?lets?the?python?example?work.??I?am?not?sure?that?quoting?all?the
>?
>?arguments?buys?you?much,?as?shQuote()?is?still?needed?for?arguments
>?
>?that?include?spaces.??E.g.,??with?3.6.3,?4.0.3,?and?my?development
>?
>?build?with?the?above?patch?we?get
>?
>>??stopifnot(dir.create(dirname?<-?file.path(tempfile(),?"A?SPACE"),
>>??recursive=TRUE))
>>??
>>???logname?<-?file.path(dirname,?"log.txt")
>>??
>>???unlink(logname)
>>??
>>???system(paste(?"C:\\R\\R-3.6.3\\bin\\R.exe?--quiet?--vanilla?-e
>>??\"commandArgs()\"?1>",?logname))
>?
>??ARGUMENT?'SPACE/log.txt'?__ignored__
>?
>?[1]?0
>?
>>??tryCatch(readLines(logname),?error=function(e)conditionMessage(e))
>?
>??[1]?"cannot?open?the?connection"
>?
>?Warning?message:
>?
>?In?file(con,?"r")?:
>?
>??cannot?open?file
>?
>?'C:\Users\willi\AppData\Local\Temp\RtmpM5tsC7\file1a1068734a49/A
>?
>?SPACE/log.txt':?No?such?file?or?directory
>?
>>??system(paste(?"C:\\R\\R-4.0.3\\bin\\R.exe?--quiet?--vanilla?-e
>>??\"commandArgs()\"?1>",?logname))
>>??
>>???commandArgs()
>?
>??[1]?"C:\\R\\R-40~1.3/bin/x64/Rterm.exe"
>?
>?[2]?"--quiet"
>?
>?[3]?"--vanilla"
>?
>?[4]?"-e"
>?
>?[5]?"commandArgs()"
>?
>?[6]?"1>"
>?
>?[7]
>?"C:\\Users\\willi\\AppData\\Local\\Temp\\RtmpM5tsC7\\file1a1068734a49/A"
>?
>?[8]?"SPACE/log.txt"
>?
>>??
>?
>??[1]?0
>?
>>??tryCatch(readLines(logname),?error=function(e)conditionMessage(e))
>?
>??[1]?"cannot?open?the?connection"
>?
>?Warning?message:
>?
>?In?file(con,?"r")?:
>?
>??cannot?open?file
>?
>?'C:\Users\willi\AppData\Local\Temp\RtmpM5tsC7\file1a1068734a49/A
>?
>?SPACE/log.txt':?No?such?file?or?directory
>?
>>??unlink(logname)
>>??
>>???system(paste(
>>??"C:\\msys64\\home\\willi\\ucrt3\\r\\trunk\\bin\\R.exe?--quiet
>>??--vanilla?-e?\"commandArgs()\"?1>",?logname))
>?
>??[1]?0
>?
>>??tryCatch(readLines(logname),?error=function(e)conditionMessage(e))
>?
>??[1]?"cannot?open?the?connection"
>?
>?Warning?message:
>?
>?In?file(con,?"r")?:
>?
>??cannot?open?file
>?
>?'C:\Users\willi\AppData\Local\Temp\RtmpM5tsC7\file1a1068734a49/A
>?
>?SPACE/log.txt':?No?such?file?or?directory
>?
>>??tryCatch(readLines(sub("?.*$",?"",?logname)),
>>??error=function(e)conditionMessage(e))
>?
>??[1]?">?commandArgs()"
>?
>??"[1]
>?
>?\"C:\\\\msys64\\\\home\\\\willi\\\\ucrt3\\\\r\\\\trunk/bin/x64/Rterm.exe\""
>?
>?[3]?"[2]?\"--quiet\"
>?
>?"?"[3]?\"--vanilla\"
>?
>??"
>?
>?[5]?"[4]?\"-e\"
>?
>?"?"[5]?\"commandArgs()\"
>?
>??"
>?
>?[7]?"[6]?\"SPACE/log.txt\"
>?
>?"?">?"
>?
>?[9]?">?"
>?
>>??unlink(logname)
>>??
>>???system(paste(
>>??"C:\\msys64\\home\\willi\\ucrt3\\r\\trunk\\bin\\R.exe?--quiet
>>??--vanilla?-e?\"commandArgs()\"?1>",?shQuote(logname)))
>?
>??[1]?0
>?
>>??tryCatch(readLines(logname),?error=function(e)conditionMessage(e))
>?
>??[1]?">?commandArgs()"
>?
>??"[1]
>?
>?\"C:\\\\msys64\\\\home\\\\willi\\\\ucrt3\\\\r\\\\trunk/bin/x64/Rterm.exe\""
>?
>?[3]?"[2]?\"--quiet\"
>?
>?"?"[3]?\"--vanilla\"
>?
>??"
>?
>?[5]?"[4]?\"-e\"
>?
>?"?"[5]?\"commandArgs()\"
>?
>??"
>?
>?[7]?">?"
>?
>??">?"
>?
>?-Bill
>?
>?On?Wed,?Jan?27,?2021?at?1:25?PM?Duncan?Murdoch
>?<murdoch.duncan at gmail.com>?wrote:
>?
>>??On?27/01/2021?3:40?p.m.,?Bill?Dunlap?wrote:
>>??
>>>???I?believe?the?problem?is?from?svn?77925?in
>>>???gnuwin/front-ends/rcmdfn.c,
>>>???
>>>????which?was?committed?a?few?days?after?3.6.3?was?released.?Rterm
>>>???used
>>>???
>>>????to?put?double?quotes?around?a?command?line?argument?only?if?it
>>>???
>>>????contained?a?space,?now?it?double?quotes?all?arguments.?It?sees
>>>???shell
>>>???
>>>????constructs?like?"1>"?and?the?following?file?name?as?arguments
>>>???and
>>>???
>>>????double?quoting?them?hides?them?from?the?shell,?leading?to?this
>>>???
>>>????problem.?I?think?we?may?have?to?rely?on?the?user?supplying
>>>???quotes?as
>>>???
>>>????needed?instead?of?blindly?adding?them.
>>??
>>???Okay,?now?I?see?what?you?mean.
>>??
>>???If?you?invoke?R?using?R.exe,?it?asks?cmd.exe?to?run?Rterm.exe,?so
>>??it?is
>>??
>>???possible?that?redirection?would?be?handled.
>>??
>>???If?you?invoke?R?directly?using?Rterm.exe,?then?my?description
>>??down?below
>>??
>>???would?be?correct.
>>??
>>???Duncan?Murdoch
>>??
>>>???-Bill
>>>???
>>>????On?Wed,?Jan?27,?2021?at?12:28?PM?Duncan?Murdoch
>>>???
>>>????<murdoch.duncan at gmail.com>?wrote:
>>>???
>>>>????On?27/01/2021?3:17?p.m.,?Duncan?Murdoch?wrote:
>>>>????
>>>>>?????On?27/01/2021?3:38?a.m.,?Martin?Maechler?wrote:
>>>>>?????
>>>>>>>>>>>???????????Martin?Maechler
>>>>>>>>>>>???????????
>>>>>>>>>>>????????????on?Tue,?26?Jan?2021?12:37:58?+0100?writes:
>>>>>>??????
>>>>>>>>>>>???????????Marcel?Baumgartner
>>>>>>>>>>>???????????
>>>>>>>>>>>????????????on?Tue,?26?Jan?2021?08:55:48?+0100?writes:
>>>>>>??????
>>>>>>???????Dear?all,?my?colleague?posted?our?issue?on?stackoverflow:
>>>>>>??????
>>>>>>???????Calling?R?script?from?Python?does?not?save?log?file?in
>>>>>>??????
>>>>>>???????version?4?-?Stack?Overflow
>>>>>>??????
>>>>>>???????[stackoverflow.com/questions...
>>>>>>??????[https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4]]
>>>>>>??????
>>>>>>???????It?is?about?this?kind?of?call?to?R:
>>>>>>??????
>>>>>>???????R.exe?-f?code.R?--args?"~/file.txt"?1>?"~/log.txt"?2>&1".
>>>>>>??????
>>>>>>???????The?issue?is?that?the?log.txt?file?is?not?created?when
>>>>>>??????
>>>>>>???????running?R?4.x.x.?The?same?code?works?perfectly?fine?with
>>>>>>??????
>>>>>>???????R?3.6.x.
>>>>>>??????
>>>>>>???????Any?idea?what's?going?wrong?as?of?version?4??Regards
>>>>>>??????
>>>>>>???????Marcel
>>>>>>??????
>>>>>>???????Dear?Marcel,?I?think?the?solution?is?embarrassingly
>>>>>>??????
>>>>>>???????simple:
>>>>>>??????
>>>>>>???????From?the?SO?post,?where?she?showed?a?bit?more?detail?than
>>>>>>??????you
>>>>>>??????
>>>>>>???????show?here,?it's?clear?you?have?confused?'R.exe'?and
>>>>>>??????
>>>>>>???????'Rscript.exe'?and?what?you?say?above?is?not?true:
>>>>>>??????
>>>>>>???????'R.exe'?was?used?for?R?3.6.0?but?for?R?4.0.3,?you/she
>>>>>>??????used
>>>>>>??????
>>>>>>???????'Rscript.exe'?instead.
>>>>>>??????
>>>>>>???????...?as?you've?noticed?now,?they?do?behave?differently,
>>>>>>??????
>>>>>>???????indeed!
>>>>>>??????
>>>>>>???????Well,?this?was?not?the?solution?to?their?--?Windows-only
>>>>>>??????--?problem.
>>>>>>??????
>>>>>>???????The?problem?*is*?indeed?visible?if?they?only?use?R.exe
>>>>>>??????(also
>>>>>>??????
>>>>>>???????for?R?4.0.3).
>>>>>>??????
>>>>>>???????I've?commented?more?on?the?SO?issue?(see?above),
>>>>>>??????
>>>>>>???????notably?asking?for?a?*minimal*?repr.ex.?(reproducible
>>>>>>??????example),
>>>>>>??????
>>>>>>???????and?one?*not*?using?"<YOUR?PATH>"?and?setwd()?..
>>>>>?????
>>>>>??????Isn't?this?purely?a?Python?or?user?problem??R?shouldn't
>>>>>?????process
>>>>>?????
>>>>>??????redirection?directives?like
>>>>>?????
>>>>>??????1>?"~/log.txt"?2>&1
>>>>>?????
>>>>>??????because?it's?the?shell's?job?to?process?those.?If?Python?is
>>>>>?????acting?as
>>>>>?????
>>>>>??????the?shell,?it?needs?to?handle?those?things.?If?R?was
>>>>>?????handling?the
>>>>>?????
>>>>>??????command?via
>>>>????
>>>>?????Oops,?sent?before?finishing:
>>>>????
>>>>?????If?R?was?handling?the?command?via?system()?or?system2(),?it
>>>>????would?handle
>>>>????
>>>>?????redirection?itself.?If?it?was?using?the?Windows-only?shell(),
>>>>????it?would
>>>>????
>>>>?????call?cmd.exe?(by?default)?to?handle?redirection.?(This?is?a
>>>>????difference
>>>>????
>>>>?????between?R?on?Windows?and?R?in?Unix:?in?Unix?a?shell?is?always
>>>>????used.)
>>>>????
>>>>?????Duncan?Murdoch
>>>>????
>>>>?????______________________________________________
>>>>????
>>>>?????R-help at r-project.org?mailing?list?--?To?UNSUBSCRIBE?and?more,
>>>>????see
>>>>????
>>>>?????stat.ethz.ch/mailman/listin...
>>>>????[https://stat.ethz.ch/mailman/listinfo/r-help]
>>>>????
>>>>?????PLEASE?do?read?the?posting?guide
>>>>????www.R-project.org/posting-g...
>>>>????[http://www.R-project.org/posting-guide.html]
>>>>????
>>>>?????and?provide?commented,?minimal,?self-contained,?reproducible
>>>>????code.



	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Jan 29 11:19:04 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 29 Jan 2021 05:19:04 -0500
Subject: [R] Error when calling (R 4.0.x on Windows) from Python
In-Reply-To: <25b589b25af628379c5a9ac502580552@mail.infomaniak.com>
References: <3cf33078e38cd82eaa62af315c5c6795@mail.infomaniak.com>
 <24591.65302.527022.733577@stat.math.ethz.ch>
 <24593.9866.492194.548636@stat.math.ethz.ch>
 <dce1a81a-a543-bbbc-24f3-54d64eae2b80@gmail.com>
 <aa6df17c-8684-3140-a545-65d217882c1b@gmail.com>
 <CAHqSRuTFc8x=mox=55s7HZHpWeOdzaR_oMev6kv=Yp8XiNzsSQ@mail.gmail.com>
 <37bf94d0-873a-5bef-87ee-60bd572c8545@gmail.com>
 <CAHqSRuSOYk=aWzKg9Ub4LN+hXTZ8ptZDw7gzrxt67957kNDwXQ@mail.gmail.com>
 <25b589b25af628379c5a9ac502580552@mail.infomaniak.com>
Message-ID: <8721759c-e3d8-5e23-dcb5-89b2d4f00ff0@gmail.com>

On 29/01/2021 3:57 a.m., Marcel Baumgartner wrote:
> Dear Bill, Duncan and Martin,
> 
> thanks for your investigation. Can you clarify on next steps? Is this 
> now an official bug, or have you found a workaround? For your 
> information: the issue showed up the first time when I called R 4.0.2 
> from within a software called "IDEA" (from Caseware Analytics), using 
> their scripting language (similar to Visual Basic). With my colleague we 
> then simply reproduce the error calling R from Python, so that we could 
> share it more easily. When we run this command directly on the CMD in 
> Windows, all works fine. The issue only happens when R is called within 
> another software.
> 

I would say this is a bug, with two workarounds.  These are only needed 
(and will only work) on Windows.

1.  If you want to include redirection in the command line, then call 
cmd.exe yourself, and have it call Rterm.exe.  I think your original command

R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1"

could be written as

cmd.exe 1>log.txt 2>&1 /C R.exe -f code.R --args "~/file.txt"

(but I haven't tested it).  You could also use the slightly more efficient

cmd.exe 1>log.txt 2>&1 /C Rterm.exe -f code.R --args "~/file.txt"

if Rterm.exe is on your path; by default I don't think it will be.

2.  Change the Python code to a different function call than 
subprocess.call.  It should be one that's equivalent to the C system() 
function; I believe os.system() is what you want, so you'd use

os.system("R.exe -f code.R --args "~/file.txt" 1> "~/log.txt" 2>&1")

and the redirection would be handled by the implicit shell that is 
called by os.system.  Again, replacing R.exe by Rterm.exe would be a 
tiny bit more efficient, but it might not be on the path.

Duncan Murdoch

> Best regards
> 
> Marcel
> 
> 
> Le 2021-01-27T23:14:36.000+01:00, Bill Dunlap <williamwdunlap at gmail.com> 
> a ?crit :
> 
>     I tried the following change, that adds quotes if the argument does
>     not include ">".
>     Index: front-ends/rcmdfn.c
>     ===================================================================
>     --- front-ends/rcmdfn.c (revision 79883)
>     +++ front-ends/rcmdfn.c (working copy)
>     @@ -173,9 +173,13 @@
>     fprintf(stderr, "command line too long\n");
>     return(27);
>     }
>     - strcat(cmd, "\"");
>     + if (!strchr(argv[i], '>')) {
>     + strcat(cmd, "\"");
>     + }
>     strcat(cmd, argv[i]);
>     - strcat(cmd, "\"");
>     + if (!strchr(argv[i], '>')) {
>     + strcat(cmd, "\"");
>     + }
>     }
>     /* the outermost double quotes are needed for cmd.exe */
>     strcat(cmd, "\"");
> 
>     It lets the python example work. I am not sure that quoting all the
>     arguments buys you much, as shQuote() is still needed for arguments
>     that include spaces. E.g., with 3.6.3, 4.0.3, and my development
>     build with the above patch we get
> 
>         stopifnot(dir.create(dirname <- file.path(tempfile(), "A
>         SPACE"), recursive=TRUE))
>         logname <- file.path(dirname, "log.txt")
>         unlink(logname)
>         system(paste( "C:\\R\\R-3.6.3\\bin\\R.exe --quiet --vanilla -e
>         \"commandArgs()\" 1>", logname))
> 
>     ARGUMENT 'SPACE/log.txt' __ignored__
> 
>     [1] 0
> 
>         tryCatch(readLines(logname), error=function(e)conditionMessage(e))
> 
>     [1] "cannot open the connection"
>     Warning message:
>     In file(con, "r") :
>     cannot open file
>     'C:\Users\willi\AppData\Local\Temp\RtmpM5tsC7\file1a1068734a49/A
>     SPACE/log.txt': No such file or directory
> 
> 
>         system(paste( "C:\\R\\R-4.0.3\\bin\\R.exe --quiet --vanilla -e
>         \"commandArgs()\" 1>", logname))
>         commandArgs()
> 
>     [1] "C:\\R\\R-40~1.3/bin/x64/Rterm.exe"
>     [2] "--quiet"
>     [3] "--vanilla"
>     [4] "-e"
>     [5] "commandArgs()"
>     [6] "1>"
>     [7]
>     "C:\\Users\\willi\\AppData\\Local\\Temp\\RtmpM5tsC7\\file1a1068734a49/A"
>     [8] "SPACE/log.txt"
> 
> 
>     [1] 0
> 
>         tryCatch(readLines(logname), error=function(e)conditionMessage(e))
> 
>     [1] "cannot open the connection"
>     Warning message:
>     In file(con, "r") :
>     cannot open file
>     'C:\Users\willi\AppData\Local\Temp\RtmpM5tsC7\file1a1068734a49/A
>     SPACE/log.txt': No such file or directory
> 
> 
>         unlink(logname)
>         system(paste(
>         "C:\\msys64\\home\\willi\\ucrt3\\r\\trunk\\bin\\R.exe --quiet
>         --vanilla -e \"commandArgs()\" 1>", logname))
> 
>     [1] 0
> 
>         tryCatch(readLines(logname), error=function(e)conditionMessage(e))
> 
>     [1] "cannot open the connection"
>     Warning message:
>     In file(con, "r") :
>     cannot open file
>     'C:\Users\willi\AppData\Local\Temp\RtmpM5tsC7\file1a1068734a49/A
>     SPACE/log.txt': No such file or directory
> 
>         tryCatch(readLines(sub(" .*$", "", logname)),
>         error=function(e)conditionMessage(e))
> 
>     [1] "> commandArgs()"
>     "[1]
>     \"C:\\\\msys64\\\\home\\\\willi\\\\ucrt3\\\\r\\\\trunk/bin/x64/Rterm.exe\""
>     [3] "[2] \"--quiet\"
>     " "[3] \"--vanilla\"
>     "
>     [5] "[4] \"-e\"
>     " "[5] \"commandArgs()\"
>     "
>     [7] "[6] \"SPACE/log.txt\"
>     " "> "
>     [9] "> "
> 
> 
>         unlink(logname)
>         system(paste(
>         "C:\\msys64\\home\\willi\\ucrt3\\r\\trunk\\bin\\R.exe --quiet
>         --vanilla -e \"commandArgs()\" 1>", shQuote(logname)))
> 
>     [1] 0
> 
>         tryCatch(readLines(logname), error=function(e)conditionMessage(e))
> 
>     [1] "> commandArgs()"
>     "[1]
>     \"C:\\\\msys64\\\\home\\\\willi\\\\ucrt3\\\\r\\\\trunk/bin/x64/Rterm.exe\""
>     [3] "[2] \"--quiet\"
>     " "[3] \"--vanilla\"
>     "
>     [5] "[4] \"-e\"
>     " "[5] \"commandArgs()\"
>     "
>     [7] "> "
>     "> "
> 
>     -Bill
> 
>     On Wed, Jan 27, 2021 at 1:25 PM Duncan Murdoch
>     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
> 
>         On 27/01/2021 3:40 p.m., Bill Dunlap wrote:
> 
>             I believe the problem is from svn 77925 in
>             gnuwin/front-ends/rcmdfn.c,
>             which was committed a few days after 3.6.3 was released.
>             Rterm used
>             to put double quotes around a command line argument only if it
>             contained a space, now it double quotes all arguments. It
>             sees shell
>             constructs like "1>" and the following file name as
>             arguments and
>             double quoting them hides them from the shell, leading to this
>             problem. I think we may have to rely on the user supplying
>             quotes as
>             needed instead of blindly adding them.
> 
> 
>         Okay, now I see what you mean.
> 
>         If you invoke R using R.exe, it asks cmd.exe to run Rterm.exe,
>         so it is
>         possible that redirection would be handled.
> 
>         If you invoke R directly using Rterm.exe, then my description
>         down below
>         would be correct.
> 
>         Duncan Murdoch
> 
> 
> 
>             -Bill
> 
>             On Wed, Jan 27, 2021 at 12:28 PM Duncan Murdoch
>             <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>
>             wrote:
> 
> 
>                 On 27/01/2021 3:17 p.m., Duncan Murdoch wrote:
> 
>                     On 27/01/2021 3:38 a.m., Martin Maechler wrote:
> 
>                                             Martin Maechler
>                                             on Tue, 26 Jan 2021 12:37:58
>                                             +0100 writes:
> 
> 
>                                             Marcel Baumgartner
>                                             on Tue, 26 Jan 2021 08:55:48
>                                             +0100 writes:
> 
> 
>                         Dear all, my colleague posted our issue on
>                         stackoverflow:
> 
>                         Calling R script from Python does not save log
>                         file in
>                         version 4 - Stack Overflow
>                         [stackoverflow.com/questions...
>                         <https://stackoverflow.com/questions/65887485/calling-r-script-from-python-does-not-save-log-file-in-version-4>]
> 
>                         It is about this kind of call to R:
> 
>                         R.exe -f code.R --args "~/file.txt" 1>
>                         "~/log.txt" 2>&1".
> 
>                         The issue is that the log.txt file is not
>                         created when
>                         running R 4.x.x. The same code works perfectly
>                         fine with
>                         R 3.6.x.
> 
>                         Any idea what's going wrong as of version 4? Regards
>                         Marcel
> 
>                         Dear Marcel, I think the solution is embarrassingly
>                         simple:
> 
>                          From the SO post, where she showed a bit more
>                         detail than you
>                         show here, it's clear you have confused 'R.exe' and
>                         'Rscript.exe' and what you say above is not true:
> 
>                         'R.exe' was used for R 3.6.0 but for R 4.0.3,
>                         you/she used
>                         'Rscript.exe' instead.
> 
> 
>                         ... as you've noticed now, they do behave
>                         differently,
>                         indeed!
> 
>                         Well, this was not the solution to their --
>                         Windows-only -- problem.
>                         The problem *is* indeed visible if they only use
>                         R.exe (also
>                         for R 4.0.3).
> 
>                         I've commented more on the SO issue (see above),
>                         notably asking for a *minimal* repr.ex.
>                         (reproducible example),
>                         and one *not* using "<YOUR PATH>" and setwd() ..
> 
> 
>                     Isn't this purely a Python or user problem? R
>                     shouldn't process
>                     redirection directives like
> 
>                     1> "~/log.txt" 2>&1
> 
>                     because it's the shell's job to process those. If
>                     Python is acting as
>                     the shell, it needs to handle those things. If R was
>                     handling the
>                     command via
> 
> 
>                 Oops, sent before finishing:
> 
>                 If R was handling the command via system() or system2(),
>                 it would handle
>                 redirection itself. If it was using the Windows-only
>                 shell(), it would
>                 call cmd.exe (by default) to handle redirection. (This
>                 is a difference
>                 between R on Windows and R in Unix: in Unix a shell is
>                 always used.)
> 
>                 Duncan Murdoch
> 
>                 ______________________________________________
>                 R-help at r-project.org <mailto:R-help at r-project.org>
>                 mailing list -- To UNSUBSCRIBE and more, see
>                 stat.ethz.ch/mailman/listin...
>                 <https://stat.ethz.ch/mailman/listinfo/r-help>
>                 PLEASE do read the posting guide
>                 www.R-project.org/posting-g...
>                 <http://www.R-project.org/posting-guide.html>
>                 and provide commented, minimal, self-contained,
>                 reproducible code.
> 
> 
>


From pet@@@@th@n@@|@ @end|ng |rom hotm@||@gr  Fri Jan 29 13:47:25 2021
From: pet@@@@th@n@@|@ @end|ng |rom hotm@||@gr (Nasia Petsa)
Date: Fri, 29 Jan 2021 12:47:25 +0000
Subject: [R] arima/fixed
Message-ID: <DBBPR03MB705015D3199567874B4564158EB99@DBBPR03MB7050.eurprd03.prod.outlook.com>

Dear all,

I have the following problem with determining the argument fixed in arima function. What is the length  of argument fixed for an ARIMA(1,0,0)(0,1,1) and what is the correct  order for the parameters ?

	[[alternative HTML version deleted]]


From @b|@yeng@|@b@ @end|ng |rom gm@||@com  Fri Jan 29 15:27:22 2021
From: @b|@yeng@|@b@ @end|ng |rom gm@||@com (Ablaye Ngalaba)
Date: Fri, 29 Jan 2021 15:27:22 +0100
Subject: [R] need help calculating the indicator function
Message-ID: <CAOkWQv28E3io-hmSouEQmnEHE3HBP9c1ZFUYkzOHsGV4gcRVEQ@mail.gmail.com>

Hello,
please, I need to calculate the indicator function as I underlined in my
attached pdf file but I can't define a code in programming language that
deals with this case. Please help me with a code whether it's in python or
R can help me.



   Sincerely.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: code algo test.pdf
Type: application/pdf
Size: 145210 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210129/19b0dec7/attachment.pdf>

From bgunter@4567 @end|ng |rom gm@||@com  Fri Jan 29 23:29:11 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 29 Jan 2021 14:29:11 -0800
Subject: [R] need help calculating the indicator function
In-Reply-To: <CAOkWQv28E3io-hmSouEQmnEHE3HBP9c1ZFUYkzOHsGV4gcRVEQ@mail.gmail.com>
References: <CAOkWQv28E3io-hmSouEQmnEHE3HBP9c1ZFUYkzOHsGV4gcRVEQ@mail.gmail.com>
Message-ID: <CAGxFJbTLcqzDeaVH24LQFmAAEt5Ni_RHE3oyeoUbsyNZsMDrVQ@mail.gmail.com>

Is this a homework problem? The posting guide linked below explicitly says:

"*Basic statistics and classroom homework:* R-help is not intended for
these."



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 29, 2021 at 2:20 PM Ablaye Ngalaba <ablayengalaba at gmail.com>
wrote:

> Hello,
> please, I need to calculate the indicator function as I underlined in my
> attached pdf file but I can't define a code in programming language that
> deals with this case. Please help me with a code whether it's in python or
> R can help me.
>
>
>
>    Sincerely.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jan 29 23:51:47 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 29 Jan 2021 14:51:47 -0800
Subject: [R] need help calculating the indicator function
In-Reply-To: <CAOkWQv28E3io-hmSouEQmnEHE3HBP9c1ZFUYkzOHsGV4gcRVEQ@mail.gmail.com>
References: <CAOkWQv28E3io-hmSouEQmnEHE3HBP9c1ZFUYkzOHsGV4gcRVEQ@mail.gmail.com>
Message-ID: <1aa883bc-f609-d852-9356-12a374529c2c@comcast.net>

Perhaps (in R):


n_i <- cumsum( Y==l )


You should read further regarding R's logical class, and operators that 
work on it, and how it is coerced.

-- 

David

On 1/29/21 6:27 AM, Ablaye Ngalaba wrote:
> Hello,
> please, I need to calculate the indicator function as I underlined in my
> attached pdf file but I can't define a code in programming language that
> deals with this case. Please help me with a code whether it's in python or
> R can help me.
>
>
>
>     Sincerely.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Jan 30 04:11:32 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 30 Jan 2021 16:11:32 +1300
Subject: [R] arima/fixed
In-Reply-To: <DBBPR03MB705015D3199567874B4564158EB99@DBBPR03MB7050.eurprd03.prod.outlook.com>
References: <DBBPR03MB705015D3199567874B4564158EB99@DBBPR03MB7050.eurprd03.prod.outlook.com>
Message-ID: <20210130161132.47004808@rolf-Latitude-E7470>


On Fri, 29 Jan 2021 12:47:25 +0000
Nasia Petsa <petsa.athanasia at hotmail.gr> wrote:

> Dear all,
> 
> I have the following problem with determining the argument fixed in
> arima function. What is the length  of argument fixed for an
> ARIMA(1,0,0)(0,1,1) and what is the correct  order for the parameters

Hmm.  The help is indeed pretty opaque, isn't it?  I tried
the following:

set.seed(42)
x <- rnorm(300)
f1 <- arima(x,order=c(1,0,0),seasonal=list(order=c(0,1,1),period=6))
coef(f1) # Which gave:
>        ar1       sma1 
> -0.0169276 -0.9999999 

f2 <- arima(x,order=c(1,0,0),seasonal=list(order=c(0,1,1),period=6),
            fixed=c(-0.5,NA),transform.pars=FALSE)
coef(f2) # Which gave:
> ar1 sma1 
> -0.5 -1.0 

So this looks like it's doing the right thing .... ???

Printing f2 indicates that the standard error of "ar1" is 0, which
makes sense since it's fixed.

I hope this helps.  Perhaps someone who actually knows what they are
talking about will chime in.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jan 30 05:38:01 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 30 Jan 2021 04:38:01 +0000
Subject: [R] need help calculating the indicator function
In-Reply-To: <CAOkWQv28E3io-hmSouEQmnEHE3HBP9c1ZFUYkzOHsGV4gcRVEQ@mail.gmail.com>
References: <CAOkWQv28E3io-hmSouEQmnEHE3HBP9c1ZFUYkzOHsGV4gcRVEQ@mail.gmail.com>
Message-ID: <5166f5af-830f-8658-1a82-298e2bf83f3a@sapo.pt>

Hello,

Maybe this?

n_l <- function(Y, l, na.rm = FALSE) sum(Y == l, na.rm = na.rm)

set.seed(2020)
q <- 6
y <- sample(q, 10, TRUE)

l <- 4
n_l(y, l)
#[1] 3


Hope this helps,

Rui Barradas


?s 14:27 de 29/01/21, Ablaye Ngalaba escreveu:
> Hello,
> please, I need to calculate the indicator function as I underlined in my
> attached pdf file but I can't define a code in programming language that
> deals with this case. Please help me with a code whether it's in python or
> R can help me.
> 
> 
> 
>     Sincerely.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r-p@ck@ge@ @end|ng |rom r-project@org  Fri Jan 29 14:33:59 2021
From: r-p@ck@ge@ @end|ng |rom r-project@org (Protonmail via R-packages)
Date: Fri, 29 Jan 2021 13:33:59 +0000
Subject: [R] [R-pkgs] sensobol 1.0.0. (variance-based sensitivity analysis)
Message-ID: <14DF4068-DD33-406D-A06D-3A56E37911A1@pm.me>

sensobol: an R package to compute variance-based sensitivity indices

Sensobol 1.0.0 is already in CRAN, and a detailed vignette can be found in CRAN and in arXiv: https://arxiv.org/abs/2101.10103

It allows to rapidly compute, bootstrap and plot up to third-order Sobol'-based sensitivity indices using several state-of-the-art first and total-order estimators. Sobol' indices can be computed either for models that yield a scalar as a model output or for systems of differential equations. The package also provides a suit of benchmark tests functions and several options to obtain publication-ready figures of the model output uncertainty and sensitivity-related analysis.
	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Sat Jan 30 12:21:14 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sat, 30 Jan 2021 12:21:14 +0100
Subject: [R] arima/fixed
In-Reply-To: <20210130161132.47004808@rolf-Latitude-E7470>
References: <DBBPR03MB705015D3199567874B4564158EB99@DBBPR03MB7050.eurprd03.prod.outlook.com>
 <20210130161132.47004808@rolf-Latitude-E7470>
Message-ID: <24597.16682.487740.434293@stat.math.ethz.ch>

>>>>> Rolf Turner 
>>>>>     on Sat, 30 Jan 2021 16:11:32 +1300 writes:

    > On Fri, 29 Jan 2021 12:47:25 +0000
    > Nasia Petsa <petsa.athanasia at hotmail.gr> wrote:

    >> Dear all,
    >> 
    >> I have the following problem with determining the argument fixed in
    >> arima function. What is the length  of argument fixed for an
    >> ARIMA(1,0,0)(0,1,1) and what is the correct  order for the parameters

    > Hmm.  The help is indeed pretty opaque, isn't it?  

Can you propose improvements?

Here(*) is the source code of the help page

  http://svn.r-project.org/R/trunk/src/library/stats/man/arima.Rd

We (and future R users) would be glad for less opaque (and still
concise) wording, notably in simple enough English for the 90%
non-natively English speaking R users ..

Thank you in advance!
Martin


--
*) and really that *is* R's source code repos.
   All else are mirrors (efficient and convenient ones, I agree)


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jan 30 12:50:07 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 30 Jan 2021 11:50:07 +0000
Subject: [R] need help calculating the indicator function
In-Reply-To: <CAOkWQv06wPsO5dOMZ_w=XK2E3T=mSz3TvVS_hCsTnTAN5LC32Q@mail.gmail.com>
References: <CAOkWQv28E3io-hmSouEQmnEHE3HBP9c1ZFUYkzOHsGV4gcRVEQ@mail.gmail.com>
 <5166f5af-830f-8658-1a82-298e2bf83f3a@sapo.pt>
 <CAOkWQv37mA5LLRJNVQox1XF37y9FKe7X4QPWgL=AFeEt94+6zA@mail.gmail.com>
 <CAOkWQv06wPsO5dOMZ_w=XK2E3T=mSz3TvVS_hCsTnTAN5LC32Q@mail.gmail.com>
Message-ID: <11281ab2-c103-8247-1b30-e2c3050795c2@sapo.pt>

Hello,

Please cc the list, R-Help is threaded and your doubt and answers might 
be of interest to others.

With a vector Y, you want 0 in all Y != l and 1 in all Y == l?


n_l <- function(Y, l) as.integer(Y == l)


Hope this helps,

Rui Barradas

?s 11:26 de 30/01/21, Ablaye Ngalaba escreveu:
> Hello Rui,
> thank you for answering me.
> I compiled your code, it's true that it works but it still gives the 
> value "3". What I want is to find either 1 if Y==l or 0 in case y 
> differs from l.
> 
> 
> Good day
> 
> Le?sam. 30 janv. 2021 ??10:42, Ablaye Ngalaba <ablayengalaba at gmail.com 
> <mailto:ablayengalaba at gmail.com>> a ?crit?:
> 
>     Thanks.
> 
>     Le?sam. 30 janv. 2021 ??05:38, Rui Barradas <ruipbarradas at sapo.pt
>     <mailto:ruipbarradas at sapo.pt>> a ?crit?:
> 
>         Hello,
> 
>         Maybe this?
> 
>         n_l <- function(Y, l, na.rm = FALSE) sum(Y == l, na.rm = na.rm)
> 
>         set.seed(2020)
>         q <- 6
>         y <- sample(q, 10, TRUE)
> 
>         l <- 4
>         n_l(y, l)
>         #[1] 3
> 
> 
>         Hope this helps,
> 
>         Rui Barradas
> 
> 
>         ?s 14:27 de 29/01/21, Ablaye Ngalaba escreveu:
>          > Hello,
>          > please, I need to calculate the indicator function as I
>         underlined in my
>          > attached pdf file but I can't define a code in programming
>         language that
>          > deals with this case. Please help me with a code whether it's
>         in python or
>          > R can help me.
>          >
>          >
>          >
>          >? ? ?Sincerely.
>          >
>          >
>          > ______________________________________________
>          > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>          > https://stat.ethz.ch/mailman/listinfo/r-help
>          > PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>          > and provide commented, minimal, self-contained, reproducible
>         code.
>          >
>


From nz@h@@m @end|ng |rom gm@||@com  Sun Jan 31 05:26:21 2021
From: nz@h@@m @end|ng |rom gm@||@com (Shaami)
Date: Sun, 31 Jan 2021 09:26:21 +0500
Subject: [R] dependent nested for loops in R
Message-ID: <CAGR+MS5S=KTu13mn=ze_jMS2dhA790Q07CkRL8WYtEc6ZUXeKQ@mail.gmail.com>

Hi
I have very large dependent nested for loops that are quite expensive
computationally. It takes weeks and does not end to give me results. Could
anyone please guide how could I use apply function or any other suggestion
for such big and dependent loops in R? A sample code is as follows.

w = NULL
for(j in 1:1000)
{
  x = rnorm(2000)
  z = x[1]
  for(i in 2:2000)
  {
    z = x[i]+5*z[i-1]
    if(z>4 | z<1) {
      w[j]=i
      break
    } else {
      w[j] = 0
    }
  }
}


Thank you

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jan 31 06:01:30 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 30 Jan 2021 21:01:30 -0800
Subject: [R] dependent nested for loops in R
In-Reply-To: <CAGR+MS5S=KTu13mn=ze_jMS2dhA790Q07CkRL8WYtEc6ZUXeKQ@mail.gmail.com>
References: <CAGR+MS5S=KTu13mn=ze_jMS2dhA790Q07CkRL8WYtEc6ZUXeKQ@mail.gmail.com>
Message-ID: <faee43e7-8503-e0cc-dba1-adcf008cf1a2@comcast.net>


On 1/30/21 8:26 PM, Shaami wrote:
> Hi
> I have very large dependent nested for loops that are quite expensive
> computationally. It takes weeks and does not end to give me results. Could
> anyone please guide how could I use apply function or any other suggestion
> for such big and dependent loops in R? A sample code is as follows.
>
> w = NULL
> for(j in 1:1000)
> {
>    x = rnorm(2000)
>    z = x[1]
>    for(i in 2:2000)
>    {
>      z = x[i]+5*z[i-1]

I'm guessing you meant to type:

 ??????? z[i] <- x[i]+5*z[i-1]

>      if(z>4 | z<1) {

And more guesses (in the absence of any sort of problem description) 
that you really wanted:


  if(z[i]>4 | z[i]<1) {  ....


>        w[j]=i
>        break
>      } else {
>        w[j] = 0
>      }
>    }
> }


Are you sure you need a for-loop? Seems like you could have done this 
with a couple of vectorized operations. And the `break` looked entirely 
superfluous.



> Thank you
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nz@h@@m @end|ng |rom gm@||@com  Sun Jan 31 06:32:02 2021
From: nz@h@@m @end|ng |rom gm@||@com (Shaami)
Date: Sun, 31 Jan 2021 10:32:02 +0500
Subject: [R] dependent nested for loops in R
In-Reply-To: <faee43e7-8503-e0cc-dba1-adcf008cf1a2@comcast.net>
References: <CAGR+MS5S=KTu13mn=ze_jMS2dhA790Q07CkRL8WYtEc6ZUXeKQ@mail.gmail.com>
 <faee43e7-8503-e0cc-dba1-adcf008cf1a2@comcast.net>
Message-ID: <CAGR+MS7bo1+PpYhk+bG2qtmO5nYx4A8c0jtmVoDhdBREA+u3rQ@mail.gmail.com>

Hi
I have made the sample code again. Could you please guide how to use
vectorization for variables whose next value depends on the previous one?

w = NULL

for(j in 1:1000)

{

  z = NULL

  x = rnorm(2000)

  z[1] = x[1]

  for(i in 2:2000)

  {

    z[i] = x[i]+5*z[i-1]

    if(z[i]>4 | z[i]<1) {

      w[j]=i

    } else {

      w[j] = 0

    }

  }

}


On Sun, Jan 31, 2021 at 10:01 AM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 1/30/21 8:26 PM, Shaami wrote:
> > Hi
> > I have very large dependent nested for loops that are quite expensive
> > computationally. It takes weeks and does not end to give me results.
> Could
> > anyone please guide how could I use apply function or any other
> suggestion
> > for such big and dependent loops in R? A sample code is as follows.
> >
> > w = NULL
> > for(j in 1:1000)
> > {
> >    x = rnorm(2000)
> >    z = x[1]
> >    for(i in 2:2000)
> >    {
> >      z = x[i]+5*z[i-1]
>
> I'm guessing you meant to type:
>
>          z[i] <- x[i]+5*z[i-1]
>
> >      if(z>4 | z<1) {
>
> And more guesses (in the absence of any sort of problem description)
> that you really wanted:
>
>
>   if(z[i]>4 | z[i]<1) {  ....
>
>
> >        w[j]=i
> >        break
> >      } else {
> >        w[j] = 0
> >      }
> >    }
> > }
>
>
> Are you sure you need a for-loop? Seems like you could have done this
> with a couple of vectorized operations. And the `break` looked entirely
> superfluous.
>
>
>
> > Thank you
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @iex_rugu m@iii@g oii y@hoo@com  Sun Jan 31 19:35:28 2021
From: @iex_rugu m@iii@g oii y@hoo@com (@iex_rugu m@iii@g oii y@hoo@com)
Date: Sun, 31 Jan 2021 18:35:28 +0000 (UTC)
Subject: [R] Help with Using spTimer or spTDyn to estimate "GP" Model
References: <1609890832.804493.1612118128111.ref@mail.yahoo.com>
Message-ID: <1609890832.804493.1612118128111@mail.yahoo.com>

When I run the following scripts I get the following error and I do not understand the source. I believe N is specified as the number of observations by year in the time series variables.? The error is
#######################################
Output: GP models?
Error in spGP.Gibbs(formula = formula, data = data, time.data = time.data,? :?
? ?Error: Years, Months, and Days are misspecified,
?i.e., total number of observations in the data set should be equal to N
? : N = n * r * T?
? ?where, N = total number of observations in the data,
? ? ? ? ? n = total number of sites,
? ? ? ? ? r = total number of years,
? ? ? ? ? T = total number of days.?
## Check spT.time function.

The scrip is
######################
library(spTimer)
library(spTDyn)
library(tidyverse)
library(ggmap)


register_google(key=" your key ") # for use with ggmap
getOption("ggmap")


#Data to analyze is from plm package
#The data include US States Production, which is a panel of 48 observations from 1970 to 1986
#A data frame containing :
#state: the state
#year : the year
#region : the region
#pcap : public capital stock
#hwy :? highway and streets
#water : water and sewer facilities
#util : other public buildings and structures
#pc : private capital stock
#gsp : gross state product
#emp :labor input measured by the employment in non?agricultural payrolls
#unemp : state unemployment rateA panel of 48 observations from 1970 to 1986


data("Produc", package = "plm")
glimpse(Produc)


#Estimate Geolocation of states to account for spill over effects
states_df <- data.frame(as.character(unique(Produc$state)))
names(states_df)<- c("state")


state_geo_df <- mutate_geocode(states_df, state)

#Join the data

Product_geo <- full_join(state_geo_df, Produc)
glimpse(Product_geo)


#Create the time series variable
#number of state
ns <- length(unique(Product_geo$state))


#number of year
ny <- length(unique(Product_geo$year))
####################################################
# I want to do Spatio-Temporal Bayesian Modeling Using spTimer or?spTDyn
#defines the time series in the Spatio-temporal data.


ts_STD <- def.time(t.series=ns, segments=ny)


##################Estimate the model using spTDyn package
#Also note that the spT.Gibbs in spTimer gives the same error


GibbsDyn(gsp ~ pcap + hwy + water + util + pc ,?
? ? ? ?data=Product_geo, model="GP",?
? ? ? ? ?time.data=ts_STD,?
? ? ? ? ?coords=~lon + lat,
? ? ? ? ? nItr=5000, nBurn=1000, report=1, tol.dist=0.05,
? ? ? ? ? ? distance.method="geodetic:km", cov.fnc="exponential",?
? ? ? ? ? ? ?spatial.decay=decay(distribution="FIXED"),truncation.para=list(at=0,lambda=2))


#Also I will appreciate showing how to deal with unbalanced panel data
#Delete some of the rows
Product_geo$cond = with(Product_geo,? if_else(state=="ALABAMA" & year==1971, 0,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?if_else(state=="COLORADO" & year==1971 | year==1973 , 0,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?if_else(state=="TEXAS" & year==1971 | year==1973 | year==1985, 0, 1))))

#Create an unbalanced panel
Product_geo_unb <- Product_geo %>% filter(cond==1) %>% select(-cond)
glimpse(Product_geo_unb)


#How to use GibbsDyn or spT.Gibbs function to estimate the "GP" model for such unbalanced panel data?


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jan 31 21:34:45 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 31 Jan 2021 12:34:45 -0800
Subject: [R] Help with Using spTimer or spTDyn to estimate "GP" Model
In-Reply-To: <1609890832.804493.1612118128111@mail.yahoo.com>
References: <1609890832.804493.1612118128111.ref@mail.yahoo.com>
 <1609890832.804493.1612118128111@mail.yahoo.com>
Message-ID: <CAGxFJbTfKty5bisttMX7WpsK8eNQ7w-B4Vu4nO8trdP4S6hNbg@mail.gmail.com>

Please not per the posting guide linked below:

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.
If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

So do not be disappointed if you do not receive a (helpful) response here.
You could, but ... There are, after all, around 25,000 R packages out
there, and this list cannot possibly support them all.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 31, 2021 at 11:26 AM alex_rugu--- via R-help <
r-help at r-project.org> wrote:

> When I run the following scripts I get the following error and I do not
> understand the source. I believe N is specified as the number of
> observations by year in the time series variables.  The error is
> #######################################
> Output: GP models
> Error in spGP.Gibbs(formula = formula, data = data, time.data =
> time.data,  :
>    Error: Years, Months, and Days are misspecified,
>  i.e., total number of observations in the data set should be equal to N
>   : N = n * r * T
>    where, N = total number of observations in the data,
>           n = total number of sites,
>           r = total number of years,
>           T = total number of days.
> ## Check spT.time function.
>
> The scrip is
> ######################
> library(spTimer)
> library(spTDyn)
> library(tidyverse)
> library(ggmap)
>
>
> register_google(key=" your key ") # for use with ggmap
> getOption("ggmap")
>
>
> #Data to analyze is from plm package
> #The data include US States Production, which is a panel of 48
> observations from 1970 to 1986
> #A data frame containing :
> #state: the state
> #year : the year
> #region : the region
> #pcap : public capital stock
> #hwy :  highway and streets
> #water : water and sewer facilities
> #util : other public buildings and structures
> #pc : private capital stock
> #gsp : gross state product
> #emp :labor input measured by the employment in non?agricultural payrolls
> #unemp : state unemployment rateA panel of 48 observations from 1970 to
> 1986
>
>
> data("Produc", package = "plm")
> glimpse(Produc)
>
>
> #Estimate Geolocation of states to account for spill over effects
> states_df <- data.frame(as.character(unique(Produc$state)))
> names(states_df)<- c("state")
>
>
> state_geo_df <- mutate_geocode(states_df, state)
>
> #Join the data
>
> Product_geo <- full_join(state_geo_df, Produc)
> glimpse(Product_geo)
>
>
> #Create the time series variable
> #number of state
> ns <- length(unique(Product_geo$state))
>
>
> #number of year
> ny <- length(unique(Product_geo$year))
> ####################################################
> # I want to do Spatio-Temporal Bayesian Modeling Using spTimer or spTDyn
> #defines the time series in the Spatio-temporal data.
>
>
> ts_STD <- def.time(t.series=ns, segments=ny)
>
>
> ##################Estimate the model using spTDyn package
> #Also note that the spT.Gibbs in spTimer gives the same error
>
>
> GibbsDyn(gsp ~ pcap + hwy + water + util + pc ,
>        data=Product_geo, model="GP",
>          time.data=ts_STD,
>          coords=~lon + lat,
>           nItr=5000, nBurn=1000, report=1, tol.dist=0.05,
>             distance.method="geodetic:km", cov.fnc="exponential",
>
>  spatial.decay=decay(distribution="FIXED"),truncation.para=list(at=0,lambda=2))
>
>
> #Also I will appreciate showing how to deal with unbalanced panel data
> #Delete some of the rows
> Product_geo$cond = with(Product_geo,  if_else(state=="ALABAMA" &
> year==1971, 0,
>                                          if_else(state=="COLORADO" &
> year==1971 | year==1973 , 0,
>                                          if_else(state=="TEXAS" &
> year==1971 | year==1973 | year==1985, 0, 1))))
>
> #Create an unbalanced panel
> Product_geo_unb <- Product_geo %>% filter(cond==1) %>% select(-cond)
> glimpse(Product_geo_unb)
>
>
> #How to use GibbsDyn or spT.Gibbs function to estimate the "GP" model for
> such unbalanced panel data?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jan 31 21:37:22 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 31 Jan 2021 12:37:22 -0800
Subject: [R] Help with Using spTimer or spTDyn to estimate "GP" Model
In-Reply-To: <CAGxFJbTfKty5bisttMX7WpsK8eNQ7w-B4Vu4nO8trdP4S6hNbg@mail.gmail.com>
References: <1609890832.804493.1612118128111.ref@mail.yahoo.com>
 <1609890832.804493.1612118128111@mail.yahoo.com>
 <CAGxFJbTfKty5bisttMX7WpsK8eNQ7w-B4Vu4nO8trdP4S6hNbg@mail.gmail.com>
Message-ID: <CAGxFJbQZfcV5KY9kv=-2umYdUdSa7xUaGKr_Z1__XZrs+U2oMw@mail.gmail.com>

Also note that you should have a higher likelihood of getting a helpful
response on the r-sig-geo list rather than here.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 31, 2021 at 12:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Please not per the posting guide linked below:
>
> "For questions about functions in standard packages distributed with R
> (see the FAQ Add-on packages in R
> <https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>),
> ask questions on R-help.
> If the question relates to a *contributed package* , e.g., one downloaded
> from CRAN, try contacting the package maintainer first. You can also use
> find("functionname") and packageDescription("packagename") to find this
> information. *Only* send such questions to R-help or R-devel if you get
> no reply or need further assistance. This applies to both requests for help
> and to bug reports."
>
> So do not be disappointed if you do not receive a (helpful) response here.
> You could, but ... There are, after all, around 25,000 R packages out
> there, and this list cannot possibly support them all.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Jan 31, 2021 at 11:26 AM alex_rugu--- via R-help <
> r-help at r-project.org> wrote:
>
>> When I run the following scripts I get the following error and I do not
>> understand the source. I believe N is specified as the number of
>> observations by year in the time series variables.  The error is
>> #######################################
>> Output: GP models
>> Error in spGP.Gibbs(formula = formula, data = data, time.data =
>> time.data,  :
>>    Error: Years, Months, and Days are misspecified,
>>  i.e., total number of observations in the data set should be equal to N
>>   : N = n * r * T
>>    where, N = total number of observations in the data,
>>           n = total number of sites,
>>           r = total number of years,
>>           T = total number of days.
>> ## Check spT.time function.
>>
>> The scrip is
>> ######################
>> library(spTimer)
>> library(spTDyn)
>> library(tidyverse)
>> library(ggmap)
>>
>>
>> register_google(key=" your key ") # for use with ggmap
>> getOption("ggmap")
>>
>>
>> #Data to analyze is from plm package
>> #The data include US States Production, which is a panel of 48
>> observations from 1970 to 1986
>> #A data frame containing :
>> #state: the state
>> #year : the year
>> #region : the region
>> #pcap : public capital stock
>> #hwy :  highway and streets
>> #water : water and sewer facilities
>> #util : other public buildings and structures
>> #pc : private capital stock
>> #gsp : gross state product
>> #emp :labor input measured by the employment in non?agricultural payrolls
>> #unemp : state unemployment rateA panel of 48 observations from 1970 to
>> 1986
>>
>>
>> data("Produc", package = "plm")
>> glimpse(Produc)
>>
>>
>> #Estimate Geolocation of states to account for spill over effects
>> states_df <- data.frame(as.character(unique(Produc$state)))
>> names(states_df)<- c("state")
>>
>>
>> state_geo_df <- mutate_geocode(states_df, state)
>>
>> #Join the data
>>
>> Product_geo <- full_join(state_geo_df, Produc)
>> glimpse(Product_geo)
>>
>>
>> #Create the time series variable
>> #number of state
>> ns <- length(unique(Product_geo$state))
>>
>>
>> #number of year
>> ny <- length(unique(Product_geo$year))
>> ####################################################
>> # I want to do Spatio-Temporal Bayesian Modeling Using spTimer or spTDyn
>> #defines the time series in the Spatio-temporal data.
>>
>>
>> ts_STD <- def.time(t.series=ns, segments=ny)
>>
>>
>> ##################Estimate the model using spTDyn package
>> #Also note that the spT.Gibbs in spTimer gives the same error
>>
>>
>> GibbsDyn(gsp ~ pcap + hwy + water + util + pc ,
>>        data=Product_geo, model="GP",
>>          time.data=ts_STD,
>>          coords=~lon + lat,
>>           nItr=5000, nBurn=1000, report=1, tol.dist=0.05,
>>             distance.method="geodetic:km", cov.fnc="exponential",
>>
>>  spatial.decay=decay(distribution="FIXED"),truncation.para=list(at=0,lambda=2))
>>
>>
>> #Also I will appreciate showing how to deal with unbalanced panel data
>> #Delete some of the rows
>> Product_geo$cond = with(Product_geo,  if_else(state=="ALABAMA" &
>> year==1971, 0,
>>                                          if_else(state=="COLORADO" &
>> year==1971 | year==1973 , 0,
>>                                          if_else(state=="TEXAS" &
>> year==1971 | year==1973 | year==1985, 0, 1))))
>>
>> #Create an unbalanced panel
>> Product_geo_unb <- Product_geo %>% filter(cond==1) %>% select(-cond)
>> glimpse(Product_geo_unb)
>>
>>
>> #How to use GibbsDyn or spT.Gibbs function to estimate the "GP" model for
>> such unbalanced panel data?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From tr@xp|@yer @end|ng |rom gm@||@com  Sun Jan 31 21:57:04 2021
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Sun, 31 Jan 2021 21:57:04 +0100
Subject: [R] union of two sets are smaller than one set?
Message-ID: <CAGAA5bcf6OsP4E_jJBJZ9eBMLdssDJ8YXgFDpYwJSz8YyPMXcA@mail.gmail.com>

This is really puzzling me and when I try to make a small example
everything works like expected.

The problem:

I got these two large vectors of strings.

> str(s1)
 chr [1:766608] "0.dk" ...
> str(s2)
 chr [1:59387] "043.dk" "0606.dk" "0618.dk" "0888.dk" "0iq.dk" "0it.dk" ...

And I need to create the union-set of s1 and s2.
I expect the size of the union-set to be between 766608 and 766608+59387.
However it is 681193 which is less that number of elements in s1!

> length(base::union(s1, s2))
[1] 681193

Any hints?

Regards
Martin

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jan 31 22:11:44 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 31 Jan 2021 16:11:44 -0500
Subject: [R] union of two sets are smaller than one set?
In-Reply-To: <CAGAA5bcf6OsP4E_jJBJZ9eBMLdssDJ8YXgFDpYwJSz8YyPMXcA@mail.gmail.com>
References: <CAGAA5bcf6OsP4E_jJBJZ9eBMLdssDJ8YXgFDpYwJSz8YyPMXcA@mail.gmail.com>
Message-ID: <e3fd91bd-8871-7417-7fd4-918509330fdb@gmail.com>

On 31/01/2021 3:57 p.m., Martin M?ller Skarbiniks Pedersen wrote:
> This is really puzzling me and when I try to make a small example
> everything works like expected.
> 
> The problem:
> 
> I got these two large vectors of strings.
> 
>> str(s1)
>   chr [1:766608] "0.dk" ...
>> str(s2)
>   chr [1:59387] "043.dk" "0606.dk" "0618.dk" "0888.dk" "0iq.dk" "0it.dk" ...
> 
> And I need to create the union-set of s1 and s2.
> I expect the size of the union-set to be between 766608 and 766608+59387.
> However it is 681193 which is less that number of elements in s1!
> 
>> length(base::union(s1, s2))
> [1] 681193
> 
> Any hints?

I imagine unique(s1) is shorter than s1.  The union function is the same as

unique(c(s1, s2))

for your data.  (The only difference is if s1 or s2 is named:  the names 
are dropped.)

Duncan Murdoch


From e@ @end|ng |rom enr|co@chum@nn@net  Sun Jan 31 22:15:44 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Sun, 31 Jan 2021 22:15:44 +0100
Subject: [R] union of two sets are smaller than one set?
In-Reply-To: <CAGAA5bcf6OsP4E_jJBJZ9eBMLdssDJ8YXgFDpYwJSz8YyPMXcA@mail.gmail.com>
 ("Martin =?utf-8?Q?M=C3=B8ller?= Skarbiniks Pedersen"'s message of "Sun, 31
 Jan 2021 21:57:04 +0100")
References: <CAGAA5bcf6OsP4E_jJBJZ9eBMLdssDJ8YXgFDpYwJSz8YyPMXcA@mail.gmail.com>
Message-ID: <87wnvsu7sv.fsf@enricoschumann.net>

On Sun, 31 Jan 2021, Martin M?ller Skarbiniks Pedersen writes:

> This is really puzzling me and when I try to make a small example
> everything works like expected.
>
> The problem:
>
> I got these two large vectors of strings.
>
>> str(s1)
>  chr [1:766608] "0.dk" ...
>> str(s2)
>  chr [1:59387] "043.dk" "0606.dk" "0618.dk" "0888.dk" "0iq.dk" "0it.dk" ...
>
> And I need to create the union-set of s1 and s2.
> I expect the size of the union-set to be between 766608 and 766608+59387.
> However it is 681193 which is less that number of elements in s1!
>
>> length(base::union(s1, s2))
> [1] 681193
>
> Any hints?
>
> Regards
> Martin
>

Duplicates?

kind regards
    Enrico

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ccberry @end|ng |rom he@|th@uc@d@edu  Sun Jan 31 22:26:13 2021
From: ccberry @end|ng |rom he@|th@uc@d@edu (Berry, Charles)
Date: Sun, 31 Jan 2021 21:26:13 +0000
Subject: [R] dependent nested for loops in R
In-Reply-To: <CAGR+MS7bo1+PpYhk+bG2qtmO5nYx4A8c0jtmVoDhdBREA+u3rQ@mail.gmail.com>
References: <CAGR+MS5S=KTu13mn=ze_jMS2dhA790Q07CkRL8WYtEc6ZUXeKQ@mail.gmail.com>
 <faee43e7-8503-e0cc-dba1-adcf008cf1a2@comcast.net>
 <CAGR+MS7bo1+PpYhk+bG2qtmO5nYx4A8c0jtmVoDhdBREA+u3rQ@mail.gmail.com>
Message-ID: <4937A207-12C7-4877-85D9-1F6DCDDC50B8@health.ucsd.edu>



> On Jan 30, 2021, at 9:32 PM, Shaami <nzshaam at gmail.com> wrote:
> 
> Hi
> I have made the sample code again. Could you please guide how to use
> vectorization for variables whose next value depends on the previous one?
> 


Glad to help.

First, it could help you to trace your code.  I suspect that the results are not at all what you want and tracing would help you see that.

I suggest running this revision and printing out x, z, and w.

#+begin_src R
  w = NULL
  for(j in 1:2)
  {
    z = NULL
    x = rnorm(10)
    z[1] = x[1]
    for(i in 2:10)
    {
      z[i] = x[i]+5*z[i-1]
      if(z[i]>4 | z[i]<1) {
	w[j]=i
      } else {
	w[j] = 0
      }
    }
  }
#+end_src


You should be able to see that the value of w can easily be obtained outside of the `i' loop.

-- 

If inspecting those results did not make you go back and rethink your approach, try writing the expression for 

z[n] = x[n] + ... + k * x[1]

If you are not good with algebra write out each of z[1], z[2], z[3] and z[4] in terms of x[1:4] and then look at what you have.

Perhaps the value of `k' will surprise you.

In any case, if the code is truly what you intended, you only need x[1:25] to get z[n] to double precision for any n.  So, 

Also, you will hardly ever be able to compute the value of z[n] for n > 450. 

If these last two statements are puzzling, see https://en.wikipedia.org/wiki/Floating-point_arithmetic

HTH,
Chuck

> w = NULL
> 
> for(j in 1:1000)
> 
> {
> 
>  z = NULL
> 
>  x = rnorm(2000)
> 
>  z[1] = x[1]
> 
>  for(i in 2:2000)
> 
>  {
> 
>    z[i] = x[i]+5*z[i-1]
> 
>    if(z[i]>4 | z[i]<1) {
> 
>      w[j]=i
> 
>    } else {
> 
>      w[j] = 0
> 
>    }
> 
>  }
> 
> }
> 


From @v|gro@@ @end|ng |rom ver|zon@net  Sun Jan 31 22:51:41 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sun, 31 Jan 2021 16:51:41 -0500
Subject: [R] union of two sets are smaller than one set?
In-Reply-To: <CAGAA5bcf6OsP4E_jJBJZ9eBMLdssDJ8YXgFDpYwJSz8YyPMXcA@mail.gmail.com>
References: <CAGAA5bcf6OsP4E_jJBJZ9eBMLdssDJ8YXgFDpYwJSz8YyPMXcA@mail.gmail.com>
Message-ID: <083101d6f81b$42e270b0$c8a75210$@verizon.net>

Martin,

You did not say your two starting objects were already sets. You said they
were vectors of strings. It may well be that your strings included
duplicates. For example, If I read in lots of text with a blank line between
paragraphs, I would have lots of seemingly empty and identical parts. Just
converting that into a set would shrink it.

You have not said how you created or processed your initial two vectors. It
is also possible parts were sort of DELETED as in removing the string
pointed to by some entry but leaving a null pointer of sorts which would
leave the length of the vector longer than the useful contents.

Your strings seem to be what may be filenames. Are they unique, especially
if they are files in different folders/directories?

There are many ways to check, but using your method, try this:

length(base::union(s1, s1))

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Martin M?ller
Skarbiniks Pedersen
Sent: Sunday, January 31, 2021 3:57 PM
To: R mailing list <r-help at r-project.org>
Subject: [R] union of two sets are smaller than one set?

This is really puzzling me and when I try to make a small example everything
works like expected.

The problem:

I got these two large vectors of strings.

> str(s1)
 chr [1:766608] "0.dk" ...
> str(s2)
 chr [1:59387] "043.dk" "0606.dk" "0618.dk" "0888.dk" "0iq.dk" "0it.dk" ...

And I need to create the union-set of s1 and s2.
I expect the size of the union-set to be between 766608 and 766608+59387.
However it is 681193 which is less that number of elements in s1!

> length(base::union(s1, s2))
[1] 681193

Any hints?

Regards
Martin

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


