From hannah.hlx at gmail.com  Thu Jun  1 02:41:58 2017
From: hannah.hlx at gmail.com (li li)
Date: Wed, 31 May 2017 20:41:58 -0400
Subject: [R] Question on function "scatterplot3d"
Message-ID: <CAHLnndZ-TKNQdMaLUca-CYOUD-YKZKvYDvy==Ne8a9+aeZvpqA@mail.gmail.com>

Hi all,
  I have a question with regard to making plots using function
"scatterplot3d".
Please see the example below. It looks like, for y axis, the tickmark text
was cutoff.
The number "10" does not show up completely. I tried to work with par(mpg).
It does not
seem to work. Hope to get some advice here. Thanks much!
   Hanna




C <- runif(30)
B <- rep(1:3, each=10)
A <- rep(1:10,3)
scatterplot3d(B,A,C, type = "h", lwd = 1, pch = 16, color="red",  main =
"",
              grid=TRUE,  col.grid="lightgreen",
              xlab="x", ylab="y", zlab="z")

	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Thu Jun  1 03:17:50 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Thu, 1 Jun 2017 04:17:50 +0300
Subject: [R] Question on function "scatterplot3d"
In-Reply-To: <CAHLnndZ-TKNQdMaLUca-CYOUD-YKZKvYDvy==Ne8a9+aeZvpqA@mail.gmail.com>
References: <CAHLnndZ-TKNQdMaLUca-CYOUD-YKZKvYDvy==Ne8a9+aeZvpqA@mail.gmail.com>
Message-ID: <7945E490-A6BC-48A2-964B-DEA0F7C30431@gmail.com>


> On 1 Jun 2017, at 03:41, li li <hannah.hlx at gmail.com> wrote:
> 
> Hi all,
>  I have a question with regard to making plots using function
> "scatterplot3d".
> Please see the example below. It looks like, for y axis, the tickmark text
> was cutoff.
> The number "10" does not show up completely. I tried to work with par(mpg).
> It does not
> seem to work. Hope to get some advice here. Thanks much!
>   Hanna
> 
> C <- runif(30)
> B <- rep(1:3, each=10)
> A <- rep(1:10,3)
> scatterplot3d(B,A,C, type = "h", lwd = 1, pch = 16, color="red",  main =
> "",
>              grid=TRUE,  col.grid="lightgreen",
>              xlab="x", ylab="y", zlab="z?)

Everything seems ok to me. Try to reset/clear all plots in your plotting window and try only to run the code above. Perhaps You changed par settings before in some point?


From anil.dabral at live.com  Thu Jun  1 03:54:51 2017
From: anil.dabral at live.com (Anil Dabral)
Date: Thu, 1 Jun 2017 01:54:51 +0000
Subject: [R] installed.packages() does not work properly
Message-ID: <PN1PR01MB0733E92BC069BEF2403240D59FF60@PN1PR01MB0733.INDPRD01.PROD.OUTLOOK.COM>

Hi,

I tried executing the following statement multiple times on R 3.4 and it worked only the first time. In older versions of R it seems to have worked. Am I doing anything wrong?


In R 3.4 (works only the first time)

tmp <- installed.packages()  #this works

tmp <- installed.packages() ## See error below


Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
  missing value where TRUE/FALSE needed



in R 3.3.3 works well when executed multiple times.

tmp <- installed.packages() #this works

tmp <- installed.packages() #this works

tmp <- installed.packages() #this works


Thanks and Regards,

Anil

Sent from Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From yuemile0902 at yahoo.com  Thu Jun  1 04:48:28 2017
From: yuemile0902 at yahoo.com (carrie wang)
Date: Thu, 1 Jun 2017 02:48:28 +0000 (UTC)
Subject: [R] Post for R
References: <170780372.145082.1496285308297.ref@mail.yahoo.com>
Message-ID: <170780372.145082.1496285308297@mail.yahoo.com>


Hello,?
I want to split the dataframe into 1000 groups based on two column values(max value and second max value). First, I made two lists L1 and L2. ?L1 is the list divided into 100 groups based on the range of max value and L2 is divided into 10 groups based on the second max values. Now I want to do the combinations based on L1 and L2. I want to do a for loop for L1 and for each element in L1, I split it into 10 groups based on L2. I tried to write the code, but it does not work.

L1<-split(df,cut(df$max,seq(0,1,by=0.01)))L2<-split(df,cut(df$submax,seq(0,0.2,by=0.02)))
Z<-list()G<-list()for (i in length(L1)){? Z=data.frame(L1[i])? G <- split(Z$submax,"0.02")? print(G)??}
Thanks so much!Carrie
	[[alternative HTML version deleted]]


From nell.redu at hotmail.fr  Thu Jun  1 06:49:42 2017
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Thu, 1 Jun 2017 04:49:42 +0000
Subject: [R] Latin Hypercube Sampling when parameters are defined
 according to specific probability distributions
In-Reply-To: <CAPtunJae1UcgrsOyS8+98BHT0E5ysnbmKumWj0zX8jOts+TsAg@mail.gmail.com>
References: <CAPtunJZJ0HpZGGaNjpfbHL_bMxHeACJ21kzpP2Zv1+qtcnTMhg@mail.gmail.com>
 <CY1PR05MB2730F1E421CF600D3A9890E799F00@CY1PR05MB2730.namprd05.prod.outlook.com>,
 <CAPtunJae1UcgrsOyS8+98BHT0E5ysnbmKumWj0zX8jOts+TsAg@mail.gmail.com>
Message-ID: <CY1PR05MB27308D07F399184179D83EB499F60@CY1PR05MB2730.namprd05.prod.outlook.com>

Thank you very much Rob for your answer. I have some difficulties to understand how to apply my agent-based model to each parameter combination generated by the LHS, in particular when parameters are defined by probability distributions. Indeed, I have multiple parameters in my model: parameters which are defined by a single value (like ?temperature", "pressure?) and parameters which are defined by probability distributions (like ?dispersal distance?). It?s correct for me to treat distance as a class. When all parameters are defined by a single value, I need first to create a data frame in which each column represents a different parameter, and each row represents a different combination of parameter values. Then, I apply my model to each row of the data frame. But, it?s not clear for me how to do this when parameters are defined from probability distributions? In particular, how can I use your code to apply my model to each of the 50 rows of the data frame ?tabLHS?? Given that one row corresponds to one model simulation, I should have a value generated by the LHS for all distance classes at the first line of the data frame.



library(pse)
q <- list("qexp", "qunif", "qunif")
q.arg <- list(list(rate=exponential_rate), list(min=0, max=1),
list(min=0, max=1))
uncoupledLHS <- LHS(model=model_function, input_parameters, N, q, q.arg)
hist(uncoupledLHS$data$dispersal_distance, breaks=10)

tabLHS <- get.data(uncoupledLHS)



Sorry, it?s the first time that I perform a sensitivity analysis using the LHS.


Thank you very much for your time.

Have a nice day

Nell


________________________________
De : Rob C <bertcarnell at gmail.com>
Envoy? : mardi 30 mai 2017 16:26:08
? : Nelly Reduan
Cc : r-help at r-project.org
Objet : Re: [R] Latin Hypercube Sampling when parameters are defined according to specific probability distributions

Nell,

I still might not be interpreting your question correctly, but I will try.

When you say that the sum of the probabilities of all distance classes
must equal one, I am going to treat distance as a class, instead of as a
continuous variable.

distance_class_probabilities <- c(9, 11, 10, 8.9, 8, 7, 6, 5.8, 5.1,
4, 3.9, 3.7, 3.4, 3.1, 2, 1.9, 1.6, 1.4, 1, 0.9, 0.8, 0.7, 0.4, 0.3,
0.1)/100
sum(distance_class_probabilities)
distance_classes <- factor(paste0("d", 1:25), ordered = TRUE,
levels=paste0("d", 1:25))
input_parameters <- c("dispersal_distance", "temperature", "pressure")
N <- 1000

plot(1:25, distance_class_probabilities, type="h", lwd=5)

set.seed(1)
require(lhs)
X <- randomLHS(N, length(input_parameters))
dimnames(X) <- list(NULL, input_parameters)
Y <- X
Y[,"dispersal_distance"] <-
approx(x=cumsum(distance_class_probabilities), y=1:25,
xout=X[,"dispersal_distance"], method="constant", yleft=0)$y + 1

hist(Y[,"dispersal_distance"], breaks=c(seq(0.5, 25.5, by=1)))
plot(table(distance_classes[Y[,"dispersal_distance"]]))


Is it still a Latin hypercube?

This is a more difficult question.  In some ways, the sample is still a Latin
hypercube since it was drawn that way.  But once the sample has been discretized
into the distance classes, then it loses the latin property of having only one
sample per "row".  It might be close enough for your purposes though.

Rob



On Tue, May 30, 2017 at 10:59 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> Thanks a lot Rob for your answer. I need to add a condition for the
> parameter ?dispersal distance?. The sum of the probabilities of all distance
> classes must be equal to 1:
>
> y <- c(9, 11, 10, 8.9, 8, 7, 6, 5.8, 5.1, 4, 3.9, 3.7, 3.4, 3.1, 2, 1.9,
> 1.6, 1.4, 1, 0.9, 0.8, 0.7, 0.4, 0.3, 0.1)
>
> x <- seq(1, 25, by = 1)
>
> barplot(y/100, names.arg=x, ylab="Probability", xlab="Distance (km)")
>
>
>
> With this condition, is it possible to perform a LHS?
>
> Thanks a lot for your time.
>
> Nell
>
>
> ________________________________
> De : R-help <r-help-bounces at r-project.org> de la part de Rob C
> <bertcarnell at gmail.com>
> Envoy? : samedi 27 mai 2017 13:32:23
> ? : r-help at r-project.org
> Objet : Re: [R] Latin Hypercube Sampling when parameters are defined
> according to specific probability distributions
>
>>May 26, 2017; 11:41am  Nelly Reduan Latin Hypercube Sampling when
>> parameters are >defined according to specific probability distributions
>>Hello,
>> I would like to perform a sensitivity analysis using a Latin Hypercube
>> Sampling (LHS).
>>Among the input parameters in the model, I have a parameter dispersal
>> distance which is defined according to an exponential probability
>> distribution.
>
>>In the model, the user thus sets a default probability value for each
>> distance class.
>
>>For example, for distances ([0  2]; ]2  4]; ]4  6]; ]6  8]; ]8  10];; ]48
>> 50],
>
>>respective probabilities are 0.055; 0.090; 0.065; 0.035; 0.045;; 0.005.
>
>  >Here is the code to represent an exponential probability
> distribution for the parameter dispersal distance:
>
>>set.seed(0)
>>foo <- rexp(100, rate = 1/10)
>>hist(foo, prob=TRUE, breaks=20, ylim=c(0,0.1), xlab ="Distance (km)")
>>lines(dexp(seq(1, 100, by = 1), rate = 1/mean(foo)),col="red")
>>1/mean(foo)
>
>>When a parameter is defined according to a specific probability
>> distribution, how can I perform a LHS ?
>>For example, should I sample N values from a uniform distribution for each
>> distance class (i.e., [0 ? 2]; ]2 ? 4]; ]4 ? 6]; ]6 ? 8]; ]8 ? 10];??; ]48 ?
>> 50])
>>or sample N values from exponential distributions with different rates ?
>
>>Here is the code used to perform a LHS when the parameter ?dispersal
>> distance? is defined by one default value in the model:
>
>>library(pse)
>>factors <- c("distance")
>>q <- c("qexp")
>>q.arg <- list( list(rate=1/30) )
>>uncoupledLHS <- LHS(model=NULL, factors, 50, q, q.arg)
>>head(uncoupledLHS)
>
>>Thanks a lot for your time.
>>Have a nice day
>>Nell
>
> Nell,
>
> I would like to suggest a slightly different method for generating the
> sample using the lhs library,  then I will try using the pse library.
> Generally when you have a package specific
> question, you should try to contact the package maintainer first.
>
> set.seed(1)
> # I don't think your model has only one parameter, so I will include
> multiple
> input_parameters <- c("dispersal_distance", "temperature", "pressure")
> N <- 50
> exponential_rate <- 1/30
>
> library(lhs)
> X <- randomLHS(N, length(input_parameters))
> dimnames(X) <- list(NULL, input_parameters)
> # X is now a uniformly distributed Latin hypercube
> head(X)
> hist(X[,1], breaks=5)
> hist(X[,2], breaks=5)
> hist(X[,3], breaks=5)
> # now, transform the dispersal_distance paramter to an exponential sample
> Y <- X
> Y[,"dispersal_distance"] <- qexp(X[,"dispersal_distance"],
> rate=exponential_rate)
> hist(Y[,1], breaks=10)
> # you can transform the other marginals as required and then assess
> function sensitivity
> model_function <- function(z) z[1]*z[2] + z[3]
> apply(Y, 1, model_function)
>
> # now, trying to use pse
> library(pse)
> q <- list("qexp", "qunif", "qunif")
> q.arg <- list(list(rate=exponential_rate), list(min=0, max=1),
> list(min=0, max=1))
> uncoupledLHS <- LHS(model=model_function, input_parameters, N, q, q.arg)
> hist(uncoupledLHS$data$dispersal_distance, breaks=10)
>
> Rob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Jun  1 07:15:40 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 1 Jun 2017 17:15:40 +1200
Subject: [R] [FORGED] Re:  Question on function "scatterplot3d"
In-Reply-To: <7945E490-A6BC-48A2-964B-DEA0F7C30431@gmail.com>
References: <CAHLnndZ-TKNQdMaLUca-CYOUD-YKZKvYDvy==Ne8a9+aeZvpqA@mail.gmail.com>
 <7945E490-A6BC-48A2-964B-DEA0F7C30431@gmail.com>
Message-ID: <c4d356d5-3761-29c0-91c0-ea86339c02c2@auckland.ac.nz>

On 01/06/17 13:17, Ismail SEZEN wrote:
> 
>> On 1 Jun 2017, at 03:41, li li <hannah.hlx at gmail.com> wrote:
>>
>> Hi all,
>>   I have a question with regard to making plots using function
>> "scatterplot3d".
>> Please see the example below. It looks like, for y axis, the tickmark text
>> was cutoff.
>> The number "10" does not show up completely. I tried to work with par(mpg).
>> It does not
>> seem to work. Hope to get some advice here. Thanks much!
>>    Hanna
>>
>> C <- runif(30)
>> B <- rep(1:3, each=10)
>> A <- rep(1:10,3)
>> scatterplot3d(B,A,C, type = "h", lwd = 1, pch = 16, color="red",  main =
>> "",
>>               grid=TRUE,  col.grid="lightgreen",
>>               xlab="x", ylab="y", zlab="z?)
> 
> Everything seems ok to me. Try to reset/clear all plots in your plotting window and try only to run the code above. Perhaps You changed par settings before in some point?


I tried the code given above, and after I replaced the <expletive 
deleted> incorrect double quote mark (after the final "z"), it ran and 
looked OK *except* for the positioning of the "y" axis label, which is 
at the "far end" of the y-axis rather than being at the "centre" of the 
y-axis.  (See attached.)

Is this a bug?

cheers,

Rolf Turner

P.S. I have also attached the code in the file "scatScript.txt", for 
convenience.

P^2. S.:

 > sessionInfo()
R Under development (unstable) (2017-04-21 r72585)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.2 LTS

Matrix products: default
BLAS: /usr/local/lib/R/lib/libRblas.so
LAPACK: /usr/local/lib/R/lib/libRlapack.so

locale:
  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] scatterplot3d_0.3-40 misc_0.0-16

loaded via a namespace (and not attached):
  [1] compiler_3.5.0       deldir_0.1-15        Matrix_1.2-8
  [4] spatstat.utils_1.4-1 tools_3.5.0          mgcv_1.8-17
  [7] abind_1.4-5          spatstat_1.50-0      rpart_4.1-11
[10] nlme_3.1-131         grid_3.5.0           polyclip_1.6-1
[13] lattice_0.20-35      goftest_1.1-1        tensor_1.5

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
-------------- next part --------------
A non-text attachment was scrubbed...
Name: scat.pdf
Type: application/pdf
Size: 5476 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170601/9701dd1d/attachment.pdf>
-------------- next part --------------
library(scatterplot3d)
set.seed(42)
C <- runif(30)
B <- rep(1:3, each=10)
A <- rep(1:10,3)
scatterplot3d(B,A,C, type = "h", lwd = 1, pch = 16, color="red",
              main = "", grid=TRUE,  col.grid="lightgreen",
              xlab="x", ylab="y", zlab="z")


From hasan.diwan at gmail.com  Thu Jun  1 08:04:01 2017
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Wed, 31 May 2017 23:04:01 -0700
Subject: [R] Post for R
In-Reply-To: <170780372.145082.1496285308297@mail.yahoo.com>
References: <170780372.145082.1496285308297.ref@mail.yahoo.com>
 <170780372.145082.1496285308297@mail.yahoo.com>
Message-ID: <CAP+bYWBO=jjmXjBSusnfb+ZtqLuQywXaz737bqA07Zm_Sz3KUQ@mail.gmail.com>

Carrie,
I would suggest a few things before posting your code here:
- Put a dput(df)
- Format it properly, as it stands it won't compile, because you're missing
newlines/semicolons between, e.g. Z <- list()*; *G <- list(); for (i in
length(L1)){  Z=data.frame(L1[i])*;* G <- split(Z$submax,"0.02")*;*
 print(G)  }
-- H

On 31 May 2017 at 19:48, carrie wang via R-help <r-help at r-project.org>
wrote:

>
> Hello,
> I want to split the dataframe into 1000 groups based on two column
> values(max value and second max value). First, I made two lists L1 and L2.
> L1 is the list divided into 100 groups based on the range of max value and
> L2 is divided into 10 groups based on the second max values. Now I want to
> do the combinations based on L1 and L2. I want to do a for loop for L1 and
> for each element in L1, I split it into 10 groups based on L2. I tried to
> write the code, but it does not work.
>
> L1<-split(df,cut(df$max,seq(0,1,by=0.01)))L2<-split(df,cut(d
> f$submax,seq(0,0.2,by=0.02)))
> Z<-list()G<-list()for (i in length(L1)){  Z=data.frame(L1[i])  G <-
> split(Z$submax,"0.02")  print(G)  }
> Thanks so much!Carrie
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=
get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using http://bit.ly/
hd1ScheduleRequest.
Si vous voudrais faire connnaisance, allez a http://bit.ly/
hd1ScheduleRequest.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Jun  1 09:52:53 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 1 Jun 2017 17:52:53 +1000
Subject: [R] Post for R
In-Reply-To: <170780372.145082.1496285308297@mail.yahoo.com>
References: <170780372.145082.1496285308297.ref@mail.yahoo.com>
 <170780372.145082.1496285308297@mail.yahoo.com>
Message-ID: <CA+8X3fUN1qFDA=8EtTx6qD_HiK_+kiyKXp86nD-fsCeWN5nNbw@mail.gmail.com>

Hi Carrie,
You may have a problem with this if some subsets are empty:

L3<-lapply(split(df,cut(df$max,seq(0,1,by=0.01))),
 split,cut(df$submax,seq(0,0.2,by=0.02)))

Jim

On Thu, Jun 1, 2017 at 12:48 PM, carrie wang via R-help
<r-help at r-project.org> wrote:
>
> Hello,
> I want to split the dataframe into 1000 groups based on two column values(max value and second max value). First, I made two lists L1 and L2.  L1 is the list divided into 100 groups based on the range of max value and L2 is divided into 10 groups based on the second max values. Now I want to do the combinations based on L1 and L2. I want to do a for loop for L1 and for each element in L1, I split it into 10 groups based on L2. I tried to write the code, but it does not work.
>
> L1<-split(df,cut(df$max,seq(0,1,by=0.01)))L2<-split(df,cut(df$submax,seq(0,0.2,by=0.02)))
> Z<-list()G<-list()for (i in length(L1)){  Z=data.frame(L1[i])  G <- split(Z$submax,"0.02")  print(G)  }
> Thanks so much!Carrie
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Thu Jun  1 09:54:13 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 1 Jun 2017 09:54:13 +0200
Subject: [R] [FORGED] Re: Question on function "scatterplot3d"
In-Reply-To: <c4d356d5-3761-29c0-91c0-ea86339c02c2@auckland.ac.nz>
References: <CAHLnndZ-TKNQdMaLUca-CYOUD-YKZKvYDvy==Ne8a9+aeZvpqA@mail.gmail.com>
 <7945E490-A6BC-48A2-964B-DEA0F7C30431@gmail.com>
 <c4d356d5-3761-29c0-91c0-ea86339c02c2@auckland.ac.nz>
Message-ID: <e7be3632-32dc-85e0-63b4-4e2d0b8adb68@statistik.tu-dortmund.de>

A design flaw, whether the labels are cut depends somewhat on the sizce 
of the device, hence there is the argument

y.margin.add	

add additional space between tick mark labels and axis label of the y axis

for working around that limittation that can be set to some positive 
value....

Best,
Uwe Ligges


On 01.06.2017 07:15, Rolf Turner wrote:
> On 01/06/17 13:17, Ismail SEZEN wrote:
>>
>>> On 1 Jun 2017, at 03:41, li li <hannah.hlx at gmail.com> wrote:
>>>
>>> Hi all,
>>>   I have a question with regard to making plots using function
>>> "scatterplot3d".
>>> Please see the example below. It looks like, for y axis, the tickmark 
>>> text
>>> was cutoff.
>>> The number "10" does not show up completely. I tried to work with 
>>> par(mpg).
>>> It does not
>>> seem to work. Hope to get some advice here. Thanks much!
>>>    Hanna
>>>
>>> C <- runif(30)
>>> B <- rep(1:3, each=10)
>>> A <- rep(1:10,3)
>>> scatterplot3d(B,A,C, type = "h", lwd = 1, pch = 16, color="red",  main =
>>> "",
>>>               grid=TRUE,  col.grid="lightgreen",
>>>               xlab="x", ylab="y", zlab="z?)
>>
>> Everything seems ok to me. Try to reset/clear all plots in your 
>> plotting window and try only to run the code above. Perhaps You 
>> changed par settings before in some point?
> 
> 
> I tried the code given above, and after I replaced the <expletive 
> deleted> incorrect double quote mark (after the final "z"), it ran and 
> looked OK *except* for the positioning of the "y" axis label, which is 
> at the "far end" of the y-axis rather than being at the "centre" of the 
> y-axis.  (See attached.)
> 
> Is this a bug?
> 
> cheers,
> 
> Rolf Turner
> 
> P.S. I have also attached the code in the file "scatScript.txt", for 
> convenience.
> 
> P^2. S.:
> 
>  > sessionInfo()
> R Under development (unstable) (2017-04-21 r72585)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.2 LTS
> 
> Matrix products: default
> BLAS: /usr/local/lib/R/lib/libRblas.so
> LAPACK: /usr/local/lib/R/lib/libRlapack.so
> 
> locale:
>   [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
>   [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
>   [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] scatterplot3d_0.3-40 misc_0.0-16
> 
> loaded via a namespace (and not attached):
>   [1] compiler_3.5.0       deldir_0.1-15        Matrix_1.2-8
>   [4] spatstat.utils_1.4-1 tools_3.5.0          mgcv_1.8-17
>   [7] abind_1.4-5          spatstat_1.50-0      rpart_4.1-11
> [10] nlme_3.1-131         grid_3.5.0           polyclip_1.6-1
> [13] lattice_0.20-35      goftest_1.1-1        tensor_1.5
> 
> 
> scatScript.txt
> 
> 
> library(scatterplot3d)
> set.seed(42)
> C <- runif(30)
> B <- rep(1:3, each=10)
> A <- rep(1:10,3)
> scatterplot3d(B,A,C, type = "h", lwd = 1, pch = 16, color="red",
>                main = "", grid=TRUE,  col.grid="lightgreen",
>                xlab="x", ylab="y", zlab="z")
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Thu Jun  1 09:54:49 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 1 Jun 2017 09:54:49 +0200
Subject: [R] installed.packages() does not work properly
In-Reply-To: <PN1PR01MB0733E92BC069BEF2403240D59FF60@PN1PR01MB0733.INDPRD01.PROD.OUTLOOK.COM>
References: <PN1PR01MB0733E92BC069BEF2403240D59FF60@PN1PR01MB0733.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <d850a32a-b886-6082-6258-a9c1a281b032@statistik.tu-dortmund.de>

Try R-3.4.0 patched.

Best,
Uwe Ligges



On 01.06.2017 03:54, Anil Dabral wrote:
> Hi,
> 
> I tried executing the following statement multiple times on R 3.4 and it worked only the first time. In older versions of R it seems to have worked. Am I doing anything wrong?
> 
> 
> In R 3.4 (works only the first time)
> 
> tmp <- installed.packages()  #this works
> 
> tmp <- installed.packages() ## See error below
> 
> 
> Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
>    missing value where TRUE/FALSE needed
> 
> 
> 
> in R 3.3.3 works well when executed multiple times.
> 
> tmp <- installed.packages() #this works
> 
> tmp <- installed.packages() #this works
> 
> tmp <- installed.packages() #this works
> 
> 
> Thanks and Regards,
> 
> Anil
> 
> Sent from Outlook<http://aka.ms/weboutlook>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.turner at auckland.ac.nz  Thu Jun  1 10:03:18 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 1 Jun 2017 20:03:18 +1200
Subject: [R] [FORGED] Re: Question on function "scatterplot3d"
In-Reply-To: <e7be3632-32dc-85e0-63b4-4e2d0b8adb68@statistik.tu-dortmund.de>
References: <CAHLnndZ-TKNQdMaLUca-CYOUD-YKZKvYDvy==Ne8a9+aeZvpqA@mail.gmail.com>
 <7945E490-A6BC-48A2-964B-DEA0F7C30431@gmail.com>
 <c4d356d5-3761-29c0-91c0-ea86339c02c2@auckland.ac.nz>
 <e7be3632-32dc-85e0-63b4-4e2d0b8adb68@statistik.tu-dortmund.de>
Message-ID: <948df1a1-57c7-6dad-4475-b2d99e5dd527@auckland.ac.nz>

On 01/06/17 19:54, Uwe Ligges wrote:
> A design flaw, whether the labels are cut depends somewhat on the sizce 
> of the device, hence there is the argument
> 
> y.margin.add
> 
> add additional space between tick mark labels and axis label of the y axis
> 
> for working around that limittation that can be set to some positive 
> value....


This seems to be addressing Hannah's (li li's) original enquiry, not my 
follow-up in which I worried about the position, along the y-axis, of 
the y-axis label.

Or am I misunderstanding/missing something?

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From msuzen at gmail.com  Thu Jun  1 11:29:44 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Thu, 1 Jun 2017 11:29:44 +0200
Subject: [R] (Somewhat?) Off topic: Containerization software
In-Reply-To: <CAGxFJbRr3B8F7B0Gs6VcRpO_EA_8h91SV96SJ+2jEHZ2CEje3w@mail.gmail.com>
References: <CAGxFJbRr3B8F7B0Gs6VcRpO_EA_8h91SV96SJ+2jEHZ2CEje3w@mail.gmail.com>
Message-ID: <CAPtbhHwHscywtG1XF5JMECWTA5p+wJLzQU08CtHi2x5oU4Km_g@mail.gmail.com>

This is a nice summary addressing the same with R:
https://arxiv.org/pdf/1410.0846.pdf

On 30 May 2017 at 17:43, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Folks:
>
> This is **off topic**, but I thought it might be informative to this
> community. Consequently: please **no on list public comments or
> discussion**. Feel free to respond to me privately, if you like; but I
> have neither knowledge nor opinions, so why bother? This is just FYI.
> My apology if it is deemed inappropriate.
>
> http://www.nature.com/news/software-simplified-1.22059
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From calum.polwart at nhs.net  Thu Jun  1 12:55:33 2017
From: calum.polwart at nhs.net (POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST))
Date: Thu, 1 Jun 2017 10:55:33 +0000
Subject: [R] odfWeave - A loop of the "same" data
Message-ID: <835a481d90af48278b637598af299650@NH-HEPEX141.AD1.NHS.NET>

Before I go and do this another way - can I check if anyone has a way of looping through data in odfWeave (or possibly sweave) to do a repeating analysis on subsets of data?

For simplicity lets use mtcars dataset in R to explain.  Dataset looks like this:

> mtcars
               mpg cyl disp  hp drat   wt ...
Mazda RX4     21.0   6  160 110 3.90 2.62 ...
Mazda RX4 Wag 21.0   6  160 110 3.90 2.88 ...
Datsun 710    22.8   4  108  93 3.85 2.32 ...
               ............

Say I wanted to have a 'catalogue' style report from mtcars, where on each page I would perhaps have the Rowname as a heading and then plot a graph of mpg highlighting that specific car

Then add a page break and *do the same for the next car*.  I can manually do this of course, but it is effectively a loop something like this:

for (n in length(mtcars$mpg)) {
barplot (mtcars$mpg, col=c(rep(1,n-1),2,rep(1,length(mtcars$mpg)-n)))
}

There is a odfWeave page break function so I can do that sort of thing (I think).  But I don't think I can output more than one image can I?  In reality I will want several images and a table per "catalogue" page.

At the moment I think I need to create a master odt document, and create individual catalogue pages.  And merge them into one document - but that feels clunky (unless I can script the merge!)

Anyone got a better way?




********************************************************************************************************************

This message may contain confidential information. If yo...{{dropped:21}}


From jdnewmil at dcn.davis.ca.us  Thu Jun  1 15:28:25 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 01 Jun 2017 06:28:25 -0700
Subject: [R] odfWeave - A loop of the "same" data
In-Reply-To: <835a481d90af48278b637598af299650@NH-HEPEX141.AD1.NHS.NET>
References: <835a481d90af48278b637598af299650@NH-HEPEX141.AD1.NHS.NET>
Message-ID: <22E52D9E-CC62-426C-9091-102A57A23ABF@dcn.davis.ca.us>

I do this regularly with knitr [1]. I have never used odfWeave, but would imagine that similar principles apply. 

If you make a child document that assumes that the desired data are stored in one or more objects, then you can use a for loop in the master document that repeatedly extracts the desired subsets and puts them into the objects the child document expects them to be in, parses the child document, and then "cat"s the parsed results into the master document output.

[1] https://yihui.name/knitr/demo/child/
-- 
Sent from my phone. Please excuse my brevity.

On June 1, 2017 3:55:33 AM PDT, "POLWART,  Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST) via R-help" <r-help at r-project.org> wrote:
>Before I go and do this another way - can I check if anyone has a way
>of looping through data in odfWeave (or possibly sweave) to do a
>repeating analysis on subsets of data?
>
>For simplicity lets use mtcars dataset in R to explain.  Dataset looks
>like this:
>
>> mtcars
>               mpg cyl disp  hp drat   wt ...
>Mazda RX4     21.0   6  160 110 3.90 2.62 ...
>Mazda RX4 Wag 21.0   6  160 110 3.90 2.88 ...
>Datsun 710    22.8   4  108  93 3.85 2.32 ...
>               ............
>
>Say I wanted to have a 'catalogue' style report from mtcars, where on
>each page I would perhaps have the Rowname as a heading and then plot a
>graph of mpg highlighting that specific car
>
>Then add a page break and *do the same for the next car*.  I can
>manually do this of course, but it is effectively a loop something like
>this:
>
>for (n in length(mtcars$mpg)) {
>barplot (mtcars$mpg, col=c(rep(1,n-1),2,rep(1,length(mtcars$mpg)-n)))
>}
>
>There is a odfWeave page break function so I can do that sort of thing
>(I think).  But I don't think I can output more than one image can I? 
>In reality I will want several images and a table per "catalogue" page.
>
>At the moment I think I need to create a master odt document, and
>create individual catalogue pages.  And merge them into one document -
>but that feels clunky (unless I can script the merge!)
>
>Anyone got a better way?
>
>
>
>
>********************************************************************************************************************
>
>This message may contain confidential information. If
>yo...{{dropped:21}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Jun  1 16:48:54 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 1 Jun 2017 07:48:54 -0700
Subject: [R] Latin Hypercube Sampling when parameters are defined
 according to specific probability distributions
In-Reply-To: <CY1PR05MB27308D07F399184179D83EB499F60@CY1PR05MB2730.namprd05.prod.outlook.com>
References: <CAPtunJZJ0HpZGGaNjpfbHL_bMxHeACJ21kzpP2Zv1+qtcnTMhg@mail.gmail.com>
 <CY1PR05MB2730F1E421CF600D3A9890E799F00@CY1PR05MB2730.namprd05.prod.outlook.com>
 <CAPtunJae1UcgrsOyS8+98BHT0E5ysnbmKumWj0zX8jOts+TsAg@mail.gmail.com>
 <CY1PR05MB27308D07F399184179D83EB499F60@CY1PR05MB2730.namprd05.prod.outlook.com>
Message-ID: <CAGxFJbRAP3FAX9i0G=5utqSFy=QVXcVOhUTTGHhEoK39+FLWQQ@mail.gmail.com>

I think you should take this conversation private or seek local
statistical expertise. This is about strategies for analysis, not
about programming in R.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, May 31, 2017 at 9:49 PM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> Thank you very much Rob for your answer. I have some difficulties to understand how to apply my agent-based model to each parameter combination generated by the LHS, in particular when parameters are defined by probability distributions. Indeed, I have multiple parameters in my model: parameters which are defined by a single value (like ?temperature", "pressure?) and parameters which are defined by probability distributions (like ?dispersal distance?). It?s correct for me to treat distance as a class. When all parameters are defined by a single value, I need first to create a data frame in which each column represents a different parameter, and each row represents a different combination of parameter values. Then, I apply my model to each row of the data frame. But, it?s not clear for me how to do this when parameters are defined from probability distributions? In particular, how can I use your code to apply my model to each of the 50 rows of the data frame ?tabLHS?? Given that one row corresponds to one model simulation, I should have a value generated by the LHS for all distance classes at the first line of the data frame.
>
>
>
> library(pse)
> q <- list("qexp", "qunif", "qunif")
> q.arg <- list(list(rate=exponential_rate), list(min=0, max=1),
> list(min=0, max=1))
> uncoupledLHS <- LHS(model=model_function, input_parameters, N, q, q.arg)
> hist(uncoupledLHS$data$dispersal_distance, breaks=10)
>
> tabLHS <- get.data(uncoupledLHS)
>
>
>
> Sorry, it?s the first time that I perform a sensitivity analysis using the LHS.
>
>
> Thank you very much for your time.
>
> Have a nice day
>
> Nell
>
>
> ________________________________
> De : Rob C <bertcarnell at gmail.com>
> Envoy? : mardi 30 mai 2017 16:26:08
> ? : Nelly Reduan
> Cc : r-help at r-project.org
> Objet : Re: [R] Latin Hypercube Sampling when parameters are defined according to specific probability distributions
>
> Nell,
>
> I still might not be interpreting your question correctly, but I will try.
>
> When you say that the sum of the probabilities of all distance classes
> must equal one, I am going to treat distance as a class, instead of as a
> continuous variable.
>
> distance_class_probabilities <- c(9, 11, 10, 8.9, 8, 7, 6, 5.8, 5.1,
> 4, 3.9, 3.7, 3.4, 3.1, 2, 1.9, 1.6, 1.4, 1, 0.9, 0.8, 0.7, 0.4, 0.3,
> 0.1)/100
> sum(distance_class_probabilities)
> distance_classes <- factor(paste0("d", 1:25), ordered = TRUE,
> levels=paste0("d", 1:25))
> input_parameters <- c("dispersal_distance", "temperature", "pressure")
> N <- 1000
>
> plot(1:25, distance_class_probabilities, type="h", lwd=5)
>
> set.seed(1)
> require(lhs)
> X <- randomLHS(N, length(input_parameters))
> dimnames(X) <- list(NULL, input_parameters)
> Y <- X
> Y[,"dispersal_distance"] <-
> approx(x=cumsum(distance_class_probabilities), y=1:25,
> xout=X[,"dispersal_distance"], method="constant", yleft=0)$y + 1
>
> hist(Y[,"dispersal_distance"], breaks=c(seq(0.5, 25.5, by=1)))
> plot(table(distance_classes[Y[,"dispersal_distance"]]))
>
>
> Is it still a Latin hypercube?
>
> This is a more difficult question.  In some ways, the sample is still a Latin
> hypercube since it was drawn that way.  But once the sample has been discretized
> into the distance classes, then it loses the latin property of having only one
> sample per "row".  It might be close enough for your purposes though.
>
> Rob
>
>
>
> On Tue, May 30, 2017 at 10:59 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
>> Thanks a lot Rob for your answer. I need to add a condition for the
>> parameter ?dispersal distance?. The sum of the probabilities of all distance
>> classes must be equal to 1:
>>
>> y <- c(9, 11, 10, 8.9, 8, 7, 6, 5.8, 5.1, 4, 3.9, 3.7, 3.4, 3.1, 2, 1.9,
>> 1.6, 1.4, 1, 0.9, 0.8, 0.7, 0.4, 0.3, 0.1)
>>
>> x <- seq(1, 25, by = 1)
>>
>> barplot(y/100, names.arg=x, ylab="Probability", xlab="Distance (km)")
>>
>>
>>
>> With this condition, is it possible to perform a LHS?
>>
>> Thanks a lot for your time.
>>
>> Nell
>>
>>
>> ________________________________
>> De : R-help <r-help-bounces at r-project.org> de la part de Rob C
>> <bertcarnell at gmail.com>
>> Envoy? : samedi 27 mai 2017 13:32:23
>> ? : r-help at r-project.org
>> Objet : Re: [R] Latin Hypercube Sampling when parameters are defined
>> according to specific probability distributions
>>
>>>May 26, 2017; 11:41am  Nelly Reduan Latin Hypercube Sampling when
>>> parameters are >defined according to specific probability distributions
>>>Hello,
>>> I would like to perform a sensitivity analysis using a Latin Hypercube
>>> Sampling (LHS).
>>>Among the input parameters in the model, I have a parameter dispersal
>>> distance which is defined according to an exponential probability
>>> distribution.
>>
>>>In the model, the user thus sets a default probability value for each
>>> distance class.
>>
>>>For example, for distances ([0  2]; ]2  4]; ]4  6]; ]6  8]; ]8  10];; ]48
>>> 50],
>>
>>>respective probabilities are 0.055; 0.090; 0.065; 0.035; 0.045;; 0.005.
>>
>>  >Here is the code to represent an exponential probability
>> distribution for the parameter dispersal distance:
>>
>>>set.seed(0)
>>>foo <- rexp(100, rate = 1/10)
>>>hist(foo, prob=TRUE, breaks=20, ylim=c(0,0.1), xlab ="Distance (km)")
>>>lines(dexp(seq(1, 100, by = 1), rate = 1/mean(foo)),col="red")
>>>1/mean(foo)
>>
>>>When a parameter is defined according to a specific probability
>>> distribution, how can I perform a LHS ?
>>>For example, should I sample N values from a uniform distribution for each
>>> distance class (i.e., [0 ? 2]; ]2 ? 4]; ]4 ? 6]; ]6 ? 8]; ]8 ? 10];??; ]48 ?
>>> 50])
>>>or sample N values from exponential distributions with different rates ?
>>
>>>Here is the code used to perform a LHS when the parameter ?dispersal
>>> distance? is defined by one default value in the model:
>>
>>>library(pse)
>>>factors <- c("distance")
>>>q <- c("qexp")
>>>q.arg <- list( list(rate=1/30) )
>>>uncoupledLHS <- LHS(model=NULL, factors, 50, q, q.arg)
>>>head(uncoupledLHS)
>>
>>>Thanks a lot for your time.
>>>Have a nice day
>>>Nell
>>
>> Nell,
>>
>> I would like to suggest a slightly different method for generating the
>> sample using the lhs library,  then I will try using the pse library.
>> Generally when you have a package specific
>> question, you should try to contact the package maintainer first.
>>
>> set.seed(1)
>> # I don't think your model has only one parameter, so I will include
>> multiple
>> input_parameters <- c("dispersal_distance", "temperature", "pressure")
>> N <- 50
>> exponential_rate <- 1/30
>>
>> library(lhs)
>> X <- randomLHS(N, length(input_parameters))
>> dimnames(X) <- list(NULL, input_parameters)
>> # X is now a uniformly distributed Latin hypercube
>> head(X)
>> hist(X[,1], breaks=5)
>> hist(X[,2], breaks=5)
>> hist(X[,3], breaks=5)
>> # now, transform the dispersal_distance paramter to an exponential sample
>> Y <- X
>> Y[,"dispersal_distance"] <- qexp(X[,"dispersal_distance"],
>> rate=exponential_rate)
>> hist(Y[,1], breaks=10)
>> # you can transform the other marginals as required and then assess
>> function sensitivity
>> model_function <- function(z) z[1]*z[2] + z[3]
>> apply(Y, 1, model_function)
>>
>> # now, trying to use pse
>> library(pse)
>> q <- list("qexp", "qunif", "qunif")
>> q.arg <- list(list(rate=exponential_rate), list(min=0, max=1),
>> list(min=0, max=1))
>> uncoupledLHS <- LHS(model=model_function, input_parameters, N, q, q.arg)
>> hist(uncoupledLHS$data$dispersal_distance, breaks=10)
>>
>> Rob
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Thu Jun  1 17:02:22 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 1 Jun 2017 17:02:22 +0200
Subject: [R] [FORGED] Re: Question on function "scatterplot3d"
In-Reply-To: <948df1a1-57c7-6dad-4475-b2d99e5dd527@auckland.ac.nz>
References: <CAHLnndZ-TKNQdMaLUca-CYOUD-YKZKvYDvy==Ne8a9+aeZvpqA@mail.gmail.com>
 <7945E490-A6BC-48A2-964B-DEA0F7C30431@gmail.com>
 <c4d356d5-3761-29c0-91c0-ea86339c02c2@auckland.ac.nz>
 <e7be3632-32dc-85e0-63b4-4e2d0b8adb68@statistik.tu-dortmund.de>
 <948df1a1-57c7-6dad-4475-b2d99e5dd527@auckland.ac.nz>
Message-ID: <8cadf1fe-d049-d9b7-2e1e-a01b51602027@statistik.tu-dortmund.de>



On 01.06.2017 10:03, Rolf Turner wrote:
> On 01/06/17 19:54, Uwe Ligges wrote:
>> A design flaw, whether the labels are cut depends somewhat on the 
>> sizce of the device, hence there is the argument
>>
>> y.margin.add
>>
>> add additional space between tick mark labels and axis label of the y 
>> axis
>>
>> for working around that limittation that can be set to some positive 
>> value....
> 
> 
> This seems to be addressing Hannah's (li li's) original enquiry, not my 
> follow-up in which I worried about the position, along the y-axis, of 
> the y-axis label.

Ah, that is intended as a smart way of rotating it along the axis is not 
easy (if not impossible) with the bas egraohics system.

Best,
Uwe Ligges



> 
> Or am I misunderstanding/missing something?
> 
> cheers,
> 
> Rolf
>


From taraadcock1 at hotmail.com  Thu Jun  1 12:02:39 2017
From: taraadcock1 at hotmail.com (Tara Adcock)
Date: Thu, 1 Jun 2017 10:02:39 +0000
Subject: [R] Data import R: some explanatory variables not showing up
 correctly in summary
Message-ID: <DB5PR0901MB1350CD14EA11108519F770DFF9F60@DB5PR0901MB1350.eurprd09.prod.outlook.com>

Hi,

I have a question regarding data importing into R.

When I import my data into R and review the summary, some of my explanatory variables are being reported as if instead of being one variable, they are two with the same name. See below for an example;

   Behav person         Behav dog               Position
  **combination  : 38   combination  :  4**     Bank    :372
  **combination  :  7   combination  :  4**   **Island  :119**
    fast         :123   fast         : 15     **Island  : 11**
    slow         :445   slow         : 95       Land    :  3
    stat         :111   stat         : 14       Water   :230

Also, all of the distances I have imported are showing up in the summary along with a line entitled "other". However, I haven't used any other distances?

   Distance        Distance.dog
   2-10m  :184     <50m   : 35
   <50m   :156     2-10m  : 27
   10-20m :156     20-30m : 23
   20-30m : 91     30-40m : 16
   40-50m : 57     10-20m : 13
   **(Other): 82   (Other): 18**

I have checked my data sheet over and over again and I think standardised the data, but the issue keeps arising. I'm assuming I need to clean the data set but as a nearly complete novice in R I am not certain how to do this. Any help at all with this would be much appreciated. Thanks so much.

Kind Regards,

Tara Adcock.


	[[alternative HTML version deleted]]


From anil.dabral at live.com  Thu Jun  1 12:17:19 2017
From: anil.dabral at live.com (Anil Dabral)
Date: Thu, 1 Jun 2017 10:17:19 +0000
Subject: [R] installed.packages() does not work properly
In-Reply-To: <d850a32a-b886-6082-6258-a9c1a281b032@statistik.tu-dortmund.de>
References: <PN1PR01MB0733E92BC069BEF2403240D59FF60@PN1PR01MB0733.INDPRD01.PROD.OUTLOOK.COM>,
 <d850a32a-b886-6082-6258-a9c1a281b032@statistik.tu-dortmund.de>
Message-ID: <PN1PR01MB0733BFBE10B786BAD67AC7329FF60@PN1PR01MB0733.INDPRD01.PROD.OUTLOOK.COM>

Thank you. The patched version worked. Installing R 3.4 patched was little tricky because windows SmartScreen Filter kept blocking. But finally, I got it installed.


Regards,

Anil


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Uwe Ligges <ligges at statistik.tu-dortmund.de>
Sent: Thursday, June 1, 2017 1:24:49 PM
To: Anil Dabral; r-help at r-project.org
Subject: Re: [R] installed.packages() does not work properly

Try R-3.4.0 patched.

Best,
Uwe Ligges



On 01.06.2017 03:54, Anil Dabral wrote:
> Hi,
>
> I tried executing the following statement multiple times on R 3.4 and it worked only the first time. In older versions of R it seems to have worked. Am I doing anything wrong?
>
>
> In R 3.4 (works only the first time)
>
> tmp <- installed.packages()  #this works
>
> tmp <- installed.packages() ## See error below
>
>
> Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
>    missing value where TRUE/FALSE needed
>
>
>
> in R 3.3.3 works well when executed multiple times.
>
> tmp <- installed.packages() #this works
>
> tmp <- installed.packages() #this works
>
> tmp <- installed.packages() #this works
>
>
> Thanks and Regards,
>
> Anil
>
> Sent from Outlook<http://aka.ms/weboutlook>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Lluis.Hurtado at uv.es  Thu Jun  1 13:58:20 2017
From: Lluis.Hurtado at uv.es (Lluis.Hurtado at uv.es)
Date: Thu, 1 Jun 2017 13:58:20 +0200 (CEST)
Subject: [R] [spatstat] Convert shapefile to pixel image
Message-ID: <2224137298hurgil@uv.es>

Dear all,

I am currently working with the spatstat package, using windows and pixel images.

First:

My aim is to transform a shapefile (see attached) into a pixel image. 

My idea is to start transforming the shapefile into a Spatial Polygon file:

x <- readShapeSpatial("200001441.shp")
y <- as(x, "SpatialPolygons")
z <- as.owin(y)

Given z, I want to identify each polygon with a single constant value. This is like adding marks to the SpatialPolygons file. Then I want to convert these polygons into an image, such that the value of each pixel corresponds to the value associated to the polygon where the pixel lies. 

I have been able to do this individually, polygon by polygon, but then I cannot merge the resulting images into a single one. Any idea?

Second:

I would also need a single window containing all the smallest polygons (the boundary). I have tried:

w <- union.owin(z)

But the resulting window w still shows internal polygons. As read in spatstas FAQ page:

"First, convert each of the regions into a separate owin object. Then apply union.owin to combine them."

So I try,

regions <- slot(y, "polygons")
regions <- lapply(regions, function(x) { SpatialPolygons(list(x)) })
windows <- lapply(regions, as.owin) 

But windows is a list of 4307 polygons. How can introduce all of them as a single argument?

> M <- union.owin(windows)
Warning messages:
1: In union.owin(windows) : Some arguments were not windows
2: In union.owin(windows) : No windows were given


Thank you very much for you help.

Llu?s Hurtado.


From Lluis.Hurtado at uv.es  Thu Jun  1 15:17:19 2017
From: Lluis.Hurtado at uv.es (Lluis.Hurtado at uv.es)
Date: Thu, 1 Jun 2017 15:17:19 +0200 (CEST)
Subject: [R] [spatstat] Convert shapefile to pixel image
Message-ID: <1188522651hurgil@uv.es>

Dear all,

I am currently working with the spatstat package, using windows and pixel images.

First:

My aim is to transform a shapefile (see attached) into a pixel image. 

My idea is to start transforming the shapefile into a Spatial Polygon file:

x <- readShapeSpatial("200001441.shp")
y <- as(x, "SpatialPolygons")
z <- as.owin(y)

Given z, I want to identify each polygon with a single constant value. This is like adding marks to the SpatialPolygons file. Then I want to convert these polygons into an image, such that the value of each pixel corresponds to the value associated to the polygon where the pixel lies. 

I have been able to do this individually, polygon by polygon, but then I cannot merge the resulting images into a single one. Any idea?

Second:

I would also need a single window containing all the smallest polygons (the boundary). I have tried:

w <- union.owin(z)

But the resulting window w still shows internal polygons. As read in spatstas FAQ page:

"First, convert each of the regions into a separate owin object. Then apply union.owin to combine them."

So I try,

regions <- slot(y, "polygons")
regions <- lapply(regions, function(x) { SpatialPolygons(list(x)) })
windows <- lapply(regions, as.owin) 

But windows is a list of 4307 polygons. How can introduce all of them as a single argument?

> M <- union.owin(windows)
Warning messages:
1: In union.owin(windows) : Some arguments were not windows
2: In union.owin(windows) : No windows were given


Thank you very much for you help.

Llu?s Hurtado.

From ruipbarradas at sapo.pt  Thu Jun  1 17:29:43 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 01 Jun 2017 16:29:43 +0100
Subject: [R] Data import R: some explanatory variables not showing up
 correctly in summary
In-Reply-To: <DB5PR0901MB1350CD14EA11108519F770DFF9F60@DB5PR0901MB1350.eurprd09.prod.outlook.com>
References: <DB5PR0901MB1350CD14EA11108519F770DFF9F60@DB5PR0901MB1350.eurprd09.prod.outlook.com>
Message-ID: <593032E7.20200@sapo.pt>

Hello,

In order for us to help we need to know how you've imported your data. 
What was the file type? What instructions have you used to import it? 
Did you use base R or a package?
Give us a minimal but complete code example that can reproduce your 
situation.

Hope this helps,

Rui Barradas

Em 01-06-2017 11:02, Tara Adcock escreveu:
> Hi,
>
> I have a question regarding data importing into R.
>
> When I import my data into R and review the summary, some of my explanatory variables are being reported as if instead of being one variable, they are two with the same name. See below for an example;
>
>     Behav person         Behav dog               Position
>    **combination  : 38   combination  :  4**     Bank    :372
>    **combination  :  7   combination  :  4**   **Island  :119**
>      fast         :123   fast         : 15     **Island  : 11**
>      slow         :445   slow         : 95       Land    :  3
>      stat         :111   stat         : 14       Water   :230
>
> Also, all of the distances I have imported are showing up in the summary along with a line entitled "other". However, I haven't used any other distances?
>
>     Distance        Distance.dog
>     2-10m  :184     <50m   : 35
>     <50m   :156     2-10m  : 27
>     10-20m :156     20-30m : 23
>     20-30m : 91     30-40m : 16
>     40-50m : 57     10-20m : 13
>     **(Other): 82   (Other): 18**
>
> I have checked my data sheet over and over again and I think standardised the data, but the issue keeps arising. I'm assuming I need to clean the data set but as a nearly complete novice in R I am not certain how to do this. Any help at all with this would be much appreciated. Thanks so much.
>
> Kind Regards,
>
> Tara Adcock.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Thu Jun  1 17:48:53 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 1 Jun 2017 15:48:53 +0000
Subject: [R] Post for R
In-Reply-To: <CA+8X3fUN1qFDA=8EtTx6qD_HiK_+kiyKXp86nD-fsCeWN5nNbw@mail.gmail.com>
References: <170780372.145082.1496285308297.ref@mail.yahoo.com>
 <170780372.145082.1496285308297@mail.yahoo.com>
 <CA+8X3fUN1qFDA=8EtTx6qD_HiK_+kiyKXp86nD-fsCeWN5nNbw@mail.gmail.com>
Message-ID: <4faaba09ce4046edb97770bf4f1b77a3@exch-2p-mbx-w2.ads.tamu.edu>

As Hasan notes, your code is scrambled because you sent your message in html format. This list converts all mail to plain text to make it readable to a wider variety of computers and operating systems around the world. One consequence is that the html code for newline gets ignored. The attached .png file shows how to send plain text messages using yahoo mail. Also use a subject line that is a bit more descriptive, e.g. Splitting a data frame on two variables.

Without knowing more about your data we cannot know if your method of dividing the data into groups is sound. As Jim points out, some of your groups could be empty depending on how the variables max and submax are coded. Using str(df) would help, but we really need a sample data set to try possible approaches. That data set should not be your entire data and can be entirely made up if your data is proprietary.

Your loop does not work because it overwrites Z and G on each step. Also it is completely unnecessary if I understand what you are trying to do. Here's a simple reproducible example, that you can try. It uses only 24 cases divided into 4 max groups and 2 submax groups, but it should show you how you might handle your data. I'll divide the groups into equal ranges, not an equal number of observations, but it is not clear which you want. As a result some groups could be empty, but that does not happen in this example:

# Set a random seed so you will get the same numbers
set.seed(42)
# Create a simple data set with 3 variables
# Name it dfr instead of df which is a function name
# R will normally figure out which you mean unless you make an error
# in which case you will get a cryptic error message about "a closure"
dfr <- data.frame(var=LETTERS[1:24], max=sample.int(100, 24), 
    submax=sample.int(100, 24))
# Create your data into 4 and 2 groups
L1 <- cut(dfr$max, 4)
L2 <- cut(dfr$submax, 2)
# Create the combinations of the two groups
L12 <- expand.grid(levels(L1), levels(L2))
# Split the data
dfr.sp <- split(dfr, L12)
length(dfr.sp)
# We get 8 groups, 4x2

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Thursday, June 1, 2017 2:53 AM
To: carrie wang <yuemile0902 at yahoo.com>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Post for R

Hi Carrie,
You may have a problem with this if some subsets are empty:

L3<-lapply(split(df,cut(df$max,seq(0,1,by=0.01))),
 split,cut(df$submax,seq(0,0.2,by=0.02)))

Jim

On Thu, Jun 1, 2017 at 12:48 PM, carrie wang via R-help
<r-help at r-project.org> wrote:
>
> Hello,
> I want to split the dataframe into 1000 groups based on two column values(max value and second max value). First, I made two lists L1 and L2.  L1 is the list divided into 100 groups based on the range of max value and L2 is divided into 10 groups based on the second max values. Now I want to do the combinations based on L1 and L2. I want to do a for loop for L1 and for each element in L1, I split it into 10 groups based on L2. I tried to write the code, but it does not work.
>
> L1<-split(df,cut(df$max,seq(0,1,by=0.01)))L2<-split(df,cut(df$submax,seq(0,0.2,by=0.02)))
> Z<-list()G<-list()for (i in length(L1)){  Z=data.frame(L1[i])  G <- split(Z$submax,"0.02")  print(G)  }
> Thanks so much!Carrie
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: YahooPlainText.png
Type: image/png
Size: 56243 bytes
Desc: YahooPlainText.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170601/0bb171ea/attachment.png>

From ulrik.stervbo at gmail.com  Thu Jun  1 17:49:44 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 01 Jun 2017 15:49:44 +0000
Subject: [R] Data import R: some explanatory variables not showing up
 correctly in summary
In-Reply-To: <593032E7.20200@sapo.pt>
References: <DB5PR0901MB1350CD14EA11108519F770DFF9F60@DB5PR0901MB1350.eurprd09.prod.outlook.com>
 <593032E7.20200@sapo.pt>
Message-ID: <CAKVAULONSARADKCVy0p2xp5n1ikw6ASZsDO8dKBcdELL3Jqv+A@mail.gmail.com>

Hi Tara,

It seems that you categorise and count for each category. Could it be that
the method you use puts everything that doesn't match the predefined
categories in Other?

I'm only guessing because without a minimal  reproducible example it's
difficult to do anything else.

Best wishes
Ulrik

Rui Barradas <ruipbarradas at sapo.pt> schrieb am Do., 1. Juni 2017, 17:30:

> Hello,
>
> In order for us to help we need to know how you've imported your data.
> What was the file type? What instructions have you used to import it?
> Did you use base R or a package?
> Give us a minimal but complete code example that can reproduce your
> situation.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 01-06-2017 11:02, Tara Adcock escreveu:
> > Hi,
> >
> > I have a question regarding data importing into R.
> >
> > When I import my data into R and review the summary, some of my
> explanatory variables are being reported as if instead of being one
> variable, they are two with the same name. See below for an example;
> >
> >     Behav person         Behav dog               Position
> >    **combination  : 38   combination  :  4**     Bank    :372
> >    **combination  :  7   combination  :  4**   **Island  :119**
> >      fast         :123   fast         : 15     **Island  : 11**
> >      slow         :445   slow         : 95       Land    :  3
> >      stat         :111   stat         : 14       Water   :230
> >
> > Also, all of the distances I have imported are showing up in the summary
> along with a line entitled "other". However, I haven't used any other
> distances?
> >
> >     Distance        Distance.dog
> >     2-10m  :184     <50m   : 35
> >     <50m   :156     2-10m  : 27
> >     10-20m :156     20-30m : 23
> >     20-30m : 91     30-40m : 16
> >     40-50m : 57     10-20m : 13
> >     **(Other): 82   (Other): 18**
> >
> > I have checked my data sheet over and over again and I think
> standardised the data, but the issue keeps arising. I'm assuming I need to
> clean the data set but as a nearly complete novice in R I am not certain
> how to do this. Any help at all with this would be much appreciated. Thanks
> so much.
> >
> > Kind Regards,
> >
> > Tara Adcock.
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Jun  1 17:57:57 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 1 Jun 2017 08:57:57 -0700
Subject: [R] Data import R: some explanatory variables not showing up
 correctly in summary
In-Reply-To: <CAKVAULONSARADKCVy0p2xp5n1ikw6ASZsDO8dKBcdELL3Jqv+A@mail.gmail.com>
References: <DB5PR0901MB1350CD14EA11108519F770DFF9F60@DB5PR0901MB1350.eurprd09.prod.outlook.com>
 <593032E7.20200@sapo.pt>
 <CAKVAULONSARADKCVy0p2xp5n1ikw6ASZsDO8dKBcdELL3Jqv+A@mail.gmail.com>
Message-ID: <CAF8bMcbKOW140RR8SmbhZeq5Mhi0-1p0-qGnNvoVMNaUF1zFwQ@mail.gmail.com>

Check for leading or trailing spaces in the strings in your data.
 dput(dataset) would show them.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jun 1, 2017 at 8:49 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> Hi Tara,
>
> It seems that you categorise and count for each category. Could it be that
> the method you use puts everything that doesn't match the predefined
> categories in Other?
>
> I'm only guessing because without a minimal  reproducible example it's
> difficult to do anything else.
>
> Best wishes
> Ulrik
>
> Rui Barradas <ruipbarradas at sapo.pt> schrieb am Do., 1. Juni 2017, 17:30:
>
> > Hello,
> >
> > In order for us to help we need to know how you've imported your data.
> > What was the file type? What instructions have you used to import it?
> > Did you use base R or a package?
> > Give us a minimal but complete code example that can reproduce your
> > situation.
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > Em 01-06-2017 11:02, Tara Adcock escreveu:
> > > Hi,
> > >
> > > I have a question regarding data importing into R.
> > >
> > > When I import my data into R and review the summary, some of my
> > explanatory variables are being reported as if instead of being one
> > variable, they are two with the same name. See below for an example;
> > >
> > >     Behav person         Behav dog               Position
> > >    **combination  : 38   combination  :  4**     Bank    :372
> > >    **combination  :  7   combination  :  4**   **Island  :119**
> > >      fast         :123   fast         : 15     **Island  : 11**
> > >      slow         :445   slow         : 95       Land    :  3
> > >      stat         :111   stat         : 14       Water   :230
> > >
> > > Also, all of the distances I have imported are showing up in the
> summary
> > along with a line entitled "other". However, I haven't used any other
> > distances?
> > >
> > >     Distance        Distance.dog
> > >     2-10m  :184     <50m   : 35
> > >     <50m   :156     2-10m  : 27
> > >     10-20m :156     20-30m : 23
> > >     20-30m : 91     30-40m : 16
> > >     40-50m : 57     10-20m : 13
> > >     **(Other): 82   (Other): 18**
> > >
> > > I have checked my data sheet over and over again and I think
> > standardised the data, but the issue keeps arising. I'm assuming I need
> to
> > clean the data set but as a nearly complete novice in R I am not certain
> > how to do this. Any help at all with this would be much appreciated.
> Thanks
> > so much.
> > >
> > > Kind Regards,
> > >
> > > Tara Adcock.
> > >
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Jun  1 18:07:14 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 1 Jun 2017 16:07:14 +0000
Subject: [R] Data import R: some explanatory variables not showing up
 correctly in summary
In-Reply-To: <CAKVAULONSARADKCVy0p2xp5n1ikw6ASZsDO8dKBcdELL3Jqv+A@mail.gmail.com>
References: <DB5PR0901MB1350CD14EA11108519F770DFF9F60@DB5PR0901MB1350.eurprd09.prod.outlook.com>
 <593032E7.20200@sapo.pt>
 <CAKVAULONSARADKCVy0p2xp5n1ikw6ASZsDO8dKBcdELL3Jqv+A@mail.gmail.com>
Message-ID: <81c5c1321053456f8ec1b0e87fa95fc8@exch-2p-mbx-w2.ads.tamu.edu>

It looks like your printouts are based on the R summary() function? The function lists the number of cases in the 5 largest categories when the variable is coded as a function. Then it indicates how many other categories are present. This is described on the manual page for function summary().

In the first case the duplicates probably represent cases in your source data (a spreadsheet?), where you have inadvertently put a space at the end of the label, e.g. "combination", and "combination ". The answers to both questions are easy to find with the levels() function:

levels(yourdataframe$Position) 

This will list all of the factor levels in variable Position for you. If there are extras spaces and you were using read.csv() to import the data, use the strip.white=TRUE argument to delete leading and trailing spaces. This is also documented on the manual page for function read.csv(). One of the problems with spreadsheets is that these extra spaces are not readily apparent.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ulrik Stervbo
Sent: Thursday, June 1, 2017 10:50 AM
To: Rui Barradas <ruipbarradas at sapo.pt>; Tara Adcock <taraadcock1 at hotmail.com>; r-help at r-project.org
Subject: Re: [R] Data import R: some explanatory variables not showing up correctly in summary

Hi Tara,

It seems that you categorise and count for each category. Could it be that
the method you use puts everything that doesn't match the predefined
categories in Other?

I'm only guessing because without a minimal  reproducible example it's
difficult to do anything else.

Best wishes
Ulrik

Rui Barradas <ruipbarradas at sapo.pt> schrieb am Do., 1. Juni 2017, 17:30:

> Hello,
>
> In order for us to help we need to know how you've imported your data.
> What was the file type? What instructions have you used to import it?
> Did you use base R or a package?
> Give us a minimal but complete code example that can reproduce your
> situation.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 01-06-2017 11:02, Tara Adcock escreveu:
> > Hi,
> >
> > I have a question regarding data importing into R.
> >
> > When I import my data into R and review the summary, some of my
> explanatory variables are being reported as if instead of being one
> variable, they are two with the same name. See below for an example;
> >
> >     Behav person         Behav dog               Position
> >    **combination  : 38   combination  :  4**     Bank    :372
> >    **combination  :  7   combination  :  4**   **Island  :119**
> >      fast         :123   fast         : 15     **Island  : 11**
> >      slow         :445   slow         : 95       Land    :  3
> >      stat         :111   stat         : 14       Water   :230
> >
> > Also, all of the distances I have imported are showing up in the summary
> along with a line entitled "other". However, I haven't used any other
> distances?
> >
> >     Distance        Distance.dog
> >     2-10m  :184     <50m   : 35
> >     <50m   :156     2-10m  : 27
> >     10-20m :156     20-30m : 23
> >     20-30m : 91     30-40m : 16
> >     40-50m : 57     10-20m : 13
> >     **(Other): 82   (Other): 18**
> >
> > I have checked my data sheet over and over again and I think
> standardised the data, but the issue keeps arising. I'm assuming I need to
> clean the data set but as a nearly complete novice in R I am not certain
> how to do this. Any help at all with this would be much appreciated. Thanks
> so much.
> >
> > Kind Regards,
> >
> > Tara Adcock.
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Jun  1 18:10:22 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 1 Jun 2017 16:10:22 +0000
Subject: [R] Data import R: some explanatory variables not showing up
 correctly in summary
In-Reply-To: <81c5c1321053456f8ec1b0e87fa95fc8@exch-2p-mbx-w2.ads.tamu.edu>
References: <DB5PR0901MB1350CD14EA11108519F770DFF9F60@DB5PR0901MB1350.eurprd09.prod.outlook.com>
 <593032E7.20200@sapo.pt>
 <CAKVAULONSARADKCVy0p2xp5n1ikw6ASZsDO8dKBcdELL3Jqv+A@mail.gmail.com>
 <81c5c1321053456f8ec1b0e87fa95fc8@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <5f4e1081cca4416e857e8b9105041b3c@exch-2p-mbx-w2.ads.tamu.edu>

It looks like your printouts are based on the R summary() function? The function lists the number of cases in the 5 largest categories when the variable is coded as a FACTOR.

David C

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Thursday, June 1, 2017 11:07 AM
To: Ulrik Stervbo <ulrik.stervbo at gmail.com>; Rui Barradas <ruipbarradas at sapo.pt>; Tara Adcock <taraadcock1 at hotmail.com>; r-help at r-project.org
Cc: William Dunlap via R-help <r-help at r-project.org>
Subject: Re: [R] Data import R: some explanatory variables not showing up correctly in summary

It looks like your printouts are based on the R summary() function? The function lists the number of cases in the 5 largest categories when the variable is coded as a function. Then it indicates how many other categories are present. This is described on the manual page for function summary().

In the first case the duplicates probably represent cases in your source data (a spreadsheet?), where you have inadvertently put a space at the end of the label, e.g. "combination", and "combination ". The answers to both questions are easy to find with the levels() function:

levels(yourdataframe$Position) 

This will list all of the factor levels in variable Position for you. If there are extras spaces and you were using read.csv() to import the data, use the strip.white=TRUE argument to delete leading and trailing spaces. This is also documented on the manual page for function read.csv(). One of the problems with spreadsheets is that these extra spaces are not readily apparent.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ulrik Stervbo
Sent: Thursday, June 1, 2017 10:50 AM
To: Rui Barradas <ruipbarradas at sapo.pt>; Tara Adcock <taraadcock1 at hotmail.com>; r-help at r-project.org
Subject: Re: [R] Data import R: some explanatory variables not showing up correctly in summary

Hi Tara,

It seems that you categorise and count for each category. Could it be that
the method you use puts everything that doesn't match the predefined
categories in Other?

I'm only guessing because without a minimal  reproducible example it's
difficult to do anything else.

Best wishes
Ulrik

Rui Barradas <ruipbarradas at sapo.pt> schrieb am Do., 1. Juni 2017, 17:30:

> Hello,
>
> In order for us to help we need to know how you've imported your data.
> What was the file type? What instructions have you used to import it?
> Did you use base R or a package?
> Give us a minimal but complete code example that can reproduce your
> situation.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 01-06-2017 11:02, Tara Adcock escreveu:
> > Hi,
> >
> > I have a question regarding data importing into R.
> >
> > When I import my data into R and review the summary, some of my
> explanatory variables are being reported as if instead of being one
> variable, they are two with the same name. See below for an example;
> >
> >     Behav person         Behav dog               Position
> >    **combination  : 38   combination  :  4**     Bank    :372
> >    **combination  :  7   combination  :  4**   **Island  :119**
> >      fast         :123   fast         : 15     **Island  : 11**
> >      slow         :445   slow         : 95       Land    :  3
> >      stat         :111   stat         : 14       Water   :230
> >
> > Also, all of the distances I have imported are showing up in the summary
> along with a line entitled "other". However, I haven't used any other
> distances?
> >
> >     Distance        Distance.dog
> >     2-10m  :184     <50m   : 35
> >     <50m   :156     2-10m  : 27
> >     10-20m :156     20-30m : 23
> >     20-30m : 91     30-40m : 16
> >     40-50m : 57     10-20m : 13
> >     **(Other): 82   (Other): 18**
> >
> > I have checked my data sheet over and over again and I think
> standardised the data, but the issue keeps arising. I'm assuming I need to
> clean the data set but as a nearly complete novice in R I am not certain
> how to do this. Any help at all with this would be much appreciated. Thanks
> so much.
> >
> > Kind Regards,
> >
> > Tara Adcock.
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jun  1 18:17:27 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 1 Jun 2017 09:17:27 -0700
Subject: [R] Data import R: some explanatory variables not showing up
	correctly in summary
In-Reply-To: <CAF8bMcbKOW140RR8SmbhZeq5Mhi0-1p0-qGnNvoVMNaUF1zFwQ@mail.gmail.com>
References: <DB5PR0901MB1350CD14EA11108519F770DFF9F60@DB5PR0901MB1350.eurprd09.prod.outlook.com>
 <593032E7.20200@sapo.pt>
 <CAKVAULONSARADKCVy0p2xp5n1ikw6ASZsDO8dKBcdELL3Jqv+A@mail.gmail.com>
 <CAF8bMcbKOW140RR8SmbhZeq5Mhi0-1p0-qGnNvoVMNaUF1zFwQ@mail.gmail.com>
Message-ID: <B60CB4DB-3BF3-4FEE-8457-630FCE303E49@comcast.net>


> On Jun 1, 2017, at 8:57 AM, William Dunlap via R-help <r-help at r-project.org> wrote:
> 
> Check for leading or trailing spaces in the strings in your data.
> dput(dataset) would show them.

This function would strip any leading or trailing spaces from a column:

trim <-
   function (s) 
        {
    s <- as.character(s)
    s <- sub(pattern = "^[[:blank:]]+", replacement = "", x = s)
    s <- sub(pattern = "[[:blank:]]+$", replacement = "", x = s)
    s
         }

You could restrict it to non-mumeric columns with:

my_dfrm[ !sapply(my_dfrm, is.numeric) ] <- lapply( my_dfrm[ !sapply(my_dfrm, is.numeric) ], trim)

It would have the side-effect, (desirable in my opinion but opinions do vary on this matter), of converting any factor columns to character-class.



> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Thu, Jun 1, 2017 at 8:49 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
> 
>> Hi Tara,
>> 
>> It seems that you categorise and count for each category. Could it be that
>> the method you use puts everything that doesn't match the predefined
>> categories in Other?
>> 
>> I'm only guessing because without a minimal  reproducible example it's
>> difficult to do anything else.
>> 
>> Best wishes
>> Ulrik
>> 
>> Rui Barradas <ruipbarradas at sapo.pt> schrieb am Do., 1. Juni 2017, 17:30:
>> 
>>> Hello,
>>> 
>>> In order for us to help we need to know how you've imported your data.
>>> What was the file type? What instructions have you used to import it?
>>> Did you use base R or a package?
>>> Give us a minimal but complete code example that can reproduce your
>>> situation.
>>> 
>>> Hope this helps,
>>> 
>>> Rui Barradas
>>> 
>>> Em 01-06-2017 11:02, Tara Adcock escreveu:
>>>> Hi,
>>>> 
>>>> I have a question regarding data importing into R.
>>>> 
>>>> When I import my data into R and review the summary, some of my
>>> explanatory variables are being reported as if instead of being one
>>> variable, they are two with the same name. See below for an example;
>>>> 
>>>>    Behav person         Behav dog               Position
>>>>   **combination  : 38   combination  :  4**     Bank    :372
>>>>   **combination  :  7   combination  :  4**   **Island  :119**
>>>>     fast         :123   fast         : 15     **Island  : 11**
>>>>     slow         :445   slow         : 95       Land    :  3
>>>>     stat         :111   stat         : 14       Water   :230
>>>> 
>>>> Also, all of the distances I have imported are showing up in the
>> summary
>>> along with a line entitled "other". However, I haven't used any other
>>> distances?
>>>> 
>>>>    Distance        Distance.dog
>>>>    2-10m  :184     <50m   : 35
>>>>    <50m   :156     2-10m  : 27
>>>>    10-20m :156     20-30m : 23
>>>>    20-30m : 91     30-40m : 16
>>>>    40-50m : 57     10-20m : 13
>>>>    **(Other): 82   (Other): 18**
>>>> 
>>>> I have checked my data sheet over and over again and I think
>>> standardised the data, but the issue keeps arising. I'm assuming I need
>> to
>>> clean the data set but as a nearly complete novice in R I am not certain
>>> how to do this. Any help at all with this would be much appreciated.
>> Thanks
>>> so much.
>>>> 
>>>> Kind Regards,
>>>> 
>>>> Tara Adcock.
>>>> 
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ccberry at ucsd.edu  Thu Jun  1 18:35:38 2017
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Thu, 1 Jun 2017 09:35:38 -0700
Subject: [R] odfWeave - A loop of the "same" data
In-Reply-To: <835a481d90af48278b637598af299650@NH-HEPEX141.AD1.NHS.NET>
References: <835a481d90af48278b637598af299650@NH-HEPEX141.AD1.NHS.NET>
Message-ID: <alpine.OSX.2.20.1706010902010.783@charles-berrys-macbook.local>

On Thu, 1 Jun 2017, POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST) via R-help wrote:

> Before I go and do this another way - can I check if anyone has a way of 
> looping through data in odfWeave (or possibly sweave) to do a repeating 
> analysis on subsets of data?
>
> For simplicity lets use mtcars dataset in R to explain.  Dataset looks like this:
>
>> mtcars
>               mpg cyl disp  hp drat   wt ...
> Mazda RX4     21.0   6  160 110 3.90 2.62 ...
> Mazda RX4 Wag 21.0   6  160 110 3.90 2.88 ...
> Datsun 710    22.8   4  108  93 3.85 2.32 ...
>               ............
>
> Say I wanted to have a 'catalogue' style report from mtcars, where on 
> each page I would perhaps have the Rowname as a heading and then plot a 
> graph of mpg highlighting that specific car
>
> Then add a page break and *do the same for the next car*.  I can manually do this of course, but it is effectively a loop something like this:
>
> for (n in length(mtcars$mpg)) {
> barplot (mtcars$mpg, col=c(rep(1,n-1),2,rep(1,length(mtcars$mpg)-n)))
> }
>
> There is a odfWeave page break function so I can do that sort of thing 
> (I think).  But I don't think I can output more than one image can I? 
> In reality I will want several images and a table per "catalogue" page.
>
> At the moment I think I need to create a master odt document, and create 
> individual catalogue pages.  And merge them into one document - but that 
> feels clunky (unless I can script the merge!)
>
> Anyone got a better way?


For a complex template inside a loop, I'd probably do as Jeff suggests and 
use a knitr child document for ease of developing and debugging the 
template.

But for the simple case you describe I'd use a brew script to
unroll the loop.

You would write your input file as usual, but put a brew script in the
right place, then run brew on the input file to produce an
intermediate file that unrolls the loop, then weave the intermediate
file to get your desired result.  Here is a simple example of such you 
can run in an R session (assuming the brew package is installed) and see 
the results printed out.

--8<---------------cut here---------------start------------->8---

brew::brew(text="

Everything before the loop

<% for (i in 1:10) { %>
Print the value of i
<% print(i) %> or better yet
\\Sexpr{<%= i %>}
<% } %>

everything after

")

--8<---------------cut here---------------end--------------->8---

The double backslash is needed in the literal string used here.  If
you put that script in a file using an editor, you would just use a
single backslash.

HTH,

Chuck


From roy.mendelssohn at noaa.gov  Thu Jun  1 18:51:47 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 1 Jun 2017 09:51:47 -0700
Subject: [R] Reversing one dimension of an array, in a generalized case
Message-ID: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>

Hi All:

I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.

A simplified idea is I have an array, say:

junk(5, 10, 3)

where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:

junk1 <- junk[, rev(seq_len(10), ]

but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.

For example,  if i try:

junk1 <- apply(junk, 2, rev)

junk1 comes out as two-dimensional,  not three-dimensional.

It is probably something obvious but I am not getting it.

Thanks for any help.

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From ccberry at ucsd.edu  Thu Jun  1 19:06:11 2017
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Thu, 1 Jun 2017 10:06:11 -0700
Subject: [R] Data import R: some explanatory variables not showing up
 correctly in summary
In-Reply-To: <593032E7.20200@sapo.pt>
References: <DB5PR0901MB1350CD14EA11108519F770DFF9F60@DB5PR0901MB1350.eurprd09.prod.outlook.com>
 <593032E7.20200@sapo.pt>
Message-ID: <alpine.OSX.2.20.1706010943340.820@charles-berrys-macbook.local>

On Thu, 1 Jun 2017, Rui Barradas wrote:

> Hello,
>
> In order for us to help we need to know how you've imported your data. What 
> was the file type? What instructions have you used to import it? Did you use 
> base R or a package?
> Give us a minimal but complete code example that can reproduce your 
> situation.
>
> Hope this helps,
>
> Rui Barradas

Absolutely.

It would also help to see what the unique values of each column 
*really* are. To that end run and report the results of this:

lapply(your.data.frame, function(x) unique(as.character(x)))

I'll bet you have both "combination" and "combination " as values or 
something similar where two different strings look to your eye to be the 
same when printed by summary().

HTH,

Chuck

>
> Em 01-06-2017 11:02, Tara Adcock escreveu:
>> Hi,
>> 
>> I have a question regarding data importing into R.
>> 
>> When I import my data into R and review the summary, some of my explanatory 
>> variables are being reported as if instead of being one variable, they are 
>> two with the same name. See below for an example;
>>
>>     Behav person         Behav dog               Position
>>    **combination  : 38   combination  :  4**     Bank    :372
>>    **combination  :  7   combination  :  4**   **Island  :119**
>>      fast         :123   fast         : 15     **Island  : 11**
>>      slow         :445   slow         : 95       Land    :  3
>>      stat         :111   stat         : 14       Water   :230
>> 
>> Also, all of the distances I have imported are showing up in the summary 
>> along with a line entitled "other". However, I haven't used any other 
>> distances?
>>
>>     Distance        Distance.dog
>>     2-10m  :184     <50m   : 35
>>     <50m   :156     2-10m  : 27
>>     10-20m :156     20-30m : 23
>>     20-30m : 91     30-40m : 16
>>     40-50m : 57     10-20m : 13
>>     **(Other): 82   (Other): 18**
>> 
>> I have checked my data sheet over and over again and I think standardised 
>> the data, but the issue keeps arising. I'm assuming I need to clean the 
>> data set but as a nearly complete novice in R I am not certain how to do 
>> this. Any help at all with this would be much appreciated. Thanks so much.
>> 
>> Kind Regards,
>> 
>> Tara Adcock.
>> 
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>

Charles C. Berry                 Dept of Family Medicine & Public Health
cberry at ucsd edu               UC San Diego / La Jolla, CA 92093-0901
http://biostat.ucsd.edu/ccberry.htm


From wdunlap at tibco.com  Thu Jun  1 19:29:04 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 1 Jun 2017 10:29:04 -0700
Subject: [R] Data import R: some explanatory variables not showing up
 correctly in summary
In-Reply-To: <B60CB4DB-3BF3-4FEE-8457-630FCE303E49@comcast.net>
References: <DB5PR0901MB1350CD14EA11108519F770DFF9F60@DB5PR0901MB1350.eurprd09.prod.outlook.com>
 <593032E7.20200@sapo.pt>
 <CAKVAULONSARADKCVy0p2xp5n1ikw6ASZsDO8dKBcdELL3Jqv+A@mail.gmail.com>
 <CAF8bMcbKOW140RR8SmbhZeq5Mhi0-1p0-qGnNvoVMNaUF1zFwQ@mail.gmail.com>
 <B60CB4DB-3BF3-4FEE-8457-630FCE303E49@comcast.net>
Message-ID: <CAF8bMcY_gV2HgJV4y0km1KahDji-=PRiLac5dvV1vw5dAxJ27w@mail.gmail.com>

Re-importing the data with read.table's strip.white=TRUE argument may be an
easier way to deal with the problem (if the problem is leading or trailing
whitespace).

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jun 1, 2017 at 9:17 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Jun 1, 2017, at 8:57 AM, William Dunlap via R-help <
> r-help at r-project.org> wrote:
> >
> > Check for leading or trailing spaces in the strings in your data.
> > dput(dataset) would show them.
>
> This function would strip any leading or trailing spaces from a column:
>
> trim <-
>    function (s)
>         {
>     s <- as.character(s)
>     s <- sub(pattern = "^[[:blank:]]+", replacement = "", x = s)
>     s <- sub(pattern = "[[:blank:]]+$", replacement = "", x = s)
>     s
>          }
>
> You could restrict it to non-mumeric columns with:
>
> my_dfrm[ !sapply(my_dfrm, is.numeric) ] <- lapply( my_dfrm[
> !sapply(my_dfrm, is.numeric) ], trim)
>
> It would have the side-effect, (desirable in my opinion but opinions do
> vary on this matter), of converting any factor columns to character-class.
>
>
>
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Thu, Jun 1, 2017 at 8:49 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> > wrote:
> >
> >> Hi Tara,
> >>
> >> It seems that you categorise and count for each category. Could it be
> that
> >> the method you use puts everything that doesn't match the predefined
> >> categories in Other?
> >>
> >> I'm only guessing because without a minimal  reproducible example it's
> >> difficult to do anything else.
> >>
> >> Best wishes
> >> Ulrik
> >>
> >> Rui Barradas <ruipbarradas at sapo.pt> schrieb am Do., 1. Juni 2017,
> 17:30:
> >>
> >>> Hello,
> >>>
> >>> In order for us to help we need to know how you've imported your data.
> >>> What was the file type? What instructions have you used to import it?
> >>> Did you use base R or a package?
> >>> Give us a minimal but complete code example that can reproduce your
> >>> situation.
> >>>
> >>> Hope this helps,
> >>>
> >>> Rui Barradas
> >>>
> >>> Em 01-06-2017 11:02, Tara Adcock escreveu:
> >>>> Hi,
> >>>>
> >>>> I have a question regarding data importing into R.
> >>>>
> >>>> When I import my data into R and review the summary, some of my
> >>> explanatory variables are being reported as if instead of being one
> >>> variable, they are two with the same name. See below for an example;
> >>>>
> >>>>    Behav person         Behav dog               Position
> >>>>   **combination  : 38   combination  :  4**     Bank    :372
> >>>>   **combination  :  7   combination  :  4**   **Island  :119**
> >>>>     fast         :123   fast         : 15     **Island  : 11**
> >>>>     slow         :445   slow         : 95       Land    :  3
> >>>>     stat         :111   stat         : 14       Water   :230
> >>>>
> >>>> Also, all of the distances I have imported are showing up in the
> >> summary
> >>> along with a line entitled "other". However, I haven't used any other
> >>> distances?
> >>>>
> >>>>    Distance        Distance.dog
> >>>>    2-10m  :184     <50m   : 35
> >>>>    <50m   :156     2-10m  : 27
> >>>>    10-20m :156     20-30m : 23
> >>>>    20-30m : 91     30-40m : 16
> >>>>    40-50m : 57     10-20m : 13
> >>>>    **(Other): 82   (Other): 18**
> >>>>
> >>>> I have checked my data sheet over and over again and I think
> >>> standardised the data, but the issue keeps arising. I'm assuming I need
> >> to
> >>> clean the data set but as a nearly complete novice in R I am not
> certain
> >>> how to do this. Any help at all with this would be much appreciated.
> >> Thanks
> >>> so much.
> >>>>
> >>>> Kind Regards,
> >>>>
> >>>> Tara Adcock.
> >>>>
> >>>>
> >>>>      [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Jun  1 19:45:35 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 1 Jun 2017 10:45:35 -0700
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
Message-ID: <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>

How about this:

f <- function(a,wh){ ## a is the array; wh is the index to be reversed
   l<- lapply(dim(a),seq_len)
   l[[wh]]<- rev(l[[wh]])
   do.call(`[`,c(list(a),l))
}

## test
z <- array(1:120,dim=2:5)

##  I omit the printouts

f(z,2)

f(z,3)


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Hi All:
>
> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
>
> A simplified idea is I have an array, say:
>
> junk(5, 10, 3)
>
> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
>
> junk1 <- junk[, rev(seq_len(10), ]
>
> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
>
> For example,  if i try:
>
> junk1 <- apply(junk, 2, rev)
>
> junk1 comes out as two-dimensional,  not three-dimensional.
>
> It is probably something obvious but I am not getting it.
>
> Thanks for any help.
>
> -Roy
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Thu Jun  1 19:50:30 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 1 Jun 2017 10:50:30 -0700
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
Message-ID: <C843A34F-4661-43A0-BCDA-ECE1EBB769D9@noaa.gov>

Thank you very much.  I have a little test example I have been working with,  and it does seem to work.    I will have to go through and parse this to understand what you are doing

What I had been doing is building up a string with the arguments and calling it,  it works but very kludgy and very fragile.

Thanks again.

-Roy


> On Jun 1, 2017, at 10:45 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> How about this:
> 
> f <- function(a,wh){ ## a is the array; wh is the index to be reversed
>   l<- lapply(dim(a),seq_len)
>   l[[wh]]<- rev(l[[wh]])
>   do.call(`[`,c(list(a),l))
> }
> 
> ## test
> z <- array(1:120,dim=2:5)
> 
> ##  I omit the printouts
> 
> f(z,2)
> 
> f(z,3)
> 
> 
> Cheers,
> Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
> <roy.mendelssohn at noaa.gov> wrote:
>> Hi All:
>> 
>> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
>> 
>> A simplified idea is I have an array, say:
>> 
>> junk(5, 10, 3)
>> 
>> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
>> 
>> junk1 <- junk[, rev(seq_len(10), ]
>> 
>> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
>> 
>> For example,  if i try:
>> 
>> junk1 <- apply(junk, 2, rev)
>> 
>> junk1 comes out as two-dimensional,  not three-dimensional.
>> 
>> It is probably something obvious but I am not getting it.
>> 
>> Thanks for any help.
>> 
>> -Roy
>> 
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From b88207001 at ntu.edu.tw  Thu Jun  1 20:07:49 2017
From: b88207001 at ntu.edu.tw (b88207001 at ntu.edu.tw)
Date: Fri, 02 Jun 2017 02:07:49 +0800
Subject: [R] Problem of a function I wrote
Message-ID: <20170602020749.6993544krwgplrlh@wmail1.cc.ntu.edu.tw>

Hello everyone,

I have been working on a code which simply repeatedly appends a number  
into a vector and write a file. However, it could not be properly  
implemented when I use it. It works when I run it line by line. I  
wonder what is the problem and I appreciate anyone who is willing to  
help.

The function and the example code is attached. Any advice is appreciated!

Best,
Yen

From b88207001 at ntu.edu.tw  Thu Jun  1 20:10:54 2017
From: b88207001 at ntu.edu.tw (b88207001 at ntu.edu.tw)
Date: Fri, 02 Jun 2017 02:10:54 +0800
Subject: [R] Problem of a function I wrote
In-Reply-To: <20170602020749.6993544krwgplrlh@wmail1.cc.ntu.edu.tw>
References: <20170602020749.6993544krwgplrlh@wmail1.cc.ntu.edu.tw>
Message-ID: <20170602021054.15087etgivvgoqlq@wmail1.cc.ntu.edu.tw>

Hello everyone,

It seems that I was not successfully attached the code. Here is the  
code. I appreciate any help!

Best,
Yen

?? b88207001 at ntu.edu.tw:

> Hello everyone,
>
> I have been working on a code which simply repeatedly appends a  
> number into a vector and write a file. However, it could not be  
> properly implemented when I use it. It works when I run it line by  
> line. I wonder what is the problem and I appreciate anyone who is  
> willing to help.
>
> The function and the example code is attached. Any advice is appreciated!
>
> Best,
> Yen
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From b88207001 at ntu.edu.tw  Thu Jun  1 20:23:49 2017
From: b88207001 at ntu.edu.tw (b88207001 at ntu.edu.tw)
Date: Fri, 02 Jun 2017 02:23:49 +0800
Subject: [R] Problem of a function I wrote
In-Reply-To: <20170602021054.15087etgivvgoqlq@wmail1.cc.ntu.edu.tw>
References: <20170602020749.6993544krwgplrlh@wmail1.cc.ntu.edu.tw>
 <20170602021054.15087etgivvgoqlq@wmail1.cc.ntu.edu.tw>
Message-ID: <20170602022349.28714v1wv4gsjhkl@wmail1.cc.ntu.edu.tw>

Hello everyone,

I know where is wrong. I forget to specify the parameters in my  
function. Thank you for anyone who was trying to help me!

Best,
Yen

?? b88207001 at ntu.edu.tw:

> Hello everyone,
>
> It seems that I was not successfully attached the code. Here is the  
> code. I appreciate any help!
>
> Best,
> Yen
>
> ?? b88207001 at ntu.edu.tw:
>
>> Hello everyone,
>>
>> I have been working on a code which simply repeatedly appends a  
>> number into a vector and write a file. However, it could not be  
>> properly implemented when I use it. It works when I run it line by  
>> line. I wonder what is the problem and I appreciate anyone who is  
>> willing to help.
>>
>> The function and the example code is attached. Any advice is appreciated!
>>
>> Best,
>> Yen
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Jun  1 20:31:58 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 1 Jun 2017 11:31:58 -0700 (PDT)
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
Message-ID: <alpine.BSF.2.00.1706011129050.44043@pedal.dcn.davis.ca.us>

Not sure it is "obvious", but this function implements what you describe:

revdim <- function( a, d ) {
    dims <- attr( a, "dim" )
    idxs <- lapply( seq_along( dims )
                  , function( dd ) {
                      if ( d == dd ) seq.int( dims[ dd ], 1, -1 )
                      else seq.int( dims[ dd ] )
                    }
                  )
    do.call( `[`, c( list( a ), idxs ) )
}

revdim( junk1, 2 )

On Thu, 1 Jun 2017, Roy Mendelssohn - NOAA Federal wrote:

> Hi All:
>
> I have been looking for an elegant way to do the following, but haven't 
> found it, I have never had a good understanding of any of the "apply" 
> functions.
>
> A simplified idea is I have an array, say:
>
> junk(5, 10, 3)
>
> where (5, 10, 3) give the dimension sizes, and I want to reverse the 
> second dimension, so I could do:
>
> junk1 <- junk[, rev(seq_len(10), ]
>
> but what I am after is a general function that will do that where the 
> array could be two, three or four dimensions, and I pass to the function 
> which dimension I want to reverse, that is the function can not assume 
> the number of dimensions of the array nor which dimension to reverse.
>
> For example,  if i try:
>
> junk1 <- apply(junk, 2, rev)
>
> junk1 comes out as two-dimensional,  not three-dimensional.
>
> It is probably something obvious but I am not getting it.
>
> Thanks for any help.
>
> -Roy
>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From dcarlson at tamu.edu  Thu Jun  1 20:34:36 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 1 Jun 2017 18:34:36 +0000
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
Message-ID: <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>

Here is an alternative approach using apply(). Note that with apply() you are reversing rows or columns not indices of rows or columns so apply(junk, 2, rev) reverses the values in each column not the column indices. We actually need to use rev() on everything but the index we are interested in reversing:

f2 <- function(a, wh) {
    dims <- seq_len(length(dim(a)))
    dims <- setdiff(dims, wh)
    apply(apply(a, dims, rev), dims, t)
}

# Your example
j1 <- junk[ , rev(1:10), ]
j2 <- f2(junk, 2)
all.equal(j1, j2)
# [1] TRUE

# Bert's example
z1 <- f(z, 2)
z2 <- f2(z, 2)
all.equal(z1, z2)
# [1] TRUE

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352






-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Thursday, June 1, 2017 12:46 PM
To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Reversing one dimension of an array, in a generalized case

How about this:

f <- function(a,wh){ ## a is the array; wh is the index to be reversed
   l<- lapply(dim(a),seq_len)
   l[[wh]]<- rev(l[[wh]])
   do.call(`[`,c(list(a),l))
}

## test
z <- array(1:120,dim=2:5)

##  I omit the printouts

f(z,2)

f(z,3)


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Hi All:
>
> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
>
> A simplified idea is I have an array, say:
>
> junk(5, 10, 3)
>
> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
>
> junk1 <- junk[, rev(seq_len(10), ]
>
> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
>
> For example,  if i try:
>
> junk1 <- apply(junk, 2, rev)
>
> junk1 comes out as two-dimensional,  not three-dimensional.
>
> It is probably something obvious but I am not getting it.
>
> Thanks for any help.
>
> -Roy
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Jun  1 21:00:27 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 1 Jun 2017 12:00:27 -0700
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
 <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>

??

> z <- array(1:24,dim=2:4)
> all.equal(f(z,3),f2(z,3))

[1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
[2] "Mean relative difference: 0.6109091"

In fact,

> dim(f(z,3))
[1] 2 3 4

> dim(f2(z,3))
[1] 3 4 2

Have I made some sort of stupid error here? Or have I misunderstood
what was wanted?

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 1, 2017 at 11:34 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> Here is an alternative approach using apply(). Note that with apply() you are reversing rows or columns not indices of rows or columns so apply(junk, 2, rev) reverses the values in each column not the column indices. We actually need to use rev() on everything but the index we are interested in reversing:
>
> f2 <- function(a, wh) {
>     dims <- seq_len(length(dim(a)))
>     dims <- setdiff(dims, wh)
>     apply(apply(a, dims, rev), dims, t)
> }
>
> # Your example
> j1 <- junk[ , rev(1:10), ]
> j2 <- f2(junk, 2)
> all.equal(j1, j2)
> # [1] TRUE
>
> # Bert's example
> z1 <- f(z, 2)
> z2 <- f2(z, 2)
> all.equal(z1, z2)
> # [1] TRUE
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
> Sent: Thursday, June 1, 2017 12:46 PM
> To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>
> How about this:
>
> f <- function(a,wh){ ## a is the array; wh is the index to be reversed
>    l<- lapply(dim(a),seq_len)
>    l[[wh]]<- rev(l[[wh]])
>    do.call(`[`,c(list(a),l))
> }
>
> ## test
> z <- array(1:120,dim=2:5)
>
> ##  I omit the printouts
>
> f(z,2)
>
> f(z,3)
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
> <roy.mendelssohn at noaa.gov> wrote:
>> Hi All:
>>
>> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
>>
>> A simplified idea is I have an array, say:
>>
>> junk(5, 10, 3)
>>
>> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
>>
>> junk1 <- junk[, rev(seq_len(10), ]
>>
>> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
>>
>> For example,  if i try:
>>
>> junk1 <- apply(junk, 2, rev)
>>
>> junk1 comes out as two-dimensional,  not three-dimensional.
>>
>> It is probably something obvious but I am not getting it.
>>
>> Thanks for any help.
>>
>> -Roy
>>
>>
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Thu Jun  1 21:10:23 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 1 Jun 2017 19:10:23 +0000
Subject: [R] [spatstat] Convert shapefile to pixel image
In-Reply-To: <1188522651hurgil@uv.es>
References: <1188522651hurgil@uv.es>
Message-ID: <09612F69-7BB1-4F17-B1E4-10AFDE6CA14D@llnl.gov>

This looks like to would be better to ask on R-sig-geo, instead of R-help.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 6/1/17, 6:17 AM, "R-help on behalf of Lluis.Hurtado at uv.es" <r-help-bounces at r-project.org on behalf of Lluis.Hurtado at uv.es> wrote:

    Dear all,
    
    I am currently working with the spatstat package, using windows and pixel images.
    
    First:
    
    My aim is to transform a shapefile (see attached) into a pixel image. 
    
    My idea is to start transforming the shapefile into a Spatial Polygon file:
    
    x <- readShapeSpatial("200001441.shp")
    y <- as(x, "SpatialPolygons")
    z <- as.owin(y)
    
    Given z, I want to identify each polygon with a single constant value. This is like adding marks to the SpatialPolygons file. Then I want to convert these polygons into an image, such that the value of each pixel corresponds to the value associated to the polygon where the pixel lies. 
    
    I have been able to do this individually, polygon by polygon, but then I cannot merge the resulting images into a single one. Any idea?
    
    Second:
    
    I would also need a single window containing all the smallest polygons (the boundary). I have tried:
    
    w <- union.owin(z)
    
    But the resulting window w still shows internal polygons. As read in spatstas FAQ page:
    
    "First, convert each of the regions into a separate owin object. Then apply union.owin to combine them."
    
    So I try,
    
    regions <- slot(y, "polygons")
    regions <- lapply(regions, function(x) { SpatialPolygons(list(x)) })
    windows <- lapply(regions, as.owin) 
    
    But windows is a list of 4307 polygons. How can introduce all of them as a single argument?
    
    > M <- union.owin(windows)
    Warning messages:
    1: In union.owin(windows) : Some arguments were not windows
    2: In union.owin(windows) : No windows were given
    
    
    Thank you very much for you help.
    
    Llu?s Hurtado.
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Jun  1 21:22:34 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 1 Jun 2017 19:22:34 +0000
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
 <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>
 <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>
Message-ID: <cf79d71578544504baf432288731b39c@exch-2p-mbx-w2.ads.tamu.edu>

My error. Clearly I did not do enough testing.

z <- array(1:24,dim=2:4)
> all.equal(f(z,1),f2(z,1))
[1] TRUE
> all.equal(f(z,2),f2(z,2))
[1] TRUE
> all.equal(f(z,3),f2(z,3))
[1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
[2] "Mean relative difference: 0.6109091"    

# Your earlier example
> z <- array(1:120, dim=2:5)
> all.equal(f(z,1),f2(z,1))
[1] TRUE
> all.equal(f(z,2),f2(z,2))
[1] TRUE
> all.equal(f(z,3),f2(z,3))
[1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
[2] "Mean relative difference: 0.1262209"                                 
> all.equal(f(z,4),f2(z,4))
[1] "Attributes: < Component ?dim?: Mean relative difference: 0.5714286 >"
[2] "Mean relative difference: 0.5855162"  

David C

-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Thursday, June 1, 2017 2:00 PM
To: David L Carlson <dcarlson at tamu.edu>
Cc: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>; R-help <r-help at r-project.org>
Subject: Re: [R] Reversing one dimension of an array, in a generalized case

??

> z <- array(1:24,dim=2:4)
> all.equal(f(z,3),f2(z,3))

[1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
[2] "Mean relative difference: 0.6109091"

In fact,

> dim(f(z,3))
[1] 2 3 4

> dim(f2(z,3))
[1] 3 4 2

Have I made some sort of stupid error here? Or have I misunderstood
what was wanted?

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 1, 2017 at 11:34 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> Here is an alternative approach using apply(). Note that with apply() you are reversing rows or columns not indices of rows or columns so apply(junk, 2, rev) reverses the values in each column not the column indices. We actually need to use rev() on everything but the index we are interested in reversing:
>
> f2 <- function(a, wh) {
>     dims <- seq_len(length(dim(a)))
>     dims <- setdiff(dims, wh)
>     apply(apply(a, dims, rev), dims, t)
> }
>
> # Your example
> j1 <- junk[ , rev(1:10), ]
> j2 <- f2(junk, 2)
> all.equal(j1, j2)
> # [1] TRUE
>
> # Bert's example
> z1 <- f(z, 2)
> z2 <- f2(z, 2)
> all.equal(z1, z2)
> # [1] TRUE
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
> Sent: Thursday, June 1, 2017 12:46 PM
> To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>
> How about this:
>
> f <- function(a,wh){ ## a is the array; wh is the index to be reversed
>    l<- lapply(dim(a),seq_len)
>    l[[wh]]<- rev(l[[wh]])
>    do.call(`[`,c(list(a),l))
> }
>
> ## test
> z <- array(1:120,dim=2:5)
>
> ##  I omit the printouts
>
> f(z,2)
>
> f(z,3)
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
> <roy.mendelssohn at noaa.gov> wrote:
>> Hi All:
>>
>> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
>>
>> A simplified idea is I have an array, say:
>>
>> junk(5, 10, 3)
>>
>> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
>>
>> junk1 <- junk[, rev(seq_len(10), ]
>>
>> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
>>
>> For example,  if i try:
>>
>> junk1 <- apply(junk, 2, rev)
>>
>> junk1 comes out as two-dimensional,  not three-dimensional.
>>
>> It is probably something obvious but I am not getting it.
>>
>> Thanks for any help.
>>
>> -Roy
>>
>>
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From hannah.hlx at gmail.com  Thu Jun  1 21:38:14 2017
From: hannah.hlx at gmail.com (li li)
Date: Thu, 1 Jun 2017 15:38:14 -0400
Subject: [R] [FORGED] Re: Question on function "scatterplot3d"
In-Reply-To: <8cadf1fe-d049-d9b7-2e1e-a01b51602027@statistik.tu-dortmund.de>
References: <CAHLnndZ-TKNQdMaLUca-CYOUD-YKZKvYDvy==Ne8a9+aeZvpqA@mail.gmail.com>
 <7945E490-A6BC-48A2-964B-DEA0F7C30431@gmail.com>
 <c4d356d5-3761-29c0-91c0-ea86339c02c2@auckland.ac.nz>
 <e7be3632-32dc-85e0-63b4-4e2d0b8adb68@statistik.tu-dortmund.de>
 <948df1a1-57c7-6dad-4475-b2d99e5dd527@auckland.ac.nz>
 <8cadf1fe-d049-d9b7-2e1e-a01b51602027@statistik.tu-dortmund.de>
Message-ID: <CAHLnndYeFn=vdORSTJ6sk_jJSH8xoJSEaFZw-28640xNGrbbkQ@mail.gmail.com>

Thanks so much for the help!!
   Hanna


2017-06-01 11:02 GMT-04:00 Uwe Ligges <ligges at statistik.tu-dortmund.de>:

>
>
> On 01.06.2017 10:03, Rolf Turner wrote:
>
>> On 01/06/17 19:54, Uwe Ligges wrote:
>>
>>> A design flaw, whether the labels are cut depends somewhat on the sizce
>>> of the device, hence there is the argument
>>>
>>> y.margin.add
>>>
>>> add additional space between tick mark labels and axis label of the y
>>> axis
>>>
>>> for working around that limittation that can be set to some positive
>>> value....
>>>
>>
>>
>> This seems to be addressing Hannah's (li li's) original enquiry, not my
>> follow-up in which I worried about the position, along the y-axis, of the
>> y-axis label.
>>
>
> Ah, that is intended as a smart way of rotating it along the axis is not
> easy (if not impossible) with the bas egraohics system.
>
> Best,
> Uwe Ligges
>
>
>
>
>> Or am I misunderstanding/missing something?
>>
>> cheers,
>>
>> Rolf
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Thu Jun  1 21:40:01 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Thu, 1 Jun 2017 22:40:01 +0300
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
 <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>
 <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>
Message-ID: <BA9A9722-3CC1-4C8D-A500-178C7EE48013@gmail.com>

And my 2 cents,

Rev <- function(x, margin) {
    newdim <- rep("", length(dim(x)))
    newdim[margin] <- paste(dim(x), ":1", sep = "")[margin]
    z <- eval(parse(text = gettextf("x[%s,drop = F]", paste(newdim, sep = "",
                                                            collapse = ","))))
    class(z) <- oldClass(x)
    return(z)
}

z <- array(1:24,dim=2:4)
dim(f(z, 3)) # 2 3 4
dim(f2(z, 3)) # 3 4 2
dim(Rev(z, 3)) # 2 3 4
dim(revdim(z,3)) # 2 3 4

microbenchmark::microbenchmark(f(z, 3), Rev(z, 3), revdim(z,3), f2(z,3))

Unit: microseconds
         expr     min       lq      mean   median       uq     max neval
      f(z, 3)   6.356   7.6090   9.74268   9.3285  11.2325  35.571   100
    Rev(z, 3) 161.079 166.9660 175.26906 172.1450 176.8130 273.078   100
 revdim(z, 3)   5.011   6.1300   7.88565   7.5695   9.0500  21.301   100
     f2(z, 3)  68.454  71.6815  82.85703  81.6700  87.9285 126.496   100

and strangely,

all.equal(f(z, 3), Rev(z, 3), revdim(z,3), f2(z,3))
[1] TRUE

?

> On 1 Jun 2017, at 22:00, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ??
> 
>> z <- array(1:24,dim=2:4)
>> all.equal(f(z,3),f2(z,3))
> 
> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
> [2] "Mean relative difference: 0.6109091"
> 
> In fact,
> 
>> dim(f(z,3))
> [1] 2 3 4
> 
>> dim(f2(z,3))
> [1] 3 4 2
> 
> Have I made some sort of stupid error here? Or have I misunderstood
> what was wanted?
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Jun 1, 2017 at 11:34 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> Here is an alternative approach using apply(). Note that with apply() you are reversing rows or columns not indices of rows or columns so apply(junk, 2, rev) reverses the values in each column not the column indices. We actually need to use rev() on everything but the index we are interested in reversing:
>> 
>> f2 <- function(a, wh) {
>>    dims <- seq_len(length(dim(a)))
>>    dims <- setdiff(dims, wh)
>>    apply(apply(a, dims, rev), dims, t)
>> }
>> 
>> # Your example
>> j1 <- junk[ , rev(1:10), ]
>> j2 <- f2(junk, 2)
>> all.equal(j1, j2)
>> # [1] TRUE
>> 
>> # Bert's example
>> z1 <- f(z, 2)
>> z2 <- f2(z, 2)
>> all.equal(z1, z2)
>> # [1] TRUE
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> 
>> 
>> 
>> 
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
>> Sent: Thursday, June 1, 2017 12:46 PM
>> To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
>> Cc: R-help <r-help at r-project.org>
>> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>> 
>> How about this:
>> 
>> f <- function(a,wh){ ## a is the array; wh is the index to be reversed
>>   l<- lapply(dim(a),seq_len)
>>   l[[wh]]<- rev(l[[wh]])
>>   do.call(`[`,c(list(a),l))
>> }
>> 
>> ## test
>> z <- array(1:120,dim=2:5)
>> 
>> ##  I omit the printouts
>> 
>> f(z,2)
>> 
>> f(z,3)
>> 
>> 
>> Cheers,
>> Bert
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
>> <roy.mendelssohn at noaa.gov> wrote:
>>> Hi All:
>>> 
>>> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
>>> 
>>> A simplified idea is I have an array, say:
>>> 
>>> junk(5, 10, 3)
>>> 
>>> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
>>> 
>>> junk1 <- junk[, rev(seq_len(10), ]
>>> 
>>> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
>>> 
>>> For example,  if i try:
>>> 
>>> junk1 <- apply(junk, 2, rev)
>>> 
>>> junk1 comes out as two-dimensional,  not three-dimensional.
>>> 
>>> It is probably something obvious but I am not getting it.
>>> 
>>> Thanks for any help.
>>> 
>>> -Roy
>>> 
>>> 
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> ***Note new street address***
>>> 110 McAllister Way
>>> Santa Cruz, CA 95060
>>> Phone: (831)-420-3666
>>> Fax: (831) 420-3980
>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>> 
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected"
>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Thu Jun  1 21:42:39 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 1 Jun 2017 12:42:39 -0700
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <cf79d71578544504baf432288731b39c@exch-2p-mbx-w2.ads.tamu.edu>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
 <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>
 <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>
 <cf79d71578544504baf432288731b39c@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <F4A29415-0F72-4EBF-A960-DC9195722A63@noaa.gov>

Thanks to all for responses/.  There was a question of exactly what was wanted.  It is the generalization of the obvious example I gave,  

>>> junk1 <- junk[, rev(seq_len(10), ]


so that

junk[1,1,1 ] = junk1[1,10,1]
junk[1,2,1]  = junk1[1,9,1]

etc.

The genesis of this is the program is downloading data from a variety of sources on (time, altitude, lat, lon) coordinates,  but all the coordinates are not always there, and sometime the latitude coordinates go from north to south and sometimes from south to north.  I want to always return the data going from south to north, so if I find that the data is north to south,  I have to first reverse the array with the coordinate values (easy enough),  and then reverse the one dimension in the data array that corresponds to latitude. The downloaded information tells me which dimension is latitude plus how many coordinates are in the data.

As I the said,  I haven't done extensive testing on what Bert sent,  but on a toy 3-dimensional example I have it appeared to do what I want.

Thanks again,

-Roy

> On Jun 1, 2017, at 12:22 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> My error. Clearly I did not do enough testing.
> 
> z <- array(1:24,dim=2:4)
>> all.equal(f(z,1),f2(z,1))
> [1] TRUE
>> all.equal(f(z,2),f2(z,2))
> [1] TRUE
>> all.equal(f(z,3),f2(z,3))
> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
> [2] "Mean relative difference: 0.6109091"    
> 
> # Your earlier example
>> z <- array(1:120, dim=2:5)
>> all.equal(f(z,1),f2(z,1))
> [1] TRUE
>> all.equal(f(z,2),f2(z,2))
> [1] TRUE
>> all.equal(f(z,3),f2(z,3))
> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
> [2] "Mean relative difference: 0.1262209"                                 
>> all.equal(f(z,4),f2(z,4))
> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.5714286 >"
> [2] "Mean relative difference: 0.5855162"  
> 
> David C
> 
> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
> Sent: Thursday, June 1, 2017 2:00 PM
> To: David L Carlson <dcarlson at tamu.edu>
> Cc: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>; R-help <r-help at r-project.org>
> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
> 
> ??
> 
>> z <- array(1:24,dim=2:4)
>> all.equal(f(z,3),f2(z,3))
> 
> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
> [2] "Mean relative difference: 0.6109091"
> 
> In fact,
> 
>> dim(f(z,3))
> [1] 2 3 4
> 
>> dim(f2(z,3))
> [1] 3 4 2
> 
> Have I made some sort of stupid error here? Or have I misunderstood
> what was wanted?
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Jun 1, 2017 at 11:34 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> Here is an alternative approach using apply(). Note that with apply() you are reversing rows or columns not indices of rows or columns so apply(junk, 2, rev) reverses the values in each column not the column indices. We actually need to use rev() on everything but the index we are interested in reversing:
>> 
>> f2 <- function(a, wh) {
>>    dims <- seq_len(length(dim(a)))
>>    dims <- setdiff(dims, wh)
>>    apply(apply(a, dims, rev), dims, t)
>> }
>> 
>> # Your example
>> j1 <- junk[ , rev(1:10), ]
>> j2 <- f2(junk, 2)
>> all.equal(j1, j2)
>> # [1] TRUE
>> 
>> # Bert's example
>> z1 <- f(z, 2)
>> z2 <- f2(z, 2)
>> all.equal(z1, z2)
>> # [1] TRUE
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> 
>> 
>> 
>> 
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
>> Sent: Thursday, June 1, 2017 12:46 PM
>> To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
>> Cc: R-help <r-help at r-project.org>
>> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>> 
>> How about this:
>> 
>> f <- function(a,wh){ ## a is the array; wh is the index to be reversed
>>   l<- lapply(dim(a),seq_len)
>>   l[[wh]]<- rev(l[[wh]])
>>   do.call(`[`,c(list(a),l))
>> }
>> 
>> ## test
>> z <- array(1:120,dim=2:5)
>> 
>> ##  I omit the printouts
>> 
>> f(z,2)
>> 
>> f(z,3)
>> 
>> 
>> Cheers,
>> Bert
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
>> <roy.mendelssohn at noaa.gov> wrote:
>>> Hi All:
>>> 
>>> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
>>> 
>>> A simplified idea is I have an array, say:
>>> 
>>> junk(5, 10, 3)
>>> 
>>> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
>>> 
>>> junk1 <- junk[, rev(seq_len(10), ]
>>> 
>>> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
>>> 
>>> For example,  if i try:
>>> 
>>> junk1 <- apply(junk, 2, rev)
>>> 
>>> junk1 comes out as two-dimensional,  not three-dimensional.
>>> 
>>> It is probably something obvious but I am not getting it.
>>> 
>>> Thanks for any help.
>>> 
>>> -Roy
>>> 
>>> 
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> ***Note new street address***
>>> 110 McAllister Way
>>> Santa Cruz, CA 95060
>>> Phone: (831)-420-3666
>>> Fax: (831) 420-3980
>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>> 
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected"
>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From msuzen at gmail.com  Thu Jun  1 21:51:34 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Thu, 1 Jun 2017 21:51:34 +0200
Subject: [R] Latin Hypercube Sampling when parameters are defined
 according to specific probability distributions
In-Reply-To: <CAGxFJbRAP3FAX9i0G=5utqSFy=QVXcVOhUTTGHhEoK39+FLWQQ@mail.gmail.com>
References: <CAPtunJZJ0HpZGGaNjpfbHL_bMxHeACJ21kzpP2Zv1+qtcnTMhg@mail.gmail.com>
 <CY1PR05MB2730F1E421CF600D3A9890E799F00@CY1PR05MB2730.namprd05.prod.outlook.com>
 <CAPtunJae1UcgrsOyS8+98BHT0E5ysnbmKumWj0zX8jOts+TsAg@mail.gmail.com>
 <CY1PR05MB27308D07F399184179D83EB499F60@CY1PR05MB2730.namprd05.prod.outlook.com>
 <CAGxFJbRAP3FAX9i0G=5utqSFy=QVXcVOhUTTGHhEoK39+FLWQQ@mail.gmail.com>
Message-ID: <CAPtbhHzTYJm7yf0ODHRsECYgasAExPqFpWhjk5D=Nw+wNsbLxg@mail.gmail.com>

No it is an R programming questions.  Nelly specifically asked you:

"how can I use your code to apply my model to each of the 50 rows of
the data frame ?tabLHS??"


From paul at stat.auckland.ac.nz  Thu Jun  1 21:56:02 2017
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 2 Jun 2017 07:56:02 +1200
Subject: [R] [FORGED]  How to create my own grDevices using java
In-Reply-To: <HK2PR0401MB1427F8D4433C522AE1D22107B5F10@HK2PR0401MB1427.apcprd04.prod.outlook.com>
References: <HK2PR0401MB1427F8D4433C522AE1D22107B5F10@HK2PR0401MB1427.apcprd04.prod.outlook.com>
Message-ID: <b5362990-0698-5610-c91a-06e54750330c@stat.auckland.ac.nz>

Hi

The 'RGraphicsDevice' package might be useful for this job.

http://www.omegahat.net/RGraphicsDevice/

Paul

On 01/06/17 07:09, Peter Cheung wrote:
> Hi All
> 
>     How to create my own grDevices using java, so that i can display the graphic from plot() in my java software?
> 
> thanks
> 
> from Peter
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From hannah.hlx at gmail.com  Thu Jun  1 22:10:03 2017
From: hannah.hlx at gmail.com (li li)
Date: Thu, 1 Jun 2017 16:10:03 -0400
Subject: [R] subletting an array according to dimnames
Message-ID: <CAHLnnda7opQRKukczBFuJMCAaoSK75eAuxvWksKiiSjYpdb8+Q@mail.gmail.com>

Hi all,
  I have a three dimensional array with the corresponding dimension names.
I would like to subset the array according to the dimension names. For
example,
suppose I want to extract the values corresponding to A=20, B=10, C=0.  I
know I
can do:
 P2[dimnames(P2)$A==20, dimnames(P2)$B==10, dimnames(P2)$C==0]

But is there a better way for doing this? Thanks for your help!
  Hanna

> dimnames(P2)

$A

[1] "20" "25" "30" "35" "40"


$B

[1] "5"  "10" "15" "20" "25" "30" "35" "40"


$C

[1] "0"  "5" "10" "15" "20" "25" "30" "35"

	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Thu Jun  1 22:35:29 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Thu, 1 Jun 2017 23:35:29 +0300
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <F4A29415-0F72-4EBF-A960-DC9195722A63@noaa.gov>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
 <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>
 <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>
 <cf79d71578544504baf432288731b39c@exch-2p-mbx-w2.ads.tamu.edu>
 <F4A29415-0F72-4EBF-A960-DC9195722A63@noaa.gov>
Message-ID: <C26CA739-162D-4F37-B203-84D1A8A97B02@gmail.com>


> On 1 Jun 2017, at 22:42, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> Thanks to all for responses/.  There was a question of exactly what was wanted.  It is the generalization of the obvious example I gave,  
> 
>>>> junk1 <- junk[, rev(seq_len(10), ]
> 
> 
> so that
> 
> junk[1,1,1 ] = junk1[1,10,1]
> junk[1,2,1]  = junk1[1,9,1]
> 
> etc.
> 
> The genesis of this is the program is downloading data from a variety of sources on (time, altitude, lat, lon) coordinates,  but all the coordinates are not always there, and sometime the latitude coordinates go from north to south and sometimes from south to north.  I want to always return the data going from south to north, so if I find that the data is north to south,  I have to first reverse the array with the coordinate values (easy enough),  and then reverse the one dimension in the data array that corresponds to latitude. The downloaded information tells me which dimension is latitude plus how many coordinates are in the data.

Hello Roy,
Perhaps you are aware of but I want to mention anyway. Basic issue is that you always want latitudes are monotonously increasing. Let me tell what I do when I read a ncdf file:

1- Set latitudes always monotonously decreasing (from 90 to -90)
2- Set longitudes always mononously increasing but from -180 to 180.
3- Set levels always monotonously decreasing (this is not relevant)

Why? If you plan to plot variables in R, you will need coordinates in this order. For instance, if you set latitudes monotonously increasing, your map will be plotted upside down. To fix this, you will need reverse dimension again. And also if your longitudes ranges from 0 to 360, you will see the only the east side of the plot on a world map. West of Greencwich will be empty.  They were the problems that I faced last year when I tried to plot netcdf files using lattice and rasterVis packages. 


> 
> As I the said,  I haven't done extensive testing on what Bert sent,  but on a toy 3-dimensional example I have it appeared to do what I want.
> 
> Thanks again,
> 
> -Roy
> 
>> On Jun 1, 2017, at 12:22 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> 
>> My error. Clearly I did not do enough testing.
>> 
>> z <- array(1:24,dim=2:4)
>>> all.equal(f(z,1),f2(z,1))
>> [1] TRUE
>>> all.equal(f(z,2),f2(z,2))
>> [1] TRUE
>>> all.equal(f(z,3),f2(z,3))
>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
>> [2] "Mean relative difference: 0.6109091"    
>> 
>> # Your earlier example
>>> z <- array(1:120, dim=2:5)
>>> all.equal(f(z,1),f2(z,1))
>> [1] TRUE
>>> all.equal(f(z,2),f2(z,2))
>> [1] TRUE
>>> all.equal(f(z,3),f2(z,3))
>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
>> [2] "Mean relative difference: 0.1262209"                                 
>>> all.equal(f(z,4),f2(z,4))
>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.5714286 >"
>> [2] "Mean relative difference: 0.5855162"  
>> 
>> David C
>> 
>> -----Original Message-----
>> From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
>> Sent: Thursday, June 1, 2017 2:00 PM
>> To: David L Carlson <dcarlson at tamu.edu>
>> Cc: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>; R-help <r-help at r-project.org>
>> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>> 
>> ??
>> 
>>> z <- array(1:24,dim=2:4)
>>> all.equal(f(z,3),f2(z,3))
>> 
>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
>> [2] "Mean relative difference: 0.6109091"
>> 
>> In fact,
>> 
>>> dim(f(z,3))
>> [1] 2 3 4
>> 
>>> dim(f2(z,3))
>> [1] 3 4 2
>> 
>> Have I made some sort of stupid error here? Or have I misunderstood
>> what was wanted?
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Thu, Jun 1, 2017 at 11:34 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>>> Here is an alternative approach using apply(). Note that with apply() you are reversing rows or columns not indices of rows or columns so apply(junk, 2, rev) reverses the values in each column not the column indices. We actually need to use rev() on everything but the index we are interested in reversing:
>>> 
>>> f2 <- function(a, wh) {
>>>   dims <- seq_len(length(dim(a)))
>>>   dims <- setdiff(dims, wh)
>>>   apply(apply(a, dims, rev), dims, t)
>>> }
>>> 
>>> # Your example
>>> j1 <- junk[ , rev(1:10), ]
>>> j2 <- f2(junk, 2)
>>> all.equal(j1, j2)
>>> # [1] TRUE
>>> 
>>> # Bert's example
>>> z1 <- f(z, 2)
>>> z2 <- f2(z, 2)
>>> all.equal(z1, z2)
>>> # [1] TRUE
>>> 
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
>>> Sent: Thursday, June 1, 2017 12:46 PM
>>> To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
>>> Cc: R-help <r-help at r-project.org>
>>> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>>> 
>>> How about this:
>>> 
>>> f <- function(a,wh){ ## a is the array; wh is the index to be reversed
>>>  l<- lapply(dim(a),seq_len)
>>>  l[[wh]]<- rev(l[[wh]])
>>>  do.call(`[`,c(list(a),l))
>>> }
>>> 
>>> ## test
>>> z <- array(1:120,dim=2:5)
>>> 
>>> ##  I omit the printouts
>>> 
>>> f(z,2)
>>> 
>>> f(z,3)
>>> 
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
>>> <roy.mendelssohn at noaa.gov> wrote:
>>>> Hi All:
>>>> 
>>>> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
>>>> 
>>>> A simplified idea is I have an array, say:
>>>> 
>>>> junk(5, 10, 3)
>>>> 
>>>> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
>>>> 
>>>> junk1 <- junk[, rev(seq_len(10), ]
>>>> 
>>>> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
>>>> 
>>>> For example,  if i try:
>>>> 
>>>> junk1 <- apply(junk, 2, rev)
>>>> 
>>>> junk1 comes out as two-dimensional,  not three-dimensional.
>>>> 
>>>> It is probably something obvious but I am not getting it.
>>>> 
>>>> Thanks for any help.
>>>> 
>>>> -Roy
>>>> 
>>>> 
>>>> **********************
>>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>>> **********************
>>>> Roy Mendelssohn
>>>> Supervisory Operations Research Analyst
>>>> NOAA/NMFS
>>>> Environmental Research Division
>>>> Southwest Fisheries Science Center
>>>> ***Note new street address***
>>>> 110 McAllister Way
>>>> Santa Cruz, CA 95060
>>>> Phone: (831)-420-3666
>>>> Fax: (831) 420-3980
>>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>>> 
>>>> "Old age and treachery will overcome youth and skill."
>>>> "From those who have been given much, much will be expected"
>>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov <mailto:Roy.Mendelssohn at noaa.gov> www: http://www.pfeg.noaa.gov/ <http://www.pfeg.noaa.gov/>
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Thu Jun  1 22:43:41 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 1 Jun 2017 13:43:41 -0700
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <C26CA739-162D-4F37-B203-84D1A8A97B02@gmail.com>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
 <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>
 <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>
 <cf79d71578544504baf432288731b39c@exch-2p-mbx-w2.ads.tamu.edu>
 <F4A29415-0F72-4EBF-A960-DC9195722A63@noaa.gov>
 <C26CA739-162D-4F37-B203-84D1A8A97B02@gmail.com>
Message-ID: <A42B6366-944F-4745-BCB0-26E052D3881A@noaa.gov>

Thank you.  That ignores certain standards in the communities I work in,  it also ignore the fact that whether I decide to always return increasing or decreasing latitudes,  if the sources aren't consistent,  then I need to reverse some of the data,  no matter which way I decide.

Increasing latitudes  (and longitudes) among other things  have the nice property that the array indices are also increasing in the same way. I do a lot of mapping in R, and a number of the mapping routines actually require you to  "melt" the data to long-form  in which case the order of the latitudes in the array is irrelevant,  as long as the mapping is correct.


-Roy



> On Jun 1, 2017, at 1:35 PM, Ismail SEZEN <sezenismail at gmail.com> wrote:
> 
>> 
>> On 1 Jun 2017, at 22:42, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
>> 
>> Thanks to all for responses/.  There was a question of exactly what was wanted.  It is the generalization of the obvious example I gave,  
>> 
>>>>> junk1 <- junk[, rev(seq_len(10), ]
>> 
>> 
>> so that
>> 
>> junk[1,1,1 ] = junk1[1,10,1]
>> junk[1,2,1]  = junk1[1,9,1]
>> 
>> etc.
>> 
>> The genesis of this is the program is downloading data from a variety of sources on (time, altitude, lat, lon) coordinates,  but all the coordinates are not always there, and sometime the latitude coordinates go from north to south and sometimes from south to north.  I want to always return the data going from south to north, so if I find that the data is north to south,  I have to first reverse the array with the coordinate values (easy enough),  and then reverse the one dimension in the data array that corresponds to latitude. The downloaded information tells me which dimension is latitude plus how many coordinates are in the data.
> 
> Hello Roy,
> Perhaps you are aware of but I want to mention anyway. Basic issue is that you always want latitudes are monotonously increasing. Let me tell what I do when I read a ncdf file:
> 
> 1- Set latitudes always monotonously decreasing (from 90 to -90)
> 2- Set longitudes always mononously increasing but from -180 to 180.
> 3- Set levels always monotonously decreasing (this is not relevant)
> 
> Why? If you plan to plot variables in R, you will need coordinates in this order. For instance, if you set latitudes monotonously increasing, your map will be plotted upside down. To fix this, you will need reverse dimension again. And also if your longitudes ranges from 0 to 360, you will see the only the east side of the plot on a world map. West of Greencwich will be empty.  They were the problems that I faced last year when I tried to plot netcdf files using lattice and rasterVis packages. 
> 
> 
>> 
>> As I the said,  I haven't done extensive testing on what Bert sent,  but on a toy 3-dimensional example I have it appeared to do what I want.
>> 
>> Thanks again,
>> 
>> -Roy
>> 
>>> On Jun 1, 2017, at 12:22 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>> 
>>> My error. Clearly I did not do enough testing.
>>> 
>>> z <- array(1:24,dim=2:4)
>>>> all.equal(f(z,1),f2(z,1))
>>> [1] TRUE
>>>> all.equal(f(z,2),f2(z,2))
>>> [1] TRUE
>>>> all.equal(f(z,3),f2(z,3))
>>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
>>> [2] "Mean relative difference: 0.6109091"    
>>> 
>>> # Your earlier example
>>>> z <- array(1:120, dim=2:5)
>>>> all.equal(f(z,1),f2(z,1))
>>> [1] TRUE
>>>> all.equal(f(z,2),f2(z,2))
>>> [1] TRUE
>>>> all.equal(f(z,3),f2(z,3))
>>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
>>> [2] "Mean relative difference: 0.1262209"                                 
>>>> all.equal(f(z,4),f2(z,4))
>>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.5714286 >"
>>> [2] "Mean relative difference: 0.5855162"  
>>> 
>>> David C
>>> 
>>> -----Original Message-----
>>> From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
>>> Sent: Thursday, June 1, 2017 2:00 PM
>>> To: David L Carlson <dcarlson at tamu.edu>
>>> Cc: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>; R-help <r-help at r-project.org>
>>> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>>> 
>>> ??
>>> 
>>>> z <- array(1:24,dim=2:4)
>>>> all.equal(f(z,3),f2(z,3))
>>> 
>>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
>>> [2] "Mean relative difference: 0.6109091"
>>> 
>>> In fact,
>>> 
>>>> dim(f(z,3))
>>> [1] 2 3 4
>>> 
>>>> dim(f2(z,3))
>>> [1] 3 4 2
>>> 
>>> Have I made some sort of stupid error here? Or have I misunderstood
>>> what was wanted?
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Thu, Jun 1, 2017 at 11:34 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>>>> Here is an alternative approach using apply(). Note that with apply() you are reversing rows or columns not indices of rows or columns so apply(junk, 2, rev) reverses the values in each column not the column indices. We actually need to use rev() on everything but the index we are interested in reversing:
>>>> 
>>>> f2 <- function(a, wh) {
>>>>   dims <- seq_len(length(dim(a)))
>>>>   dims <- setdiff(dims, wh)
>>>>   apply(apply(a, dims, rev), dims, t)
>>>> }
>>>> 
>>>> # Your example
>>>> j1 <- junk[ , rev(1:10), ]
>>>> j2 <- f2(junk, 2)
>>>> all.equal(j1, j2)
>>>> # [1] TRUE
>>>> 
>>>> # Bert's example
>>>> z1 <- f(z, 2)
>>>> z2 <- f2(z, 2)
>>>> all.equal(z1, z2)
>>>> # [1] TRUE
>>>> 
>>>> -------------------------------------
>>>> David L Carlson
>>>> Department of Anthropology
>>>> Texas A&M University
>>>> College Station, TX 77840-4352
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
>>>> Sent: Thursday, June 1, 2017 12:46 PM
>>>> To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
>>>> Cc: R-help <r-help at r-project.org>
>>>> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>>>> 
>>>> How about this:
>>>> 
>>>> f <- function(a,wh){ ## a is the array; wh is the index to be reversed
>>>>  l<- lapply(dim(a),seq_len)
>>>>  l[[wh]]<- rev(l[[wh]])
>>>>  do.call(`[`,c(list(a),l))
>>>> }
>>>> 
>>>> ## test
>>>> z <- array(1:120,dim=2:5)
>>>> 
>>>> ##  I omit the printouts
>>>> 
>>>> f(z,2)
>>>> 
>>>> f(z,3)
>>>> 
>>>> 
>>>> Cheers,
>>>> Bert
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> 
>>>> On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
>>>> <roy.mendelssohn at noaa.gov> wrote:
>>>>> Hi All:
>>>>> 
>>>>> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
>>>>> 
>>>>> A simplified idea is I have an array, say:
>>>>> 
>>>>> junk(5, 10, 3)
>>>>> 
>>>>> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
>>>>> 
>>>>> junk1 <- junk[, rev(seq_len(10), ]
>>>>> 
>>>>> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
>>>>> 
>>>>> For example,  if i try:
>>>>> 
>>>>> junk1 <- apply(junk, 2, rev)
>>>>> 
>>>>> junk1 comes out as two-dimensional,  not three-dimensional.
>>>>> 
>>>>> It is probably something obvious but I am not getting it.
>>>>> 
>>>>> Thanks for any help.
>>>>> 
>>>>> -Roy
>>>>> 
>>>>> 
>>>>> **********************
>>>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>>>> **********************
>>>>> Roy Mendelssohn
>>>>> Supervisory Operations Research Analyst
>>>>> NOAA/NMFS
>>>>> Environmental Research Division
>>>>> Southwest Fisheries Science Center
>>>>> ***Note new street address***
>>>>> 110 McAllister Way
>>>>> Santa Cruz, CA 95060
>>>>> Phone: (831)-420-3666
>>>>> Fax: (831) 420-3980
>>>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>>>> 
>>>>> "Old age and treachery will overcome youth and skill."
>>>>> "From those who have been given much, much will be expected"
>>>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected" 
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From r.turner at auckland.ac.nz  Thu Jun  1 22:44:42 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 2 Jun 2017 08:44:42 +1200
Subject: [R] [FORGED] Re: Question on function "scatterplot3d"
In-Reply-To: <8cadf1fe-d049-d9b7-2e1e-a01b51602027@statistik.tu-dortmund.de>
References: <CAHLnndZ-TKNQdMaLUca-CYOUD-YKZKvYDvy==Ne8a9+aeZvpqA@mail.gmail.com>
 <7945E490-A6BC-48A2-964B-DEA0F7C30431@gmail.com>
 <c4d356d5-3761-29c0-91c0-ea86339c02c2@auckland.ac.nz>
 <e7be3632-32dc-85e0-63b4-4e2d0b8adb68@statistik.tu-dortmund.de>
 <948df1a1-57c7-6dad-4475-b2d99e5dd527@auckland.ac.nz>
 <8cadf1fe-d049-d9b7-2e1e-a01b51602027@statistik.tu-dortmund.de>
Message-ID: <96c80960-f7f4-b2e5-deae-09190789a538@auckland.ac.nz>

On 02/06/17 03:02, Uwe Ligges wrote:
> 
> 
> On 01.06.2017 10:03, Rolf Turner wrote:
>> On 01/06/17 19:54, Uwe Ligges wrote:
>>> A design flaw, whether the labels are cut depends somewhat on the 
>>> sizce of the device, hence there is the argument
>>>
>>> y.margin.add
>>>
>>> add additional space between tick mark labels and axis label of the y 
>>> axis
>>>
>>> for working around that limittation that can be set to some positive 
>>> value....
>>
>>
>> This seems to be addressing Hannah's (li li's) original enquiry, not 
>> my follow-up in which I worried about the position, along the y-axis, 
>> of the y-axis label.
> 
> Ah, that is intended as a smart way of rotating it along the axis is not 
> easy (if not impossible) with the bas egraohics system.

OK.  Fair enuff.  Thanks.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dcarlson at tamu.edu  Thu Jun  1 22:56:51 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 1 Jun 2017 20:56:51 +0000
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <C26CA739-162D-4F37-B203-84D1A8A97B02@gmail.com>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
 <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>
 <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>
 <cf79d71578544504baf432288731b39c@exch-2p-mbx-w2.ads.tamu.edu>
 <F4A29415-0F72-4EBF-A960-DC9195722A63@noaa.gov>
 <C26CA739-162D-4F37-B203-84D1A8A97B02@gmail.com>
Message-ID: <abb91d0ddbf84fc988a649b8399ba1c1@exch-2p-mbx-w2.ads.tamu.edu>

On the off chance that anyone is still interested, here is the corrected function using aperm():

z <- array(1:120,dim=2:5)
f2 <- function(a, wh) {
    idx <- seq_len(length(dim(a)))
    dims <- setdiff(idx, wh)
    idx <- append(idx[-1], idx[1], wh-1)
    aperm(apply(a, dims, rev), idx)
}

all.equal(f(z, 1), f2(z, 1))
# [1] TRUE
all.equal(f(z, 2), f2(z, 2))
# [1] TRUE
all.equal(f(z, 3), f2(z, 3))
# [1] TRUE
all.equal(f(z, 4), f2(z, 4))
# [1] TRUE

David C


From: Ismail SEZEN [mailto:sezenismail at gmail.com] 
Sent: Thursday, June 1, 2017 3:35 PM
To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
Cc: David L Carlson <dcarlson at tamu.edu>; R-help <r-help at r-project.org>
Subject: Re: [R] Reversing one dimension of an array, in a generalized case


On 1 Jun 2017, at 22:42, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:

Thanks to all for responses/. ?There was a question of exactly what was wanted. ?It is the generalization of the obvious example I gave, ?


junk1 <- junk[, rev(seq_len(10), ]


so that

junk[1,1,1 ] = junk1[1,10,1]
junk[1,2,1] ?= junk1[1,9,1]

etc.

The genesis of this is the program is downloading data from a variety of sources on (time, altitude, lat, lon) coordinates, ?but all the coordinates are not always there, and sometime the latitude coordinates go from north to south and sometimes from south to north. ?I want to always return the data going from south to north, so if I find that the data is north to south, ?I have to first reverse the array with the coordinate values (easy enough), ?and then reverse the one dimension in the data array that corresponds to latitude. The downloaded information tells me which dimension is latitude plus how many coordinates are in the data.

Hello Roy,
Perhaps you are aware of but I want to mention anyway. Basic issue is that you always want latitudes are monotonously increasing. Let me tell what I do when I read a ncdf file:

1- Set latitudes always monotonously decreasing (from 90 to -90)
2- Set longitudes always mononously increasing but from -180 to 180.
3- Set levels always monotonously decreasing (this is not relevant)

Why? If you plan to plot variables in R, you will need coordinates in this order. For instance, if you set latitudes monotonously increasing, your map will be plotted upside down. To fix this, you will need reverse dimension again. And also if your longitudes ranges from 0 to 360, you will see the only the east side of the plot on a world map. West of Greencwich will be empty. ?They were the problems that I faced last year when I tried to plot netcdf files using lattice and rasterVis packages.?




As I the said, ?I haven't done extensive testing on what Bert sent, ?but on a toy 3-dimensional example I have it appeared to do what I want.

Thanks again,

-Roy


On Jun 1, 2017, at 12:22 PM, David L Carlson <dcarlson at tamu.edu> wrote:

My error. Clearly I did not do enough testing.

z <- array(1:24,dim=2:4)

all.equal(f(z,1),f2(z,1))
[1] TRUE

all.equal(f(z,2),f2(z,2))
[1] TRUE

all.equal(f(z,3),f2(z,3))
[1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
[2] "Mean relative difference: 0.6109091" ???

# Your earlier example

z <- array(1:120, dim=2:5)
all.equal(f(z,1),f2(z,1))
[1] TRUE

all.equal(f(z,2),f2(z,2))
[1] TRUE

all.equal(f(z,3),f2(z,3))
[1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
[2] "Mean relative difference: 0.1262209" ????????????????????????????????

all.equal(f(z,4),f2(z,4))
[1] "Attributes: < Component ?dim?: Mean relative difference: 0.5714286 >"
[2] "Mean relative difference: 0.5855162" ?

David C

-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com]?
Sent: Thursday, June 1, 2017 2:00 PM
To: David L Carlson <dcarlson at tamu.edu>
Cc: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>; R-help <r-help at r-project.org>
Subject: Re: [R] Reversing one dimension of an array, in a generalized case

??


z <- array(1:24,dim=2:4)
all.equal(f(z,3),f2(z,3))

[1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
[2] "Mean relative difference: 0.6109091"

In fact,


dim(f(z,3))
[1] 2 3 4


dim(f2(z,3))
[1] 3 4 2

Have I made some sort of stupid error here? Or have I misunderstood
what was wanted?

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 1, 2017 at 11:34 AM, David L Carlson <dcarlson at tamu.edu> wrote:

Here is an alternative approach using apply(). Note that with apply() you are reversing rows or columns not indices of rows or columns so apply(junk, 2, rev) reverses the values in each column not the column indices. We actually need to use rev() on everything but the index we are interested in reversing:

f2 <- function(a, wh) {
??dims <- seq_len(length(dim(a)))
??dims <- setdiff(dims, wh)
??apply(apply(a, dims, rev), dims, t)
}

# Your example
j1 <- junk[ , rev(1:10), ]
j2 <- f2(junk, 2)
all.equal(j1, j2)
# [1] TRUE

# Bert's example
z1 <- f(z, 2)
z2 <- f2(z, 2)
all.equal(z1, z2)
# [1] TRUE

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352






-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Thursday, June 1, 2017 12:46 PM
To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Reversing one dimension of an array, in a generalized case

How about this:

f <- function(a,wh){ ## a is the array; wh is the index to be reversed
?l<- lapply(dim(a),seq_len)
?l[[wh]]<- rev(l[[wh]])
?do.call(`[`,c(list(a),l))
}

## test
z <- array(1:120,dim=2:5)

## ?I omit the printouts

f(z,2)

f(z,3)


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:

Hi All:

I have been looking for an elegant way to do the following, ?but haven't found it, ?I have never had a good understanding of any of the "apply" functions.

A simplified idea is I have an array, say:

junk(5, 10, 3)

where ?(5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:

junk1 <- junk[, rev(seq_len(10), ]

but what I am after is a general function that will do that where the array could be two, three or four dimensions, ?and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.

For example, ?if i try:

junk1 <- apply(junk, 2, rev)

junk1 comes out as two-dimensional, ?not three-dimensional.

It is probably something obvious but I am not getting it.

Thanks for any help.

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected"
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail:?Roy.Mendelssohn at noaa.gov?www:?http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected"?
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.

______________________________________________
R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide?http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Thu Jun  1 22:59:22 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 1 Jun 2017 13:59:22 -0700
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <abb91d0ddbf84fc988a649b8399ba1c1@exch-2p-mbx-w2.ads.tamu.edu>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
 <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>
 <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>
 <cf79d71578544504baf432288731b39c@exch-2p-mbx-w2.ads.tamu.edu>
 <F4A29415-0F72-4EBF-A960-DC9195722A63@noaa.gov>
 <C26CA739-162D-4F37-B203-84D1A8A97B02@gmail.com>
 <abb91d0ddbf84fc988a649b8399ba1c1@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <4CB71166-65AF-4790-A121-861D47A3DDEF@noaa.gov>

Thanks again.  I am going to try the different versions.   But I probably won't be able to get to it till next week.

This is probably at the point where anything further should be sent to me privately.

-Roy



> On Jun 1, 2017, at 1:56 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> On the off chance that anyone is still interested, here is the corrected function using aperm():
> 
> z <- array(1:120,dim=2:5)
> f2 <- function(a, wh) {
>    idx <- seq_len(length(dim(a)))
>    dims <- setdiff(idx, wh)
>    idx <- append(idx[-1], idx[1], wh-1)
>    aperm(apply(a, dims, rev), idx)
> }
> 
> all.equal(f(z, 1), f2(z, 1))
> # [1] TRUE
> all.equal(f(z, 2), f2(z, 2))
> # [1] TRUE
> all.equal(f(z, 3), f2(z, 3))
> # [1] TRUE
> all.equal(f(z, 4), f2(z, 4))
> # [1] TRUE
> 
> David C
> 
> 
> From: Ismail SEZEN [mailto:sezenismail at gmail.com] 
> Sent: Thursday, June 1, 2017 3:35 PM
> To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
> Cc: David L Carlson <dcarlson at tamu.edu>; R-help <r-help at r-project.org>
> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
> 
> 
> On 1 Jun 2017, at 22:42, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> Thanks to all for responses/.  There was a question of exactly what was wanted.  It is the generalization of the obvious example I gave,  
> 
> 
> junk1 <- junk[, rev(seq_len(10), ]
> 
> 
> so that
> 
> junk[1,1,1 ] = junk1[1,10,1]
> junk[1,2,1]  = junk1[1,9,1]
> 
> etc.
> 
> The genesis of this is the program is downloading data from a variety of sources on (time, altitude, lat, lon) coordinates,  but all the coordinates are not always there, and sometime the latitude coordinates go from north to south and sometimes from south to north.  I want to always return the data going from south to north, so if I find that the data is north to south,  I have to first reverse the array with the coordinate values (easy enough),  and then reverse the one dimension in the data array that corresponds to latitude. The downloaded information tells me which dimension is latitude plus how many coordinates are in the data.
> 
> Hello Roy,
> Perhaps you are aware of but I want to mention anyway. Basic issue is that you always want latitudes are monotonously increasing. Let me tell what I do when I read a ncdf file:
> 
> 1- Set latitudes always monotonously decreasing (from 90 to -90)
> 2- Set longitudes always mononously increasing but from -180 to 180.
> 3- Set levels always monotonously decreasing (this is not relevant)
> 
> Why? If you plan to plot variables in R, you will need coordinates in this order. For instance, if you set latitudes monotonously increasing, your map will be plotted upside down. To fix this, you will need reverse dimension again. And also if your longitudes ranges from 0 to 360, you will see the only the east side of the plot on a world map. West of Greencwich will be empty.  They were the problems that I faced last year when I tried to plot netcdf files using lattice and rasterVis packages. 
> 
> 
> 
> 
> As I the said,  I haven't done extensive testing on what Bert sent,  but on a toy 3-dimensional example I have it appeared to do what I want.
> 
> Thanks again,
> 
> -Roy
> 
> 
> On Jun 1, 2017, at 12:22 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> My error. Clearly I did not do enough testing.
> 
> z <- array(1:24,dim=2:4)
> 
> all.equal(f(z,1),f2(z,1))
> [1] TRUE
> 
> all.equal(f(z,2),f2(z,2))
> [1] TRUE
> 
> all.equal(f(z,3),f2(z,3))
> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
> [2] "Mean relative difference: 0.6109091"    
> 
> # Your earlier example
> 
> z <- array(1:120, dim=2:5)
> all.equal(f(z,1),f2(z,1))
> [1] TRUE
> 
> all.equal(f(z,2),f2(z,2))
> [1] TRUE
> 
> all.equal(f(z,3),f2(z,3))
> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
> [2] "Mean relative difference: 0.1262209"                                 
> 
> all.equal(f(z,4),f2(z,4))
> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.5714286 >"
> [2] "Mean relative difference: 0.5855162"  
> 
> David C
> 
> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
> Sent: Thursday, June 1, 2017 2:00 PM
> To: David L Carlson <dcarlson at tamu.edu>
> Cc: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>; R-help <r-help at r-project.org>
> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
> 
> ??
> 
> 
> z <- array(1:24,dim=2:4)
> all.equal(f(z,3),f2(z,3))
> 
> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
> [2] "Mean relative difference: 0.6109091"
> 
> In fact,
> 
> 
> dim(f(z,3))
> [1] 2 3 4
> 
> 
> dim(f2(z,3))
> [1] 3 4 2
> 
> Have I made some sort of stupid error here? Or have I misunderstood
> what was wanted?
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Jun 1, 2017 at 11:34 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> Here is an alternative approach using apply(). Note that with apply() you are reversing rows or columns not indices of rows or columns so apply(junk, 2, rev) reverses the values in each column not the column indices. We actually need to use rev() on everything but the index we are interested in reversing:
> 
> f2 <- function(a, wh) {
>   dims <- seq_len(length(dim(a)))
>   dims <- setdiff(dims, wh)
>   apply(apply(a, dims, rev), dims, t)
> }
> 
> # Your example
> j1 <- junk[ , rev(1:10), ]
> j2 <- f2(junk, 2)
> all.equal(j1, j2)
> # [1] TRUE
> 
> # Bert's example
> z1 <- f(z, 2)
> z2 <- f2(z, 2)
> all.equal(z1, z2)
> # [1] TRUE
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> 
> 
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
> Sent: Thursday, June 1, 2017 12:46 PM
> To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
> 
> How about this:
> 
> f <- function(a,wh){ ## a is the array; wh is the index to be reversed
>  l<- lapply(dim(a),seq_len)
>  l[[wh]]<- rev(l[[wh]])
>  do.call(`[`,c(list(a),l))
> }
> 
> ## test
> z <- array(1:120,dim=2:5)
> 
> ##  I omit the printouts
> 
> f(z,2)
> 
> f(z,3)
> 
> 
> Cheers,
> Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
> <roy.mendelssohn at noaa.gov> wrote:
> 
> Hi All:
> 
> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
> 
> A simplified idea is I have an array, say:
> 
> junk(5, 10, 3)
> 
> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
> 
> junk1 <- junk[, rev(seq_len(10), ]
> 
> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
> 
> For example,  if i try:
> 
> junk1 <- apply(junk, 2, rev)
> 
> junk1 comes out as two-dimensional,  not three-dimensional.
> 
> It is probably something obvious but I am not getting it.
> 
> Thanks for any help.
> 
> -Roy
> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From r.turner at auckland.ac.nz  Thu Jun  1 23:45:11 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 2 Jun 2017 09:45:11 +1200
Subject: [R] [spatstat] Convert shapefile to pixel image
In-Reply-To: <1188522651hurgil@uv.es>
References: <1188522651hurgil@uv.es>
Message-ID: <6284d3d5-bf70-b1c3-3c8d-4d51d1dc48eb@auckland.ac.nz>


On 02/06/17 01:17, Lluis.Hurtado at uv.es wrote:

> Dear all,
> 
> I am currently working with the spatstat package, using windows and pixel images.
> 
> First:
> 
> My aim is to transform a shapefile (see attached) into a pixel image.
> 
> My idea is to start transforming the shapefile into a Spatial Polygon file:
> 
> x <- readShapeSpatial("200001441.shp")
> y <- as(x, "SpatialPolygons")
> z <- as.owin(y)
> 
> Given z, I want to identify each polygon with a single constant value. This is like adding marks to the SpatialPolygons file. Then I want to convert these polygons into an image, such that the value of each pixel corresponds to the value associated to the polygon where the pixel lies.
> 
> I have been able to do this individually, polygon by polygon, but then I cannot merge the resulting images into a single one. Any idea?
> 
> Second:
> 
> I would also need a single window containing all the smallest polygons (the boundary). I have tried:
> 
> w <- union.owin(z)
> 
> But the resulting window w still shows internal polygons. As read in spatstas FAQ page:
> 
> "First, convert each of the regions into a separate owin object. Then apply union.owin to combine them."
> 
> So I try,
> 
> regions <- slot(y, "polygons")
> regions <- lapply(regions, function(x) { SpatialPolygons(list(x)) })
> windows <- lapply(regions, as.owin)
> 
> But windows is a list of 4307 polygons. How can introduce all of them as a single argument?
> 
>> M <- union.owin(windows)
> Warning messages:
> 1: In union.owin(windows) : Some arguments were not windows
> 2: In union.owin(windows) : No windows were given
> 
> 
> Thank you very much for you help.

As Don has said, this question would be better asked on R-sig-geo.

A *reproducible* example would be nice, e.g. perhaps you could tell us 
how to get the shapefile in question.

In respect of your last point:  Rather than "M <- union.owin(windows)" 
you should use:

     M <- do.call(union.owin, windows)

But that's rather off the track.  What I think you should do (it's hard 
to be certain without a reproducible example) is something like:

tw <- tess(tiles=windows)
iw <- as.im(funxy(as.function(tw,values=vvv),W=Window(tw)),dimyx=128)

where "vvv" is a vector of the values that you wish to associate with 
the individual polygons.  There may be less cryptic ways of 
accomplishing the same thing, but this is the sexiest way, I think.

The value chosen for "dimyx", i.e. 128, is just by way of example.  You 
can use whatever value suits you.  The larger it is, the smoother the 
individual polygons will look, in pixellated form, but the longer things 
will take.  With 4307 polygons, that might be a rather long time!

HTH

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From henrik.bengtsson at gmail.com  Fri Jun  2 01:18:46 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 1 Jun 2017 16:18:46 -0700
Subject: [R] odfWeave - A loop of the "same" data
In-Reply-To: <alpine.OSX.2.20.1706010902010.783@charles-berrys-macbook.local>
References: <835a481d90af48278b637598af299650@NH-HEPEX141.AD1.NHS.NET>
 <alpine.OSX.2.20.1706010902010.783@charles-berrys-macbook.local>
Message-ID: <CAFDcVCQaAgTy2=4JrNh1SOYaOg3oHS7NfEk0qr1XGXO6VPP2cQ@mail.gmail.com>

This is what the R.rsp (https://cran.r-project.org/package=R.rsp; I'm
the author) and it's RSP markup is good at and was designed to handle.
We're using it lots in report generation where we iterate of elements,
e.g. over the 24 chromosomes.  See Section 2.3 in
https://cran.r-project.org/web/packages/R.rsp/vignettes/Dynamic_document_creation_using_RSP.pdf.
RSP is independent of input format - all it requires is that it's
text-based - so you can use RSP-embedded LaTeX, HTML, Markdown, ...,
and even RSP-embedded Sweave, knitr, Rmarkdown (where it then it
effectively works as a pre-processor to those formats).

Hope this helps

Henrik



On Thu, Jun 1, 2017 at 9:35 AM, Charles C. Berry <ccberry at ucsd.edu> wrote:
> On Thu, 1 Jun 2017, POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
> FOUNDATION TRUST) via R-help wrote:
>
>> Before I go and do this another way - can I check if anyone has a way of
>> looping through data in odfWeave (or possibly sweave) to do a repeating
>> analysis on subsets of data?
>>
>> For simplicity lets use mtcars dataset in R to explain.  Dataset looks
>> like this:
>>
>>> mtcars
>>
>>               mpg cyl disp  hp drat   wt ...
>> Mazda RX4     21.0   6  160 110 3.90 2.62 ...
>> Mazda RX4 Wag 21.0   6  160 110 3.90 2.88 ...
>> Datsun 710    22.8   4  108  93 3.85 2.32 ...
>>               ............
>>
>> Say I wanted to have a 'catalogue' style report from mtcars, where on each
>> page I would perhaps have the Rowname as a heading and then plot a graph of
>> mpg highlighting that specific car
>>
>> Then add a page break and *do the same for the next car*.  I can manually
>> do this of course, but it is effectively a loop something like this:
>>
>> for (n in length(mtcars$mpg)) {
>> barplot (mtcars$mpg, col=c(rep(1,n-1),2,rep(1,length(mtcars$mpg)-n)))
>> }
>>
>> There is a odfWeave page break function so I can do that sort of thing (I
>> think).  But I don't think I can output more than one image can I? In
>> reality I will want several images and a table per "catalogue" page.
>>
>> At the moment I think I need to create a master odt document, and create
>> individual catalogue pages.  And merge them into one document - but that
>> feels clunky (unless I can script the merge!)
>>
>> Anyone got a better way?
>
>
>
> For a complex template inside a loop, I'd probably do as Jeff suggests and
> use a knitr child document for ease of developing and debugging the
> template.
>
> But for the simple case you describe I'd use a brew script to
> unroll the loop.
>
> You would write your input file as usual, but put a brew script in the
> right place, then run brew on the input file to produce an
> intermediate file that unrolls the loop, then weave the intermediate
> file to get your desired result.  Here is a simple example of such you can
> run in an R session (assuming the brew package is installed) and see the
> results printed out.
>
> --8<---------------cut here---------------start------------->8---
>
> brew::brew(text="
>
> Everything before the loop
>
> <% for (i in 1:10) { %>
> Print the value of i
> <% print(i) %> or better yet
> \\Sexpr{<%= i %>}
> <% } %>
>
> everything after
>
> ")
>
> --8<---------------cut here---------------end--------------->8---
>
> The double backslash is needed in the literal string used here.  If
> you put that script in a file using an editor, you would just use a
> single backslash.
>
> HTH,
>
> Chuck
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mdsumner at gmail.com  Fri Jun  2 02:29:41 2017
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 02 Jun 2017 00:29:41 +0000
Subject: [R] [spatstat] Convert shapefile to pixel image
In-Reply-To: <6284d3d5-bf70-b1c3-3c8d-4d51d1dc48eb@auckland.ac.nz>
References: <1188522651hurgil@uv.es>
 <6284d3d5-bf70-b1c3-3c8d-4d51d1dc48eb@auckland.ac.nz>
Message-ID: <CAAcGz9_3cS0qC6WuDZe9Wq5aPwgO+9apPXWc7411zj8UpZLphg@mail.gmail.com>

Try fasterize, converting to spatstat from raster is straightforward, happy
to help.

https://github.com/ecohealthalliance/fasterize

Cheers, Mije

On Fri, 2 Jun 2017, 07:45 Rolf Turner, <r.turner at auckland.ac.nz> wrote:

>
> On 02/06/17 01:17, Lluis.Hurtado at uv.es wrote:
>
> > Dear all,
> >
> > I am currently working with the spatstat package, using windows and
> pixel images.
> >
> > First:
> >
> > My aim is to transform a shapefile (see attached) into a pixel image.
> >
> > My idea is to start transforming the shapefile into a Spatial Polygon
> file:
> >
> > x <- readShapeSpatial("200001441.shp")
> > y <- as(x, "SpatialPolygons")
> > z <- as.owin(y)
> >
> > Given z, I want to identify each polygon with a single constant value.
> This is like adding marks to the SpatialPolygons file. Then I want to
> convert these polygons into an image, such that the value of each pixel
> corresponds to the value associated to the polygon where the pixel lies.
> >
> > I have been able to do this individually, polygon by polygon, but then I
> cannot merge the resulting images into a single one. Any idea?
> >
> > Second:
> >
> > I would also need a single window containing all the smallest polygons
> (the boundary). I have tried:
> >
> > w <- union.owin(z)
> >
> > But the resulting window w still shows internal polygons. As read in
> spatstas FAQ page:
> >
> > "First, convert each of the regions into a separate owin object. Then
> apply union.owin to combine them."
> >
> > So I try,
> >
> > regions <- slot(y, "polygons")
> > regions <- lapply(regions, function(x) { SpatialPolygons(list(x)) })
> > windows <- lapply(regions, as.owin)
> >
> > But windows is a list of 4307 polygons. How can introduce all of them as
> a single argument?
> >
> >> M <- union.owin(windows)
> > Warning messages:
> > 1: In union.owin(windows) : Some arguments were not windows
> > 2: In union.owin(windows) : No windows were given
> >
> >
> > Thank you very much for you help.
>
> As Don has said, this question would be better asked on R-sig-geo.
>
> A *reproducible* example would be nice, e.g. perhaps you could tell us
> how to get the shapefile in question.
>
> In respect of your last point:  Rather than "M <- union.owin(windows)"
> you should use:
>
>      M <- do.call(union.owin, windows)
>
> But that's rather off the track.  What I think you should do (it's hard
> to be certain without a reproducible example) is something like:
>
> tw <- tess(tiles=windows)
> iw <- as.im(funxy(as.function(tw,values=vvv),W=Window(tw)),dimyx=128)
>
> where "vvv" is a vector of the values that you wish to associate with
> the individual polygons.  There may be less cryptic ways of
> accomplishing the same thing, but this is the sexiest way, I think.
>
> The value chosen for "dimyx", i.e. 128, is just by way of example.  You
> can use whatever value suits you.  The larger it is, the smoother the
> individual polygons will look, in pixellated form, but the longer things
> will take.  With 4307 polygons, that might be a rather long time!
>
> HTH
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun  2 03:51:06 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 1 Jun 2017 18:51:06 -0700
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
Message-ID: <6473E3EB-F366-42B3-A66F-CA282F97C8D1@comcast.net>


> On Jun 1, 2017, at 9:51 AM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> Hi All:
> 
> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
> 
> A simplified idea is I have an array, say:
> 
> junk(5, 10, 3)
> 
> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
> 
> junk1 <- junk[, rev(seq_len(10), ]
> 
> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
> 
> For example,  if i try:
> 
> junk1 <- apply(junk, 2, rev)
> 
> junk1 comes out as two-dimensional,  not three-dimensional.
> 
> It is probably something obvious but I am not getting it.

It was clear whether you wanted every slice along a particular dimension reversed or just one particular slice in a particular dimension. I thought probably the former:

Try:

(arr <- array(1:(2*3*4), dim=c(2,3,4) ) )
 
array( apply(arr, 3, rev), dim (arr) )

-- 
David.
> 
> Thanks for any help.
> 
> -Roy
> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From percentil101 at gmail.com  Thu Jun  1 20:20:04 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Thu, 1 Jun 2017 20:20:04 +0200
Subject: [R] Upper bands and lower bands
Message-ID: <CAB-TgNvke8riEgKbJYVLMo6BUZ+=gvFeqQUTdEzLGnk1CnDiGQ@mail.gmail.com>

Hi all

I want to add a band of fluctuaci?n (exponential decreading) to a linear
deacrecing values

Imagine: I have a matrix like c(10,9,8,7,6,5,4,3,2,1)

The thing is I want  two new lines so that the m?ximum value of the new
colum on the m?ximum is from 10% to 5% higher and the same lower for the
m?nimum

the final two matix will be something like

c(10+0.10*10,9+0.089*9,8+0.075*8.....,1+0.05*1)
c(10-0.10*10,9-0.09*9,8-0.075*8.....,1-0.05*1)

What I?m looking for is a function tu calculate de "values, weights" so
that including the 10% and 5% and the nunmber of decreasing values, in this
case n=10, calculates de smotth weigths.

I don?t know if I have expalined well so thar finally putting initial value
final and periods I can find a matrix like

g(0.1,0.89,0.79,0.075,...,0.05)

Exists something like that?

	[[alternative HTML version deleted]]


From percentil101 at gmail.com  Thu Jun  1 22:20:42 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Thu, 1 Jun 2017 22:20:42 +0200
Subject: [R] Upper bands and lower bands
In-Reply-To: <CAB-TgNvke8riEgKbJYVLMo6BUZ+=gvFeqQUTdEzLGnk1CnDiGQ@mail.gmail.com>
References: <CAB-TgNvke8riEgKbJYVLMo6BUZ+=gvFeqQUTdEzLGnk1CnDiGQ@mail.gmail.com>
Message-ID: <CAB-TgNviySQqt4VQ4PD=7FVDk607G_nP3QHpOwJHzGVzLSgO+g@mail.gmail.com>

I explain better:

I have this percentage z<-1/(n*365) where n=20 so z is
0,000136986

Imagine: a matrix with length(n*365) so that

matrix result is

resultc(
1,
1-z
result previous row-z
result previous row-z
....
0)

If I plot this is a linear decreasing line

I want to plot an upper line wich is 10% higher tan resultc on the first
values and then decreasing so that last value will be 0.05.
 the same in the lower, a line which values are at the beggining a 10%
lower and smoothly dreasing values till the last will be 5% lower.

Is it posible to make thins bands exponencially with a code?





2017-06-01 20:20 GMT+02:00 Pedro p?ramo <percentil101 at gmail.com>:

> Hi all
>
> I want to add a band of fluctuaci?n (exponential decreading) to a linear
> deacrecing values
>
> Imagine: I have a matrix like c(10,9,8,7,6,5,4,3,2,1)
>
> The thing is I want  two new lines so that the m?ximum value of the new
> colum on the m?ximum is from 10% to 5% higher and the same lower for the
> m?nimum
>
> the final two matix will be something like
>
> c(10+0.10*10,9+0.089*9,8+0.075*8.....,1+0.05*1)
> c(10-0.10*10,9-0.09*9,8-0.075*8.....,1-0.05*1)
>
> What I?m looking for is a function tu calculate de "values, weights" so
> that including the 10% and 5% and the nunmber of decreasing values, in this
> case n=10, calculates de smotth weigths.
>
> I don?t know if I have expalined well so thar finally putting initial
> value final and periods I can find a matrix like
>
> g(0.1,0.89,0.79,0.075,...,0.05)
>
> Exists something like that?
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun  2 07:01:27 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 1 Jun 2017 22:01:27 -0700
Subject: [R] Upper bands and lower bands
In-Reply-To: <CAB-TgNvke8riEgKbJYVLMo6BUZ+=gvFeqQUTdEzLGnk1CnDiGQ@mail.gmail.com>
References: <CAB-TgNvke8riEgKbJYVLMo6BUZ+=gvFeqQUTdEzLGnk1CnDiGQ@mail.gmail.com>
Message-ID: <CAGxFJbQnxqH9g=22W44bKm2S4_bTkZ0S4Nfw9Y415sM02xF4Jg@mail.gmail.com>

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 1, 2017 at 11:20 AM, Pedro p?ramo <percentil101 at gmail.com> wrote:
> Hi all
>
> I want to add a band of fluctuaci?n (exponential decreading) to a linear
> deacrecing values
>
> Imagine: I have a matrix like c(10,9,8,7,6,5,4,3,2,1)

Ummm... That is not a matrix.  It's a vector.

-- Bert


>
> The thing is I want  two new lines so that the m?ximum value of the new
> colum on the m?ximum is from 10% to 5% higher and the same lower for the
> m?nimum
>
> the final two matix will be something like
>
> c(10+0.10*10,9+0.089*9,8+0.075*8.....,1+0.05*1)
> c(10-0.10*10,9-0.09*9,8-0.075*8.....,1-0.05*1)
>
> What I?m looking for is a function tu calculate de "values, weights" so
> that including the 10% and 5% and the nunmber of decreasing values, in this
> case n=10, calculates de smotth weigths.
>
> I don?t know if I have expalined well so thar finally putting initial value
> final and periods I can find a matrix like
>
> g(0.1,0.89,0.79,0.075,...,0.05)
>
> Exists something like that?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From trott.sean at gmail.com  Fri Jun  2 06:47:00 2017
From: trott.sean at gmail.com (Sean Trott)
Date: Thu, 1 Jun 2017 21:47:00 -0700
Subject: [R] Question on interpreting glmer() results
Message-ID: <CAOW2oWEg-mhjzGOa8OeCkFTt+aeEBKDUUJ=DnFASvQwgertvdg@mail.gmail.com>

Hello,

I originally posted this on the stats stack exchange site, but given its
focus on R software, it was removed -- so I figured I'd post here.

I'm having trouble interpreting a change in effect direction and
significance when I add an interaction term to my glmer() model.

*Part 1*

I ran an experiment in which participants made categorical decisions (out
of two categories) in one of two conditions. The conditional manipulations
were within-subject, and there were 8 trials total.

For my initial model, I used glmer():

glmer(factor(categorization) ~ condition  + (1 + condition | subject) +
                  (1 | subject) +
                  (1  | item),
                data = coded,
                family=binomial)

Comparing this to the null model (without *condition* as a predictor)
results in a very low p-value, where X^2=43.5, p<.00001 (4.2 * 10^-11).
This is in line with our plot (which I can include if necessary), which
shows a very significant effect of condition.

Additionally, the model output shows a significant effect of condition:

conditionno_belief   2.1733     0.3123   6.959 3.43e-12 ***

*Part 2*

Then, I ran another experiment to assess individual differences, such that
each participant was associated with a reading comprehension score (and
some other scores).

I ran another glmer() model with an interaction term between reading
comprehension ("rc") and condition:

glmer(factor(categorization) ~ condition * rc +
                      (1 | subject) +
                      (1  | stimNum),
                    data = new.coded,
                    family=binomial)

I'm having a really hard time interpreting these results:

conditionno_belief    -2.30562    1.08306  -2.129 0.033271 *

rc                   -0.24367    0.08607  -2.831 0.004639 **

conditionno_belief:rc  0.46426    0.12185   3.810 0.000139 ***

(I also realize that subjects are included just as random intercepts
instead of random slopes in this second model.)

*Questions*

There are several things I'm unsure about:

   1.

   How does glmer() treat dummy variables (e.g. categories like
   "conditionA" and "conditionB", or "optionA" and "optionB")? That is, how
   can I interpret the effect direction (whether the z-value is negative or
   positive)?
   2.

   I've plotted the relationship between effect and reading comprehension,
   and conducted separate analyses, and found no relationship there. And yet
   this model seems to be saying that once I factor in reading comprehension
   as a main effect, the effect direction of condition reverses (and becomes
   less significant). This just seems very counterintuitive to me, given the
   huge effect of condition in the initial model (and visualization), and the
   lack of a significant relationship between effect and RC in other analyses.
   Why might this be?
   3.

   Is there a way to add an interaction term without glmer() also looking
   at the main effect of each of those terms? (Which I want to do for reading
   comprehension.)

Thank you! Please let me know if you need other information.

	[[alternative HTML version deleted]]


From percentil101 at gmail.com  Fri Jun  2 08:37:28 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Fri, 2 Jun 2017 08:37:28 +0200
Subject: [R] Upper bands and lower bands
In-Reply-To: <CAGxFJbQnxqH9g=22W44bKm2S4_bTkZ0S4Nfw9Y415sM02xF4Jg@mail.gmail.com>
References: <CAB-TgNvke8riEgKbJYVLMo6BUZ+=gvFeqQUTdEzLGnk1CnDiGQ@mail.gmail.com>
 <CAGxFJbQnxqH9g=22W44bKm2S4_bTkZ0S4Nfw9Y415sM02xF4Jg@mail.gmail.com>
Message-ID: <CAB-TgNv+yctvtxTsvMqz=Lg-fMaxa813hBQmDZ0hbWGmU0uXDA@mail.gmail.com>

Sorry,

For me a vector is a matrix with mx1 dimmensions. But it is true that it is
not the way I correctly must talk in R.

Can you guide me in what I?m trying to do? I?m trying to find what I want
in Excel using something like a parabolic function but dind?t get yet (then
to try to replicate in R).


2017-06-02 7:01 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:

> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Jun 1, 2017 at 11:20 AM, Pedro p?ramo <percentil101 at gmail.com>
> wrote:
> > Hi all
> >
> > I want to add a band of fluctuaci?n (exponential decreading) to a linear
> > deacrecing values
> >
> > Imagine: I have a matrix like c(10,9,8,7,6,5,4,3,2,1)
>
> Ummm... That is not a matrix.  It's a vector.
>
> -- Bert
>
>
> >
> > The thing is I want  two new lines so that the m?ximum value of the new
> > colum on the m?ximum is from 10% to 5% higher and the same lower for the
> > m?nimum
> >
> > the final two matix will be something like
> >
> > c(10+0.10*10,9+0.089*9,8+0.075*8.....,1+0.05*1)
> > c(10-0.10*10,9-0.09*9,8-0.075*8.....,1-0.05*1)
> >
> > What I?m looking for is a function tu calculate de "values, weights" so
> > that including the 10% and 5% and the nunmber of decreasing values, in
> this
> > case n=10, calculates de smotth weigths.
> >
> > I don?t know if I have expalined well so thar finally putting initial
> value
> > final and periods I can find a matrix like
> >
> > g(0.1,0.89,0.79,0.075,...,0.05)
> >
> > Exists something like that?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Jun  2 13:46:37 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 2 Jun 2017 21:46:37 +1000
Subject: [R] Upper bands and lower bands
In-Reply-To: <CAB-TgNviySQqt4VQ4PD=7FVDk607G_nP3QHpOwJHzGVzLSgO+g@mail.gmail.com>
References: <CAB-TgNvke8riEgKbJYVLMo6BUZ+=gvFeqQUTdEzLGnk1CnDiGQ@mail.gmail.com>
 <CAB-TgNviySQqt4VQ4PD=7FVDk607G_nP3QHpOwJHzGVzLSgO+g@mail.gmail.com>
Message-ID: <CA+8X3fXxVXufxKjHO3QhtdvJS4=mHGC+VMGGJO+dZjj6Gsnqhg@mail.gmail.com>

Hi Pedro,
If I get the idea, you want a vector of length 7300 starting at 1 and
ending at 0.

seq(1,0,length.out=7300)

Produces such a vector. It seems to me that:

seq(1.1,0.05,length.out=7300)

produces the upper vector and:

seq(0.95,-0.05 length.out=7300)

the lower. Then again, I might have the wrong idea big time.

Jim

On Fri, Jun 2, 2017 at 6:20 AM, Pedro p?ramo <percentil101 at gmail.com> wrote:
> I explain better:
>
> I have this percentage z<-1/(n*365) where n=20 so z is
> 0,000136986
>
> Imagine: a matrix with length(n*365) so that
>
> matrix result is
>
> resultc(
> 1,
> 1-z
> result previous row-z
> result previous row-z
> ....
> 0)
>
> If I plot this is a linear decreasing line
>
> I want to plot an upper line wich is 10% higher tan resultc on the first
> values and then decreasing so that last value will be 0.05.
>  the same in the lower, a line which values are at the beggining a 10%
> lower and smoothly dreasing values till the last will be 5% lower.
>
> Is it posible to make thins bands exponencially with a code?
>
>
>
>
>
> 2017-06-01 20:20 GMT+02:00 Pedro p?ramo <percentil101 at gmail.com>:
>
>> Hi all
>>
>> I want to add a band of fluctuaci?n (exponential decreading) to a linear
>> deacrecing values
>>
>> Imagine: I have a matrix like c(10,9,8,7,6,5,4,3,2,1)
>>
>> The thing is I want  two new lines so that the m?ximum value of the new
>> colum on the m?ximum is from 10% to 5% higher and the same lower for the
>> m?nimum
>>
>> the final two matix will be something like
>>
>> c(10+0.10*10,9+0.089*9,8+0.075*8.....,1+0.05*1)
>> c(10-0.10*10,9-0.09*9,8-0.075*8.....,1-0.05*1)
>>
>> What I?m looking for is a function tu calculate de "values, weights" so
>> that including the 10% and 5% and the nunmber of decreasing values, in this
>> case n=10, calculates de smotth weigths.
>>
>> I don?t know if I have expalined well so thar finally putting initial
>> value final and periods I can find a matrix like
>>
>> g(0.1,0.89,0.79,0.075,...,0.05)
>>
>> Exists something like that?
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Fri Jun  2 14:00:16 2017
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 2 Jun 2017 07:00:16 -0500
Subject: [R] subletting an array according to dimnames
In-Reply-To: <CAHLnnda7opQRKukczBFuJMCAaoSK75eAuxvWksKiiSjYpdb8+Q@mail.gmail.com>
References: <CAHLnnda7opQRKukczBFuJMCAaoSK75eAuxvWksKiiSjYpdb8+Q@mail.gmail.com>
Message-ID: <CAN5YmCGjSQaR9wzjWFLMVvLrOqRjZnSf_Vrr-ArT5wnUKT0J_w@mail.gmail.com>

Have you tried P2["20", "10", "0"] ?

Jean

On Thu, Jun 1, 2017 at 3:10 PM, li li <hannah.hlx at gmail.com> wrote:

> Hi all,
>   I have a three dimensional array with the corresponding dimension names.
> I would like to subset the array according to the dimension names. For
> example,
> suppose I want to extract the values corresponding to A=20, B=10, C=0.  I
> know I
> can do:
>  P2[dimnames(P2)$A==20, dimnames(P2)$B==10, dimnames(P2)$C==0]
>
> But is there a better way for doing this? Thanks for your help!
>   Hanna
>
> > dimnames(P2)
>
> $A
>
> [1] "20" "25" "30" "35" "40"
>
>
> $B
>
> [1] "5"  "10" "15" "20" "25" "30" "35" "40"
>
>
> $C
>
> [1] "0"  "5" "10" "15" "20" "25" "30" "35"
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From aanchalsharma833 at gmail.com  Fri Jun  2 16:22:33 2017
From: aanchalsharma833 at gmail.com (Aanchal Sharma)
Date: Fri, 2 Jun 2017 10:22:33 -0400
Subject: [R] modEvA D-squared for gamma glm
Message-ID: <CAFp0Li1HujT8C0Ce4ZxZg_g9kQ1wiZdECwjfiqjp_RXr03KJhQ@mail.gmail.com>

Hi All,

I am running a generalized linear model with gamma distribution in R (glm,
family=gamma ) for my data (gene expression as response variable and few
predictors). I want to calculate r-squared for this model.

I have been reading online about it and found there are multiple formulas
for calculating R2 (psuedo) for glm (in R) with gaussian (r2 from linear
model), logistic regression (1-deviance/null deviance), poisson
distribution (using pR2 in pscl package, D-squared value from modEvA R
package). But I could not find anything specific to gamma distributions.

Can pscl and modEVA packages be used for gamma distributions as well? or
there is any other formula for doing the same?

Thanks

Regards,

Anchal

-- 
Anchal Sharma, PhD
Postdoctoral Fellow
195, Little Albany street,
Cancer Institute of New Jersey
Rutgers University
NJ-08901

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun  2 16:38:29 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 2 Jun 2017 07:38:29 -0700
Subject: [R] modEvA D-squared for gamma glm
In-Reply-To: <CAFp0Li1HujT8C0Ce4ZxZg_g9kQ1wiZdECwjfiqjp_RXr03KJhQ@mail.gmail.com>
References: <CAFp0Li1HujT8C0Ce4ZxZg_g9kQ1wiZdECwjfiqjp_RXr03KJhQ@mail.gmail.com>
Message-ID: <CAGxFJbQFukootJFtq5kQ1=_aKgmu0eO0tPEgtj7zqUDdo430nQ@mail.gmail.com>

... As this concerns gene expression, perhaps the Bioconductor list
might be more appropriate. As it is prmarily statistics, not R
programming, maybe stats.stackexchange.com might be a better venue.
You might also be better off contacting the package maintainers
(?maintainer) for such package-specific questions.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 2, 2017 at 7:22 AM, Aanchal Sharma
<aanchalsharma833 at gmail.com> wrote:
> Hi All,
>
> I am running a generalized linear model with gamma distribution in R (glm,
> family=gamma ) for my data (gene expression as response variable and few
> predictors). I want to calculate r-squared for this model.
>
> I have been reading online about it and found there are multiple formulas
> for calculating R2 (psuedo) for glm (in R) with gaussian (r2 from linear
> model), logistic regression (1-deviance/null deviance), poisson
> distribution (using pR2 in pscl package, D-squared value from modEvA R
> package). But I could not find anything specific to gamma distributions.
>
> Can pscl and modEVA packages be used for gamma distributions as well? or
> there is any other formula for doing the same?
>
> Thanks
>
> Regards,
>
> Anchal
>
> --
> Anchal Sharma, PhD
> Postdoctoral Fellow
> 195, Little Albany street,
> Cancer Institute of New Jersey
> Rutgers University
> NJ-08901
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd.mes at cbs.dk  Fri Jun  2 17:07:49 2017
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Fri, 2 Jun 2017 15:07:49 +0000
Subject: [R] R 3.4.1 at end of June
Message-ID: <6621C3FA-1128-4C01-B27B-8DF830A8FF22@cbs.dk>

Just a quick note to say that we intend to have a patch release, probably on June 30, mainly to pick up a few balls that were dropped on the 3.4.0 release. Full schedule to appear later (just need a little time to actually set it up + checking that the date doesn't collide with schedules of other people).

- Peter Dalgaard

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From petr.pikal at precheza.cz  Fri Jun  2 09:29:43 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 2 Jun 2017 07:29:43 +0000
Subject: [R] Upper bands and lower bands
In-Reply-To: <CAB-TgNv+yctvtxTsvMqz=Lg-fMaxa813hBQmDZ0hbWGmU0uXDA@mail.gmail.com>
References: <CAB-TgNvke8riEgKbJYVLMo6BUZ+=gvFeqQUTdEzLGnk1CnDiGQ@mail.gmail.com>
 <CAGxFJbQnxqH9g=22W44bKm2S4_bTkZ0S4Nfw9Y415sM02xF4Jg@mail.gmail.com>
 <CAB-TgNv+yctvtxTsvMqz=Lg-fMaxa813hBQmDZ0hbWGmU0uXDA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A61A4@SRVEXCHCM301.precheza.cz>

Hi

seems to me like homework, this list has no homework policy.

For linear decay you can use

> temp<-c(10,9,8,7,6,5,4,3,2,1)
> plus <- seq(10,5, length=10)/100
> plot(1:10, temp, ylim=c(0, max(temp+plus)))
> lines(1:10, temp+temp*plus)
> lines(1:10, temp-temp*plus)
>
 for exponential you should solve equation

plus=a*exp(k*t)

for 10 = 0.1 and 1 = 0.05.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Pedro
> p?ramo
> Sent: Friday, June 2, 2017 8:37 AM
> To: Bert Gunter <bgunter.4567 at gmail.com>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] Upper bands and lower bands
>
> Sorry,
>
> For me a vector is a matrix with mx1 dimmensions. But it is true that it is not
> the way I correctly must talk in R.
>
> Can you guide me in what I?m trying to do? I?m trying to find what I want in
> Excel using something like a parabolic function but dind?t get yet (then to try
> to replicate in R).
>
>
> 2017-06-02 7:01 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
>
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Thu, Jun 1, 2017 at 11:20 AM, Pedro p?ramo <percentil101 at gmail.com>
> > wrote:
> > > Hi all
> > >
> > > I want to add a band of fluctuaci?n (exponential decreading) to a
> > > linear deacrecing values
> > >
> > > Imagine: I have a matrix like c(10,9,8,7,6,5,4,3,2,1)
> >
> > Ummm... That is not a matrix.  It's a vector.
> >
> > -- Bert
> >
> >
> > >
> > > The thing is I want  two new lines so that the m?ximum value of the
> > > new colum on the m?ximum is from 10% to 5% higher and the same
> lower
> > > for the m?nimum
> > >
> > > the final two matix will be something like
> > >
> > > c(10+0.10*10,9+0.089*9,8+0.075*8.....,1+0.05*1)
> > > c(10-0.10*10,9-0.09*9,8-0.075*8.....,1-0.05*1)
> > >
> > > What I?m looking for is a function tu calculate de "values, weights"
> > > so that including the 10% and 5% and the nunmber of decreasing
> > > values, in
> > this
> > > case n=10, calculates de smotth weigths.
> > >
> > > I don?t know if I have expalined well so thar finally putting
> > > initial
> > value
> > > final and periods I can find a matrix like
> > >
> > > g(0.1,0.89,0.79,0.075,...,0.05)
> > >
> > > Exists something like that?
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Jun  2 09:35:51 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 2 Jun 2017 07:35:51 +0000
Subject: [R] Problem of a function I wrote
In-Reply-To: <20170602022349.28714v1wv4gsjhkl@wmail1.cc.ntu.edu.tw>
References: <20170602020749.6993544krwgplrlh@wmail1.cc.ntu.edu.tw>
 <20170602021054.15087etgivvgoqlq@wmail1.cc.ntu.edu.tw>
 <20170602022349.28714v1wv4gsjhkl@wmail1.cc.ntu.edu.tw>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A61B6@SRVEXCHCM301.precheza.cz>

Hi

only some attachment types are alowed, see Posting Guide. Post your code with some toy data directly into body of your mail text.

From your explanation I wonder why you append vaues to vector, it is rarely necessary.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> b88207001 at ntu.edu.tw
> Sent: Thursday, June 1, 2017 8:24 PM
> To: b88207001 at ntu.edu.tw
> Cc: R-help at r-project.org
> Subject: Re: [R] Problem of a function I wrote
>
> Hello everyone,
>
> I know where is wrong. I forget to specify the parameters in my function.
> Thank you for anyone who was trying to help me!
>
> Best,
> Yen
>
> ?? b88207001 at ntu.edu.tw:
>
> > Hello everyone,
> >
> > It seems that I was not successfully attached the code. Here is the
> > code. I appreciate any help!
> >
> > Best,
> > Yen
> >
> > ?? b88207001 at ntu.edu.tw:
> >
> >> Hello everyone,
> >>
> >> I have been working on a code which simply repeatedly appends a
> >> number into a vector and write a file. However, it could not be
> >> properly implemented when I use it. It works when I run it line by
> >> line. I wonder what is the problem and I appreciate anyone who is
> >> willing to help.
> >>
> >> The function and the example code is attached. Any advice is appreciated!
> >>
> >> Best,
> >> Yen
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bgunter.4567 at gmail.com  Fri Jun  2 17:44:10 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 2 Jun 2017 08:44:10 -0700
Subject: [R] Reversing one dimension of an array, in a generalized case
In-Reply-To: <4CB71166-65AF-4790-A121-861D47A3DDEF@noaa.gov>
References: <314E3B2E-84E8-4312-80D7-3BB2EDD76182@noaa.gov>
 <CAGxFJbRm76=o6kwb7K3t4H+Qw4fNJv_K_Jicv1CzwR58zvo9OA@mail.gmail.com>
 <387b2b317a094e34a639a48a56402dec@exch-2p-mbx-w2.ads.tamu.edu>
 <CAGxFJbQ2w_1C3OmiVa_u1gA-VfYSfz3-6kHGJXMjr4=a8Pj0Ew@mail.gmail.com>
 <cf79d71578544504baf432288731b39c@exch-2p-mbx-w2.ads.tamu.edu>
 <F4A29415-0F72-4EBF-A960-DC9195722A63@noaa.gov>
 <C26CA739-162D-4F37-B203-84D1A8A97B02@gmail.com>
 <abb91d0ddbf84fc988a649b8399ba1c1@exch-2p-mbx-w2.ads.tamu.edu>
 <4CB71166-65AF-4790-A121-861D47A3DDEF@noaa.gov>
Message-ID: <CAGxFJbQ4LQ4Tervdsd5MbuPp0PBDNttWArk7As8T59WGSDJhoQ@mail.gmail.com>

At the very real risk of flogging a dead horse, I realized that it is
slightly cleaner to use the logical index TRUE in the argument list of
`[` rather than the seq_len(dim[i])  to indicate "everything" in the
ith array dimension. I post on list because maybe this might be a bit
informative to others (as it took me a while to realize it). Here is
the modified version of my function incorporating this variation:

f2 <-function(a, i){
   d <- dim(a)
   l <- as.list(rep(TRUE, length(d))) ## instead of lapply() loop
   l[[i]] <- seq.int(d[i],1)  ## used rev() in prior version
   do.call("[", c(list(a), l))
}


It may also be a teeny tiny bit more efficient to do this way, albeit
unimportantly so.

As this reproduces my prior function, if that was not what you wanted,
neither is this.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 1, 2017 at 1:59 PM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Thanks again.  I am going to try the different versions.   But I probably won't be able to get to it till next week.
>
> This is probably at the point where anything further should be sent to me privately.
>
> -Roy
>
>
>
>> On Jun 1, 2017, at 1:56 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>
>> On the off chance that anyone is still interested, here is the corrected function using aperm():
>>
>> z <- array(1:120,dim=2:5)
>> f2 <- function(a, wh) {
>>    idx <- seq_len(length(dim(a)))
>>    dims <- setdiff(idx, wh)
>>    idx <- append(idx[-1], idx[1], wh-1)
>>    aperm(apply(a, dims, rev), idx)
>> }
>>
>> all.equal(f(z, 1), f2(z, 1))
>> # [1] TRUE
>> all.equal(f(z, 2), f2(z, 2))
>> # [1] TRUE
>> all.equal(f(z, 3), f2(z, 3))
>> # [1] TRUE
>> all.equal(f(z, 4), f2(z, 4))
>> # [1] TRUE
>>
>> David C
>>
>>
>> From: Ismail SEZEN [mailto:sezenismail at gmail.com]
>> Sent: Thursday, June 1, 2017 3:35 PM
>> To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
>> Cc: David L Carlson <dcarlson at tamu.edu>; R-help <r-help at r-project.org>
>> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>>
>>
>> On 1 Jun 2017, at 22:42, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
>>
>> Thanks to all for responses/.  There was a question of exactly what was wanted.  It is the generalization of the obvious example I gave,
>>
>>
>> junk1 <- junk[, rev(seq_len(10), ]
>>
>>
>> so that
>>
>> junk[1,1,1 ] = junk1[1,10,1]
>> junk[1,2,1]  = junk1[1,9,1]
>>
>> etc.
>>
>> The genesis of this is the program is downloading data from a variety of sources on (time, altitude, lat, lon) coordinates,  but all the coordinates are not always there, and sometime the latitude coordinates go from north to south and sometimes from south to north.  I want to always return the data going from south to north, so if I find that the data is north to south,  I have to first reverse the array with the coordinate values (easy enough),  and then reverse the one dimension in the data array that corresponds to latitude. The downloaded information tells me which dimension is latitude plus how many coordinates are in the data.
>>
>> Hello Roy,
>> Perhaps you are aware of but I want to mention anyway. Basic issue is that you always want latitudes are monotonously increasing. Let me tell what I do when I read a ncdf file:
>>
>> 1- Set latitudes always monotonously decreasing (from 90 to -90)
>> 2- Set longitudes always mononously increasing but from -180 to 180.
>> 3- Set levels always monotonously decreasing (this is not relevant)
>>
>> Why? If you plan to plot variables in R, you will need coordinates in this order. For instance, if you set latitudes monotonously increasing, your map will be plotted upside down. To fix this, you will need reverse dimension again. And also if your longitudes ranges from 0 to 360, you will see the only the east side of the plot on a world map. West of Greencwich will be empty.  They were the problems that I faced last year when I tried to plot netcdf files using lattice and rasterVis packages.
>>
>>
>>
>>
>> As I the said,  I haven't done extensive testing on what Bert sent,  but on a toy 3-dimensional example I have it appeared to do what I want.
>>
>> Thanks again,
>>
>> -Roy
>>
>>
>> On Jun 1, 2017, at 12:22 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>
>> My error. Clearly I did not do enough testing.
>>
>> z <- array(1:24,dim=2:4)
>>
>> all.equal(f(z,1),f2(z,1))
>> [1] TRUE
>>
>> all.equal(f(z,2),f2(z,2))
>> [1] TRUE
>>
>> all.equal(f(z,3),f2(z,3))
>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
>> [2] "Mean relative difference: 0.6109091"
>>
>> # Your earlier example
>>
>> z <- array(1:120, dim=2:5)
>> all.equal(f(z,1),f2(z,1))
>> [1] TRUE
>>
>> all.equal(f(z,2),f2(z,2))
>> [1] TRUE
>>
>> all.equal(f(z,3),f2(z,3))
>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
>> [2] "Mean relative difference: 0.1262209"
>>
>> all.equal(f(z,4),f2(z,4))
>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.5714286 >"
>> [2] "Mean relative difference: 0.5855162"
>>
>> David C
>>
>> -----Original Message-----
>> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> Sent: Thursday, June 1, 2017 2:00 PM
>> To: David L Carlson <dcarlson at tamu.edu>
>> Cc: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>; R-help <r-help at r-project.org>
>> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>>
>> ??
>>
>>
>> z <- array(1:24,dim=2:4)
>> all.equal(f(z,3),f2(z,3))
>>
>> [1] "Attributes: < Component ?dim?: Mean relative difference: 0.4444444 >"
>> [2] "Mean relative difference: 0.6109091"
>>
>> In fact,
>>
>>
>> dim(f(z,3))
>> [1] 2 3 4
>>
>>
>> dim(f2(z,3))
>> [1] 3 4 2
>>
>> Have I made some sort of stupid error here? Or have I misunderstood
>> what was wanted?
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Jun 1, 2017 at 11:34 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>>
>> Here is an alternative approach using apply(). Note that with apply() you are reversing rows or columns not indices of rows or columns so apply(junk, 2, rev) reverses the values in each column not the column indices. We actually need to use rev() on everything but the index we are interested in reversing:
>>
>> f2 <- function(a, wh) {
>>   dims <- seq_len(length(dim(a)))
>>   dims <- setdiff(dims, wh)
>>   apply(apply(a, dims, rev), dims, t)
>> }
>>
>> # Your example
>> j1 <- junk[ , rev(1:10), ]
>> j2 <- f2(junk, 2)
>> all.equal(j1, j2)
>> # [1] TRUE
>>
>> # Bert's example
>> z1 <- f(z, 2)
>> z2 <- f2(z, 2)
>> all.equal(z1, z2)
>> # [1] TRUE
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>>
>>
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
>> Sent: Thursday, June 1, 2017 12:46 PM
>> To: Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov>
>> Cc: R-help <r-help at r-project.org>
>> Subject: Re: [R] Reversing one dimension of an array, in a generalized case
>>
>> How about this:
>>
>> f <- function(a,wh){ ## a is the array; wh is the index to be reversed
>>  l<- lapply(dim(a),seq_len)
>>  l[[wh]]<- rev(l[[wh]])
>>  do.call(`[`,c(list(a),l))
>> }
>>
>> ## test
>> z <- array(1:120,dim=2:5)
>>
>> ##  I omit the printouts
>>
>> f(z,2)
>>
>> f(z,3)
>>
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Jun 1, 2017 at 9:51 AM, Roy Mendelssohn - NOAA Federal
>> <roy.mendelssohn at noaa.gov> wrote:
>>
>> Hi All:
>>
>> I have been looking for an elegant way to do the following,  but haven't found it,  I have never had a good understanding of any of the "apply" functions.
>>
>> A simplified idea is I have an array, say:
>>
>> junk(5, 10, 3)
>>
>> where  (5, 10, 3) give the dimension sizes, and I want to reverse the second dimension, so I could do:
>>
>> junk1 <- junk[, rev(seq_len(10), ]
>>
>> but what I am after is a general function that will do that where the array could be two, three or four dimensions,  and I pass to the function which dimension I want to reverse, that is the function can not assume the number of dimensions of the array nor which dimension to reverse.
>>
>> For example,  if i try:
>>
>> junk1 <- apply(junk, 2, rev)
>>
>> junk1 comes out as two-dimensional,  not three-dimensional.
>>
>> It is probably something obvious but I am not getting it.
>>
>> Thanks for any help.
>>
>> -Roy
>>
>>
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>


From hannah.hlx at gmail.com  Fri Jun  2 21:47:37 2017
From: hannah.hlx at gmail.com (li li)
Date: Fri, 2 Jun 2017 15:47:37 -0400
Subject: [R] subletting an array according to dimnames
In-Reply-To: <CAN5YmCGjSQaR9wzjWFLMVvLrOqRjZnSf_Vrr-ArT5wnUKT0J_w@mail.gmail.com>
References: <CAHLnnda7opQRKukczBFuJMCAaoSK75eAuxvWksKiiSjYpdb8+Q@mail.gmail.com>
 <CAN5YmCGjSQaR9wzjWFLMVvLrOqRjZnSf_Vrr-ArT5wnUKT0J_w@mail.gmail.com>
Message-ID: <CAHLnndYFKjgvmE5RsaagBgjctBf-iX+vx+HJm9MUvbwd-3s-QA@mail.gmail.com>

That works. Thank you!

2017-06-02 8:00 GMT-04:00 Adams, Jean <jvadams at usgs.gov>:

> Have you tried P2["20", "10", "0"] ?
>
> Jean
>
> On Thu, Jun 1, 2017 at 3:10 PM, li li <hannah.hlx at gmail.com> wrote:
>
>> Hi all,
>>   I have a three dimensional array with the corresponding dimension names.
>> I would like to subset the array according to the dimension names. For
>> example,
>> suppose I want to extract the values corresponding to A=20, B=10, C=0.  I
>> know I
>> can do:
>>  P2[dimnames(P2)$A==20, dimnames(P2)$B==10, dimnames(P2)$C==0]
>>
>> But is there a better way for doing this? Thanks for your help!
>>   Hanna
>>
>> > dimnames(P2)
>>
>> $A
>>
>> [1] "20" "25" "30" "35" "40"
>>
>>
>> $B
>>
>> [1] "5"  "10" "15" "20" "25" "30" "35" "40"
>>
>>
>> $C
>>
>> [1] "0"  "5" "10" "15" "20" "25" "30" "35"
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From aanchalsharma833 at gmail.com  Fri Jun  2 23:22:11 2017
From: aanchalsharma833 at gmail.com (Aanchal Sharma)
Date: Fri, 2 Jun 2017 17:22:11 -0400
Subject: [R] comparing columns and printing overlapping rows
Message-ID: <CAFp0Li2T+8Byhj0JeXCph5S5RWgh-COCqY5Z1kV5Wa-vuKY43w@mail.gmail.com>

Hi All,

I have two files.
1. with only one column
2. data matrix

I need to compare first columns of both files and print the rows from
second file for the overlapping entries. I have solutions for awk and sed,
but I need how to do it in R.
Thanks

Regards
Anchal
-- 
Anchal Sharma, PhD
Postdoctoral Fellow
195, Little Albany street,
Cancer Institute of New Jersey
Rutgers University
NJ-08901

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Sat Jun  3 01:06:47 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 2 Jun 2017 23:06:47 +0000
Subject: [R] comparing columns and printing overlapping rows
In-Reply-To: <CAFp0Li2T+8Byhj0JeXCph5S5RWgh-COCqY5Z1kV5Wa-vuKY43w@mail.gmail.com>
References: <CAFp0Li2T+8Byhj0JeXCph5S5RWgh-COCqY5Z1kV5Wa-vuKY43w@mail.gmail.com>
Message-ID: <07734F23-9AA9-47E6-B1B7-6F276639255B@llnl.gov>

There are missing details, such as:

  what do you mean by "overlapping"?
  do the "files" have the same number of rows?
  do you care whether the "overlapping" entries are in the same row?
  what kind of R data structure do you have the "files" stored in?

Assuming your file 1 is stored in a vector and your file 2 is stored in a data frame,
then this example shows one possibility.

## make some example data
f1 <- c('a','b')

f2 <- data.frame( c1=sample(letters[1:5] , 6, replace=TRUE),
                 c2=1:6,
                 c3=month.abb[1:6]
                 )

## find rows in f2 in which a value in the first column of f2 is found in f1
subset(f2, f2$c1 %in% f1)


oh, and,
where's your reproducible example? which is generally expected; please see the posting guide
please don't send html email to r-help, it usually makes email unreadable on r-help


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 6/2/17, 2:22 PM, "R-help on behalf of Aanchal Sharma" <r-help-bounces at r-project.org on behalf of aanchalsharma833 at gmail.com> wrote:

    Hi All,
    
    I have two files.
    1. with only one column
    2. data matrix
    
    I need to compare first columns of both files and print the rows from
    second file for the overlapping entries. I have solutions for awk and sed,
    but I need how to do it in R.
    Thanks
    
    Regards
    Anchal
    -- 
    Anchal Sharma, PhD
    Postdoctoral Fellow
    195, Little Albany street,
    Cancer Institute of New Jersey
    Rutgers University
    NJ-08901
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From valkremk at gmail.com  Sat Jun  3 05:49:11 2017
From: valkremk at gmail.com (Val)
Date: Fri, 2 Jun 2017 22:49:11 -0500
Subject: [R] New var
Message-ID: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>

Hi all,

I have a data set with time interval and depending on the interval I want
to create 5 more variables . Sample data below

obs,   Start,   End
1,2/1/2015,  1/1/2017
2,4/11/2010, 1/1/2011
3,1/4/2006,  5/3/2007
4,10/1/2007, 1/1/2008
5,6/1/2011,  1/1/2012
6,10/15/2004,12/1/2004

First, I want get  interval between the start date and end dates
(End-start).

 obs,  Start , end, datediff
1,2/1/2015,  1/1/2017, 700
2,4/11/2010, 1/1/2011, 265
3,1/4/2006,  5/3/2007, 484
4,10/1/2007, 1/1/2008, 92
5,6/1/2011,  1/1/2012, 214
6,10/15/2004,12/1/2004,47

Second. I want create 5 more variables  t1, t2, t3, t4 and  t5
The value of each variable is defined as follows
if datediff <   100 then  t1=1,  t2=t3=t4=t5=-1.
if datediff >= 100 and  < 200 then  t1=0, t2=1,t3=t4=t5=-1,
if datediff >= 200 and  < 300 then  t1=0, t2=0,t3=1,t4=t5=-1,
if datediff >= 300 and  < 400 then  t1=0, t2=0,t3=0,t4=1,t5=-1,
if datediff >= 400 and  < 500 then  t1=0, t2=0,t3=0,t4=0,t5=1,
if datediff >= 500 then  t1=0, t2=0,t3=0,t4=0,t5=0

The complete out put looks like as follow.
obs, start,         end,    datediff,   t1, t2, t3, t4, t5
1,    2/1/2015,   1/1/2017,    700, 0,  0,  0,  0,  0
2,  4/11/2010,   1/1/2011,    265, 0,  0,  1, -1,  -1
3,    1/4/2006,   5/3/2007,    484, 0,  0,  0, 0,   1
4,   10/1/2007,  1/1/2008,      92, 1, -1, -1,-1,  -1
5 ,    6/1/2011,    1/1/2012,  214,  0,  0,  1,-1,  -1
6, 10/15/2004, 12/1/2004,     47, 1, -1, -1, -1, -1

Thank you.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Jun  3 06:57:52 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 02 Jun 2017 21:57:52 -0700
Subject: [R] New var
In-Reply-To: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>
References: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>
Message-ID: <FFD134D7-0900-45DC-A35A-DB02CC3B8CEF@dcn.davis.ca.us>

You do understand that this is not the "do my work for me" mailing list, don't you? You should be asking questions like "why doesn't my code do one of these if conditions?" so that you know HOW to write the rest of them yourself. 

In addition you have been posting here long enough to know that your use of HTML format means we get a scrambled version of what you think you posted. Go do your homework this time (follow the Posting Guide) and come back with a question that helps us help you instead of asking for us to provide you with free work. 
-- 
Sent from my phone. Please excuse my brevity.

On June 2, 2017 8:49:11 PM PDT, Val <valkremk at gmail.com> wrote:
>Hi all,
>
>I have a data set with time interval and depending on the interval I
>want
>to create 5 more variables . Sample data below
>
>obs,   Start,   End
>1,2/1/2015,  1/1/2017
>2,4/11/2010, 1/1/2011
>3,1/4/2006,  5/3/2007
>4,10/1/2007, 1/1/2008
>5,6/1/2011,  1/1/2012
>6,10/15/2004,12/1/2004
>
>First, I want get  interval between the start date and end dates
>(End-start).
>
> obs,  Start , end, datediff
>1,2/1/2015,  1/1/2017, 700
>2,4/11/2010, 1/1/2011, 265
>3,1/4/2006,  5/3/2007, 484
>4,10/1/2007, 1/1/2008, 92
>5,6/1/2011,  1/1/2012, 214
>6,10/15/2004,12/1/2004,47
>
>Second. I want create 5 more variables  t1, t2, t3, t4 and  t5
>The value of each variable is defined as follows
>if datediff <   100 then  t1=1,  t2=t3=t4=t5=-1.
>if datediff >= 100 and  < 200 then  t1=0, t2=1,t3=t4=t5=-1,
>if datediff >= 200 and  < 300 then  t1=0, t2=0,t3=1,t4=t5=-1,
>if datediff >= 300 and  < 400 then  t1=0, t2=0,t3=0,t4=1,t5=-1,
>if datediff >= 400 and  < 500 then  t1=0, t2=0,t3=0,t4=0,t5=1,
>if datediff >= 500 then  t1=0, t2=0,t3=0,t4=0,t5=0
>
>The complete out put looks like as follow.
>obs, start,         end,    datediff,   t1, t2, t3, t4, t5
>1,    2/1/2015,   1/1/2017,    700, 0,  0,  0,  0,  0
>2,  4/11/2010,   1/1/2011,    265, 0,  0,  1, -1,  -1
>3,    1/4/2006,   5/3/2007,    484, 0,  0,  0, 0,   1
>4,   10/1/2007,  1/1/2008,      92, 1, -1, -1,-1,  -1
>5 ,    6/1/2011,    1/1/2012,  214,  0,  0,  1,-1,  -1
>6, 10/15/2004, 12/1/2004,     47, 1, -1, -1, -1, -1
>
>Thank you.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Jun  3 07:13:13 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 2 Jun 2017 22:13:13 -0700
Subject: [R] New var
In-Reply-To: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>
References: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>
Message-ID: <CAGxFJbS1E8bqibBybgs25xZ5FPVAD=BY++J1g-HF3Kk5RkRCSw@mail.gmail.com>

Ii is difficult to provide useful help, because you have failed to
read and follow the posting guide. In particular:

1. Plain text, not HTML.
2. Use dput() or provide code to create your example. Text printouts
such as that which you gave require some work to wrangle into into an
example that we can test.

Specifically:

3. Have you gone through any R tutorials?-- it sure doesn't look like
it. We do expect some effort to learn R before posting.

4. What is the format of your date columns? character, factors,
POSIX,...? See ?date-time for details. Note particularly the
"difftime" link to obtain intervals.

5. ?ifelse  for vectorized conditionals.

Also, you might want to explain the context of what you are trying to
do. I strongly suspect you shouldn't be doing it at all, but that is
just a guess.

Be sure to cc your reply to the list, not just to me.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 2, 2017 at 8:49 PM, Val <valkremk at gmail.com> wrote:
> Hi all,
>
> I have a data set with time interval and depending on the interval I want
> to create 5 more variables . Sample data below
>
> obs,   Start,   End
> 1,2/1/2015,  1/1/2017
> 2,4/11/2010, 1/1/2011
> 3,1/4/2006,  5/3/2007
> 4,10/1/2007, 1/1/2008
> 5,6/1/2011,  1/1/2012
> 6,10/15/2004,12/1/2004
>
> First, I want get  interval between the start date and end dates
> (End-start).
>
>  obs,  Start , end, datediff
> 1,2/1/2015,  1/1/2017, 700
> 2,4/11/2010, 1/1/2011, 265
> 3,1/4/2006,  5/3/2007, 484
> 4,10/1/2007, 1/1/2008, 92
> 5,6/1/2011,  1/1/2012, 214
> 6,10/15/2004,12/1/2004,47
>
> Second. I want create 5 more variables  t1, t2, t3, t4 and  t5
> The value of each variable is defined as follows
> if datediff <   100 then  t1=1,  t2=t3=t4=t5=-1.
> if datediff >= 100 and  < 200 then  t1=0, t2=1,t3=t4=t5=-1,
> if datediff >= 200 and  < 300 then  t1=0, t2=0,t3=1,t4=t5=-1,
> if datediff >= 300 and  < 400 then  t1=0, t2=0,t3=0,t4=1,t5=-1,
> if datediff >= 400 and  < 500 then  t1=0, t2=0,t3=0,t4=0,t5=1,
> if datediff >= 500 then  t1=0, t2=0,t3=0,t4=0,t5=0
>
> The complete out put looks like as follow.
> obs, start,         end,    datediff,   t1, t2, t3, t4, t5
> 1,    2/1/2015,   1/1/2017,    700, 0,  0,  0,  0,  0
> 2,  4/11/2010,   1/1/2011,    265, 0,  0,  1, -1,  -1
> 3,    1/4/2006,   5/3/2007,    484, 0,  0,  0, 0,   1
> 4,   10/1/2007,  1/1/2008,      92, 1, -1, -1,-1,  -1
> 5 ,    6/1/2011,    1/1/2012,  214,  0,  0,  1,-1,  -1
> 6, 10/15/2004, 12/1/2004,     47, 1, -1, -1, -1, -1
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sat Jun  3 10:01:32 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 3 Jun 2017 10:01:32 +0200
Subject: [R] New var
In-Reply-To: <CAGxFJbS1E8bqibBybgs25xZ5FPVAD=BY++J1g-HF3Kk5RkRCSw@mail.gmail.com>
References: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>
 <CAGxFJbS1E8bqibBybgs25xZ5FPVAD=BY++J1g-HF3Kk5RkRCSw@mail.gmail.com>
Message-ID: <CBA48749-254D-4FBB-AF2E-A7B5458566BC@gmail.com>

As Bert says/implies, "some assembly is required".

as.Date() is your friend and you can basically just subtract those to get differences.  Also, it seems to me that you are really trying to convert differences to a factor, and then represent the factor using particular dummy variables for successive differences, for use in a linear model of sorts. A combination of cut() and a contrast matrix (see contrasts<-) might be a better structured approach.

-pd

> On 3 Jun 2017, at 07:13 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Ii is difficult to provide useful help, because you have failed to
> read and follow the posting guide. In particular:
> 
> 1. Plain text, not HTML.
> 2. Use dput() or provide code to create your example. Text printouts
> such as that which you gave require some work to wrangle into into an
> example that we can test.
> 
> Specifically:
> 
> 3. Have you gone through any R tutorials?-- it sure doesn't look like
> it. We do expect some effort to learn R before posting.
> 
> 4. What is the format of your date columns? character, factors,
> POSIX,...? See ?date-time for details. Note particularly the
> "difftime" link to obtain intervals.
> 
> 5. ?ifelse  for vectorized conditionals.
> 
> Also, you might want to explain the context of what you are trying to
> do. I strongly suspect you shouldn't be doing it at all, but that is
> just a guess.
> 
> Be sure to cc your reply to the list, not just to me.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Fri, Jun 2, 2017 at 8:49 PM, Val <valkremk at gmail.com> wrote:
>> Hi all,
>> 
>> I have a data set with time interval and depending on the interval I want
>> to create 5 more variables . Sample data below
>> 
>> obs,   Start,   End
>> 1,2/1/2015,  1/1/2017
>> 2,4/11/2010, 1/1/2011
>> 3,1/4/2006,  5/3/2007
>> 4,10/1/2007, 1/1/2008
>> 5,6/1/2011,  1/1/2012
>> 6,10/15/2004,12/1/2004
>> 
>> First, I want get  interval between the start date and end dates
>> (End-start).
>> 
>> obs,  Start , end, datediff
>> 1,2/1/2015,  1/1/2017, 700
>> 2,4/11/2010, 1/1/2011, 265
>> 3,1/4/2006,  5/3/2007, 484
>> 4,10/1/2007, 1/1/2008, 92
>> 5,6/1/2011,  1/1/2012, 214
>> 6,10/15/2004,12/1/2004,47
>> 
>> Second. I want create 5 more variables  t1, t2, t3, t4 and  t5
>> The value of each variable is defined as follows
>> if datediff <   100 then  t1=1,  t2=t3=t4=t5=-1.
>> if datediff >= 100 and  < 200 then  t1=0, t2=1,t3=t4=t5=-1,
>> if datediff >= 200 and  < 300 then  t1=0, t2=0,t3=1,t4=t5=-1,
>> if datediff >= 300 and  < 400 then  t1=0, t2=0,t3=0,t4=1,t5=-1,
>> if datediff >= 400 and  < 500 then  t1=0, t2=0,t3=0,t4=0,t5=1,
>> if datediff >= 500 then  t1=0, t2=0,t3=0,t4=0,t5=0
>> 
>> The complete out put looks like as follow.
>> obs, start,         end,    datediff,   t1, t2, t3, t4, t5
>> 1,    2/1/2015,   1/1/2017,    700, 0,  0,  0,  0,  0
>> 2,  4/11/2010,   1/1/2011,    265, 0,  0,  1, -1,  -1
>> 3,    1/4/2006,   5/3/2007,    484, 0,  0,  0, 0,   1
>> 4,   10/1/2007,  1/1/2008,      92, 1, -1, -1,-1,  -1
>> 5 ,    6/1/2011,    1/1/2012,  214,  0,  0,  1,-1,  -1
>> 6, 10/15/2004, 12/1/2004,     47, 1, -1, -1, -1, -1
>> 
>> Thank you.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From viveksutra at gmail.com  Sat Jun  3 12:31:57 2017
From: viveksutra at gmail.com (Vivek Sutradhara)
Date: Sat, 3 Jun 2017 12:31:57 +0200
Subject: [R] cygwin1.dll problems when installing packages from source
Message-ID: <CAHLp6SB+Vrm-OCAAu4vKaXsi3LRkiw5taV04wtWBasCvEsPrNQ@mail.gmail.com>

Hi all,
I am having some problems in updating some packages from source. I start
with :
install.packages("Boom",lib="C:/RownLib",type="source")

I get the following error message :

* installing *source* package 'Boom' ...
** package 'Boom' successfully unpacked and MD5 sums checked
** libs

*** arch - i386
c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
-I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
-DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
-c Models/Bart/Bart.cpp -o Models/Bart/Bart.o
      0 [main] make (3304) c:\Rtools\bin\make.exe: *** fatal error -
cygheap base mismatch detected - 0xD57408/0xC47408.
This problem is probably due to using incompatible versions of the cygwin DLL.
Search for cygwin1.dll using the Windows Start->Find/Search facility
and delete all but the most recent version.  The most recent version *should*
reside in x:\cygwin\bin, where 'x' is the drive on which you have
installed the cygwin distribution.  Rebooting is also suggested if you
are unable to find another cygwin DLL.
      0 [main] make 9868 fork: child -1 - forked process 3304 died
unexpectedly, retry 0, exit code 0xC0000142, errno 11
make: vfork: Resource temporarily unavailable
c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
-I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
-DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
-c Models/Bart/GaussianBartModel.cpp -o
Models/Bart/GaussianBartModel.o
      0 [main] make (5256) c:\Rtools\bin\make.exe: *** fatal error -
cygheap base mismatch detected - 0xD57408/0xEB7408.
This problem is probably due to using incompatible versions of the cygwin DLL.
Search for cygwin1.dll using the Windows Start->Find/Search facility
and delete all but the most recent version.  The most recent version *should*
reside in x:\cygwin\bin, where 'x' is the drive on which you have
installed the cygwin distribution.  Rebooting is also suggested if you
are unable to find another cygwin DLL.
  31956 [main] make 9868 fork: child -1 - forked process 5256 died
unexpectedly, retry 0, exit code 0xC0000142, errno 11
make: vfork: Resource temporarily unavailable
c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
-I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
-DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
-c Models/Bart/GaussianLinearBartModel.cpp -o
Models/Bart/GaussianLinearBartModel.o
      0 [main] make (2308) c:\Rtools\bin\make.exe: *** fatal error -
cygheap base mismatch detected - 0xD57408/0xDB7408.
This problem is probably due to using incompatible versions of the cygwin DLL.
Search for cygwin1.dll using the Windows Start->Find/Search facility
and delete all but the most recent version.  The most recent version *should*
reside in x:\cygwin\bin, where 'x' is the drive on which you have
installed the cygwin distribution.  Rebooting is also suggested if you
are unable to find another cygwin DLL.
  65040 [main] make 9868 fork: child -1 - forked process 2308 died
unexpectedly, retry 0, exit code 0xC0000142, errno 11
make: vfork: Resource temporarily unavailable
c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
-I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
-DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
-c Models/Bart/LogitBartModel.cpp -o Models/Bart/LogitBartModel.o
      0 [main] sh (1836) C:\Rtools\bin\sh.exe: *** fatal error -
cygheap base mismatch detected - 0xD57408/0xDD7408.
This problem is probably due to using incompatible versions of the cygwin DLL.
Search for cygwin1.dll using the Windows Start->Find/Search facility
and delete all but the most recent version.  The most recent version *should*
reside in x:\cygwin\bin, where 'x' is the drive on which you have
installed the cygwin distribution.  Rebooting is also suggested if you
are unable to find another cygwin DLL.
make: *** [Models/Bart/LogitBartModel.o] Error 127
Warning: running command 'make -f "Makevars" -f
"C:/R/R-34~1.0/etc/i386/Makeconf" -f
"C:/R/R-34~1.0/share/make/winshlib.mk" -f
"C:/Users/john/Documents/.R/Makevars" CXX='$(CXX11) $(CXX11STD)'
CXXFLAGS='$(CXX11FLAGS)' CXXPICFLAGS='$(CXX11PICFLAGS)'
SHLIB_LDFLAGS='$(SHLIB_CXX11LDFLAGS)' SHLIB_LD='$(SHLIB_CXX11LD)'
SHLIB="Boom.dll" ' had status 2
ERROR: compilation failed for package 'Boom'
* removing 'C:/RownLib/Boom'
* restoring previous 'C:/RownLib/Boom'
Warning in install.packages :
  running command '"C:/R/R-34~1.0/bin/x64/R" CMD INSTALL -l
"C:\RownLib" C:\TMP\Rtmpegxnel/downloaded_packages/Boom_0.7.tar.gz'
had status 1
Warning in install.packages :
  installation of package ?Boom? had non-zero exit status


> sessionInfo()R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=Swedish_Sweden.1252  LC_CTYPE=Swedish_Sweden.1252
LC_MONETARY=Swedish_Sweden.1252 LC_NUMERIC=C
[5] LC_TIME=Swedish_Sweden.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
 [1] shiny_1.0.3     compiler_3.4.0  R6_2.2.1        htmltools_0.3.6
tools_3.4.0     withr_1.0.2     Rcpp_0.12.11    memoise_1.1.0
 [9] git2r_0.18.0    digest_0.6.12   xtable_1.8-2    httpuv_1.3.3
mime_0.5        ghit_0.2.17     devtools_1.13.2

On checking, I have confirmed that the only location of
cygwin1.dll is :
C:\Rtools\bin

I have not had any similiar problems before prior R3.4. The only new
installation that I have done recently is python with
Anaconda2. But I can't see any cygwin1.dll there. I wonder what
the problem is. I will appreciate any help that I can get.

Thanks,

Vivek

	[[alternative HTML version deleted]]


From viveksutra at gmail.com  Sat Jun  3 12:55:51 2017
From: viveksutra at gmail.com (Vivek Sutradhara)
Date: Sat, 3 Jun 2017 12:55:51 +0200
Subject: [R] Fwd: cygwin1.dll problems when installing packages from source
In-Reply-To: <CAHLp6SB+Vrm-OCAAu4vKaXsi3LRkiw5taV04wtWBasCvEsPrNQ@mail.gmail.com>
References: <CAHLp6SB+Vrm-OCAAu4vKaXsi3LRkiw5taV04wtWBasCvEsPrNQ@mail.gmail.com>
Message-ID: <CAHLp6SAs1EHhC5U5OdWzTEZ5CbV+P9Ym6zQZt_+yAj6GCjV3kQ@mail.gmail.com>

Hi all,
I would just like to add that I have installed R3.4.0patched and again run
the same commands. This does not help. I get essentially the same error
message. It is just a lot more longer with multiple repetitions of
essentially the following :

c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0PA/include"
 -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
-DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
-c distributions/matrix_normal.cpp -o distributions/matrix_normal.o
      0 [main] make (5544) c:\Rtools\bin\make.exe: *** fatal error -
cygheap base mismatch detected - 0xBF7408/0xE17408.
This problem is probably due to using incompatible versions of the cygwin DLL.
Search for cygwin1.dll using the Windows Start->Find/Search facility
and delete all but the most recent version.  The most recent version *should*
reside in x:\cygwin\bin, where 'x' is the drive on which you have
installed the cygwin distribution.  Rebooting is also suggested if you
are unable to find another cygwin DLL.
 753152 [main] make 3132 fork: child -1 - forked process 5544 died
unexpectedly, retry 0, exit code 0xC0000142, errno 11
make: vfork: Resource temporarily unavailable
c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0PA/include"
 -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
-DNO_BOOST_

I would appreciate all help with troubleshooting.

Thanks,

Vivek

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Jun  3 12:57:03 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 3 Jun 2017 06:57:03 -0400
Subject: [R] cygwin1.dll problems when installing packages from source
In-Reply-To: <CAHLp6SB+Vrm-OCAAu4vKaXsi3LRkiw5taV04wtWBasCvEsPrNQ@mail.gmail.com>
References: <CAHLp6SB+Vrm-OCAAu4vKaXsi3LRkiw5taV04wtWBasCvEsPrNQ@mail.gmail.com>
Message-ID: <a23ab23e-de0f-63c5-4bd9-fd5c2e92540c@gmail.com>

On 03/06/2017 6:31 AM, Vivek Sutradhara wrote:
> Hi all,
> I am having some problems in updating some packages from source. I start
> with :
> install.packages("Boom",lib="C:/RownLib",type="source")
>
> I get the following error message :

Do you have multiple copies of cygwin1.dll?

Duncan Murdoch

>
> * installing *source* package 'Boom' ...
> ** package 'Boom' successfully unpacked and MD5 sums checked
> ** libs
>
> *** arch - i386
> c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
> -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
> -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c Models/Bart/Bart.cpp -o Models/Bart/Bart.o
>       0 [main] make (3304) c:\Rtools\bin\make.exe: *** fatal error -
> cygheap base mismatch detected - 0xD57408/0xC47408.
> This problem is probably due to using incompatible versions of the cygwin DLL.
> Search for cygwin1.dll using the Windows Start->Find/Search facility
> and delete all but the most recent version.  The most recent version *should*
> reside in x:\cygwin\bin, where 'x' is the drive on which you have
> installed the cygwin distribution.  Rebooting is also suggested if you
> are unable to find another cygwin DLL.
>       0 [main] make 9868 fork: child -1 - forked process 3304 died
> unexpectedly, retry 0, exit code 0xC0000142, errno 11
> make: vfork: Resource temporarily unavailable
> c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
> -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
> -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c Models/Bart/GaussianBartModel.cpp -o
> Models/Bart/GaussianBartModel.o
>       0 [main] make (5256) c:\Rtools\bin\make.exe: *** fatal error -
> cygheap base mismatch detected - 0xD57408/0xEB7408.
> This problem is probably due to using incompatible versions of the cygwin DLL.
> Search for cygwin1.dll using the Windows Start->Find/Search facility
> and delete all but the most recent version.  The most recent version *should*
> reside in x:\cygwin\bin, where 'x' is the drive on which you have
> installed the cygwin distribution.  Rebooting is also suggested if you
> are unable to find another cygwin DLL.
>   31956 [main] make 9868 fork: child -1 - forked process 5256 died
> unexpectedly, retry 0, exit code 0xC0000142, errno 11
> make: vfork: Resource temporarily unavailable
> c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
> -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
> -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c Models/Bart/GaussianLinearBartModel.cpp -o
> Models/Bart/GaussianLinearBartModel.o
>       0 [main] make (2308) c:\Rtools\bin\make.exe: *** fatal error -
> cygheap base mismatch detected - 0xD57408/0xDB7408.
> This problem is probably due to using incompatible versions of the cygwin DLL.
> Search for cygwin1.dll using the Windows Start->Find/Search facility
> and delete all but the most recent version.  The most recent version *should*
> reside in x:\cygwin\bin, where 'x' is the drive on which you have
> installed the cygwin distribution.  Rebooting is also suggested if you
> are unable to find another cygwin DLL.
>   65040 [main] make 9868 fork: child -1 - forked process 2308 died
> unexpectedly, retry 0, exit code 0xC0000142, errno 11
> make: vfork: Resource temporarily unavailable
> c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
> -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
> -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c Models/Bart/LogitBartModel.cpp -o Models/Bart/LogitBartModel.o
>       0 [main] sh (1836) C:\Rtools\bin\sh.exe: *** fatal error -
> cygheap base mismatch detected - 0xD57408/0xDD7408.
> This problem is probably due to using incompatible versions of the cygwin DLL.
> Search for cygwin1.dll using the Windows Start->Find/Search facility
> and delete all but the most recent version.  The most recent version *should*
> reside in x:\cygwin\bin, where 'x' is the drive on which you have
> installed the cygwin distribution.  Rebooting is also suggested if you
> are unable to find another cygwin DLL.
> make: *** [Models/Bart/LogitBartModel.o] Error 127
> Warning: running command 'make -f "Makevars" -f
> "C:/R/R-34~1.0/etc/i386/Makeconf" -f
> "C:/R/R-34~1.0/share/make/winshlib.mk" -f
> "C:/Users/john/Documents/.R/Makevars" CXX='$(CXX11) $(CXX11STD)'
> CXXFLAGS='$(CXX11FLAGS)' CXXPICFLAGS='$(CXX11PICFLAGS)'
> SHLIB_LDFLAGS='$(SHLIB_CXX11LDFLAGS)' SHLIB_LD='$(SHLIB_CXX11LD)'
> SHLIB="Boom.dll" ' had status 2
> ERROR: compilation failed for package 'Boom'
> * removing 'C:/RownLib/Boom'
> * restoring previous 'C:/RownLib/Boom'
> Warning in install.packages :
>   running command '"C:/R/R-34~1.0/bin/x64/R" CMD INSTALL -l
> "C:\RownLib" C:\TMP\Rtmpegxnel/downloaded_packages/Boom_0.7.tar.gz'
> had status 1
> Warning in install.packages :
>   installation of package ?Boom? had non-zero exit status
>
>
>> sessionInfo()R version 3.4.0 (2017-04-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=Swedish_Sweden.1252  LC_CTYPE=Swedish_Sweden.1252
> LC_MONETARY=Swedish_Sweden.1252 LC_NUMERIC=C
> [5] LC_TIME=Swedish_Sweden.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
>  [1] shiny_1.0.3     compiler_3.4.0  R6_2.2.1        htmltools_0.3.6
> tools_3.4.0     withr_1.0.2     Rcpp_0.12.11    memoise_1.1.0
>  [9] git2r_0.18.0    digest_0.6.12   xtable_1.8-2    httpuv_1.3.3
> mime_0.5        ghit_0.2.17     devtools_1.13.2
>
> On checking, I have confirmed that the only location of
> cygwin1.dll is :
> C:\Rtools\bin
>
> I have not had any similiar problems before prior R3.4. The only new
> installation that I have done recently is python with
> Anaconda2. But I can't see any cygwin1.dll there. I wonder what
> the problem is. I will appreciate any help that I can get.
>
> Thanks,
>
> Vivek
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From viveksutra at gmail.com  Sat Jun  3 13:00:29 2017
From: viveksutra at gmail.com (Vivek Sutradhara)
Date: Sat, 3 Jun 2017 13:00:29 +0200
Subject: [R] cygwin1.dll problems when installing packages from source
In-Reply-To: <a23ab23e-de0f-63c5-4bd9-fd5c2e92540c@gmail.com>
References: <CAHLp6SB+Vrm-OCAAu4vKaXsi3LRkiw5taV04wtWBasCvEsPrNQ@mail.gmail.com>
 <a23ab23e-de0f-63c5-4bd9-fd5c2e92540c@gmail.com>
Message-ID: <CAHLp6SCyA_Kx4AsjTejr4bhoPVkeNG8vD1f4rTqK2hHeRFkPSQ@mail.gmail.com>

Hi,
As far as I can see, no.

On checking, I have confirmed that the only location of
cygwin1.dll is :
C:\Rtools\bin

Thanks
Vivek

2017-06-03 12:57 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 03/06/2017 6:31 AM, Vivek Sutradhara wrote:
>
>> Hi all,
>> I am having some problems in updating some packages from source. I start
>> with :
>> install.packages("Boom",lib="C:/RownLib",type="source")
>>
>> I get the following error message :
>>
>
> Do you have multiple copies of cygwin1.dll?
>
> Duncan Murdoch
>
>
>> * installing *source* package 'Boom' ...
>> ** package 'Boom' successfully unpacked and MD5 sums checked
>> ** libs
>>
>> *** arch - i386
>> c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>> -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>> -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
>> -c Models/Bart/Bart.cpp -o Models/Bart/Bart.o
>>       0 [main] make (3304) c:\Rtools\bin\make.exe: *** fatal error -
>> cygheap base mismatch detected - 0xD57408/0xC47408.
>> This problem is probably due to using incompatible versions of the cygwin
>> DLL.
>> Search for cygwin1.dll using the Windows Start->Find/Search facility
>> and delete all but the most recent version.  The most recent version
>> *should*
>> reside in x:\cygwin\bin, where 'x' is the drive on which you have
>> installed the cygwin distribution.  Rebooting is also suggested if you
>> are unable to find another cygwin DLL.
>>       0 [main] make 9868 fork: child -1 - forked process 3304 died
>> unexpectedly, retry 0, exit code 0xC0000142, errno 11
>> make: vfork: Resource temporarily unavailable
>> c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>> -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>> -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
>> -c Models/Bart/GaussianBartModel.cpp -o
>> Models/Bart/GaussianBartModel.o
>>       0 [main] make (5256) c:\Rtools\bin\make.exe: *** fatal error -
>> cygheap base mismatch detected - 0xD57408/0xEB7408.
>> This problem is probably due to using incompatible versions of the cygwin
>> DLL.
>> Search for cygwin1.dll using the Windows Start->Find/Search facility
>> and delete all but the most recent version.  The most recent version
>> *should*
>> reside in x:\cygwin\bin, where 'x' is the drive on which you have
>> installed the cygwin distribution.  Rebooting is also suggested if you
>> are unable to find another cygwin DLL.
>>   31956 [main] make 9868 fork: child -1 - forked process 5256 died
>> unexpectedly, retry 0, exit code 0xC0000142, errno 11
>> make: vfork: Resource temporarily unavailable
>> c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>> -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>> -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
>> -c Models/Bart/GaussianLinearBartModel.cpp -o
>> Models/Bart/GaussianLinearBartModel.o
>>       0 [main] make (2308) c:\Rtools\bin\make.exe: *** fatal error -
>> cygheap base mismatch detected - 0xD57408/0xDB7408.
>> This problem is probably due to using incompatible versions of the cygwin
>> DLL.
>> Search for cygwin1.dll using the Windows Start->Find/Search facility
>> and delete all but the most recent version.  The most recent version
>> *should*
>> reside in x:\cygwin\bin, where 'x' is the drive on which you have
>> installed the cygwin distribution.  Rebooting is also suggested if you
>> are unable to find another cygwin DLL.
>>   65040 [main] make 9868 fork: child -1 - forked process 2308 died
>> unexpectedly, retry 0, exit code 0xC0000142, errno 11
>> make: vfork: Resource temporarily unavailable
>> c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>> -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>> -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
>> -c Models/Bart/LogitBartModel.cpp -o Models/Bart/LogitBartModel.o
>>       0 [main] sh (1836) C:\Rtools\bin\sh.exe: *** fatal error -
>> cygheap base mismatch detected - 0xD57408/0xDD7408.
>> This problem is probably due to using incompatible versions of the cygwin
>> DLL.
>> Search for cygwin1.dll using the Windows Start->Find/Search facility
>> and delete all but the most recent version.  The most recent version
>> *should*
>> reside in x:\cygwin\bin, where 'x' is the drive on which you have
>> installed the cygwin distribution.  Rebooting is also suggested if you
>> are unable to find another cygwin DLL.
>> make: *** [Models/Bart/LogitBartModel.o] Error 127
>> Warning: running command 'make -f "Makevars" -f
>> "C:/R/R-34~1.0/etc/i386/Makeconf" -f
>> "C:/R/R-34~1.0/share/make/winshlib.mk" -f
>> "C:/Users/john/Documents/.R/Makevars" CXX='$(CXX11) $(CXX11STD)'
>> CXXFLAGS='$(CXX11FLAGS)' CXXPICFLAGS='$(CXX11PICFLAGS)'
>> SHLIB_LDFLAGS='$(SHLIB_CXX11LDFLAGS)' SHLIB_LD='$(SHLIB_CXX11LD)'
>> SHLIB="Boom.dll" ' had status 2
>> ERROR: compilation failed for package 'Boom'
>> * removing 'C:/RownLib/Boom'
>> * restoring previous 'C:/RownLib/Boom'
>> Warning in install.packages :
>>   running command '"C:/R/R-34~1.0/bin/x64/R" CMD INSTALL -l
>> "C:\RownLib" C:\TMP\Rtmpegxnel/downloaded_packages/Boom_0.7.tar.gz'
>> had status 1
>> Warning in install.packages :
>>   installation of package ?Boom? had non-zero exit status
>>
>>
>> sessionInfo()R version 3.4.0 (2017-04-21)
>>>
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows >= 8 x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=Swedish_Sweden.1252  LC_CTYPE=Swedish_Sweden.1252
>> LC_MONETARY=Swedish_Sweden.1252 LC_NUMERIC=C
>> [5] LC_TIME=Swedish_Sweden.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>>  [1] shiny_1.0.3     compiler_3.4.0  R6_2.2.1        htmltools_0.3.6
>> tools_3.4.0     withr_1.0.2     Rcpp_0.12.11    memoise_1.1.0
>>  [9] git2r_0.18.0    digest_0.6.12   xtable_1.8-2    httpuv_1.3.3
>> mime_0.5        ghit_0.2.17     devtools_1.13.2
>>
>> On checking, I have confirmed that the only location of
>> cygwin1.dll is :
>> C:\Rtools\bin
>>
>> I have not had any similiar problems before prior R3.4. The only new
>> installation that I have done recently is python with
>> Anaconda2. But I can't see any cygwin1.dll there. I wonder what
>> the problem is. I will appreciate any help that I can get.
>>
>> Thanks,
>>
>> Vivek
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Jun  3 13:09:43 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 3 Jun 2017 07:09:43 -0400
Subject: [R] cygwin1.dll problems when installing packages from source
In-Reply-To: <CAHLp6SCyA_Kx4AsjTejr4bhoPVkeNG8vD1f4rTqK2hHeRFkPSQ@mail.gmail.com>
References: <CAHLp6SB+Vrm-OCAAu4vKaXsi3LRkiw5taV04wtWBasCvEsPrNQ@mail.gmail.com>
 <a23ab23e-de0f-63c5-4bd9-fd5c2e92540c@gmail.com>
 <CAHLp6SCyA_Kx4AsjTejr4bhoPVkeNG8vD1f4rTqK2hHeRFkPSQ@mail.gmail.com>
Message-ID: <dc717846-6ff7-413f-c069-bde16c215677@gmail.com>

On 03/06/2017 7:00 AM, Vivek Sutradhara wrote:
> Hi,
> As far as I can see, no.
>
> On checking, I have confirmed that the only location of
> cygwin1.dll is :
> C:\Rtools\bin

I would re-install Rtools, and make sure C:\Rtools\bin appears first in 
your PATH.

Duncan Murdoch

>
> Thanks
> Vivek
>
> 2017-06-03 12:57 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>>:
>
>     On 03/06/2017 6:31 AM, Vivek Sutradhara wrote:
>
>         Hi all,
>         I am having some problems in updating some packages from source.
>         I start
>         with :
>         install.packages("Boom",lib="C:/RownLib",type="source")
>
>         I get the following error message :
>
>
>     Do you have multiple copies of cygwin1.dll?
>
>     Duncan Murdoch
>
>
>         * installing *source* package 'Boom' ...
>         ** package 'Boom' successfully unpacked and MD5 sums checked
>         ** libs
>
>         *** arch - i386
>         c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>         -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>         -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>         -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall
>         -mtune=core2
>         -c Models/Bart/Bart.cpp -o Models/Bart/Bart.o
>               0 [main] make (3304) c:\Rtools\bin\make.exe: *** fatal error -
>         cygheap base mismatch detected - 0xD57408/0xC47408.
>         This problem is probably due to using incompatible versions of
>         the cygwin DLL.
>         Search for cygwin1.dll using the Windows Start->Find/Search facility
>         and delete all but the most recent version.  The most recent
>         version *should*
>         reside in x:\cygwin\bin, where 'x' is the drive on which you have
>         installed the cygwin distribution.  Rebooting is also suggested
>         if you
>         are unable to find another cygwin DLL.
>               0 [main] make 9868 fork: child -1 - forked process 3304 died
>         unexpectedly, retry 0, exit code 0xC0000142, errno 11
>         make: vfork: Resource temporarily unavailable
>         c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>         -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>         -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>         -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall
>         -mtune=core2
>         -c Models/Bart/GaussianBartModel.cpp -o
>         Models/Bart/GaussianBartModel.o
>               0 [main] make (5256) c:\Rtools\bin\make.exe: *** fatal error -
>         cygheap base mismatch detected - 0xD57408/0xEB7408.
>         This problem is probably due to using incompatible versions of
>         the cygwin DLL.
>         Search for cygwin1.dll using the Windows Start->Find/Search facility
>         and delete all but the most recent version.  The most recent
>         version *should*
>         reside in x:\cygwin\bin, where 'x' is the drive on which you have
>         installed the cygwin distribution.  Rebooting is also suggested
>         if you
>         are unable to find another cygwin DLL.
>           31956 [main] make 9868 fork: child -1 - forked process 5256 died
>         unexpectedly, retry 0, exit code 0xC0000142, errno 11
>         make: vfork: Resource temporarily unavailable
>         c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>         -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>         -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>         -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall
>         -mtune=core2
>         -c Models/Bart/GaussianLinearBartModel.cpp -o
>         Models/Bart/GaussianLinearBartModel.o
>               0 [main] make (2308) c:\Rtools\bin\make.exe: *** fatal error -
>         cygheap base mismatch detected - 0xD57408/0xDB7408.
>         This problem is probably due to using incompatible versions of
>         the cygwin DLL.
>         Search for cygwin1.dll using the Windows Start->Find/Search facility
>         and delete all but the most recent version.  The most recent
>         version *should*
>         reside in x:\cygwin\bin, where 'x' is the drive on which you have
>         installed the cygwin distribution.  Rebooting is also suggested
>         if you
>         are unable to find another cygwin DLL.
>           65040 [main] make 9868 fork: child -1 - forked process 2308 died
>         unexpectedly, retry 0, exit code 0xC0000142, errno 11
>         make: vfork: Resource temporarily unavailable
>         c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>         -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>         -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>         -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall
>         -mtune=core2
>         -c Models/Bart/LogitBartModel.cpp -o Models/Bart/LogitBartModel.o
>               0 [main] sh (1836) C:\Rtools\bin\sh.exe: *** fatal error -
>         cygheap base mismatch detected - 0xD57408/0xDD7408.
>         This problem is probably due to using incompatible versions of
>         the cygwin DLL.
>         Search for cygwin1.dll using the Windows Start->Find/Search facility
>         and delete all but the most recent version.  The most recent
>         version *should*
>         reside in x:\cygwin\bin, where 'x' is the drive on which you have
>         installed the cygwin distribution.  Rebooting is also suggested
>         if you
>         are unable to find another cygwin DLL.
>         make: *** [Models/Bart/LogitBartModel.o] Error 127
>         Warning: running command 'make -f "Makevars" -f
>         "C:/R/R-34~1.0/etc/i386/Makeconf" -f
>         "C:/R/R-34~1.0/share/make/winshlib.mk <http://winshlib.mk>" -f
>         "C:/Users/john/Documents/.R/Makevars" CXX='$(CXX11) $(CXX11STD)'
>         CXXFLAGS='$(CXX11FLAGS)' CXXPICFLAGS='$(CXX11PICFLAGS)'
>         SHLIB_LDFLAGS='$(SHLIB_CXX11LDFLAGS)' SHLIB_LD='$(SHLIB_CXX11LD)'
>         SHLIB="Boom.dll" ' had status 2
>         ERROR: compilation failed for package 'Boom'
>         * removing 'C:/RownLib/Boom'
>         * restoring previous 'C:/RownLib/Boom'
>         Warning in install.packages :
>           running command '"C:/R/R-34~1.0/bin/x64/R" CMD INSTALL -l
>         "C:\RownLib" C:\TMP\Rtmpegxnel/downloaded_packages/Boom_0.7.tar.gz'
>         had status 1
>         Warning in install.packages :
>           installation of package ?Boom? had non-zero exit status
>
>
>             sessionInfo()R version 3.4.0 (2017-04-21)
>
>         Platform: x86_64-w64-mingw32/x64 (64-bit)
>         Running under: Windows >= 8 x64 (build 9200)
>
>         Matrix products: default
>
>         locale:
>         [1] LC_COLLATE=Swedish_Sweden.1252  LC_CTYPE=Swedish_Sweden.1252
>         LC_MONETARY=Swedish_Sweden.1252 LC_NUMERIC=C
>         [5] LC_TIME=Swedish_Sweden.1252
>
>         attached base packages:
>         [1] stats     graphics  grDevices utils     datasets  methods   base
>
>         loaded via a namespace (and not attached):
>          [1] shiny_1.0.3     compiler_3.4.0  R6_2.2.1        htmltools_0.3.6
>         tools_3.4.0     withr_1.0.2     Rcpp_0.12.11    memoise_1.1.0
>          [9] git2r_0.18.0    digest_0.6.12   xtable_1.8-2    httpuv_1.3.3
>         mime_0.5        ghit_0.2.17     devtools_1.13.2
>
>         On checking, I have confirmed that the only location of
>         cygwin1.dll is :
>         C:\Rtools\bin
>
>         I have not had any similiar problems before prior R3.4. The only new
>         installation that I have done recently is python with
>         Anaconda2. But I can't see any cygwin1.dll there. I wonder what
>         the problem is. I will appreciate any help that I can get.
>
>         Thanks,
>
>         Vivek
>
>                 [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>


From viveksutra at gmail.com  Sat Jun  3 14:14:52 2017
From: viveksutra at gmail.com (Vivek Sutradhara)
Date: Sat, 3 Jun 2017 14:14:52 +0200
Subject: [R] cygwin1.dll problems when installing packages from source
In-Reply-To: <dc717846-6ff7-413f-c069-bde16c215677@gmail.com>
References: <CAHLp6SB+Vrm-OCAAu4vKaXsi3LRkiw5taV04wtWBasCvEsPrNQ@mail.gmail.com>
 <a23ab23e-de0f-63c5-4bd9-fd5c2e92540c@gmail.com>
 <CAHLp6SCyA_Kx4AsjTejr4bhoPVkeNG8vD1f4rTqK2hHeRFkPSQ@mail.gmail.com>
 <dc717846-6ff7-413f-c069-bde16c215677@gmail.com>
Message-ID: <CAHLp6SDJCydYhTrp2SYERgkJATytPeYJJ7XXHcGG2S7Zv=j=KA@mail.gmail.com>

Hi,
I have now re-installed Rtools. This has solved my problem.

Even previously, Rtools was the first on the path. However, thanks a lot
for this help. I can now move on.
Thanks,
Vivek

2017-06-03 13:09 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 03/06/2017 7:00 AM, Vivek Sutradhara wrote:
>
>> Hi,
>> As far as I can see, no.
>>
>> On checking, I have confirmed that the only location of
>> cygwin1.dll is :
>> C:\Rtools\bin
>>
>
> I would re-install Rtools, and make sure C:\Rtools\bin appears first in
> your PATH.
>
> Duncan Murdoch
>
>
>> Thanks
>> Vivek
>>
>> 2017-06-03 12:57 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>>:
>>
>>     On 03/06/2017 6:31 AM, Vivek Sutradhara wrote:
>>
>>         Hi all,
>>         I am having some problems in updating some packages from source.
>>         I start
>>         with :
>>         install.packages("Boom",lib="C:/RownLib",type="source")
>>
>>         I get the following error message :
>>
>>
>>     Do you have multiple copies of cygwin1.dll?
>>
>>     Duncan Murdoch
>>
>>
>>         * installing *source* package 'Boom' ...
>>         ** package 'Boom' successfully unpacked and MD5 sums checked
>>         ** libs
>>
>>         *** arch - i386
>>         c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>>         -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>>         -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>>         -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall
>>         -mtune=core2
>>         -c Models/Bart/Bart.cpp -o Models/Bart/Bart.o
>>               0 [main] make (3304) c:\Rtools\bin\make.exe: *** fatal
>> error -
>>         cygheap base mismatch detected - 0xD57408/0xC47408.
>>         This problem is probably due to using incompatible versions of
>>         the cygwin DLL.
>>         Search for cygwin1.dll using the Windows Start->Find/Search
>> facility
>>         and delete all but the most recent version.  The most recent
>>         version *should*
>>         reside in x:\cygwin\bin, where 'x' is the drive on which you have
>>         installed the cygwin distribution.  Rebooting is also suggested
>>         if you
>>         are unable to find another cygwin DLL.
>>               0 [main] make 9868 fork: child -1 - forked process 3304 died
>>         unexpectedly, retry 0, exit code 0xC0000142, errno 11
>>         make: vfork: Resource temporarily unavailable
>>         c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>>         -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>>         -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>>         -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall
>>         -mtune=core2
>>         -c Models/Bart/GaussianBartModel.cpp -o
>>         Models/Bart/GaussianBartModel.o
>>               0 [main] make (5256) c:\Rtools\bin\make.exe: *** fatal
>> error -
>>         cygheap base mismatch detected - 0xD57408/0xEB7408.
>>         This problem is probably due to using incompatible versions of
>>         the cygwin DLL.
>>         Search for cygwin1.dll using the Windows Start->Find/Search
>> facility
>>         and delete all but the most recent version.  The most recent
>>         version *should*
>>         reside in x:\cygwin\bin, where 'x' is the drive on which you have
>>         installed the cygwin distribution.  Rebooting is also suggested
>>         if you
>>         are unable to find another cygwin DLL.
>>           31956 [main] make 9868 fork: child -1 - forked process 5256 died
>>         unexpectedly, retry 0, exit code 0xC0000142, errno 11
>>         make: vfork: Resource temporarily unavailable
>>         c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>>         -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>>         -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>>         -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall
>>         -mtune=core2
>>         -c Models/Bart/GaussianLinearBartModel.cpp -o
>>         Models/Bart/GaussianLinearBartModel.o
>>               0 [main] make (2308) c:\Rtools\bin\make.exe: *** fatal
>> error -
>>         cygheap base mismatch detected - 0xD57408/0xDB7408.
>>         This problem is probably due to using incompatible versions of
>>         the cygwin DLL.
>>         Search for cygwin1.dll using the Windows Start->Find/Search
>> facility
>>         and delete all but the most recent version.  The most recent
>>         version *should*
>>         reside in x:\cygwin\bin, where 'x' is the drive on which you have
>>         installed the cygwin distribution.  Rebooting is also suggested
>>         if you
>>         are unable to find another cygwin DLL.
>>           65040 [main] make 9868 fork: child -1 - forked process 2308 died
>>         unexpectedly, retry 0, exit code 0xC0000142, errno 11
>>         make: vfork: Resource temporarily unavailable
>>         c:/Rtools/mingw_32/bin/g++  -std=gnu++11 -I"C:/R/R-34~1.0/include"
>>         -I. -I../inst/include -IBmath -Imath/cephes -DNO_BOOST_THREADS
>>         -DNO_BOOST_FILESYSTEM -DADD_ -DRLANGUAGE -I"C:/RownLib/BH/include"
>>         -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall
>>         -mtune=core2
>>         -c Models/Bart/LogitBartModel.cpp -o Models/Bart/LogitBartModel.o
>>               0 [main] sh (1836) C:\Rtools\bin\sh.exe: *** fatal error -
>>         cygheap base mismatch detected - 0xD57408/0xDD7408.
>>         This problem is probably due to using incompatible versions of
>>         the cygwin DLL.
>>         Search for cygwin1.dll using the Windows Start->Find/Search
>> facility
>>         and delete all but the most recent version.  The most recent
>>         version *should*
>>         reside in x:\cygwin\bin, where 'x' is the drive on which you have
>>         installed the cygwin distribution.  Rebooting is also suggested
>>         if you
>>         are unable to find another cygwin DLL.
>>         make: *** [Models/Bart/LogitBartModel.o] Error 127
>>         Warning: running command 'make -f "Makevars" -f
>>         "C:/R/R-34~1.0/etc/i386/Makeconf" -f
>>         "C:/R/R-34~1.0/share/make/winshlib.mk <http://winshlib.mk>" -f
>>         "C:/Users/john/Documents/.R/Makevars" CXX='$(CXX11) $(CXX11STD)'
>>         CXXFLAGS='$(CXX11FLAGS)' CXXPICFLAGS='$(CXX11PICFLAGS)'
>>         SHLIB_LDFLAGS='$(SHLIB_CXX11LDFLAGS)' SHLIB_LD='$(SHLIB_CXX11LD)'
>>         SHLIB="Boom.dll" ' had status 2
>>         ERROR: compilation failed for package 'Boom'
>>         * removing 'C:/RownLib/Boom'
>>         * restoring previous 'C:/RownLib/Boom'
>>         Warning in install.packages :
>>           running command '"C:/R/R-34~1.0/bin/x64/R" CMD INSTALL -l
>>         "C:\RownLib" C:\TMP\Rtmpegxnel/downloaded_p
>> ackages/Boom_0.7.tar.gz'
>>         had status 1
>>         Warning in install.packages :
>>           installation of package ?Boom? had non-zero exit status
>>
>>
>>             sessionInfo()R version 3.4.0 (2017-04-21)
>>
>>         Platform: x86_64-w64-mingw32/x64 (64-bit)
>>         Running under: Windows >= 8 x64 (build 9200)
>>
>>         Matrix products: default
>>
>>         locale:
>>         [1] LC_COLLATE=Swedish_Sweden.1252  LC_CTYPE=Swedish_Sweden.1252
>>         LC_MONETARY=Swedish_Sweden.1252 LC_NUMERIC=C
>>         [5] LC_TIME=Swedish_Sweden.1252
>>
>>         attached base packages:
>>         [1] stats     graphics  grDevices utils     datasets  methods
>>  base
>>
>>         loaded via a namespace (and not attached):
>>          [1] shiny_1.0.3     compiler_3.4.0  R6_2.2.1
>> htmltools_0.3.6
>>         tools_3.4.0     withr_1.0.2     Rcpp_0.12.11    memoise_1.1.0
>>          [9] git2r_0.18.0    digest_0.6.12   xtable_1.8-2    httpuv_1.3.3
>>         mime_0.5        ghit_0.2.17     devtools_1.13.2
>>
>>         On checking, I have confirmed that the only location of
>>         cygwin1.dll is :
>>         C:\Rtools\bin
>>
>>         I have not had any similiar problems before prior R3.4. The only
>> new
>>         installation that I have done recently is python with
>>         Anaconda2. But I can't see any cygwin1.dll there. I wonder what
>>         the problem is. I will appreciate any help that I can get.
>>
>>         Thanks,
>>
>>         Vivek
>>
>>                 [[alternative HTML version deleted]]
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>         -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Sat Jun  3 21:09:33 2017
From: valkremk at gmail.com (Val)
Date: Sat, 3 Jun 2017 14:09:33 -0500
Subject: [R] New var
In-Reply-To: <CAGxFJbS1E8bqibBybgs25xZ5FPVAD=BY++J1g-HF3Kk5RkRCSw@mail.gmail.com>
References: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>
 <CAGxFJbS1E8bqibBybgs25xZ5FPVAD=BY++J1g-HF3Kk5RkRCSw@mail.gmail.com>
Message-ID: <CAJOiR6bnLd745OL2eQOgvocRrrmZ-TwSbXJK_9Yp+5NETE1HMw@mail.gmail.com>

Thank you all for the useful suggestion. I did some of my homework.

library(data.table)
DFM <- read.table(header=TRUE, text='obs start end
1 2/1/2015   1/1/2017
2 4/11/2010  1/1/2011
3 1/4/2006   5/3/2007
4 10/1/2007  1/1/2008
5 6/1/2011   1/1/2012
6 10/5/2004 12/1/2004',stringsAsFactors = FALSE)
DFM

DFM$D =as.numeric(difftime(as.Date(DFM$end,format="%m/%d/%Y"),
as.Date(DFM$start,format="%m/%d/%Y"), units = "days"))
DFM

output.
     obs     start       end   D
1   1  2/1/2015  1/1/2017 700
2   2 4/11/2010  1/1/2011 265
3   3  1/4/2006  5/3/2007 484
4   4 10/1/2007  1/1/2008  92
5   5  6/1/2011  1/1/2012 214
6   6 10/5/2004 12/1/2004  57

My problem is how do I get the other new variables

obs     start       end   D  t1,t2,t3,t4, t5
1, 2/1/2015,  1/1/2017, 700,0,0,0,0,0
2, 4/11/2010, 1/1/2011, 265,0,0,1,-1,-1
3, 1/4/2006,  5/3/2007, 484,0,0,0,0,1
4, 10/1/2007, 1/1/2008, 92,1,-1,-1,-1,-1
5, 6/1/2011,  1/1/2012, 214,0,0,1,-1,-1
6, 10/15/2004,12/1/2004,47,1,-1,-1,-1,-1

Thank you again.



On Sat, Jun 3, 2017 at 12:13 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Ii is difficult to provide useful help, because you have failed to
> read and follow the posting guide. In particular:
>
> 1. Plain text, not HTML.
> 2. Use dput() or provide code to create your example. Text printouts
> such as that which you gave require some work to wrangle into into an
> example that we can test.
>
> Specifically:
>
> 3. Have you gone through any R tutorials?-- it sure doesn't look like
> it. We do expect some effort to learn R before posting.
>
> 4. What is the format of your date columns? character, factors,
> POSIX,...? See ?date-time for details. Note particularly the
> "difftime" link to obtain intervals.
>
> 5. ?ifelse  for vectorized conditionals.
>
> Also, you might want to explain the context of what you are trying to
> do. I strongly suspect you shouldn't be doing it at all, but that is
> just a guess.
>
> Be sure to cc your reply to the list, not just to me.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Jun 2, 2017 at 8:49 PM, Val <valkremk at gmail.com> wrote:
>> Hi all,
>>
>> I have a data set with time interval and depending on the interval I want
>> to create 5 more variables . Sample data below
>>
>> obs,   Start,   End
>> 1,2/1/2015,  1/1/2017
>> 2,4/11/2010, 1/1/2011
>> 3,1/4/2006,  5/3/2007
>> 4,10/1/2007, 1/1/2008
>> 5,6/1/2011,  1/1/2012
>> 6,10/15/2004,12/1/2004
>>
>> First, I want get  interval between the start date and end dates
>> (End-start).
>>
>>  obs,  Start , end, datediff
>> 1,2/1/2015,  1/1/2017, 700
>> 2,4/11/2010, 1/1/2011, 265
>> 3,1/4/2006,  5/3/2007, 484
>> 4,10/1/2007, 1/1/2008, 92
>> 5,6/1/2011,  1/1/2012, 214
>> 6,10/15/2004,12/1/2004,47
>>
>> Second. I want create 5 more variables  t1, t2, t3, t4 and  t5
>> The value of each variable is defined as follows
>> if datediff <   100 then  t1=1,  t2=t3=t4=t5=-1.
>> if datediff >= 100 and  < 200 then  t1=0, t2=1,t3=t4=t5=-1,
>> if datediff >= 200 and  < 300 then  t1=0, t2=0,t3=1,t4=t5=-1,
>> if datediff >= 300 and  < 400 then  t1=0, t2=0,t3=0,t4=1,t5=-1,
>> if datediff >= 400 and  < 500 then  t1=0, t2=0,t3=0,t4=0,t5=1,
>> if datediff >= 500 then  t1=0, t2=0,t3=0,t4=0,t5=0
>>
>> The complete out put looks like as follow.
>> obs, start,         end,    datediff,   t1, t2, t3, t4, t5
>> 1,    2/1/2015,   1/1/2017,    700, 0,  0,  0,  0,  0
>> 2,  4/11/2010,   1/1/2011,    265, 0,  0,  1, -1,  -1
>> 3,    1/4/2006,   5/3/2007,    484, 0,  0,  0, 0,   1
>> 4,   10/1/2007,  1/1/2008,      92, 1, -1, -1,-1,  -1
>> 5 ,    6/1/2011,    1/1/2012,  214,  0,  0,  1,-1,  -1
>> 6, 10/15/2004, 12/1/2004,     47, 1, -1, -1, -1, -1
>>
>> Thank you.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ramnik.bansal at gmail.com  Sun Jun  4 03:14:20 2017
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Sun, 4 Jun 2017 06:44:20 +0530
Subject: [R] nmax parameter in factor function
Message-ID: <CAMLd9E6z009S-VNT6tBuZVNp3yJ6pJKemrTPMU2DL=XAyHA9MA@mail.gmail.com>

I have been trying to understand how the argument 'nmax' works in
'factor' function. R-Documentation states - "Since factors typically
have quite a small number of levels, for large vectors x it is helpful
to supply nmax as an upper bound on the number of unique values."

In the code below what is the reason for error when value of nmax is
24. Why did the same error not occur with nmax = 25  and also how come
there are 26 levels when nmax = 25 ?

> factor(x = letters, nmax = 26)
 [1] a b c d e f g h i j k l m n o p q r s t u v w x y z
Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z

> factor(x = letters, nmax = 25)
 [1] a b c d e f g h i j k l m n o p q r s t u v w x y z
Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z

> factor(x = letters, nmax = 24)
Error in unique.default(x, nmax = nmax) : hash table is full


From jdnewmil at dcn.davis.ca.us  Sun Jun  4 04:50:36 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 3 Jun 2017 19:50:36 -0700 (PDT)
Subject: [R] New var
In-Reply-To: <CAJOiR6bnLd745OL2eQOgvocRrrmZ-TwSbXJK_9Yp+5NETE1HMw@mail.gmail.com>
References: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>
 <CAGxFJbS1E8bqibBybgs25xZ5FPVAD=BY++J1g-HF3Kk5RkRCSw@mail.gmail.com>
 <CAJOiR6bnLd745OL2eQOgvocRrrmZ-TwSbXJK_9Yp+5NETE1HMw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1706031941440.64647@pedal.dcn.davis.ca.us>

# read.table is NOT part of the data.table package
#library(data.table)
DFM <- read.table( text=
'obs start end
1 2/1/2015   1/1/2017
2 4/11/2010  1/1/2011
3 1/4/2006   5/3/2007
4 10/1/2007  1/1/2008
5 6/1/2011   1/1/2012
6 10/5/2004 12/1/2004
',header = TRUE, stringsAsFactors = FALSE)
# cleaner way to compute D
DFM$start <- as.Date( DFM$start, format="%m/%d/%Y" )
DFM$end <- as.Date( DFM$end, format="%m/%d/%Y" )
DFM$D <- as.numeric( DFM$end - DFM$start, units="days" )
# categorize your data into groups
DFM$bin <- cut( DFM$D
               , breaks=c( seq( 0, 500, 100 ), Inf )
               , right=FALSE # do not include the right edge
               , ordered_result = TRUE
               )
# brute force method you should have been able to figure out to show us some work
DFM$t1 <- ifelse( DFM$D < 100, 1, 0 )
DFM$t2 <- ifelse( 100 <= DFM$D & DFM$D < 200, 1, ifelse( DFM$D < 100, -1, 0 ) )
DFM$t3 <- ifelse( 200 <= DFM$D & DFM$D < 300, 1, ifelse( DFM$D < 200, -1, 0 ) )
DFM$t4 <- ifelse( 300 <= DFM$D & DFM$D < 400, 1, ifelse( DFM$D < 300, -1, 0 ) )
DFM$t5 <- ifelse( 400 <= DFM$D & DFM$D < 500, 1, ifelse( DFM$D < 400, -1, 0 ) )
# brute force method with ordered factor
DFM$tf1 <- ifelse( "[0,100)" == DFM$bin, 1, 0 )
DFM$tf2 <- ifelse( "[100,200)" == DFM$bin, 1, ifelse( "[100,200)" < DFM$bin, 0, -1 ) )
DFM$tf3 <- ifelse( "[200,300)" == DFM$bin, 1, ifelse( "[200,300)" < DFM$bin, 0, -1 ) )
DFM$tf4 <- ifelse( "[300,400)" == DFM$bin, 1, ifelse( "[300,400)" < DFM$bin, 0, -1 ) )
DFM$tf5 <- ifelse( "[400,500)" == DFM$bin, 1, ifelse( "[400,500)" < DFM$bin, 0, -1 ) )
# less obvious approach using the fact that factors are integers
# and using the outer function to find all combinations of elements of two vectors
# and the sign function
DFM[ , paste0( "tm", 1:5 )] <- outer( as.integer( DFM$bin )
                                     , 1:5
                                     , FUN = function(x,y) {
                                           z <- sign(y-x)+1L
                                           ifelse( 2 == z, -1L, z )
                                       }
                                     )

# my result, provided using dput for precise representation
DFMresult <- structure(list(obs = 1:6, start = structure(c(16467, 14710, 
13152, 13787, 15126, 12696), class = "Date"), end = structure(c(17167,
14975, 13636, 13879, 15340, 12753), class = "Date"), D = c(700,
265, 484, 92, 214, 57), bin = structure(c(6L, 3L, 5L, 1L, 3L,
1L), .Label = c("[0,100)", "[100,200)", "[200,300)", "[300,400)",
"[400,500)", "[500,Inf)"), class = c("ordered", "factor")), t1 = c(0,
0, 0, 1, 0, 1), t2 = c(0, 0, 0, -1, 0, -1), t3 = c(0, 1, 0, -1,
1, -1), t4 = c(0, -1, 0, -1, -1, -1), t5 = c(0, -1, 1, -1, -1,
-1), tf1 = c(0, 0, 0, 1, 0, 1), tf2 = c(0, 0, 0, -1, 0, -1),
     tf3 = c(0, 1, 0, -1, 1, -1), tf4 = c(0, -1, 0, -1, -1, -1
     ), tf5 = c(0, -1, 1, -1, -1, -1), tm1 = c(0, 0, 0, 1, 0,
     1), tm2 = c(0, 0, 0, -1, 0, -1), tm3 = c(0, 1, 0, -1, 1,
     -1), tm4 = c(0, -1, 0, -1, -1, -1), tm5 = c(0, -1, 1, -1,
     -1, -1)), row.names = c(NA, -6L), .Names = c("obs", "start",
"end", "D", "bin", "t1", "t2", "t3", "t4", "t5", "tf1", "tf2",
"tf3", "tf4", "tf5", "tm1", "tm2", "tm3", "tm4", "tm5"), class = 
"data.frame")

You did not address Bert's request for some context, but I am curious how 
he or Peter would have approached this problem, so I encourage you do 
provide some insight on the list as to why you are doing this.

On Sat, 3 Jun 2017, Val wrote:

> Thank you all for the useful suggestion. I did some of my homework.
>
> library(data.table)
> DFM <- read.table(header=TRUE, text='obs start end
> 1 2/1/2015   1/1/2017
> 2 4/11/2010  1/1/2011
> 3 1/4/2006   5/3/2007
> 4 10/1/2007  1/1/2008
> 5 6/1/2011   1/1/2012
> 6 10/5/2004 12/1/2004',stringsAsFactors = FALSE)
> DFM
>
> DFM$D =as.numeric(difftime(as.Date(DFM$end,format="%m/%d/%Y"),
> as.Date(DFM$start,format="%m/%d/%Y"), units = "days"))
> DFM
>
> output.
>     obs     start       end   D
> 1   1  2/1/2015  1/1/2017 700
> 2   2 4/11/2010  1/1/2011 265
> 3   3  1/4/2006  5/3/2007 484
> 4   4 10/1/2007  1/1/2008  92
> 5   5  6/1/2011  1/1/2012 214
> 6   6 10/5/2004 12/1/2004  57
>
> My problem is how do I get the other new variables
>
> obs     start       end   D  t1,t2,t3,t4, t5
> 1, 2/1/2015,  1/1/2017, 700,0,0,0,0,0
> 2, 4/11/2010, 1/1/2011, 265,0,0,1,-1,-1
> 3, 1/4/2006,  5/3/2007, 484,0,0,0,0,1
> 4, 10/1/2007, 1/1/2008, 92,1,-1,-1,-1,-1
> 5, 6/1/2011,  1/1/2012, 214,0,0,1,-1,-1
> 6, 10/15/2004,12/1/2004,47,1,-1,-1,-1,-1
>
> Thank you again.
>
>
>
> On Sat, Jun 3, 2017 at 12:13 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Ii is difficult to provide useful help, because you have failed to
>> read and follow the posting guide. In particular:
>>
>> 1. Plain text, not HTML.
>> 2. Use dput() or provide code to create your example. Text printouts
>> such as that which you gave require some work to wrangle into into an
>> example that we can test.
>>
>> Specifically:
>>
>> 3. Have you gone through any R tutorials?-- it sure doesn't look like
>> it. We do expect some effort to learn R before posting.
>>
>> 4. What is the format of your date columns? character, factors,
>> POSIX,...? See ?date-time for details. Note particularly the
>> "difftime" link to obtain intervals.
>>
>> 5. ?ifelse  for vectorized conditionals.
>>
>> Also, you might want to explain the context of what you are trying to
>> do. I strongly suspect you shouldn't be doing it at all, but that is
>> just a guess.
>>
>> Be sure to cc your reply to the list, not just to me.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Jun 2, 2017 at 8:49 PM, Val <valkremk at gmail.com> wrote:
>>> Hi all,
>>>
>>> I have a data set with time interval and depending on the interval I want
>>> to create 5 more variables . Sample data below
>>>
>>> obs,   Start,   End
>>> 1,2/1/2015,  1/1/2017
>>> 2,4/11/2010, 1/1/2011
>>> 3,1/4/2006,  5/3/2007
>>> 4,10/1/2007, 1/1/2008
>>> 5,6/1/2011,  1/1/2012
>>> 6,10/15/2004,12/1/2004
>>>
>>> First, I want get  interval between the start date and end dates
>>> (End-start).
>>>
>>>  obs,  Start , end, datediff
>>> 1,2/1/2015,  1/1/2017, 700
>>> 2,4/11/2010, 1/1/2011, 265
>>> 3,1/4/2006,  5/3/2007, 484
>>> 4,10/1/2007, 1/1/2008, 92
>>> 5,6/1/2011,  1/1/2012, 214
>>> 6,10/15/2004,12/1/2004,47
>>>
>>> Second. I want create 5 more variables  t1, t2, t3, t4 and  t5
>>> The value of each variable is defined as follows
>>> if datediff <   100 then  t1=1,  t2=t3=t4=t5=-1.
>>> if datediff >= 100 and  < 200 then  t1=0, t2=1,t3=t4=t5=-1,
>>> if datediff >= 200 and  < 300 then  t1=0, t2=0,t3=1,t4=t5=-1,
>>> if datediff >= 300 and  < 400 then  t1=0, t2=0,t3=0,t4=1,t5=-1,
>>> if datediff >= 400 and  < 500 then  t1=0, t2=0,t3=0,t4=0,t5=1,
>>> if datediff >= 500 then  t1=0, t2=0,t3=0,t4=0,t5=0
>>>
>>> The complete out put looks like as follow.
>>> obs, start,         end,    datediff,   t1, t2, t3, t4, t5
>>> 1,    2/1/2015,   1/1/2017,    700, 0,  0,  0,  0,  0
>>> 2,  4/11/2010,   1/1/2011,    265, 0,  0,  1, -1,  -1
>>> 3,    1/4/2006,   5/3/2007,    484, 0,  0,  0, 0,   1
>>> 4,   10/1/2007,  1/1/2008,      92, 1, -1, -1,-1,  -1
>>> 5 ,    6/1/2011,    1/1/2012,  214,  0,  0,  1,-1,  -1
>>> 6, 10/15/2004, 12/1/2004,     47, 1, -1, -1, -1, -1
>>>
>>> Thank you.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From snpandit at hotmail.com  Sun Jun  4 05:22:02 2017
From: snpandit at hotmail.com (Shubha Nath Pandit)
Date: Sun, 4 Jun 2017 03:22:02 +0000
Subject: [R] Hlep in analysis in RWinBugs
Message-ID: <cd4066a82e114db7899550594ff65696CO2PR14MB0122B8BA06E718C7A342099BD4F50@CO2PR14MB0122.namprd14.prod.outlook.com>

Hi R User,
I was trying to use R for WINBUGS using following model and data (example), but I am new with WINBUGS and don't know how we perform the analysis. I wonder whether I can run the following the example data and Winbugs Model in R.  Your help will be highly appreciated.

Sincerely,

SN PANDIT
 ===

library(R2WinBUGS)
#Model
model{
#likelihood
for(i in 1:N){
a1[i] ~ dnorm(a11[i],tau)
2[i] ~ dnorm(a21[i],tau1)
a3[i] ~ dnorm(a31[i],tau2)
a11[i]<-sm[i]*S1*m1
a21[i]<-sm[i]*S1*(1-m1)*S2*m2
a31[i]<-sm[i]*S1*(1-m1)*S2*(1-m2)*S3
sum[i]<-a11[i]+a21[i]+a31[i]
  }
#priors
#priors are dbeta(0.5,0.5), uniform is dbeta(1,1)
S1~dbeta(1,1)#I(0,0.2) #
S2~dbeta(1,1)#I(0.15,0.5) #
S3~dbeta(1,1)#I(0.3,1)
m1~dbeta(1,1)#I(0.01,1)
m2~dbeta(1,1)#I(0,1)
sd ~ dunif(0,100)
sd1 ~ dunif(0,100)
sd2 ~ dunif(0,100)
tau <- 1/(sd*sd)
tau1 <- 1/(sd1*sd1)
tau2 <- 1/(sd2*sd2)
}
model.file <- Model
file.show(model.file)
#The Data
list(N = 4,
sm=c(9309,3253,5292,1361),
a1=c(16,3,4,2),
a2=c(96,31,42,3),
a3=c(47,5,18,1))

inits <- function(){
list(sd = 1000, sd1 = 1000, sd2 = 1000, S1 = 0.10, S2 = 0.25, S3 = 0.5, m1 = 0.25, m2 = 75)
}



	[[alternative HTML version deleted]]


From snpandit at hotmail.com  Sun Jun  4 05:31:45 2017
From: snpandit at hotmail.com (Shubha Nath Pandit)
Date: Sun, 4 Jun 2017 03:31:45 +0000
Subject: [R] Help in analysis in RWinBugs
Message-ID: <f867bfd2635242bcb260e9a434db976ecd4066a82e114db7899550594ff65696CO2PR14MB0122B8BA06E718C7A342099BD4F50@CO2PR14MB0122.namprd14.prod.outlook.com>

Hi R User,
I was trying to use R for WINBUGS using following model and data (example), but I am new with WINBUGS and don't know how we perform the analysis. I wonder whether I can run the following the example data and Winbugs Model in R.  Your help will be highly appreciated.

Sincerely,

SN PANDIT
 ===

library(R2WinBUGS)
#Model
model{
#likelihood
for(i in 1:N){
a1[i] ~ dnorm(a11[i],tau)
2[i] ~ dnorm(a21[i],tau1)
a3[i] ~ dnorm(a31[i],tau2)
a11[i]<-sm[i]*S1*m1
a21[i]<-sm[i]*S1*(1-m1)*S2*m2
a31[i]<-sm[i]*S1*(1-m1)*S2*(1-m2)*S3
sum[i]<-a11[i]+a21[i]+a31[i]
  }
#priors
#priors are dbeta(0.5,0.5), uniform is dbeta(1,1)
S1~dbeta(1,1)#I(0,0.2) #
S2~dbeta(1,1)#I(0.15,0.5) #
S3~dbeta(1,1)#I(0.3,1)
m1~dbeta(1,1)#I(0.01,1)
m2~dbeta(1,1)#I(0,1)
sd ~ dunif(0,100)
sd1 ~ dunif(0,100)
sd2 ~ dunif(0,100)
tau <- 1/(sd*sd)
tau1 <- 1/(sd1*sd1)
tau2 <- 1/(sd2*sd2)
}
model.file <- Model
file.show(model.file)
#The Data
list(N = 4,
sm=c(9309,3253,5292,1361),
a1=c(16,3,4,2),
a2=c(96,31,42,3),
a3=c(47,5,18,1))

inits <- function(){
list(sd = 1000, sd1 = 1000, sd2 = 1000, S1 = 0.10, S2 = 0.25, S3 = 0.5, m1 = 0.25, m2 = 75)
}



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Jun  4 06:11:45 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 3 Jun 2017 21:11:45 -0700
Subject: [R] nmax parameter in factor function
In-Reply-To: <CAMLd9E6z009S-VNT6tBuZVNp3yJ6pJKemrTPMU2DL=XAyHA9MA@mail.gmail.com>
References: <CAMLd9E6z009S-VNT6tBuZVNp3yJ6pJKemrTPMU2DL=XAyHA9MA@mail.gmail.com>
Message-ID: <CAGxFJbR=5VH1Uep9wM6HTsfg0gTp8r9U9iK8YpiQPHJTLy8Bjw@mail.gmail.com>

Well, you won't like this, but it is kind of wimpily (is that a word?)
documented:

If you check the code of factor(), you will see that nmax appears as
an argument in a call to unique(). ?unique says for nmax, "... see
duplicated" . And ?duplicated says:

"If nmax is set too small there is liable to be an error: nmax = 1 is
silently ignored."

So sometimes you get an error when nmax is too small with the hash
table error message; and sometimes you just apparently get the nmax
argument ignored:

> identical(factor(letters,nmax = 25), factor(letters,nmax=26))
[1] TRUE

and that, to paraphrase what Roger Hammerstein said about Kansas City,
is about "as fer as I can go."

(http://lyricsplayground.com/alpha/songs/e/everythingsuptodateinkansascity.shtml)

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jun 3, 2017 at 6:14 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
> I have been trying to understand how the argument 'nmax' works in
> 'factor' function. R-Documentation states - "Since factors typically
> have quite a small number of levels, for large vectors x it is helpful
> to supply nmax as an upper bound on the number of unique values."
>
> In the code below what is the reason for error when value of nmax is
> 24. Why did the same error not occur with nmax = 25  and also how come
> there are 26 levels when nmax = 25 ?
>
>> factor(x = letters, nmax = 26)
>  [1] a b c d e f g h i j k l m n o p q r s t u v w x y z
> Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z
>
>> factor(x = letters, nmax = 25)
>  [1] a b c d e f g h i j k l m n o p q r s t u v w x y z
> Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z
>
>> factor(x = letters, nmax = 24)
> Error in unique.default(x, nmax = nmax) : hash table is full
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Jun  4 06:35:15 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 3 Jun 2017 21:35:15 -0700
Subject: [R] nmax parameter in factor function
In-Reply-To: <CAGxFJbR=5VH1Uep9wM6HTsfg0gTp8r9U9iK8YpiQPHJTLy8Bjw@mail.gmail.com>
References: <CAMLd9E6z009S-VNT6tBuZVNp3yJ6pJKemrTPMU2DL=XAyHA9MA@mail.gmail.com>
 <CAGxFJbR=5VH1Uep9wM6HTsfg0gTp8r9U9iK8YpiQPHJTLy8Bjw@mail.gmail.com>
Message-ID: <CAGxFJbQTeVovahhbZEgyMiDeBJbhBAZ8x2H6orCeFYpJPxn8_w@mail.gmail.com>

I'll go just a bit "fer-er." It appears the anomaly -- I hesitate to
call it a bug -- is in the C code for duplicated.default():

> duplicated(letters[1:10],nmax=10)
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE

> duplicated(letters[1:10],nmax=9)
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE

> duplicated(letters[1:10],nmax=8) ## for all nmax <9
Error in duplicated.default(letters[1:10], nmax = 8) : hash table is full

Cleverer folks than I must now explain (and possibly correct me).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jun 3, 2017 at 9:11 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Well, you won't like this, but it is kind of wimpily (is that a word?)
> documented:
>
> If you check the code of factor(), you will see that nmax appears as
> an argument in a call to unique(). ?unique says for nmax, "... see
> duplicated" . And ?duplicated says:
>
> "If nmax is set too small there is liable to be an error: nmax = 1 is
> silently ignored."
>
> So sometimes you get an error when nmax is too small with the hash
> table error message; and sometimes you just apparently get the nmax
> argument ignored:
>
>> identical(factor(letters,nmax = 25), factor(letters,nmax=26))
> [1] TRUE
>
> and that, to paraphrase what Roger Hammerstein said about Kansas City,
> is about "as fer as I can go."
>
> (http://lyricsplayground.com/alpha/songs/e/everythingsuptodateinkansascity.shtml)
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Jun 3, 2017 at 6:14 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
>> I have been trying to understand how the argument 'nmax' works in
>> 'factor' function. R-Documentation states - "Since factors typically
>> have quite a small number of levels, for large vectors x it is helpful
>> to supply nmax as an upper bound on the number of unique values."
>>
>> In the code below what is the reason for error when value of nmax is
>> 24. Why did the same error not occur with nmax = 25  and also how come
>> there are 26 levels when nmax = 25 ?
>>
>>> factor(x = letters, nmax = 26)
>>  [1] a b c d e f g h i j k l m n o p q r s t u v w x y z
>> Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z
>>
>>> factor(x = letters, nmax = 25)
>>  [1] a b c d e f g h i j k l m n o p q r s t u v w x y z
>> Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z
>>
>>> factor(x = letters, nmax = 24)
>> Error in unique.default(x, nmax = nmax) : hash table is full
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sun Jun  4 09:33:36 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 4 Jun 2017 09:33:36 +0200
Subject: [R] nmax parameter in factor function
In-Reply-To: <CAGxFJbQTeVovahhbZEgyMiDeBJbhBAZ8x2H6orCeFYpJPxn8_w@mail.gmail.com>
References: <CAMLd9E6z009S-VNT6tBuZVNp3yJ6pJKemrTPMU2DL=XAyHA9MA@mail.gmail.com>
 <CAGxFJbR=5VH1Uep9wM6HTsfg0gTp8r9U9iK8YpiQPHJTLy8Bjw@mail.gmail.com>
 <CAGxFJbQTeVovahhbZEgyMiDeBJbhBAZ8x2H6orCeFYpJPxn8_w@mail.gmail.com>
Message-ID: <B5D10EDF-5EB6-447C-898B-70268AFE6442@gmail.com>

No anomaly, it is just that you need to know what it is for, before trying to use it. 

Basically, duplicated() works by looking up entries in a hash table (for which there is a substantial literature, just google it). This will be somewhat more efficient if you know the number of  unique values in advance (otherwise the table is the same size as the input vector), so you have the option of setting nmax. If you set nmax too small, you get to keep both pieces. 

nmax is directly linked to a variable in C code, and I expect that 0-based indexing is the reason that nmax can be one less than the actual number of unique values.

-pd  

> On 4 Jun 2017, at 06:35 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I'll go just a bit "fer-er." It appears the anomaly -- I hesitate to
> call it a bug -- is in the C code for duplicated.default():
> 
>> duplicated(letters[1:10],nmax=10)
> [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> 
>> duplicated(letters[1:10],nmax=9)
> [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> 
>> duplicated(letters[1:10],nmax=8) ## for all nmax <9
> Error in duplicated.default(letters[1:10], nmax = 8) : hash table is full
> 
> Cleverer folks than I must now explain (and possibly correct me).
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sat, Jun 3, 2017 at 9:11 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Well, you won't like this, but it is kind of wimpily (is that a word?)
>> documented:
>> 
>> If you check the code of factor(), you will see that nmax appears as
>> an argument in a call to unique(). ?unique says for nmax, "... see
>> duplicated" . And ?duplicated says:
>> 
>> "If nmax is set too small there is liable to be an error: nmax = 1 is
>> silently ignored."
>> 
>> So sometimes you get an error when nmax is too small with the hash
>> table error message; and sometimes you just apparently get the nmax
>> argument ignored:
>> 
>>> identical(factor(letters,nmax = 25), factor(letters,nmax=26))
>> [1] TRUE
>> 
>> and that, to paraphrase what Roger Hammerstein said about Kansas City,
>> is about "as fer as I can go."
>> 
>> (http://lyricsplayground.com/alpha/songs/e/everythingsuptodateinkansascity.shtml)
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Sat, Jun 3, 2017 at 6:14 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
>>> I have been trying to understand how the argument 'nmax' works in
>>> 'factor' function. R-Documentation states - "Since factors typically
>>> have quite a small number of levels, for large vectors x it is helpful
>>> to supply nmax as an upper bound on the number of unique values."
>>> 
>>> In the code below what is the reason for error when value of nmax is
>>> 24. Why did the same error not occur with nmax = 25  and also how come
>>> there are 26 levels when nmax = 25 ?
>>> 
>>>> factor(x = letters, nmax = 26)
>>> [1] a b c d e f g h i j k l m n o p q r s t u v w x y z
>>> Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z
>>> 
>>>> factor(x = letters, nmax = 25)
>>> [1] a b c d e f g h i j k l m n o p q r s t u v w x y z
>>> Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z
>>> 
>>>> factor(x = letters, nmax = 24)
>>> Error in unique.default(x, nmax = nmax) : hash table is full
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ashimkapoor at gmail.com  Sun Jun  4 12:48:16 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 4 Jun 2017 16:18:16 +0530
Subject: [R] Warning from reshape2 when melting a data frame with uneven
	number of columns.
Message-ID: <CAC8=1eoykfDUHMcZ+OEafnT6jCSHV-9kvLAxXYnCkaKjbT_zPQ@mail.gmail.com>

Here is a small reproducible example:

data <-
structure(list(V1 = structure(1:3, .Label = c("Name1", "Name2",
"Name3"), class = "factor"), V2 = structure(c(1L, 3L, 2L), .Label =
c("nam1",
"name-1", "name_12"), class = "factor"), V3 = structure(1:3, .Label =
c("nam2",
"nam_34", "name-2"), class = "factor"), V4 = structure(c(2L,
3L, 1L), .Label = c("", "nam3", "nam_56"), class = "factor"),
    V5 = structure(c(1L, 2L, 1L), .Label = c("", "name_78"), class =
"factor")), .Names = c("V1",
"V2", "V3", "V4", "V5"), class = "data.frame", row.names = c(NA,
-3L))

library(reshape2)
data_long <- melt(data,id.vars="V1")

Warning message:
attributes are not identical across measure variables; they will be dropped


Can someone please tell me how to correct this?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Sun Jun  4 17:03:38 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 4 Jun 2017 20:33:38 +0530
Subject: [R] Warning from reshape2 when melting a data frame with uneven
 number of columns.
In-Reply-To: <345127699.1703514.1496587482949@mail.yahoo.com>
References: <CAC8=1eoykfDUHMcZ+OEafnT6jCSHV-9kvLAxXYnCkaKjbT_zPQ@mail.gmail.com>
 <345127699.1703514.1496587482949@mail.yahoo.com>
Message-ID: <CAC8=1eoH1fmjD5zSQ6Qf7+r=1DkN8BubvQ3wpVVHBi+0yO5cxg@mail.gmail.com>

Is this the solution?

> d1<- as.data.frame(lapply(data,as.character),stringsAsFactors=FALSE)
> str(d1)
'data.frame':    3 obs. of  5 variables:
 $ V1: chr  "Name1" "Name2" "Name3"
 $ V2: chr  "nam1" "name_12" "name-1"
 $ V3: chr  "nam2" "nam_34" "name-2"
 $ V4: chr  "nam3" "nam_56" ""
 $ V5: chr  "" "name_78" ""
> melt(d1,id.vars="V1")
      V1 variable   value
1  Name1       V2    nam1
2  Name2       V2 name_12
3  Name3       V2  name-1
4  Name1       V3    nam2
5  Name2       V3  nam_34
6  Name3       V3  name-2
7  Name1       V4    nam3
8  Name2       V4  nam_56
9  Name3       V4
10 Name1       V5
11 Name2       V5 name_78
12 Name3       V5
>

On Sun, Jun 4, 2017 at 8:14 PM, John Kane <jrkrideau at yahoo.ca> wrote:

> I am not really sure what the warning means but I think your underlying
> problem is that all your variables are factors. Did you intend the values
> in each variable to be character?
> data.frame':    3 obs. of  5 variables:
>  $ V1: Factor w/ 3 levels "Name1","Name2",..: 1 2 3
>  $ V2: Factor w/ 3 levels "nam1","name-1",..: 1 3 2
>  $ V3: Factor w/ 3 levels "nam2","nam_34",..: 1 2 3
>  $ V4: Factor w/ 3 levels "","nam3","nam_56": 2 3 1
>  $ V5: Factor w/ 2 levels "","name_78": 1 2 1
>
>
>
> On Sunday, June 4, 2017 6:48 AM, Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
>
>
> Here is a small reproducible example:
>
> data <-
> structure(list(V1 = structure(1:3, .Label = c("Name1", "Name2",
> "Name3"), class = "factor"), V2 = structure(c(1L, 3L, 2L), .Label =
> c("nam1",
> "name-1", "name_12"), class = "factor"), V3 = structure(1:3, .Label =
> c("nam2",
> "nam_34", "name-2"), class = "factor"), V4 = structure(c(2L,
> 3L, 1L), .Label = c("", "nam3", "nam_56"), class = "factor"),
>     V5 = structure(c(1L, 2L, 1L), .Label = c("", "name_78"), class =
> "factor")), .Names = c("V1",
> "V2", "V3", "V4", "V5"), class = "data.frame", row.names = c(NA,
> -3L))
>
> library(reshape2)
> data_long <- melt(data,id.vars="V1")
>
> Warning message:
> attributes are not identical across measure variables; they will be dropped
>
>
> Can someone please tell me how to correct this?
>
> Best Regards,
> Ashim
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Sun Jun  4 18:31:21 2017
From: valkremk at gmail.com (Val)
Date: Sun, 4 Jun 2017 11:31:21 -0500
Subject: [R] New var
In-Reply-To: <alpine.BSF.2.00.1706031941440.64647@pedal.dcn.davis.ca.us>
References: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>
 <CAGxFJbS1E8bqibBybgs25xZ5FPVAD=BY++J1g-HF3Kk5RkRCSw@mail.gmail.com>
 <CAJOiR6bnLd745OL2eQOgvocRrrmZ-TwSbXJK_9Yp+5NETE1HMw@mail.gmail.com>
 <alpine.BSF.2.00.1706031941440.64647@pedal.dcn.davis.ca.us>
Message-ID: <CAJOiR6arQxPObKgsSzDZM=LjXPrs5i8LDXGLVyCgfH1EtUun9A@mail.gmail.com>

Thank you Jeff and All,

Within a given time period (say 700 days, from the start day),  I am
expecting measurements taken at each time interval;. In this case "0" means
measurement taken, "1"  not taken (stopped or opted out  and " -1"  don't
consider that time period for that individual. This will be compared with
the actual measurements taken (Observed- expected)  within each time
interval.




On Sat, Jun 3, 2017 at 9:50 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> # read.table is NOT part of the data.table package
> #library(data.table)
> DFM <- read.table( text=
> 'obs start end
> 1 2/1/2015   1/1/2017
> 2 4/11/2010  1/1/2011
> 3 1/4/2006   5/3/2007
> 4 10/1/2007  1/1/2008
> 5 6/1/2011   1/1/2012
> 6 10/5/2004 12/1/2004
> ',header = TRUE, stringsAsFactors = FALSE)
> # cleaner way to compute D
> DFM$start <- as.Date( DFM$start, format="%m/%d/%Y" )
> DFM$end <- as.Date( DFM$end, format="%m/%d/%Y" )
> DFM$D <- as.numeric( DFM$end - DFM$start, units="days" )
> # categorize your data into groups
> DFM$bin <- cut( DFM$D
>               , breaks=c( seq( 0, 500, 100 ), Inf )
>               , right=FALSE # do not include the right edge
>               , ordered_result = TRUE
>               )
> # brute force method you should have been able to figure out to show us
> some work
> DFM$t1 <- ifelse( DFM$D < 100, 1, 0 )
> DFM$t2 <- ifelse( 100 <= DFM$D & DFM$D < 200, 1, ifelse( DFM$D < 100, -1,
> 0 ) )
> DFM$t3 <- ifelse( 200 <= DFM$D & DFM$D < 300, 1, ifelse( DFM$D < 200, -1,
> 0 ) )
> DFM$t4 <- ifelse( 300 <= DFM$D & DFM$D < 400, 1, ifelse( DFM$D < 300, -1,
> 0 ) )
> DFM$t5 <- ifelse( 400 <= DFM$D & DFM$D < 500, 1, ifelse( DFM$D < 400, -1,
> 0 ) )
> # brute force method with ordered factor
> DFM$tf1 <- ifelse( "[0,100)" == DFM$bin, 1, 0 )
> DFM$tf2 <- ifelse( "[100,200)" == DFM$bin, 1, ifelse( "[100,200)" <
> DFM$bin, 0, -1 ) )
> DFM$tf3 <- ifelse( "[200,300)" == DFM$bin, 1, ifelse( "[200,300)" <
> DFM$bin, 0, -1 ) )
> DFM$tf4 <- ifelse( "[300,400)" == DFM$bin, 1, ifelse( "[300,400)" <
> DFM$bin, 0, -1 ) )
> DFM$tf5 <- ifelse( "[400,500)" == DFM$bin, 1, ifelse( "[400,500)" <
> DFM$bin, 0, -1 ) )
> # less obvious approach using the fact that factors are integers
> # and using the outer function to find all combinations of elements of two
> vectors
> # and the sign function
> DFM[ , paste0( "tm", 1:5 )] <- outer( as.integer( DFM$bin )
>                                     , 1:5
>                                     , FUN = function(x,y) {
>                                           z <- sign(y-x)+1L
>                                           ifelse( 2 == z, -1L, z )
>                                       }
>                                     )
>
> # my result, provided using dput for precise representation
> DFMresult <- structure(list(obs = 1:6, start = structure(c(16467, 14710,
> 13152, 13787, 15126, 12696), class = "Date"), end = structure(c(17167,
> 14975, 13636, 13879, 15340, 12753), class = "Date"), D = c(700,
> 265, 484, 92, 214, 57), bin = structure(c(6L, 3L, 5L, 1L, 3L,
> 1L), .Label = c("[0,100)", "[100,200)", "[200,300)", "[300,400)",
> "[400,500)", "[500,Inf)"), class = c("ordered", "factor")), t1 = c(0,
> 0, 0, 1, 0, 1), t2 = c(0, 0, 0, -1, 0, -1), t3 = c(0, 1, 0, -1,
> 1, -1), t4 = c(0, -1, 0, -1, -1, -1), t5 = c(0, -1, 1, -1, -1,
> -1), tf1 = c(0, 0, 0, 1, 0, 1), tf2 = c(0, 0, 0, -1, 0, -1),
>     tf3 = c(0, 1, 0, -1, 1, -1), tf4 = c(0, -1, 0, -1, -1, -1
>     ), tf5 = c(0, -1, 1, -1, -1, -1), tm1 = c(0, 0, 0, 1, 0,
>     1), tm2 = c(0, 0, 0, -1, 0, -1), tm3 = c(0, 1, 0, -1, 1,
>     -1), tm4 = c(0, -1, 0, -1, -1, -1), tm5 = c(0, -1, 1, -1,
>     -1, -1)), row.names = c(NA, -6L), .Names = c("obs", "start",
> "end", "D", "bin", "t1", "t2", "t3", "t4", "t5", "tf1", "tf2",
> "tf3", "tf4", "tf5", "tm1", "tm2", "tm3", "tm4", "tm5"), class =
> "data.frame")
>
> You did not address Bert's request for some context, but I am curious how
> he or Peter would have approached this problem, so I encourage you do
> provide some insight on the list as to why you are doing this.
>
>
> On Sat, 3 Jun 2017, Val wrote:
>
> Thank you all for the useful suggestion. I did some of my homework.
>>
>> library(data.table)
>> DFM <- read.table(header=TRUE, text='obs start end
>> 1 2/1/2015   1/1/2017
>> 2 4/11/2010  1/1/2011
>> 3 1/4/2006   5/3/2007
>> 4 10/1/2007  1/1/2008
>> 5 6/1/2011   1/1/2012
>> 6 10/5/2004 12/1/2004',stringsAsFactors = FALSE)
>> DFM
>>
>> DFM$D =as.numeric(difftime(as.Date(DFM$end,format="%m/%d/%Y"),
>> as.Date(DFM$start,format="%m/%d/%Y"), units = "days"))
>> DFM
>>
>> output.
>>     obs     start       end   D
>> 1   1  2/1/2015  1/1/2017 700
>> 2   2 4/11/2010  1/1/2011 265
>> 3   3  1/4/2006  5/3/2007 484
>> 4   4 10/1/2007  1/1/2008  92
>> 5   5  6/1/2011  1/1/2012 214
>> 6   6 10/5/2004 12/1/2004  57
>>
>> My problem is how do I get the other new variables
>>
>> obs     start       end   D  t1,t2,t3,t4, t5
>> 1, 2/1/2015,  1/1/2017, 700,0,0,0,0,0
>> 2, 4/11/2010, 1/1/2011, 265,0,0,1,-1,-1
>> 3, 1/4/2006,  5/3/2007, 484,0,0,0,0,1
>> 4, 10/1/2007, 1/1/2008, 92,1,-1,-1,-1,-1
>> 5, 6/1/2011,  1/1/2012, 214,0,0,1,-1,-1
>> 6, 10/15/2004,12/1/2004,47,1,-1,-1,-1,-1
>>
>> Thank you again.
>>
>>
>>
>> On Sat, Jun 3, 2017 at 12:13 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> Ii is difficult to provide useful help, because you have failed to
>>> read and follow the posting guide. In particular:
>>>
>>> 1. Plain text, not HTML.
>>> 2. Use dput() or provide code to create your example. Text printouts
>>> such as that which you gave require some work to wrangle into into an
>>> example that we can test.
>>>
>>> Specifically:
>>>
>>> 3. Have you gone through any R tutorials?-- it sure doesn't look like
>>> it. We do expect some effort to learn R before posting.
>>>
>>> 4. What is the format of your date columns? character, factors,
>>> POSIX,...? See ?date-time for details. Note particularly the
>>> "difftime" link to obtain intervals.
>>>
>>> 5. ?ifelse  for vectorized conditionals.
>>>
>>> Also, you might want to explain the context of what you are trying to
>>> do. I strongly suspect you shouldn't be doing it at all, but that is
>>> just a guess.
>>>
>>> Be sure to cc your reply to the list, not just to me.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Fri, Jun 2, 2017 at 8:49 PM, Val <valkremk at gmail.com> wrote:
>>>
>>>> Hi all,
>>>>
>>>> I have a data set with time interval and depending on the interval I
>>>> want
>>>> to create 5 more variables . Sample data below
>>>>
>>>> obs,   Start,   End
>>>> 1,2/1/2015,  1/1/2017
>>>> 2,4/11/2010, 1/1/2011
>>>> 3,1/4/2006,  5/3/2007
>>>> 4,10/1/2007, 1/1/2008
>>>> 5,6/1/2011,  1/1/2012
>>>> 6,10/15/2004,12/1/2004
>>>>
>>>> First, I want get  interval between the start date and end dates
>>>> (End-start).
>>>>
>>>>  obs,  Start , end, datediff
>>>> 1,2/1/2015,  1/1/2017, 700
>>>> 2,4/11/2010, 1/1/2011, 265
>>>> 3,1/4/2006,  5/3/2007, 484
>>>> 4,10/1/2007, 1/1/2008, 92
>>>> 5,6/1/2011,  1/1/2012, 214
>>>> 6,10/15/2004,12/1/2004,47
>>>>
>>>> Second. I want create 5 more variables  t1, t2, t3, t4 and  t5
>>>> The value of each variable is defined as follows
>>>> if datediff <   100 then  t1=1,  t2=t3=t4=t5=-1.
>>>> if datediff >= 100 and  < 200 then  t1=0, t2=1,t3=t4=t5=-1,
>>>> if datediff >= 200 and  < 300 then  t1=0, t2=0,t3=1,t4=t5=-1,
>>>> if datediff >= 300 and  < 400 then  t1=0, t2=0,t3=0,t4=1,t5=-1,
>>>> if datediff >= 400 and  < 500 then  t1=0, t2=0,t3=0,t4=0,t5=1,
>>>> if datediff >= 500 then  t1=0, t2=0,t3=0,t4=0,t5=0
>>>>
>>>> The complete out put looks like as follow.
>>>> obs, start,         end,    datediff,   t1, t2, t3, t4, t5
>>>> 1,    2/1/2015,   1/1/2017,    700, 0,  0,  0,  0,  0
>>>> 2,  4/11/2010,   1/1/2011,    265, 0,  0,  1, -1,  -1
>>>> 3,    1/4/2006,   5/3/2007,    484, 0,  0,  0, 0,   1
>>>> 4,   10/1/2007,  1/1/2008,      92, 1, -1, -1,-1,  -1
>>>> 5 ,    6/1/2011,    1/1/2012,  214,  0,  0,  1,-1,  -1
>>>> 6, 10/15/2004, 12/1/2004,     47, 1, -1, -1, -1, -1
>>>>
>>>> Thank you.
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Sun Jun  4 19:36:01 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 4 Jun 2017 17:36:01 +0000
Subject: [R] New var
In-Reply-To: <CAJOiR6arQxPObKgsSzDZM=LjXPrs5i8LDXGLVyCgfH1EtUun9A@mail.gmail.com>
References: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>
 <CAGxFJbS1E8bqibBybgs25xZ5FPVAD=BY++J1g-HF3Kk5RkRCSw@mail.gmail.com>
 <CAJOiR6bnLd745OL2eQOgvocRrrmZ-TwSbXJK_9Yp+5NETE1HMw@mail.gmail.com>
 <alpine.BSF.2.00.1706031941440.64647@pedal.dcn.davis.ca.us>
 <CAJOiR6arQxPObKgsSzDZM=LjXPrs5i8LDXGLVyCgfH1EtUun9A@mail.gmail.com>
Message-ID: <12216049f6ea4d4f8911036e1fc73f4e@exch-2p-mbx-w2.ads.tamu.edu>

Since the number of choices is small (6), how about this?

Starting with Jeff's initial DFM:

DFM <- structure(list(obs = 1:6, start = structure(c(16467, 14710, 13152, 
13787, 15126, 12696), class = "Date"), end = structure(c(17167, 
14975, 13636, 13879, 15340, 12753), class = "Date"), D = c(700, 
265, 484, 92, 214, 57), bin = structure(c(6L, 3L, 5L, 1L, 3L, 
1L), .Label = c("[0,100)", "[100,200)", "[200,300)", "[300,400)", 
"[400,500)", "[500,Inf)"), class = c("ordered", "factor"))), .Names = c("obs", 
"start", "end", "D", "bin"), row.names = c(NA, -6L), class = "data.frame")

Construct a matrix of the six alternatives:

tvals <- c(1, -1, -1, -1, -1, 0, 1, -1, -1, -1, 0, 0, 1, -1, -1, 0, 0, 
    0, 1, -1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0)
tmat <- matrix(tvals, 6, 5, byrow=TRUE)
colnames(tmat) <- paste0("t", 1:5)
tmat
#      t1 t2 t3 t4 t5
# [1,]  1 -1 -1 -1 -1
# [2,]  0  1 -1 -1 -1
# [3,]  0  0  1 -1 -1
# [4,]  0  0  0  1 -1
# [5,]  0  0  0  0  1
# [6,]  0  0  0  0  0

idx <-as.numeric(DFM$bin)
(DFM <- data.frame(DFM, tmat[idx, ]))
#    obs      start        end   D       bin t1 t2 t3 t4 t5
# 1   1 2015-02-01 2017-01-01 700 [500,Inf)  0  0  0  0  0
# 2   2 2010-04-11 2011-01-01 265 [200,300)  0  0  1 -1 -1
# 3   3 2006-01-04 2007-05-03 484 [400,500)  0  0  0  0  1
# 4   4 2007-10-01 2008-01-01  92   [0,100)  1 -1 -1 -1 -1
# 5   5 2011-06-01 2012-01-01 214 [200,300)  0  0  1 -1 -1
# 6   6 2004-10-05 2004-12-01  57   [0,100)  1 -1 -1 -1 -1


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
Sent: Sunday, June 4, 2017 11:31 AM
To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Cc: r-help at R-project.org
Subject: Re: [R] New var

Thank you Jeff and All,

Within a given time period (say 700 days, from the start day),  I am
expecting measurements taken at each time interval;. In this case "0" means
measurement taken, "1"  not taken (stopped or opted out  and " -1"  don't
consider that time period for that individual. This will be compared with
the actual measurements taken (Observed- expected)  within each time
interval.




On Sat, Jun 3, 2017 at 9:50 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> # read.table is NOT part of the data.table package
> #library(data.table)
> DFM <- read.table( text=
> 'obs start end
> 1 2/1/2015   1/1/2017
> 2 4/11/2010  1/1/2011
> 3 1/4/2006   5/3/2007
> 4 10/1/2007  1/1/2008
> 5 6/1/2011   1/1/2012
> 6 10/5/2004 12/1/2004
> ',header = TRUE, stringsAsFactors = FALSE)
> # cleaner way to compute D
> DFM$start <- as.Date( DFM$start, format="%m/%d/%Y" )
> DFM$end <- as.Date( DFM$end, format="%m/%d/%Y" )
> DFM$D <- as.numeric( DFM$end - DFM$start, units="days" )
> # categorize your data into groups
> DFM$bin <- cut( DFM$D
>               , breaks=c( seq( 0, 500, 100 ), Inf )
>               , right=FALSE # do not include the right edge
>               , ordered_result = TRUE
>               )
> # brute force method you should have been able to figure out to show us
> some work
> DFM$t1 <- ifelse( DFM$D < 100, 1, 0 )
> DFM$t2 <- ifelse( 100 <= DFM$D & DFM$D < 200, 1, ifelse( DFM$D < 100, -1,
> 0 ) )
> DFM$t3 <- ifelse( 200 <= DFM$D & DFM$D < 300, 1, ifelse( DFM$D < 200, -1,
> 0 ) )
> DFM$t4 <- ifelse( 300 <= DFM$D & DFM$D < 400, 1, ifelse( DFM$D < 300, -1,
> 0 ) )
> DFM$t5 <- ifelse( 400 <= DFM$D & DFM$D < 500, 1, ifelse( DFM$D < 400, -1,
> 0 ) )
> # brute force method with ordered factor
> DFM$tf1 <- ifelse( "[0,100)" == DFM$bin, 1, 0 )
> DFM$tf2 <- ifelse( "[100,200)" == DFM$bin, 1, ifelse( "[100,200)" <
> DFM$bin, 0, -1 ) )
> DFM$tf3 <- ifelse( "[200,300)" == DFM$bin, 1, ifelse( "[200,300)" <
> DFM$bin, 0, -1 ) )
> DFM$tf4 <- ifelse( "[300,400)" == DFM$bin, 1, ifelse( "[300,400)" <
> DFM$bin, 0, -1 ) )
> DFM$tf5 <- ifelse( "[400,500)" == DFM$bin, 1, ifelse( "[400,500)" <
> DFM$bin, 0, -1 ) )
> # less obvious approach using the fact that factors are integers
> # and using the outer function to find all combinations of elements of two
> vectors
> # and the sign function
> DFM[ , paste0( "tm", 1:5 )] <- outer( as.integer( DFM$bin )
>                                     , 1:5
>                                     , FUN = function(x,y) {
>                                           z <- sign(y-x)+1L
>                                           ifelse( 2 == z, -1L, z )
>                                       }
>                                     )
>
> # my result, provided using dput for precise representation
> DFMresult <- structure(list(obs = 1:6, start = structure(c(16467, 14710,
> 13152, 13787, 15126, 12696), class = "Date"), end = structure(c(17167,
> 14975, 13636, 13879, 15340, 12753), class = "Date"), D = c(700,
> 265, 484, 92, 214, 57), bin = structure(c(6L, 3L, 5L, 1L, 3L,
> 1L), .Label = c("[0,100)", "[100,200)", "[200,300)", "[300,400)",
> "[400,500)", "[500,Inf)"), class = c("ordered", "factor")), t1 = c(0,
> 0, 0, 1, 0, 1), t2 = c(0, 0, 0, -1, 0, -1), t3 = c(0, 1, 0, -1,
> 1, -1), t4 = c(0, -1, 0, -1, -1, -1), t5 = c(0, -1, 1, -1, -1,
> -1), tf1 = c(0, 0, 0, 1, 0, 1), tf2 = c(0, 0, 0, -1, 0, -1),
>     tf3 = c(0, 1, 0, -1, 1, -1), tf4 = c(0, -1, 0, -1, -1, -1
>     ), tf5 = c(0, -1, 1, -1, -1, -1), tm1 = c(0, 0, 0, 1, 0,
>     1), tm2 = c(0, 0, 0, -1, 0, -1), tm3 = c(0, 1, 0, -1, 1,
>     -1), tm4 = c(0, -1, 0, -1, -1, -1), tm5 = c(0, -1, 1, -1,
>     -1, -1)), row.names = c(NA, -6L), .Names = c("obs", "start",
> "end", "D", "bin", "t1", "t2", "t3", "t4", "t5", "tf1", "tf2",
> "tf3", "tf4", "tf5", "tm1", "tm2", "tm3", "tm4", "tm5"), class =
> "data.frame")
>
> You did not address Bert's request for some context, but I am curious how
> he or Peter would have approached this problem, so I encourage you do
> provide some insight on the list as to why you are doing this.
>
>
> On Sat, 3 Jun 2017, Val wrote:
>
> Thank you all for the useful suggestion. I did some of my homework.
>>
>> library(data.table)
>> DFM <- read.table(header=TRUE, text='obs start end
>> 1 2/1/2015   1/1/2017
>> 2 4/11/2010  1/1/2011
>> 3 1/4/2006   5/3/2007
>> 4 10/1/2007  1/1/2008
>> 5 6/1/2011   1/1/2012
>> 6 10/5/2004 12/1/2004',stringsAsFactors = FALSE)
>> DFM
>>
>> DFM$D =as.numeric(difftime(as.Date(DFM$end,format="%m/%d/%Y"),
>> as.Date(DFM$start,format="%m/%d/%Y"), units = "days"))
>> DFM
>>
>> output.
>>     obs     start       end   D
>> 1   1  2/1/2015  1/1/2017 700
>> 2   2 4/11/2010  1/1/2011 265
>> 3   3  1/4/2006  5/3/2007 484
>> 4   4 10/1/2007  1/1/2008  92
>> 5   5  6/1/2011  1/1/2012 214
>> 6   6 10/5/2004 12/1/2004  57
>>
>> My problem is how do I get the other new variables
>>
>> obs     start       end   D  t1,t2,t3,t4, t5
>> 1, 2/1/2015,  1/1/2017, 700,0,0,0,0,0
>> 2, 4/11/2010, 1/1/2011, 265,0,0,1,-1,-1
>> 3, 1/4/2006,  5/3/2007, 484,0,0,0,0,1
>> 4, 10/1/2007, 1/1/2008, 92,1,-1,-1,-1,-1
>> 5, 6/1/2011,  1/1/2012, 214,0,0,1,-1,-1
>> 6, 10/15/2004,12/1/2004,47,1,-1,-1,-1,-1
>>
>> Thank you again.
>>
>>
>>
>> On Sat, Jun 3, 2017 at 12:13 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> Ii is difficult to provide useful help, because you have failed to
>>> read and follow the posting guide. In particular:
>>>
>>> 1. Plain text, not HTML.
>>> 2. Use dput() or provide code to create your example. Text printouts
>>> such as that which you gave require some work to wrangle into into an
>>> example that we can test.
>>>
>>> Specifically:
>>>
>>> 3. Have you gone through any R tutorials?-- it sure doesn't look like
>>> it. We do expect some effort to learn R before posting.
>>>
>>> 4. What is the format of your date columns? character, factors,
>>> POSIX,...? See ?date-time for details. Note particularly the
>>> "difftime" link to obtain intervals.
>>>
>>> 5. ?ifelse  for vectorized conditionals.
>>>
>>> Also, you might want to explain the context of what you are trying to
>>> do. I strongly suspect you shouldn't be doing it at all, but that is
>>> just a guess.
>>>
>>> Be sure to cc your reply to the list, not just to me.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Fri, Jun 2, 2017 at 8:49 PM, Val <valkremk at gmail.com> wrote:
>>>
>>>> Hi all,
>>>>
>>>> I have a data set with time interval and depending on the interval I
>>>> want
>>>> to create 5 more variables . Sample data below
>>>>
>>>> obs,   Start,   End
>>>> 1,2/1/2015,  1/1/2017
>>>> 2,4/11/2010, 1/1/2011
>>>> 3,1/4/2006,  5/3/2007
>>>> 4,10/1/2007, 1/1/2008
>>>> 5,6/1/2011,  1/1/2012
>>>> 6,10/15/2004,12/1/2004
>>>>
>>>> First, I want get  interval between the start date and end dates
>>>> (End-start).
>>>>
>>>>  obs,  Start , end, datediff
>>>> 1,2/1/2015,  1/1/2017, 700
>>>> 2,4/11/2010, 1/1/2011, 265
>>>> 3,1/4/2006,  5/3/2007, 484
>>>> 4,10/1/2007, 1/1/2008, 92
>>>> 5,6/1/2011,  1/1/2012, 214
>>>> 6,10/15/2004,12/1/2004,47
>>>>
>>>> Second. I want create 5 more variables  t1, t2, t3, t4 and  t5
>>>> The value of each variable is defined as follows
>>>> if datediff <   100 then  t1=1,  t2=t3=t4=t5=-1.
>>>> if datediff >= 100 and  < 200 then  t1=0, t2=1,t3=t4=t5=-1,
>>>> if datediff >= 200 and  < 300 then  t1=0, t2=0,t3=1,t4=t5=-1,
>>>> if datediff >= 300 and  < 400 then  t1=0, t2=0,t3=0,t4=1,t5=-1,
>>>> if datediff >= 400 and  < 500 then  t1=0, t2=0,t3=0,t4=0,t5=1,
>>>> if datediff >= 500 then  t1=0, t2=0,t3=0,t4=0,t5=0
>>>>
>>>> The complete out put looks like as follow.
>>>> obs, start,         end,    datediff,   t1, t2, t3, t4, t5
>>>> 1,    2/1/2015,   1/1/2017,    700, 0,  0,  0,  0,  0
>>>> 2,  4/11/2010,   1/1/2011,    265, 0,  0,  1, -1,  -1
>>>> 3,    1/4/2006,   5/3/2007,    484, 0,  0,  0, 0,   1
>>>> 4,   10/1/2007,  1/1/2008,      92, 1, -1, -1,-1,  -1
>>>> 5 ,    6/1/2011,    1/1/2012,  214,  0,  0,  1,-1,  -1
>>>> 6, 10/15/2004, 12/1/2004,     47, 1, -1, -1, -1, -1
>>>>
>>>> Thank you.
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drf at vims.edu  Sun Jun  4 20:14:03 2017
From: drf at vims.edu (David R Forrest)
Date: Sun, 4 Jun 2017 18:14:03 +0000
Subject: [R] New var
In-Reply-To: <12216049f6ea4d4f8911036e1fc73f4e@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAJOiR6aayLBNvFtOPU8SMpcVHWbummgKY=F6f8EJPx6zvscX0A@mail.gmail.com>
 <CAGxFJbS1E8bqibBybgs25xZ5FPVAD=BY++J1g-HF3Kk5RkRCSw@mail.gmail.com>
 <CAJOiR6bnLd745OL2eQOgvocRrrmZ-TwSbXJK_9Yp+5NETE1HMw@mail.gmail.com>
 <alpine.BSF.2.00.1706031941440.64647@pedal.dcn.davis.ca.us>
 <CAJOiR6arQxPObKgsSzDZM=LjXPrs5i8LDXGLVyCgfH1EtUun9A@mail.gmail.com>,
 <12216049f6ea4d4f8911036e1fc73f4e@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <EB64B0D3-B4A0-4FB3-A85A-64D8C0824427@vims.edu>



Sent from my iPhone

> On Jun 4, 2017, at 1:36 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> Since the number of choices is small (6), how about this?
> 
> Starting with Jeff's initial DFM:
> 
> DFM <- structure(list(obs = 1:6, start = structure(c(16467, 14710, 13152, 
> 13787, 15126, 12696), class = "Date"), end = structure(c(17167, 
> 14975, 13636, 13879, 15340, 12753), class = "Date"), D = c(700, 
> 265, 484, 92, 214, 57), bin = structure(c(6L, 3L, 5L, 1L, 3L, 
> 1L), .Label = c("[0,100)", "[100,200)", "[200,300)", "[300,400)", 
> "[400,500)", "[500,Inf)"), class = c("ordered", "factor"))), .Names = c("obs", 
> "start", "end", "D", "bin"), row.names = c(NA, -6L), class = "data.frame")
> 
> Construct a matrix of the six alternatives:
> 
> tvals <- c(1, -1, -1, -1, -1, 0, 1, -1, -1, -1, 0, 0, 1, -1, -1, 0, 0, 
>    0, 1, -1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0)
> tmat <- matrix(tvals, 6, 5, byrow=TRUE)
> colnames(tmat) <- paste0("t", 1:5)
> tmat
> #      t1 t2 t3 t4 t5
> # [1,]  1 -1 -1 -1 -1
> # [2,]  0  1 -1 -1 -1
> # [3,]  0  0  1 -1 -1
> # [4,]  0  0  0  1 -1
> # [5,]  0  0  0  0  1
> # [6,]  0  0  0  0  0
> 
> idx <-as.numeric(DFM$bin)
> (DFM <- data.frame(DFM, tmat[idx, ]))
> #    obs      start        end   D       bin t1 t2 t3 t4 t5
> # 1   1 2015-02-01 2017-01-01 700 [500,Inf)  0  0  0  0  0
> # 2   2 2010-04-11 2011-01-01 265 [200,300)  0  0  1 -1 -1
> # 3   3 2006-01-04 2007-05-03 484 [400,500)  0  0  0  0  1
> # 4   4 2007-10-01 2008-01-01  92   [0,100)  1 -1 -1 -1 -1
> # 5   5 2011-06-01 2012-01-01 214 [200,300)  0  0  1 -1 -1
> # 6   6 2004-10-05 2004-12-01  57   [0,100)  1 -1 -1 -1 -1
> 
> 
> David L. Carlson
> Department of Anthropology
> Texas A&M University
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
> Sent: Sunday, June 4, 2017 11:31 AM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Cc: r-help at R-project.org
> Subject: Re: [R] New var
> 
> Thank you Jeff and All,
> 
> Within a given time period (say 700 days, from the start day),  I am
> expecting measurements taken at each time interval;. In this case "0" means
> measurement taken, "1"  not taken (stopped or opted out  and " -1"  don't
> consider that time period for that individual. This will be compared with
> the actual measurements taken (Observed- expected)  within each time
> interval.
> 
> 
> 
> 
> On Sat, Jun 3, 2017 at 9:50 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> # read.table is NOT part of the data.table package
>> #library(data.table)
>> DFM <- read.table( text=
>> 'obs start end
>> 1 2/1/2015   1/1/2017
>> 2 4/11/2010  1/1/2011
>> 3 1/4/2006   5/3/2007
>> 4 10/1/2007  1/1/2008
>> 5 6/1/2011   1/1/2012
>> 6 10/5/2004 12/1/2004
>> ',header = TRUE, stringsAsFactors = FALSE)
>> # cleaner way to compute D
>> DFM$start <- as.Date( DFM$start, format="%m/%d/%Y" )
>> DFM$end <- as.Date( DFM$end, format="%m/%d/%Y" )
>> DFM$D <- as.numeric( DFM$end - DFM$start, units="days" )
>> # categorize your data into groups
>> DFM$bin <- cut( DFM$D
>>              , breaks=c( seq( 0, 500, 100 ), Inf )
>>              , right=FALSE # do not include the right edge
>>              , ordered_result = TRUE
>>              )
>> # brute force method you should have been able to figure out to show us
>> some work
>> DFM$t1 <- ifelse( DFM$D < 100, 1, 0 )
>> DFM$t2 <- ifelse( 100 <= DFM$D & DFM$D < 200, 1, ifelse( DFM$D < 100, -1,
>> 0 ) )
>> DFM$t3 <- ifelse( 200 <= DFM$D & DFM$D < 300, 1, ifelse( DFM$D < 200, -1,
>> 0 ) )
>> DFM$t4 <- ifelse( 300 <= DFM$D & DFM$D < 400, 1, ifelse( DFM$D < 300, -1,
>> 0 ) )
>> DFM$t5 <- ifelse( 400 <= DFM$D & DFM$D < 500, 1, ifelse( DFM$D < 400, -1,
>> 0 ) )
>> # brute force method with ordered factor
>> DFM$tf1 <- ifelse( "[0,100)" == DFM$bin, 1, 0 )
>> DFM$tf2 <- ifelse( "[100,200)" == DFM$bin, 1, ifelse( "[100,200)" <
>> DFM$bin, 0, -1 ) )
>> DFM$tf3 <- ifelse( "[200,300)" == DFM$bin, 1, ifelse( "[200,300)" <
>> DFM$bin, 0, -1 ) )
>> DFM$tf4 <- ifelse( "[300,400)" == DFM$bin, 1, ifelse( "[300,400)" <
>> DFM$bin, 0, -1 ) )
>> DFM$tf5 <- ifelse( "[400,500)" == DFM$bin, 1, ifelse( "[400,500)" <
>> DFM$bin, 0, -1 ) )
>> # less obvious approach using the fact that factors are integers
>> # and using the outer function to find all combinations of elements of two
>> vectors
>> # and the sign function
>> DFM[ , paste0( "tm", 1:5 )] <- outer( as.integer( DFM$bin )
>>                                    , 1:5
>>                                    , FUN = function(x,y) {
>>                                          z <- sign(y-x)+1L
>>                                          ifelse( 2 == z, -1L, z )
>>                                      }
>>                                    )
>> 
>> # my result, provided using dput for precise representation
>> DFMresult <- structure(list(obs = 1:6, start = structure(c(16467, 14710,
>> 13152, 13787, 15126, 12696), class = "Date"), end = structure(c(17167,
>> 14975, 13636, 13879, 15340, 12753), class = "Date"), D = c(700,
>> 265, 484, 92, 214, 57), bin = structure(c(6L, 3L, 5L, 1L, 3L,
>> 1L), .Label = c("[0,100)", "[100,200)", "[200,300)", "[300,400)",
>> "[400,500)", "[500,Inf)"), class = c("ordered", "factor")), t1 = c(0,
>> 0, 0, 1, 0, 1), t2 = c(0, 0, 0, -1, 0, -1), t3 = c(0, 1, 0, -1,
>> 1, -1), t4 = c(0, -1, 0, -1, -1, -1), t5 = c(0, -1, 1, -1, -1,
>> -1), tf1 = c(0, 0, 0, 1, 0, 1), tf2 = c(0, 0, 0, -1, 0, -1),
>>    tf3 = c(0, 1, 0, -1, 1, -1), tf4 = c(0, -1, 0, -1, -1, -1
>>    ), tf5 = c(0, -1, 1, -1, -1, -1), tm1 = c(0, 0, 0, 1, 0,
>>    1), tm2 = c(0, 0, 0, -1, 0, -1), tm3 = c(0, 1, 0, -1, 1,
>>    -1), tm4 = c(0, -1, 0, -1, -1, -1), tm5 = c(0, -1, 1, -1,
>>    -1, -1)), row.names = c(NA, -6L), .Names = c("obs", "start",
>> "end", "D", "bin", "t1", "t2", "t3", "t4", "t5", "tf1", "tf2",
>> "tf3", "tf4", "tf5", "tm1", "tm2", "tm3", "tm4", "tm5"), class =
>> "data.frame")
>> 
>> You did not address Bert's request for some context, but I am curious how
>> he or Peter would have approached this problem, so I encourage you do
>> provide some insight on the list as to why you are doing this.
>> 
>> 
>> On Sat, 3 Jun 2017, Val wrote:
>> 
>> Thank you all for the useful suggestion. I did some of my homework.
>>> 
>>> library(data.table)
>>> DFM <- read.table(header=TRUE, text='obs start end
>>> 1 2/1/2015   1/1/2017
>>> 2 4/11/2010  1/1/2011
>>> 3 1/4/2006   5/3/2007
>>> 4 10/1/2007  1/1/2008
>>> 5 6/1/2011   1/1/2012
>>> 6 10/5/2004 12/1/2004',stringsAsFactors = FALSE)
>>> DFM
>>> 
>>> DFM$D =as.numeric(difftime(as.Date(DFM$end,format="%m/%d/%Y"),
>>> as.Date(DFM$start,format="%m/%d/%Y"), units = "days"))
>>> DFM
>>> 
>>> output.
>>>    obs     start       end   D
>>> 1   1  2/1/2015  1/1/2017 700
>>> 2   2 4/11/2010  1/1/2011 265
>>> 3   3  1/4/2006  5/3/2007 484
>>> 4   4 10/1/2007  1/1/2008  92
>>> 5   5  6/1/2011  1/1/2012 214
>>> 6   6 10/5/2004 12/1/2004  57
>>> 
>>> My problem is how do I get the other new variables
>>> 
>>> obs     start       end   D  t1,t2,t3,t4, t5
>>> 1, 2/1/2015,  1/1/2017, 700,0,0,0,0,0
>>> 2, 4/11/2010, 1/1/2011, 265,0,0,1,-1,-1
>>> 3, 1/4/2006,  5/3/2007, 484,0,0,0,0,1
>>> 4, 10/1/2007, 1/1/2008, 92,1,-1,-1,-1,-1
>>> 5, 6/1/2011,  1/1/2012, 214,0,0,1,-1,-1
>>> 6, 10/15/2004,12/1/2004,47,1,-1,-1,-1,-1
>>> 
>>> Thank you again.
>>> 
>>> 
>>> 
>>> On Sat, Jun 3, 2017 at 12:13 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> 
>>>> Ii is difficult to provide useful help, because you have failed to
>>>> read and follow the posting guide. In particular:
>>>> 
>>>> 1. Plain text, not HTML.
>>>> 2. Use dput() or provide code to create your example. Text printouts
>>>> such as that which you gave require some work to wrangle into into an
>>>> example that we can test.
>>>> 
>>>> Specifically:
>>>> 
>>>> 3. Have you gone through any R tutorials?-- it sure doesn't look like
>>>> it. We do expect some effort to learn R before posting.
>>>> 
>>>> 4. What is the format of your date columns? character, factors,
>>>> POSIX,...? See ?date-time for details. Note particularly the
>>>> "difftime" link to obtain intervals.
>>>> 
>>>> 5. ?ifelse  for vectorized conditionals.
>>>> 
>>>> Also, you might want to explain the context of what you are trying to
>>>> do. I strongly suspect you shouldn't be doing it at all, but that is
>>>> just a guess.
>>>> 
>>>> Be sure to cc your reply to the list, not just to me.
>>>> 
>>>> Cheers,
>>>> Bert
>>>> 
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> 
>>>>> On Fri, Jun 2, 2017 at 8:49 PM, Val <valkremk at gmail.com> wrote:
>>>>> 
>>>>> Hi all,
>>>>> 
>>>>> I have a data set with time interval and depending on the interval I
>>>>> want
>>>>> to create 5 more variables . Sample data below
>>>>> 
>>>>> obs,   Start,   End
>>>>> 1,2/1/2015,  1/1/2017
>>>>> 2,4/11/2010, 1/1/2011
>>>>> 3,1/4/2006,  5/3/2007
>>>>> 4,10/1/2007, 1/1/2008
>>>>> 5,6/1/2011,  1/1/2012
>>>>> 6,10/15/2004,12/1/2004
>>>>> 
>>>>> First, I want get  interval between the start date and end dates
>>>>> (End-start).
>>>>> 
>>>>> obs,  Start , end, datediff
>>>>> 1,2/1/2015,  1/1/2017, 700
>>>>> 2,4/11/2010, 1/1/2011, 265
>>>>> 3,1/4/2006,  5/3/2007, 484
>>>>> 4,10/1/2007, 1/1/2008, 92
>>>>> 5,6/1/2011,  1/1/2012, 214
>>>>> 6,10/15/2004,12/1/2004,47
>>>>> 
>>>>> Second. I want create 5 more variables  t1, t2, t3, t4 and  t5
>>>>> The value of each variable is defined as follows
>>>>> if datediff <   100 then  t1=1,  t2=t3=t4=t5=-1.
>>>>> if datediff >= 100 and  < 200 then  t1=0, t2=1,t3=t4=t5=-1,
>>>>> if datediff >= 200 and  < 300 then  t1=0, t2=0,t3=1,t4=t5=-1,
>>>>> if datediff >= 300 and  < 400 then  t1=0, t2=0,t3=0,t4=1,t5=-1,
>>>>> if datediff >= 400 and  < 500 then  t1=0, t2=0,t3=0,t4=0,t5=1,
>>>>> if datediff >= 500 then  t1=0, t2=0,t3=0,t4=0,t5=0
>>>>> 
>>>>> The complete out put looks like as follow.
>>>>> obs, start,         end,    datediff,   t1, t2, t3, t4, t5
>>>>> 1,    2/1/2015,   1/1/2017,    700, 0,  0,  0,  0,  0
>>>>> 2,  4/11/2010,   1/1/2011,    265, 0,  0,  1, -1,  -1
>>>>> 3,    1/4/2006,   5/3/2007,    484, 0,  0,  0, 0,   1
>>>>> 4,   10/1/2007,  1/1/2008,      92, 1, -1, -1,-1,  -1
>>>>> 5 ,    6/1/2011,    1/1/2012,  214,  0,  0,  1,-1,  -1
>>>>> 6, 10/15/2004, 12/1/2004,     47, 1, -1, -1, -1, -1
>>>>> 
>>>>> Thank you.
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>> ng-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> ------------------------------------------------------------
>> ---------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ------------------------------------------------------------
>> ---------------
>> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From percentil101 at gmail.com  Sun Jun  4 11:11:24 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Sun, 4 Jun 2017 11:11:24 +0200
Subject: [R] Format y axis
Message-ID: <CAB-TgNu5xUXpo73TU7CY_vPWpys9qFaZBexj1DkXmjJ0ksRHbw@mail.gmail.com>

Hi all,

I have been looking on documentation but I?m not able to find how to
customize format on y axis so that for example:

y value goes from 1000 to 9000 it appears on thousand position a 1,000 and
on the comas with "," and two decimals.

(For the previous answers many thanks)

	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Sun Jun  4 16:44:42 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Sun, 4 Jun 2017 14:44:42 +0000 (UTC)
Subject: [R] Warning from reshape2 when melting a data frame with
	uneven	number of columns.
In-Reply-To: <CAC8=1eoykfDUHMcZ+OEafnT6jCSHV-9kvLAxXYnCkaKjbT_zPQ@mail.gmail.com>
References: <CAC8=1eoykfDUHMcZ+OEafnT6jCSHV-9kvLAxXYnCkaKjbT_zPQ@mail.gmail.com>
Message-ID: <345127699.1703514.1496587482949@mail.yahoo.com>

I am not really sure what the warning means but I think your underlying problem is that all your variables are factors. Did you intend the values in each variable to be character?
data.frame':??? 3 obs. of? 5 variables:
?$ V1: Factor w/ 3 levels "Name1","Name2",..: 1 2 3
?$ V2: Factor w/ 3 levels "nam1","name-1",..: 1 3 2
?$ V3: Factor w/ 3 levels "nam2","nam_34",..: 1 2 3
?$ V4: Factor w/ 3 levels "","nam3","nam_56": 2 3 1
?$ V5: Factor w/ 2 levels "","name_78": 1 2 1

 

    On Sunday, June 4, 2017 6:48 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
 

 Here is a small reproducible example:

data <-
structure(list(V1 = structure(1:3, .Label = c("Name1", "Name2",
"Name3"), class = "factor"), V2 = structure(c(1L, 3L, 2L), .Label =
c("nam1",
"name-1", "name_12"), class = "factor"), V3 = structure(1:3, .Label =
c("nam2",
"nam_34", "name-2"), class = "factor"), V4 = structure(c(2L,
3L, 1L), .Label = c("", "nam3", "nam_56"), class = "factor"),
? ? V5 = structure(c(1L, 2L, 1L), .Label = c("", "name_78"), class =
"factor")), .Names = c("V1",
"V2", "V3", "V4", "V5"), class = "data.frame", row.names = c(NA,
-3L))

library(reshape2)
data_long <- melt(data,id.vars="V1")

Warning message:
attributes are not identical across measure variables; they will be dropped


Can someone please tell me how to correct this?

Best Regards,
Ashim

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Jun  5 00:12:54 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 5 Jun 2017 08:12:54 +1000
Subject: [R] Format y axis
In-Reply-To: <CAB-TgNu5xUXpo73TU7CY_vPWpys9qFaZBexj1DkXmjJ0ksRHbw@mail.gmail.com>
References: <CAB-TgNu5xUXpo73TU7CY_vPWpys9qFaZBexj1DkXmjJ0ksRHbw@mail.gmail.com>
Message-ID: <CA+8X3fXu9Fe_1VXxW-P8tL73mimZnhMSv+_1w-L2nNMRjFJYHw@mail.gmail.com>

Hi Pedro,
Try this:

par(mar=c(5,5,4,2))
plot(seq(0,9000,1000),yaxt="n",ylab="")
axis(2,seq(1000,9000,1000),
 labels=formatC(seq(1000,9000,1000),format="f",
 big.mark=",",digits=2),las=2)

Jim


On Sun, Jun 4, 2017 at 7:11 PM, Pedro p?ramo <percentil101 at gmail.com> wrote:
> Hi all,
>
> I have been looking on documentation but I?m not able to find how to
> customize format on y axis so that for example:
>
> y value goes from 1000 to 9000 it appears on thousand position a 1,000 and
> on the comas with "," and two decimals.
>
> (For the previous answers many thanks)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From beni.gfoehler at hispeed.ch  Sun Jun  4 23:20:40 2017
From: beni.gfoehler at hispeed.ch (=?utf-8?Q?Benjamin_Gf=C3=B6hler?=)
Date: Sun, 4 Jun 2017 23:20:40 +0200
Subject: [R] plot command error message
Message-ID: <8D85B491-BCCD-4BCC-A75A-1AE66274798B@hispeed.ch>

 
I tried to plot a clustered linear regression model with the cplot command in R (code below). Leaflet is a binary variable (I know logit would be better), partisan is nummeric variable (0-4) and partisan_mis a dummy (0,1). As you can see it is clustered around two variables: around individuals and around the specific survey. When I try to run the cplot command I always get this error message:

error in plot.window(...) : need finite 'ylim' values 

Zus?tzlich: Warnmeldungen:	 1: In min(x) : no non-missing arguments to min; returning Inf 

						2: In max(x) : no non-missing arguments to max; returning -Inf

Does anyone know how to solve this problem?

As I suppose that the problem has something to do with the way I coded the variables, here is how i did it:


voxit$leaflet[voxit$a65== "Ja"] <- 1
voxit$leaflet[voxit$a65== "Nein"] <- 0
voxitf <- subset(voxit, leaflet >= 0 ) 

voxitf$partisan[voxitf$a87x== "1 Tag oder weniger vorher"] <- 0
voxitf$partisan[voxitf$a87x== "Einige Tage vorher"] <- 1
voxitf$partisan[voxitf$a87x== "1-2 Woche(n) vorher"] <- 2
voxitf$partisan[voxitf$a87x== "Mehrere Wochen vorher"] <- 3
voxitf$partisan[voxitf$a87x== "Schon immer klar"] <- 4
mean(voxitf$partisan, na.rm = TRUE)

voxitf$partisan[is.na(voxitf$a87x)]<- 2.73493
table(voxitf$partisan)

voxitf$partisan_mis[is.na(voxitf$a87x)]<- 1
voxitf$partisan_mis[!is.na(voxitf$a87x)]<- 0


model1.1 <- lm(leaflet ~ partisan + partisan_mis , data = voxitf)

vcov_clust1.1 <- cluster.vcov(model1.1, cbind(voxitf$id,voxitf$projetx))

(marginal_effects1.1 <- margins(model1.1)) 

summary(marginal_effects1.1)

cplot(model1.1, x = "partisan", dx = "leaflet", what = "effect", se.type = "shade")
	[[alternative HTML version deleted]]


From kls.gokhale at gmail.com  Mon Jun  5 12:11:23 2017
From: kls.gokhale at gmail.com (Kailas Gokhale)
Date: Mon, 5 Jun 2017 15:41:23 +0530
Subject: [R] issues in plm using random effect model
Message-ID: <CAMO91N4oCvTf1ZkHLqQ4t3SAbVw=VYLM-6JKt49CPbw+kUBiGg@mail.gmail.com>

Dear Sir,

Thank you for accepting my request for registration on this site.
I am trying to solve panel data problems using plm package , but while
suing random effect model i am getting following messege saying
"

Warning message:In sqrt(sigma2) : NaNs produced

"

In some other cases i am getting message saying where TSS = NA , that I am
not understanding
I am sending you my code along with out put.

Kindly help me .

I am sending you my code and output for your kind reference. data file is
also attached


rm(list=ls())
library(MASS)
library(bdsmatrix)
library(zoo)
library(nlme)
library(sandwich)
library(car)
library(lmtest)
library(plm)

data1<- read.csv(file.choose(),header=TRUE,sep=",")
D<-na.omit(data1)
attach(D)
Pdata<-plm.data(D, index=c("CT","T"))

pool11<- plm(Y~X1+X2,data = Pdata, model="pooling")
# pool21<- plm(Equity.dividend.1~ Profit.after.tax.1+ LaggedDivd.1+
log(Size.1)+factor(CompanyName)-1,data = Pdata, model="pooling")
fixed.mod1<- plm(Y~X1+X2,data = Pdata, model="within")
rand.mod1<- plm(Y~X1+X2,data = Pdata, model="random")


summary(pool11)
summary(fixed.mod1)
summary(fixef(fixed.mod1))
summary(rand.mod1)


##################output####################

Oneway (individual) effect Pooling Model

Call:
plm(formula = Y ~ X1 + X2, data = Pdata, model = "pooling")

Unbalanced Panel: n=6, T=4-6, N=34

Residuals :
   Min. 1st Qu.  Median 3rd Qu.    Max.
-19.400  -9.810  -0.648   8.490  23.900

Coefficients :
             Estimate Std. Error t-value  Pr(>|t|)
(Intercept) 25.229162   6.858418  3.6786 0.0008847 ***
X1           0.016438   0.046905  0.3504 0.7283744
X2          -2.231250   2.220346 -1.0049 0.3227198
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Total Sum of Squares:    5082
Residual Sum of Squares: 4892.7
R-Squared:      0.037241
Adj. R-Squared: 0.033955
F-statistic: 0.599566 on 2 and 31 DF, p-value: 0.55529>
summary(fixed.mod1)Oneway (individual) effect Within Model

Call:
plm(formula = Y ~ X1 + X2, data = Pdata, model = "within")

Unbalanced Panel: n=6, T=4-6, N=34

Residuals :
    Min.  1st Qu.   Median  3rd Qu.     Max.
-24.0000  -8.0400  -0.0795   6.6300  25.1000

Coefficients :
    Estimate Std. Error t-value Pr(>|t|)
X1  0.065306   0.060090  1.0868   0.2871
X2 -3.082215   2.514602 -1.2257   0.2313

Total Sum of Squares:    4791.9
Residual Sum of Squares: 4380.7
R-Squared:      0.085822
Adj. R-Squared: 0.065628
F-statistic: 1.22042 on 2 and 26 DF, p-value: 0.31146>
summary(fixef(fixed.mod1))  Estimate Std. Error t-value  Pr(>|t|)
A  33.2672    10.4360  3.1877 0.0014340 **
B  21.9300     9.2930  2.3598 0.0182831 *
C  27.6590     7.9522  3.4781 0.0005049 ***
D  21.9369     9.4271  2.3270 0.0199647 *
E  17.6243     8.6149  2.0458 0.0407766 *
F  23.8578     9.2198  2.5877 0.0096625 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1>
summary(rand.mod1)Oneway (individual) effect Random Effect Model
   (Swamy-Arora's transformation)

Call:
plm(formula = Y ~ X1 + X2, data = Pdata, model = "random")

Unbalanced Panel: n=6, T=4-6, N=34

Effects:
                 var std.dev  share
idiosyncratic 168.49   12.98  1.117
individual    -17.60      NA -0.117
theta  :
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
-0.6366 -0.6366 -0.6366 -0.5983 -0.6366 -0.3106

Residuals :
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
-21.000 -11.400   0.913   0.114   9.040  24.000

Coefficients :
              Estimate Std. Error t-value  Pr(>|t|)
(Intercept) 26.3963638  6.5706835  4.0173 0.0003482 ***
X1          -0.0066621  0.0433425 -0.1537 0.8788364
X2          -2.1087903  2.1533566 -0.9793 0.3350111
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Total Sum of Squares:    5548.4
Residual Sum of Squares: 5382.1
R-Squared:      0.037133
Adj. R-Squared: 0.033856
F-statistic: 0.479037 on 2 and 31 DF, p-value: 0.62389Warning
message:In sqrt(sigma2) : NaNs produced



with warm regards
kailas D. Gokhale

From michael.keilhacker at tum.de  Mon Jun  5 12:14:59 2017
From: michael.keilhacker at tum.de (Keilhacker, Michael)
Date: Mon, 5 Jun 2017 10:14:59 +0000
Subject: [R] R] Error message "cs_lu(A) failed: near-singular A (or out of
 memory)"
Message-ID: <58f4e286034c4286ace75cc93df0f345@tum.de>

Dear Arne,


thank you very much upfront for your time that you invest in answering my question.


I'm using your systemfit R package to analyze if companies risk appetite has a relationship to their performance and how it evolves over time. We collected data for ca. 80 companies, from 6 segments over 15 years that gives us a final data set with 1,312 firm-year observations. We have set up 3 equations (based on existing SEM from literature) and experience the following:

- The systemfit package performs well when using no dummy variables (e.g. for year, segment, firm)

- When adding dummy variables (year / segment) the systemfit package still provides results; however, if we remove the segment dummy variable and add a firm dummy variable we experience the error message: "cs_lu(A) failed: near-singular A (or out of memory)"

- We also tested the systemfit package with firm and year dummy variable using a sub-sample of our data (ca. 10 companies) and the package worked without any error messages

- Afterwards we tested the systemfit package using a server (64 gb ram, 16 core,...) by applying the systemfit package again on the final data set. However, we experienced again the same error message.


We use R 3.3.2 and the systemfit package 1.1-20.


I would be very grateful if you could support us anyhow and give us a hint how we could solve the situation.


Thanks again for your help.


Warm Regards from Munich,

Michael
___________________________________________________

Michael Keilhacker, MBA, M.A.
Logistics and Supply Chain Management
Technische Universit?t M?nchen ? TUM School of Management
Arcisstra?e 21 ? 80333 M?nchen ? +49-163-5454918<tel:%2B49-89-289-28203> ? michael.keilhacker at tum.de<mailto:christian.mandl at tum.de>
www.log.wi.tum.de<http://www.log.wi.tum.de>

	[[alternative HTML version deleted]]


From MOSHEKE at cellcom.co.il  Mon Jun  5 13:33:56 2017
From: MOSHEKE at cellcom.co.il (Moshe Kelner)
Date: Mon, 5 Jun 2017 11:33:56 +0000
Subject: [R] Hi
Message-ID: <ACCDA47888F81B479E942854544FA4210187591BC2@MBX2.corp.cellcom.co.il>

Hi ,

I'm asking for a way to compute the integral of:  function(x) {x*(log(x)+b)*((log(x)+b)^(a-1)-b^(a-1))/(a-1)*(b^(a-1)}
When a and b are between 1 to 10 and X is the integral parameter between 0 to 1 '

Thanks,

Moshe



This e-mail message may contain confidential, commercial and privileged information or data that
constitute proprietary information of Cellcom Israel Ltd. Any review or distribution by others is
strictly prohibited. If you are not the intended recipient you are hereby notified that any use
of this information or data by any other person is absolutely prohibited.
If you are not the intended recipient, please delete all copies.

Thank You.
http://www.cellcom.co.il

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Jun  5 15:31:48 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 05 Jun 2017 06:31:48 -0700
Subject: [R] Hi
In-Reply-To: <ACCDA47888F81B479E942854544FA4210187591BC2@MBX2.corp.cellcom.co.il>
References: <ACCDA47888F81B479E942854544FA4210187591BC2@MBX2.corp.cellcom.co.il>
Message-ID: <B21DB184-4D92-423E-AD1C-68A70F444CED@dcn.davis.ca.us>

Your function has mismatching parentheses.

I recommend using a computer algebra system like Maxima.
-- 
Sent from my phone. Please excuse my brevity.

On June 5, 2017 4:33:56 AM PDT, Moshe Kelner <MOSHEKE at cellcom.co.il> wrote:
>Hi ,
>
>I'm asking for a way to compute the integral of:  function(x)
>{x*(log(x)+b)*((log(x)+b)^(a-1)-b^(a-1))/(a-1)*(b^(a-1)}
>When a and b are between 1 to 10 and X is the integral parameter
>between 0 to 1 '
>
>Thanks,
>
>Moshe
>
>
>
>This e-mail message may contain confidential, commercial and privileged
>information or data that
>constitute proprietary information of Cellcom Israel Ltd. Any review or
>distribution by others is
>strictly prohibited. If you are not the intended recipient you are
>hereby notified that any use
>of this information or data by any other person is absolutely
>prohibited.
>If you are not the intended recipient, please delete all copies.
>
>Thank You.
>http://www.cellcom.co.il
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Jun  5 18:31:28 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 5 Jun 2017 09:31:28 -0700
Subject: [R] Hi
In-Reply-To: <ACCDA47888F81B479E942854544FA4210187591BC2@MBX2.corp.cellcom.co.il>
References: <ACCDA47888F81B479E942854544FA4210187591BC2@MBX2.corp.cellcom.co.il>
Message-ID: <2F27B5BA-BFA3-4939-A6D6-63E78895D4D7@comcast.net>


> On Jun 5, 2017, at 4:33 AM, Moshe Kelner <MOSHEKE at cellcom.co.il> wrote:
> 
> Hi ,
> 
> I'm asking for a way to compute the integral of:  


> function(x) {x*(log(x)+b)*((log(x)+b)^(a-1)-b^(a-1))/(a-1)*(b^(a-1)}

Problems here ----------------^^^-----and if(a==1)-----^^^---paren--^
                              |||                      |||         |

Annotation only useful with monospaced font. Not likely to be useful to Moshe if he will be using HTML for posting.

> When a and b are between 1 to 10 and X is the integral parameter between 0 to 1 '

How are you planning to handle a value of log(0)? Or for that matter division by 0 if a==1

R does do limiting integrations (if that is the correct term for lim(integrate(func, lower=0, ...)) with the value of func(0) undefined. You may need to set the lower limit of integration to be a small positive number.

R also has difficulties with fractional powers of negative numbers:

> (-.2)^(1.1-1)
[1] NaN 

Did you perhaps intend `a` to be in the set: 2:9 ?

If I set: 

 my_f <- function(x, a=1.1, b=1.1)   # will error out with those defaults
                    {x*(log(x)+b)*((log(x)+b)^(a-1)-b^(a-1))/(a-1)*(b^(a-1))}

> integrate(my_f, lower=0.1,upper=.9, a=2, b=2)  #call with integer `a` and `b`
-0.5063435 with absolute error < 4.6e-09
> integrate(my_f, lower=0.01,upper=.9, a=2, b=2)
-0.4829606 with absolute error < 3.5e-05
> integrate(my_f, lower=0.001,upper=.9, a=2, b=2)
-0.4813907 with absolute error < 4.8e-05


> 
> Moshe
> 
excised meaningless confidentiality message
> 
> Thank You.
> http://www.cellcom.co.il
> 
> 	[[alternative HTML version deleted]]

Do read the Posting Guide which advises not to use HTML.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Mon Jun  5 18:40:57 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 05 Jun 2017 09:40:57 -0700
Subject: [R] R] Error message "cs_lu(A) failed: near-singular A (or out
	of memory)"
In-Reply-To: <58f4e286034c4286ace75cc93df0f345@tum.de>
References: <58f4e286034c4286ace75cc93df0f345@tum.de>
Message-ID: <FEAC479E-E2E8-40B5-B16F-1A9B19775BCF@dcn.davis.ca.us>

This appears to be a case of insufficient understanding of statistics, which is not on topic for r-help. Look at how well the per-firm models would work... my guess is that some of the firms have insufficient data for useful analysis. If that is not it, consider providing a more concrete example on stats.stackexchange.com.
-- 
Sent from my phone. Please excuse my brevity.

On June 5, 2017 3:14:59 AM PDT, "Keilhacker, Michael" <michael.keilhacker at tum.de> wrote:
>Dear Arne,
>
>
>thank you very much upfront for your time that you invest in answering
>my question.
>
>
>I'm using your systemfit R package to analyze if companies risk
>appetite has a relationship to their performance and how it evolves
>over time. We collected data for ca. 80 companies, from 6 segments over
>15 years that gives us a final data set with 1,312 firm-year
>observations. We have set up 3 equations (based on existing SEM from
>literature) and experience the following:
>
>- The systemfit package performs well when using no dummy variables
>(e.g. for year, segment, firm)
>
>- When adding dummy variables (year / segment) the systemfit package
>still provides results; however, if we remove the segment dummy
>variable and add a firm dummy variable we experience the error message:
>"cs_lu(A) failed: near-singular A (or out of memory)"
>
>- We also tested the systemfit package with firm and year dummy
>variable using a sub-sample of our data (ca. 10 companies) and the
>package worked without any error messages
>
>- Afterwards we tested the systemfit package using a server (64 gb ram,
>16 core,...) by applying the systemfit package again on the final data
>set. However, we experienced again the same error message.
>
>
>We use R 3.3.2 and the systemfit package 1.1-20.
>
>
>I would be very grateful if you could support us anyhow and give us a
>hint how we could solve the situation.
>
>
>Thanks again for your help.
>
>
>Warm Regards from Munich,
>
>Michael
>___________________________________________________
>
>Michael Keilhacker, MBA, M.A.
>Logistics and Supply Chain Management
>Technische Universit?t M?nchen ? TUM School of Management
>Arcisstra?e 21 ? 80333 M?nchen ?
>+49-163-5454918<tel:%2B49-89-289-28203> ?
>michael.keilhacker at tum.de<mailto:christian.mandl at tum.de>
>www.log.wi.tum.de<http://www.log.wi.tum.de>
>
>	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Mon Jun  5 20:14:41 2017
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Mon, 5 Jun 2017 13:14:41 -0500
Subject: [R] months not working with local language (weekdays does)
Message-ID: <CAM-xyZjJmQkfYHb09Or2j1NY7qfE4f4d9nso5XiqK0i=w4GvCA@mail.gmail.com>

Hi,

I want to reporte some strange behaviour with the "months" function, from
base R.

When using "months" to extract months from a date column, I'm getting the
months in english, when I was expecting months in spanish.

When using "weekdays" to extract days of week from a date column, I'm
getting the the days in spanish (as expected).


My understanding is that both work with local language. What may be
happening?


My Session Info:

R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Spanish_Peru.1252
[2] LC_CTYPE=Spanish_Peru.1252
[3] LC_MONETARY=Spanish_Peru.1252
[4] LC_NUMERIC=C
[5] LC_TIME=Spanish_Peru.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets
[6] methods   base

other attached packages:
 [1] anytime_0.2.2      ggplot2_2.2.1.9000 lubridate_1.6.0
 [4] tidyr_0.6.3        rtweet_0.4.4       dplyr_0.5.0
 [7] Rfacebook_0.6.16   httpuv_1.3.3       rjson_0.2.15
[10] httr_1.2.1

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.10     magrittr_1.5     devtools_1.13.2
 [4] munsell_0.4.3    colorspace_1.3-2 R6_2.2.0
 [7] rlang_0.1        plyr_1.8.4       stringr_1.2.0
[10] tools_3.4.0      grid_3.4.0       gtable_0.2.0
[13] DBI_0.6-1        git2r_0.18.0     withr_1.0.2
[16] openssl_0.9.6    lazyeval_0.2.0   assertthat_0.2.0
[19] digest_0.6.12    tibble_1.3.1     curl_2.6
[22] memoise_1.1.0    labeling_0.3     stringi_1.1.5
[25] compiler_3.4.0   scales_0.4.1     jsonlite_1.5

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Jun  5 21:21:09 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 05 Jun 2017 20:21:09 +0100
Subject: [R] months not working with local language (weekdays does)
In-Reply-To: <CAM-xyZjJmQkfYHb09Or2j1NY7qfE4f4d9nso5XiqK0i=w4GvCA@mail.gmail.com>
References: <CAM-xyZjJmQkfYHb09Or2j1NY7qfE4f4d9nso5XiqK0i=w4GvCA@mail.gmail.com>
Message-ID: <5935AF25.2080500@sapo.pt>

Hello,

This doesn't answer the question, but in portuguese it works as expected.

 > x <- as.Date("2017-06-05")
 > months(x)
[1] "junho"
 > weekdays(x)
[1] "segunda-feira"
 > sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.0

Hope this helps,

Rui Barradas

Em 05-06-2017 19:14, Omar Andr? Gonz?les D?az escreveu:
> Hi,
>
> I want to reporte some strange behaviour with the "months" function, from
> base R.
>
> When using "months" to extract months from a date column, I'm getting the
> months in english, when I was expecting months in spanish.
>
> When using "weekdays" to extract days of week from a date column, I'm
> getting the the days in spanish (as expected).
>
>
> My understanding is that both work with local language. What may be
> happening?
>
>
> My Session Info:
>
> R version 3.4.0 (2017-04-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=Spanish_Peru.1252
> [2] LC_CTYPE=Spanish_Peru.1252
> [3] LC_MONETARY=Spanish_Peru.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=Spanish_Peru.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets
> [6] methods   base
>
> other attached packages:
>   [1] anytime_0.2.2      ggplot2_2.2.1.9000 lubridate_1.6.0
>   [4] tidyr_0.6.3        rtweet_0.4.4       dplyr_0.5.0
>   [7] Rfacebook_0.6.16   httpuv_1.3.3       rjson_0.2.15
> [10] httr_1.2.1
>
> loaded via a namespace (and not attached):
>   [1] Rcpp_0.12.10     magrittr_1.5     devtools_1.13.2
>   [4] munsell_0.4.3    colorspace_1.3-2 R6_2.2.0
>   [7] rlang_0.1        plyr_1.8.4       stringr_1.2.0
> [10] tools_3.4.0      grid_3.4.0       gtable_0.2.0
> [13] DBI_0.6-1        git2r_0.18.0     withr_1.0.2
> [16] openssl_0.9.6    lazyeval_0.2.0   assertthat_0.2.0
> [19] digest_0.6.12    tibble_1.3.1     curl_2.6
> [22] memoise_1.1.0    labeling_0.3     stringi_1.1.5
> [25] compiler_3.4.0   scales_0.4.1     jsonlite_1.5
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Mon Jun  5 21:37:38 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 5 Jun 2017 15:37:38 -0400
Subject: [R] months not working with local language (weekdays does)
In-Reply-To: <5935AF25.2080500@sapo.pt>
References: <CAM-xyZjJmQkfYHb09Or2j1NY7qfE4f4d9nso5XiqK0i=w4GvCA@mail.gmail.com>
 <5935AF25.2080500@sapo.pt>
Message-ID: <f2d230d4-4f3d-48d4-3509-679ad26ecb2c@gmail.com>

For what it's worth, I tried setting my Region | Formats setting to 
Spanish (Peru) in Windows 10 Control Panel, and got Spanish weekday and 
month results.

I believe on Windows we use the Microsoft C strftime function to produce 
these strings, with the %A (for weekday) or %B (for month) formats.  So 
this question probably needs to be addressed to Microsoft.

Duncan Murdoch

On 05/06/2017 3:21 PM, Rui Barradas wrote:
> Hello,
>
> This doesn't answer the question, but in portuguese it works as expected.
>
>  > x <- as.Date("2017-06-05")
>  > months(x)
> [1] "junho"
>  > weekdays(x)
> [1] "segunda-feira"
>  > sessionInfo()
> R version 3.4.0 (2017-04-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=Portuguese_Portugal.1252
> LC_CTYPE=Portuguese_Portugal.1252
> [3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C
>
> [5] LC_TIME=Portuguese_Portugal.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.0
>
> Hope this helps,
>
> Rui Barradas
>
> Em 05-06-2017 19:14, Omar Andr? Gonz?les D?az escreveu:
>> Hi,
>>
>> I want to reporte some strange behaviour with the "months" function, from
>> base R.
>>
>> When using "months" to extract months from a date column, I'm getting the
>> months in english, when I was expecting months in spanish.
>>
>> When using "weekdays" to extract days of week from a date column, I'm
>> getting the the days in spanish (as expected).
>>
>>
>> My understanding is that both work with local language. What may be
>> happening?
>>
>>
>> My Session Info:
>>
>> R version 3.4.0 (2017-04-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=Spanish_Peru.1252
>> [2] LC_CTYPE=Spanish_Peru.1252
>> [3] LC_MONETARY=Spanish_Peru.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=Spanish_Peru.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets
>> [6] methods   base
>>
>> other attached packages:
>>   [1] anytime_0.2.2      ggplot2_2.2.1.9000 lubridate_1.6.0
>>   [4] tidyr_0.6.3        rtweet_0.4.4       dplyr_0.5.0
>>   [7] Rfacebook_0.6.16   httpuv_1.3.3       rjson_0.2.15
>> [10] httr_1.2.1
>>
>> loaded via a namespace (and not attached):
>>   [1] Rcpp_0.12.10     magrittr_1.5     devtools_1.13.2
>>   [4] munsell_0.4.3    colorspace_1.3-2 R6_2.2.0
>>   [7] rlang_0.1        plyr_1.8.4       stringr_1.2.0
>> [10] tools_3.4.0      grid_3.4.0       gtable_0.2.0
>> [13] DBI_0.6-1        git2r_0.18.0     withr_1.0.2
>> [16] openssl_0.9.6    lazyeval_0.2.0   assertthat_0.2.0
>> [19] digest_0.6.12    tibble_1.3.1     curl_2.6
>> [22] memoise_1.1.0    labeling_0.3     stringi_1.1.5
>> [25] compiler_3.4.0   scales_0.4.1     jsonlite_1.5
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From oma.gonzales at gmail.com  Mon Jun  5 22:01:46 2017
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Mon, 5 Jun 2017 15:01:46 -0500
Subject: [R] months not working with local language (weekdays does)
In-Reply-To: <f2d230d4-4f3d-48d4-3509-679ad26ecb2c@gmail.com>
References: <CAM-xyZjJmQkfYHb09Or2j1NY7qfE4f4d9nso5XiqK0i=w4GvCA@mail.gmail.com>
 <5935AF25.2080500@sapo.pt> <f2d230d4-4f3d-48d4-3509-679ad26ecb2c@gmail.com>
Message-ID: <CAM-xyZiQnpR7YsHaphdcta96KwesqLJi+iWdJY05rVNdU4AgOQ@mail.gmail.com>

Thank you Duncan and Rui for your time and interest in this issue.

Maybe it is a problem with Windows 7 and Spanish, and not Windows 10.

Let's wait for someone with the same enviroment, before assuming it's a
problem with my PC/configuration.











2017-06-05 14:37 GMT-05:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> For what it's worth, I tried setting my Region | Formats setting to
> Spanish (Peru) in Windows 10 Control Panel, and got Spanish weekday and
> month results.
>
> I believe on Windows we use the Microsoft C strftime function to produce
> these strings, with the %A (for weekday) or %B (for month) formats.  So
> this question probably needs to be addressed to Microsoft.
>
> Duncan Murdoch
>
>
> On 05/06/2017 3:21 PM, Rui Barradas wrote:
>
>> Hello,
>>
>> This doesn't answer the question, but in portuguese it works as expected.
>>
>>  > x <- as.Date("2017-06-05")
>>  > months(x)
>> [1] "junho"
>>  > weekdays(x)
>> [1] "segunda-feira"
>>  > sessionInfo()
>> R version 3.4.0 (2017-04-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=Portuguese_Portugal.1252
>> LC_CTYPE=Portuguese_Portugal.1252
>> [3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C
>>
>> [5] LC_TIME=Portuguese_Portugal.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.0
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 05-06-2017 19:14, Omar Andr? Gonz?les D?az escreveu:
>>
>>> Hi,
>>>
>>> I want to reporte some strange behaviour with the "months" function, from
>>> base R.
>>>
>>> When using "months" to extract months from a date column, I'm getting the
>>> months in english, when I was expecting months in spanish.
>>>
>>> When using "weekdays" to extract days of week from a date column, I'm
>>> getting the the days in spanish (as expected).
>>>
>>>
>>> My understanding is that both work with local language. What may be
>>> happening?
>>>
>>>
>>> My Session Info:
>>>
>>> R version 3.4.0 (2017-04-21)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=Spanish_Peru.1252
>>> [2] LC_CTYPE=Spanish_Peru.1252
>>> [3] LC_MONETARY=Spanish_Peru.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=Spanish_Peru.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets
>>> [6] methods   base
>>>
>>> other attached packages:
>>>   [1] anytime_0.2.2      ggplot2_2.2.1.9000 lubridate_1.6.0
>>>   [4] tidyr_0.6.3        rtweet_0.4.4       dplyr_0.5.0
>>>   [7] Rfacebook_0.6.16   httpuv_1.3.3       rjson_0.2.15
>>> [10] httr_1.2.1
>>>
>>> loaded via a namespace (and not attached):
>>>   [1] Rcpp_0.12.10     magrittr_1.5     devtools_1.13.2
>>>   [4] munsell_0.4.3    colorspace_1.3-2 R6_2.2.0
>>>   [7] rlang_0.1        plyr_1.8.4       stringr_1.2.0
>>> [10] tools_3.4.0      grid_3.4.0       gtable_0.2.0
>>> [13] DBI_0.6-1        git2r_0.18.0     withr_1.0.2
>>> [16] openssl_0.9.6    lazyeval_0.2.0   assertthat_0.2.0
>>> [19] digest_0.6.12    tibble_1.3.1     curl_2.6
>>> [22] memoise_1.1.0    labeling_0.3     stringi_1.1.5
>>> [25] compiler_3.4.0   scales_0.4.1     jsonlite_1.5
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Mon Jun  5 22:46:27 2017
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Mon, 5 Jun 2017 15:46:27 -0500
Subject: [R] months not working with local language (weekdays does)
In-Reply-To: <CAM-xyZiQnpR7YsHaphdcta96KwesqLJi+iWdJY05rVNdU4AgOQ@mail.gmail.com>
References: <CAM-xyZjJmQkfYHb09Or2j1NY7qfE4f4d9nso5XiqK0i=w4GvCA@mail.gmail.com>
 <5935AF25.2080500@sapo.pt> <f2d230d4-4f3d-48d4-3509-679ad26ecb2c@gmail.com>
 <CAM-xyZiQnpR7YsHaphdcta96KwesqLJi+iWdJY05rVNdU4AgOQ@mail.gmail.com>
Message-ID: <CAM-xyZh-Nw2-z1n1w_jb41ezg+iAFY2XEz-4uLzC_363zcRD_w@mail.gmail.com>

After, restarting PC I do get the months in spanish. Sorry for the hassle.

2017-06-05 15:01 GMT-05:00 Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com>
:

> Thank you Duncan and Rui for your time and interest in this issue.
>
> Maybe it is a problem with Windows 7 and Spanish, and not Windows 10.
>
> Let's wait for someone with the same enviroment, before assuming it's a
> problem with my PC/configuration.
>
>
>
>
>
>
>
>
>
>
>
> 2017-06-05 14:37 GMT-05:00 Duncan Murdoch <murdoch.duncan at gmail.com>:
>
>> For what it's worth, I tried setting my Region | Formats setting to
>> Spanish (Peru) in Windows 10 Control Panel, and got Spanish weekday and
>> month results.
>>
>> I believe on Windows we use the Microsoft C strftime function to produce
>> these strings, with the %A (for weekday) or %B (for month) formats.  So
>> this question probably needs to be addressed to Microsoft.
>>
>> Duncan Murdoch
>>
>>
>> On 05/06/2017 3:21 PM, Rui Barradas wrote:
>>
>>> Hello,
>>>
>>> This doesn't answer the question, but in portuguese it works as expected.
>>>
>>>  > x <- as.Date("2017-06-05")
>>>  > months(x)
>>> [1] "junho"
>>>  > weekdays(x)
>>> [1] "segunda-feira"
>>>  > sessionInfo()
>>> R version 3.4.0 (2017-04-21)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=Portuguese_Portugal.1252
>>> LC_CTYPE=Portuguese_Portugal.1252
>>> [3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C
>>>
>>> [5] LC_TIME=Portuguese_Portugal.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.0
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Em 05-06-2017 19:14, Omar Andr? Gonz?les D?az escreveu:
>>>
>>>> Hi,
>>>>
>>>> I want to reporte some strange behaviour with the "months" function,
>>>> from
>>>> base R.
>>>>
>>>> When using "months" to extract months from a date column, I'm getting
>>>> the
>>>> months in english, when I was expecting months in spanish.
>>>>
>>>> When using "weekdays" to extract days of week from a date column, I'm
>>>> getting the the days in spanish (as expected).
>>>>
>>>>
>>>> My understanding is that both work with local language. What may be
>>>> happening?
>>>>
>>>>
>>>> My Session Info:
>>>>
>>>> R version 3.4.0 (2017-04-21)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>>
>>>> Matrix products: default
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=Spanish_Peru.1252
>>>> [2] LC_CTYPE=Spanish_Peru.1252
>>>> [3] LC_MONETARY=Spanish_Peru.1252
>>>> [4] LC_NUMERIC=C
>>>> [5] LC_TIME=Spanish_Peru.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets
>>>> [6] methods   base
>>>>
>>>> other attached packages:
>>>>   [1] anytime_0.2.2      ggplot2_2.2.1.9000 lubridate_1.6.0
>>>>   [4] tidyr_0.6.3        rtweet_0.4.4       dplyr_0.5.0
>>>>   [7] Rfacebook_0.6.16   httpuv_1.3.3       rjson_0.2.15
>>>> [10] httr_1.2.1
>>>>
>>>> loaded via a namespace (and not attached):
>>>>   [1] Rcpp_0.12.10     magrittr_1.5     devtools_1.13.2
>>>>   [4] munsell_0.4.3    colorspace_1.3-2 R6_2.2.0
>>>>   [7] rlang_0.1        plyr_1.8.4       stringr_1.2.0
>>>> [10] tools_3.4.0      grid_3.4.0       gtable_0.2.0
>>>> [13] DBI_0.6-1        git2r_0.18.0     withr_1.0.2
>>>> [16] openssl_0.9.6    lazyeval_0.2.0   assertthat_0.2.0
>>>> [19] digest_0.6.12    tibble_1.3.1     curl_2.6
>>>> [22] memoise_1.1.0    labeling_0.3     stringi_1.1.5
>>>> [25] compiler_3.4.0   scales_0.4.1     jsonlite_1.5
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From tanasa at gmail.com  Tue Jun  6 03:45:53 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Mon, 5 Jun 2017 18:45:53 -0700
Subject: [R] integrating 2 lists and a data frame in R
Message-ID: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>

 Dear all,

please could you advise on the R code I could use in order to do the
following operation :

a. -- I have 2 lists of "genome coordinates" : a list is composed by
numbers that represent genome coordinates;

let's say list N :

n1

n2

n3

n4

and a list M:

m1

m2

m3

m4

m5

2 -- and a data frame C, where for some pairs of coordinates (n,m) from the
lists above, we have a numerical intensity;

for example :

n1; m1; 100

n1; m2; 300

The question would be : what is the most efficient R code I could use in
order to integrate the list N, the list M, and the data frame C, in order
to obtain a DATA FRAME,

-- list N as the columns names
-- list M as the rows names
-- the values in the cells of N * M, corresponding to the numerical values
in the data frame C.

A little example would be :

      n1  n2  n3 n4

      m1  100  -   -   -

      m2  300  -   -   -

      m3   -   -   -   -

      m4   -   -   -   -

      m5   -   -   -   -
I wrote a script in perl, although i would like to do this in R
Many thanks ;)
-- bogdan

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun  6 03:57:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Jun 2017 18:57:36 -0700
Subject: [R] integrating 2 lists and a data frame in R
In-Reply-To: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
References: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
Message-ID: <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>

Reproducible example, please. -- In particular, what exactly does C look ilike?

(You should know this by now).

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 5, 2017 at 6:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>  Dear all,
>
> please could you advise on the R code I could use in order to do the
> following operation :
>
> a. -- I have 2 lists of "genome coordinates" : a list is composed by
> numbers that represent genome coordinates;
>
> let's say list N :
>
> n1
>
> n2
>
> n3
>
> n4
>
> and a list M:
>
> m1
>
> m2
>
> m3
>
> m4
>
> m5
>
> 2 -- and a data frame C, where for some pairs of coordinates (n,m) from the
> lists above, we have a numerical intensity;
>
> for example :
>
> n1; m1; 100
>
> n1; m2; 300
>
> The question would be : what is the most efficient R code I could use in
> order to integrate the list N, the list M, and the data frame C, in order
> to obtain a DATA FRAME,
>
> -- list N as the columns names
> -- list M as the rows names
> -- the values in the cells of N * M, corresponding to the numerical values
> in the data frame C.
>
> A little example would be :
>
>       n1  n2  n3 n4
>
>       m1  100  -   -   -
>
>       m2  300  -   -   -
>
>       m3   -   -   -   -
>
>       m4   -   -   -   -
>
>       m5   -   -   -   -
> I wrote a script in perl, although i would like to do this in R
> Many thanks ;)
> -- bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tanasa at gmail.com  Tue Jun  6 07:51:08 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Mon, 5 Jun 2017 22:51:08 -0700
Subject: [R] integrating 2 lists and a data frame in R
In-Reply-To: <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>
References: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
 <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>
Message-ID: <CA+JEM013i7+cTLqr4XHXGoxunXLKgsrG9pEd5F7=QvpyFb_y5Q@mail.gmail.com>

Dear Bert,

thank you for your response. here it is the piece of R code : given 3 data
frames below ---

N <- data.frame(N=c("n1","n2","n3","n4"))

M <- data.frame(M=c("m1","m2","m3","m4","m5"))

C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"), I=c(100,300,400))

how shall I integrate N, and M, and C in such a way that at the end we have
a data frame with :


   - list N as the columns names
   - list M as the rows names
   - the values in the cells of N * M, corresponding to the numerical
   values in the data frame C.

more precisely, the result shall be :

     n1  n2  n3 n4
m1  100  200   -   -
m2   -   -   -   -
m3   -   -   300   -
m4   -   -   -   -
m5   -   -   -   -

thank you !


On Mon, Jun 5, 2017 at 6:57 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Reproducible example, please. -- In particular, what exactly does C look
> ilike?
>
> (You should know this by now).
>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 5, 2017 at 6:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >  Dear all,
> >
> > please could you advise on the R code I could use in order to do the
> > following operation :
> >
> > a. -- I have 2 lists of "genome coordinates" : a list is composed by
> > numbers that represent genome coordinates;
> >
> > let's say list N :
> >
> > n1
> >
> > n2
> >
> > n3
> >
> > n4
> >
> > and a list M:
> >
> > m1
> >
> > m2
> >
> > m3
> >
> > m4
> >
> > m5
> >
> > 2 -- and a data frame C, where for some pairs of coordinates (n,m) from
> the
> > lists above, we have a numerical intensity;
> >
> > for example :
> >
> > n1; m1; 100
> >
> > n1; m2; 300
> >
> > The question would be : what is the most efficient R code I could use in
> > order to integrate the list N, the list M, and the data frame C, in order
> > to obtain a DATA FRAME,
> >
> > -- list N as the columns names
> > -- list M as the rows names
> > -- the values in the cells of N * M, corresponding to the numerical
> values
> > in the data frame C.
> >
> > A little example would be :
> >
> >       n1  n2  n3 n4
> >
> >       m1  100  -   -   -
> >
> >       m2  300  -   -   -
> >
> >       m3   -   -   -   -
> >
> >       m4   -   -   -   -
> >
> >       m5   -   -   -   -
> > I wrote a script in perl, although i would like to do this in R
> > Many thanks ;)
> > -- bogdan
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Tue Jun  6 08:08:43 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Tue, 6 Jun 2017 08:08:43 +0200
Subject: [R] glm and stepAIC selects too many effects
Message-ID: <2cca6b03-efb3-37be-d145-1931f12849fe@yahoo.fr>

This is a question at the border between stats and r.

When I do a glm with many potential effects, and select a model using 
stepAIC, many independent variables are selected even if there are no 
relationship between dependent variable and the effects (all are random 
numbers).

Do someone has a solution to prevent this effect ? Is it related to 
Bonferoni correction ?

Is there is a ratio of independent vs number of observations that is 
safe for stepAIC ?

Thanks

Marc

Example of code. When 2 independent variables are included, no effect is 
selected, when 11 are included, 7 to 8 are selected.

x <- rnorm(15, 15, 2)
A <- rnorm(15, 20, 5)
B <- rnorm(15, 20, 5)
C <- rnorm(15, 20, 5)
D <- rnorm(15, 20, 5)
E <- rnorm(15, 20, 5)
F <- rnorm(15, 20, 5)
G <- rnorm(15, 20, 5)
H <- rnorm(15, 20, 5)
I <- rnorm(15, 20, 5)
J <- rnorm(15, 20, 5)
K <- rnorm(15, 20, 5)

df <- data.frame(x=x, A=A, B=B, C=C, D=D,
                  E=E, F=F, G=G, H=H, I=I, J=J,
                  K=K)

G1 <- glm(formula = x ~ A + B,
          data=df, family = gaussian(link = "identity"))

g1 <- stepAIC(G1)

summary(g1)

G2 <- glm(formula = x ~ A + B + C + D + E + F + G + H + I + J + K,
          data=df, family = gaussian(link = "identity"))

g2 <- stepAIC(G2)

summary(g2)


From r.turner at auckland.ac.nz  Tue Jun  6 08:25:38 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 6 Jun 2017 18:25:38 +1200
Subject: [R] [FORGED]  glm and stepAIC selects too many effects
In-Reply-To: <2cca6b03-efb3-37be-d145-1931f12849fe@yahoo.fr>
References: <2cca6b03-efb3-37be-d145-1931f12849fe@yahoo.fr>
Message-ID: <64608b54-dba1-6e24-0eac-13a3d4bb7335@auckland.ac.nz>

On 06/06/17 18:08, Marc Girondot via R-help wrote:
> This is a question at the border between stats and r.
> 
> When I do a glm with many potential effects, and select a model using 
> stepAIC, many independent variables are selected even if there are no 
> relationship between dependent variable and the effects (all are random 
> numbers).
> 
> Do someone has a solution to prevent this effect ? Is it related to 
> Bonferoni correction ?
> 
> Is there is a ratio of independent vs number of observations that is 
> safe for stepAIC ?
> 
> Thanks
> 
> Marc
> 
> Example of code. When 2 independent variables are included, no effect is 
> selected, when 11 are included, 7 to 8 are selected.
> 
> x <- rnorm(15, 15, 2)
> A <- rnorm(15, 20, 5)
> B <- rnorm(15, 20, 5)
> C <- rnorm(15, 20, 5)
> D <- rnorm(15, 20, 5)
> E <- rnorm(15, 20, 5)
> F <- rnorm(15, 20, 5)
> G <- rnorm(15, 20, 5)
> H <- rnorm(15, 20, 5)
> I <- rnorm(15, 20, 5)
> J <- rnorm(15, 20, 5)
> K <- rnorm(15, 20, 5)
> 
> df <- data.frame(x=x, A=A, B=B, C=C, D=D,
>                   E=E, F=F, G=G, H=H, I=I, J=J,
>                   K=K)
> 
> G1 <- glm(formula = x ~ A + B,
>           data=df, family = gaussian(link = "identity"))
> 
> g1 <- stepAIC(G1)
> 
> summary(g1)
> 
> G2 <- glm(formula = x ~ A + B + C + D + E + F + G + H + I + J + K,
>           data=df, family = gaussian(link = "identity"))
> 
> g2 <- stepAIC(G2)
> 
> summary(g2)

IMHO there's nothing much that you can do about this.  Trying to get the 
data to select a model is always fraught with peril.

The phenomenon that you have observed has been remarked on before; see
Alan Miller's book "Subset Selection in Regression" (Chapman and Hall, 
1990), page 12 (first paragraph of section 1.4).

However you might find some of Miller's recommendations to be at least a 
*bit* useful.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From p_connolly at slingshot.co.nz  Tue Jun  6 11:27:16 2017
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Tue, 6 Jun 2017 21:27:16 +1200
Subject: [R] Error in readRDS(dest) SOLVED
In-Reply-To: <72e983a8-06e8-2504-0e70-3614de672b83@roswellpark.org>
References: <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>
 <3A3EC3DC-6AE0-4292-A628-F68398154CA2@gmail.com>
 <20170522091022.GC4553@slingshot.co.nz>
 <7b8f4895-b41d-6634-367b-1754bc737c02@roswellpark.org>
 <20170523084722.GD4553@slingshot.co.nz>
 <22820.3316.479418.85208@stat.math.ethz.ch>
 <20170531083810.GF4553@slingshot.co.nz>
 <72e983a8-06e8-2504-0e70-3614de672b83@roswellpark.org>
Message-ID: <20170606092716.GG4553@slingshot.co.nz>

On Wed, 31-May-2017 at 10:05AM -0400, Martin Morgan wrote:

|> On 05/31/2017 04:38 AM, Patrick Connolly wrote:

|> >When I check out those directories in a terminal, there's a big diffrence:
|> >
|> >With R-3.4.0
|> >~ > ll /tmp/RtmpFUhtpY
|> >total 4
|> >drwxr-xr-x 2 hrapgc hrapgc 4096 May 31 10:45 downloaded_packages/
|> >-rw-r--r-- 1 hrapgc hrapgc    0 May 31 10:56 repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds
|> >
|> >
|> 
|> The file
|> repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds was
|> likely created earlier in your R session. Likely the download a few
|> lines down
|> 
|>                     download.file(url = paste0(repos, "/PACKAGES.rds"),
|>                                   destfile = dest, method = method,
|>                                   cacheOK = FALSE, quiet = TRUE,
|> mode = "wb")
|> 
|> 'succeeded' but created a zero-length file.
|> 
|> You could try to troubleshoot this with something like the
|> following, downloading to a temporary location
|> 
|>   dest = tempfile()
|>   url = "http://cran.stat.auckland.ac.nz/src/contrib/PACKAGES.rds"
|>   download.file(url, dest)
|>   file.size(dest)

That works fine using R-3.3.3 but with R-3.4.0, this happens:

>  download.file(url, dest)
trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/PACKAGES.rds'
Error in download.file(url, dest) : 
  cannot open URL 'http://cran.stat.auckland.ac.nz/src/contrib/PACKAGES.rds'
In addition: Warning message:
In download.file(url, dest) :
  URL 'http://cran.stat.auckland.ac.nz/src/contrib/PACKAGES.rds': status was 'Couldn't connect to server'
> 

Which seems to indicate that something else is preventing connexion to
the server.  Is there something that's changed with the way proxy
servers are used? was the question that led me to check out the
changes in R 3.4.0 which mentions visible changes to download.file().
So I tried method = "internal" which worked!

So making the same setting to the call to install.packages() fixed my
problem.


Thanks for all the suggestions which led me to the solution.  I just
wonder if there could be a more informative error message.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From drjimlemon at gmail.com  Tue Jun  6 13:01:58 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 6 Jun 2017 21:01:58 +1000
Subject: [R] integrating 2 lists and a data frame in R
In-Reply-To: <CA+JEM013i7+cTLqr4XHXGoxunXLKgsrG9pEd5F7=QvpyFb_y5Q@mail.gmail.com>
References: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
 <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>
 <CA+JEM013i7+cTLqr4XHXGoxunXLKgsrG9pEd5F7=QvpyFb_y5Q@mail.gmail.com>
Message-ID: <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>

Hi Bogdan,
Kinda messy, but:

N <- data.frame(N=c("n1","n2","n3","n4"))
M <- data.frame(M=c("m1","m2","m3","m4","m5"))
C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"), I=c(100,300,400))
MN<-as.data.frame(matrix(NA,nrow=length(N[,1]),ncol=length(M[,1])))
names(MN)<-M[,1]
rownames(MN)<-N[,1]
C[,1]<-as.character(C[,1])
C[,2]<-as.character(C[,2])
for(row in 1:dim(C)[1]) MN[C[row,1],C[row,2]]<-C[row,3]

Jim

On Tue, Jun 6, 2017 at 3:51 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear Bert,
>
> thank you for your response. here it is the piece of R code : given 3 data
> frames below ---
>
> N <- data.frame(N=c("n1","n2","n3","n4"))
>
> M <- data.frame(M=c("m1","m2","m3","m4","m5"))
>
> C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"), I=c(100,300,400))
>
> how shall I integrate N, and M, and C in such a way that at the end we have
> a data frame with :
>
>
>    - list N as the columns names
>    - list M as the rows names
>    - the values in the cells of N * M, corresponding to the numerical
>    values in the data frame C.
>
> more precisely, the result shall be :
>
>      n1  n2  n3 n4
> m1  100  200   -   -
> m2   -   -   -   -
> m3   -   -   300   -
> m4   -   -   -   -
> m5   -   -   -   -
>
> thank you !
>
>
> On Mon, Jun 5, 2017 at 6:57 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> Reproducible example, please. -- In particular, what exactly does C look
>> ilike?
>>
>> (You should know this by now).
>>
>> -- Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Jun 5, 2017 at 6:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>> >  Dear all,
>> >
>> > please could you advise on the R code I could use in order to do the
>> > following operation :
>> >
>> > a. -- I have 2 lists of "genome coordinates" : a list is composed by
>> > numbers that represent genome coordinates;
>> >
>> > let's say list N :
>> >
>> > n1
>> >
>> > n2
>> >
>> > n3
>> >
>> > n4
>> >
>> > and a list M:
>> >
>> > m1
>> >
>> > m2
>> >
>> > m3
>> >
>> > m4
>> >
>> > m5
>> >
>> > 2 -- and a data frame C, where for some pairs of coordinates (n,m) from
>> the
>> > lists above, we have a numerical intensity;
>> >
>> > for example :
>> >
>> > n1; m1; 100
>> >
>> > n1; m2; 300
>> >
>> > The question would be : what is the most efficient R code I could use in
>> > order to integrate the list N, the list M, and the data frame C, in order
>> > to obtain a DATA FRAME,
>> >
>> > -- list N as the columns names
>> > -- list M as the rows names
>> > -- the values in the cells of N * M, corresponding to the numerical
>> values
>> > in the data frame C.
>> >
>> > A little example would be :
>> >
>> >       n1  n2  n3 n4
>> >
>> >       m1  100  -   -   -
>> >
>> >       m2  300  -   -   -
>> >
>> >       m3   -   -   -   -
>> >
>> >       m4   -   -   -   -
>> >
>> >       m5   -   -   -   -
>> > I wrote a script in perl, although i would like to do this in R
>> > Many thanks ;)
>> > -- bogdan
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ravi.varadhan at jhu.edu  Tue Jun  6 16:16:02 2017
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 6 Jun 2017 14:16:02 +0000
Subject: [R] Subject:  glm and stepAIC selects too many effects
Message-ID: <1496758539469.46773@jhu.edu>

If AIC is giving you a model that is too large, then use BIC (log(n) as the penalty for adding a term in the model).  This will yield a more parsimonious model.  Now, if you ask me which is the better option, I have to refer you to the huge literature on model selection.

Best,

Ravi

	[[alternative HTML version deleted]]


From tanasa at gmail.com  Tue Jun  6 16:30:59 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Tue, 6 Jun 2017 07:30:59 -0700
Subject: [R] integrating 2 lists and a data frame in R
In-Reply-To: <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>
References: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
 <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>
 <CA+JEM013i7+cTLqr4XHXGoxunXLKgsrG9pEd5F7=QvpyFb_y5Q@mail.gmail.com>
 <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>
Message-ID: <CA+JEM00vjikVamUbcnBCRvJyNPjLcQ61X4Jmg4xf0BHViaerVw@mail.gmail.com>

Thank you Jim !

On Tue, Jun 6, 2017 at 4:01 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Bogdan,
> Kinda messy, but:
>
> N <- data.frame(N=c("n1","n2","n3","n4"))
> M <- data.frame(M=c("m1","m2","m3","m4","m5"))
> C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
> I=c(100,300,400))
> MN<-as.data.frame(matrix(NA,nrow=length(N[,1]),ncol=length(M[,1])))
> names(MN)<-M[,1]
> rownames(MN)<-N[,1]
> C[,1]<-as.character(C[,1])
> C[,2]<-as.character(C[,2])
> for(row in 1:dim(C)[1]) MN[C[row,1],C[row,2]]<-C[row,3]
>
> Jim
>
> On Tue, Jun 6, 2017 at 3:51 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > Dear Bert,
> >
> > thank you for your response. here it is the piece of R code : given 3
> data
> > frames below ---
> >
> > N <- data.frame(N=c("n1","n2","n3","n4"))
> >
> > M <- data.frame(M=c("m1","m2","m3","m4","m5"))
> >
> > C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
> I=c(100,300,400))
> >
> > how shall I integrate N, and M, and C in such a way that at the end we
> have
> > a data frame with :
> >
> >
> >    - list N as the columns names
> >    - list M as the rows names
> >    - the values in the cells of N * M, corresponding to the numerical
> >    values in the data frame C.
> >
> > more precisely, the result shall be :
> >
> >      n1  n2  n3 n4
> > m1  100  200   -   -
> > m2   -   -   -   -
> > m3   -   -   300   -
> > m4   -   -   -   -
> > m5   -   -   -   -
> >
> > thank you !
> >
> >
> > On Mon, Jun 5, 2017 at 6:57 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> >> Reproducible example, please. -- In particular, what exactly does C look
> >> ilike?
> >>
> >> (You should know this by now).
> >>
> >> -- Bert
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Mon, Jun 5, 2017 at 6:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >> >  Dear all,
> >> >
> >> > please could you advise on the R code I could use in order to do the
> >> > following operation :
> >> >
> >> > a. -- I have 2 lists of "genome coordinates" : a list is composed by
> >> > numbers that represent genome coordinates;
> >> >
> >> > let's say list N :
> >> >
> >> > n1
> >> >
> >> > n2
> >> >
> >> > n3
> >> >
> >> > n4
> >> >
> >> > and a list M:
> >> >
> >> > m1
> >> >
> >> > m2
> >> >
> >> > m3
> >> >
> >> > m4
> >> >
> >> > m5
> >> >
> >> > 2 -- and a data frame C, where for some pairs of coordinates (n,m)
> from
> >> the
> >> > lists above, we have a numerical intensity;
> >> >
> >> > for example :
> >> >
> >> > n1; m1; 100
> >> >
> >> > n1; m2; 300
> >> >
> >> > The question would be : what is the most efficient R code I could use
> in
> >> > order to integrate the list N, the list M, and the data frame C, in
> order
> >> > to obtain a DATA FRAME,
> >> >
> >> > -- list N as the columns names
> >> > -- list M as the rows names
> >> > -- the values in the cells of N * M, corresponding to the numerical
> >> values
> >> > in the data frame C.
> >> >
> >> > A little example would be :
> >> >
> >> >       n1  n2  n3 n4
> >> >
> >> >       m1  100  -   -   -
> >> >
> >> >       m2  300  -   -   -
> >> >
> >> >       m3   -   -   -   -
> >> >
> >> >       m4   -   -   -   -
> >> >
> >> >       m5   -   -   -   -
> >> > I wrote a script in perl, although i would like to do this in R
> >> > Many thanks ;)
> >> > -- bogdan
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Jun  6 16:34:43 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 6 Jun 2017 14:34:43 +0000
Subject: [R] integrating 2 lists and a data frame in R
In-Reply-To: <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>
References: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
 <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>
 <CA+JEM013i7+cTLqr4XHXGoxunXLKgsrG9pEd5F7=QvpyFb_y5Q@mail.gmail.com>
 <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>
Message-ID: <352cc08047fb4bee8b21f6edf86f5b64@exch-2p-mbx-w2.ads.tamu.edu>

Here's another approach:

N <- data.frame(N=c("n1","n2","n3","n4"))
M <- data.frame(M=c("m1","m2","m3","m4","m5"))
C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"), I=c(100,300,400))

# Rebuild the factors using M and N
C$m <- factor(as.character(C$m), levels=levels(M$M))
C$n <- factor(as.character(C$n), levels=levels(N$N))
MN <- xtabs(I~m+n, C)
print(MN, zero.print="-")
#     n
# m     n1  n2  n3 n4
#   m1 100 300   -  -
#   m2   -   -   -  -
#   m3   -   - 400  -
#   m4   -   -   -  -
#   m5   -   -   -  -

class(MN)
# [1] "xtabs" "table"
# MN is a table. If you want a data.frame
MN <- as.data.frame.matrix(MN)
class(MN)
# [1] "data.frame"

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Tuesday, June 6, 2017 6:02 AM
To: Bogdan Tanasa <tanasa at gmail.com>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] integrating 2 lists and a data frame in R

Hi Bogdan,
Kinda messy, but:

N <- data.frame(N=c("n1","n2","n3","n4"))
M <- data.frame(M=c("m1","m2","m3","m4","m5"))
C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"), I=c(100,300,400))
MN<-as.data.frame(matrix(NA,nrow=length(N[,1]),ncol=length(M[,1])))
names(MN)<-M[,1]
rownames(MN)<-N[,1]
C[,1]<-as.character(C[,1])
C[,2]<-as.character(C[,2])
for(row in 1:dim(C)[1]) MN[C[row,1],C[row,2]]<-C[row,3]

Jim

On Tue, Jun 6, 2017 at 3:51 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear Bert,
>
> thank you for your response. here it is the piece of R code : given 3 data
> frames below ---
>
> N <- data.frame(N=c("n1","n2","n3","n4"))
>
> M <- data.frame(M=c("m1","m2","m3","m4","m5"))
>
> C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"), I=c(100,300,400))
>
> how shall I integrate N, and M, and C in such a way that at the end we have
> a data frame with :
>
>
>    - list N as the columns names
>    - list M as the rows names
>    - the values in the cells of N * M, corresponding to the numerical
>    values in the data frame C.
>
> more precisely, the result shall be :
>
>      n1  n2  n3 n4
> m1  100  200   -   -
> m2   -   -   -   -
> m3   -   -   300   -
> m4   -   -   -   -
> m5   -   -   -   -
>
> thank you !
>
>
> On Mon, Jun 5, 2017 at 6:57 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> Reproducible example, please. -- In particular, what exactly does C look
>> ilike?
>>
>> (You should know this by now).
>>
>> -- Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Jun 5, 2017 at 6:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>> >  Dear all,
>> >
>> > please could you advise on the R code I could use in order to do the
>> > following operation :
>> >
>> > a. -- I have 2 lists of "genome coordinates" : a list is composed by
>> > numbers that represent genome coordinates;
>> >
>> > let's say list N :
>> >
>> > n1
>> >
>> > n2
>> >
>> > n3
>> >
>> > n4
>> >
>> > and a list M:
>> >
>> > m1
>> >
>> > m2
>> >
>> > m3
>> >
>> > m4
>> >
>> > m5
>> >
>> > 2 -- and a data frame C, where for some pairs of coordinates (n,m) from
>> the
>> > lists above, we have a numerical intensity;
>> >
>> > for example :
>> >
>> > n1; m1; 100
>> >
>> > n1; m2; 300
>> >
>> > The question would be : what is the most efficient R code I could use in
>> > order to integrate the list N, the list M, and the data frame C, in order
>> > to obtain a DATA FRAME,
>> >
>> > -- list N as the columns names
>> > -- list M as the rows names
>> > -- the values in the cells of N * M, corresponding to the numerical
>> values
>> > in the data frame C.
>> >
>> > A little example would be :
>> >
>> >       n1  n2  n3 n4
>> >
>> >       m1  100  -   -   -
>> >
>> >       m2  300  -   -   -
>> >
>> >       m3   -   -   -   -
>> >
>> >       m4   -   -   -   -
>> >
>> >       m5   -   -   -   -
>> > I wrote a script in perl, although i would like to do this in R
>> > Many thanks ;)
>> > -- bogdan
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tanasa at gmail.com  Tue Jun  6 16:41:44 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Tue, 6 Jun 2017 07:41:44 -0700
Subject: [R] integrating 2 lists and a data frame in R
In-Reply-To: <352cc08047fb4bee8b21f6edf86f5b64@exch-2p-mbx-w2.ads.tamu.edu>
References: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
 <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>
 <CA+JEM013i7+cTLqr4XHXGoxunXLKgsrG9pEd5F7=QvpyFb_y5Q@mail.gmail.com>
 <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>
 <352cc08047fb4bee8b21f6edf86f5b64@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CA+JEM03cjbA7iQ8L+pstTTO6RUMrqtXA7r5+Fct8NruuzA9hvw@mail.gmail.com>

Thank you David for the code, as I am learning about xtabs operation. That
works great too ;)

On Tue, Jun 6, 2017 at 7:34 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> Here's another approach:
>
> N <- data.frame(N=c("n1","n2","n3","n4"))
> M <- data.frame(M=c("m1","m2","m3","m4","m5"))
> C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
> I=c(100,300,400))
>
> # Rebuild the factors using M and N
> C$m <- factor(as.character(C$m), levels=levels(M$M))
> C$n <- factor(as.character(C$n), levels=levels(N$N))
> MN <- xtabs(I~m+n, C)
> print(MN, zero.print="-")
> #     n
> # m     n1  n2  n3 n4
> #   m1 100 300   -  -
> #   m2   -   -   -  -
> #   m3   -   - 400  -
> #   m4   -   -   -  -
> #   m5   -   -   -  -
>
> class(MN)
> # [1] "xtabs" "table"
> # MN is a table. If you want a data.frame
> MN <- as.data.frame.matrix(MN)
> class(MN)
> # [1] "data.frame"
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Tuesday, June 6, 2017 6:02 AM
> To: Bogdan Tanasa <tanasa at gmail.com>; r-help mailing list <
> r-help at r-project.org>
> Subject: Re: [R] integrating 2 lists and a data frame in R
>
> Hi Bogdan,
> Kinda messy, but:
>
> N <- data.frame(N=c("n1","n2","n3","n4"))
> M <- data.frame(M=c("m1","m2","m3","m4","m5"))
> C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
> I=c(100,300,400))
> MN<-as.data.frame(matrix(NA,nrow=length(N[,1]),ncol=length(M[,1])))
> names(MN)<-M[,1]
> rownames(MN)<-N[,1]
> C[,1]<-as.character(C[,1])
> C[,2]<-as.character(C[,2])
> for(row in 1:dim(C)[1]) MN[C[row,1],C[row,2]]<-C[row,3]
>
> Jim
>
> On Tue, Jun 6, 2017 at 3:51 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > Dear Bert,
> >
> > thank you for your response. here it is the piece of R code : given 3
> data
> > frames below ---
> >
> > N <- data.frame(N=c("n1","n2","n3","n4"))
> >
> > M <- data.frame(M=c("m1","m2","m3","m4","m5"))
> >
> > C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
> I=c(100,300,400))
> >
> > how shall I integrate N, and M, and C in such a way that at the end we
> have
> > a data frame with :
> >
> >
> >    - list N as the columns names
> >    - list M as the rows names
> >    - the values in the cells of N * M, corresponding to the numerical
> >    values in the data frame C.
> >
> > more precisely, the result shall be :
> >
> >      n1  n2  n3 n4
> > m1  100  200   -   -
> > m2   -   -   -   -
> > m3   -   -   300   -
> > m4   -   -   -   -
> > m5   -   -   -   -
> >
> > thank you !
> >
> >
> > On Mon, Jun 5, 2017 at 6:57 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> >> Reproducible example, please. -- In particular, what exactly does C look
> >> ilike?
> >>
> >> (You should know this by now).
> >>
> >> -- Bert
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Mon, Jun 5, 2017 at 6:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >> >  Dear all,
> >> >
> >> > please could you advise on the R code I could use in order to do the
> >> > following operation :
> >> >
> >> > a. -- I have 2 lists of "genome coordinates" : a list is composed by
> >> > numbers that represent genome coordinates;
> >> >
> >> > let's say list N :
> >> >
> >> > n1
> >> >
> >> > n2
> >> >
> >> > n3
> >> >
> >> > n4
> >> >
> >> > and a list M:
> >> >
> >> > m1
> >> >
> >> > m2
> >> >
> >> > m3
> >> >
> >> > m4
> >> >
> >> > m5
> >> >
> >> > 2 -- and a data frame C, where for some pairs of coordinates (n,m)
> from
> >> the
> >> > lists above, we have a numerical intensity;
> >> >
> >> > for example :
> >> >
> >> > n1; m1; 100
> >> >
> >> > n1; m2; 300
> >> >
> >> > The question would be : what is the most efficient R code I could use
> in
> >> > order to integrate the list N, the list M, and the data frame C, in
> order
> >> > to obtain a DATA FRAME,
> >> >
> >> > -- list N as the columns names
> >> > -- list M as the rows names
> >> > -- the values in the cells of N * M, corresponding to the numerical
> >> values
> >> > in the data frame C.
> >> >
> >> > A little example would be :
> >> >
> >> >       n1  n2  n3 n4
> >> >
> >> >       m1  100  -   -   -
> >> >
> >> >       m2  300  -   -   -
> >> >
> >> >       m3   -   -   -   -
> >> >
> >> >       m4   -   -   -   -
> >> >
> >> >       m5   -   -   -   -
> >> > I wrote a script in perl, although i would like to do this in R
> >> > Many thanks ;)
> >> > -- bogdan
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Jun  6 16:44:34 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 6 Jun 2017 07:44:34 -0700
Subject: [R] integrating 2 lists and a data frame in R
In-Reply-To: <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>
References: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
 <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>
 <CA+JEM013i7+cTLqr4XHXGoxunXLKgsrG9pEd5F7=QvpyFb_y5Q@mail.gmail.com>
 <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>
Message-ID: <1998008C-D9AC-4A19-893C-CAF6BBE0B300@comcast.net>


> On Jun 6, 2017, at 4:01 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Bogdan,
> Kinda messy, but:
> 
> N <- data.frame(N=c("n1","n2","n3","n4"))
> M <- data.frame(M=c("m1","m2","m3","m4","m5"))
> C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"), I=c(100,300,400))
> MN<-as.data.frame(matrix(NA,nrow=length(N[,1]),ncol=length(M[,1])))
> names(MN)<-M[,1]
> rownames(MN)<-N[,1]
> C[,1]<-as.character(C[,1])
> C[,2]<-as.character(C[,2])
> for(row in 1:dim(C)[1]) MN[C[row,1],C[row,2]]<-C[row,3]

`xtabs` offers another route:

C$m <- factor(C$m, levels=M$M)
C$n <- factor(C$n, levels=N$N)

Option 1:  Zeroes in the empty positions:
> (X <- xtabs(I ~ m+n , C, addNA=TRUE))
    n
m     n1  n2  n3  n4
  m1 100 300   0   0
  m2   0   0   0   0
  m3   0   0 400   0
  m4   0   0   0   0
  m5   0   0   0   0

Option 2: Sparase matrix
> (X <- xtabs(I ~ m+n , C, sparse=TRUE))
5 x 4 sparse Matrix of class "dgCMatrix"
    n
m     n1  n2  n3 n4
  m1 100 300   .  .
  m2   .   .   .  .
  m3   .   . 400  .
  m4   .   .   .  .
  m5   .   .   .  .

I wasn't sure if the sparse reuslts of xtabs would make a distinction between 0 and NA, but happily it does:

> C <- data.frame(n=c("n1","n2","n3", "n3", "n4"), m=c("m1","m1","m3", "m4", "m5"), I=c(100,300,400, NA, 0))
> C
   n  m   I
1 n1 m1 100
2 n2 m1 300
3 n3 m3 400
4 n3 m4  NA
5 n4 m5   0
> (X <- xtabs(I ~ m+n , C, sparse=TRUE))
4 x 4 sparse Matrix of class "dgCMatrix"
    n
m     n1  n2  n3 n4
  m1 100 300   .  .
  m3   .   . 400  .
  m4   .   .   .  .
  m5   .   .   .  0

(In the example I forgot to repeat the lines that augmented the factor levels so m2 is not seen.

-- 
Davod
> 
> 
> Jim
> 
> On Tue, Jun 6, 2017 at 3:51 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>> Dear Bert,
>> 
>> thank you for your response. here it is the piece of R code : given 3 data
>> frames below ---
>> 
>> N <- data.frame(N=c("n1","n2","n3","n4"))
>> 
>> M <- data.frame(M=c("m1","m2","m3","m4","m5"))
>> 
>> C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"), I=c(100,300,400))
>> 
>> how shall I integrate N, and M, and C in such a way that at the end we have
>> a data frame with :
>> 
>> 
>>   - list N as the columns names
>>   - list M as the rows names
>>   - the values in the cells of N * M, corresponding to the numerical
>>   values in the data frame C.
>> 
>> more precisely, the result shall be :
>> 
>>     n1  n2  n3 n4
>> m1  100  200   -   -
>> m2   -   -   -   -
>> m3   -   -   300   -
>> m4   -   -   -   -
>> m5   -   -   -   -
>> 
>> thank you !
>> 
>> 
>> On Mon, Jun 5, 2017 at 6:57 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 
>>> Reproducible example, please. -- In particular, what exactly does C look
>>> ilike?
>>> 
>>> (You should know this by now).
>>> 
>>> -- Bert
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Mon, Jun 5, 2017 at 6:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>>>> Dear all,
>>>> 
>>>> please could you advise on the R code I could use in order to do the
>>>> following operation :
>>>> 
>>>> a. -- I have 2 lists of "genome coordinates" : a list is composed by
>>>> numbers that represent genome coordinates;
>>>> 
>>>> let's say list N :
>>>> 
>>>> n1
>>>> 
>>>> n2
>>>> 
>>>> n3
>>>> 
>>>> n4
>>>> 
>>>> and a list M:
>>>> 
>>>> m1
>>>> 
>>>> m2
>>>> 
>>>> m3
>>>> 
>>>> m4
>>>> 
>>>> m5
>>>> 
>>>> 2 -- and a data frame C, where for some pairs of coordinates (n,m) from
>>> the
>>>> lists above, we have a numerical intensity;
>>>> 
>>>> for example :
>>>> 
>>>> n1; m1; 100
>>>> 
>>>> n1; m2; 300
>>>> 
>>>> The question would be : what is the most efficient R code I could use in
>>>> order to integrate the list N, the list M, and the data frame C, in order
>>>> to obtain a DATA FRAME,
>>>> 
>>>> -- list N as the columns names
>>>> -- list M as the rows names
>>>> -- the values in the cells of N * M, corresponding to the numerical
>>> values
>>>> in the data frame C.
>>>> 
>>>> A little example would be :
>>>> 
>>>>      n1  n2  n3 n4
>>>> 
>>>>      m1  100  -   -   -
>>>> 
>>>>      m2  300  -   -   -
>>>> 
>>>>      m3   -   -   -   -
>>>> 
>>>>      m4   -   -   -   -
>>>> 
>>>>      m5   -   -   -   -
>>>> I wrote a script in perl, although i would like to do this in R
>>>> Many thanks ;)
>>>> -- bogdan
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tanasa at gmail.com  Tue Jun  6 16:46:42 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Tue, 6 Jun 2017 07:46:42 -0700
Subject: [R] integrating 2 lists and a data frame in R
In-Reply-To: <1998008C-D9AC-4A19-893C-CAF6BBE0B300@comcast.net>
References: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
 <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>
 <CA+JEM013i7+cTLqr4XHXGoxunXLKgsrG9pEd5F7=QvpyFb_y5Q@mail.gmail.com>
 <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>
 <1998008C-D9AC-4A19-893C-CAF6BBE0B300@comcast.net>
Message-ID: <CA+JEM03WwX-O2knOzAdU6EC_bheBxRUmC=h_yLawTX859DRpRQ@mail.gmail.com>

Thank you David. Using xtabs operation simplifies the code very much, many
thanks ;)

On Tue, Jun 6, 2017 at 7:44 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Jun 6, 2017, at 4:01 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Bogdan,
> > Kinda messy, but:
> >
> > N <- data.frame(N=c("n1","n2","n3","n4"))
> > M <- data.frame(M=c("m1","m2","m3","m4","m5"))
> > C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
> I=c(100,300,400))
> > MN<-as.data.frame(matrix(NA,nrow=length(N[,1]),ncol=length(M[,1])))
> > names(MN)<-M[,1]
> > rownames(MN)<-N[,1]
> > C[,1]<-as.character(C[,1])
> > C[,2]<-as.character(C[,2])
> > for(row in 1:dim(C)[1]) MN[C[row,1],C[row,2]]<-C[row,3]
>
> `xtabs` offers another route:
>
> C$m <- factor(C$m, levels=M$M)
> C$n <- factor(C$n, levels=N$N)
>
> Option 1:  Zeroes in the empty positions:
> > (X <- xtabs(I ~ m+n , C, addNA=TRUE))
>     n
> m     n1  n2  n3  n4
>   m1 100 300   0   0
>   m2   0   0   0   0
>   m3   0   0 400   0
>   m4   0   0   0   0
>   m5   0   0   0   0
>
> Option 2: Sparase matrix
> > (X <- xtabs(I ~ m+n , C, sparse=TRUE))
> 5 x 4 sparse Matrix of class "dgCMatrix"
>     n
> m     n1  n2  n3 n4
>   m1 100 300   .  .
>   m2   .   .   .  .
>   m3   .   . 400  .
>   m4   .   .   .  .
>   m5   .   .   .  .
>
> I wasn't sure if the sparse reuslts of xtabs would make a distinction
> between 0 and NA, but happily it does:
>
> > C <- data.frame(n=c("n1","n2","n3", "n3", "n4"), m=c("m1","m1","m3",
> "m4", "m5"), I=c(100,300,400, NA, 0))
> > C
>    n  m   I
> 1 n1 m1 100
> 2 n2 m1 300
> 3 n3 m3 400
> 4 n3 m4  NA
> 5 n4 m5   0
> > (X <- xtabs(I ~ m+n , C, sparse=TRUE))
> 4 x 4 sparse Matrix of class "dgCMatrix"
>     n
> m     n1  n2  n3 n4
>   m1 100 300   .  .
>   m3   .   . 400  .
>   m4   .   .   .  .
>   m5   .   .   .  0
>
> (In the example I forgot to repeat the lines that augmented the factor
> levels so m2 is not seen.
>
> --
> Davod
> >
> >
> > Jim
> >
> > On Tue, Jun 6, 2017 at 3:51 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >> Dear Bert,
> >>
> >> thank you for your response. here it is the piece of R code : given 3
> data
> >> frames below ---
> >>
> >> N <- data.frame(N=c("n1","n2","n3","n4"))
> >>
> >> M <- data.frame(M=c("m1","m2","m3","m4","m5"))
> >>
> >> C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
> I=c(100,300,400))
> >>
> >> how shall I integrate N, and M, and C in such a way that at the end we
> have
> >> a data frame with :
> >>
> >>
> >>   - list N as the columns names
> >>   - list M as the rows names
> >>   - the values in the cells of N * M, corresponding to the numerical
> >>   values in the data frame C.
> >>
> >> more precisely, the result shall be :
> >>
> >>     n1  n2  n3 n4
> >> m1  100  200   -   -
> >> m2   -   -   -   -
> >> m3   -   -   300   -
> >> m4   -   -   -   -
> >> m5   -   -   -   -
> >>
> >> thank you !
> >>
> >>
> >> On Mon, Jun 5, 2017 at 6:57 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>
> >>> Reproducible example, please. -- In particular, what exactly does C
> look
> >>> ilike?
> >>>
> >>> (You should know this by now).
> >>>
> >>> -- Bert
> >>> Bert Gunter
> >>>
> >>> "The trouble with having an open mind is that people keep coming along
> >>> and sticking things into it."
> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>
> >>>
> >>> On Mon, Jun 5, 2017 at 6:45 PM, Bogdan Tanasa <tanasa at gmail.com>
> wrote:
> >>>> Dear all,
> >>>>
> >>>> please could you advise on the R code I could use in order to do the
> >>>> following operation :
> >>>>
> >>>> a. -- I have 2 lists of "genome coordinates" : a list is composed by
> >>>> numbers that represent genome coordinates;
> >>>>
> >>>> let's say list N :
> >>>>
> >>>> n1
> >>>>
> >>>> n2
> >>>>
> >>>> n3
> >>>>
> >>>> n4
> >>>>
> >>>> and a list M:
> >>>>
> >>>> m1
> >>>>
> >>>> m2
> >>>>
> >>>> m3
> >>>>
> >>>> m4
> >>>>
> >>>> m5
> >>>>
> >>>> 2 -- and a data frame C, where for some pairs of coordinates (n,m)
> from
> >>> the
> >>>> lists above, we have a numerical intensity;
> >>>>
> >>>> for example :
> >>>>
> >>>> n1; m1; 100
> >>>>
> >>>> n1; m2; 300
> >>>>
> >>>> The question would be : what is the most efficient R code I could use
> in
> >>>> order to integrate the list N, the list M, and the data frame C, in
> order
> >>>> to obtain a DATA FRAME,
> >>>>
> >>>> -- list N as the columns names
> >>>> -- list M as the rows names
> >>>> -- the values in the cells of N * M, corresponding to the numerical
> >>> values
> >>>> in the data frame C.
> >>>>
> >>>> A little example would be :
> >>>>
> >>>>      n1  n2  n3 n4
> >>>>
> >>>>      m1  100  -   -   -
> >>>>
> >>>>      m2  300  -   -   -
> >>>>
> >>>>      m3   -   -   -   -
> >>>>
> >>>>      m4   -   -   -   -
> >>>>
> >>>>      m5   -   -   -   -
> >>>> I wrote a script in perl, although i would like to do this in R
> >>>> Many thanks ;)
> >>>> -- bogdan
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/
> >>> posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From HDoran at air.org  Tue Jun  6 17:01:11 2017
From: HDoran at air.org (Doran, Harold)
Date: Tue, 6 Jun 2017 15:01:11 +0000
Subject: [R] Force argument to have quotes
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D8DC00@DC1VEX10MB01.air.org>

I am writing a program where non-technical R users will read in a config file and the config file will then parse the arguments found within the config and pass them to respective functions. I'm having trouble (efficiently) writing a piece of code to retain quotation marks around the argument which requires it as input, as found in the example function below, myFuncton1.

Below is a minimal, reproducible example of the issue with comments.

### This is a sample structure of the configuration file

scoreConfig <- structure(list(Function = c("myFunction1", "myFunction1", "myFunction1", 
"myFunction2", "myFunction2"), Argument = c("arg1", "arg2", "arg3", 
"arg1", "arg2"), Value = c("5", "10", "Hello", "5", "10"), Class = c("numeric", 
"numeric", "character", "numeric", "numeric")), .Names = c("Function", 
"Argument", "Value", "Class"), class = "data.frame", row.names = c(NA, 
-5L))

### Two sample functions, once of which requires a string
myFunction1 <- function(arg1, arg2, arg3 = c('Hello', 'Goodbye')){
	arg3 <- match.arg(arg3)
	result <- arg1 + arg2
	cat(arg3, result, '\n')
	}
	
	
myFunction2 <- function(arg1, arg2){
	result <- arg1 * arg2
	result
	}


### Working Example. 
### myFunction2 works no problem
myFunction2Vals <- subset(scoreConfig, Function == 'myFunction2')
myOptions <- with(myFunction2Vals, paste(Argument, Value, sep = '=', collapse = ','))
eval(parse(text = paste( "myFunction2(", myOptions, ")" )))


### myFunction1 fails 
myFunction1Vals <- subset(scoreConfig, Function == 'myFunction1')
myOptions <- with(myFunction1Vals, paste(Argument, Value, sep = '=', collapse = ','))
eval(parse(text = paste( "myFunction1(", myOptions, ")" )))

### What I want is simply
myFunction1(arg1 = 1, arg2 = 2, arg3 = 'Hello')

I'm curious if someone has a perspective on the most efficient way to automate this by using information provided in the 'Value" column, so perhaps conditional on that value it could wrap the name in quotes.

I admit to running into a limit and am tapping out so to speak on the right way to do this.

Thanks for any advice
Harold


From bgunter.4567 at gmail.com  Tue Jun  6 17:19:05 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Jun 2017 08:19:05 -0700
Subject: [R] integrating 2 lists and a data frame in R
In-Reply-To: <CA+JEM03WwX-O2knOzAdU6EC_bheBxRUmC=h_yLawTX859DRpRQ@mail.gmail.com>
References: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
 <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>
 <CA+JEM013i7+cTLqr4XHXGoxunXLKgsrG9pEd5F7=QvpyFb_y5Q@mail.gmail.com>
 <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>
 <1998008C-D9AC-4A19-893C-CAF6BBE0B300@comcast.net>
 <CA+JEM03WwX-O2knOzAdU6EC_bheBxRUmC=h_yLawTX859DRpRQ@mail.gmail.com>
Message-ID: <CAGxFJbQ_ppioySiOOacGxv0r+KzwfNNWxk35kQY3CbvhLBKpVg@mail.gmail.com>

Simple matrix indexing suffices without any fancier functionality.

## First convert M and N to character vectors -- which they should
have been in the first place!

M <- sort(as.character(M[,1]))
N <-  sort(as.character(N[,1]))

## This could be a one-liner, but I'll split it up for clarity.

res <-matrix(NA, length(M),length(N),dimnames = list(M,N))

res[as.matrix(C[,2:1])] <- C$I ## matrix indexing

res

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 6, 2017 at 7:46 AM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Thank you David. Using xtabs operation simplifies the code very much, many
> thanks ;)
>
> On Tue, Jun 6, 2017 at 7:44 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> > On Jun 6, 2017, at 4:01 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> >
>> > Hi Bogdan,
>> > Kinda messy, but:
>> >
>> > N <- data.frame(N=c("n1","n2","n3","n4"))
>> > M <- data.frame(M=c("m1","m2","m3","m4","m5"))
>> > C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
>> I=c(100,300,400))
>> > MN<-as.data.frame(matrix(NA,nrow=length(N[,1]),ncol=length(M[,1])))
>> > names(MN)<-M[,1]
>> > rownames(MN)<-N[,1]
>> > C[,1]<-as.character(C[,1])
>> > C[,2]<-as.character(C[,2])
>> > for(row in 1:dim(C)[1]) MN[C[row,1],C[row,2]]<-C[row,3]
>>
>> `xtabs` offers another route:
>>
>> C$m <- factor(C$m, levels=M$M)
>> C$n <- factor(C$n, levels=N$N)
>>
>> Option 1:  Zeroes in the empty positions:
>> > (X <- xtabs(I ~ m+n , C, addNA=TRUE))
>>     n
>> m     n1  n2  n3  n4
>>   m1 100 300   0   0
>>   m2   0   0   0   0
>>   m3   0   0 400   0
>>   m4   0   0   0   0
>>   m5   0   0   0   0
>>
>> Option 2: Sparase matrix
>> > (X <- xtabs(I ~ m+n , C, sparse=TRUE))
>> 5 x 4 sparse Matrix of class "dgCMatrix"
>>     n
>> m     n1  n2  n3 n4
>>   m1 100 300   .  .
>>   m2   .   .   .  .
>>   m3   .   . 400  .
>>   m4   .   .   .  .
>>   m5   .   .   .  .
>>
>> I wasn't sure if the sparse reuslts of xtabs would make a distinction
>> between 0 and NA, but happily it does:
>>
>> > C <- data.frame(n=c("n1","n2","n3", "n3", "n4"), m=c("m1","m1","m3",
>> "m4", "m5"), I=c(100,300,400, NA, 0))
>> > C
>>    n  m   I
>> 1 n1 m1 100
>> 2 n2 m1 300
>> 3 n3 m3 400
>> 4 n3 m4  NA
>> 5 n4 m5   0
>> > (X <- xtabs(I ~ m+n , C, sparse=TRUE))
>> 4 x 4 sparse Matrix of class "dgCMatrix"
>>     n
>> m     n1  n2  n3 n4
>>   m1 100 300   .  .
>>   m3   .   . 400  .
>>   m4   .   .   .  .
>>   m5   .   .   .  0
>>
>> (In the example I forgot to repeat the lines that augmented the factor
>> levels so m2 is not seen.
>>
>> --
>> Davod
>> >
>> >
>> > Jim
>> >
>> > On Tue, Jun 6, 2017 at 3:51 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>> >> Dear Bert,
>> >>
>> >> thank you for your response. here it is the piece of R code : given 3
>> data
>> >> frames below ---
>> >>
>> >> N <- data.frame(N=c("n1","n2","n3","n4"))
>> >>
>> >> M <- data.frame(M=c("m1","m2","m3","m4","m5"))
>> >>
>> >> C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
>> I=c(100,300,400))
>> >>
>> >> how shall I integrate N, and M, and C in such a way that at the end we
>> have
>> >> a data frame with :
>> >>
>> >>
>> >>   - list N as the columns names
>> >>   - list M as the rows names
>> >>   - the values in the cells of N * M, corresponding to the numerical
>> >>   values in the data frame C.
>> >>
>> >> more precisely, the result shall be :
>> >>
>> >>     n1  n2  n3 n4
>> >> m1  100  200   -   -
>> >> m2   -   -   -   -
>> >> m3   -   -   300   -
>> >> m4   -   -   -   -
>> >> m5   -   -   -   -
>> >>
>> >> thank you !
>> >>
>> >>
>> >> On Mon, Jun 5, 2017 at 6:57 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >>
>> >>> Reproducible example, please. -- In particular, what exactly does C
>> look
>> >>> ilike?
>> >>>
>> >>> (You should know this by now).
>> >>>
>> >>> -- Bert
>> >>> Bert Gunter
>> >>>
>> >>> "The trouble with having an open mind is that people keep coming along
>> >>> and sticking things into it."
>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>
>> >>>
>> >>> On Mon, Jun 5, 2017 at 6:45 PM, Bogdan Tanasa <tanasa at gmail.com>
>> wrote:
>> >>>> Dear all,
>> >>>>
>> >>>> please could you advise on the R code I could use in order to do the
>> >>>> following operation :
>> >>>>
>> >>>> a. -- I have 2 lists of "genome coordinates" : a list is composed by
>> >>>> numbers that represent genome coordinates;
>> >>>>
>> >>>> let's say list N :
>> >>>>
>> >>>> n1
>> >>>>
>> >>>> n2
>> >>>>
>> >>>> n3
>> >>>>
>> >>>> n4
>> >>>>
>> >>>> and a list M:
>> >>>>
>> >>>> m1
>> >>>>
>> >>>> m2
>> >>>>
>> >>>> m3
>> >>>>
>> >>>> m4
>> >>>>
>> >>>> m5
>> >>>>
>> >>>> 2 -- and a data frame C, where for some pairs of coordinates (n,m)
>> from
>> >>> the
>> >>>> lists above, we have a numerical intensity;
>> >>>>
>> >>>> for example :
>> >>>>
>> >>>> n1; m1; 100
>> >>>>
>> >>>> n1; m2; 300
>> >>>>
>> >>>> The question would be : what is the most efficient R code I could use
>> in
>> >>>> order to integrate the list N, the list M, and the data frame C, in
>> order
>> >>>> to obtain a DATA FRAME,
>> >>>>
>> >>>> -- list N as the columns names
>> >>>> -- list M as the rows names
>> >>>> -- the values in the cells of N * M, corresponding to the numerical
>> >>> values
>> >>>> in the data frame C.
>> >>>>
>> >>>> A little example would be :
>> >>>>
>> >>>>      n1  n2  n3 n4
>> >>>>
>> >>>>      m1  100  -   -   -
>> >>>>
>> >>>>      m2  300  -   -   -
>> >>>>
>> >>>>      m3   -   -   -   -
>> >>>>
>> >>>>      m4   -   -   -   -
>> >>>>
>> >>>>      m5   -   -   -   -
>> >>>> I wrote a script in perl, although i would like to do this in R
>> >>>> Many thanks ;)
>> >>>> -- bogdan
>> >>>>
>> >>>>        [[alternative HTML version deleted]]
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide http://www.R-project.org/
>> >>> posting-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>
>> >>        [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tanasa at gmail.com  Tue Jun  6 17:27:06 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Tue, 6 Jun 2017 08:27:06 -0700
Subject: [R] integrating 2 lists and a data frame in R
In-Reply-To: <CAGxFJbQ_ppioySiOOacGxv0r+KzwfNNWxk35kQY3CbvhLBKpVg@mail.gmail.com>
References: <CA+JEM00vG3fv8a+1kOhW+g-nP7VybX9hhWNrX_sN4gS5VUBEgA@mail.gmail.com>
 <CAGxFJbQkn5GqvKtcG1hKoKOYuUxxE3x+Gs2bFR2k3P5TMyLefw@mail.gmail.com>
 <CA+JEM013i7+cTLqr4XHXGoxunXLKgsrG9pEd5F7=QvpyFb_y5Q@mail.gmail.com>
 <CA+8X3fXpi5C_U3FPGViNq4QrWVmj5XYVUY-hsoJYyBPTkRFhXQ@mail.gmail.com>
 <1998008C-D9AC-4A19-893C-CAF6BBE0B300@comcast.net>
 <CA+JEM03WwX-O2knOzAdU6EC_bheBxRUmC=h_yLawTX859DRpRQ@mail.gmail.com>
 <CAGxFJbQ_ppioySiOOacGxv0r+KzwfNNWxk35kQY3CbvhLBKpVg@mail.gmail.com>
Message-ID: <CA+JEM012UoWw+iJxcCFZq0rsAzNLwnDKeMhyeWaA4BQtssOrAg@mail.gmail.com>

Thank you Bert for your suggestion ;).

On Tue, Jun 6, 2017 at 8:19 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Simple matrix indexing suffices without any fancier functionality.
>
> ## First convert M and N to character vectors -- which they should
> have been in the first place!
>
> M <- sort(as.character(M[,1]))
> N <-  sort(as.character(N[,1]))
>
> ## This could be a one-liner, but I'll split it up for clarity.
>
> res <-matrix(NA, length(M),length(N),dimnames = list(M,N))
>
> res[as.matrix(C[,2:1])] <- C$I ## matrix indexing
>
> res
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Jun 6, 2017 at 7:46 AM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > Thank you David. Using xtabs operation simplifies the code very much,
> many
> > thanks ;)
> >
> > On Tue, Jun 6, 2017 at 7:44 AM, David Winsemius <dwinsemius at comcast.net>
> > wrote:
> >
> >>
> >> > On Jun 6, 2017, at 4:01 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >> >
> >> > Hi Bogdan,
> >> > Kinda messy, but:
> >> >
> >> > N <- data.frame(N=c("n1","n2","n3","n4"))
> >> > M <- data.frame(M=c("m1","m2","m3","m4","m5"))
> >> > C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
> >> I=c(100,300,400))
> >> > MN<-as.data.frame(matrix(NA,nrow=length(N[,1]),ncol=length(M[,1])))
> >> > names(MN)<-M[,1]
> >> > rownames(MN)<-N[,1]
> >> > C[,1]<-as.character(C[,1])
> >> > C[,2]<-as.character(C[,2])
> >> > for(row in 1:dim(C)[1]) MN[C[row,1],C[row,2]]<-C[row,3]
> >>
> >> `xtabs` offers another route:
> >>
> >> C$m <- factor(C$m, levels=M$M)
> >> C$n <- factor(C$n, levels=N$N)
> >>
> >> Option 1:  Zeroes in the empty positions:
> >> > (X <- xtabs(I ~ m+n , C, addNA=TRUE))
> >>     n
> >> m     n1  n2  n3  n4
> >>   m1 100 300   0   0
> >>   m2   0   0   0   0
> >>   m3   0   0 400   0
> >>   m4   0   0   0   0
> >>   m5   0   0   0   0
> >>
> >> Option 2: Sparase matrix
> >> > (X <- xtabs(I ~ m+n , C, sparse=TRUE))
> >> 5 x 4 sparse Matrix of class "dgCMatrix"
> >>     n
> >> m     n1  n2  n3 n4
> >>   m1 100 300   .  .
> >>   m2   .   .   .  .
> >>   m3   .   . 400  .
> >>   m4   .   .   .  .
> >>   m5   .   .   .  .
> >>
> >> I wasn't sure if the sparse reuslts of xtabs would make a distinction
> >> between 0 and NA, but happily it does:
> >>
> >> > C <- data.frame(n=c("n1","n2","n3", "n3", "n4"), m=c("m1","m1","m3",
> >> "m4", "m5"), I=c(100,300,400, NA, 0))
> >> > C
> >>    n  m   I
> >> 1 n1 m1 100
> >> 2 n2 m1 300
> >> 3 n3 m3 400
> >> 4 n3 m4  NA
> >> 5 n4 m5   0
> >> > (X <- xtabs(I ~ m+n , C, sparse=TRUE))
> >> 4 x 4 sparse Matrix of class "dgCMatrix"
> >>     n
> >> m     n1  n2  n3 n4
> >>   m1 100 300   .  .
> >>   m3   .   . 400  .
> >>   m4   .   .   .  .
> >>   m5   .   .   .  0
> >>
> >> (In the example I forgot to repeat the lines that augmented the factor
> >> levels so m2 is not seen.
> >>
> >> --
> >> Davod
> >> >
> >> >
> >> > Jim
> >> >
> >> > On Tue, Jun 6, 2017 at 3:51 PM, Bogdan Tanasa <tanasa at gmail.com>
> wrote:
> >> >> Dear Bert,
> >> >>
> >> >> thank you for your response. here it is the piece of R code : given 3
> >> data
> >> >> frames below ---
> >> >>
> >> >> N <- data.frame(N=c("n1","n2","n3","n4"))
> >> >>
> >> >> M <- data.frame(M=c("m1","m2","m3","m4","m5"))
> >> >>
> >> >> C <- data.frame(n=c("n1","n2","n3"), m=c("m1","m1","m3"),
> >> I=c(100,300,400))
> >> >>
> >> >> how shall I integrate N, and M, and C in such a way that at the end
> we
> >> have
> >> >> a data frame with :
> >> >>
> >> >>
> >> >>   - list N as the columns names
> >> >>   - list M as the rows names
> >> >>   - the values in the cells of N * M, corresponding to the numerical
> >> >>   values in the data frame C.
> >> >>
> >> >> more precisely, the result shall be :
> >> >>
> >> >>     n1  n2  n3 n4
> >> >> m1  100  200   -   -
> >> >> m2   -   -   -   -
> >> >> m3   -   -   300   -
> >> >> m4   -   -   -   -
> >> >> m5   -   -   -   -
> >> >>
> >> >> thank you !
> >> >>
> >> >>
> >> >> On Mon, Jun 5, 2017 at 6:57 PM, Bert Gunter <bgunter.4567 at gmail.com>
> >> wrote:
> >> >>
> >> >>> Reproducible example, please. -- In particular, what exactly does C
> >> look
> >> >>> ilike?
> >> >>>
> >> >>> (You should know this by now).
> >> >>>
> >> >>> -- Bert
> >> >>> Bert Gunter
> >> >>>
> >> >>> "The trouble with having an open mind is that people keep coming
> along
> >> >>> and sticking things into it."
> >> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >>>
> >> >>>
> >> >>> On Mon, Jun 5, 2017 at 6:45 PM, Bogdan Tanasa <tanasa at gmail.com>
> >> wrote:
> >> >>>> Dear all,
> >> >>>>
> >> >>>> please could you advise on the R code I could use in order to do
> the
> >> >>>> following operation :
> >> >>>>
> >> >>>> a. -- I have 2 lists of "genome coordinates" : a list is composed
> by
> >> >>>> numbers that represent genome coordinates;
> >> >>>>
> >> >>>> let's say list N :
> >> >>>>
> >> >>>> n1
> >> >>>>
> >> >>>> n2
> >> >>>>
> >> >>>> n3
> >> >>>>
> >> >>>> n4
> >> >>>>
> >> >>>> and a list M:
> >> >>>>
> >> >>>> m1
> >> >>>>
> >> >>>> m2
> >> >>>>
> >> >>>> m3
> >> >>>>
> >> >>>> m4
> >> >>>>
> >> >>>> m5
> >> >>>>
> >> >>>> 2 -- and a data frame C, where for some pairs of coordinates (n,m)
> >> from
> >> >>> the
> >> >>>> lists above, we have a numerical intensity;
> >> >>>>
> >> >>>> for example :
> >> >>>>
> >> >>>> n1; m1; 100
> >> >>>>
> >> >>>> n1; m2; 300
> >> >>>>
> >> >>>> The question would be : what is the most efficient R code I could
> use
> >> in
> >> >>>> order to integrate the list N, the list M, and the data frame C, in
> >> order
> >> >>>> to obtain a DATA FRAME,
> >> >>>>
> >> >>>> -- list N as the columns names
> >> >>>> -- list M as the rows names
> >> >>>> -- the values in the cells of N * M, corresponding to the numerical
> >> >>> values
> >> >>>> in the data frame C.
> >> >>>>
> >> >>>> A little example would be :
> >> >>>>
> >> >>>>      n1  n2  n3 n4
> >> >>>>
> >> >>>>      m1  100  -   -   -
> >> >>>>
> >> >>>>      m2  300  -   -   -
> >> >>>>
> >> >>>>      m3   -   -   -   -
> >> >>>>
> >> >>>>      m4   -   -   -   -
> >> >>>>
> >> >>>>      m5   -   -   -   -
> >> >>>> I wrote a script in perl, although i would like to do this in R
> >> >>>> Many thanks ;)
> >> >>>> -- bogdan
> >> >>>>
> >> >>>>        [[alternative HTML version deleted]]
> >> >>>>
> >> >>>> ______________________________________________
> >> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>> PLEASE do read the posting guide http://www.R-project.org/
> >> >>> posting-guide.html
> >> >>>> and provide commented, minimal, self-contained, reproducible code.
> >> >>>
> >> >>
> >> >>        [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Tue Jun  6 17:10:52 2017
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 6 Jun 2017 15:10:52 +0000
Subject: [R] Subject:  glm and stepAIC selects too many effects
In-Reply-To: <1496758539469.46773@jhu.edu>
References: <1496758539469.46773@jhu.edu>
Message-ID: <1496761828339.69438@jhu.edu>

More principled would be to use a lasso-type approach, which combines selection and estimation in one fell swoop!



Ravi

________________________________
From: Ravi Varadhan
Sent: Tuesday, June 6, 2017 10:16 AM
To: r-help at r-project.org
Subject: Subject: [R] glm and stepAIC selects too many effects


If AIC is giving you a model that is too large, then use BIC (log(n) as the penalty for adding a term in the model).  This will yield a more parsimonious model.  Now, if you ask me which is the better option, I have to refer you to the huge literature on model selection.

Best,

Ravi

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun  6 18:24:28 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Jun 2017 09:24:28 -0700
Subject: [R] Subject: glm and stepAIC selects too many effects
In-Reply-To: <1496761828339.69438@jhu.edu>
References: <1496758539469.46773@jhu.edu> <1496761828339.69438@jhu.edu>
Message-ID: <CAGxFJbRBAtnxQzr5dmG7XJ-SxySYsPQKWDda=6S0-nbY5_s8RA@mail.gmail.com>

See package "glmnet".

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 6, 2017 at 8:10 AM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> More principled would be to use a lasso-type approach, which combines selection and estimation in one fell swoop!
>
>
>
> Ravi
>
> ________________________________
> From: Ravi Varadhan
> Sent: Tuesday, June 6, 2017 10:16 AM
> To: r-help at r-project.org
> Subject: Subject: [R] glm and stepAIC selects too many effects
>
>
> If AIC is giving you a model that is too large, then use BIC (log(n) as the penalty for adding a term in the model).  This will yield a more parsimonious model.  Now, if you ask me which is the better option, I have to refer you to the huge literature on model selection.
>
> Best,
>
> Ravi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Tue Jun  6 20:34:40 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 6 Jun 2017 14:34:40 -0400
Subject: [R] Force argument to have quotes
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D8DC00@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D8DC00@DC1VEX10MB01.air.org>
Message-ID: <2CCBCA45-716F-435B-AEBA-3746E806E086@utoronto.ca>

If I understand you correctly what you are really asking is how to embed quotes in a string so that it can be parse()'d as an expression. The answer would be: escape the quotes.


R > myOptions <- "Hello"
R > eval(parse(text = paste( "print(", myOptions, ")" )))
 Error in print(Hello) : object 'Hello' not found 

R > eval(parse(text = paste( "print( \"", myOptions, "\")", sep="" )))
[1] "Hello"

(Myself, I would use sprintf(),

R > myFunction <- "print"
R > eval(parse(text = sprintf("%s(\"%s\")", myFunction, myOptions)))
[1] "Hello"

)


Ask again if this is only part of the problem.

B.




> On Jun 6, 2017, at 11:01 AM, Doran, Harold <HDoran at air.org> wrote:
> 
> I am writing a program where non-technical R users will read in a config file and the config file will then parse the arguments found within the config and pass them to respective functions. I'm having trouble (efficiently) writing a piece of code to retain quotation marks around the argument which requires it as input, as found in the example function below, myFuncton1.
> 
> Below is a minimal, reproducible example of the issue with comments.
> 
> ### This is a sample structure of the configuration file
> 
> scoreConfig <- structure(list(Function = c("myFunction1", "myFunction1", "myFunction1", 
> "myFunction2", "myFunction2"), Argument = c("arg1", "arg2", "arg3", 
> "arg1", "arg2"), Value = c("5", "10", "Hello", "5", "10"), Class = c("numeric", 
> "numeric", "character", "numeric", "numeric")), .Names = c("Function", 
> "Argument", "Value", "Class"), class = "data.frame", row.names = c(NA, 
> -5L))
> 
> ### Two sample functions, once of which requires a string
> myFunction1 <- function(arg1, arg2, arg3 = c('Hello', 'Goodbye')){
> 	arg3 <- match.arg(arg3)
> 	result <- arg1 + arg2
> 	cat(arg3, result, '\n')
> 	}
> 	
> 	
> myFunction2 <- function(arg1, arg2){
> 	result <- arg1 * arg2
> 	result
> 	}
> 
> 
> ### Working Example. 
> ### myFunction2 works no problem
> myFunction2Vals <- subset(scoreConfig, Function == 'myFunction2')
> myOptions <- with(myFunction2Vals, paste(Argument, Value, sep = '=', collapse = ','))
> eval(parse(text = paste( "myFunction2(", myOptions, ")" )))
> 
> 
> ### myFunction1 fails 
> myFunction1Vals <- subset(scoreConfig, Function == 'myFunction1')
> myOptions <- with(myFunction1Vals, paste(Argument, Value, sep = '=', collapse = ','))
> eval(parse(text = paste( "myFunction1(", myOptions, ")" )))
> 
> ### What I want is simply
> myFunction1(arg1 = 1, arg2 = 2, arg3 = 'Hello')
> 
> I'm curious if someone has a perspective on the most efficient way to automate this by using information provided in the 'Value" column, so perhaps conditional on that value it could wrap the name in quotes.
> 
> I admit to running into a limit and am tapping out so to speak on the right way to do this.
> 
> Thanks for any advice
> Harold
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Jun  6 21:13:54 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Jun 2017 12:13:54 -0700
Subject: [R] Force argument to have quotes
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D8DC00@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D8DC00@DC1VEX10MB01.air.org>
Message-ID: <CAGxFJbRXjeCHzHqk1ThYh+PN1_u5aRp1Pe8B=GLHtgzFnf3w=w@mail.gmail.com>

Harold:

As a general rule, if you are using eval(parse(...)) you are doing it
poorly in R; cf

library("fortunes")
fortune(106)

Why is something like this not suitable:

fun1 <- function(a1,a2,a3 = c("hi","by"))
{
   cat(a3,a1+a2,"\n")
}

> fun1 (1,2)
hi by 3
> fun1(1,2, a3 = "whoopee")
whoopee 3

... or, if you want to include the function as an argument of a list:

> myArgs <- list(fun=fun1, arglist=list(a1=2, a2 =5, a3 = c("hi","by")))

For which you can do stuff like:

> do.call(myArgs[[1]],myArgs[-1][[1]])
hi by 7

> arglist <- myArgs[-1][[1]][-3]
> do.call(myArgs[[1]],c(arglist,a3 = "whoopee"))
whoopee 7

etc. etc.
See ?do.call

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 6, 2017 at 8:01 AM, Doran, Harold <HDoran at air.org> wrote:
> I am writing a program where non-technical R users will read in a config file and the config file will then parse the arguments found within the config and pass them to respective functions. I'm having trouble (efficiently) writing a piece of code to retain quotation marks around the argument which requires it as input, as found in the example function below, myFuncton1.
>
> Below is a minimal, reproducible example of the issue with comments.
>
> ### This is a sample structure of the configuration file
>
> scoreConfig <- structure(list(Function = c("myFunction1", "myFunction1", "myFunction1",
> "myFunction2", "myFunction2"), Argument = c("arg1", "arg2", "arg3",
> "arg1", "arg2"), Value = c("5", "10", "Hello", "5", "10"), Class = c("numeric",
> "numeric", "character", "numeric", "numeric")), .Names = c("Function",
> "Argument", "Value", "Class"), class = "data.frame", row.names = c(NA,
> -5L))
>
> ### Two sample functions, once of which requires a string
> myFunction1 <- function(arg1, arg2, arg3 = c('Hello', 'Goodbye')){
>         arg3 <- match.arg(arg3)
>         result <- arg1 + arg2
>         cat(arg3, result, '\n')
>         }
>
>
> myFunction2 <- function(arg1, arg2){
>         result <- arg1 * arg2
>         result
>         }
>
>
> ### Working Example.
> ### myFunction2 works no problem
> myFunction2Vals <- subset(scoreConfig, Function == 'myFunction2')
> myOptions <- with(myFunction2Vals, paste(Argument, Value, sep = '=', collapse = ','))
> eval(parse(text = paste( "myFunction2(", myOptions, ")" )))
>
>
> ### myFunction1 fails
> myFunction1Vals <- subset(scoreConfig, Function == 'myFunction1')
> myOptions <- with(myFunction1Vals, paste(Argument, Value, sep = '=', collapse = ','))
> eval(parse(text = paste( "myFunction1(", myOptions, ")" )))
>
> ### What I want is simply
> myFunction1(arg1 = 1, arg2 = 2, arg3 = 'Hello')
>
> I'm curious if someone has a perspective on the most efficient way to automate this by using information provided in the 'Value" column, so perhaps conditional on that value it could wrap the name in quotes.
>
> I admit to running into a limit and am tapping out so to speak on the right way to do this.
>
> Thanks for any advice
> Harold
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From davidsmi at microsoft.com  Tue Jun  6 21:18:43 2017
From: davidsmi at microsoft.com (David Smith)
Date: Tue, 6 Jun 2017 19:18:43 +0000
Subject: [R] Revolutions blog: May 2017 roundup
Message-ID: <BN6PR21MB049720568298249588B5210EC8CB0@BN6PR21MB0497.namprd21.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests
have written about R every weekday at the Revolutions blog
(http://blog.revolutionanalytics.com) and every month I post a summary
of articles from the previous month of particular interest to readers
of r-help.

In case you missed them, here are some articles related to R from the
month of May:

Many interesting presentations recorded at the R/Finance 2017
conference in Chicago are now available to watch:
http://blog.revolutionanalytics.com/2017/05/watch-rfinance-2017.html

A review of some of the R packages and projects implemented at the
2017 ROpenSci Unconference:
http://blog.revolutionanalytics.com/2017/05/runconf17.html

An example of applying Bayesian Learning with the "bnlearn" package to
challenge stereotypical assumptions:
http://blog.revolutionanalytics.com/2017/05/who-is-the-caretaker.html

Data from the Billboard Hot 100 chart used to find the most popular
words in the titles of pop hits:
http://blog.revolutionanalytics.com/2017/05/love-is-all-around.html

Microsoft R Open 3.4.0 is now available for Windows, Mac and Linux:
http://blog.revolutionanalytics.com/2017/05/microsoft-r-open-340-now-available.html

How to use the "tweenr" package to create smooth transitions in data
animations: http://blog.revolutionanalytics.com/2017/05/tweenr.html

A preview of some of the companies and R applications to be presented
at the EARL conference in San Francisco:
http://blog.revolutionanalytics.com/2017/05/preview-of-earl-san-francisco.html

The AsureDSVM package makes it easy to spawn and manage clusters of
the Azure Data Science Virtual Machine:
http://blog.revolutionanalytics.com/2017/05/azuredsvm-a-new-r-package-for-elastic-use-of-the-azure-data-science-virtual-machine.html

A course on spatial data analysis in R, from the Consumer Data
Research Centre in the UK:
http://blog.revolutionanalytics.com/2017/05/cdrc-spatial-course.html

Video and slides of Lixun Zhang's presentation "R in Financial
Services: Challenges and Opportunity" from the New York R Conference:
http://blog.revolutionanalytics.com/2017/05/r-in-financial-services-presentation.html

Visual Studio 2017 now features built-in support for both R and Python
development:
http://blog.revolutionanalytics.com/2017/05/r-and-python-support-now-built-in-to-visual-studio-2017.html

Quantifying the home-field advantage in English Premier League
football:
http://blog.revolutionanalytics.com/2017/05/analyzing-the-home-advantage-in-english-soccer-with-r.html

Using the new CRAN_package_db function to analyze data about CRAN
packages:
http://blog.revolutionanalytics.com/2017/05/analyzing-data-on-cran-packages.html

Stack Overflow Trends tracks the trajectory of questions about R and Python:
http://blog.revolutionanalytics.com/2017/05/stack-overflow-trends.html

A recorded webinar on using Microsoft R to predict length of stay in
hospitals:
http://blog.revolutionanalytics.com/2017/05/hospital-length-of-stay.html

The new "Real-Time Scoring" capability in Microsoft R Server creates a
service to generate predictions from certain models in milliseconds:
http://blog.revolutionanalytics.com/2017/05/real-time-scoring-with-mrs-91.html

"Technical Foundations of Informatics" is an open course guide on data
analysis and visualization with R with a modern slant:
http://blog.revolutionanalytics.com/2017/05/technical-foundations-of-informatics.html

The Datasaurus Dozen generalizes Anscombe's Quartet with a process to
greate datasets of any shape with (nearly) the same summary
statistics:
http://blog.revolutionanalytics.com/2017/05/the-datasaurus-dozen.html

You can now use Microsoft R within Alteryx Designer:
http://blog.revolutionanalytics.com/2017/05/using-microsoft-r-with-alteryx.html

And some general interest stories (not necessarily related to R):

* The history of Australia's states: 
  http://blog.revolutionanalytics.com/2017/05/because-its-friday-history-of-australia.html

* An amusingly animated history of the Universe:
  http://blog.revolutionanalytics.com/2017/05/the-history-of-the-universe-in-20-minutes.html

* How to clean messy data in Excel by providing just a few examples of
  transformations:
  http://blog.revolutionanalytics.com/2017/05/clean-messy-data-by-providing-examples-in-excel.html

* A Neural Network predicts a movie from just one frame:
  http://blog.revolutionanalytics.com/2017/05/because-its-friday-video-projection.html

* The Bayesian Trap, explained:
  http://blog.revolutionanalytics.com/2017/05/becasue-its-friday-bayesian-trap.html

* CareerCast ranks Statistician as the best job to have in 2017:
  http://blog.revolutionanalytics.com/2017/05/best-job-i2017-statistican.html

As always, thanks for the comments and please keep sending suggestions
to me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From NordlDJ at dshs.wa.gov  Tue Jun  6 21:38:45 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 6 Jun 2017 19:38:45 +0000
Subject: [R] Force argument to have quotes
In-Reply-To: <CAGxFJbRXjeCHzHqk1ThYh+PN1_u5aRp1Pe8B=GLHtgzFnf3w=w@mail.gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D8DC00@DC1VEX10MB01.air.org>
 <CAGxFJbRXjeCHzHqk1ThYh+PN1_u5aRp1Pe8B=GLHtgzFnf3w=w@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643EC2B56@WAXMXOLYMB025.WAX.wa.lcl>

Bert has suggested there are better ways to do what you want.  But if you want to continue down the path you have started and you want to decide whether to quote based on the variable Class, something like this might work for you  

myOptions <- with(myFunction1Vals, paste(Argument, ifelse(Class=='character',shQuote(Value), Value), sep = '=', collapse = ","))


Hope this helps,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert
> Gunter
> Sent: Tuesday, June 06, 2017 12:14 PM
> To: Doran, Harold
> Cc: r-help at r-project.org
> Subject: Re: [R] Force argument to have quotes
> 
> Harold:
> 
> As a general rule, if you are using eval(parse(...)) you are doing it
> poorly in R; cf
> 
> library("fortunes")
> fortune(106)
> 
> Why is something like this not suitable:
> 
> fun1 <- function(a1,a2,a3 = c("hi","by"))
> {
>    cat(a3,a1+a2,"\n")
> }
> 
> > fun1 (1,2)
> hi by 3
> > fun1(1,2, a3 = "whoopee")
> whoopee 3
> 
> ... or, if you want to include the function as an argument of a list:
> 
> > myArgs <- list(fun=fun1, arglist=list(a1=2, a2 =5, a3 = c("hi","by")))
> 
> For which you can do stuff like:
> 
> > do.call(myArgs[[1]],myArgs[-1][[1]])
> hi by 7
> 
> > arglist <- myArgs[-1][[1]][-3]
> > do.call(myArgs[[1]],c(arglist,a3 = "whoopee"))
> whoopee 7
> 
> etc. etc.
> See ?do.call
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, Jun 6, 2017 at 8:01 AM, Doran, Harold <HDoran at air.org> wrote:
> > I am writing a program where non-technical R users will read in a config file
> and the config file will then parse the arguments found within the config and
> pass them to respective functions. I'm having trouble (efficiently) writing a
> piece of code to retain quotation marks around the argument which requires
> it as input, as found in the example function below, myFuncton1.
> >
> > Below is a minimal, reproducible example of the issue with comments.
> >
> > ### This is a sample structure of the configuration file
> >
> > scoreConfig <- structure(list(Function = c("myFunction1", "myFunction1",
> "myFunction1",
> > "myFunction2", "myFunction2"), Argument = c("arg1", "arg2", "arg3",
> > "arg1", "arg2"), Value = c("5", "10", "Hello", "5", "10"), Class = c("numeric",
> > "numeric", "character", "numeric", "numeric")), .Names = c("Function",
> > "Argument", "Value", "Class"), class = "data.frame", row.names = c(NA,
> > -5L))
> >
> > ### Two sample functions, once of which requires a string
> > myFunction1 <- function(arg1, arg2, arg3 = c('Hello', 'Goodbye')){
> >         arg3 <- match.arg(arg3)
> >         result <- arg1 + arg2
> >         cat(arg3, result, '\n')
> >         }
> >
> >
> > myFunction2 <- function(arg1, arg2){
> >         result <- arg1 * arg2
> >         result
> >         }
> >
> >
> > ### Working Example.
> > ### myFunction2 works no problem
> > myFunction2Vals <- subset(scoreConfig, Function == 'myFunction2')
> > myOptions <- with(myFunction2Vals, paste(Argument, Value, sep = '=',
> collapse = ','))
> > eval(parse(text = paste( "myFunction2(", myOptions, ")" )))
> >
> >
> > ### myFunction1 fails
> > myFunction1Vals <- subset(scoreConfig, Function == 'myFunction1')
> > myOptions <- with(myFunction1Vals, paste(Argument, Value, sep = '=',
> collapse = ','))
> > eval(parse(text = paste( "myFunction1(", myOptions, ")" )))
> >
> > ### What I want is simply
> > myFunction1(arg1 = 1, arg2 = 2, arg3 = 'Hello')
> >
> > I'm curious if someone has a perspective on the most efficient way to
> automate this by using information provided in the 'Value" column, so
> perhaps conditional on that value it could wrap the name in quotes.
> >
> > I admit to running into a limit and am tapping out so to speak on the right
> way to do this.
> >
> > Thanks for any advice
> > Harold
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From emorway at usgs.gov  Wed Jun  7 03:30:29 2017
From: emorway at usgs.gov (Morway, Eric)
Date: Tue, 6 Jun 2017 18:30:29 -0700
Subject: [R] Determining which.max() within groups
Message-ID: <CAPoqHzoYUoeQs+frqSA1VTGcyC2_6gepAYDDWEDUgM364i6Mzg@mail.gmail.com>

Using the dataset below, I got close to what I'm after, but not quite all
the way there.  Any suggestions appreciated:

Daily <- read.table(textConnection("     Date  wyr        Q
1911-04-01 1990 4.530695
1911-04-02 1990 4.700596
1911-04-03 1990 4.898814
1911-04-04 1990 5.097032
1911-04-05 1991 5.295250
1911-04-06 1991 6.569508
1911-04-07 1991 5.861587
1911-04-08 1991 5.153666
1911-04-09 1992 4.445745
1911-04-10 1992 3.737824
1911-04-11 1992 3.001586
1911-04-12 1992 3.001586
1911-04-13 1993 2.350298
1911-04-14 1993 2.661784
1911-04-16 1993 3.001586
1911-04-17 1993 2.661784
1911-04-19 1994 2.661784
1911-04-28 1994 3.369705
1911-04-29 1994 3.001586
1911-05-20 1994 2.661784"),header=TRUE)

aggregate(Q ~ wyr, data = Daily, which.max)

# gives:
#    wyr Q
# 1 1990 4
# 2 1991 2
# 3 1992 1
# 4 1993 3
# 5 1994 2

I can 'see' that it is returning the which.max() relative to each
grouping.  Is there a way to instead return the absolute position (row) of
the max value within each group.  i.e.:

# Would instead like to have
#     wyr  Q
# 1  1990  4
# 2  1991  6
# 3  1992  9
# 4  1993  15
# 5  1994  18

The icing on the cake would be to get the Julien Day corresponding to the
date on which each year's maximum occurs?

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jun  7 04:15:31 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Jun 2017 19:15:31 -0700
Subject: [R] Determining which.max() within groups
In-Reply-To: <CAPoqHzoYUoeQs+frqSA1VTGcyC2_6gepAYDDWEDUgM364i6Mzg@mail.gmail.com>
References: <CAPoqHzoYUoeQs+frqSA1VTGcyC2_6gepAYDDWEDUgM364i6Mzg@mail.gmail.com>
Message-ID: <CAGxFJbQH1x43nzdrW-zUWPyEVgoPu-6vMAYF=cwoWvqvEYOfrA@mail.gmail.com>

cumsum() seems to be what you need.

This can probably be done more elegantly, but ...

out <- aggregate(Q ~ wyr, data = Daily, which.max)
tbl <- table(Daily$wyr)
out$Q <- out$Q + cumsum(c(0,tbl[-length(tbl)]))
out

## yields

   wyr  Q
1 1990  4
2 1991  6
3 1992  9
4 1993 15
5 1994 18

I leave the matter of Julian dates to you or others.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 6, 2017 at 6:30 PM, Morway, Eric <emorway at usgs.gov> wrote:
> Using the dataset below, I got close to what I'm after, but not quite all
> the way there.  Any suggestions appreciated:
>
> Daily <- read.table(textConnection("     Date  wyr        Q
> 1911-04-01 1990 4.530695
> 1911-04-02 1990 4.700596
> 1911-04-03 1990 4.898814
> 1911-04-04 1990 5.097032
> 1911-04-05 1991 5.295250
> 1911-04-06 1991 6.569508
> 1911-04-07 1991 5.861587
> 1911-04-08 1991 5.153666
> 1911-04-09 1992 4.445745
> 1911-04-10 1992 3.737824
> 1911-04-11 1992 3.001586
> 1911-04-12 1992 3.001586
> 1911-04-13 1993 2.350298
> 1911-04-14 1993 2.661784
> 1911-04-16 1993 3.001586
> 1911-04-17 1993 2.661784
> 1911-04-19 1994 2.661784
> 1911-04-28 1994 3.369705
> 1911-04-29 1994 3.001586
> 1911-05-20 1994 2.661784"),header=TRUE)
>
> aggregate(Q ~ wyr, data = Daily, which.max)
>
> # gives:
> #    wyr Q
> # 1 1990 4
> # 2 1991 2
> # 3 1992 1
> # 4 1993 3
> # 5 1994 2
>
> I can 'see' that it is returning the which.max() relative to each
> grouping.  Is there a way to instead return the absolute position (row) of
> the max value within each group.  i.e.:
>
> # Would instead like to have
> #     wyr  Q
> # 1  1990  4
> # 2  1991  6
> # 3  1992  9
> # 4  1993  15
> # 5  1994  18
>
> The icing on the cake would be to get the Julien Day corresponding to the
> date on which each year's maximum occurs?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From percentil101 at gmail.com  Tue Jun  6 22:37:24 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Tue, 6 Jun 2017 22:37:24 +0200
Subject: [R] Plot MArginal distribution in the correct place
Message-ID: <CAB-TgNt4u_r01t3vpBOo471tj-CZSazjL-zbSonyFsQrrQLbtQ@mail.gmail.com>

Hi all,

I have this code, but the marginal distribution plot doesn?t appear aligned
with the left plot.


I think could be something about layout or par() mar.

The code was programmed by me time ago.

Can anyone help me to get the marginal distribution on the center (more
higher centered)

id.txt

Could have this code:

05/01/2016;9335,200195
06/01/2016;9197,400391
07/01/2016;9059,299805
08/01/2016;8909,200195
11/01/2016;8886,099609
12/01/2016;8915,400391
13/01/2016;8934,5
14/01/2016;8787,700195
15/01/2016;8543,599609
18/01/2016;8469,299805
19/01/2016;8554,900391
20/01/2016;8281,400391
21/01/2016;8444,200195
22/01/2016;8722,900391
25/01/2016;8567,700195
26/01/2016;8692,5
27/01/2016;8741



g<-read.table("id.txt", col.names=c("Dateh","LAST"), sep=";", dec=",")

N=5000
B=24
ghy<-nrow(g)
r<-as.numeric(as.character(g$LAST[ghy]))


nf<-layout(matrix(c(1,1,1,1,2,2),1,6,byrow=TRUE))

par(mar=c(6,6,6,0.5))

A<-matrix(1:B,B,N);



sigma<-0.06;



mu<-0.00;


Z<-r*exp((mu-0.5*((sigma)^2)*A) +sigma*(sqrt(A))*matrix( rnorm(N*B,0,1), B,
N))

real1<-g$LAST[1:nrow(g)]

real2<-matrix(NA,nrow(g),N-1)

real<-cbind(real1,real2)




Po<-r*matrix(1,1,N);



Sim<-rbind(Po,Z)
Simulation<-rbind(real,Z)






par(mar=c(10,6,6,6))
matplot(Simulation,type="l",ylim=c(0,40000))

abline(h = 8000, lwd = 2, col = "black")

abline(h = 12000, lwd = 2, col = "black")
title("Dinamic Montecarlo Simulation 2 years ahead",font=4)

fhist<-hist(Simulation,plot=FALSE)
par(mar=c(6,0,6,6))
barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
grid()
title("Marginal Distribution",font=4)


rect(0, 0, 0, 0) # transparent

	[[alternative HTML version deleted]]


From dhiv.shreya at gmail.com  Wed Jun  7 06:47:20 2017
From: dhiv.shreya at gmail.com (Dhivya Narayanasamy)
Date: Wed, 7 Jun 2017 10:17:20 +0530
Subject: [R] Getting forecast values using DCC GARCH fit
Message-ID: <CACmggQti8T5Nf2Uz9YTcHXAC1_BcYj0tsQbPgZ3yRK8=a2iBiw@mail.gmail.com>

Hi,
I am trying to fit a multivariate time series model using DCC GARCH model
and forecast it.

The data looks like this:

> head(datax)
                    x   vibration_x     Speed
1 2017-05-16 17:53:00      -0.132  421.4189
2 2017-05-16 17:54:00      -0.296 1296.8882
3 2017-05-16 17:55:00      -0.572    0.0000
4 2017-05-16 17:56:00      -0.736 1254.2695
5 2017-05-16 17:57:00       0.000    0.0000
6 2017-05-16 17:58:00       0.000    0.0000

> garch11.spec = ugarchspec(mean.model = list(armaOrder = c(1,1)),
                           variance.model = list(garchOrder = c(1,1),
                                          model = "sGARCH"),
distribution.model = "norm")
> dcc.garch11.spec = dccspec(uspec = multispec( replicate(2, garch11.spec)
),
                  dccOrder = c(1,1), distribution = "mvnorm")
> fit.a = dccfit(dcc.garch11.spec, data = datax[,c(2,3)], out.sample = 500,
                             fit.control = list(eval.se=T))
> dcc.focast=dccforecast(fit.a, n.ahead = 1, n.roll = 499)

May I know how to get the forecast values from 'dcc.focast' ?  I have given
500 as n.roll in rolling forecast. I mean where to find this 500 forecast
values? Any help is much appreciated as I am new to GARCH model.

Also when i plot the forecast model
> plot(dcc.focast, which = 1)

The graph shows weird x axis values starting from 2050 year. Is the graph
showing the forecast values? I have attached the graph as well for your
reference. Thanks in advance.





Regards| Mit freundlichen Gr??en,
> Dhivya Narayanasamy

From percentil101 at gmail.com  Wed Jun  7 08:01:35 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Wed, 7 Jun 2017 08:01:35 +0200
Subject: [R] Plot MArginal distribution in the correct place
In-Reply-To: <CAB-TgNt4u_r01t3vpBOo471tj-CZSazjL-zbSonyFsQrrQLbtQ@mail.gmail.com>
References: <CAB-TgNt4u_r01t3vpBOo471tj-CZSazjL-zbSonyFsQrrQLbtQ@mail.gmail.com>
Message-ID: <CAB-TgNtFXvxHPCbNWM2UeDeyDAt+56i=m5Mamc6mgFdB2kv3aA@mail.gmail.com>

Please, I'm trying to put the right plot higher and centered on the left
values but I don't achive.

I would appreciate so much your help

El 6 jun. 2017 22:37, "Pedro p?ramo" <percentil101 at gmail.com> escribi?:

> Hi all,
>
> I have this code, but the marginal distribution plot doesn?t appear
> aligned with the left plot.
>
>
> I think could be something about layout or par() mar.
>
> The code was programmed by me time ago.
>
> Can anyone help me to get the marginal distribution on the center (more
> higher centered)
>
> id.txt
>
> Could have this code:
>
> 05/01/2016;9335,200195
> 06/01/2016;9197,400391
> 07/01/2016;9059,299805
> 08/01/2016;8909,200195
> 11/01/2016;8886,099609
> 12/01/2016;8915,400391
> 13/01/2016;8934,5
> 14/01/2016;8787,700195
> 15/01/2016;8543,599609
> 18/01/2016;8469,299805
> 19/01/2016;8554,900391
> 20/01/2016;8281,400391
> 21/01/2016;8444,200195
> 22/01/2016;8722,900391
> 25/01/2016;8567,700195
> 26/01/2016;8692,5
> 27/01/2016;8741
>
>
>
> g<-read.table("id.txt", col.names=c("Dateh","LAST"), sep=";", dec=",")
>
> N=5000
> B=24
> ghy<-nrow(g)
> r<-as.numeric(as.character(g$LAST[ghy]))
>
>
> nf<-layout(matrix(c(1,1,1,1,2,2),1,6,byrow=TRUE))
>
> par(mar=c(6,6,6,0.5))
>
> A<-matrix(1:B,B,N);
>
>
>
> sigma<-0.06;
>
>
>
> mu<-0.00;
>
>
> Z<-r*exp((mu-0.5*((sigma)^2)*A) +sigma*(sqrt(A))*matrix( rnorm(N*B,0,1),
> B, N))
>
> real1<-g$LAST[1:nrow(g)]
>
> real2<-matrix(NA,nrow(g),N-1)
>
> real<-cbind(real1,real2)
>
>
>
>
> Po<-r*matrix(1,1,N);
>
>
>
> Sim<-rbind(Po,Z)
> Simulation<-rbind(real,Z)
>
>
>
>
>
>
> par(mar=c(10,6,6,6))
> matplot(Simulation,type="l",ylim=c(0,40000))
>
> abline(h = 8000, lwd = 2, col = "black")
>
> abline(h = 12000, lwd = 2, col = "black")
> title("Dinamic Montecarlo Simulation 2 years ahead",font=4)
>
> fhist<-hist(Simulation,plot=FALSE)
> par(mar=c(6,0,6,6))
> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
> grid()
> title("Marginal Distribution",font=4)
>
>
> rect(0, 0, 0, 0) # transparent
>
>

	[[alternative HTML version deleted]]


From shigesong at gmail.com  Wed Jun  7 09:29:16 2017
From: shigesong at gmail.com (Shige Song)
Date: Wed, 7 Jun 2017 03:29:16 -0400
Subject: [R] Errors running spdplyr example
Message-ID: <CAGuGQczGh8d-8cfB1doDtfsrwTPDNscoAK_NUycBefF8bkjWWw@mail.gmail.com>

Dear All,

When I tried to run the following code (taken from the *spdplyr* package
vignettes):

library(spdplyr)
library(maptools)
data(wrld_simpl)

worldcorner <- wrld_simpl %>%
  mutate(lon = coordinates(wrld_simpl)[,1], lat =
coordinates(wrld_simpl)[,2]) %>%
  filter(lat < -20, lon > 60) %>%
  dplyr::select(NAME)


I got the following error messages:

Error in (function (cl, name, valueClass)  :
  c("assignment of an object of class ?tbl_df? is not valid for @?data? in
an object of class ?SpatialPolygonsDataFrame?; is(value, \"data.frame\") is
not TRUE", "assignment of an object of class ?tbl? is not valid for @?data?
in an object of class ?SpatialPolygonsDataFrame?; is(value, \"data.frame\")
is not TRUE", "assignment of an object of class ?data.frame? is not valid
for @?data? in an object of class ?SpatialPolygonsDataFrame?; is(value,
\"data.frame\") is not TRUE")

I am running R 3.3.3 with the latest CRAN version of *spdplyr* (0.1.3) on
Windows 10.

Thanks.

Best,
Shige

	[[alternative HTML version deleted]]


From Mohan.Radhakrishnan at cognizant.com  Wed Jun  7 10:35:07 2017
From: Mohan.Radhakrishnan at cognizant.com (Mohan.Radhakrishnan at cognizant.com)
Date: Wed, 7 Jun 2017 08:35:07 +0000
Subject: [R] Operating on RC in a list
Message-ID: <E1B160F4999FD6449524E16C2CB94E031F90F19C@CTSINCHNSXMBE.cts.com>

Hi,

I have a hierarchy of such classes. Subject has a list of measurements. Let assume I have a list of such 'Subject' RC's.

Can I use dplyr to navigate from Subject to the list of measurement RC's and filter and group data ? dplyr should
be able to call the methods on these RC's to operate on the data structure ?

I tried to coerce the list of RC's into a data frame unsuccessfully. But dplyr should be able to work with lists too. Right ?


Subject <- setRefClass("Subject",
fields = list( id = "numeric",
measurement = "Measurement",
location = "Location"),
methods=list(getmeasurement = function()
{
measurement
},
getid = function()
{
id
},
getlocation = function()
{
location
},
summary = function()#Implement other summary methods in appropriate objects as per their responsibilities
{
paste("Subject summary ID [",id,"] Location [",location$summary(),"]")
},show = function(){
cat("Subject summary ID [",id,"] Location [",location$summary(),"]\n")
})
)


Thanks,
Mohan
This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.

	[[alternative HTML version deleted]]


From dhiv.shreya at gmail.com  Wed Jun  7 11:25:30 2017
From: dhiv.shreya at gmail.com (Dhivya Narayanasamy)
Date: Wed, 7 Jun 2017 14:55:30 +0530
Subject: [R] Getting forecast values using DCC GARCH fit
Message-ID: <CACmggQu8ryOJ-zXvCG2qios9aS4W+0AVfVgNmnnTcEYkp6yeAQ@mail.gmail.com>

Hi,
I am completely new to GARCH models and trying to fit a multivariate time
series model using DCC GARCH model and forecast it.

The data looks like this:

> head(datax)
                    x   vibration_x     Speed
1 2017-05-16 17:53:00      -0.132  421.4189
2 2017-05-16 17:54:00      -0.296 1296.8882
3 2017-05-16 17:55:00      -0.572    0.0000
4 2017-05-16 17:56:00      -0.736 1254.2695
5 2017-05-16 17:57:00       0.000    0.0000
6 2017-05-16 17:58:00       0.000    0.0000

> garch11.spec = ugarchspec(mean.model = list(armaOrder = c(1,1)),
                           variance.model = list(garchOrder = c(1,1),
                                          model = "sGARCH"),
distribution.model = "norm")
> dcc.garch11.spec = dccspec(uspec = multispec( replicate(2, garch11.spec)
),
                  dccOrder = c(1,1), distribution = "mvnorm")
> fit.a = dccfit(dcc.garch11.spec, data = datax[,c(2,3)], out.sample = 100,
                             fit.control = list(eval.se=T))
> dcc.focast=dccforecast(fit.a, n.ahead = 100)

May I know how to get the forecast values from 'dcc.focast' ? when i plot
the model using,

> plot(dcc.focast, which = 1)

I get different plots such as.
Make a plot selection (or 0 to exit):

1:   Conditional Mean (vs Realized Returns)
2:   Conditional Sigma (vs Realized Absolute Returns)
3:   Conditional Covariance
4:   Conditional Correlation
5:   EW Portfolio Plot with conditional density VaR limits

May i know what i should do with "Conditional covariance" and "conditional
correlation" forecast. I know this is for volatility prediction. I am
interested to know what things i can interpret from this conditional
covariance ?

 Any help is much appreciated. Thanks.,

Regards
Dhivya

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Jun  7 12:08:52 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 7 Jun 2017 20:08:52 +1000
Subject: [R] Plot MArginal distribution in the correct place
In-Reply-To: <CAB-TgNtFXvxHPCbNWM2UeDeyDAt+56i=m5Mamc6mgFdB2kv3aA@mail.gmail.com>
References: <CAB-TgNt4u_r01t3vpBOo471tj-CZSazjL-zbSonyFsQrrQLbtQ@mail.gmail.com>
 <CAB-TgNtFXvxHPCbNWM2UeDeyDAt+56i=m5Mamc6mgFdB2kv3aA@mail.gmail.com>
Message-ID: <CA+8X3fVP84StrtWD=gg7pUygf2WpSxOx4G1YW42YW-3AR3kfqw@mail.gmail.com>

Hi Pedro,
As a one-off, you just shove the coordinates around a bit:

par(mar=c(11,0,6,6))
barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray",
 ylim=c(0,24))

However, I don't think that this plot illustrates quite what you think it does.

Jim


On Wed, Jun 7, 2017 at 4:01 PM, Pedro p?ramo <percentil101 at gmail.com> wrote:
> Please, I'm trying to put the right plot higher and centered on the left
> values but I don't achive.
>
> I would appreciate so much your help
>
> El 6 jun. 2017 22:37, "Pedro p?ramo" <percentil101 at gmail.com> escribi?:
>
>> Hi all,
>>
>> I have this code, but the marginal distribution plot doesn?t appear
>> aligned with the left plot.
>>
>>
>> I think could be something about layout or par() mar.
>>
>> The code was programmed by me time ago.
>>
>> Can anyone help me to get the marginal distribution on the center (more
>> higher centered)
>>
>> id.txt
>>
>> Could have this code:
>>
>> 05/01/2016;9335,200195
>> 06/01/2016;9197,400391
>> 07/01/2016;9059,299805
>> 08/01/2016;8909,200195
>> 11/01/2016;8886,099609
>> 12/01/2016;8915,400391
>> 13/01/2016;8934,5
>> 14/01/2016;8787,700195
>> 15/01/2016;8543,599609
>> 18/01/2016;8469,299805
>> 19/01/2016;8554,900391
>> 20/01/2016;8281,400391
>> 21/01/2016;8444,200195
>> 22/01/2016;8722,900391
>> 25/01/2016;8567,700195
>> 26/01/2016;8692,5
>> 27/01/2016;8741
>>
>>
>>
>> g<-read.table("id.txt", col.names=c("Dateh","LAST"), sep=";", dec=",")
>>
>> N=5000
>> B=24
>> ghy<-nrow(g)
>> r<-as.numeric(as.character(g$LAST[ghy]))
>>
>>
>> nf<-layout(matrix(c(1,1,1,1,2,2),1,6,byrow=TRUE))
>>
>> par(mar=c(6,6,6,0.5))
>>
>> A<-matrix(1:B,B,N);
>>
>>
>>
>> sigma<-0.06;
>>
>>
>>
>> mu<-0.00;
>>
>>
>> Z<-r*exp((mu-0.5*((sigma)^2)*A) +sigma*(sqrt(A))*matrix( rnorm(N*B,0,1),
>> B, N))
>>
>> real1<-g$LAST[1:nrow(g)]
>>
>> real2<-matrix(NA,nrow(g),N-1)
>>
>> real<-cbind(real1,real2)
>>
>>
>>
>>
>> Po<-r*matrix(1,1,N);
>>
>>
>>
>> Sim<-rbind(Po,Z)
>> Simulation<-rbind(real,Z)
>>
>>
>>
>>
>>
>>
>> par(mar=c(10,6,6,6))
>> matplot(Simulation,type="l",ylim=c(0,40000))
>>
>> abline(h = 8000, lwd = 2, col = "black")
>>
>> abline(h = 12000, lwd = 2, col = "black")
>> title("Dinamic Montecarlo Simulation 2 years ahead",font=4)
>>
>> fhist<-hist(Simulation,plot=FALSE)
>> par(mar=c(6,0,6,6))
>> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
>> grid()
>> title("Marginal Distribution",font=4)
>>
>>
>> rect(0, 0, 0, 0) # transparent
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mdsumner at gmail.com  Wed Jun  7 13:32:18 2017
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 07 Jun 2017 11:32:18 +0000
Subject: [R] Errors running spdplyr example
In-Reply-To: <CAGuGQczGh8d-8cfB1doDtfsrwTPDNscoAK_NUycBefF8bkjWWw@mail.gmail.com>
References: <CAGuGQczGh8d-8cfB1doDtfsrwTPDNscoAK_NUycBefF8bkjWWw@mail.gmail.com>
Message-ID: <CAAcGz9970sC9V5SRdF1=KHgivvhPiH7FLyNryxORcZgL--oJDg@mail.gmail.com>

On Wed, 7 Jun 2017 at 17:29 Shige Song <shigesong at gmail.com> wrote:

> Dear All,
>
> When I tried to run the following code (taken from the *spdplyr* package
> vignettes):
>
> library(spdplyr)
> library(maptools)
> data(wrld_simpl)
>
> worldcorner <- wrld_simpl %>%
>   mutate(lon = coordinates(wrld_simpl)[,1], lat =
> coordinates(wrld_simpl)[,2]) %>%
>   filter(lat < -20, lon > 60) %>%
>   dplyr::select(NAME)
>
>
> I got the following error messages:
>
> Error in (function (cl, name, valueClass)  :
>   c("assignment of an object of class ?tbl_df? is not valid for @?data? in
> an object of class ?SpatialPolygonsDataFrame?; is(value, \"data.frame\") is
> not TRUE", "assignment of an object of class ?tbl? is not valid for @?data?
> in an object of class ?SpatialPolygonsDataFrame?; is(value, \"data.frame\")
> is not TRUE", "assignment of an object of class ?data.frame? is not valid
> for @?data? in an object of class ?SpatialPolygonsDataFrame?; is(value,
> \"data.frame\") is not TRUE")
>
>
Hi Shige,

I can't reproduce this, could you run 'sessionInfo()' and let me know?

I'm pretty sure you could workaround this by running

setOldClass( c("tbl_df", "tbl", "data.frame" ) )

but I don't understand why that's not already working, and it's not
something you want to rely on. (You are only the second report where I've
heard anyone seeing this, it's because sp is strict about only accepting
'data.frame' rather than anything inheriting from 'data.frame', as 'tbl_df'
does. )

Feel free to take this off-list and post directly to the Issues on Github
or email me.

 bug.report(package = "spdplyr")

Cheers, Mike.



> I am running R 3.3.3 with the latest CRAN version of *spdplyr* (0.1.3) on
> Windows 10.
>
> Thanks.
>
> Best,
> Shige
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Jun  7 15:49:42 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 7 Jun 2017 13:49:42 +0000
Subject: [R] Determining which.max() within groups
In-Reply-To: <CAGxFJbQH1x43nzdrW-zUWPyEVgoPu-6vMAYF=cwoWvqvEYOfrA@mail.gmail.com>
References: <CAPoqHzoYUoeQs+frqSA1VTGcyC2_6gepAYDDWEDUgM364i6Mzg@mail.gmail.com>
 <CAGxFJbQH1x43nzdrW-zUWPyEVgoPu-6vMAYF=cwoWvqvEYOfrA@mail.gmail.com>
Message-ID: <4dd596fe29c541f3a8f8e567805cbe95@exch-2p-mbx-w2.ads.tamu.edu>

If you want the Julian date, you could use Bert's index on the original data frame:

Daily[out$Q, ]
         Date  wyr        Q
4  1911-04-04 1990 5.097032
6  1911-04-06 1991 6.569508
9  1911-04-09 1992 4.445745
15 1911-04-16 1993 3.001586
18 1911-04-28 1994 3.369705

Another way to get that index would be to use by():

idx <- as.vector(by(Daily, Daily$wyr, function(x) rownames(x)[which.max(x$Q)]))
Daily[idx, ]

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Tuesday, June 6, 2017 9:16 PM
To: Morway, Eric <emorway at usgs.gov>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] Determining which.max() within groups

cumsum() seems to be what you need.

This can probably be done more elegantly, but ...

out <- aggregate(Q ~ wyr, data = Daily, which.max)
tbl <- table(Daily$wyr)
out$Q <- out$Q + cumsum(c(0,tbl[-length(tbl)]))
out

## yields

   wyr  Q
1 1990  4
2 1991  6
3 1992  9
4 1993 15
5 1994 18

I leave the matter of Julian dates to you or others.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 6, 2017 at 6:30 PM, Morway, Eric <emorway at usgs.gov> wrote:
> Using the dataset below, I got close to what I'm after, but not quite all
> the way there.  Any suggestions appreciated:
>
> Daily <- read.table(textConnection("     Date  wyr        Q
> 1911-04-01 1990 4.530695
> 1911-04-02 1990 4.700596
> 1911-04-03 1990 4.898814
> 1911-04-04 1990 5.097032
> 1911-04-05 1991 5.295250
> 1911-04-06 1991 6.569508
> 1911-04-07 1991 5.861587
> 1911-04-08 1991 5.153666
> 1911-04-09 1992 4.445745
> 1911-04-10 1992 3.737824
> 1911-04-11 1992 3.001586
> 1911-04-12 1992 3.001586
> 1911-04-13 1993 2.350298
> 1911-04-14 1993 2.661784
> 1911-04-16 1993 3.001586
> 1911-04-17 1993 2.661784
> 1911-04-19 1994 2.661784
> 1911-04-28 1994 3.369705
> 1911-04-29 1994 3.001586
> 1911-05-20 1994 2.661784"),header=TRUE)
>
> aggregate(Q ~ wyr, data = Daily, which.max)
>
> # gives:
> #    wyr Q
> # 1 1990 4
> # 2 1991 2
> # 3 1992 1
> # 4 1993 3
> # 5 1994 2
>
> I can 'see' that it is returning the which.max() relative to each
> grouping.  Is there a way to instead return the absolute position (row) of
> the max value within each group.  i.e.:
>
> # Would instead like to have
> #     wyr  Q
> # 1  1990  4
> # 2  1991  6
> # 3  1992  9
> # 4  1993  15
> # 5  1994  18
>
> The icing on the cake would be to get the Julien Day corresponding to the
> date on which each year's maximum occurs?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Wed Jun  7 16:32:07 2017
From: hannah.hlx at gmail.com (li li)
Date: Wed, 7 Jun 2017 10:32:07 -0400
Subject: [R] An R question
Message-ID: <CAHLnndaN3uhZZozUOCg_2gEaCbgyEzQXoaa7BnGdN-0njcXzig@mail.gmail.com>

Hi all,
  In checking my R codes, I encountered the following problem. Is there a
way to fix this?
I tried to specify options(digits=). I did not fix the problem.
  Thanks so much for your help!
   Hanna


> cdf(pmass)[2,2]==pcum[2,2][1] FALSE> cdf(pmass)[2,2][1] 0.9999758> pcum[2,2][1] 0.9999758

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Jun  7 16:35:17 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 07 Jun 2017 15:35:17 +0100
Subject: [R] An R question
In-Reply-To: <CAHLnndaN3uhZZozUOCg_2gEaCbgyEzQXoaa7BnGdN-0njcXzig@mail.gmail.com>
References: <CAHLnndaN3uhZZozUOCg_2gEaCbgyEzQXoaa7BnGdN-0njcXzig@mail.gmail.com>
Message-ID: <59380F25.70503@sapo.pt>

Hello,

See FAQ 7.31
And try ?all.equal.

Hope this helps,

Rui Barradas


Em 07-06-2017 15:32, li li escreveu:
> Hi all,
>    In checking my R codes, I encountered the following problem. Is there a
> way to fix this?
> I tried to specify options(digits=). I did not fix the problem.
>    Thanks so much for your help!
>     Hanna
>
>
>> cdf(pmass)[2,2]==pcum[2,2][1] FALSE> cdf(pmass)[2,2][1] 0.9999758> pcum[2,2][1] 0.9999758
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From G.Maubach at weinwolf.de  Wed Jun  7 16:34:43 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 7 Jun 2017 16:34:43 +0200
Subject: [R] purrr::pmap does not work
Message-ID: <OFB7AADCC8.966A1660-ONC1258138.004D4D8C-C1258138.00501586@lotus.hawesko.de>

Hi All,

I try to do a scatterplot for a bunch of variables. I plot a dependent 
variable against a bunch of independent variables:

-- cut --
graphics::plot(
  v01_r01 ~ v08_01_up11,
  data = dataset,
  xlab = "Dependent",
  ylab = "Independent #1"
)

-- cut --

It is tedious to repeat the statement for all independent variables. Found 
an alternative, i.e. :

-- cut --

mu <- list(5, 10, -3)
sigma <- list(1, 5, 10)
n <- list(1, 3, 5)
fargs <- list(mean = mu, sd = sigma, n = n)
fargs %>%
  purrr::pmap(rnorm) %>%
  str()

-- cut --

I tried to use this for may scatterplot task:

-- cut --

var_battery$v08 <- paste0("v08_", formatC(1:8, width = 2, format = "d", 
flag = "0"))
v08_var_labs <- paste0("Label_", 1:8)

dataset <- as.data.frame(
  matrix(
    data = sample(
      x = 1:11,
      size = 90,
      replace = TRUE),
    nrow = 10,
    ncol = 9))
names(dataset) <- c("v01_r01", var_battery$v08)

independent <- as.list(dataset$v01_r01)
dependent <- as.list(dataset[var_battery$v08])

fargs <- list(
  x = independent,
  y = dependent,
  ylab = v08_var_labs)

fargs %>% 
  purrr::pmap(
    function(d = dataset, xvalue = x, yvalue = y,
             xlab = "Label for x variable",
             ylab = ylab) {
      graphics::plot(
        xvalue ~ yvalue,
        data = d,
        xlab = xlab,
        ylab = ylab)
    }
  )

-- cut --

The last statement comes back with

Error: Element 2 has length 8, not 1 or 10.

How can I get it up n running? Do you suggest a better solution for the 
task described?

Kind regards

Georg


From calandra at rgzm.de  Wed Jun  7 16:38:26 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Wed, 7 Jun 2017 16:38:26 +0200
Subject: [R] An R question
In-Reply-To: <CAHLnndaN3uhZZozUOCg_2gEaCbgyEzQXoaa7BnGdN-0njcXzig@mail.gmail.com>
References: <CAHLnndaN3uhZZozUOCg_2gEaCbgyEzQXoaa7BnGdN-0njcXzig@mail.gmail.com>
Message-ID: <66ff4eb1-0a3b-4c5d-266e-87ceb61ceaa8@rgzm.de>

Hi,

Check the FAQ 7.31
https://cran.rstudio.com/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

And read the posting guide too...
https://www.r-project.org/posting-guide.html

HTH,
Ivan

--
Dr. Ivan Calandra
TraCEr, Laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 07/06/2017 16:32, li li wrote:
> Hi all,
>    In checking my R codes, I encountered the following problem. Is there a
> way to fix this?
> I tried to specify options(digits=). I did not fix the problem.
>    Thanks so much for your help!
>     Hanna
>
>
>> cdf(pmass)[2,2]==pcum[2,2][1] FALSE> cdf(pmass)[2,2][1] 0.9999758> pcum[2,2][1] 0.9999758
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hannah.hlx at gmail.com  Wed Jun  7 17:12:58 2017
From: hannah.hlx at gmail.com (li li)
Date: Wed, 7 Jun 2017 11:12:58 -0400
Subject: [R] An R question
In-Reply-To: <66ff4eb1-0a3b-4c5d-266e-87ceb61ceaa8@rgzm.de>
References: <CAHLnndaN3uhZZozUOCg_2gEaCbgyEzQXoaa7BnGdN-0njcXzig@mail.gmail.com>
 <66ff4eb1-0a3b-4c5d-266e-87ceb61ceaa8@rgzm.de>
Message-ID: <CAHLnndYvfknedVWZpn5g+hRnS_nF1Ywbn6=7PPB3VETM5Kp0uA@mail.gmail.com>

Thank you!

2017-06-07 10:38 GMT-04:00 Ivan Calandra <calandra at rgzm.de>:

> Hi,
>
> Check the FAQ 7.31
> https://cran.rstudio.com/doc/FAQ/R-FAQ.html#Why-doesn_0027t-
> R-think-these-numbers-are-equal_003f
>
> And read the posting guide too...
> https://www.r-project.org/posting-guide.html
>
> HTH,
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, Laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
>
> On 07/06/2017 16:32, li li wrote:
>
>> Hi all,
>>    In checking my R codes, I encountered the following problem. Is there a
>> way to fix this?
>> I tried to specify options(digits=). I did not fix the problem.
>>    Thanks so much for your help!
>>     Hanna
>>
>>
>> cdf(pmass)[2,2]==pcum[2,2][1] FALSE> cdf(pmass)[2,2][1] 0.9999758>
>>> pcum[2,2][1] 0.9999758
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Wed Jun  7 17:33:30 2017
From: hannah.hlx at gmail.com (li li)
Date: Wed, 7 Jun 2017 11:33:30 -0400
Subject: [R] Adding zeros in each dimension of an array
Message-ID: <CAHLnndbi3akoyNAhjyntBY00gX4ihoJ0Rqcbrbqa46iScbXbjw@mail.gmail.com>

For a data frame, we can add an additional row or column easily. For
example, we can add an additional row of zero and an additional row of
column as follows.

Is there an easy and similar way to add zeros in each dimension? For
example, for
array(1:12, dim=c(2,2,3))?

Thanks for your help!!
   Hanna



> x <- as.data.frame(matrix(1:20,4,5))> x[5,] <- 0> x[,6] <- 0> x  V1 V2 V3 V4 V5 V6
1  1  5  9 13 17  0
2  2  6 10 14 18  0
3  3  7 11 15 19  0
4  4  8 12 16 20  0
5  0  0  0  0  0  0

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jun  7 17:57:10 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 7 Jun 2017 08:57:10 -0700 (PDT)
Subject: [R] Determining which.max() within groups
In-Reply-To: <CAGxFJbQH1x43nzdrW-zUWPyEVgoPu-6vMAYF=cwoWvqvEYOfrA@mail.gmail.com>
References: <CAPoqHzoYUoeQs+frqSA1VTGcyC2_6gepAYDDWEDUgM364i6Mzg@mail.gmail.com>
 <CAGxFJbQH1x43nzdrW-zUWPyEVgoPu-6vMAYF=cwoWvqvEYOfrA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1706070848200.50464@pedal.dcn.davis.ca.us>

Aggregate can do both which.max and group length calculations, but the 
result ends up as a matrix inside the data frame, which I find cumbersome 
to work with.

Daily <- read.table( text =
"     Date  wyr        Q
1911-04-01 1990 4.530695
1911-04-02 1990 4.700596
1911-04-03 1990 4.898814
1911-04-04 1990 5.097032
1911-04-05 1991 5.295250
1911-04-06 1991 6.569508
1911-04-07 1991 5.861587
1911-04-08 1991 5.153666
1911-04-09 1992 4.445745
1911-04-10 1992 3.737824
1911-04-11 1992 3.001586
1911-04-12 1992 3.001586
1911-04-13 1993 2.350298
1911-04-14 1993 2.661784
1911-04-16 1993 3.001586
1911-04-17 1993 2.661784
1911-04-19 1994 2.661784
1911-04-28 1994 3.369705
1911-04-29 1994 3.001586
1911-05-20 1994 2.661784
", header = TRUE, stringsAsFactors=FALSE)

# this algorithm only works if wyr groups are contiguous
out <- out[ order(out$wyr), ]
# generate a data frame with key column wyr and matrix Q as the second 
column
out <- aggregate( Q ~ wyr
                 , data = Daily
                 , FUN = function(x) {
                      c( WM = which.max(x)
                       , n=length( x )
                       )
                   }
                 )
# put matrix into separate columns Q.WM
out[ , paste( "Q", colnames( out$Q ), sep="." ) ] <- out$Q
# drop the matrix
out$Q <- NULL
# form absolute indexes Q.N
out <- within( out, {
         Q.maxidx <- cumsum( c( 0, Q.n[ -length(Q.n) ] ) ) + Q.WM
        })
result <- Daily[ with( out, Q.maxidx ), ]

# or save ourselves some effort
library(dplyr)
result2 <- (   Daily
            %>% group_by( wyr )
            %>% slice( which.max( Q ) )
            %>% as.data.frame
            )

On Tue, 6 Jun 2017, Bert Gunter wrote:

> cumsum() seems to be what you need.
>
> This can probably be done more elegantly, but ...
>
> out <- aggregate(Q ~ wyr, data = Daily, which.max)
> tbl <- table(Daily$wyr)
> out$Q <- out$Q + cumsum(c(0,tbl[-length(tbl)]))
> out
>
> ## yields
>
>   wyr  Q
> 1 1990  4
> 2 1991  6
> 3 1992  9
> 4 1993 15
> 5 1994 18
>
> I leave the matter of Julian dates to you or others.
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Jun 6, 2017 at 6:30 PM, Morway, Eric <emorway at usgs.gov> wrote:
>> Using the dataset below, I got close to what I'm after, but not quite all
>> the way there.  Any suggestions appreciated:
>>
>> Daily <- read.table(textConnection("     Date  wyr        Q
>> 1911-04-01 1990 4.530695
>> 1911-04-02 1990 4.700596
>> 1911-04-03 1990 4.898814
>> 1911-04-04 1990 5.097032
>> 1911-04-05 1991 5.295250
>> 1911-04-06 1991 6.569508
>> 1911-04-07 1991 5.861587
>> 1911-04-08 1991 5.153666
>> 1911-04-09 1992 4.445745
>> 1911-04-10 1992 3.737824
>> 1911-04-11 1992 3.001586
>> 1911-04-12 1992 3.001586
>> 1911-04-13 1993 2.350298
>> 1911-04-14 1993 2.661784
>> 1911-04-16 1993 3.001586
>> 1911-04-17 1993 2.661784
>> 1911-04-19 1994 2.661784
>> 1911-04-28 1994 3.369705
>> 1911-04-29 1994 3.001586
>> 1911-05-20 1994 2.661784"),header=TRUE)
>>
>> aggregate(Q ~ wyr, data = Daily, which.max)
>>
>> # gives:
>> #    wyr Q
>> # 1 1990 4
>> # 2 1991 2
>> # 3 1992 1
>> # 4 1993 3
>> # 5 1994 2
>>
>> I can 'see' that it is returning the which.max() relative to each
>> grouping.  Is there a way to instead return the absolute position (row) of
>> the max value within each group.  i.e.:
>>
>> # Would instead like to have
>> #     wyr  Q
>> # 1  1990  4
>> # 2  1991  6
>> # 3  1992  9
>> # 4  1993  15
>> # 5  1994  18
>>
>> The icing on the cake would be to get the Julien Day corresponding to the
>> date on which each year's maximum occurs?
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From dwinsemius at comcast.net  Wed Jun  7 18:03:30 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 7 Jun 2017 09:03:30 -0700
Subject: [R] Adding zeros in each dimension of an array
In-Reply-To: <CAHLnndbi3akoyNAhjyntBY00gX4ihoJ0Rqcbrbqa46iScbXbjw@mail.gmail.com>
References: <CAHLnndbi3akoyNAhjyntBY00gX4ihoJ0Rqcbrbqa46iScbXbjw@mail.gmail.com>
Message-ID: <012DCDEC-ACFC-4004-9BEA-69C955703457@comcast.net>


> On Jun 7, 2017, at 8:33 AM, li li <hannah.hlx at gmail.com> wrote:
> 
> For a data frame, we can add an additional row or column easily. For
> example, we can add an additional row of zero and an additional row of
> column as follows.
> 
> Is there an easy and similar way to add zeros in each dimension? For
> example, for
> array(1:12, dim=c(2,2,3))?
> 
> Thanks for your help!!
>   Hanna
> 
> 
> 
>> x <- as.data.frame(matrix(1:20,4,5))> x[5,] <- 0> x[,6] <- 0> x  V1 V2 V3 V4 V5 V6
> 1  1  5  9 13 17  0
> 2  2  6 10 14 18  0
> 3  3  7 11 15 19  0
> 4  4  8 12 16 20  0
> 5  0  0  0  0  0  0
> 

Try installing the abind package.


> 	[[alternative HTML version deleted]]

And learn to post in plaint text.


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Wed Jun  7 18:25:46 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 7 Jun 2017 09:25:46 -0700 (PDT)
Subject: [R] Adding zeros in each dimension of an array
In-Reply-To: <CAHLnndbi3akoyNAhjyntBY00gX4ihoJ0Rqcbrbqa46iScbXbjw@mail.gmail.com>
References: <CAHLnndbi3akoyNAhjyntBY00gX4ihoJ0Rqcbrbqa46iScbXbjw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1706070902050.50464@pedal.dcn.davis.ca.us>

Please read
https://www.lifewire.com/how-to-send-a-message-in-plain-text-from-gmail-1171963

Re your question: easy is in the eye of the beholder.

a <- array( 1:12, dim = c( 2, 2, 3 ) )
b <- array( 0, dim = dim( a ) + 1 )
b[ 1:2, 1:2, 1:3 ] <- a

If you want to do a lot of this, it could be wrapped for convenience 
though implementing that last expression without hardcoding the sequences 
may not be obvious:

expandArray <- function( a ) {
   b <- array( 0, dim = dim( a ) + 1 )
   do.call( `[<-`, c( list( b ), lapply( dim( a ), seq.int ), list( a ) ) )
}
expandArray( a )

On Wed, 7 Jun 2017, li li wrote:

> For a data frame, we can add an additional row or column easily. For
> example, we can add an additional row of zero and an additional row of
> column as follows.
>
> Is there an easy and similar way to add zeros in each dimension? For
> example, for
> array(1:12, dim=c(2,2,3))?
>
> Thanks for your help!!
>   Hanna
>
>
>
>> x <- as.data.frame(matrix(1:20,4,5))> x[5,] <- 0> x[,6] <- 0> x  V1 V2 V3 V4 V5 V6
> 1  1  5  9 13 17  0
> 2  2  6 10 14 18  0
> 3  3  7 11 15 19  0
> 4  4  8 12 16 20  0
> 5  0  0  0  0  0  0
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From yogesh2cute at gmail.com  Wed Jun  7 11:08:51 2017
From: yogesh2cute at gmail.com (Yogesh Gupta)
Date: Wed, 7 Jun 2017 18:08:51 +0900
Subject: [R] Problem related to rowSums
Message-ID: <CAAjHrnO6iQMM7UJ5qswT1iE95sjvn8gfbgV5D9HPx8oXbFKQ5A@mail.gmail.com>

Hi...

I have a dataframe with n columns and n rows. I need to find how many rows
contains zero raw read count across all column.

Thanks

-- 
*Yogesh Gupta*
*Postdoctoral Researcher*
*Department of Biological Science*
*Seoul National University*
*Seoul, South Korea*

	[[alternative HTML version deleted]]


From yogesh2cute at gmail.com  Wed Jun  7 11:53:40 2017
From: yogesh2cute at gmail.com (Yogesh Gupta)
Date: Wed, 7 Jun 2017 18:53:40 +0900
Subject: [R] error while opening vignette DESeq2
Message-ID: <CAAjHrnMSs4CBm0cx77jtEJgHsGJEFUBFPGRkuEN4xX3NQMj8+Q@mail.gmail.com>

Hi ,

I am trying to open vignette DESeq2 but getting below error:

> vignette("DESeq2")
> START /usr/bin/evince "/usr/lib64/R/library/DESeq2/doc/DESeq2.pdf"
Cannot parse arguments: Cannot open display:
xdg-open: no method available for opening
'/usr/lib64/R/library/DESeq2/doc/DESeq2.pdf'

-- 
*Yogesh Gupta*
*Postdoctoral Researcher*
*Department of Biological Science*
*Seoul National University*
*Seoul, South Korea*

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Wed Jun  7 18:35:11 2017
From: hannah.hlx at gmail.com (li li)
Date: Wed, 7 Jun 2017 12:35:11 -0400
Subject: [R] Adding zeros in each dimension of an array
In-Reply-To: <alpine.BSF.2.00.1706070902050.50464@pedal.dcn.davis.ca.us>
References: <CAHLnndbi3akoyNAhjyntBY00gX4ihoJ0Rqcbrbqa46iScbXbjw@mail.gmail.com>
 <alpine.BSF.2.00.1706070902050.50464@pedal.dcn.davis.ca.us>
Message-ID: <CAHLnndbanGrE6O5xWzMos+B9U+YmberpYJpo0H3i-5UUjTppZA@mail.gmail.com>

Thanks! That is the method I am using now but I was checking whether there
is a simpler option. I will look into the abind package too.
   Hanna

2017-06-07 12:25 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> Please read
> https://www.lifewire.com/how-to-send-a-message-in-plain-text
> -from-gmail-1171963
>
> Re your question: easy is in the eye of the beholder.
>
> a <- array( 1:12, dim = c( 2, 2, 3 ) )
> b <- array( 0, dim = dim( a ) + 1 )
> b[ 1:2, 1:2, 1:3 ] <- a
>
> If you want to do a lot of this, it could be wrapped for convenience
> though implementing that last expression without hardcoding the sequences
> may not be obvious:
>
> expandArray <- function( a ) {
>   b <- array( 0, dim = dim( a ) + 1 )
>   do.call( `[<-`, c( list( b ), lapply( dim( a ), seq.int ), list( a ) ) )
> }
> expandArray( a )
>
>
> On Wed, 7 Jun 2017, li li wrote:
>
> For a data frame, we can add an additional row or column easily. For
>> example, we can add an additional row of zero and an additional row of
>> column as follows.
>>
>> Is there an easy and similar way to add zeros in each dimension? For
>> example, for
>> array(1:12, dim=c(2,2,3))?
>>
>> Thanks for your help!!
>>   Hanna
>>
>>
>>
>> x <- as.data.frame(matrix(1:20,4,5))> x[5,] <- 0> x[,6] <- 0> x  V1 V2
>>> V3 V4 V5 V6
>>>
>> 1  1  5  9 13 17  0
>> 2  2  6 10 14 18  0
>> 3  3  7 11 15 19  0
>> 4  4  8 12 16 20  0
>> 5  0  0  0  0  0  0
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jun  7 18:38:06 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 7 Jun 2017 09:38:06 -0700 (PDT)
Subject: [R] purrr::pmap does not work
In-Reply-To: <OFB7AADCC8.966A1660-ONC1258138.004D4D8C-C1258138.00501586@lotus.hawesko.de>
References: <OFB7AADCC8.966A1660-ONC1258138.004D4D8C-C1258138.00501586@lotus.hawesko.de>
Message-ID: <alpine.BSF.2.00.1706070933200.50464@pedal.dcn.davis.ca.us>

A) You are not making reproducible examples. Try out the package "reprex" 
to help you recognize when you are forgetting details.

B) I suspect your problem is not understanding formulas. The first thing 
that comes to my mind is using a version of the plot function that does 
not use formulas for the input data specification. E.g.

graphics::plot(
   dataset[[ xvarname ]],
   dataset[[ yvarname ]],
   xlab = "Dependent",
   ylab = "Independent #1"
)

On Wed, 7 Jun 2017, G.Maubach at weinwolf.de wrote:

> Hi All,
>
> I try to do a scatterplot for a bunch of variables. I plot a dependent
> variable against a bunch of independent variables:
>
> -- cut --
> graphics::plot(
>  v01_r01 ~ v08_01_up11,
>  data = dataset,
>  xlab = "Dependent",
>  ylab = "Independent #1"
> )
>
> -- cut --
>
> It is tedious to repeat the statement for all independent variables. Found
> an alternative, i.e. :
>
> -- cut --
>
> mu <- list(5, 10, -3)
> sigma <- list(1, 5, 10)
> n <- list(1, 3, 5)
> fargs <- list(mean = mu, sd = sigma, n = n)
> fargs %>%
>  purrr::pmap(rnorm) %>%
>  str()
>
> -- cut --
>
> I tried to use this for may scatterplot task:
>
> -- cut --
>
> var_battery$v08 <- paste0("v08_", formatC(1:8, width = 2, format = "d",
> flag = "0"))
> v08_var_labs <- paste0("Label_", 1:8)
>
> dataset <- as.data.frame(
>  matrix(
>    data = sample(
>      x = 1:11,
>      size = 90,
>      replace = TRUE),
>    nrow = 10,
>    ncol = 9))
> names(dataset) <- c("v01_r01", var_battery$v08)
>
> independent <- as.list(dataset$v01_r01)
> dependent <- as.list(dataset[var_battery$v08])
>
> fargs <- list(
>  x = independent,
>  y = dependent,
>  ylab = v08_var_labs)
>
> fargs %>%
>  purrr::pmap(
>    function(d = dataset, xvalue = x, yvalue = y,
>             xlab = "Label for x variable",
>             ylab = ylab) {
>      graphics::plot(
>        xvalue ~ yvalue,
>        data = d,
>        xlab = xlab,
>        ylab = ylab)
>    }
>  )
>
> -- cut --
>
> The last statement comes back with
>
> Error: Element 2 has length 8, not 1 or 10.
>
> How can I get it up n running? Do you suggest a better solution for the
> task described?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Wed Jun  7 18:42:01 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 7 Jun 2017 09:42:01 -0700 (PDT)
Subject: [R] error while opening vignette DESeq2
In-Reply-To: <CAAjHrnMSs4CBm0cx77jtEJgHsGJEFUBFPGRkuEN4xX3NQMj8+Q@mail.gmail.com>
References: <CAAjHrnMSs4CBm0cx77jtEJgHsGJEFUBFPGRkuEN4xX3NQMj8+Q@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1706070940440.50464@pedal.dcn.davis.ca.us>

Sounds like your operating system does not have a default PDF viewer, or 
does not have X-windows installed.

On Wed, 7 Jun 2017, Yogesh Gupta wrote:

> Hi ,
>
> I am trying to open vignette DESeq2 but getting below error:
>
>> vignette("DESeq2")
>> START /usr/bin/evince "/usr/lib64/R/library/DESeq2/doc/DESeq2.pdf"
> Cannot parse arguments: Cannot open display:
> xdg-open: no method available for opening
> '/usr/lib64/R/library/DESeq2/doc/DESeq2.pdf'
>
> -- 
> *Yogesh Gupta*
> *Postdoctoral Researcher*
> *Department of Biological Science*
> *Seoul National University*
> *Seoul, South Korea*
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Wed Jun  7 18:45:05 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 7 Jun 2017 09:45:05 -0700 (PDT)
Subject: [R] Problem related to rowSums
In-Reply-To: <CAAjHrnO6iQMM7UJ5qswT1iE95sjvn8gfbgV5D9HPx8oXbFKQ5A@mail.gmail.com>
References: <CAAjHrnO6iQMM7UJ5qswT1iE95sjvn8gfbgV5D9HPx8oXbFKQ5A@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1706070942240.50464@pedal.dcn.davis.ca.us>

I don't understand "zero raw read count across all column".

Please read the Posting Guide (mentioned below) which points out that this 
is a plain text mailing list (your email gets damaged to varying degrees 
if you don't set your sending format to plain text), and you need to make 
your example reproducible (look up the package "reprex") to clearly 
communicate your problem.

On Wed, 7 Jun 2017, Yogesh Gupta wrote:

> Hi...
>
> I have a dataframe with n columns and n rows. I need to find how many rows
> contains zero raw read count across all column.
>
> Thanks
>
> -- 
> *Yogesh Gupta*
> *Postdoctoral Researcher*
> *Department of Biological Science*
> *Seoul National University*
> *Seoul, South Korea*
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From suharto_anggono at yahoo.com  Wed Jun  7 18:33:53 2017
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Wed, 7 Jun 2017 16:33:53 +0000 (UTC)
Subject: [R] Another way to count TRUE
References: <404940310.3782437.1496853233928.ref@mail.yahoo.com>
Message-ID: <404940310.3782437.1496853233928@mail.yahoo.com>

To get the number of TRUE in logical vector 'x',
tabulate(x, 1)
can be used. Actually, it gives count of 1, but TRUE as integer is 1. Since R 3.4.0, it gives a correct answer, too, when the count is 2^31 or more.


From bgunter.4567 at gmail.com  Wed Jun  7 20:09:43 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 7 Jun 2017 11:09:43 -0700
Subject: [R] Another way to count TRUE
In-Reply-To: <404940310.3782437.1496853233928@mail.yahoo.com>
References: <404940310.3782437.1496853233928.ref@mail.yahoo.com>
 <404940310.3782437.1496853233928@mail.yahoo.com>
Message-ID: <CAGxFJbSvYLcf19haEX+0WpbKsBCVq_9DzTWL=9sgNzE+vAun1w@mail.gmail.com>

Bad idea!

In R3.3.3 it doesn't even work:

> y1 <- tabulate(x,1)
Error in tabulate(x, 1) : 'bin' must be numeric or a factor

## This does:
>  y1 <- tabulate(as.integer(x),1)

But it's more inefficient than just using sum(), even discounting the
as.integer() conversion:

> y1 <- tabulate(as.integer(x),1)
> y2 <- sum(x)
> identical(y1,y2)
[1] TRUE

> xx <- as.integer(x)
> system.time(replicate(12,tabulate(xx,1)))
   user  system elapsed
  2.488   0.003   2.491
> system.time(replicate(12,sum(x)))
   user  system elapsed
  0.626   0.001   0.627

Were you simply unaware of sum() or was there some other reason for
your recommendation?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 7, 2017 at 9:33 AM, Suharto Anggono Suharto Anggono via
R-help <r-help at r-project.org> wrote:
> To get the number of TRUE in logical vector 'x',
> tabulate(x, 1)
> can be used. Actually, it gives count of 1, but TRUE as integer is 1. Since R 3.4.0, it gives a correct answer, too, when the count is 2^31 or more.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ccberry at ucsd.edu  Wed Jun  7 21:06:09 2017
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Wed, 7 Jun 2017 12:06:09 -0700
Subject: [R] Determining which.max() within groups
In-Reply-To: <CAPoqHzoYUoeQs+frqSA1VTGcyC2_6gepAYDDWEDUgM364i6Mzg@mail.gmail.com>
References: <CAPoqHzoYUoeQs+frqSA1VTGcyC2_6gepAYDDWEDUgM364i6Mzg@mail.gmail.com>
Message-ID: <alpine.OSX.2.20.1706071156560.21534@charles-berrys-macbook.local>

On Tue, 6 Jun 2017, Morway, Eric wrote:

> Using the dataset below, I got close to what I'm after, but not quite all
> the way there.  Any suggestions appreciated:
>
> Daily <- read.table(textConnection("     Date  wyr        Q
> 1911-04-01 1990 4.530695
> 1911-04-02 1990 4.700596
> 1911-04-03 1990 4.898814
> 1911-04-04 1990 5.097032
> 1911-04-05 1991 5.295250
> 1911-04-06 1991 6.569508
> 1911-04-07 1991 5.861587
> 1911-04-08 1991 5.153666
> 1911-04-09 1992 4.445745
> 1911-04-10 1992 3.737824
> 1911-04-11 1992 3.001586
> 1911-04-12 1992 3.001586
> 1911-04-13 1993 2.350298
> 1911-04-14 1993 2.661784
> 1911-04-16 1993 3.001586
> 1911-04-17 1993 2.661784
> 1911-04-19 1994 2.661784
> 1911-04-28 1994 3.369705
> 1911-04-29 1994 3.001586
> 1911-05-20 1994 2.661784"),header=TRUE)
>
> aggregate(Q ~ wyr, data = Daily, which.max)
>
> # gives:
> #    wyr Q
> # 1 1990 4
> # 2 1991 2
> # 3 1992 1
> # 4 1993 3
> # 5 1994 2
>
> I can 'see' that it is returning the which.max() relative to each
> grouping.  Is there a way to instead return the absolute position (row) of
> the max value within each group.  i.e.:
>
> # Would instead like to have
> #     wyr  Q
> # 1  1990  4
> # 2  1991  6
> # 3  1992  9
> # 4  1993  15
> # 5  1994  18
>
> The icing on the cake would be to get the Julien Day corresponding to the
> date on which each year's maximum occurs?
>


Like this:

> which.max.by.wyr <- with(Daily, which( ave( Q, wyr, FUN=max) == Q))
> cbind( Daily[ which.max.by.wyr, ], index=which.max.by.wyr )
          Date  wyr        Q index
4  1911-04-04 1990 5.097032     4
6  1911-04-06 1991 6.569508     6
9  1911-04-09 1992 4.445745     9
15 1911-04-16 1993 3.001586    15
18 1911-04-28 1994 3.369705    18

If there are ties in Q and you do not want more than one max value listed, 
you can add a litle fuzz to randomly pick one. i.e.

> fuzz <- runif(nrow(Daily), 0, 1e-10)
> which.max.by.wyr <- with(Daily, which(ave(Q+fuzz,wyr,FUN=max)==Q+fuzz))


If you want the first tied value, then sort fuzz before determining 
which.max.by.wyr.

HTH,

Chuck


From mazatlanmexico at yahoo.com  Wed Jun  7 22:48:24 2017
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Wed, 7 Jun 2017 20:48:24 +0000
Subject: [R] Time series axis breaks
References: <196519365.4786624.1496868504568.ref@mail.yahoo.com>
Message-ID: <196519365.4786624.1496868504568@mail.yahoo.com>

I hope this is the appropriate list for this type of question
Consider the dataset below:I have a column DOC with values from 3 to 101and those are the values that I want to show on my x axis, howeverI only get 3, 3.1, 3.2 and so on. I tried to change those values with xlim(3, 101) but I getthe following error:Error in unit(x, default.units) : 'x' and 'units' must have length > 0
question: Which argument is needed in the ts() call to make the x axis showbreaks every 7 days starting with 3?
wt <- structure(list(DOC = c(3, 10, 17, 24, 31, 38, 45, 52, 59, 66,?73, 80, 87, 94, 101), AvgWeight = c(1, 1.66666666666667, 2.06666666666667,?2.275, 3.83333333333333, 6.2, 7.4, 8.5, 10.25, 11.1, 13.625,?15.2, 16.375, 17.8, 21.5), PondName = structure(c(1L, 1L, 1L,?1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "Pond01", class = "factor"),?? ? SampleDate = structure(c(1182585600, 1183190400, 1183795200,?? ? 1184400000, 1185004800, 1185609600, 1186214400, 1186819200,?? ? 1187424000, 1188028800, 1188633600, 1189238400, 1189843200,?? ? 1190448000, 1191052800), class = c("POSIXct", "POSIXt"))), .Names = c("DOC",?"AvgWeight", "PondName", "SampleDate"), row.names = c(NA, 15L), class = "data.frame") ?
wt$SampleDate <- as.Date(wt$SampleDate) ?wt
library(forecast)library(ggplot2)pond <- ts(wt$AvgWeight,start=3,frequency=52)pond?d.arima <- auto.arima(pond)d.forecast <- forecast(d.arima, level = c(95), h = 3)d.forecast

autoplot(d.forecast) + xlim(7, 101)Error in unit(x, default.units) : 'x' and 'units' must have length > 0

Take a look at the attached plot
-------------- next part --------------
A non-text attachment was scrubbed...
Name: timeseries.png
Type: image/png
Size: 4042 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170607/e7b0789e/attachment.png>

From macqueen1 at llnl.gov  Thu Jun  8 00:12:24 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 7 Jun 2017 22:12:24 +0000
Subject: [R] purrr::pmap does not work
In-Reply-To: <OFB7AADCC8.966A1660-ONC1258138.004D4D8C-C1258138.00501586@lotus.hawesko.de>
References: <OFB7AADCC8.966A1660-ONC1258138.004D4D8C-C1258138.00501586@lotus.hawesko.de>
Message-ID: <B41DF8A5-F837-4A30-9353-A570ED2E26A5@llnl.gov>

You might try
   matplot()

example:
x <- matrix(rnorm(30), ncol=3)

## plot a dependent variable (1:10) against a bunch of independent variables (the three columns of x)
matplot(x , 1:10, type='b')

## or a bunch of dependent variables (the three columns of x) against an independent variable (1:10)
matplot(1:10,  x, type='b')

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 6/7/17, 7:34 AM, "R-help on behalf of G.Maubach at weinwolf.de" <r-help-bounces at r-project.org on behalf of G.Maubach at weinwolf.de> wrote:

    Hi All,
    
    I try to do a scatterplot for a bunch of variables. I plot a dependent 
    variable against a bunch of independent variables:
    
    -- cut --
    graphics::plot(
      v01_r01 ~ v08_01_up11,
      data = dataset,
      xlab = "Dependent",
      ylab = "Independent #1"
    )
    
    -- cut --
    
    It is tedious to repeat the statement for all independent variables. Found 
    an alternative, i.e. :
    
    -- cut --
    
    mu <- list(5, 10, -3)
    sigma <- list(1, 5, 10)
    n <- list(1, 3, 5)
    fargs <- list(mean = mu, sd = sigma, n = n)
    fargs %>%
      purrr::pmap(rnorm) %>%
      str()
    
    -- cut --
    
    I tried to use this for may scatterplot task:
    
    -- cut --
    
    var_battery$v08 <- paste0("v08_", formatC(1:8, width = 2, format = "d", 
    flag = "0"))
    v08_var_labs <- paste0("Label_", 1:8)
    
    dataset <- as.data.frame(
      matrix(
        data = sample(
          x = 1:11,
          size = 90,
          replace = TRUE),
        nrow = 10,
        ncol = 9))
    names(dataset) <- c("v01_r01", var_battery$v08)
    
    independent <- as.list(dataset$v01_r01)
    dependent <- as.list(dataset[var_battery$v08])
    
    fargs <- list(
      x = independent,
      y = dependent,
      ylab = v08_var_labs)
    
    fargs %>% 
      purrr::pmap(
        function(d = dataset, xvalue = x, yvalue = y,
                 xlab = "Label for x variable",
                 ylab = ylab) {
          graphics::plot(
            xvalue ~ yvalue,
            data = d,
            xlab = xlab,
            ylab = ylab)
        }
      )
    
    -- cut --
    
    The last statement comes back with
    
    Error: Element 2 has length 8, not 1 or 10.
    
    How can I get it up n running? Do you suggest a better solution for the 
    task described?
    
    Kind regards
    
    Georg
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From r.turner at auckland.ac.nz  Thu Jun  8 00:40:36 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 8 Jun 2017 10:40:36 +1200
Subject: [R] [FORGED]  Problem related to rowSums
In-Reply-To: <CAAjHrnO6iQMM7UJ5qswT1iE95sjvn8gfbgV5D9HPx8oXbFKQ5A@mail.gmail.com>
References: <CAAjHrnO6iQMM7UJ5qswT1iE95sjvn8gfbgV5D9HPx8oXbFKQ5A@mail.gmail.com>
Message-ID: <392b74cd-0636-48c1-9269-aa6323e90c89@auckland.ac.nz>


On 07/06/17 21:08, Yogesh Gupta wrote:

> Hi...
> 
> I have a dataframe with n columns and n rows. I need to find how many rows
> contains zero raw read count across all column.

(1) You should probably have a *matrix*, not a data frame.

(2) Have you ever heard of the idea of providing a *reproducible* example?

(3) I *think* the following may be what you want/need:

M <- as.matrix(M) # Where the initial M is your "data frame".
sum(apply(M,1,function(x){isTRUE(all.equal(x,rep(0,length(x))))}))

Untested, since you did not supply a reproducible example.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From macqueen1 at llnl.gov  Thu Jun  8 01:57:51 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 7 Jun 2017 23:57:51 +0000
Subject: [R] rmarkdown and font size
Message-ID: <08E5EBA9-4C89-4376-9F39-E6A59D204FB9@llnl.gov>

Suppose I have a file (named "tmp.rmd") containing:


---
title: Test
---

```{r example, echo=FALSE, results='asis'}
tmp <- data.frame(a=1:5, b=letters[1:5])
print( knitr::kable(tmp, row.names=FALSE))
```



And I render it with:

rmarkdown::render('tmp.rmd', output_format=c('html_document','pdf_document'))

I get two files:
  tmp.pdf
  tmp.html

Is there a way to control (change or specify) the font size of the table in the pdf output?
(or of the entire document, if it can't be changed for just the table)

With my actual data, the table is too wide to fit on a page in the pdf output; perhaps if I reduce the font size I can get it to fit.

I would like the html version to still look decent, but I don't care very much what happens to its font size.

Thanks!
-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062



From suharto_anggono at yahoo.com  Wed Jun  7 23:52:24 2017
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Wed, 7 Jun 2017 21:52:24 +0000 (UTC)
Subject: [R] Another way to count TRUE
References: <342536443.4065449.1496872344471.ref@mail.yahoo.com>
Message-ID: <342536443.4065449.1496872344471@mail.yahoo.com>

Ah, yes, of course.
tabulate(x, 1)
doesn't work, too, in R 3.4.0. Sorry, I didn't actually try.

I thought of an alternative when TRUE count is 2^31 or more. sum(x) returns NA with a warning. sum(as.numeric(x)) works, but requires a quite large memory.

--------------------------------------------
On Thu, 8/6/17, Bert Gunter <bgunter.4567 at gmail.com> wrote:

 Subject: Re: [R] Another way to count TRUE

 Cc: "R-help" <r-help at r-project.org>
 Date: Thursday, 8 June, 2017, 1:09 AM

 Bad idea!

 In R3.3.3 it doesn't even work:

 > y1 <- tabulate(x,1)
 Error in tabulate(x, 1) : 'bin' must be
 numeric or a factor

 ## This
 does:
 >? y1 <-
 tabulate(as.integer(x),1)

 But it's more inefficient than just using
 sum(), even discounting the
 as.integer()
 conversion:

 > y1 <-
 tabulate(as.integer(x),1)
 > y2 <-
 sum(x)
 > identical(y1,y2)
 [1] TRUE

 >
 xx <- as.integer(x)
 >
 system.time(replicate(12,tabulate(xx,1)))
 ?
  user? system elapsed
 ? 2.488?  0.003? 
 2.491
 >
 system.time(replicate(12,sum(x)))
 ?  user?
 system elapsed
 ? 0.626?  0.001?  0.627

 Were you simply unaware of
 sum() or was there some other reason for
 your recommendation?

 Cheers,
 Bert


 Bert
 Gunter

 "The trouble
 with having an open mind is that people keep coming along
 and sticking things into it."
 -- Opus (aka Berkeley Breathed in his
 "Bloom County" comic strip )


 On Wed, Jun 7, 2017 at 9:33 AM, Suharto Anggono
 Suharto Anggono via
 R-help <r-help at r-project.org>
 wrote:
 > To get the number of TRUE in
 logical vector 'x',
 > tabulate(x,
 1)
 > can be used. Actually, it gives
 count of 1, but TRUE as integer is 1. Since R 3.4.0, it
 gives a correct answer, too, when the count is 2^31 or
 more.
 >
 >
 ______________________________________________
 > R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal,
 self-contained, reproducible code.


From syen04 at gmail.com  Thu Jun  8 05:50:55 2017
From: syen04 at gmail.com (Steven Yen)
Date: Thu, 8 Jun 2017 11:50:55 +0800
Subject: [R] Matrix multiplication
In-Reply-To: <f1de81cd-9907-1782-2801-19556db2b91b@gmail.com>
References: <f1de81cd-9907-1782-2801-19556db2b91b@gmail.com>
Message-ID: <58e5630e-3274-b4ac-6e76-e4e8a46713d4@gmail.com>

I need to have all elements of a matrix multiplied by a weight before 
being post-multiplied by itself, as shown in the forst block of codes 
below. I can also multiply the matrix by the square root of the weight 
and then take the outer product.

Actually, what I need is this. Denote each row of the matrix by a row 
vector as xi and each element of the weighting vector as wi. Then, I 
need the sum of wi * t(xi) %*% xi over i.

Any suggestion for a compact approach would be appreciated.

set.seed(76543211)
w<-1:10; w
a<-matrix(rpois(20,2),nrow=10); a
b<-a
a<-w*a
t(a)%*%b

set.seed(76543211)
a<-matrix(rpois(20,2),nrow=10); a
a<-sqrt(w)*a; a
t(a)%*%a




On 1/4/2017 5:41 PM, Steven Yen wrote:
> I need help with gls{nlme}.
> Specifically, I am estimating an equation with AR(1) using 
> maximum-likelihood. I am not understanding the correlationoption 
> below. Help appreciated.
>
> ===
> library(nlme)
> eq1<-log(chnimp)~log(chempi)+log(gas)+log(rtwex)+befile6+
>                  affile6+afdec6
> reg1<-gls(eq1,data=mydata,correlation=corAR1(),method="ML",verbose=T)
>

	[[alternative HTML version deleted]]


From mazatlanmexico at yahoo.com  Thu Jun  8 05:57:28 2017
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Thu, 8 Jun 2017 03:57:28 +0000 (UTC)
Subject: [R] time series x axis labels
References: <1390337507.5025642.1496894248776.ref@mail.yahoo.com>
Message-ID: <1390337507.5025642.1496894248776@mail.yahoo.com>

I hope this is the appropriate list for this type of question
Consider the dataset below:I have a column DOC with values from 3 to 101and those are the values that I want to show on my x axis, howeverI only get 3, 3.1, 3.2 and so on. I tried to change those values with xlim(3, 101) but I getthe following error:Error in unit(x, default.units) : 'x' and 'units' must have length > 0
question: Which argument is needed in the ts() call to make the x axis showbreaks every 7 days starting with 3?
wt <- structure(list(DOC = c(3, 10, 17, 24, 31, 38, 45, 52, 59, 66,?73, 80, 87, 94, 101), AvgWeight = c(1, 1.66666666666667, 2.06666666666667,?2.275, 3.83333333333333, 6.2, 7.4, 8.5, 10.25, 11.1, 13.625,?15.2, 16.375, 17.8, 21.5), PondName = structure(c(1L, 1L, 1L,?1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "Pond01", class = "factor"),?? ? SampleDate = structure(c(1182585600, 1183190400, 1183795200,?? ? 1184400000, 1185004800, 1185609600, 1186214400, 1186819200,?? ? 1187424000, 1188028800, 1188633600, 1189238400, 1189843200,?? ? 1190448000, 1191052800), class = c("POSIXct", "POSIXt"))), .Names = c("DOC",?"AvgWeight", "PondName", "SampleDate"), row.names = c(NA, 15L), class = "data.frame") ?
wt$SampleDate <- as.Date(wt$SampleDate) ?wt
library(forecast)library(ggplot2)pond <- ts(wt$AvgWeight,start=3,frequency=52)pond?d.arima <- auto.arima(pond)d.forecast <- forecast(d.arima, level = c(95), h = 3)d.forecast

autoplot(d.forecast) + xlim(7, 101)Error in unit(x, default.units) : 'x' and 'units' must have length > 0

Take a look at the attached plot

-------------- next part --------------
A non-text attachment was scrubbed...
Name: timeseries.png
Type: image/png
Size: 4042 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170608/7633f1ea/attachment.png>

From jdnewmil at dcn.davis.ca.us  Thu Jun  8 06:09:38 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 07 Jun 2017 21:09:38 -0700
Subject: [R] Matrix multiplication
In-Reply-To: <58e5630e-3274-b4ac-6e76-e4e8a46713d4@gmail.com>
References: <f1de81cd-9907-1782-2801-19556db2b91b@gmail.com>
 <58e5630e-3274-b4ac-6e76-e4e8a46713d4@gmail.com>
Message-ID: <C7BD4B95-CC69-4B37-A226-5CF0273FC430@dcn.davis.ca.us>

Is this a question? You seem to have three possible calculations, have already implemented two of them (?) and it is unclear (to me) what you think the right answer for any of them is supposed to be. 
-- 
Sent from my phone. Please excuse my brevity.

On June 7, 2017 8:50:55 PM PDT, Steven Yen <syen04 at gmail.com> wrote:
>I need to have all elements of a matrix multiplied by a weight before 
>being post-multiplied by itself, as shown in the forst block of codes 
>below. I can also multiply the matrix by the square root of the weight 
>and then take the outer product.
>
>Actually, what I need is this. Denote each row of the matrix by a row 
>vector as xi and each element of the weighting vector as wi. Then, I 
>need the sum of wi * t(xi) %*% xi over i.
>
>Any suggestion for a compact approach would be appreciated.
>
>set.seed(76543211)
>w<-1:10; w
>a<-matrix(rpois(20,2),nrow=10); a
>b<-a
>a<-w*a
>t(a)%*%b
>
>set.seed(76543211)
>a<-matrix(rpois(20,2),nrow=10); a
>a<-sqrt(w)*a; a
>t(a)%*%a
>
>
>
>
>On 1/4/2017 5:41 PM, Steven Yen wrote:
>> I need help with gls{nlme}.
>> Specifically, I am estimating an equation with AR(1) using 
>> maximum-likelihood. I am not understanding the correlationoption 
>> below. Help appreciated.
>>
>> ===
>> library(nlme)
>> eq1<-log(chnimp)~log(chempi)+log(gas)+log(rtwex)+befile6+
>>                  affile6+afdec6
>> reg1<-gls(eq1,data=mydata,correlation=corAR1(),method="ML",verbose=T)
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Thu Jun  8 06:16:48 2017
From: syen04 at gmail.com (Steven Yen)
Date: Thu, 8 Jun 2017 12:16:48 +0800
Subject: [R] Matrix multiplication
In-Reply-To: <C7BD4B95-CC69-4B37-A226-5CF0273FC430@dcn.davis.ca.us>
References: <f1de81cd-9907-1782-2801-19556db2b91b@gmail.com>
 <58e5630e-3274-b4ac-6e76-e4e8a46713d4@gmail.com>
 <C7BD4B95-CC69-4B37-A226-5CF0273FC430@dcn.davis.ca.us>
Message-ID: <11861cc7-f91c-50e6-c832-131d4b04b15b@gmail.com>

OK Thanks. Your response made me think. Here (the last line) is what I need:

set.seed(76543211)
w<-1:10; w
a<-matrix(rpois(20,2),nrow=10); a
t(w*a)%*%a

On 6/8/2017 12:09 PM, Jeff Newmiller wrote:
> Is this a question? You seem to have three possible calculations, have already implemented two of them (?) and it is unclear (to me) what you think the right answer for any of them is supposed to be.
> -- Sent from my phone. Please excuse my brevity. On June 7, 2017 
> 8:50:55 PM PDT, Steven Yen <syen04 at gmail.com> wrote:
>> I need to have all elements of a matrix multiplied by a weight before
>> being post-multiplied by itself, as shown in the forst block of codes
>> below. I can also multiply the matrix by the square root of the weight
>> and then take the outer product.
>>
>> Actually, what I need is this. Denote each row of the matrix by a row
>> vector as xi and each element of the weighting vector as wi. Then, I
>> need the sum of wi * t(xi) %*% xi over i.
>>
>> Any suggestion for a compact approach would be appreciated.
>>
>> set.seed(76543211)
>> w<-1:10; w
>> a<-matrix(rpois(20,2),nrow=10); a
>> b<-a
>> a<-w*a
>> t(a)%*%b
>>
>> set.seed(76543211)
>> a<-matrix(rpois(20,2),nrow=10); a
>> a<-sqrt(w)*a; a
>> t(a)%*%a


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Jun  8 06:33:28 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 07 Jun 2017 21:33:28 -0700
Subject: [R] Matrix multiplication
In-Reply-To: <11861cc7-f91c-50e6-c832-131d4b04b15b@gmail.com>
References: <f1de81cd-9907-1782-2801-19556db2b91b@gmail.com>
 <58e5630e-3274-b4ac-6e76-e4e8a46713d4@gmail.com>
 <C7BD4B95-CC69-4B37-A226-5CF0273FC430@dcn.davis.ca.us>
 <11861cc7-f91c-50e6-c832-131d4b04b15b@gmail.com>
Message-ID: <92BA4884-6B2A-4E3B-85CA-B24BDC5ED839@dcn.davis.ca.us>

Fine,  except that you already seen to have a very compact solution if that really is what you are looking for. What am I missing? 
-- 
Sent from my phone. Please excuse my brevity.

On June 7, 2017 9:16:48 PM PDT, Steven Yen <syen04 at gmail.com> wrote:
>OK Thanks. Your response made me think. Here (the last line) is what I
>need:
>
>set.seed(76543211)
>w<-1:10; w
>a<-matrix(rpois(20,2),nrow=10); a
>t(w*a)%*%a
>
>On 6/8/2017 12:09 PM, Jeff Newmiller wrote:
>> Is this a question? You seem to have three possible calculations,
>have already implemented two of them (?) and it is unclear (to me) what
>you think the right answer for any of them is supposed to be.
>> -- Sent from my phone. Please excuse my brevity. On June 7, 2017 
>> 8:50:55 PM PDT, Steven Yen <syen04 at gmail.com> wrote:
>>> I need to have all elements of a matrix multiplied by a weight
>before
>>> being post-multiplied by itself, as shown in the forst block of
>codes
>>> below. I can also multiply the matrix by the square root of the
>weight
>>> and then take the outer product.
>>>
>>> Actually, what I need is this. Denote each row of the matrix by a
>row
>>> vector as xi and each element of the weighting vector as wi. Then, I
>>> need the sum of wi * t(xi) %*% xi over i.
>>>
>>> Any suggestion for a compact approach would be appreciated.
>>>
>>> set.seed(76543211)
>>> w<-1:10; w
>>> a<-matrix(rpois(20,2),nrow=10); a
>>> b<-a
>>> a<-w*a
>>> t(a)%*%b
>>>
>>> set.seed(76543211)
>>> a<-matrix(rpois(20,2),nrow=10); a
>>> a<-sqrt(w)*a; a
>>> t(a)%*%a


From marc_grt at yahoo.fr  Thu Jun  8 06:54:26 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Thu, 8 Jun 2017 06:54:26 +0200
Subject: [R] stepAIC() that can use new extractAIC() function implementing
	AICc
Message-ID: <0f14e04c-38c9-672b-36e5-520559c8e612@yahoo.fr>

I would like test AICc as a criteria for model selection for a glm using 
stepAIC() from MASS package.

Based on various information available in WEB, stepAIC() use 
extractAIC() to get the criteria used for model selection.

I have created a new extractAIC() function (and extractAIC.glm() and 
extractAIC.lm() ones) that use a new parameter criteria that can be AIC, 
BIC or AICc.

It works as expected using extractAIC() but when I run stepAIC(), the 
first AIC shown in the result is correct, but after it still shows the 
original AIC:

For example (the full code is below) the "Start:  AIC=70.06" is indeed 
the AICc but after, "<none>      47.548 67.874" is the AIC.

 > stepAIC(G1, criteria="AICc")
Start:  AIC=70.06
x ~ A + B

        Df Deviance    AIC
- A     1   48.506 66.173
<none>      47.548 67.874
- B     1   57.350 68.685

Thanks if you can help me that stepAIC() use always the new extractAIC() 
function.

Marc




library("MASS")
set.seed(1)

df <- data.frame(x=rnorm(15, 15, 2))
for (i in 1:10) {
   df <- cbind(df, matrix(data = rnorm(15, 15, 2), ncol=1, 
dimnames=list(NULL, LETTERS[i])))
}

G1 <- glm(formula = x ~ A + B,
           data=df, family = gaussian(link = "identity"))

extractAIC(G1)
stepAIC(G1)

extractAIC.glm <- function(fit, scale, k = 2, criteria = c("AIC", 
"AICc", "BIC"), ...) {
   criteria <- match.arg(arg=criteria, choice=c("AIC", "AICc", "BIC"))
   AIC <- fit$aic
   edf <- length(fit$coefficients)
   n <- nobs(fit, use.fallback = TRUE)
   if (criteria == "AICc") return(c(edf, AIC + (2*edf*(edf+1))/(n - edf 
-1)))
   if (criteria == "AIC")  return(c(edf, AIC-2*edf + k*edf))
   if (criteria == "BIC")  return(c(edf, AIC -2*edf + log(n)*edf))
}

extractAIC <- extractAIC.lm <- extractAIC.glm

extractAIC(G1, criteria="AIC")
extractAIC(G1, k=log(15))
extractAIC(G1, criteria="BIC")
stats:::extractAIC.glm(G1, k=log(15))
extractAIC(G1, criteria="AICc")

stepAIC(G1)
stepAIC(G1, criteria="AICc")


From marc_grt at yahoo.fr  Thu Jun  8 10:34:16 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Thu, 8 Jun 2017 10:34:16 +0200
Subject: [R] stepAIC() that can use new extractAIC() function
 implementing AICc
In-Reply-To: <0f14e04c-38c9-672b-36e5-520559c8e612@yahoo.fr>
References: <0f14e04c-38c9-672b-36e5-520559c8e612@yahoo.fr>
Message-ID: <69230901-577f-ebb9-357f-4064fa3b52e6@yahoo.fr>

I have found the problem and a solution.

The problem comes from the functions addterm.glm() and dropterm.glm() 
from MASS package. They use extractAIC() without transmitting the ... 
argument:

aic <- aic + (extractAIC(object, k = k)[2L] - aic[1L])

I replace the call with:
aic <- aic + (extractAIC(object, k = k, ...)[2L] - aic[1L])

and I create dropterm.glm() and addterm.glm() in global environnement.
I add:
dropterm <- dropterm.lm <- dropterm.glm
addterm <- addterm.lm <- addterm.glm

I copy also stepAIC from MASS package to global environnement.
I detach MASS package, and it works:

 > stepAIC(G1, criteria="AICc", steps = 1)
Start:  AIC=70.06
x ~ A + B

        Df Deviance    AIC
- A     1   48.506 68.355
<none>      47.548 70.055
- B     1   57.350 70.867

Now stepAIC can use AICc

Marc


From sai.sathvick96 at gmail.com  Thu Jun  8 07:34:25 2017
From: sai.sathvick96 at gmail.com (Sai Sathvick)
Date: Thu, 8 Jun 2017 11:04:25 +0530
Subject: [R] help regarding r-project
Message-ID: <CAH9yqxPZLib-wvWAcGrbqthoZyzPXQ7ypezv46iUkKQ8630Ucg@mail.gmail.com>

hello sir/ma'am,

                        trying to build a small prototype of resume filter
 but not able to get expected intercept values, could you please help
regarding this project ASAP.

to predict,  skills + experience =result

-- 
*With Regards,*
*C Sai Sathvick*

From ashimkapoor at gmail.com  Thu Jun  8 11:56:15 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Thu, 8 Jun 2017 15:26:15 +0530
Subject: [R] regular expression help
Message-ID: <CAC8=1epoYDyr5tXZAL482+Gb43uLxnQ=z8SU8d_NOd6oPe6gPQ@mail.gmail.com>

Dear All,

My query is:

Do we always need to use perl = TRUE option when doing ignore.case=TRUE?

A small example :

my_text =
"RECOVERY OFFICER-II\nDEBTS RECOVERY TRIBUNAL-III\n  RC No. 162/2015\nSBI
VS RAMESH GUPTA.\n    Dated: 01.03.2016                   Item no.01\n
Present:   Ms. Sonakshi, the proxy counsel for Ms. Usha Singh, the counsel
for ARCIL.\n                None for the CDs.\n  The counsel for the CHFI
submitted that the matter has been assigned to ARCIL and deed of
assignment, application for substituting the name and vakalatnama has been
filed vide diary no. 1454 dated 08.02.2016\nIn the application it has been
prayed that ARCIL may be substituted in place of SBI for the purpose of
further proceedings in the matter. Request allowed.\nThe proxy counsel for
CHFI further requested to issue demand notice thereby mentioning the name
of ARCIL. Request allowed.\nRegistry is directed to issue fresh demand
notice mentioning the name of ARCIL.\nCHFI is directed to file status of
the mortgaged property as well as other assets of the CDs.\nList the case
on 28.03.2016.\n  (SUJEET KUMAR)\nRECOVERY OFFICER-II."

My regular expression is:

parties_present_start_1=
regexpr("\n.*Present.*\n.*\n",my_text,ignore.case=TRUE,perl=T)

parties_present_start_2=
regexpr("\n.*Present.*\n.*\n",my_text,ignore.case=TRUE)

> parties_present_start_1
[1] 138
attr(,"match.length")
[1] 123
attr(,"useBytes")
[1] TRUE
> parties_present_start_2
[1] 20
attr(,"match.length")
[1] 949
attr(,"useBytes")
[1] TRUE
>

Why do I see the correct result only in the first case?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From Mohan.Radhakrishnan at cognizant.com  Thu Jun  8 12:02:03 2017
From: Mohan.Radhakrishnan at cognizant.com (Mohan.Radhakrishnan at cognizant.com)
Date: Thu, 8 Jun 2017 10:02:03 +0000
Subject: [R] Operating on RC in a list
In-Reply-To: <E1B160F4999FD6449524E16C2CB94E031F90F19C@CTSINCHNSXMBE.cts.com>
References: <E1B160F4999FD6449524E16C2CB94E031F90F19C@CTSINCHNSXMBE.cts.com>
Message-ID: <E1B160F4999FD6449524E16C2CB94E031F90F3F4@CTSINCHNSXMBE.cts.com>

I am replying to my question.
AFAIK dplyr works only with data frames.

So I flattened the RC's like this. A pure OO approach and a functional representation of it are at loggerheads. I think.

                                  filteredmeasurements <-
                                  keep(measurements, function(x){
                                                       x$getid() == subject$getid()
                                                       })
                                  groupedmeasurements <-
                                         filteredmeasurements %>% lapply(function(x){
                                                       m <<- x$getmeasurement()
                                                       as.data.frame(list('visit'=m$getvisit(),
                                                                                      'location'=x$getlocation()$getlocation(),
                                                                                         'amount'=m$getquantity()$amount))
                                                }) %>% rbind_all()
                                  dataColumns <- c('amount')
                                  ddply(groupedmeasurements,c('visit','location'),function(x) colSums(x[dataColumns]))



Thanks,
Mohan

From: Radhakrishnan, Mohan (Cognizant)
Sent: Wednesday, June 07, 2017 2:05 PM
To: r-help at r-project.org
Subject: Operating on RC in a list

Hi,

I have a hierarchy of such classes. Subject has a list of measurements. Let assume I have a list of such 'Subject' RC's.

Can I use dplyr to navigate from Subject to the list of measurement RC's and filter and group data ? dplyr should
be able to call the methods on these RC's to operate on the data structure ?

I tried to coerce the list of RC's into a data frame unsuccessfully. But dplyr should be able to work with lists too. Right ?


Subject <- setRefClass("Subject",
fields = list( id = "numeric",
measurement = "Measurement",
location = "Location"),
methods=list(getmeasurement = function()
{
measurement
},
getid = function()
{
id
},
getlocation = function()
{
location
},
summary = function()#Implement other summary methods in appropriate objects as per their responsibilities
{
paste("Subject summary ID [",id,"] Location [",location$summary(),"]")
},show = function(){
cat("Subject summary ID [",id,"] Location [",location$summary(),"]\n")
})
)


Thanks,
Mohan
This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Thu Jun  8 12:57:52 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 8 Jun 2017 11:57:52 +0100
Subject: [R] help regarding r-project
In-Reply-To: <CAH9yqxPZLib-wvWAcGrbqthoZyzPXQ7ypezv46iUkKQ8630Ucg@mail.gmail.com>
References: <CAH9yqxPZLib-wvWAcGrbqthoZyzPXQ7ypezv46iUkKQ8630Ucg@mail.gmail.com>
Message-ID: <88b829c3-a1ae-39bf-d779-1ae7af9ca1ab@dewey.myzen.co.uk>

I do not think anyone is going to be able to help you unless you can 
provide a reproducible example with a clear account of what it dies and 
what you expected it to do.

On 08/06/2017 06:34, Sai Sathvick wrote:
> hello sir/ma'am,
>
>                         trying to build a small prototype of resume filter
>  but not able to get expected intercept values, could you please help
> regarding this project ASAP.
>
> to predict,  skills + experience =result
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From G.Maubach at weinwolf.de  Thu Jun  8 13:15:55 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 8 Jun 2017 13:15:55 +0200
Subject: [R] Paths in knitr
Message-ID: <OFE37F0A6B.835B65D9-ONC1258139.003D3941-C1258139.003DE23D@lotus.hawesko.de>

Hi All,

I have to compile a report for the management and decided to use RMarkdown 
and knitr. I compiled all needed plots (using separate R scripts) before 
compiling the report, thus all plots reside in my graphics directory. The 
RMarkdown report needs to access these files. I have defined

```{r setup, include = FALSE}
knitr::opts_knit$set(
  echo = FALSE,
  xtable.type = "html",
  base.dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
  root_dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
  fig.path = "results/graphics")  # relative path required, see 
http://yihui.name/knitr/options
```

and then referenced my plot using

<img src = "email_distribution_pie.png"></img>

because I want to be able to customize the plotting attributes.

But that fails with the message "pandoc.exe: Could not fetch 
email_distribution_pie.png".

If I give it the absolute path 
"H:/2017/Analysen/Kundenzufriedenheit/Auswertung/results/graphics/email_distribution_pie.png" 
it works fine as well if I copy the plot into the directory where the 
report.RMD file resides. 

How can I tell knitr to fetch the ready-made plots from the graphics 
directory?

Kind regards

Georg


From es at enricoschumann.net  Thu Jun  8 13:41:24 2017
From: es at enricoschumann.net (Enrico Schumann)
Date: Thu, 08 Jun 2017 13:41:24 +0200
Subject: [R] regular expression help
In-Reply-To: <CAC8=1epoYDyr5tXZAL482+Gb43uLxnQ=z8SU8d_NOd6oPe6gPQ@mail.gmail.com>
Message-ID: <20170608134124.Horde.-kP6bUxvM_bkoaoRHXIMxjc@webmail.your-server.de>


Zitat von Ashim Kapoor <ashimkapoor at gmail.com>:

> Dear All,
>
> My query is:
>
> Do we always need to use perl = TRUE option when doing ignore.case=TRUE?
>
> A small example :
>
> my_text =
> "RECOVERY OFFICER-II\nDEBTS RECOVERY TRIBUNAL-III\n  RC No. 162/2015\nSBI
> VS RAMESH GUPTA.\n    Dated: 01.03.2016                   Item no.01\n
> Present:   Ms. Sonakshi, the proxy counsel for Ms. Usha Singh, the counsel
> for ARCIL.\n                None for the CDs.\n  The counsel for the CHFI
> submitted that the matter has been assigned to ARCIL and deed of
> assignment, application for substituting the name and vakalatnama has been
> filed vide diary no. 1454 dated 08.02.2016\nIn the application it has been
> prayed that ARCIL may be substituted in place of SBI for the purpose of
> further proceedings in the matter. Request allowed.\nThe proxy counsel for
> CHFI further requested to issue demand notice thereby mentioning the name
> of ARCIL. Request allowed.\nRegistry is directed to issue fresh demand
> notice mentioning the name of ARCIL.\nCHFI is directed to file status of
> the mortgaged property as well as other assets of the CDs.\nList the case
> on 28.03.2016.\n  (SUJEET KUMAR)\nRECOVERY OFFICER-II."
>
> My regular expression is:
>
> parties_present_start_1=
> regexpr("\n.*Present.*\n.*\n",my_text,ignore.case=TRUE,perl=T)
>
> parties_present_start_2=
> regexpr("\n.*Present.*\n.*\n",my_text,ignore.case=TRUE)
>
>> parties_present_start_1
> [1] 138
> attr(,"match.length")
> [1] 123
> attr(,"useBytes")
> [1] TRUE
>> parties_present_start_2
> [1] 20
> attr(,"match.length")
> [1] 949
> attr(,"useBytes")
> [1] TRUE
>>
>
> Why do I see the correct result only in the first case?
>
> Best Regards,
> Ashim
>

In Perl, '.' matches anything but a newline.

In R, '.' matches any character.

   test <- "hello\n1"
   regexpr(".*[0-9]", test)
   ## [1] 1
   ## attr(,"match.length")
   ## [1] 7
   ## attr(,"useBytes")
   ## [1] TRUE

   regexpr(".*[0-9]", test, perl = TRUE)
   ## [1] 7
   ## attr(,"match.length")
   ## [1] 1
   ## attr(,"useBytes")
   ## [1] TRUE


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ed_isfahani at yahoo.com  Thu Jun  8 13:48:01 2017
From: ed_isfahani at yahoo.com (Sara Edi)
Date: Thu, 8 Jun 2017 11:48:01 +0000 (UTC)
Subject: [R] I don't want to receive mail from questioner
References: <1436667647.6062385.1496922481951.ref@mail.yahoo.com>
Message-ID: <1436667647.6062385.1496922481951@mail.yahoo.com>

 blockquote, div.yahoo_quoted { margin-left: 0 !important; border-left:1px #715FFA solid !important; padding-left:1ex !important; background-color:white !important; } How can I cancel R-help mail?I do not want to receive questions of questioner becouse I do not have enough information about R.
?Best Regards
Sent from Yahoo Mail for iPhone

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Thu Jun  8 14:06:39 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Thu, 8 Jun 2017 17:36:39 +0530
Subject: [R] regular expression help
In-Reply-To: <20170608134124.Horde.-kP6bUxvM_bkoaoRHXIMxjc@webmail.your-server.de>
References: <CAC8=1epoYDyr5tXZAL482+Gb43uLxnQ=z8SU8d_NOd6oPe6gPQ@mail.gmail.com>
 <20170608134124.Horde.-kP6bUxvM_bkoaoRHXIMxjc@webmail.your-server.de>
Message-ID: <CAC8=1eqBdYWNR5G1-7kjCieTQTzj4Q6MxNeWBBWoS3p87NHAfA@mail.gmail.com>

Dear Enrico,

Many thanks and Best Regards,

Ashim.

On Thu, Jun 8, 2017 at 5:11 PM, Enrico Schumann <es at enricoschumann.net>
wrote:

>
> Zitat von Ashim Kapoor <ashimkapoor at gmail.com>:
>
>
> Dear All,
>>
>> My query is:
>>
>> Do we always need to use perl = TRUE option when doing ignore.case=TRUE?
>>
>> A small example :
>>
>> my_text =
>> "RECOVERY OFFICER-II\nDEBTS RECOVERY TRIBUNAL-III\n  RC No. 162/2015\nSBI
>> VS RAMESH GUPTA.\n    Dated: 01.03.2016                   Item no.01\n
>> Present:   Ms. Sonakshi, the proxy counsel for Ms. Usha Singh, the counsel
>> for ARCIL.\n                None for the CDs.\n  The counsel for the CHFI
>> submitted that the matter has been assigned to ARCIL and deed of
>> assignment, application for substituting the name and vakalatnama has been
>> filed vide diary no. 1454 dated 08.02.2016\nIn the application it has been
>> prayed that ARCIL may be substituted in place of SBI for the purpose of
>> further proceedings in the matter. Request allowed.\nThe proxy counsel for
>> CHFI further requested to issue demand notice thereby mentioning the name
>> of ARCIL. Request allowed.\nRegistry is directed to issue fresh demand
>> notice mentioning the name of ARCIL.\nCHFI is directed to file status of
>> the mortgaged property as well as other assets of the CDs.\nList the case
>> on 28.03.2016.\n  (SUJEET KUMAR)\nRECOVERY OFFICER-II."
>>
>> My regular expression is:
>>
>> parties_present_start_1=
>> regexpr("\n.*Present.*\n.*\n",my_text,ignore.case=TRUE,perl=T)
>>
>> parties_present_start_2=
>> regexpr("\n.*Present.*\n.*\n",my_text,ignore.case=TRUE)
>>
>> parties_present_start_1
>>>
>> [1] 138
>> attr(,"match.length")
>> [1] 123
>> attr(,"useBytes")
>> [1] TRUE
>>
>>> parties_present_start_2
>>>
>> [1] 20
>> attr(,"match.length")
>> [1] 949
>> attr(,"useBytes")
>> [1] TRUE
>>
>>>
>>>
>> Why do I see the correct result only in the first case?
>>
>> Best Regards,
>> Ashim
>>
>>
> In Perl, '.' matches anything but a newline.
>
> In R, '.' matches any character.
>
>   test <- "hello\n1"
>   regexpr(".*[0-9]", test)
>   ## [1] 1
>   ## attr(,"match.length")
>   ## [1] 7
>   ## attr(,"useBytes")
>   ## [1] TRUE
>
>   regexpr(".*[0-9]", test, perl = TRUE)
>   ## [1] 7
>   ## attr(,"match.length")
>   ## [1] 1
>   ## attr(,"useBytes")
>   ## [1] TRUE
>
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
>
>

	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Thu Jun  8 14:20:18 2017
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Thu, 8 Jun 2017 13:20:18 +0100 (BST)
Subject: [R] Rainbow in loop
Message-ID: <767948908.1587407.1496924418592.JavaMail.open-xchange@oxbe23.tb.ukmail.iss.as9143.net>

Hi R folk  I have a distance time graph for a locomotive and at various times
different events occur on board the loco.  I want to put a vertical line on the
speed time graph for each event, but I want to colour each different kind of
event differently to see visually whether there's any pattern to these events
happening.  I could just create a vector of colours and use abline which is easy
obviously, but there's a different number of events for each loco and what I
would like to do is to use rainbow to create a new palette for each graph

To illustrate I have some model code (made-up and v simplified)  Real times are
not necessarily whole numbers so  there's  not a one to one correspondence
between times and index of time elements

sec.time<-seq(0,100)

distance<-c(rep(0,
10),rep(1,5),rep(2,20),rep(3,10),rep(4,20),rep(5,5),rep(6,31))
plot(sec.time,distance,type="l")
horntime<-c(7,23,52,67,81,90)
wipertime<-c(4,18,34,47,62,78,89)
calltime<-c(27,58,93)

abline(v=sec.time[horntime], col="red")
abline(v=sec.time[wipertime], col="blue")
abline(v=sec.time[calltime], col="green")

what I want, in this case as there are three events, is to have horn in red,
wiper in blue and call in green using rainbow with 3.  The problem is that I
can't see how to call rainbow using a sequence (for loop doesn't work) and
putting horn/wiper/call as vectors in a list doesn't work as it's too recursive.
 I suppose that I could put horn/wiper/call etc into a matrix of width the
longest vector and fill the other spaces with dummy -1 but this seems a bit
inelegant and also in principle I'd like to be able to call rainbow in the
desired way as I have to prepare various graphs of different aspects of loco
behaviour

If anyone has any ideas I'd be v grateful

Thanks Nick
	[[alternative HTML version deleted]]


From frainj at gmail.com  Thu Jun  8 14:47:00 2017
From: frainj at gmail.com (John C Frain)
Date: Thu, 8 Jun 2017 13:47:00 +0100
Subject: [R] I don't want to receive mail from questioner
In-Reply-To: <1436667647.6062385.1496922481951@mail.yahoo.com>
References: <1436667647.6062385.1496922481951.ref@mail.yahoo.com>
 <1436667647.6062385.1496922481951@mail.yahoo.com>
Message-ID: <CAHrK515odNbEz79SW4os07pdVLpBpjAobdt1ivG5FHrto6qsAg@mail.gmail.com>

Unsubscribe by following the instructions at https://stat.ethz.ch/mailman/
listinfo/r-help. There is a message to this effect at the end of each
message from r-help. If you are going to use R you should stay subscribed
as you may find that some of the answers provide valuable information to
users at various levels of expertise.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 8 June 2017 at 12:48, Sara Edi via R-help <r-help at r-project.org> wrote:

>  blockquote, div.yahoo_quoted { margin-left: 0 !important; border-left:1px
> #715FFA solid !important; padding-left:1ex !important;
> background-color:white !important; } How can I cancel R-help mail?I do not
> want to receive questions of questioner becouse I do not have enough
> information about R.
>  Best Regards
> Sent from Yahoo Mail for iPhone
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Thu Jun  8 15:13:57 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 8 Jun 2017 09:13:57 -0400
Subject: [R] Rainbow in loop
In-Reply-To: <767948908.1587407.1496924418592.JavaMail.open-xchange@oxbe23.tb.ukmail.iss.as9143.net>
References: <767948908.1587407.1496924418592.JavaMail.open-xchange@oxbe23.tb.ukmail.iss.as9143.net>
Message-ID: <E04A2C6D-69FA-4688-AEE4-AE584E1CB0A1@utoronto.ca>

Does:

  rainbow(3)[1]
  rainbow(3)[2]
  rainbow(3)[3]

... solve your issue?

B.





> On Jun 8, 2017, at 8:20 AM, WRAY NICHOLAS <nicholas.wray at ntlworld.com> wrote:
> 
> Hi R folk  I have a distance time graph for a locomotive and at various times
> different events occur on board the loco.  I want to put a vertical line on the
> speed time graph for each event, but I want to colour each different kind of
> event differently to see visually whether there's any pattern to these events
> happening.  I could just create a vector of colours and use abline which is easy
> obviously, but there's a different number of events for each loco and what I
> would like to do is to use rainbow to create a new palette for each graph
> 
> To illustrate I have some model code (made-up and v simplified)  Real times are
> not necessarily whole numbers so  there's  not a one to one correspondence
> between times and index of time elements
> 
> sec.time<-seq(0,100)
> 
> distance<-c(rep(0,
> 10),rep(1,5),rep(2,20),rep(3,10),rep(4,20),rep(5,5),rep(6,31))
> plot(sec.time,distance,type="l")
> horntime<-c(7,23,52,67,81,90)
> wipertime<-c(4,18,34,47,62,78,89)
> calltime<-c(27,58,93)
> 
> abline(v=sec.time[horntime], col="red")
> abline(v=sec.time[wipertime], col="blue")
> abline(v=sec.time[calltime], col="green")
> 
> what I want, in this case as there are three events, is to have horn in red,
> wiper in blue and call in green using rainbow with 3.  The problem is that I
> can't see how to call rainbow using a sequence (for loop doesn't work) and
> putting horn/wiper/call as vectors in a list doesn't work as it's too recursive.
> I suppose that I could put horn/wiper/call etc into a matrix of width the
> longest vector and fill the other spaces with dummy -1 but this seems a bit
> inelegant and also in principle I'd like to be able to call rainbow in the
> desired way as I have to prepare various graphs of different aspects of loco
> behaviour
> 
> If anyone has any ideas I'd be v grateful
> 
> Thanks Nick
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nicholas.wray at ntlworld.com  Thu Jun  8 15:22:03 2017
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Thu, 8 Jun 2017 14:22:03 +0100 (BST)
Subject: [R] Rainbow in loop
In-Reply-To: <E04A2C6D-69FA-4688-AEE4-AE584E1CB0A1@utoronto.ca>
References: <767948908.1587407.1496924418592.JavaMail.open-xchange@oxbe23.tb.ukmail.iss.as9143.net>
 <E04A2C6D-69FA-4688-AEE4-AE584E1CB0A1@utoronto.ca>
Message-ID: <224584522.1589583.1496928123611.JavaMail.open-xchange@oxbe23.tb.ukmail.iss.as9143.net>

Yep fabbo I can then call each vector as a separate element in a list and it
gives the colours...  Thanks aleph-null times Nick

> 
>     On 08 June 2017 at 14:13 Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
>     Does:
> 
>     rainbow(3)[1]
>     rainbow(3)[2]
>     rainbow(3)[3]
> 
>     ... solve your issue?
> 
>     B.
> 
> 
> 
> 
> 
>     > On Jun 8, 2017, at 8:20 AM, WRAY NICHOLAS <nicholas.wray at ntlworld.com>
>     > wrote:
>     >
>     > Hi R folk I have a distance time graph for a locomotive and at various
>     > times
>     > different events occur on board the loco. I want to put a vertical line
>     > on the
>     > speed time graph for each event, but I want to colour each different
>     > kind of
>     > event differently to see visually whether there's any pattern to these
>     > events
>     > happening. I could just create a vector of colours and use abline which
>     > is easy
>     > obviously, but there's a different number of events for each loco and
>     > what I
>     > would like to do is to use rainbow to create a new palette for each
>     > graph
>     >
>     > To illustrate I have some model code (made-up and v simplified) Real
>     > times are
>     > not necessarily whole numbers so there's not a one to one correspondence
>     > between times and index of time elements
>     >
>     > sec.time<-seq(0,100)
>     >
>     > distance<-c(rep(0,
>     > 10),rep(1,5),rep(2,20),rep(3,10),rep(4,20),rep(5,5),rep(6,31))
>     > plot(sec.time,distance,type="l")
>     > horntime<-c(7,23,52,67,81,90)
>     > wipertime<-c(4,18,34,47,62,78,89)
>     > calltime<-c(27,58,93)
>     >
>     > abline(v=sec.time[horntime], col="red")
>     > abline(v=sec.time[wipertime], col="blue")
>     > abline(v=sec.time[calltime], col="green")
>     >
>     > what I want, in this case as there are three events, is to have horn in
>     > red,
>     > wiper in blue and call in green using rainbow with 3. The problem is
>     > that I
>     > can't see how to call rainbow using a sequence (for loop doesn't work)
>     > and
>     > putting horn/wiper/call as vectors in a list doesn't work as it's too
>     > recursive.
>     > I suppose that I could put horn/wiper/call etc into a matrix of width
>     > the
>     > longest vector and fill the other spaces with dummy -1 but this seems a
>     > bit
>     > inelegant and also in principle I'd like to be able to call rainbow in
>     > the
>     > desired way as I have to prepare various graphs of different aspects of
>     > loco
>     > behaviour
>     >
>     > If anyone has any ideas I'd be v grateful
>     >
>     > Thanks Nick
>     > [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
> 

>
	[[alternative HTML version deleted]]


From xie at yihui.name  Thu Jun  8 17:05:34 2017
From: xie at yihui.name (Yihui Xie)
Date: Thu, 8 Jun 2017 10:05:34 -0500
Subject: [R] Paths in knitr
In-Reply-To: <OFE37F0A6B.835B65D9-ONC1258139.003D3941-C1258139.003DE23D@lotus.hawesko.de>
References: <OFE37F0A6B.835B65D9-ONC1258139.003D3941-C1258139.003DE23D@lotus.hawesko.de>
Message-ID: <CANROs4f0FyOpEhX8KPA3Z_fJxb3EA2FhPy2ud3cGAYgSEKHdqA@mail.gmail.com>

Why do you have to set the base.dir option?

Regards,
Yihui
--
https://yihui.name


On Thu, Jun 8, 2017 at 6:15 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I have to compile a report for the management and decided to use RMarkdown
> and knitr. I compiled all needed plots (using separate R scripts) before
> compiling the report, thus all plots reside in my graphics directory. The
> RMarkdown report needs to access these files. I have defined
>
> ```{r setup, include = FALSE}
> knitr::opts_knit$set(
>   echo = FALSE,
>   xtable.type = "html",
>   base.dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
>   root_dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
>   fig.path = "results/graphics")  # relative path required, see
> http://yihui.name/knitr/options
> ```
>
> and then referenced my plot using
>
> <img src = "email_distribution_pie.png"></img>
>
> because I want to be able to customize the plotting attributes.
>
> But that fails with the message "pandoc.exe: Could not fetch
> email_distribution_pie.png".
>
> If I give it the absolute path
> "H:/2017/Analysen/Kundenzufriedenheit/Auswertung/results/graphics/email_distribution_pie.png"
> it works fine as well if I copy the plot into the directory where the
> report.RMD file resides.
>
> How can I tell knitr to fetch the ready-made plots from the graphics
> directory?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Jun  8 17:03:39 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 8 Jun 2017 11:03:39 -0400
Subject: [R] Paths in knitr
In-Reply-To: <OFE37F0A6B.835B65D9-ONC1258139.003D3941-C1258139.003DE23D@lotus.hawesko.de>
References: <OFE37F0A6B.835B65D9-ONC1258139.003D3941-C1258139.003DE23D@lotus.hawesko.de>
Message-ID: <85f5ed19-deec-db0f-11e2-b31d6920475e@gmail.com>

On 08/06/2017 7:15 AM, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> I have to compile a report for the management and decided to use RMarkdown
> and knitr. I compiled all needed plots (using separate R scripts) before
> compiling the report, thus all plots reside in my graphics directory. The
> RMarkdown report needs to access these files. I have defined
>
> ```{r setup, include = FALSE}
> knitr::opts_knit$set(
>   echo = FALSE,
>   xtable.type = "html",
>   base.dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
>   root_dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
>   fig.path = "results/graphics")  # relative path required, see
> http://yihui.name/knitr/options
> ```
>
> and then referenced my plot using
>
> <img src = "email_distribution_pie.png"></img>
>
> because I want to be able to customize the plotting attributes.
>
> But that fails with the message "pandoc.exe: Could not fetch
> email_distribution_pie.png".
>
> If I give it the absolute path
> "H:/2017/Analysen/Kundenzufriedenheit/Auswertung/results/graphics/email_distribution_pie.png"
> it works fine as well if I copy the plot into the directory where the
> report.RMD file resides.
>
> How can I tell knitr to fetch the ready-made plots from the graphics
> directory?

Put the path in a variable, and use that in the img tag, e.g.

```{r}
gdir <- file.path(knitr::opts_knit$get("base.dir"), "graphics")
```

<img src = `r file.path(gdir, "email_distribution_pie.png")`></img>

If you think that is still too much typing, you could make a little 
function to turn a string like "email_distribution_pie" into the fully 
specified path.

HOWEVER:  Your workflow may not be ideal.  It is almost always better to 
produce the graphs in code that's in the document, rather than in 
separate R scripts.   This makes it *much* easier to modify the plots 
and be sure that the latest version makes it into the report.

If the plots require lots of code and you think it would be distracting 
in the source of your document, then it's time to make a private 
package, and put the code in there.  In the document, just include calls 
to functions from that package.

Duncan Murdoch


From yogesh2cute at gmail.com  Thu Jun  8 16:35:55 2017
From: yogesh2cute at gmail.com (Yogesh Gupta)
Date: Thu, 8 Jun 2017 23:35:55 +0900
Subject: [R] DESeq2 pairwise compasion
Message-ID: <CAAjHrnNL6uM_upKxN13ed6w2WBDb1o87Ec=Snk58mE2gSA5wKA@mail.gmail.com>

There are two line 216 and 218

Three development stages 5 WEEK (5W), 7W, 9W.

Three tissue: Ca, Co, Pa

each with 2 biological replicate.

With two biological replicate. I want to do differential gene expression
analysis using DESeq2 so I tried these codes after reading about DESeq2:
,my aim is to do the pairwise comparison. how to make colData and design
formula.

library("DESeq2")

countMatrix = read.table("read_count.22May.2017.new.txt",header=T,sep='\t',check.names=F)

head(countMatrix)

dim(countMatrix)
[1] 57894    35

Now I am not sure how to construct a DESeqDataSet:

dds <- DESeqDataSetFromMatrix(countData = countMatrix,

colData = colData,

design = ~ condition)


Thanks

Yogesh

-- 
*Yogesh Gupta*
*Postdoctoral Researcher*
*Department of Biological Science*
*Seoul National University*
*Seoul, South Korea*

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Thu Jun  8 18:16:04 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 8 Jun 2017 16:16:04 +0000
Subject: [R] rmarkdown and font size
In-Reply-To: <08E5EBA9-4C89-4376-9F39-E6A59D204FB9@llnl.gov>
References: <08E5EBA9-4C89-4376-9F39-E6A59D204FB9@llnl.gov>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643EC3F4F@WAXMXOLYMB025.WAX.wa.lcl>

You can change the style, modifying a variety of things.  E.g,

---
title: Test
---

<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 8px;
}
h1.title {
  font-size: 38px;
  color: DarkRed;
}
h1 { /* Header 1 */
  font-size: 28px;
  color: DarkBlue;
}
h2 { /* Header 2 */
    font-size: 22px;
  color: DarkBlue;
}
h3 { /* Header 3 */
  font-size: 18px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>

Here is some normal text.  It is a 12-point font.  The table is in 8-point . 
  
```{r example, echo=FALSE, results='asis'}
tmp <- data.frame(a=1:5, b=letters[1:5])
print( knitr::kable(tmp, row.names=FALSE))
```


Hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> MacQueen, Don
> Sent: Wednesday, June 07, 2017 4:58 PM
> To: r-help at r-project.org
> Subject: [R] rmarkdown and font size
> 
> Suppose I have a file (named "tmp.rmd") containing:
> 
> 
> ---
> title: Test
> ---
> 
> ```{r example, echo=FALSE, results='asis'}
> tmp <- data.frame(a=1:5, b=letters[1:5])
> print( knitr::kable(tmp, row.names=FALSE))
> ```
> 
> 
> 
> And I render it with:
> 
> rmarkdown::render('tmp.rmd',
> output_format=c('html_document','pdf_document'))
> 
> I get two files:
>   tmp.pdf
>   tmp.html
> 
> Is there a way to control (change or specify) the font size of the table in the
> pdf output?
> (or of the entire document, if it can't be changed for just the table)
> 
> With my actual data, the table is too wide to fit on a page in the pdf output;
> perhaps if I reduce the font size I can get it to fit.
> 
> I would like the html version to still look decent, but I don't care very much
> what happens to its font size.
> 
> Thanks!
> -Don
> 
> --
> Don MacQueen
> 
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Jun  8 18:32:52 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 08 Jun 2017 09:32:52 -0700
Subject: [R] DESeq2 pairwise compasion
In-Reply-To: <CAAjHrnNL6uM_upKxN13ed6w2WBDb1o87Ec=Snk58mE2gSA5wKA@mail.gmail.com>
References: <CAAjHrnNL6uM_upKxN13ed6w2WBDb1o87Ec=Snk58mE2gSA5wKA@mail.gmail.com>
Message-ID: <F4303270-4CFE-4BD2-A5A4-153CC03919CA@dcn.davis.ca.us>

I think you are asking on the wrong mailing list. Perhaps you should be asking this question on the Bioconductor mailing list? 
-- 
Sent from my phone. Please excuse my brevity.

On June 8, 2017 7:35:55 AM PDT, Yogesh Gupta <yogesh2cute at gmail.com> wrote:
>There are two line 216 and 218
>
>Three development stages 5 WEEK (5W), 7W, 9W.
>
>Three tissue: Ca, Co, Pa
>
>each with 2 biological replicate.
>
>With two biological replicate. I want to do differential gene
>expression
>analysis using DESeq2 so I tried these codes after reading about
>DESeq2:
>,my aim is to do the pairwise comparison. how to make colData and
>design
>formula.
>
>library("DESeq2")
>
>countMatrix =
>read.table("read_count.22May.2017.new.txt",header=T,sep='\t',check.names=F)
>
>head(countMatrix)
>
>dim(countMatrix)
>[1] 57894    35
>
>Now I am not sure how to construct a DESeqDataSet:
>
>dds <- DESeqDataSetFromMatrix(countData = countMatrix,
>
>colData = colData,
>
>design = ~ condition)
>
>
>Thanks
>
>Yogesh


From cole.beck at vanderbilt.edu  Thu Jun  8 18:40:23 2017
From: cole.beck at vanderbilt.edu (Cole Beck)
Date: Thu, 8 Jun 2017 11:40:23 -0500
Subject: [R] Math ops behaviour with multiple classes
Message-ID: <5b0d579e-532a-20a6-febb-febcb4f79f39@vanderbilt.edu>

I would expect that several math operations should always return values 
with a class of numeric.  If the input is defined with multiple classes, 
however, the class attribute is preserved.  I would think this may have 
some unintended side-effects.  Here's an example:

 > sessionInfo()$R.version$version.string
[1] "R version 3.4.0 (2017-04-21)"
 > x <- seq.int(5)
 > class(x)
[1] "integer"
 > class(log(x))
[1] "numeric"
 > class(x) <- c("integer", "foo")
 > log(x)
[1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379
attr(,"class")
[1] "integer" "foo"
 > x + 0.5
[1] 1.5 2.5 3.5 4.5 5.5
attr(,"class")
[1] "integer" "foo"

I do see the note in ?Arithmetic that states "All attributes (including 
class) are preserved if there is no coercion".  Is this correct, or 
should the returned value have an updated class of c("numeric", "foo")? 
Should foo have its own methods to coerce the output to numeric?

Thanks,
Cole


From percentil101 at gmail.com  Thu Jun  8 19:50:00 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Thu, 8 Jun 2017 19:50:00 +0200
Subject: [R] Plot MArginal distribution in the correct place
In-Reply-To: <CA+8X3fVP84StrtWD=gg7pUygf2WpSxOx4G1YW42YW-3AR3kfqw@mail.gmail.com>
References: <CAB-TgNt4u_r01t3vpBOo471tj-CZSazjL-zbSonyFsQrrQLbtQ@mail.gmail.com>
 <CAB-TgNtFXvxHPCbNWM2UeDeyDAt+56i=m5Mamc6mgFdB2kv3aA@mail.gmail.com>
 <CA+8X3fVP84StrtWD=gg7pUygf2WpSxOx4G1YW42YW-3AR3kfqw@mail.gmail.com>
Message-ID: <CAB-TgNtyt8WkKa5xaZWZuJjWHriNbpr-XceBoYd2xqRpHX-4zQ@mail.gmail.com>

Many thanks Jim.

What I,m trying to show with the fhist plot is the empirical distribution
of the values of the left plot simulation.

You say:
However, I don't think that this plot illustrates quite what you think it
does.

Can you give me a clue to try to illustrate better if it is not showing
what I believe it shows a better way to show it?

Many thanks in advance.





El 7 jun. 2017 12:08, "Jim Lemon" <drjimlemon at gmail.com> escribi?:

Hi Pedro,
As a one-off, you just shove the coordinates around a bit:

par(mar=c(11,0,6,6))
barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray",
 ylim=c(0,24))

However, I don't think that this plot illustrates quite what you think it
does.

Jim


On Wed, Jun 7, 2017 at 4:01 PM, Pedro p?ramo <percentil101 at gmail.com> wrote:
> Please, I'm trying to put the right plot higher and centered on the left
> values but I don't achive.
>
> I would appreciate so much your help
>
> El 6 jun. 2017 22:37, "Pedro p?ramo" <percentil101 at gmail.com> escribi?:
>
>> Hi all,
>>
>> I have this code, but the marginal distribution plot doesn?t appear
>> aligned with the left plot.
>>
>>
>> I think could be something about layout or par() mar.
>>
>> The code was programmed by me time ago.
>>
>> Can anyone help me to get the marginal distribution on the center (more
>> higher centered)
>>
>> id.txt
>>
>> Could have this code:
>>
>> 05/01/2016;9335,200195
>> 06/01/2016;9197,400391
>> 07/01/2016;9059,299805
>> 08/01/2016;8909,200195
>> 11/01/2016;8886,099609
>> 12/01/2016;8915,400391
>> 13/01/2016;8934,5
>> 14/01/2016;8787,700195
>> 15/01/2016;8543,599609
>> 18/01/2016;8469,299805
>> 19/01/2016;8554,900391
>> 20/01/2016;8281,400391
>> 21/01/2016;8444,200195
>> 22/01/2016;8722,900391
>> 25/01/2016;8567,700195
>> 26/01/2016;8692,5
>> 27/01/2016;8741
>>
>>
>>
>> g<-read.table("id.txt", col.names=c("Dateh","LAST"), sep=";", dec=",")
>>
>> N=5000
>> B=24
>> ghy<-nrow(g)
>> r<-as.numeric(as.character(g$LAST[ghy]))
>>
>>
>> nf<-layout(matrix(c(1,1,1,1,2,2),1,6,byrow=TRUE))
>>
>> par(mar=c(6,6,6,0.5))
>>
>> A<-matrix(1:B,B,N);
>>
>>
>>
>> sigma<-0.06;
>>
>>
>>
>> mu<-0.00;
>>
>>
>> Z<-r*exp((mu-0.5*((sigma)^2)*A) +sigma*(sqrt(A))*matrix( rnorm(N*B,0,1),
>> B, N))
>>
>> real1<-g$LAST[1:nrow(g)]
>>
>> real2<-matrix(NA,nrow(g),N-1)
>>
>> real<-cbind(real1,real2)
>>
>>
>>
>>
>> Po<-r*matrix(1,1,N);
>>
>>
>>
>> Sim<-rbind(Po,Z)
>> Simulation<-rbind(real,Z)
>>
>>
>>
>>
>>
>>
>> par(mar=c(10,6,6,6))
>> matplot(Simulation,type="l",ylim=c(0,40000))
>>
>> abline(h = 8000, lwd = 2, col = "black")
>>
>> abline(h = 12000, lwd = 2, col = "black")
>> title("Dinamic Montecarlo Simulation 2 years ahead",font=4)
>>
>> fhist<-hist(Simulation,plot=FALSE)
>> par(mar=c(6,0,6,6))
>> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
>> grid()
>> title("Marginal Distribution",font=4)
>>
>>
>> rect(0, 0, 0, 0) # transparent
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Thu Jun  8 23:01:30 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 8 Jun 2017 21:01:30 +0000 (UTC)
Subject: [R] help regarding r-project
In-Reply-To: <88b829c3-a1ae-39bf-d779-1ae7af9ca1ab@dewey.myzen.co.uk>
References: <CAH9yqxPZLib-wvWAcGrbqthoZyzPXQ7ypezv46iUkKQ8630Ucg@mail.gmail.com>
 <88b829c3-a1ae-39bf-d779-1ae7af9ca1ab@dewey.myzen.co.uk>
Message-ID: <1606594832.5672926.1496955690158@mail.yahoo.com>

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

 

    On Thursday, June 8, 2017 6:57 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
 

 I do not think anyone is going to be able to help you unless you can 
provide a reproducible example with a clear account of what it dies and 
what you expected it to do.

On 08/06/2017 06:34, Sai Sathvick wrote:
> hello sir/ma'am,
>
>? ? ? ? ? ? ? ? ? ? ? ? trying to build a small prototype of resume filter
>? but not able to get expected intercept values, could you please help
> regarding this project ASAP.
>
> to predict,? skills + experience =result
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Jun  8 23:45:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Jun 2017 14:45:36 -0700
Subject: [R] Math ops behaviour with multiple classes
In-Reply-To: <5b0d579e-532a-20a6-febb-febcb4f79f39@vanderbilt.edu>
References: <5b0d579e-532a-20a6-febb-febcb4f79f39@vanderbilt.edu>
Message-ID: <CAGxFJbQPXZUqZnCM34AQ21LGx8yJ4aXDxNLViGur8P+cDYoYXg@mail.gmail.com>

I think you may be confusing (S3) class and ?mode.

> x <- seq.int(1:3)
> class(x)
[1] "integer"
> mode(x)
[1] "numeric"
> class(x+.5) ## coercion
[1] "numeric"
> mode(x+.5)
[1] "numeric"

But note:

> y <- as.integer(1)
> class(y)
[1] "integer"
> class(y) <- "foo"
> mode(y)
[1] "numeric"
> class(y+.5)
[1] "foo"
> mode(y+.5)
[1] "numeric"

And further:

> class(y) <-c("foo","integer")
> class(y+.5)
[1] "foo"     "integer"

So basically, the behavior seems to be: when the class attribute can
be coerced to "numeric" by as.numeric(), it is. Otherwise it is left
as is.

Note that log is a primitive function not in the Ops groups, but has
similar behavior.

I would guess (corroboration or correction by more knowledgeable folks
appreciated!) that this sort of semi-confusion with S3 classes was one
of the motivators for adding the more rigorous S4 system.

HTH

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 8, 2017 at 9:40 AM, Cole Beck <cole.beck at vanderbilt.edu> wrote:
> I would expect that several math operations should always return values with
> a class of numeric.  If the input is defined with multiple classes, however,
> the class attribute is preserved.  I would think this may have some
> unintended side-effects.  Here's an example:
>
>> sessionInfo()$R.version$version.string
> [1] "R version 3.4.0 (2017-04-21)"
>> x <- seq.int(5)
>> class(x)
> [1] "integer"
>> class(log(x))
> [1] "numeric"
>> class(x) <- c("integer", "foo")
>> log(x)
> [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379
> attr(,"class")
> [1] "integer" "foo"
>> x + 0.5
> [1] 1.5 2.5 3.5 4.5 5.5
> attr(,"class")
> [1] "integer" "foo"
>
> I do see the note in ?Arithmetic that states "All attributes (including
> class) are preserved if there is no coercion".  Is this correct, or should
> the returned value have an updated class of c("numeric", "foo")? Should foo
> have its own methods to coerce the output to numeric?
>
> Thanks,
> Cole
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cole.beck at Vanderbilt.Edu  Fri Jun  9 00:48:23 2017
From: cole.beck at Vanderbilt.Edu (Beck, Cole)
Date: Thu, 8 Jun 2017 22:48:23 +0000
Subject: [R] Math ops behaviour with multiple classes
In-Reply-To: <CAGxFJbQPXZUqZnCM34AQ21LGx8yJ4aXDxNLViGur8P+cDYoYXg@mail.gmail.com>
References: <5b0d579e-532a-20a6-febb-febcb4f79f39@vanderbilt.edu>,
 <CAGxFJbQPXZUqZnCM34AQ21LGx8yJ4aXDxNLViGur8P+cDYoYXg@mail.gmail.com>
Message-ID: <1750F3CE3280FB48853FEC80386B77EE6023CA22@ITS-HCWNEM103.ds.vanderbilt.edu>

Thanks Bert, I think we agree on the current behaviour, but I'm still not sure if it's desirable.  The mode isn't used for method dispatch.  In the following example, I have to write `log.foo` in order for the correct method to be called.

> x <- seq.int(5)
> class(x) <- c("integer", "foo")
> half <- function(x) UseMethod("half")
> half.default <- function(x) {
+   floor(x) / 2
+ }
> half.integer <- function(x) {
+   x %/% 2
+ }
> half(log(x)) # dispatches half.integer, not desired
[1] 0 0 0 0 0
attr(,"class")
[1] "integer" "foo"    
> half(log(seq(5))) # dispatches half.default, as desired
[1] 0.0 0.0 0.5 0.5 0.5
> log.foo <- function(x) {
+   res <- log(as.numeric(x))
+   class(res) <- c("numeric", "foo")
+   res
+ }
> half(log(x)) # dispatches log.foo, then half.default, as desired
[1] 0.0 0.0 0.5 0.5 0.5
attr(,"class")
[1] "numeric" "foo"    

Not only would I have to write `log.foo`, but I'd need to add my own `foo` methods for the Math and Ops groups.  Using a different class system might be a better solution, but my preference would definitely be for the base functions to coerce the class to numeric (which it indeed does if there are not multiple classes).

Cole
________________________________________
From: Bert Gunter [bgunter.4567 at gmail.com]
Sent: Thursday, June 08, 2017 4:45 PM
To: Beck, Cole
Cc: R-help
Subject: Re: [R] Math ops behaviour with multiple classes

I think you may be confusing (S3) class and ?mode.

> x <- seq.int(1:3)
> class(x)
[1] "integer"
> mode(x)
[1] "numeric"
> class(x+.5) ## coercion
[1] "numeric"
> mode(x+.5)
[1] "numeric"

But note:

> y <- as.integer(1)
> class(y)
[1] "integer"
> class(y) <- "foo"
> mode(y)
[1] "numeric"
> class(y+.5)
[1] "foo"
> mode(y+.5)
[1] "numeric"

And further:

> class(y) <-c("foo","integer")
> class(y+.5)
[1] "foo"     "integer"

So basically, the behavior seems to be: when the class attribute can
be coerced to "numeric" by as.numeric(), it is. Otherwise it is left
as is.

Note that log is a primitive function not in the Ops groups, but has
similar behavior.

I would guess (corroboration or correction by more knowledgeable folks
appreciated!) that this sort of semi-confusion with S3 classes was one
of the motivators for adding the more rigorous S4 system.

HTH

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 8, 2017 at 9:40 AM, Cole Beck <cole.beck at vanderbilt.edu> wrote:
> I would expect that several math operations should always return values with
> a class of numeric.  If the input is defined with multiple classes, however,
> the class attribute is preserved.  I would think this may have some
> unintended side-effects.  Here's an example:
>
>> sessionInfo()$R.version$version.string
> [1] "R version 3.4.0 (2017-04-21)"
>> x <- seq.int(5)
>> class(x)
> [1] "integer"
>> class(log(x))
> [1] "numeric"
>> class(x) <- c("integer", "foo")
>> log(x)
> [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379
> attr(,"class")
> [1] "integer" "foo"
>> x + 0.5
> [1] 1.5 2.5 3.5 4.5 5.5
> attr(,"class")
> [1] "integer" "foo"
>
> I do see the note in ?Arithmetic that states "All attributes (including
> class) are preserved if there is no coercion".  Is this correct, or should
> the returned value have an updated class of c("numeric", "foo")? Should foo
> have its own methods to coerce the output to numeric?
>
> Thanks,
> Cole
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Fri Jun  9 02:01:48 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 8 Jun 2017 17:01:48 -0700
Subject: [R] Math ops behaviour with multiple classes
In-Reply-To: <CAGxFJbQPXZUqZnCM34AQ21LGx8yJ4aXDxNLViGur8P+cDYoYXg@mail.gmail.com>
References: <5b0d579e-532a-20a6-febb-febcb4f79f39@vanderbilt.edu>
 <CAGxFJbQPXZUqZnCM34AQ21LGx8yJ4aXDxNLViGur8P+cDYoYXg@mail.gmail.com>
Message-ID: <CABdHhvE44N02wUCrRO5PJBn1Hjy3pva4MXhpD0axttibdp8CaQ@mail.gmail.com>

On Thu, Jun 8, 2017 at 2:45 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> I think you may be confusing (S3) class and ?mode.

Your point is well made, but to be precise, I think you should talk
about the "type of" an object, not it's mode. mode() is a wrapper
around typeof(), designed (I believe) for S compatibility.

Hadley

-- 
http://hadley.nz


From jdnewmil at dcn.davis.ca.us  Fri Jun  9 02:46:27 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 08 Jun 2017 17:46:27 -0700
Subject: [R] Math ops behaviour with multiple classes
In-Reply-To: <1750F3CE3280FB48853FEC80386B77EE6023CA22@ITS-HCWNEM103.ds.vanderbilt.edu>
References: <5b0d579e-532a-20a6-febb-febcb4f79f39@vanderbilt.edu>,
 <CAGxFJbQPXZUqZnCM34AQ21LGx8yJ4aXDxNLViGur8P+cDYoYXg@mail.gmail.com>
 <1750F3CE3280FB48853FEC80386B77EE6023CA22@ITS-HCWNEM103.ds.vanderbilt.edu>
Message-ID: <2B637CF6-4FBE-4F8D-9F20-E713177DB0E1@dcn.davis.ca.us>

Cole, that cow left the barn decades ago. 

You really should read Patrick Burns' discussion of the history of R [1].

[1] http://www.burns-stat.com/documents/presentations/inferno-ish-R/
-- 
Sent from my phone. Please excuse my brevity.

On June 8, 2017 3:48:23 PM PDT, "Beck, Cole" <cole.beck at Vanderbilt.Edu> wrote:
>Thanks Bert, I think we agree on the current behaviour, but I'm still
>not sure if it's desirable.  The mode isn't used for method dispatch. 
>In the following example, I have to write `log.foo` in order for the
>correct method to be called.
>
>> x <- seq.int(5)
>> class(x) <- c("integer", "foo")
>> half <- function(x) UseMethod("half")
>> half.default <- function(x) {
>+   floor(x) / 2
>+ }
>> half.integer <- function(x) {
>+   x %/% 2
>+ }
>> half(log(x)) # dispatches half.integer, not desired
>[1] 0 0 0 0 0
>attr(,"class")
>[1] "integer" "foo"    
>> half(log(seq(5))) # dispatches half.default, as desired
>[1] 0.0 0.0 0.5 0.5 0.5
>> log.foo <- function(x) {
>+   res <- log(as.numeric(x))
>+   class(res) <- c("numeric", "foo")
>+   res
>+ }
>> half(log(x)) # dispatches log.foo, then half.default, as desired
>[1] 0.0 0.0 0.5 0.5 0.5
>attr(,"class")
>[1] "numeric" "foo"    
>
>Not only would I have to write `log.foo`, but I'd need to add my own
>`foo` methods for the Math and Ops groups.  Using a different class
>system might be a better solution, but my preference would definitely
>be for the base functions to coerce the class to numeric (which it
>indeed does if there are not multiple classes).
>
>Cole
>________________________________________
>From: Bert Gunter [bgunter.4567 at gmail.com]
>Sent: Thursday, June 08, 2017 4:45 PM
>To: Beck, Cole
>Cc: R-help
>Subject: Re: [R] Math ops behaviour with multiple classes
>
>I think you may be confusing (S3) class and ?mode.
>
>> x <- seq.int(1:3)
>> class(x)
>[1] "integer"
>> mode(x)
>[1] "numeric"
>> class(x+.5) ## coercion
>[1] "numeric"
>> mode(x+.5)
>[1] "numeric"
>
>But note:
>
>> y <- as.integer(1)
>> class(y)
>[1] "integer"
>> class(y) <- "foo"
>> mode(y)
>[1] "numeric"
>> class(y+.5)
>[1] "foo"
>> mode(y+.5)
>[1] "numeric"
>
>And further:
>
>> class(y) <-c("foo","integer")
>> class(y+.5)
>[1] "foo"     "integer"
>
>So basically, the behavior seems to be: when the class attribute can
>be coerced to "numeric" by as.numeric(), it is. Otherwise it is left
>as is.
>
>Note that log is a primitive function not in the Ops groups, but has
>similar behavior.
>
>I would guess (corroboration or correction by more knowledgeable folks
>appreciated!) that this sort of semi-confusion with S3 classes was one
>of the motivators for adding the more rigorous S4 system.
>
>HTH
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Thu, Jun 8, 2017 at 9:40 AM, Cole Beck <cole.beck at vanderbilt.edu>
>wrote:
>> I would expect that several math operations should always return
>values with
>> a class of numeric.  If the input is defined with multiple classes,
>however,
>> the class attribute is preserved.  I would think this may have some
>> unintended side-effects.  Here's an example:
>>
>>> sessionInfo()$R.version$version.string
>> [1] "R version 3.4.0 (2017-04-21)"
>>> x <- seq.int(5)
>>> class(x)
>> [1] "integer"
>>> class(log(x))
>> [1] "numeric"
>>> class(x) <- c("integer", "foo")
>>> log(x)
>> [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379
>> attr(,"class")
>> [1] "integer" "foo"
>>> x + 0.5
>> [1] 1.5 2.5 3.5 4.5 5.5
>> attr(,"class")
>> [1] "integer" "foo"
>>
>> I do see the note in ?Arithmetic that states "All attributes
>(including
>> class) are preserved if there is no coercion".  Is this correct, or
>should
>> the returned value have an updated class of c("numeric", "foo")?
>Should foo
>> have its own methods to coerce the output to numeric?
>>
>> Thanks,
>> Cole
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From yogesh2cute at gmail.com  Fri Jun  9 14:22:06 2017
From: yogesh2cute at gmail.com (Yogesh Gupta)
Date: Fri, 9 Jun 2017 21:22:06 +0900
Subject: [R] Dendogram from RNAseq read count to show correlation between
 biological replicate using R
In-Reply-To: <CAAjHrnM5N3ukR3CcJ8C0Lg7FdHfg1zdyMPLss_QkoZ_tctQ+pQ@mail.gmail.com>
References: <CAAjHrnOJAiRkz17nJ3Vn0p2VWZA-vOKjMce=b0dwS8fhowLuDw@mail.gmail.com>
 <CAAjHrnOKiHxqOcdhkH74tL7UyubbK6mPSXXTkb=bu_0A3ujf4Q@mail.gmail.com>
 <CAAjHrnMhViTpY0gk3EMHf-mX7QE=swzTt0rXBGGqmdEYTJKhqA@mail.gmail.com>
 <CAAjHrnMoUTQ7eTZ5wPEHE-OhKLah6JmQ2a8pK-s9tZBihPLXXQ@mail.gmail.com>
 <CAAjHrnM5N3ukR3CcJ8C0Lg7FdHfg1zdyMPLss_QkoZ_tctQ+pQ@mail.gmail.com>
Message-ID: <CAAjHrnO3p-L7UpuNDb3UE8TCxNULbpn4NqPAWrzgtmY3uiUGtQ@mail.gmail.com>

Dear all,

I need to make dendogram from read count in a csv file across 34 samples
including biological replicate.

Please share R code or package to do this.

Do I also need to normalized read count before using read data?

Thanks

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun  9 17:16:10 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 9 Jun 2017 08:16:10 -0700
Subject: [R] Dendogram from RNAseq read count to show correlation
 between biological replicate using R
In-Reply-To: <CAAjHrnO3p-L7UpuNDb3UE8TCxNULbpn4NqPAWrzgtmY3uiUGtQ@mail.gmail.com>
References: <CAAjHrnOJAiRkz17nJ3Vn0p2VWZA-vOKjMce=b0dwS8fhowLuDw@mail.gmail.com>
 <CAAjHrnOKiHxqOcdhkH74tL7UyubbK6mPSXXTkb=bu_0A3ujf4Q@mail.gmail.com>
 <CAAjHrnMhViTpY0gk3EMHf-mX7QE=swzTt0rXBGGqmdEYTJKhqA@mail.gmail.com>
 <CAAjHrnMoUTQ7eTZ5wPEHE-OhKLah6JmQ2a8pK-s9tZBihPLXXQ@mail.gmail.com>
 <CAAjHrnM5N3ukR3CcJ8C0Lg7FdHfg1zdyMPLss_QkoZ_tctQ+pQ@mail.gmail.com>
 <CAAjHrnO3p-L7UpuNDb3UE8TCxNULbpn4NqPAWrzgtmY3uiUGtQ@mail.gmail.com>
Message-ID: <CAGxFJbRHjPMhCyBQkb5chqmNLW+KAATmvPfUE10tzMRFzBawSA@mail.gmail.com>

We don't do your work for you. Read the posting guide (below) to find
what we will do. If you are unwilling or unable to do your work
yourself -- including learning R-- you should consider finding someone
else who will.

-- Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 9, 2017 at 5:22 AM, Yogesh Gupta <yogesh2cute at gmail.com> wrote:
> Dear all,
>
> I need to make dendogram from read count in a csv file across 34 samples
> including biological replicate.
>
> Please share R code or package to do this.
>
> Do I also need to normalized read count before using read data?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From vd4mmind at gmail.com  Fri Jun  9 19:24:04 2017
From: vd4mmind at gmail.com (Vivek Das)
Date: Fri, 9 Jun 2017 19:24:04 +0200
Subject: [R] Dendogram from RNAseq read count to show correlation
 between biological replicate using R
In-Reply-To: <CAAjHrnO3p-L7UpuNDb3UE8TCxNULbpn4NqPAWrzgtmY3uiUGtQ@mail.gmail.com>
References: <CAAjHrnOJAiRkz17nJ3Vn0p2VWZA-vOKjMce=b0dwS8fhowLuDw@mail.gmail.com>
 <CAAjHrnOKiHxqOcdhkH74tL7UyubbK6mPSXXTkb=bu_0A3ujf4Q@mail.gmail.com>
 <CAAjHrnMhViTpY0gk3EMHf-mX7QE=swzTt0rXBGGqmdEYTJKhqA@mail.gmail.com>
 <CAAjHrnMoUTQ7eTZ5wPEHE-OhKLah6JmQ2a8pK-s9tZBihPLXXQ@mail.gmail.com>
 <CAAjHrnM5N3ukR3CcJ8C0Lg7FdHfg1zdyMPLss_QkoZ_tctQ+pQ@mail.gmail.com>
 <CAAjHrnO3p-L7UpuNDb3UE8TCxNULbpn4NqPAWrzgtmY3uiUGtQ@mail.gmail.com>
Message-ID: <CAFkF=gF2dZdDaTH8YvM_e_19xdhzCuB=2XsN8YRx4-iiVaYf+A@mail.gmail.com>

Yogesh please try to search in google or stackoverfolow or for that matter
Biostars. These are pretty simple linear programming tools specially
needing just required package and function once you parse the matrix or in
your case .csv file. If you find particular problem when your code runs an
error we can help. Without trying anything no one will do anything for you.
Try framing your query and search in google in the above-mentioned websites
you will find your answers. All the queries you have asked have been
addressed in multiple websites and bioinformatics or SO blogs. Try to learn
and practice R about how to work with it and then understand a standard
workflow used in RNA-Seq, and follow some Bioconductor tools there. You
will find your answers. Thanks

----------------------------------------------------------

Vivek Das


On Fri, Jun 9, 2017 at 2:22 PM, Yogesh Gupta <yogesh2cute at gmail.com> wrote:

> Dear all,
>
> I need to make dendogram from read count in a csv file across 34 samples
> including biological replicate.
>
> Please share R code or package to do this.
>
> Do I also need to normalized read count before using read data?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From xie at yihui.name  Fri Jun  9 20:53:27 2017
From: xie at yihui.name (Yihui Xie)
Date: Fri, 9 Jun 2017 13:53:27 -0500
Subject: [R] Paths in knitr
In-Reply-To: <trinity-3adc6b26-b5e9-4556-90aa-3565dd0e2093-1497001836366@3capp-gmx-bs27>
References: <OFE37F0A6B.835B65D9-ONC1258139.003D3941-C1258139.003DE23D@lotus.hawesko.de>
 <CANROs4f0FyOpEhX8KPA3Z_fJxb3EA2FhPy2ud3cGAYgSEKHdqA@mail.gmail.com>
 <trinity-3adc6b26-b5e9-4556-90aa-3565dd0e2093-1497001836366@3capp-gmx-bs27>
Message-ID: <CANROs4cTgVBTEw6r6We_gwjGTVs8PPqWVCbHD2_QSo9W=b8Gjg@mail.gmail.com>

I'd say it is an expert-only option. If you do not understand what it
means, I strongly recommend you not to set it.

Similarly, you set the root_dir option and I don't know why you did it, but
it is a typo anyway (should be root.dir).

Regards,
Yihui
--
https://yihui.name

On Fri, Jun 9, 2017 at 4:50 AM, <G.Maubach at gmx.de> wrote:

> Hi Yi,
>
> many thanks for your reply.
>
> Why I do have to se the base.dir option? Cause, to me it is not clear from
> the documentation, where knitr looks for data files and how I can adjust
> knitr to tell it where to look. base.dir was a try, but did not work.
>
> Can you give me a hint where I can find information/documentation on this
> path issue?
>
> Kind regards
>
> Georg
>
>
> > Gesendet: Donnerstag, 08. Juni 2017 um 15:05 Uhr
> > Von: "Yihui Xie" <xie at yihui.name>
> > An: G.Maubach at weinwolf.de
> > Cc: "R Help" <r-help at r-project.org>
> > Betreff: Re: [R] Paths in knitr
> >
> > Why do you have to set the base.dir option?
> >
> > Regards,
> > Yihui
> > --
> > https://yihui.name
> >
> >
> > On Thu, Jun 8, 2017 at 6:15 AM,  <G.Maubach at weinwolf.de> wrote:
> > > Hi All,
> > >
> > > I have to compile a report for the management and decided to use
> RMarkdown
> > > and knitr. I compiled all needed plots (using separate R scripts)
> before
> > > compiling the report, thus all plots reside in my graphics directory.
> The
> > > RMarkdown report needs to access these files. I have defined
> > >
> > > ```{r setup, include = FALSE}
> > > knitr::opts_knit$set(
> > >   echo = FALSE,
> > >   xtable.type = "html",
> > >   base.dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
> > >   root_dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
> > >   fig.path = "results/graphics")  # relative path required, see
> > > http://yihui.name/knitr/options
> > > ```
> > >
> > > and then referenced my plot using
> > >
> > > <img src = "email_distribution_pie.png"></img>
> > >
> > > because I want to be able to customize the plotting attributes.
> > >
> > > But that fails with the message "pandoc.exe: Could not fetch
> > > email_distribution_pie.png".
> > >
> > > If I give it the absolute path
> > > "H:/2017/Analysen/Kundenzufriedenheit/Auswertung/results/
> graphics/email_distribution_pie.png"
> > > it works fine as well if I copy the plot into the directory where the
> > > report.RMD file resides.
> > >
> > > How can I tell knitr to fetch the ready-made plots from the graphics
> > > directory?
> > >
> > > Kind regards
> > >
> > > Georg
>

	[[alternative HTML version deleted]]


From Rikushadow at hotmail.it  Fri Jun  9 18:10:54 2017
From: Rikushadow at hotmail.it (Alex Ferrara)
Date: Fri, 9 Jun 2017 16:10:54 +0000
Subject: [R] Exercise in R
Message-ID: <HE1PR08MB108285690576B22E8AA2B4F7B0CE0@HE1PR08MB1082.eurprd08.prod.outlook.com>

Hi i need some help with this exercise:

FIles: https://mega.nz/#!JxMFGIwC!qA85SBIBRVagCzYfmLwSvGuNK_qXqCXrakPxXryCpGg

#PARZIAL 3: GEO

#Data:
# Shapefile "INCOME" contains dummy information about revenue
# Common Abbreviations in the "INCOME" variable and the centroid altitude
#dell common in the variable "ALT"

#Richieste

# 1
#map of the variable "INCOME", choosing an appropriate color scale (save the map in pdf)

#2
#map of the variable "ALT", choosing a color palette from green to white, passing for brown (save the map in pdf)

# 3
#calculate the confidence interval of the pearson correlation coefficient between the variables considered

# 4
# Graph (and save in pdf) the relationship between variables via scatterplot,
#Set the graphic parameters appropriately and enter the correlation value in the title
#del previous point

# 5
#Comment what appears from the analysis performed

# 6
# Find a way to map variables on the same scale so that it is obvious
#the correlation found. (Suggestion: to use transformation, and possibly reversal of signs)

# 7
#fit a linear model that explains the income in function of altitude (original scales)

# 8
#load the metered values and those observed on the same scale

# 9
#wrap the gap between residual and observed and write the instructions that they print
# Consoles municipalities with the worst estimate (below and above estimated)

How should i do? Thanks for reply


	[[alternative HTML version deleted]]


From ezrabekele17 at gmail.com  Fri Jun  9 19:45:43 2017
From: ezrabekele17 at gmail.com (Ezra Bekele)
Date: Fri, 9 Jun 2017 10:45:43 -0700
Subject: [R] efetch result not in character format
Message-ID: <CAJ-7V8VsNtroioE=x0DvVXihiRGijTY_yHsNDqPyVVba__DdxQ@mail.gmail.com>

Hi,

I want to use reutils to obtain the accession numbers of a query search in
character format. When I use efetch, the accession number isn't in a
character format, and I'm not sure if the number is accurate, because I get
the error:

Error in file.exists(destfile) : object 'destfile' not found

This is what I tried:

UIDs<-esearch( "Methylation" )

accession_numbers = efetch(UIDs, rettype = "acc")

How do I obtain only the accession number and is the number accruate?

Thank you

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Jun 10 05:44:49 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 9 Jun 2017 20:44:49 -0700
Subject: [R] Exercise in R
In-Reply-To: <HE1PR08MB108285690576B22E8AA2B4F7B0CE0@HE1PR08MB1082.eurprd08.prod.outlook.com>
References: <HE1PR08MB108285690576B22E8AA2B4F7B0CE0@HE1PR08MB1082.eurprd08.prod.outlook.com>
Message-ID: <CAGxFJbQJz2UCOh7pLH00fVSpD_5cTJZOsjhUh01-i2FntZDCYA@mail.gmail.com>

We don't do homework here. Ask your professor for help.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 9, 2017 at 9:10 AM, Alex Ferrara <Rikushadow at hotmail.it> wrote:
> Hi i need some help with this exercise:
>
> FIles: https://mega.nz/#!JxMFGIwC!qA85SBIBRVagCzYfmLwSvGuNK_qXqCXrakPxXryCpGg
>
> #PARZIAL 3: GEO
>
> #Data:
> # Shapefile "INCOME" contains dummy information about revenue
> # Common Abbreviations in the "INCOME" variable and the centroid altitude
> #dell common in the variable "ALT"
>
> #Richieste
>
> # 1
> #map of the variable "INCOME", choosing an appropriate color scale (save the map in pdf)
>
> #2
> #map of the variable "ALT", choosing a color palette from green to white, passing for brown (save the map in pdf)
>
> # 3
> #calculate the confidence interval of the pearson correlation coefficient between the variables considered
>
> # 4
> # Graph (and save in pdf) the relationship between variables via scatterplot,
> #Set the graphic parameters appropriately and enter the correlation value in the title
> #del previous point
>
> # 5
> #Comment what appears from the analysis performed
>
> # 6
> # Find a way to map variables on the same scale so that it is obvious
> #the correlation found. (Suggestion: to use transformation, and possibly reversal of signs)
>
> # 7
> #fit a linear model that explains the income in function of altitude (original scales)
>
> # 8
> #load the metered values and those observed on the same scale
>
> # 9
> #wrap the gap between residual and observed and write the instructions that they print
> # Consoles municipalities with the worst estimate (below and above estimated)
>
> How should i do? Thanks for reply
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Jun 10 07:00:32 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 9 Jun 2017 22:00:32 -0700
Subject: [R] efetch result not in character format
In-Reply-To: <CAJ-7V8VsNtroioE=x0DvVXihiRGijTY_yHsNDqPyVVba__DdxQ@mail.gmail.com>
References: <CAJ-7V8VsNtroioE=x0DvVXihiRGijTY_yHsNDqPyVVba__DdxQ@mail.gmail.com>
Message-ID: <2E4923B0-5E6B-4327-ABA2-9B897A6290C1@comcast.net>


> On Jun 9, 2017, at 10:45 AM, Ezra Bekele <ezrabekele17 at gmail.com> wrote:
> 
> Hi,
> 
> I want to use reutils to obtain the accession numbers of a query search in
> character format. When I use efetch, the accession number isn't in a
> character format, and I'm not sure if the number is accurate, because I get
> the error:
> 
> Error in file.exists(destfile) : object 'destfile' not found
> 
> This is what I tried:
> 
> UIDs<-esearch( "Methylation" )

When I follow the rabbithole that is a question about a package I don't use, I first read the help pages for the functions that are proposed:
Search on efetch:
+++++++++++
Value

An efetch object.
+++++++

=====follow link to efetch======

Class "eutil": Reference classes that hold the response from EUtils requests.

Description
The reference classes eutil, einfo, esearch, esummary, efetch, elink, epost,egquery, espell, and ecitmatch implement the request generator for interaction with the NCBI services. They should not be used direcly, but initialized through the respective constructor functions einfo, esearch, esummary, efetch, elink, epost, egquery, espell, andecitmatch.
===

Note second sentence, and ...


> print(accession_numbers)
Object of class ?efetch? 
NDEW01000036.1
NDEX01000017.1
NDET01000017.1
NDEX01000020.1
NDEX01000029.1
NDET01000061.1
NDET01000086.1
NDEW01000125.1
NDEW01000140.1
NDEQ01000011.1
NDEY01000012.1
NDEY01000036.1
...
EFetch query using the ?nuccore? database.
Query url: ?https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?=efetch&db=nuccore...?
Retrieval type: ?acc?, retrieval mode: ?text?

> str(accession_numbers)
Error: This document does not contain XML data


I'm not going to be much help beyond this.


> 
> accession_numbers = efetch(UIDs, rettype = "acc")
> 
> How do I obtain only the accession number and is the number accruate?
> 
> Thank you
> 
> 	[[alternative HTML version deleted]]

Asking nicely: Please do post in plain text as suggested strongly by the Posting Guide.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From valkremk at gmail.com  Sun Jun 11 05:18:37 2017
From: valkremk at gmail.com (Val)
Date: Sat, 10 Jun 2017 22:18:37 -0500
Subject: [R] remove
Message-ID: <CAJOiR6ZnAZhrcA+R=zBMJgPoEpGPGhhQPgHDw6Q33s3gNsh9_w@mail.gmail.com>

Hi all,
I have  a date  issue and would appreciate any help.

I am reading a field data and  n one of the columns I am expecting a
date but has  non date  values  such as  character and  empty. space.
Here is a sample of my data.

KL <- read.table(header=TRUE, text='ID date
711 Dead
712 Uknown
713 20-11-08
714 11-28-07
301
302 09-02-02
303 09-21-02',stringsAsFactors = FALSE, fill =T)

str(KL)
data.frame': 7 obs. of  2 variables:
 $ ID  : int  711 712 713 714 301 302 303
 $ date: chr  "Dead" "Uknown" "20-11-08" "11-28-07" .

I wanted to convert the date column as follows.
if (max(unique(nchar(as.character(KL$date))))==10) {
  KL$date <- as.Date(KL$date,"%m/%d/%Y")
}
but not working.


How  could I to remove the corresponding entire row. that do not have
a date format and do the operation?
thank you in advance


From jdnewmil at dcn.davis.ca.us  Sun Jun 11 07:17:52 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 10 Jun 2017 22:17:52 -0700
Subject: [R] remove
In-Reply-To: <CAJOiR6ZnAZhrcA+R=zBMJgPoEpGPGhhQPgHDw6Q33s3gNsh9_w@mail.gmail.com>
References: <CAJOiR6ZnAZhrcA+R=zBMJgPoEpGPGhhQPgHDw6Q33s3gNsh9_w@mail.gmail.com>
Message-ID: <0B8421AF-7E79-4344-8651-432F92ED91C5@dcn.davis.ca.us>

You are using a slash in your format string to separate sub-fields but your data uses a dash.
-- 
Sent from my phone. Please excuse my brevity.

On June 10, 2017 8:18:37 PM PDT, Val <valkremk at gmail.com> wrote:
>Hi all,
>I have  a date  issue and would appreciate any help.
>
>I am reading a field data and  n one of the columns I am expecting a
>date but has  non date  values  such as  character and  empty. space.
>Here is a sample of my data.
>
>KL <- read.table(header=TRUE, text='ID date
>711 Dead
>712 Uknown
>713 20-11-08
>714 11-28-07
>301
>302 09-02-02
>303 09-21-02',stringsAsFactors = FALSE, fill =T)
>
>str(KL)
>data.frame': 7 obs. of  2 variables:
> $ ID  : int  711 712 713 714 301 302 303
> $ date: chr  "Dead" "Uknown" "20-11-08" "11-28-07" .
>
>I wanted to convert the date column as follows.
>if (max(unique(nchar(as.character(KL$date))))==10) {
>  KL$date <- as.Date(KL$date,"%m/%d/%Y")
>}
>but not working.
>
>
>How  could I to remove the corresponding entire row. that do not have
>a date format and do the operation?
>thank you in advance
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Jun 11 07:34:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 10 Jun 2017 22:34:36 -0700
Subject: [R] remove
In-Reply-To: <0B8421AF-7E79-4344-8651-432F92ED91C5@dcn.davis.ca.us>
References: <CAJOiR6ZnAZhrcA+R=zBMJgPoEpGPGhhQPgHDw6Q33s3gNsh9_w@mail.gmail.com>
 <0B8421AF-7E79-4344-8651-432F92ED91C5@dcn.davis.ca.us>
Message-ID: <CAGxFJbQ1_2t1a1+7oKC+=V3OxGxwYD-HVy7ppFg-XWDnQ5jkNQ@mail.gmail.com>

Also ?ifelse  rather than if()  I think.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jun 10, 2017 at 10:17 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> You are using a slash in your format string to separate sub-fields but your data uses a dash.
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 10, 2017 8:18:37 PM PDT, Val <valkremk at gmail.com> wrote:
>>Hi all,
>>I have  a date  issue and would appreciate any help.
>>
>>I am reading a field data and  n one of the columns I am expecting a
>>date but has  non date  values  such as  character and  empty. space.
>>Here is a sample of my data.
>>
>>KL <- read.table(header=TRUE, text='ID date
>>711 Dead
>>712 Uknown
>>713 20-11-08
>>714 11-28-07
>>301
>>302 09-02-02
>>303 09-21-02',stringsAsFactors = FALSE, fill =T)
>>
>>str(KL)
>>data.frame': 7 obs. of  2 variables:
>> $ ID  : int  711 712 713 714 301 302 303
>> $ date: chr  "Dead" "Uknown" "20-11-08" "11-28-07" .
>>
>>I wanted to convert the date column as follows.
>>if (max(unique(nchar(as.character(KL$date))))==10) {
>>  KL$date <- as.Date(KL$date,"%m/%d/%Y")
>>}
>>but not working.
>>
>>
>>How  could I to remove the corresponding entire row. that do not have
>>a date format and do the operation?
>>thank you in advance
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Jun 11 20:40:50 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 11 Jun 2017 11:40:50 -0700
Subject: [R] remove
In-Reply-To: <0B8421AF-7E79-4344-8651-432F92ED91C5@dcn.davis.ca.us>
References: <CAJOiR6ZnAZhrcA+R=zBMJgPoEpGPGhhQPgHDw6Q33s3gNsh9_w@mail.gmail.com>
 <0B8421AF-7E79-4344-8651-432F92ED91C5@dcn.davis.ca.us>
Message-ID: <FC29AF41-B49C-4AC9-A92D-3F79299C9B9A@dcn.davis.ca.us>

The usual way I filter is:

KL$Dt <- as.Date( KL$date, format='%d-%m-%y' )
KL2 <- KL[ !is.na( KL$Dt ), ]

-- 
Sent from my phone. Please excuse my brevity.

On June 10, 2017 10:17:52 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>You are using a slash in your format string to separate sub-fields but
>your data uses a dash.


From sinasac.s at gmail.com  Sun Jun 11 21:16:41 2017
From: sinasac.s at gmail.com (Sarah Sinasac)
Date: Sun, 11 Jun 2017 15:16:41 -0400
Subject: [R] plspm package error in data frame
Message-ID: <CAJcZ3mh_p+-C9QJ7=RBbcKdMvVq-RRZDrMeWcN9-bNKaasemXg@mail.gmail.com>

Hello,
I am new to R and hope I will not seem ignorant in this post. I am
currently using the plspm package by Gaston Sanchez accompanied by his
text book.
I have attempted to create a square matrix, which has seemed
successful. I used the following code:

> "Attitude" = c(1, 0, 0, 0, 0, 0, 0, 0)

> "Normative Beliefs" = c(1, 0, 0, 0, 0, 0, 0, 0)

> "Subjective Norm" = c(0, 0, 1, 0, 0, 0, 0, 0)

> "Control Beliefs" = c(1, 0, 1, 0, 0, 0, 0, 0)

> "Perceived Behavioural Control" = c(0, 0, 0, 0, 1, 0, 0, 0)

> "Intention" = c(0, 1, 0, 1, 0, 1, 0, 0)

> "Behaviour" = c(0, 0, 0, 0, 0, 0, 1, 0)

> TPB_path = rbind(`Behavioural Beliefs`, Attitude, `Normative Beliefs`, `Subjective Norm`, `Control Beliefs`, `Perceived Behavioural Control`, Intention, Behaviour)

> colnames(TPB_path) = rownames(TPB_path)

> innerplot(TPB_path, box.size = 0.1)

Then I attempted to set up the pls model using the following code (as
directed by the textbook and the r help function):

> #outermodel

> TPB_blocks = list(1:7, 8:14, 15:21, 22:28, 29:34, 35:39, 40:44, 45:48)

> TPB_modes = rep("A", 8)

> TPB_pls1 = plspm(TPBDATA, TPB_path, TPB_blocks, modes = TPB_modes)

However, I received the following error (I tried multiple times, and
cannot determine what the error is):

Error in `[.data.frame`(crossloadings, , c("name", "block", colnames(xloads))) :

  undefined columns selected


I would really appreciate if anyone could provide advice on how to
correct this error. I am using the plspm package in order to analyze
my data for my masters thesis at the University of Waterloo.

Thank you!
Sarah


From bgunter.4567 at gmail.com  Sun Jun 11 21:54:40 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 11 Jun 2017 12:54:40 -0700
Subject: [R] plspm package error in data frame
In-Reply-To: <CAJcZ3mh_p+-C9QJ7=RBbcKdMvVq-RRZDrMeWcN9-bNKaasemXg@mail.gmail.com>
References: <CAJcZ3mh_p+-C9QJ7=RBbcKdMvVq-RRZDrMeWcN9-bNKaasemXg@mail.gmail.com>
Message-ID: <CAGxFJbTuUzRnbSxCNwMTGUgLA0DnB4k+0zhCSV+HarR6TaOgeQ@mail.gmail.com>

You need to first go through a basic tutorial to learn basic R
constructs and functionality. IMHO, fooling around with special
packages before you learn the basics is a bad strategy. Packages
generally assume you know the basics.

Some tutorial recommendations can be found here:

https://www.rstudio.com/online-learning/

But just googling around the web will turn up lots of alternatives.
Choose what suits you best.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 11, 2017 at 12:16 PM, Sarah Sinasac <sinasac.s at gmail.com> wrote:
> Hello,
> I am new to R and hope I will not seem ignorant in this post. I am
> currently using the plspm package by Gaston Sanchez accompanied by his
> text book.
> I have attempted to create a square matrix, which has seemed
> successful. I used the following code:
>
>> "Attitude" = c(1, 0, 0, 0, 0, 0, 0, 0)
>
>> "Normative Beliefs" = c(1, 0, 0, 0, 0, 0, 0, 0)
>
>> "Subjective Norm" = c(0, 0, 1, 0, 0, 0, 0, 0)
>
>> "Control Beliefs" = c(1, 0, 1, 0, 0, 0, 0, 0)
>
>> "Perceived Behavioural Control" = c(0, 0, 0, 0, 1, 0, 0, 0)
>
>> "Intention" = c(0, 1, 0, 1, 0, 1, 0, 0)
>
>> "Behaviour" = c(0, 0, 0, 0, 0, 0, 1, 0)
>
>> TPB_path = rbind(`Behavioural Beliefs`, Attitude, `Normative Beliefs`, `Subjective Norm`, `Control Beliefs`, `Perceived Behavioural Control`, Intention, Behaviour)
>
>> colnames(TPB_path) = rownames(TPB_path)
>
>> innerplot(TPB_path, box.size = 0.1)
>
> Then I attempted to set up the pls model using the following code (as
> directed by the textbook and the r help function):
>
>> #outermodel
>
>> TPB_blocks = list(1:7, 8:14, 15:21, 22:28, 29:34, 35:39, 40:44, 45:48)
>
>> TPB_modes = rep("A", 8)
>
>> TPB_pls1 = plspm(TPBDATA, TPB_path, TPB_blocks, modes = TPB_modes)
>
> However, I received the following error (I tried multiple times, and
> cannot determine what the error is):
>
> Error in `[.data.frame`(crossloadings, , c("name", "block", colnames(xloads))) :
>
>   undefined columns selected
>
>
> I would really appreciate if anyone could provide advice on how to
> correct this error. I am using the plspm package in order to analyze
> my data for my masters thesis at the University of Waterloo.
>
> Thank you!
> Sarah
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sun Jun 11 22:36:03 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 11 Jun 2017 21:36:03 +0100
Subject: [R] plspm package error in data frame
In-Reply-To: <CAJcZ3mh_p+-C9QJ7=RBbcKdMvVq-RRZDrMeWcN9-bNKaasemXg@mail.gmail.com>
References: <CAJcZ3mh_p+-C9QJ7=RBbcKdMvVq-RRZDrMeWcN9-bNKaasemXg@mail.gmail.com>
Message-ID: <593DA9B3.1010508@sapo.pt>

Hello,

Your code throws an error before the line you've mentioned:

 > library(plspm)
 >
 > "Attitude" = c(1, 0, 0, 0, 0, 0, 0, 0)
 >
 > "Normative Beliefs" = c(1, 0, 0, 0, 0, 0, 0, 0)
 >
 > "Subjective Norm" = c(0, 0, 1, 0, 0, 0, 0, 0)
 >
 > "Control Beliefs" = c(1, 0, 1, 0, 0, 0, 0, 0)
 >
 > "Perceived Behavioural Control" = c(0, 0, 0, 0, 1, 0, 0, 0)
 >
 > "Intention" = c(0, 1, 0, 1, 0, 1, 0, 0)
 >
 > "Behaviour" = c(0, 0, 0, 0, 0, 0, 1, 0)
 >
 > TPB_path = rbind(`Behavioural Beliefs`, Attitude, `Normative 
Beliefs`, `Subjective Norm`, `Control Beliefs`, `Perceived Behavioural 
Control`, Intention, Behaviour)
Error in rbind(`Behavioural Beliefs`, Attitude, `Normative Beliefs`, 
`Subjective Norm`,  :
   object 'Behavioural Beliefs' not found


Please correct this error and post what 'Behavioural Beliefs' is.

Hope this helps,

Rui Barradas

Em 11-06-2017 20:16, Sarah Sinasac escreveu:
> Hello,
> I am new to R and hope I will not seem ignorant in this post. I am
> currently using the plspm package by Gaston Sanchez accompanied by his
> text book.
> I have attempted to create a square matrix, which has seemed
> successful. I used the following code:
>
>> "Attitude" = c(1, 0, 0, 0, 0, 0, 0, 0)
>
>> "Normative Beliefs" = c(1, 0, 0, 0, 0, 0, 0, 0)
>
>> "Subjective Norm" = c(0, 0, 1, 0, 0, 0, 0, 0)
>
>> "Control Beliefs" = c(1, 0, 1, 0, 0, 0, 0, 0)
>
>> "Perceived Behavioural Control" = c(0, 0, 0, 0, 1, 0, 0, 0)
>
>> "Intention" = c(0, 1, 0, 1, 0, 1, 0, 0)
>
>> "Behaviour" = c(0, 0, 0, 0, 0, 0, 1, 0)
>
>> TPB_path = rbind(`Behavioural Beliefs`, Attitude, `Normative Beliefs`, `Subjective Norm`, `Control Beliefs`, `Perceived Behavioural Control`, Intention, Behaviour)
>
>> colnames(TPB_path) = rownames(TPB_path)
>
>> innerplot(TPB_path, box.size = 0.1)
>
> Then I attempted to set up the pls model using the following code (as
> directed by the textbook and the r help function):
>
>> #outermodel
>
>> TPB_blocks = list(1:7, 8:14, 15:21, 22:28, 29:34, 35:39, 40:44, 45:48)
>
>> TPB_modes = rep("A", 8)
>
>> TPB_pls1 = plspm(TPBDATA, TPB_path, TPB_blocks, modes = TPB_modes)
>
> However, I received the following error (I tried multiple times, and
> cannot determine what the error is):
>
> Error in `[.data.frame`(crossloadings, , c("name", "block", colnames(xloads))) :
>
>    undefined columns selected
>
>
> I would really appreciate if anyone could provide advice on how to
> correct this error. I am using the plspm package in order to analyze
> my data for my masters thesis at the University of Waterloo.
>
> Thank you!
> Sarah
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From aleach at ualberta.ca  Sun Jun 11 23:16:40 2017
From: aleach at ualberta.ca (Andrew Leach)
Date: Sun, 11 Jun 2017 15:16:40 -0600
Subject: [R] Memory leak in nleqslv()
Message-ID: <CAM8OZNrAGwCPxnOxQXqeN332jx-1Sii+vjPhWPXbBJkPy=at1A@mail.gmail.com>

Hello all,

I am relatively new to R, but enjoying it very much.  I am hoping that
someone on this list can help me with an issue I am having.

I am having issues with iterations over nleqslv, in that the solver
does not appear to clean up memory used in previous iterations. I
believe I've isolated the/my issue in a small sample of code:

library(nleqslv)

cons_ext_test <- function(x){
rows_x <- length(x)/2
x_1 <- x[1:rows_x]
x_2 <- x[(rows_x+1):(rows_x*2)]
eq1<- x_1-100
eq2<-x_2*10-40
return(c(eq1,eq2))
}

model_test <- function()
{
reserves<-(c(0:200)/200)^(2)*2000
lambda <- numeric(NROW(reserves))+5
res_ext <- pmin((reserves*.5),5)
x_test <- c(res_ext,lambda)
#print(x_test)
for(test_iter in c(1:1000))
   nleqslv(x_test,cons_ext_test,jacobian=NULL)
i<- sort( sapply(ls(),function(x){object.size(get(x))}))
print(i[(NROW(i)-5):NROW(i)])
}

model_test()

When I run this over 1000 iterations, memory use ramps up to over 2.4 GB

While running it with 10 iterations uses far less memory, only 95MB:

Running it once has my rsession with 62Mb of use, so growth in memory
allocation scales with iterations.

Even after 1000 iterations, with 2+ GB of memory used by the R
session, no large-sized objects are listed, although mem_use() shows
2+ GB of memory used.

test_iter    lambda   res_ext  reserves    x_test
       48      1648     1648      1648      3256

I've replicated this on OS-X and in Windows both on a desktop and a
Surface Pro, however colleagues have run this on their machines and
not found the same result.  gc() does not rectify the issue, although
re-starting R does.

Any help would be much appreciated.

AJL


-- 
Andrew Leach
Associate Professor of Natural Resources, Energy and Environment (NREE)
Academic Director, Energy Programs
Alberta School of Business| 3-20D Business Building
University of Alberta |Edmonton, AB  T6G 2R6 | Canada
T. 780.492.8489
E. andrew.leach at ualberta.ca
www.business.ualberta.ca

Follow me on Twitter at @andrew_leach


From ashimkapoor at gmail.com  Mon Jun 12 07:23:40 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Mon, 12 Jun 2017 10:53:40 +0530
Subject: [R] Keep only those values in a row in a data frame which occur
	only once.
Message-ID: <CAC8=1er_BvCWEFjQ6x-8pEfuGiM7G-hDQ3nQW6ZtuNzE3Uz_9g@mail.gmail.com>

Dear All,

I have a file data.txt as follows:

Name_1,A,B,C
Name_2,E,F
Name_3,I,J,I,K,L,M

I will read this with:
my_data<- read.csv("data.txt",header=FALSE,col.names=paste0("V",
seq(1:10)),fill=TRUE)

Then the file will have 10 columns. I am assuming that each row in data.txt
will have at the max 10 entries.

Note: Here each row will have a different number of columns in data.txt but
each row will have 10 ( some trailing blank columns ) columns.

My query is how can I keep only the unique elements in each row? For
example: I want the row 3 to be Name_3,I,J,K,L,M

Please note I don't want the 2nd I to appear.

How can I do this?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From neiljsalkind at gmail.com  Mon Jun 12 03:39:40 2017
From: neiljsalkind at gmail.com (Neil Salkind)
Date: Sun, 11 Jun 2017 20:39:40 -0500
Subject: [R] =?utf-8?q?Beginner=E2=80=99s_Question?=
Message-ID: <055AA8AC-8060-40CC-BF9B-8D072CA7F889@gmail.com>

Please excuse the naive question but my first hour with RStudio, resulted in this?

> data()
> data(?women?)
Error: unexpected input in "data(??

So,that did not work but 

>data(women)

without the quotes did.

Would someone be so kind as to explain the function of quotes in RStudio? Thanks, Neil

*********************************
Whenever the people are well informed, they can be trusted with their own government.  ~ ~ ~Thomas Jefferson

Neil J. Salkind
(785) 841-0947
neiljsalkind at gmail.com


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Jun 12 08:48:53 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 12 Jun 2017 16:48:53 +1000
Subject: [R] =?utf-8?q?Beginner=E2=80=99s_Question?=
In-Reply-To: <055AA8AC-8060-40CC-BF9B-8D072CA7F889@gmail.com>
References: <055AA8AC-8060-40CC-BF9B-8D072CA7F889@gmail.com>
Message-ID: <CA+8X3fV4JBXyKwSEHsDWNPhBgLknkMS4+p9v=k2tqnWchmyB1A@mail.gmail.com>

Hi Meil,
Looks like the old fancy quote problem. You aren't cutting and pasting
text from Word are you?

Jim

On Mon, Jun 12, 2017 at 11:39 AM, Neil Salkind <neiljsalkind at gmail.com> wrote:
> Please excuse the naive question but my first hour with RStudio, resulted in this?
>
>> data()
>> data(?women?)
> Error: unexpected input in "data(??
>
> So,that did not work but
>
>>data(women)
>
> without the quotes did.
>
> Would someone be so kind as to explain the function of quotes in RStudio? Thanks, Neil
>
> *********************************
> Whenever the people are well informed, they can be trusted with their own government.  ~ ~ ~Thomas Jefferson
>
> Neil J. Salkind
> (785) 841-0947
> neiljsalkind at gmail.com
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Jun 12 09:02:42 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 12 Jun 2017 17:02:42 +1000
Subject: [R] Keep only those values in a row in a data frame which occur
 only once.
In-Reply-To: <CAC8=1er_BvCWEFjQ6x-8pEfuGiM7G-hDQ3nQW6ZtuNzE3Uz_9g@mail.gmail.com>
References: <CAC8=1er_BvCWEFjQ6x-8pEfuGiM7G-hDQ3nQW6ZtuNzE3Uz_9g@mail.gmail.com>
Message-ID: <CA+8X3fW4nQp9Oo=ej3eWd3nOJB2J6AM7AFU=T1DwggL8B3h98w@mail.gmail.com>

Hi Ashim,
One way is this, assuming that your data frame is named akdf:

akdf<-t(apply(akdf,1,function(x) return(unique(x)[1:length(x)])))

If you want factors instead of strings, more processing will be required.
Jim

On Mon, Jun 12, 2017 at 3:23 PM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> Dear All,
>
> I have a file data.txt as follows:
>
> Name_1,A,B,C
> Name_2,E,F
> Name_3,I,J,I,K,L,M
>
> I will read this with:
> my_data<- read.csv("data.txt",header=FALSE,col.names=paste0("V",
> seq(1:10)),fill=TRUE)
>
> Then the file will have 10 columns. I am assuming that each row in data.txt
> will have at the max 10 entries.
>
> Note: Here each row will have a different number of columns in data.txt but
> each row will have 10 ( some trailing blank columns ) columns.
>
> My query is how can I keep only the unique elements in each row? For
> example: I want the row 3 to be Name_3,I,J,K,L,M
>
> Please note I don't want the 2nd I to appear.
>
> How can I do this?
>
> Best Regards,
> Ashim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Mon Jun 12 09:24:48 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 12 Jun 2017 09:24:48 +0200
Subject: [R] Paths in knitr
Message-ID: <OF09B3F946.11C2DB96-ONC125813D.002544F6-C125813D.0028BABF@lotus.hawesko.de>

Hi Yihui,
Hi Duncan,

I corrected my typo. Unfortunately knitr did not find my plots in the 
directory where they reside which is different from the Rmd document.

The documentation of knitr says:

base.dir: (NULL) an absolute directory under which the plots are generate
root.dir: (NULL) the root directory when evaluating code chunks; if NULL, 
the directory of the input document will be used

>From that description I thought, if the base.dir can be used for writng 
plots, it is then also used for reading plots if set? No, it is not.
If I set the root directory to the plots/graphics directory will knitr 
then find my plots? No, it does not.

Reading blog posts my thoughts looked not so strange to me, e.g. 
https://philmikejones.wordpress.com/2015/05/20/set-root-directory-knitr/. 
Unfortunately, it does not work for me.

I am using a RStudio project file. Could it be that this interferes which 
the knitr options?

I tried the solution that Duncan suggested:

c_path_plots <- 
"H:/2017/Analysen/Kundenzufriedenheit/Auswertung/results/graphics

`r knitr::include_graphics(file.path(c_path_plots, 
"email_distribution_pie.png"))`

This solution works fine. I will go with it for this project as I have to 
finish my report soon.

I read Hadley's book on bulding R Packages (
https://www.amazon.de/R-Packages-Hadley-Wickham/dp/1491910593) and found 
it quite complicated and time consuming to build one. Thus I did not try 
yet to build my own packages. At the end of last week I heard from another 
library (http://reaktanz.de/R/pckg/roxyPackage/) which shall make building 
packages much easier. I plan to try that shortly.

On my path to become better in analytics using R, I will try to use 
modules of Rmd files which can then easily be integrated into a Rmd 
report. I have yet to see how I can include these file into a complete 
report.

Kind regards

Georg


----- Weitergeleitet von Georg Maubach/WWBO/WW/HAW am 12.06.2017 08:47 
-----

Von:    Yihui Xie <xie at yihui.name>
An:     G.Maubach at gmx.de, 
Kopie:  R Help <r-help at r-project.org>
Datum:  09.06.2017 20:53
Betreff:        Re: [R] Paths in knitr
Gesendet von:   "R-help" <r-help-bounces at r-project.org>



I'd say it is an expert-only option. If you do not understand what it
means, I strongly recommend you not to set it.

Similarly, you set the root_dir option and I don't know why you did it, 
but
it is a typo anyway (should be root.dir).

Regards,
Yihui
--
https://yihui.name

On Fri, Jun 9, 2017 at 4:50 AM, <G.Maubach at gmx.de> wrote:

> Hi Yi,
>
> many thanks for your reply.
>
> Why I do have to se the base.dir option? Cause, to me it is not clear 
from
> the documentation, where knitr looks for data files and how I can adjust
> knitr to tell it where to look. base.dir was a try, but did not work.
>
> Can you give me a hint where I can find information/documentation on 
this
> path issue?
>
> Kind regards
>
> Georg
>
>
> > Gesendet: Donnerstag, 08. Juni 2017 um 15:05 Uhr
> > Von: "Yihui Xie" <xie at yihui.name>
> > An: G.Maubach at weinwolf.de
> > Cc: "R Help" <r-help at r-project.org>
> > Betreff: Re: [R] Paths in knitr
> >
> > Why do you have to set the base.dir option?
> >
> > Regards,
> > Yihui
> > --
> > https://yihui.name
> >
> >
> > On Thu, Jun 8, 2017 at 6:15 AM,  <G.Maubach at weinwolf.de> wrote:
> > > Hi All,
> > >
> > > I have to compile a report for the management and decided to use
> RMarkdown
> > > and knitr. I compiled all needed plots (using separate R scripts)
> before
> > > compiling the report, thus all plots reside in my graphics 
directory.
> The
> > > RMarkdown report needs to access these files. I have defined
> > >
> > > ```{r setup, include = FALSE}
> > > knitr::opts_knit$set(
> > >   echo = FALSE,
> > >   xtable.type = "html",
> > >   base.dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
> > >   root_dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
> > >   fig.path = "results/graphics")  # relative path required, see
> > > http://yihui.name/knitr/options
> > > ```
> > >
> > > and then referenced my plot using
> > >
> > > <img src = "email_distribution_pie.png"></img>
> > >
> > > because I want to be able to customize the plotting attributes.
> > >
> > > But that fails with the message "pandoc.exe: Could not fetch
> > > email_distribution_pie.png".
> > >
> > > If I give it the absolute path
> > > "H:/2017/Analysen/Kundenzufriedenheit/Auswertung/results/
> graphics/email_distribution_pie.png"
> > > it works fine as well if I copy the plot into the directory where 
the
> > > report.RMD file resides.
> > >
> > > How can I tell knitr to fetch the ready-made plots from the graphics
> > > directory?
> > >
> > > Kind regards
> > >
> > > Georg
>

                 [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From b.rowlingson at lancaster.ac.uk  Mon Jun 12 10:39:29 2017
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 12 Jun 2017 09:39:29 +0100
Subject: [R] =?utf-8?q?Beginner=E2=80=99s_Question?=
In-Reply-To: <4a1719b0f8854904bcffd5ba6c567aa9@EX-0-HT0.lancs.local>
References: <4a1719b0f8854904bcffd5ba6c567aa9@EX-0-HT0.lancs.local>
Message-ID: <CANVKczPN+fBqZAEm8coy93uV=f6xh2CKmSDSBpeuMaqA7_oP2A@mail.gmail.com>

On Mon, Jun 12, 2017 at 2:39 AM, Neil Salkind <neiljsalkind at gmail.com> wrote:
> Please excuse the naive question but my first hour with RStudio, resulted in this?
>
>> data()
>> data(?women?)
> Error: unexpected input in "data(??
>
> So,that did not work but
>
>>data(women)
>
> without the quotes did.
>
> Would someone be so kind as to explain the function of quotes in RStudio? Thanks, Neil

First of all this is R, not RStudio. R is the language, the core, it
does all the computation. RStudio is just a pretty wrapper that lets
you click menus and arranges all your windows for you because it
thinks it knows how to arrange windows better than your operating
system. But I digress.

Quotes in R are used to define character strings. You can use single
or double quotes, but the exact same quote mark is used at the start
and finish. Unlike in proper books, R doesn't use "66" quotes at the
start and "99" quotes at the end of a string. Some word processors
will magically change standard plain quotes to super cute 66 and 99
quotes which seems to be how they may have sneaked into your RStudio
session.

Now in R, if you just type a word it usually means the value of the
thing with that name. So there's a difference between:

 x = y

and

 x = "y"

In the first case, x is going to get the value of an object called y,
and if there is no object called y it will error. In the second case x
is going to get the character value "y", and there's no object called
y involved at all. But there are exceptions....

The library function is probably the first exception people come
across. You can type:

library(stats)

without using any quotes, and even though there's no object called
stats, you don't get an error. The code in the library function uses
special powers to look at what you typed rather than the value of an
object called stats that you passed to the function. This means that
although there is a package called ggplot2 on my system, this doesn't
work:

 > thing="ggplot2"
 > library(thing)
 Error in library(thing) : there is no package called ?thing?

It looks for a package called thing rather than one called ggplot2. Surprise!

You *can* pass a character string value to library, so both
library(ggplot2) and  library("ggplot2") both work the same.

The data function is another function that uses the same methods as
library to get what you asked for. So (once you get your quotes
straightened out) you can do:

data(women)

or (double quotes):

data("women")

or (single quotes):

data('women')

Those of us who see this kind of behaviour as an impurity in a
language shudder when we think about it - names are names and strings
are strings - but others are grateful for saving two keystrokes every
time they type library(ggplot2).


> *********************************
> Whenever the people are well informed, they can be trusted with their own government.  ~ ~ ~Thomas Jefferson
>
> Neil J. Salkind
> (785) 841-0947
> neiljsalkind at gmail.com
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nina.schoenfelder at fernuni-hagen.de  Mon Jun 12 10:42:17 2017
From: nina.schoenfelder at fernuni-hagen.de (=?UTF-8?Q?Nina_Sch=c3=b6nfelder?=)
Date: Mon, 12 Jun 2017 10:42:17 +0200
Subject: [R] issues in plm using random effect model
In-Reply-To: <mailman.1.1496743201.20350.r-help@r-project.org>
References: <mailman.1.1496743201.20350.r-help@r-project.org>
Message-ID: <8b4e8c3d-bae8-6323-4d52-9888782b1e3c@fernuni-hagen.de>

Dear Kailas Gokhale,

The negative individual variance is not a problem with your code or plm. 
It a property of your data. Please check the posts of Giovanni Millo on 
this topic:

[R] R: plm random effect: the estimated variance of the individual 
effect is negative
Millo Giovanni Giovanni_Millo at Generali.com
Sat Jan 5 10:10:01 CET 2013

You can find the posts in the archive by rseek.org.

Kind regards,

Nina Sch?nfelder

-----
FernUniversit?t in Hagen
Fakult?t f?r Wirtschaftswissenschaft
Lehrstuhl f?r Volkswirtschaftslehre,
insbes. Makro?konomik
58084 Hagen

E-Mail: Nina.Schoenfelder at FernUni-Hagen.de
Telefon: +49 2331 987 - 2379
Fax: +49 2331 987 - 391

Hausanschrift:
Informationszentrum (IZ, ehemals TGZ)
Universit?tsstr. 11
Raum B110

Am 06.06.2017 um 12:00 schrieb r-help-request at r-project.org:
> Message: 1
> Date: Mon, 5 Jun 2017 15:41:23 +0530
> From: Kailas Gokhale<kls.gokhale at gmail.com>
> To:r-help at r-project.org
> Subject: [R] issues in plm using random effect model
> Message-ID:
> 	<CAMO91N4oCvTf1ZkHLqQ4t3SAbVw=VYLM-6JKt49CPbw+kUBiGg at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Dear Sir,
>
> Thank you for accepting my request for registration on this site.
> I am trying to solve panel data problems using plm package , but while
> suing random effect model i am getting following messege saying
> "
>
> Warning message:In sqrt(sigma2) : NaNs produced
>
> "
>
> In some other cases i am getting message saying where TSS = NA , that I am
> not understanding
> I am sending you my code along with out put.
>
> Kindly help me .
>
> I am sending you my code and output for your kind reference. data file is
> also attached
>
>
> rm(list=ls())
> library(MASS)
> library(bdsmatrix)
> library(zoo)
> library(nlme)
> library(sandwich)
> library(car)
> library(lmtest)
> library(plm)
>
> data1<- read.csv(file.choose(),header=TRUE,sep=",")
> D<-na.omit(data1)
> attach(D)
> Pdata<-plm.data(D, index=c("CT","T"))
>
> pool11<- plm(Y~X1+X2,data = Pdata, model="pooling")
> # pool21<- plm(Equity.dividend.1~ Profit.after.tax.1+ LaggedDivd.1+
> log(Size.1)+factor(CompanyName)-1,data = Pdata, model="pooling")
> fixed.mod1<- plm(Y~X1+X2,data = Pdata, model="within")
> rand.mod1<- plm(Y~X1+X2,data = Pdata, model="random")
>
>
> summary(pool11)
> summary(fixed.mod1)
> summary(fixef(fixed.mod1))
> summary(rand.mod1)
>
>
> ##################output####################
>
> Oneway (individual) effect Pooling Model
>
> Call:
> plm(formula = Y ~ X1 + X2, data = Pdata, model = "pooling")
>
> Unbalanced Panel: n=6, T=4-6, N=34
>
> Residuals :
>     Min. 1st Qu.  Median 3rd Qu.    Max.
> -19.400  -9.810  -0.648   8.490  23.900
>
> Coefficients :
>               Estimate Std. Error t-value  Pr(>|t|)
> (Intercept) 25.229162   6.858418  3.6786 0.0008847 ***
> X1           0.016438   0.046905  0.3504 0.7283744
> X2          -2.231250   2.220346 -1.0049 0.3227198
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Total Sum of Squares:    5082
> Residual Sum of Squares: 4892.7
> R-Squared:      0.037241
> Adj. R-Squared: 0.033955
> F-statistic: 0.599566 on 2 and 31 DF, p-value: 0.55529>
> summary(fixed.mod1)Oneway (individual) effect Within Model
>
> Call:
> plm(formula = Y ~ X1 + X2, data = Pdata, model = "within")
>
> Unbalanced Panel: n=6, T=4-6, N=34
>
> Residuals :
>      Min.  1st Qu.   Median  3rd Qu.     Max.
> -24.0000  -8.0400  -0.0795   6.6300  25.1000
>
> Coefficients :
>      Estimate Std. Error t-value Pr(>|t|)
> X1  0.065306   0.060090  1.0868   0.2871
> X2 -3.082215   2.514602 -1.2257   0.2313
>
> Total Sum of Squares:    4791.9
> Residual Sum of Squares: 4380.7
> R-Squared:      0.085822
> Adj. R-Squared: 0.065628
> F-statistic: 1.22042 on 2 and 26 DF, p-value: 0.31146>
> summary(fixef(fixed.mod1))  Estimate Std. Error t-value  Pr(>|t|)
> A  33.2672    10.4360  3.1877 0.0014340 **
> B  21.9300     9.2930  2.3598 0.0182831 *
> C  27.6590     7.9522  3.4781 0.0005049 ***
> D  21.9369     9.4271  2.3270 0.0199647 *
> E  17.6243     8.6149  2.0458 0.0407766 *
> F  23.8578     9.2198  2.5877 0.0096625 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1>
> summary(rand.mod1)Oneway (individual) effect Random Effect Model
>     (Swamy-Arora's transformation)
>
> Call:
> plm(formula = Y ~ X1 + X2, data = Pdata, model = "random")
>
> Unbalanced Panel: n=6, T=4-6, N=34
>
> Effects:
>                   var std.dev  share
> idiosyncratic 168.49   12.98  1.117
> individual    -17.60      NA -0.117
> theta  :
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> -0.6366 -0.6366 -0.6366 -0.5983 -0.6366 -0.3106
>
> Residuals :
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> -21.000 -11.400   0.913   0.114   9.040  24.000
>
> Coefficients :
>                Estimate Std. Error t-value  Pr(>|t|)
> (Intercept) 26.3963638  6.5706835  4.0173 0.0003482 ***
> X1          -0.0066621  0.0433425 -0.1537 0.8788364
> X2          -2.1087903  2.1533566 -0.9793 0.3350111
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Total Sum of Squares:    5548.4
> Residual Sum of Squares: 5382.1
> R-Squared:      0.037133
> Adj. R-Squared: 0.033856
> F-statistic: 0.479037 on 2 and 31 DF, p-value: 0.62389Warning
> message:In sqrt(sigma2) : NaNs produced
>
>
>
> with warm regards
> kailas D. Gokhale


From ruipbarradas at sapo.pt  Mon Jun 12 11:29:37 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 12 Jun 2017 10:29:37 +0100
Subject: [R] plspm package error in data frame
In-Reply-To: <CAJcZ3mjyYhzLb972L_inBAktfM1BBJxYGnsPbN8U-HDD=D4H4w@mail.gmail.com>
References: <CAJcZ3mh_p+-C9QJ7=RBbcKdMvVq-RRZDrMeWcN9-bNKaasemXg@mail.gmail.com>
 <593DA9B3.1010508@sapo.pt>
 <CAJcZ3mjyYhzLb972L_inBAktfM1BBJxYGnsPbN8U-HDD=D4H4w@mail.gmail.com>
Message-ID: <593E5F01.9030607@sapo.pt>

Hello,

Please allways cc the list, don't answer just to me.

Now I'm getting a different error. I had noticed that you have no 
reference to 'TPBDATA' before the call to plspm but I forgot to mention 
it in my first e-mail.


TPB_pls1 = plspm(TPBDATA, TPB_path, TPB_blocks, modes = TPB_modes)
Error in is_tabular(x) : object 'TPBDATA' not found

So we need to know what 'TPBDATA' is.

Rui Barradas

Em 12-06-2017 00:19, Sarah Sinasac escreveu:
> Hello Rui,
> I must have missed that line when I copied and pasted my code.
> Behavioural Beliefs is:
> "Behavioural Beliefs" = c(0, 0, 0, 0, 0, 0, 0, 0)
>
> Thank you,
> Sarah
>
> On Sun, Jun 11, 2017 at 4:36 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> Your code throws an error before the line you've mentioned:
>>
>>> library(plspm)
>>>
>>> "Attitude" = c(1, 0, 0, 0, 0, 0, 0, 0)
>>>
>>> "Normative Beliefs" = c(1, 0, 0, 0, 0, 0, 0, 0)
>>>
>>> "Subjective Norm" = c(0, 0, 1, 0, 0, 0, 0, 0)
>>>
>>> "Control Beliefs" = c(1, 0, 1, 0, 0, 0, 0, 0)
>>>
>>> "Perceived Behavioural Control" = c(0, 0, 0, 0, 1, 0, 0, 0)
>>>
>>> "Intention" = c(0, 1, 0, 1, 0, 1, 0, 0)
>>>
>>> "Behaviour" = c(0, 0, 0, 0, 0, 0, 1, 0)
>>>
>>> TPB_path = rbind(`Behavioural Beliefs`, Attitude, `Normative Beliefs`,
>>> `Subjective Norm`, `Control Beliefs`, `Perceived Behavioural Control`,
>>> Intention, Behaviour)
>> Error in rbind(`Behavioural Beliefs`, Attitude, `Normative Beliefs`,
>> `Subjective Norm`,  :
>>    object 'Behavioural Beliefs' not found
>>
>>
>> Please correct this error and post what 'Behavioural Beliefs' is.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> Em 11-06-2017 20:16, Sarah Sinasac escreveu:
>>>
>>> Hello,
>>> I am new to R and hope I will not seem ignorant in this post. I am
>>> currently using the plspm package by Gaston Sanchez accompanied by his
>>> text book.
>>> I have attempted to create a square matrix, which has seemed
>>> successful. I used the following code:
>>>
>>>> "Attitude" = c(1, 0, 0, 0, 0, 0, 0, 0)
>>>
>>>
>>>> "Normative Beliefs" = c(1, 0, 0, 0, 0, 0, 0, 0)
>>>
>>>
>>>> "Subjective Norm" = c(0, 0, 1, 0, 0, 0, 0, 0)
>>>
>>>
>>>> "Control Beliefs" = c(1, 0, 1, 0, 0, 0, 0, 0)
>>>
>>>
>>>> "Perceived Behavioural Control" = c(0, 0, 0, 0, 1, 0, 0, 0)
>>>
>>>
>>>> "Intention" = c(0, 1, 0, 1, 0, 1, 0, 0)
>>>
>>>
>>>> "Behaviour" = c(0, 0, 0, 0, 0, 0, 1, 0)
>>>
>>>
>>>> TPB_path = rbind(`Behavioural Beliefs`, Attitude, `Normative Beliefs`,
>>>> `Subjective Norm`, `Control Beliefs`, `Perceived Behavioural Control`,
>>>> Intention, Behaviour)
>>>
>>>
>>>> colnames(TPB_path) = rownames(TPB_path)
>>>
>>>
>>>> innerplot(TPB_path, box.size = 0.1)
>>>
>>>
>>> Then I attempted to set up the pls model using the following code (as
>>> directed by the textbook and the r help function):
>>>
>>>> #outermodel
>>>
>>>
>>>> TPB_blocks = list(1:7, 8:14, 15:21, 22:28, 29:34, 35:39, 40:44, 45:48)
>>>
>>>
>>>> TPB_modes = rep("A", 8)
>>>
>>>
>>>> TPB_pls1 = plspm(TPBDATA, TPB_path, TPB_blocks, modes = TPB_modes)
>>>
>>>
>>> However, I received the following error (I tried multiple times, and
>>> cannot determine what the error is):
>>>
>>> Error in `[.data.frame`(crossloadings, , c("name", "block",
>>> colnames(xloads))) :
>>>
>>>     undefined columns selected
>>>
>>>
>>> I would really appreciate if anyone could provide advice on how to
>>> correct this error. I am using the plspm package in order to analyze
>>> my data for my masters thesis at the University of Waterloo.
>>>
>>> Thank you!
>>> Sarah
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>


From sezenismail at gmail.com  Mon Jun 12 12:31:05 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Mon, 12 Jun 2017 13:31:05 +0300
Subject: [R] Memory leak in nleqslv()
In-Reply-To: <CAM8OZNrAGwCPxnOxQXqeN332jx-1Sii+vjPhWPXbBJkPy=at1A@mail.gmail.com>
References: <CAM8OZNrAGwCPxnOxQXqeN332jx-1Sii+vjPhWPXbBJkPy=at1A@mail.gmail.com>
Message-ID: <5F370185-AA48-4A69-8F75-73A0BFBA5731@gmail.com>


> On 12 Jun 2017, at 00:16, Andrew Leach <aleach at ualberta.ca> wrote:
> 
> Hello all,
> 
> I am relatively new to R, but enjoying it very much.  I am hoping that
> someone on this list can help me with an issue I am having.
> 
> I am having issues with iterations over nleqslv, in that the solver
> does not appear to clean up memory used in previous iterations. I
> believe I've isolated the/my issue in a small sample of code:
> 
> library(nleqslv)
> 
> cons_ext_test <- function(x){
> rows_x <- length(x)/2
> x_1 <- x[1:rows_x]
> x_2 <- x[(rows_x+1):(rows_x*2)]
> eq1<- x_1-100
> eq2<-x_2*10-40
> return(c(eq1,eq2))
> }
> 
> model_test <- function()
> {
> reserves<-(c(0:200)/200)^(2)*2000
> lambda <- numeric(NROW(reserves))+5
> res_ext <- pmin((reserves*.5),5)
> x_test <- c(res_ext,lambda)
> #print(x_test)
> for(test_iter in c(1:1000))
>   nleqslv(x_test,cons_ext_test,jacobian=NULL)
> i<- sort( sapply(ls(),function(x){object.size(get(x))}))
> print(i[(NROW(i)-5):NROW(i)])
> }
> 
> model_test()
> 
> When I run this over 1000 iterations, memory use ramps up to over 2.4 GB
> 
> While running it with 10 iterations uses far less memory, only 95MB:
> 
> Running it once has my rsession with 62Mb of use, so growth in memory
> allocation scales with iterations.
> 
> Even after 1000 iterations, with 2+ GB of memory used by the R
> session, no large-sized objects are listed, although mem_use() shows
> 2+ GB of memory used.
> 
> test_iter    lambda   res_ext  reserves    x_test
>       48      1648     1648      1648      3256
> 
> I've replicated this on OS-X and in Windows both on a desktop and a
> Surface Pro, however colleagues have run this on their machines and
> not found the same result.  gc() does not rectify the issue, although
> re-starting R does.
> 
> Any help would be much appreciated.
> 
> AJL
> 


Hello Andrew,

I could replicated same result. I think it?s time to send a bug report to author (Berend Hasselman <bhh at xs4all.nl>).

> sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Sierra 10.12.5

Matrix products: default
BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base     

other attached packages:
[1] nleqslv_3.3

loaded via a namespace (and not attached):
[1] compiler_3.4.0 tools_3.4.0 

From chalabi.elahe at yahoo.de  Mon Jun 12 14:40:47 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Mon, 12 Jun 2017 12:40:47 +0000 (UTC)
Subject: [R] count number of stop words in R
References: <1270272744.13109630.1497271247713.ref@mail.yahoo.com>
Message-ID: <1270272744.13109630.1497271247713@mail.yahoo.com>

Hi all,

Is there a way in R to count the number of stop words (English) of a string using tm package?

str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing . 

255 Levels: A boy's on the uh falling off the stool picking up cookies . The girl's reaching up for it . The girl the lady is is drying dishes . The water is uh running over uh from the sink into the floor . The window's opened . Dishes on the on the counter . She's outside ."

Thanks for any help!
Elahe


From mlathouri at yahoo.gr  Mon Jun 12 12:56:39 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Mon, 12 Jun 2017 10:56:39 +0000 (UTC)
Subject: [R] plotting gamm results in lattice
References: <1285525141.12938366.1497264999370.ref@mail.yahoo.com>
Message-ID: <1285525141.12938366.1497264999370@mail.yahoo.com>

Dear all,?
I hope that you can help me on this. I have been struggling to figure this out but I haven't found any solution.
I am running a generalised mixed effect model, gamm4, for an ecology project. Below is the code for the model:
model<-gamm4(LIFE.OE_spring~s(Q95, by=super.end.group)+Year+Hms_Rsctned+Hms_Poaching+X.broadleaved_woodland? ? ? ? ? ? ?+X.urban.suburban+X.CapWks, data=spring, random=~(1|WATERBODY_ID/SITE_ID))
plot(model$gam, page=1, font.lab=2, xlab="Residual Q95")

I am trying to plot the results in lattice for publication purposes so I need to figure this out. I have been struggling but I think I have reached a dead end.?

Here is what I have been able to code:
M<-predict(model$gam,type="response",se.fit=T)
upr<- M$fit + (1.96 * M$se.fit)lwr<- M$fit - (1.96 * M$se.fit)
library(lattice)xyplot(fitted(model$gam) ~ Q95 |super.end.group, data = spring, gm=model,? ? ? ?prepanel=function (x,y,...)list(ylim=c(min(upr),max(lwr))),? ? ? ?panel = function(x,y, gm, ...){ ? ??? ? ? ? ?panel.xyplot(x,y, type="smooth")? ? ? ? ?panel.lines(upr,lty=2, col="red")? ? ? ? ?panel.lines(lwr,lty=2, col="red")? ? ? ? ?panel.loess(x,y,...)? ? ? ? ?panel.rug(x = x[is.na(y)],? ? ? ? ? ? ? ? ? ?y = y[is.na(x)])? ? ? ?}? ? ? ?)
But, unfortunately, this is not what I get when I have the simple plot(model$gam).?

I have also attached a reproducible example in case you want to see for yourself. I hope that someone here has come up with a similar problem and can help me on this.
Thank you very much for your time.
Kind regards,Maria?
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: example.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170612/3a9fedae/attachment-0001.txt>

From petr.pikal at precheza.cz  Mon Jun 12 11:03:29 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 12 Jun 2017 09:03:29 +0000
Subject: [R] Problem related to rowSums
In-Reply-To: <CAAjHrnO6iQMM7UJ5qswT1iE95sjvn8gfbgV5D9HPx8oXbFKQ5A@mail.gmail.com>
References: <CAAjHrnO6iQMM7UJ5qswT1iE95sjvn8gfbgV5D9HPx8oXbFKQ5A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A72A0@SRVEXCHCM301.precheza.cz>

Hi

Not sure of your intention, do you want count how many rows have zeroes in all columns?

In that case something like

sum(rowSums(dat == 0) == ncol(dat))

should do the trick.

If it is not an answer for your problem, post some toy data and desired result.

Regards
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Yogesh
> Gupta
> Sent: Wednesday, June 7, 2017 11:09 AM
> To: r-help at r-project.org
> Subject: [R] Problem related to rowSums
>
> Hi...
>
> I have a dataframe with n columns and n rows. I need to find how many rows
> contains zero raw read count across all column.
>
> Thanks
>
> --
> *Yogesh Gupta*
> *Postdoctoral Researcher*
> *Department of Biological Science*
> *Seoul National University*
> *Seoul, South Korea*
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From S.Ellison at LGCGroup.com  Mon Jun 12 15:54:18 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 12 Jun 2017 14:54:18 +0100
Subject: [R] Keep only those values in a row in a data frame which
	occur	only once.
In-Reply-To: <CAC8=1er_BvCWEFjQ6x-8pEfuGiM7G-hDQ3nQW6ZtuNzE3Uz_9g@mail.gmail.com>
References: <CAC8=1er_BvCWEFjQ6x-8pEfuGiM7G-hDQ3nQW6ZtuNzE3Uz_9g@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E267240BA3DB200B@GBTEDVPEXCMB04.corp.lgc-group.com>

> I have a file data.txt as follows:
> 
> Name_1,A,B,C
> Name_2,E,F
> Name_3,I,J,I,K,L,M
> 
> My query is how can I keep only the unique elements in each row? For
> example: I want the row 3 to be Name_3,I,J,K,L,M
> 
> Please note I don't want the 2nd I to appear.
> 
> How can I do this?
Use unique() on each row and pad with NA?

Example:
uniq10 <- function(x, L=10) {
	u <- unique(x)
	c(u, rep(NA, L-length(u)) )
}

as.data.frame(  t( apply(tmp, 1, uniq10)  )  )

assuming tmp is the name of your initial data frame.

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From bgunter.4567 at gmail.com  Mon Jun 12 16:12:33 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 12 Jun 2017 07:12:33 -0700
Subject: [R] count number of stop words in R
In-Reply-To: <1270272744.13109630.1497271247713@mail.yahoo.com>
References: <1270272744.13109630.1497271247713.ref@mail.yahoo.com>
 <1270272744.13109630.1497271247713@mail.yahoo.com>
Message-ID: <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>

You can use regular expressions.

?regex and/or the stringr package are good places to start.  Of
course, you have to define "stop words."


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 12, 2017 at 5:40 AM, Elahe chalabi via R-help
<r-help at r-project.org> wrote:
> Hi all,
>
> Is there a way in R to count the number of stop words (English) of a string using tm package?
>
> str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .
>
> 255 Levels: A boy's on the uh falling off the stool picking up cookies . The girl's reaching up for it . The girl the lady is is drying dishes . The water is uh running over uh from the sink into the floor . The window's opened . Dishes on the on the counter . She's outside ."
>
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From patrcasi at nova.edu  Mon Jun 12 16:24:23 2017
From: patrcasi at nova.edu (Patrick Casimir)
Date: Mon, 12 Jun 2017 14:24:23 +0000
Subject: [R] count number of stop words in R
In-Reply-To: <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>
References: <1270272744.13109630.1497271247713.ref@mail.yahoo.com>
 <1270272744.13109630.1497271247713@mail.yahoo.com>,
 <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>
Message-ID: <BN6PR06MB347531A658E5563E18185044B9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>

You can define stop words as below.

data <- tm_map(data, removeWords, stopwords("english"))



Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Bert Gunter <bgunter.4567 at gmail.com>
Sent: Monday, June 12, 2017 10:12:33 AM
To: Elahe chalabi
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R

You can use regular expressions.

?regex and/or the stringr package are good places to start.  Of
course, you have to define "stop words."


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 12, 2017 at 5:40 AM, Elahe chalabi via R-help
<r-help at r-project.org> wrote:
> Hi all,
>
> Is there a way in R to count the number of stop words (English) of a string using tm package?
>
> str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .
>
> 255 Levels: A boy's on the uh falling off the stool picking up cookies . The girl's reaching up for it . The girl the lady is is drying dishes . The water is uh running over uh from the sink into the floor . The window's opened . Dishes on the on the counter . She's outside ."
>
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Mon Jun 12 17:23:42 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Mon, 12 Jun 2017 15:23:42 +0000 (UTC)
Subject: [R] count number of stop words in R
In-Reply-To: <BN6PR06MB347531A658E5563E18185044B9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>
References: <1270272744.13109630.1497271247713.ref@mail.yahoo.com>
 <1270272744.13109630.1497271247713@mail.yahoo.com>
 <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>
 <BN6PR06MB347531A658E5563E18185044B9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>
Message-ID: <1358356640.13454340.1497281022354@mail.yahoo.com>

Thanks for your reply. I know the command  
data <- tm_map(data, removeWords, stopwords("english"))
removes English stop words, I don't know how should I count stop words of my string:


str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .





On Monday, June 12, 2017 7:24 AM, Patrick Casimir <patrcasi at nova.edu> wrote:



You can define stop words as below.
data <- tm_map(data, removeWords, stopwords("english"))


Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________

From: R-help <r-help-bounces at r-project.org> on behalf of Bert Gunter <bgunter.4567 at gmail.com>
Sent: Monday, June 12, 2017 10:12:33 AM
To: Elahe chalabi
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R 
 
You can use regular expressions.

?regex and/or the stringr package are good places to start.  Of
course, you have to define "stop words."


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 12, 2017 at 5:40 AM, Elahe chalabi via R-help
<r-help at r-project.org> wrote:
> Hi all,
>
> Is there a way in R to count the number of stop words (English) of a string using tm package?
>
> str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the
sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .
>
> 255 Levels: A boy's on the uh falling off the stool picking up cookies . The girl's reaching up for it . The girl the lady is is drying dishes . The water is uh running over uh from the sink into the floor . The window's opened . Dishes on the on the counter
. She's outside ."
>
[[elided Yahoo spam]]
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From patrcasi at nova.edu  Mon Jun 12 17:36:45 2017
From: patrcasi at nova.edu (Patrick Casimir)
Date: Mon, 12 Jun 2017 15:36:45 +0000
Subject: [R] count number of stop words in R
In-Reply-To: <1358356640.13454340.1497281022354@mail.yahoo.com>
References: <1270272744.13109630.1497271247713.ref@mail.yahoo.com>
 <1270272744.13109630.1497271247713@mail.yahoo.com>
 <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>
 <BN6PR06MB347531A658E5563E18185044B9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>,
 <1358356640.13454340.1497281022354@mail.yahoo.com>
Message-ID: <BN6PR06MB3475D0803A605E9CC4F8DD0AB9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>

define your string as whatever object you want:

data <- "Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing."



Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________
From: Elahe chalabi <chalabi.elahe at yahoo.de>
Sent: Monday, June 12, 2017 11:23:42 AM
To: Patrick Casimir; Bert Gunter
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R

Thanks for your reply. I know the command
data <- tm_map(data, removeWords, stopwords("english"))
removes English stop words, I don't know how should I count stop words of my string:


str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .





On Monday, June 12, 2017 7:24 AM, Patrick Casimir <patrcasi at nova.edu> wrote:



You can define stop words as below.
data <- tm_map(data, removeWords, stopwords("english"))


Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________

From: R-help <r-help-bounces at r-project.org> on behalf of Bert Gunter <bgunter.4567 at gmail.com>
Sent: Monday, June 12, 2017 10:12:33 AM
To: Elahe chalabi
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R

You can use regular expressions.

?regex and/or the stringr package are good places to start.  Of
course, you have to define "stop words."


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 12, 2017 at 5:40 AM, Elahe chalabi via R-help
<r-help at r-project.org> wrote:
> Hi all,
>
> Is there a way in R to count the number of stop words (English) of a string using tm package?
>
> str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the
sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .
>
> 255 Levels: A boy's on the uh falling off the stool picking up cookies . The girl's reaching up for it . The girl the lady is is drying dishes . The water is uh running over uh from the sink into the floor . The window's opened . Dishes on the on the counter
. She's outside ."
>
[[elided Yahoo spam]]
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Mon Jun 12 17:42:43 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Mon, 12 Jun 2017 15:42:43 +0000 (UTC)
Subject: [R] count number of stop words in R
In-Reply-To: <BN6PR06MB3475D0803A605E9CC4F8DD0AB9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>
References: <1270272744.13109630.1497271247713.ref@mail.yahoo.com>
 <1270272744.13109630.1497271247713@mail.yahoo.com>
 <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>
 <BN6PR06MB347531A658E5563E18185044B9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>
 <1358356640.13454340.1497281022354@mail.yahoo.com>
 <BN6PR06MB3475D0803A605E9CC4F8DD0AB9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>
Message-ID: <1961213959.13453897.1497282163975@mail.yahoo.com>

Defining data as you mentioned in your respond causes the following error:

    
Error in UseMethod("tm_map", x) : 
no applicable method for 'tm_map' applied to an object of class "character"

I can solve this error by using  Corpus(VectorSource(my string)) and the using your command but I cannot see the number of stop words in my string!


On Monday, June 12, 2017 8:36 AM, Patrick Casimir <patrcasi at nova.edu> wrote:



define your string as whatever object you want:
data <- "Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing."


Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________


Sent: Monday, June 12, 2017 11:23:42 AM
To: Patrick Casimir; Bert Gunter
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R 
 
Thanks for your reply. I know the command  
data <- tm_map(data, removeWords, stopwords("english"))
removes English stop words, I don't know how should I count stop words of my string:


str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink
. And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .





On Monday, June 12, 2017 7:24 AM, Patrick Casimir <patrcasi at nova.edu> wrote:



You can define stop words as below.
data <- tm_map(data, removeWords, stopwords("english"))


Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________

From: R-help <r-help-bounces at r-project.org> on behalf of Bert Gunter <bgunter.4567 at gmail.com>
Sent: Monday, June 12, 2017 10:12:33 AM
To: Elahe chalabi
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R 
 
You can use regular expressions.

?regex and/or the stringr package are good places to start.  Of
course, you have to define "stop words."


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 12, 2017 at 5:40 AM, Elahe chalabi via R-help
<r-help at r-project.org> wrote:
> Hi all,
>
> Is there a way in R to count the number of stop words (English) of a string using tm package?
>
> str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the
sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .
>
> 255 Levels: A boy's on the uh falling off the stool picking up cookies . The girl's reaching up for it . The girl the lady is is drying dishes . The water is uh running over uh from the sink into the floor . The window's opened . Dishes on the on the counter
. She's outside ."
>
[[elided Yahoo spam]]
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From patrcasi at nova.edu  Mon Jun 12 17:48:42 2017
From: patrcasi at nova.edu (Patrick Casimir)
Date: Mon, 12 Jun 2017 15:48:42 +0000
Subject: [R] count number of stop words in R
In-Reply-To: <1961213959.13453897.1497282163975@mail.yahoo.com>
References: <1270272744.13109630.1497271247713.ref@mail.yahoo.com>
 <1270272744.13109630.1497271247713@mail.yahoo.com>
 <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>
 <BN6PR06MB347531A658E5563E18185044B9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>
 <1358356640.13454340.1497281022354@mail.yahoo.com>
 <BN6PR06MB3475D0803A605E9CC4F8DD0AB9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>,
 <1961213959.13453897.1497282163975@mail.yahoo.com>
Message-ID: <BN6PR06MB3475469E46E3128C0834D35FB9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>

you can use

summary (my string)


Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________
From: Elahe chalabi <chalabi.elahe at yahoo.de>
Sent: Monday, June 12, 2017 11:42:43 AM
To: Patrick Casimir; Bert Gunter
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R

Defining data as you mentioned in your respond causes the following error:


Error in UseMethod("tm_map", x) :
no applicable method for 'tm_map' applied to an object of class "character"

I can solve this error by using  Corpus(VectorSource(my string)) and the us[[elided Yahoo spam]]


On Monday, June 12, 2017 8:36 AM, Patrick Casimir <patrcasi at nova.edu> wrote:



define your string as whatever object you want:
data <- "Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing."


Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________


Sent: Monday, June 12, 2017 11:23:42 AM
To: Patrick Casimir; Bert Gunter
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R

Thanks for your reply. I know the command
data <- tm_map(data, removeWords, stopwords("english"))
removes English stop words, I don't know how should I count stop words of my string:


str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink
. And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .





On Monday, June 12, 2017 7:24 AM, Patrick Casimir <patrcasi at nova.edu> wrote:



You can define stop words as below.
data <- tm_map(data, removeWords, stopwords("english"))


Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________

From: R-help <r-help-bounces at r-project.org> on behalf of Bert Gunter <bgunter.4567 at gmail.com>
Sent: Monday, June 12, 2017 10:12:33 AM
To: Elahe chalabi
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R

You can use regular expressions.

?regex and/or the stringr package are good places to start.  Of
course, you have to define "stop words."


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 12, 2017 at 5:40 AM, Elahe chalabi via R-help
<r-help at r-project.org> wrote:
> Hi all,
>
> Is there a way in R to count the number of stop words (English) of a string using tm package?
>
> str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the
sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .
>
> 255 Levels: A boy's on the uh falling off the stool picking up cookies . The girl's reaching up for it . The girl the lady is is drying dishes . The water is uh running over uh from the sink into the floor . The window's opened . Dishes on the on the counter
. She's outside ."
>
[[elided Yahoo spam]]
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From patrcasi at nova.edu  Mon Jun 12 17:54:44 2017
From: patrcasi at nova.edu (Patrick Casimir)
Date: Mon, 12 Jun 2017 15:54:44 +0000
Subject: [R] count number of stop words in R
In-Reply-To: <1961213959.13453897.1497282163975@mail.yahoo.com>
References: <1270272744.13109630.1497271247713.ref@mail.yahoo.com>
 <1270272744.13109630.1497271247713@mail.yahoo.com>
 <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>
 <BN6PR06MB347531A658E5563E18185044B9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>
 <1358356640.13454340.1497281022354@mail.yahoo.com>
 <BN6PR06MB3475D0803A605E9CC4F8DD0AB9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>,
 <1961213959.13453897.1497282163975@mail.yahoo.com>
Message-ID: <BN6PR06MB347533550FAB9F1912CD6F15B9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>

Or use the qdap package to perform any quantitative analysis of your string.

https://cran.r-project.org/web/packages/qdap/qdap.pdf

Package ?qdap? - The Comprehensive R Archive Network<https://cran.r-project.org/web/packages/qdap/qdap.pdf>
cran.r-project.org
Package ?qdap? August 29, 2016 Type Package Title Bridging the Gap Between Qualitative Data and Quantitative Analysis Version 2.2.5 Date 2016-06-15





Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________
From: Elahe chalabi <chalabi.elahe at yahoo.de>
Sent: Monday, June 12, 2017 11:42:43 AM
To: Patrick Casimir; Bert Gunter
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R

Defining data as you mentioned in your respond causes the following error:


Error in UseMethod("tm_map", x) :
no applicable method for 'tm_map' applied to an object of class "character"

I can solve this error by using  Corpus(VectorSource(my string)) and the us[[elided Yahoo spam]]


On Monday, June 12, 2017 8:36 AM, Patrick Casimir <patrcasi at nova.edu> wrote:



define your string as whatever object you want:
data <- "Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing."


Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________


Sent: Monday, June 12, 2017 11:23:42 AM
To: Patrick Casimir; Bert Gunter
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R

Thanks for your reply. I know the command
data <- tm_map(data, removeWords, stopwords("english"))
removes English stop words, I don't know how should I count stop words of my string:


str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink
. And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .





On Monday, June 12, 2017 7:24 AM, Patrick Casimir <patrcasi at nova.edu> wrote:



You can define stop words as below.
data <- tm_map(data, removeWords, stopwords("english"))


Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________

From: R-help <r-help-bounces at r-project.org> on behalf of Bert Gunter <bgunter.4567 at gmail.com>
Sent: Monday, June 12, 2017 10:12:33 AM
To: Elahe chalabi
Cc: R-help Mailing List
Subject: Re: [R] count number of stop words in R

You can use regular expressions.

?regex and/or the stringr package are good places to start.  Of
course, you have to define "stop words."


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 12, 2017 at 5:40 AM, Elahe chalabi via R-help
<r-help at r-project.org> wrote:
> Hi all,
>
> Is there a way in R to count the number of stop words (English) of a string using tm package?
>
> str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the
sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .
>
> 255 Levels: A boy's on the uh falling off the stool picking up cookies . The girl's reaching up for it . The girl the lady is is drying dishes . The water is uh running over uh from the sink into the floor . The window's opened . Dishes on the on the counter
. She's outside ."
>
[[elided Yahoo spam]]
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Florian_Schwendinger at gmx.at  Mon Jun 12 17:41:28 2017
From: Florian_Schwendinger at gmx.at (Florian Schwendinger)
Date: Mon, 12 Jun 2017 17:41:28 +0200
Subject: [R] count number of stop words in R
In-Reply-To: <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>
References: <1270272744.13109630.1497271247713.ref@mail.yahoo.com>
 <1270272744.13109630.1497271247713@mail.yahoo.com>
 <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>
Message-ID: <trinity-75ed3b77-63e3-4596-a317-3c4c40062c48-1497282088721@3capp-gmx-bs56>

If you just want to count the stopwords you cloud do something like,

library(slam)
library(tm)

your_string <- "Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing ."
corp <- Corpus(VectorSource(your_string))

stopwords("en")

cntrl <- list(tolower=TRUE, stopwords = NULL,
              removePunctuation = FALSE, removeNumbers = TRUE, 
              stemming = FALSE, wordLengths = c(0, Inf))


dtm <- DocumentTermMatrix(corp, cntrl)

col_sums(dtm[, which(colnames(dtm) %in% stopwords("en"))])



Best,
Florian
?

Gesendet:?Montag, 12. Juni 2017 um 16:12 Uhr
Von:?"Bert Gunter" <bgunter.4567 at gmail.com>
An:?"Elahe chalabi" <chalabi.elahe at yahoo.de>
Cc:?"R-help Mailing List" <r-help at r-project.org>
Betreff:?Re: [R] count number of stop words in R
You can use regular expressions.

?regex and/or the stringr package are good places to start. Of
course, you have to define "stop words."


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 12, 2017 at 5:40 AM, Elahe chalabi via R-help
<r-help at r-project.org> wrote:
> Hi all,
>
> Is there a way in R to count the number of stop words (English) of a string using tm package?
>
> str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .
>
> 255 Levels: A boy's on the uh falling off the stool picking up cookies . The girl's reaching up for it . The girl the lady is is drying dishes . The water is uh running over uh from the sink into the floor . The window's opened . Dishes on the on the counter . She's outside ."
>
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Jun 12 18:16:08 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 12 Jun 2017 09:16:08 -0700
Subject: [R] count number of stop words in R
In-Reply-To: <1358356640.13454340.1497281022354@mail.yahoo.com>
References: <1270272744.13109630.1497271247713.ref@mail.yahoo.com>
 <1270272744.13109630.1497271247713@mail.yahoo.com>
 <CAGxFJbR20DfBbt3aiHOGDozbBaS7-bhxB+Xfooc1tYfUn-=n8g@mail.gmail.com>
 <BN6PR06MB347531A658E5563E18185044B9CD0@BN6PR06MB3475.namprd06.prod.outlook.com>
 <1358356640.13454340.1497281022354@mail.yahoo.com>
Message-ID: <CAGxFJbR_1OHYb_A1i-+KP_KDq_hqcDjrdWEH461Zor31BWc3cA@mail.gmail.com>

I am unfamiliar with the tm package, but using basic regex tools, is
this what you want:

test <- "Mhm . Alright . There's um a young boy that's getting a
cookie jar . And it he's uh in bad shape because uh the thing is
falling over . And in the picture the mother is washing dishes and
doesn't see it . And so is the the water is overflowing in the sink .
And the dishes might get falled over if you don't fell fall over there
there if you don't get it . And it there it's a picture of a kitchen
window . And the curtains are very uh distinct . But the water is
still flowing ."

out <- strsplit(test, " ") ## creates a list whose only component is a
vector of the words

stopw <- c("a","the") ## or whatever they are

sum(grepl(paste(stopw,collapse="|"), out[[1]]))

## If you want to include ".", a regex special character, add:
sum(grepl(".",out[[1]],fixed=TRUE))


If this is all nonsense, just ignore -- and sorry I couldn't help.

-- Bert




Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 12, 2017 at 8:23 AM, Elahe chalabi <chalabi.elahe at yahoo.de> wrote:
> Thanks for your reply. I know the command
> data <- tm_map(data, removeWords, stopwords("english"))
> removes English stop words, I don't know how should I count stop words of my string:
>
>
> str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .
>
>
>
>
>
> On Monday, June 12, 2017 7:24 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
>
>
>
> You can define stop words as below.
> data <- tm_map(data, removeWords, stopwords("english"))
>
>
> Patrick Casimir, PhD
> Health Analytics, Data Science, Big Data Expert & Independent Consultant
> C: 954.614.1178
>
> ________________________________
>
> From: R-help <r-help-bounces at r-project.org> on behalf of Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Monday, June 12, 2017 10:12:33 AM
> To: Elahe chalabi
> Cc: R-help Mailing List
> Subject: Re: [R] count number of stop words in R
>
> You can use regular expressions.
>
> ?regex and/or the stringr package are good places to start.  Of
> course, you have to define "stop words."
>
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 12, 2017 at 5:40 AM, Elahe chalabi via R-help
> <r-help at r-project.org> wrote:
>> Hi all,
>>
>> Is there a way in R to count the number of stop words (English) of a string using tm package?
>>
>> str="Mhm . Alright . There's um a young boy that's getting a cookie jar . And it he's uh in bad shape because uh the thing is falling over . And in the picture the mother is washing dishes and doesn't see it . And so is the the water is overflowing in the
> sink . And the dishes might get falled over if you don't fell fall over there there if you don't get it . And it there it's a picture of a kitchen window . And the curtains are very uh distinct . But the water is still flowing .
>>
>> 255 Levels: A boy's on the uh falling off the stool picking up cookies . The girl's reaching up for it . The girl the lady is is drying dishes . The water is uh running over uh from the sink into the floor . The window's opened . Dishes on the on the counter
> . She's outside ."
>>
>> Thanks for any help!
>> Elahe
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Mon Jun 12 17:26:27 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 13 Jun 2017 01:26:27 +1000
Subject: [R] plotting gamm results in lattice
In-Reply-To: <1285525141.12938366.1497264999370@mail.yahoo.com>
References: <1285525141.12938366.1497264999370.ref@mail.yahoo.com>
 <1285525141.12938366.1497264999370@mail.yahoo.com>
Message-ID: <000001d2e390$42cd9210$c868b630$@bigpond.com>

Hi Maria

If you have problems just start with a small model with predictions and then plot with xyplot
the same applies to xyplot
Try 

library(gamm4)

spring <- dget(file = "G:/1/example.txt")
 str(spring)
'data.frame':   11744 obs. of  11 variables:
 $ WATERBODY_ID          : Factor w/ 1994 levels "GB102021072830",..: 1 1 2 2 2 3 3 3 4 4 ...
 $ SITE_ID               : int  157166 157166 1636 1636 1636 1635 1635 1635 134261 1631 ...
 $ Year                  : int  2011 2014 2013 2006 2003 2002 2013 2005 2013 2006 ...
 $ Q95                   : num  100 100 80 80 80 98 98 98 105 105 ...
 $ LIFE.OE_spring        : num  1.02 1.03 1.02 1.06 1.06 1.07 1.12 1.05 1.14 1.05 ...
 $ super.end.group       : Factor w/ 6 levels "B","C","D","E",..: 1 1 3 3 3 2 2 2 4 4 ...
 $ X.urban.suburban      : num  0 0 0.07 0.07 0.07 0.53 0.53 0.53 8.07 8.07 ...
 $ X.broadleaved_woodland: num  2.83 2.83 10.39 10.39 10.39 ...
 $ X.CapWks              : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Hms_Poaching          : int  0 0 10 10 10 0 0 0 0 0 ...
 $ Hms_Rsctned           : int  0 0 0 0 0 0 0 0 0 0 ...

model<-
gamm4(LIFE.OE_spring~s(Q95, by=super.end.group)+Year+Hms_Rsctned+Hms_Poaching+X.broadleaved_woodland +X.urban.suburban+X.CapWks, data=spring,
      random=~(1|WATERBODY_ID/SITE_ID))
Warning message:
Some predictor variables are on very different scales: consider rescaling

# plot(model$gam, page=1, font.lab=2, xlab="Residual Q95")

M <-predict(model$gam,type="response",se.fit=T)

# joining the dataset and the predictions keep it "in house" and on path
springP = cbind(spring, M)
springP$upper = with(springP,fit+1.96*se.fit)
springP$lower = with(springP,fit-1.96*se.fit)
str(springP)
'data.frame':   11744 obs. of  15 variables:
 $ WATERBODY_ID          : Factor w/ 1994 levels "GB102021072830",..: 1 1 2 2 2 3 3 3 4 4 ...
 $ SITE_ID               : int  157166 157166 1636 1636 1636 1635 1635 1635 134261 1631 ...
 $ Year                  : int  2011 2014 2013 2006 2003 2002 2013 2005 2013 2006 ...
 $ Q95                   : num  100 100 80 80 80 98 98 98 105 105 ...
 $ LIFE.OE_spring        : num  1.02 1.03 1.02 1.06 1.06 1.07 1.12 1.05 1.14 1.05 ...
 $ super.end.group       : Factor w/ 6 levels "B","C","D","E",..: 1 1 3 3 3 2 2 2 4 4 ...
 $ X.urban.suburban      : num  0 0 0.07 0.07 0.07 0.53 0.53 0.53 8.07 8.07 ...
 $ X.broadleaved_woodland: num  2.83 2.83 10.39 10.39 10.39 ...
 $ X.CapWks              : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Hms_Poaching          : int  0 0 10 10 10 0 0 0 0 0 ...
 $ Hms_Rsctned           : int  0 0 0 0 0 0 0 0 0 0 ...
 $ fit                   : num [1:11744(1d)] 1.03 1.04 1.04 1.02 1.01 ...
  ..- attr(*, "dimnames")=List of 1
  .. ..$ : chr  "1" "2" "3" "4" ...
 $ se.fit                : num [1:11744(1d)] 0.00263 0.00266 0.00408 0.00408 0.00411 ...
  ..- attr(*, "dimnames")=List of 1
  .. ..$ : chr  "1" "2" "3" "4" ...
 $ upper                 : num [1:11744(1d)] 1.03 1.04 1.05 1.03 1.02 ...
  ..- attr(*, "dimnames")=List of 1
  .. ..$ : chr  "1" "2" "3" "4" ...
 $ lower                 : num [1:11744(1d)] 1.02 1.03 1.03 1.01 1 ...
  ..- attr(*, "dimnames")=List of 1
  .. ..$ : chr  "1" "2" "3" "4" ...

# this produces a mess of lines for the upper and lower
xyplot(fitted(model$gam) ~ Q95 |super.end.group, data = springP,
       lower = springP$lower,
       upper = springP$upper,
       subscripts = TRUE,
       panel = function(x,y, upper, lower, subscripts, ...){
                  panel.xyplot(x,y, type="smooth")
                  panel.xyplot(x[order(x)], upper[subscripts][order(x)], lty=2, col="red")
                  panel.xyplot(x[order(x)], lower[subscripts][order(x)], lty=2, col="red")
                  #panel.loess(x,y,...) #  have not tried to fix these lines- depends on what you want to do
                  #panel.rug(x = x[is.na(y)], y = y[is.na(x)])
                }
)

# smoothing them produces reasonable lines
xyplot(fitted(model$gam) ~ Q95 |super.end.group, data = springP,
       lower = springP$lower,
       upper = springP$upper,
       subscripts = TRUE,
       panel = function(x,y, upper, lower, subscripts, ...){
                  panel.xyplot(x,y, type="smooth")
                  panel.xyplot(x[order(x)], upper[subscripts][order(x)], type = "smooth", lty=2, col="red")
                  panel.xyplot(x[order(x)], lower[subscripts][order(x)], type = "smooth", lty=2, col="red")
                  #panel.loess(x,y,...)
                  #panel.rug(x = x[is.na(y)], y = y[is.na(x)])
                }
)

# by newdata = ...
# take a cross-section of data - reduces the amount of data to be plotted
mx = aggregate(Q95 ~ super.end.group, spring, max, na.rm=T)
newlst <-
do.call(rbind,
        lapply(1:6, function(j) expand.grid(Q95 = seq(0,mx[j,2], length = 50), super.end.group = LETTERS[j])
                                            Year =
                                            Hms_Rsctned =
                                            ...))   # fill in yourself
newd <- data.frame(newlst)

and predict using newdata = newd

# starting with a smaller model
model2 <-
gamm4(LIFE.OE_spring~s(Q95, by=super.end.group), data=spring,
      random=~(1|WATERBODY_ID/SITE_ID))

newlst <-
do.call(rbind,
        lapply(1:6, function(j) expand.grid(Q95 = seq(0,mx[j,2], length = 50), super.end.group = LETTERS[j])) )
newd <- data.frame(Q95 = newlst)
# The following is untested
# I have not used gamm4 for a while; is  model$gam correct? Had problems here - have no time to go into the help pages
M3 <- predict(model2$gamm, newdata = newd, type="response",se.fit=T)

# keep together 
newdat = cbind(newd, M3)

# If you want CIs
newdat <- within(newdat, {
    lower = fit-1.96*se.fit
    upper = fit+1.96*se.fit
})

# plot- something like
xyplot(fitted(model$gam) ~ Q95 |super.end.group, data = springP,
       Q2    = newddat$Q95,
       lower = newdat$lower,
       upper = newdat$upper,
       subscripts = TRUE,
       panel = function(x,y, Q2, upper, lower, subscripts, ...){
                  panel.xyplot(x,y, type="smooth")
                  panel.xyplot(Q2, upper, lty=2, col="red")
                  panel.xyplot(Q2, lower, lty=2, col="red")
                  #panel.loess(x,y,...)
                  #panel.rug(x = x[is.na(y)], y = y[is.na(x)])
                }
)

If you are putting a key onto the plot see
? xyplot and par.settings and key 

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maria Lathouri via R-help
Sent: Monday, 12 June 2017 20:57
To: R-help Mailing List
Subject: [R] plotting gamm results in lattice

Dear all, 
I hope that you can help me on this. I have been struggling to figure this out but I haven't found any solution.
I am running a generalised mixed effect model, gamm4, for an ecology project. Below is the code for the model:
model<-gamm4(LIFE.OE_spring~s(Q95, by=super.end.group)+Year+Hms_Rsctned+Hms_Poaching+X.broadleaved_woodland             +X.urban.suburban+X.CapWks, data=spring, random=~(1|WATERBODY_ID/SITE_ID))
plot(model$gam, page=1, font.lab=2, xlab="Residual Q95")

I am trying to plot the results in lattice for publication purposes so I need to figure this out. I have been struggling but I think I have reached a dead end. 

Here is what I have been able to code:
M<-predict(model$gam,type="response",se.fit=T)
upr<- M$fit + (1.96 * M$se.fit)lwr<- M$fit - (1.96 * M$se.fit)
library(lattice)xyplot(fitted(model$gam) ~ Q95 |super.end.group, data = spring, gm=model,       prepanel=function (x,y,...)list(ylim=c(min(upr),max(lwr))),       panel = function(x,y, gm, ...){              panel.xyplot(x,y, type="smooth")         panel.lines(upr,lty=2, col="red")         panel.lines(lwr,lty=2, col="red")         panel.loess(x,y,...)         panel.rug(x = x[is.na(y)],                   y = y[is.na(x)])       }       )
But, unfortunately, this is not what I get when I have the simple plot(model$gam). 

I have also attached a reproducible example in case you want to see for yourself. I hope that someone here has come up with a similar problem and can help me on this.
Thank you very much for your time.
Kind regards,Maria 


From xie at yihui.name  Mon Jun 12 18:29:33 2017
From: xie at yihui.name (Yihui Xie)
Date: Mon, 12 Jun 2017 11:29:33 -0500
Subject: [R] Paths in knitr
In-Reply-To: <OF09B3F946.11C2DB96-ONC125813D.002544F6-C125813D.0028BABF@lotus.hawesko.de>
References: <OF09B3F946.11C2DB96-ONC125813D.002544F6-C125813D.0028BABF@lotus.hawesko.de>
Message-ID: <CANROs4cZe=McrdHiGTYvK1+uOf_iKxohrHJ1ZO-Gf6WNNhVTPg@mail.gmail.com>

Will there be anything wrong if you do not set these options?

Regards,
Yihui
--
https://yihui.name


On Mon, Jun 12, 2017 at 2:24 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi Yihui,
> Hi Duncan,
>
> I corrected my typo. Unfortunately knitr did not find my plots in the
> directory where they reside which is different from the Rmd document.
>
> The documentation of knitr says:
>
> base.dir: (NULL) an absolute directory under which the plots are generate
> root.dir: (NULL) the root directory when evaluating code chunks; if NULL,
> the directory of the input document will be used
>
> From that description I thought, if the base.dir can be used for writng
> plots, it is then also used for reading plots if set? No, it is not.
> If I set the root directory to the plots/graphics directory will knitr
> then find my plots? No, it does not.
>
> Reading blog posts my thoughts looked not so strange to me, e.g.
> https://philmikejones.wordpress.com/2015/05/20/set-root-directory-knitr/.
> Unfortunately, it does not work for me.
>
> I am using a RStudio project file. Could it be that this interferes which
> the knitr options?
>
> I tried the solution that Duncan suggested:
>
> c_path_plots <-
> "H:/2017/Analysen/Kundenzufriedenheit/Auswertung/results/graphics
>
> `r knitr::include_graphics(file.path(c_path_plots,
> "email_distribution_pie.png"))`
>
> This solution works fine. I will go with it for this project as I have to
> finish my report soon.
>
> I read Hadley's book on bulding R Packages (
> https://www.amazon.de/R-Packages-Hadley-Wickham/dp/1491910593) and found
> it quite complicated and time consuming to build one. Thus I did not try
> yet to build my own packages. At the end of last week I heard from another
> library (http://reaktanz.de/R/pckg/roxyPackage/) which shall make building
> packages much easier. I plan to try that shortly.
>
> On my path to become better in analytics using R, I will try to use
> modules of Rmd files which can then easily be integrated into a Rmd
> report. I have yet to see how I can include these file into a complete
> report.
>
> Kind regards
>
> Georg
>
>
> ----- Weitergeleitet von Georg Maubach/WWBO/WW/HAW am 12.06.2017 08:47
> -----
>
> Von:    Yihui Xie <xie at yihui.name>
> An:     G.Maubach at gmx.de,
> Kopie:  R Help <r-help at r-project.org>
> Datum:  09.06.2017 20:53
> Betreff:        Re: [R] Paths in knitr
> Gesendet von:   "R-help" <r-help-bounces at r-project.org>
>
>
>
> I'd say it is an expert-only option. If you do not understand what it
> means, I strongly recommend you not to set it.
>
> Similarly, you set the root_dir option and I don't know why you did it,
> but
> it is a typo anyway (should be root.dir).
>
> Regards,
> Yihui
> --
> https://yihui.name
>
> On Fri, Jun 9, 2017 at 4:50 AM, <G.Maubach at gmx.de> wrote:
>
>> Hi Yi,
>>
>> many thanks for your reply.
>>
>> Why I do have to se the base.dir option? Cause, to me it is not clear
> from
>> the documentation, where knitr looks for data files and how I can adjust
>> knitr to tell it where to look. base.dir was a try, but did not work.
>>
>> Can you give me a hint where I can find information/documentation on
> this
>> path issue?
>>
>> Kind regards
>>
>> Georg
>>
>>
>> > Gesendet: Donnerstag, 08. Juni 2017 um 15:05 Uhr
>> > Von: "Yihui Xie" <xie at yihui.name>
>> > An: G.Maubach at weinwolf.de
>> > Cc: "R Help" <r-help at r-project.org>
>> > Betreff: Re: [R] Paths in knitr
>> >
>> > Why do you have to set the base.dir option?
>> >
>> > Regards,
>> > Yihui
>> > --
>> > https://yihui.name
>> >
>> >
>> > On Thu, Jun 8, 2017 at 6:15 AM,  <G.Maubach at weinwolf.de> wrote:
>> > > Hi All,
>> > >
>> > > I have to compile a report for the management and decided to use
>> RMarkdown
>> > > and knitr. I compiled all needed plots (using separate R scripts)
>> before
>> > > compiling the report, thus all plots reside in my graphics
> directory.
>> The
>> > > RMarkdown report needs to access these files. I have defined
>> > >
>> > > ```{r setup, include = FALSE}
>> > > knitr::opts_knit$set(
>> > >   echo = FALSE,
>> > >   xtable.type = "html",
>> > >   base.dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
>> > >   root_dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
>> > >   fig.path = "results/graphics")  # relative path required, see
>> > > http://yihui.name/knitr/options
>> > > ```
>> > >
>> > > and then referenced my plot using
>> > >
>> > > <img src = "email_distribution_pie.png"></img>
>> > >
>> > > because I want to be able to customize the plotting attributes.
>> > >
>> > > But that fails with the message "pandoc.exe: Could not fetch
>> > > email_distribution_pie.png".
>> > >
>> > > If I give it the absolute path
>> > > "H:/2017/Analysen/Kundenzufriedenheit/Auswertung/results/
>> graphics/email_distribution_pie.png"
>> > > it works fine as well if I copy the plot into the directory where
> the
>> > > report.RMD file resides.
>> > >
>> > > How can I tell knitr to fetch the ready-made plots from the graphics
>> > > directory?
>> > >
>> > > Kind regards
>> > >
>> > > Georg
>>
>
>                  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hopkins0727 at gmail.com  Mon Jun 12 22:32:08 2017
From: hopkins0727 at gmail.com (Manqing Liu)
Date: Mon, 12 Jun 2017 16:32:08 -0400
Subject: [R] replacement has *** rows, data has ***
Message-ID: <CAD7cP_hd_qeFkR0WcqVS1hNGm19qGpsdKLUW1KcpS1egN=527Q@mail.gmail.com>

Hi all,

I created a predicted variable based on a model, but somehow not all
observations have a predicted value. When I tired to add the predicated
value to the main data set (data$pr <- pr) , it said:
replacement has 34333 rows, data has 34347.
Do you know how to solve that?

Thanks,
Manqing

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Jun 13 00:06:09 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 12 Jun 2017 15:06:09 -0700
Subject: [R] replacement has *** rows, data has ***
In-Reply-To: <CAD7cP_hd_qeFkR0WcqVS1hNGm19qGpsdKLUW1KcpS1egN=527Q@mail.gmail.com>
References: <CAD7cP_hd_qeFkR0WcqVS1hNGm19qGpsdKLUW1KcpS1egN=527Q@mail.gmail.com>
Message-ID: <83E3C5AB-8BDA-4A86-8CBB-5BBF9FF02B9C@comcast.net>


> On Jun 12, 2017, at 1:32 PM, Manqing Liu <hopkins0727 at gmail.com> wrote:
> 
> Hi all,
> 
> I created a predicted variable based on a model, but somehow not all
> observations have a predicted value. When I tired to add the predicated
> value to the main data set (data$pr <- pr) , it said:
> replacement has 34333 rows, data has 34347.
> Do you know how to solve that?
> 
> Thanks,
> Manqing
> 
> 	[[alternative HTML version deleted]]

First, you should read the Posting Guide. Then you should read the help page for ?predict. 

Only then should  you write a follow-up email (in plain text) with code that constructs a simple example using whatever method was used to construct this `pr` variable and  provide enough information to support a sensible answer.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Tue Jun 13 00:05:57 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 12 Jun 2017 15:05:57 -0700
Subject: [R] replacement has *** rows, data has ***
In-Reply-To: <CAD7cP_hd_qeFkR0WcqVS1hNGm19qGpsdKLUW1KcpS1egN=527Q@mail.gmail.com>
References: <CAD7cP_hd_qeFkR0WcqVS1hNGm19qGpsdKLUW1KcpS1egN=527Q@mail.gmail.com>
Message-ID: <CAF8bMcYt0V_JxWJK0ODOSaw01p_gP6j5sogOGSNAzLvz=3ybjQ@mail.gmail.com>

This can happen if there are rows containing missing values (NA's) in the
data used to fit the model.  Use na.action=na.exclude when fitting the
model instead of the default na.action=na.omit to make the prediction
vector line up with the input data instead of lining up with the input data
after the NA-rows have been dropped.

E.g.,

> d <- data.frame(y=1:10, x=log2(c(1,2,NA,4:10)))
> fitDefault <- lm(y ~ x, data=d)
> fitNaExclude <- lm(y ~ x, data=d, na.action=na.exclude)
> length(predict(fitDefault))
[1] 9
> length(predict(fitNaExclude))
[1] 10
> predict(fitNaExclude)
         1          2          3          4          5          6
 7          8          9         10
-0.2041631  2.4602537         NA  5.1246704  5.9824210  6.6832543
 7.2758004  7.7890872  8.2418382  8.6468378


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jun 12, 2017 at 1:32 PM, Manqing Liu <hopkins0727 at gmail.com> wrote:

> Hi all,
>
> I created a predicted variable based on a model, but somehow not all
> observations have a predicted value. When I tired to add the predicated
> value to the main data set (data$pr <- pr) , it said:
> replacement has 34333 rows, data has 34347.
> Do you know how to solve that?
>
> Thanks,
> Manqing
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From donmac at matstat.com  Tue Jun 13 03:55:40 2017
From: donmac at matstat.com (Donald Macnaughton)
Date: Mon, 12 Jun 2017 21:55:40 -0400
Subject: [R] How Can I Execute a String Expression?
Message-ID: <003e01d2e3e8$2a0b30e0$7e2192a0$@matstat.com>

I have the string ggstr that I've built with string manipulation:

ggstr =  "ggplot(df1, aes(x,y)) + geom_smooth(se=FALSE, span=0.01)"

Assuming df1 is properly defined, this string will execute properly if I
submit it manually without the quotes. How can execute the command as a
string, so that I can run it repeatedly (with minor modifications) in a
loop?  Presumably, it would be something like:

execute(ggstr)

Thanks for your help,

Don Macnaughton


From r.turner at auckland.ac.nz  Tue Jun 13 04:26:46 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 13 Jun 2017 14:26:46 +1200
Subject: [R] How Can I Execute a String Expression?
In-Reply-To: <003e01d2e3e8$2a0b30e0$7e2192a0$@matstat.com>
References: <003e01d2e3e8$2a0b30e0$7e2192a0$@matstat.com>
Message-ID: <275fdff5-32cc-a9af-a301-cc4404053833@auckland.ac.nz>


On 13/06/17 13:55, Donald Macnaughton wrote:

> I have the string ggstr that I've built with string manipulation:
> 
> ggstr =  "ggplot(df1, aes(x,y)) + geom_smooth(se=FALSE, span=0.01)"
> 
> Assuming df1 is properly defined, this string will execute properly if I
> submit it manually without the quotes. How can execute the command as a
> string, so that I can run it repeatedly (with minor modifications) in a
> loop?  Presumably, it would be something like:
> 
> execute(ggstr)
> 
> Thanks for your help.

eval(parse(text = ggstr))

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter.4567 at gmail.com  Tue Jun 13 04:30:39 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 12 Jun 2017 19:30:39 -0700
Subject: [R] How Can I Execute a String Expression?
In-Reply-To: <003e01d2e3e8$2a0b30e0$7e2192a0$@matstat.com>
References: <003e01d2e3e8$2a0b30e0$7e2192a0$@matstat.com>
Message-ID: <CAGxFJbQjRgcrLufz+NnEZ0mJ3Cz94_qw_gHSUqdX8yxJVLXYZg@mail.gmail.com>

eval(parse(text = yourstring))  # your string must be  quoted, because
that's what a string is.

But .... don't do this! (usually)

install.packages("fortunes") ## if not already downloaded and installed
library("fortunes")
fortune(106)

See ?substitute and ?bquote for perhaps better ways to proceed.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 12, 2017 at 6:55 PM, Donald Macnaughton <donmac at matstat.com> wrote:
> I have the string ggstr that I've built with string manipulation:
>
> ggstr =  "ggplot(df1, aes(x,y)) + geom_smooth(se=FALSE, span=0.01)"
>
> Assuming df1 is properly defined, this string will execute properly if I
> submit it manually without the quotes. How can execute the command as a
> string, so that I can run it repeatedly (with minor modifications) in a
> loop?  Presumably, it would be something like:
>
> execute(ggstr)
>
> Thanks for your help,
>
> Don Macnaughton
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Jun 13 04:33:49 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 12 Jun 2017 19:33:49 -0700
Subject: [R] How Can I Execute a String Expression?
In-Reply-To: <003e01d2e3e8$2a0b30e0$7e2192a0$@matstat.com>
References: <003e01d2e3e8$2a0b30e0$7e2192a0$@matstat.com>
Message-ID: <356F9858-1E65-470A-8699-E3A984EF56F2@dcn.davis.ca.us>

R is not a very good macro language... I recommend against this strategy.

We could be more concrete in offering alternatives if you were a little more complete in your reproducible example [1][2][3]. What variations exactly were you thinking of? What kind of data are you working with? The way you read in the data can make a big difference in how effectively you analyze it. (Not asking for your actual data... just a fake version of it.)

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html
-- 
Sent from my phone. Please excuse my brevity.

On June 12, 2017 6:55:40 PM PDT, Donald Macnaughton <donmac at matstat.com> wrote:
>I have the string ggstr that I've built with string manipulation:
>
>ggstr =  "ggplot(df1, aes(x,y)) + geom_smooth(se=FALSE, span=0.01)"
>
>Assuming df1 is properly defined, this string will execute properly if
>I
>submit it manually without the quotes. How can execute the command as a
>string, so that I can run it repeatedly (with minor modifications) in a
>loop?  Presumably, it would be something like:
>
>execute(ggstr)
>
>Thanks for your help,
>
>Don Macnaughton
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tony1greening at hotmail.com  Tue Jun 13 06:50:38 2017
From: tony1greening at hotmail.com (Tony Greening)
Date: Tue, 13 Jun 2017 04:50:38 +0000
Subject: [R] binequality - Problems with fitFunc()
Message-ID: <ME1PR01MB110665CD54D97A5368C9538CE9C20@ME1PR01MB1106.ausprd01.prod.outlook.com>

binequality looks like just the package I need, specifically for obtaining Gini income coefficients for binned data.


I have upgraded to the latest version of R, the latest version of RStudio, and updated all packages. Still I have a persistent problem using fitFunc().


To keep things simple, I am testing things using the example code in the binequality manual, page 6 (or, "?fitFunc").

However, it exhibits the same problems as does my code and another example found elsewhere on the Internet, namely NA results for all fields of interest, as follows:




Time difference of 0.776551 secs
for LNO fit across 2 distributions

$datOut
       State obsMean distribution estMean var cv cv_sqr gini theil MLD
1 California      NA          LNO      NA  NA NA     NA   NA    NA  NA
2      Texas      NA          LNO      NA  NA NA     NA   NA    NA  NA
  SDL aic bic didConverge logLikelihood nparams median sd
1  NA  NA  NA       FALSE            NA      NA     NA NA
2  NA  NA  NA       FALSE            NA      NA     NA NA

$timeStamp
[1] 1497327774

$parameters
           mu sigma nu tau
California NA    NA NA  NA
Texas      NA    NA NA  NA

$quantiles
NULL



To summarise, I have tried fitFunc() in my own code and it produced similar results to that above. I found another example (for a different purpose) and tried it, and it also gave these results. Finally, trying the example in the fitFunc example code proves that the results are (i) consistent and (ii) not what any of the three authors would be expecting.


Any thoughts?



	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Tue Jun 13 08:31:37 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 13 Jun 2017 08:31:37 +0200
Subject: [R] Antwort: Re: Re:  Paths in knitr
In-Reply-To: <CANROs4cZe=McrdHiGTYvK1+uOf_iKxohrHJ1ZO-Gf6WNNhVTPg@mail.gmail.com>
References: <OF09B3F946.11C2DB96-ONC125813D.002544F6-C125813D.0028BABF@lotus.hawesko.de>
 <CANROs4cZe=McrdHiGTYvK1+uOf_iKxohrHJ1ZO-Gf6WNNhVTPg@mail.gmail.com>
Message-ID: <OFF5A54928.277E8B0D-ONC125813E.0023A2CF-C125813E.0023DA19@lotus.hawesko.de>

Hi Yihui,

I took root.dir and base.dir out. Everything works fine despite the 
change.

I have implemented the solution Duncun suggested. I have difficulties with 
the scaling / image size in my report. Some plots are too big, some are 
too small. I need to adjust any plot. Steep learning curve :)

Kind regards

Georg




Von:    Yihui Xie <xie at yihui.name>
An:     G.Maubach at weinwolf.de, 
Kopie:  Duncan Murdoch <murdoch.duncan at gmail.com>, R Help 
<r-help at r-project.org>
Datum:  12.06.2017 18:29
Betreff:        Re: Re: [R] Paths in knitr
Gesendet von:   xieyihui at gmail.com



Will there be anything wrong if you do not set these options?

Regards,
Yihui
--
https://yihui.name


On Mon, Jun 12, 2017 at 2:24 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi Yihui,
> Hi Duncan,
>
> I corrected my typo. Unfortunately knitr did not find my plots in the
> directory where they reside which is different from the Rmd document.
>
> The documentation of knitr says:
>
> base.dir: (NULL) an absolute directory under which the plots are 
generate
> root.dir: (NULL) the root directory when evaluating code chunks; if 
NULL,
> the directory of the input document will be used
>
> From that description I thought, if the base.dir can be used for writng
> plots, it is then also used for reading plots if set? No, it is not.
> If I set the root directory to the plots/graphics directory will knitr
> then find my plots? No, it does not.
>
> Reading blog posts my thoughts looked not so strange to me, e.g.
> https://philmikejones.wordpress.com/2015/05/20/set-root-directory-knitr/
.
> Unfortunately, it does not work for me.
>
> I am using a RStudio project file. Could it be that this interferes 
which
> the knitr options?
>
> I tried the solution that Duncan suggested:
>
> c_path_plots <-
> "H:/2017/Analysen/Kundenzufriedenheit/Auswertung/results/graphics
>
> `r knitr::include_graphics(file.path(c_path_plots,
> "email_distribution_pie.png"))`
>
> This solution works fine. I will go with it for this project as I have 
to
> finish my report soon.
>
> I read Hadley's book on bulding R Packages (
> https://www.amazon.de/R-Packages-Hadley-Wickham/dp/1491910593) and found
> it quite complicated and time consuming to build one. Thus I did not try
> yet to build my own packages. At the end of last week I heard from 
another
> library (http://reaktanz.de/R/pckg/roxyPackage/) which shall make 
building
> packages much easier. I plan to try that shortly.
>
> On my path to become better in analytics using R, I will try to use
> modules of Rmd files which can then easily be integrated into a Rmd
> report. I have yet to see how I can include these file into a complete
> report.
>
> Kind regards
>
> Georg
>
>
> ----- Weitergeleitet von Georg Maubach/WWBO/WW/HAW am 12.06.2017 08:47
> -----
>
> Von:    Yihui Xie <xie at yihui.name>
> An:     G.Maubach at gmx.de,
> Kopie:  R Help <r-help at r-project.org>
> Datum:  09.06.2017 20:53
> Betreff:        Re: [R] Paths in knitr
> Gesendet von:   "R-help" <r-help-bounces at r-project.org>
>
>
>
> I'd say it is an expert-only option. If you do not understand what it
> means, I strongly recommend you not to set it.
>
> Similarly, you set the root_dir option and I don't know why you did it,
> but
> it is a typo anyway (should be root.dir).
>
> Regards,
> Yihui
> --
> https://yihui.name
>
> On Fri, Jun 9, 2017 at 4:50 AM, <G.Maubach at gmx.de> wrote:
>
>> Hi Yi,
>>
>> many thanks for your reply.
>>
>> Why I do have to se the base.dir option? Cause, to me it is not clear
> from
>> the documentation, where knitr looks for data files and how I can 
adjust
>> knitr to tell it where to look. base.dir was a try, but did not work.
>>
>> Can you give me a hint where I can find information/documentation on
> this
>> path issue?
>>
>> Kind regards
>>
>> Georg
>>
>>
>> > Gesendet: Donnerstag, 08. Juni 2017 um 15:05 Uhr
>> > Von: "Yihui Xie" <xie at yihui.name>
>> > An: G.Maubach at weinwolf.de
>> > Cc: "R Help" <r-help at r-project.org>
>> > Betreff: Re: [R] Paths in knitr
>> >
>> > Why do you have to set the base.dir option?
>> >
>> > Regards,
>> > Yihui
>> > --
>> > https://yihui.name
>> >
>> >
>> > On Thu, Jun 8, 2017 at 6:15 AM,  <G.Maubach at weinwolf.de> wrote:
>> > > Hi All,
>> > >
>> > > I have to compile a report for the management and decided to use
>> RMarkdown
>> > > and knitr. I compiled all needed plots (using separate R scripts)
>> before
>> > > compiling the report, thus all plots reside in my graphics
> directory.
>> The
>> > > RMarkdown report needs to access these files. I have defined
>> > >
>> > > ```{r setup, include = FALSE}
>> > > knitr::opts_knit$set(
>> > >   echo = FALSE,
>> > >   xtable.type = "html",
>> > >   base.dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
>> > >   root_dir = "H:/2017/Analysen/Kundenzufriedenheit/Auswertung",
>> > >   fig.path = "results/graphics")  # relative path required, see
>> > > http://yihui.name/knitr/options
>> > > ```
>> > >
>> > > and then referenced my plot using
>> > >
>> > > <img src = "email_distribution_pie.png"></img>
>> > >
>> > > because I want to be able to customize the plotting attributes.
>> > >
>> > > But that fails with the message "pandoc.exe: Could not fetch
>> > > email_distribution_pie.png".
>> > >
>> > > If I give it the absolute path
>> > > "H:/2017/Analysen/Kundenzufriedenheit/Auswertung/results/
>> graphics/email_distribution_pie.png"
>> > > it works fine as well if I copy the plot into the directory where
> the
>> > > report.RMD file resides.
>> > >
>> > > How can I tell knitr to fetch the ready-made plots from the 
graphics
>> > > directory?
>> > >
>> > > Kind regards
>> > >
>> > > Georg
>>
>
>                  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From G.Maubach at weinwolf.de  Tue Jun 13 08:37:01 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 13 Jun 2017 08:37:01 +0200
Subject: [R] WG: Fw: Re:  rmarkdown and font size
Message-ID: <OF8BEEF0A1.D070CDE1-ONC125813E.002408B3-C125813E.0024586A@lotus.hawesko.de>

Hi Dan,
Hi All,

I read the below post. I am wondering how do I know which "keys" are 
available, e.g. "core.r" and "pre". Where kind I find the definition of 
what can be adjusted and which "words" to use?

Kind regards

Georg


> Gesendet: Donnerstag, 08. Juni 2017 um 16:16 Uhr
> Von: "Nordlund, Dan (DSHS/RDA)" <NordlDJ at dshs.wa.gov>
> An: "MacQueen, Don" <macqueen1 at llnl.gov>, "r-help at r-project.org" 
<r-help at r-project.org>
> Betreff: Re: [R] rmarkdown and font size
>
> You can change the style, modifying a variety of things.  E.g,
> 
> ---
> title: Test
> ---
> 
> <style type="text/css">
> 
> body{ /* Normal  */
>       font-size: 12px;
>   }
> td {  /* Table  */
>   font-size: 8px;
> }
> h1.title {
>   font-size: 38px;
>   color: DarkRed;
> }
> h1 { /* Header 1 */
>   font-size: 28px;
>   color: DarkBlue;
> }
> h2 { /* Header 2 */
>     font-size: 22px;
>   color: DarkBlue;
> }
> h3 { /* Header 3 */
>   font-size: 18px;
>   font-family: "Times New Roman", Times, serif;
>   color: DarkBlue;
> }
> code.r{ /* Code block */
>     font-size: 12px;
> }
> pre { /* Code block - determines code spacing between lines */
>     font-size: 14px;
> }
> </style>
> 
> Here is some normal text.  It is a 12-point font.  The table is in 
8-point . 
> 
> ```{r example, echo=FALSE, results='asis'}
> tmp <- data.frame(a=1:5, b=letters[1:5])
> print( knitr::kable(tmp, row.names=FALSE))
> ```
> 
> 
> Hope this is helpful,
> 
> Dan
> 
> Daniel Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
> 
> 
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > MacQueen, Don
> > Sent: Wednesday, June 07, 2017 4:58 PM
> > To: r-help at r-project.org
> > Subject: [R] rmarkdown and font size
> > 
> > Suppose I have a file (named "tmp.rmd") containing:
> > 
> > 
> > ---
> > title: Test
> > ---
> > 
> > ```{r example, echo=FALSE, results='asis'}
> > tmp <- data.frame(a=1:5, b=letters[1:5])
> > print( knitr::kable(tmp, row.names=FALSE))
> > ```
> > 
> > 
> > 
> > And I render it with:
> > 
> > rmarkdown::render('tmp.rmd',
> > output_format=c('html_document','pdf_document'))
> > 
> > I get two files:
> >   tmp.pdf
> >   tmp.html
> > 
> > Is there a way to control (change or specify) the font size of the 
table in the
> > pdf output?
> > (or of the entire document, if it can't be changed for just the table)
> > 
> > With my actual data, the table is too wide to fit on a page in the pdf 
output;
> > perhaps if I reduce the font size I can get it to fit.
> > 
> > I would like the html version to still look decent, but I don't care 
very much
> > what happens to its font size.
> > 
> > Thanks!
> > -Don
> > 
> > --
> > Don MacQueen
> > 
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> > 
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sergio.ferreira-cardoso at umontpellier.fr  Tue Jun 13 10:15:00 2017
From: sergio.ferreira-cardoso at umontpellier.fr (Sergio Ferreira Cardoso)
Date: Tue, 13 Jun 2017 10:15:00 +0200 (CEST)
Subject: [R] Mean correlation within cluster
Message-ID: <543170611.265283.1497341700166.JavaMail.zimbra@umontpellier.fr>



Hello all, 

I'd like to calculate the mean correlation within a cluster and understand if it's significantly >0. I'm using packages 'geomorph' and 'paleomorph'. 
#Simulate an array A <- array ( rep ( 1 : 36 , by = 4 ), dim = c ( 12 , 3 , 4 )) #Load 'geomorph' package and superimpose coordinates test.gpa <- gpagen ( A , print.progress = FALSE ) #Load 'paleomorph' and generate covariance and correlation matrices cvmatrix <- dotcvm ( test.gpa $ coords ) corrmatrix <- dotcorr ( test.gpa $ coords ) 


Then I do a clustering with Ward method and euclidean distance, using the cvmatrix and I get a dendrogram. This part is not the problem, so I'll go directly to what I want. I would like to calculate the mean correlation between the elements of each cluster. Since clustering methods will mandatorily produce clusters, I'd like to know if the elements of my clusters are correlated (I mean, if the clusters are valid). 

I believe this might not be very complicated, given that I have all the elements. I just don't know how to do it on R. I tried to do the clustering with p-values for each cluster, with pvclust(), but I'm following a paper in which the authors test the significancy of the clusters by assessing the mean correlation of the elements within each cluster. I'd like to compare this method with the one from pvclust(). 

Thank you in advance. 




Best regards, 

S?rgio. 



	[[alternative HTML version deleted]]


From mlathouri at yahoo.gr  Tue Jun 13 15:17:25 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Tue, 13 Jun 2017 13:17:25 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBwbG90dGluZyBnYW1tIHJlc3VsdHMgaW4g?=
	=?utf-8?q?lattice?=
In-Reply-To: <000001d2e390$42cd9210$c868b630$@bigpond.com>
References: <1285525141.12938366.1497264999370.ref@mail.yahoo.com>
 <1285525141.12938366.1497264999370@mail.yahoo.com>
 <000001d2e390$42cd9210$c868b630$@bigpond.com>
Message-ID: <613578220.14870923.1497359845393@mail.yahoo.com>

Hi Duncan
Thank you very much for your help.?
The function model$gam is correct; it applies to gamm4 as well.?
I believe that it is the smooth term the reason that the plots from lattice are not the same as the plots from the plot(model$gam) but at least I can get the smooth line and the confidence intervals.?
Kind regards,Maria 

    ???? 4:26 ?.?. ???????, 12 ??????? 2017, ?/? Duncan Mackay <dulcalma at bigpond.com> ??????:
 

 Hi Maria

If you have problems just start with a small model with predictions and then plot with xyplot
the same applies to xyplot
Try 

library(gamm4)

spring <- dget(file = "G:/1/example.txt")
 str(spring)
'data.frame':? 11744 obs. of? 11 variables:
 $ WATERBODY_ID? ? ? ? ? : Factor w/ 1994 levels "GB102021072830",..: 1 1 2 2 2 3 3 3 4 4 ...
 $ SITE_ID? ? ? ? ? ? ? : int? 157166 157166 1636 1636 1636 1635 1635 1635 134261 1631 ...
 $ Year? ? ? ? ? ? ? ? ? : int? 2011 2014 2013 2006 2003 2002 2013 2005 2013 2006 ...
 $ Q95? ? ? ? ? ? ? ? ? : num? 100 100 80 80 80 98 98 98 105 105 ...
 $ LIFE.OE_spring? ? ? ? : num? 1.02 1.03 1.02 1.06 1.06 1.07 1.12 1.05 1.14 1.05 ...
 $ super.end.group? ? ? : Factor w/ 6 levels "B","C","D","E",..: 1 1 3 3 3 2 2 2 4 4 ...
 $ X.urban.suburban? ? ? : num? 0 0 0.07 0.07 0.07 0.53 0.53 0.53 8.07 8.07 ...
 $ X.broadleaved_woodland: num? 2.83 2.83 10.39 10.39 10.39 ...
 $ X.CapWks? ? ? ? ? ? ? : num? 0 0 0 0 0 0 0 0 0 0 ...
 $ Hms_Poaching? ? ? ? ? : int? 0 0 10 10 10 0 0 0 0 0 ...
 $ Hms_Rsctned? ? ? ? ? : int? 0 0 0 0 0 0 0 0 0 0 ...

model<-
gamm4(LIFE.OE_spring~s(Q95, by=super.end.group)+Year+Hms_Rsctned+Hms_Poaching+X.broadleaved_woodland +X.urban.suburban+X.CapWks, data=spring,
? ? ? random=~(1|WATERBODY_ID/SITE_ID))
Warning message:
Some predictor variables are on very different scales: consider rescaling

# plot(model$gam, page=1, font.lab=2, xlab="Residual Q95")

M <-predict(model$gam,type="response",se.fit=T)

# joining the dataset and the predictions keep it "in house" and on path
springP = cbind(spring, M)
springP$upper = with(springP,fit+1.96*se.fit)
springP$lower = with(springP,fit-1.96*se.fit)
str(springP)
'data.frame':? 11744 obs. of? 15 variables:
 $ WATERBODY_ID? ? ? ? ? : Factor w/ 1994 levels "GB102021072830",..: 1 1 2 2 2 3 3 3 4 4 ...
 $ SITE_ID? ? ? ? ? ? ? : int? 157166 157166 1636 1636 1636 1635 1635 1635 134261 1631 ...
 $ Year? ? ? ? ? ? ? ? ? : int? 2011 2014 2013 2006 2003 2002 2013 2005 2013 2006 ...
 $ Q95? ? ? ? ? ? ? ? ? : num? 100 100 80 80 80 98 98 98 105 105 ...
 $ LIFE.OE_spring? ? ? ? : num? 1.02 1.03 1.02 1.06 1.06 1.07 1.12 1.05 1.14 1.05 ...
 $ super.end.group? ? ? : Factor w/ 6 levels "B","C","D","E",..: 1 1 3 3 3 2 2 2 4 4 ...
 $ X.urban.suburban? ? ? : num? 0 0 0.07 0.07 0.07 0.53 0.53 0.53 8.07 8.07 ...
 $ X.broadleaved_woodland: num? 2.83 2.83 10.39 10.39 10.39 ...
 $ X.CapWks? ? ? ? ? ? ? : num? 0 0 0 0 0 0 0 0 0 0 ...
 $ Hms_Poaching? ? ? ? ? : int? 0 0 10 10 10 0 0 0 0 0 ...
 $ Hms_Rsctned? ? ? ? ? : int? 0 0 0 0 0 0 0 0 0 0 ...
 $ fit? ? ? ? ? ? ? ? ? : num [1:11744(1d)] 1.03 1.04 1.04 1.02 1.01 ...
? ..- attr(*, "dimnames")=List of 1
? .. ..$ : chr? "1" "2" "3" "4" ...
 $ se.fit? ? ? ? ? ? ? ? : num [1:11744(1d)] 0.00263 0.00266 0.00408 0.00408 0.00411 ...
? ..- attr(*, "dimnames")=List of 1
? .. ..$ : chr? "1" "2" "3" "4" ...
 $ upper? ? ? ? ? ? ? ? : num [1:11744(1d)] 1.03 1.04 1.05 1.03 1.02 ...
? ..- attr(*, "dimnames")=List of 1
? .. ..$ : chr? "1" "2" "3" "4" ...
 $ lower? ? ? ? ? ? ? ? : num [1:11744(1d)] 1.02 1.03 1.03 1.01 1 ...
? ..- attr(*, "dimnames")=List of 1
? .. ..$ : chr? "1" "2" "3" "4" ...

# this produces a mess of lines for the upper and lower
xyplot(fitted(model$gam) ~ Q95 |super.end.group, data = springP,
? ? ? lower = springP$lower,
? ? ? upper = springP$upper,
? ? ? subscripts = TRUE,
? ? ? panel = function(x,y, upper, lower, subscripts, ...){
? ? ? ? ? ? ? ? ? panel.xyplot(x,y, type="smooth")
? ? ? ? ? ? ? ? ? panel.xyplot(x[order(x)], upper[subscripts][order(x)], lty=2, col="red")
? ? ? ? ? ? ? ? ? panel.xyplot(x[order(x)], lower[subscripts][order(x)], lty=2, col="red")
? ? ? ? ? ? ? ? ? #panel.loess(x,y,...) #? have not tried to fix these lines- depends on what you want to do
? ? ? ? ? ? ? ? ? #panel.rug(x = x[is.na(y)], y = y[is.na(x)])
? ? ? ? ? ? ? ? }
)

# smoothing them produces reasonable lines
xyplot(fitted(model$gam) ~ Q95 |super.end.group, data = springP,
? ? ? lower = springP$lower,
? ? ? upper = springP$upper,
? ? ? subscripts = TRUE,
? ? ? panel = function(x,y, upper, lower, subscripts, ...){
? ? ? ? ? ? ? ? ? panel.xyplot(x,y, type="smooth")
? ? ? ? ? ? ? ? ? panel.xyplot(x[order(x)], upper[subscripts][order(x)], type = "smooth", lty=2, col="red")
? ? ? ? ? ? ? ? ? panel.xyplot(x[order(x)], lower[subscripts][order(x)], type = "smooth", lty=2, col="red")
? ? ? ? ? ? ? ? ? #panel.loess(x,y,...)
? ? ? ? ? ? ? ? ? #panel.rug(x = x[is.na(y)], y = y[is.na(x)])
? ? ? ? ? ? ? ? }
)

# by newdata = ...
# take a cross-section of data - reduces the amount of data to be plotted
mx = aggregate(Q95 ~ super.end.group, spring, max, na.rm=T)
newlst <-
do.call(rbind,
? ? ? ? lapply(1:6, function(j) expand.grid(Q95 = seq(0,mx[j,2], length = 50), super.end.group = LETTERS[j])
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Year =
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Hms_Rsctned =
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ...))? # fill in yourself
newd <- data.frame(newlst)

and predict using newdata = newd

# starting with a smaller model
model2 <-
gamm4(LIFE.OE_spring~s(Q95, by=super.end.group), data=spring,
? ? ? random=~(1|WATERBODY_ID/SITE_ID))

newlst <-
do.call(rbind,
? ? ? ? lapply(1:6, function(j) expand.grid(Q95 = seq(0,mx[j,2], length = 50), super.end.group = LETTERS[j])) )
newd <- data.frame(Q95 = newlst)
# The following is untested
# I have not used gamm4 for a while; is? model$gam correct? Had problems here - have no time to go into the help pages
M3 <- predict(model2$gamm, newdata = newd, type="response",se.fit=T)

# keep together 
newdat = cbind(newd, M3)

# If you want CIs
newdat <- within(newdat, {
? ? lower = fit-1.96*se.fit
? ? upper = fit+1.96*se.fit
})

# plot- something like
xyplot(fitted(model$gam) ~ Q95 |super.end.group, data = springP,
? ? ? Q2? ? = newddat$Q95,
? ? ? lower = newdat$lower,
? ? ? upper = newdat$upper,
? ? ? subscripts = TRUE,
? ? ? panel = function(x,y, Q2, upper, lower, subscripts, ...){
? ? ? ? ? ? ? ? ? panel.xyplot(x,y, type="smooth")
? ? ? ? ? ? ? ? ? panel.xyplot(Q2, upper, lty=2, col="red")
? ? ? ? ? ? ? ? ? panel.xyplot(Q2, lower, lty=2, col="red")
? ? ? ? ? ? ? ? ? #panel.loess(x,y,...)
? ? ? ? ? ? ? ? ? #panel.rug(x = x[is.na(y)], y = y[is.na(x)])
? ? ? ? ? ? ? ? }
)

If you are putting a key onto the plot see
? xyplot and par.settings and key 

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maria Lathouri via R-help
Sent: Monday, 12 June 2017 20:57
To: R-help Mailing List
Subject: [R] plotting gamm results in lattice

Dear all, 
I hope that you can help me on this. I have been struggling to figure this out but I haven't found any solution.
I am running a generalised mixed effect model, gamm4, for an ecology project. Below is the code for the model:
model<-gamm4(LIFE.OE_spring~s(Q95, by=super.end.group)+Year+Hms_Rsctned+Hms_Poaching+X.broadleaved_woodland? ? ? ? ? ? +X.urban.suburban+X.CapWks, data=spring, random=~(1|WATERBODY_ID/SITE_ID))
plot(model$gam, page=1, font.lab=2, xlab="Residual Q95")

I am trying to plot the results in lattice for publication purposes so I need to figure this out. I have been struggling but I think I have reached a dead end. 

Here is what I have been able to code:
M<-predict(model$gam,type="response",se.fit=T)
upr<- M$fit + (1.96 * M$se.fit)lwr<- M$fit - (1.96 * M$se.fit)
library(lattice)xyplot(fitted(model$gam) ~ Q95 |super.end.group, data = spring, gm=model,? ? ? prepanel=function (x,y,...)list(ylim=c(min(upr),max(lwr))),? ? ? panel = function(x,y, gm, ...){? ? ? ? ? ? ? panel.xyplot(x,y, type="smooth")? ? ? ? panel.lines(upr,lty=2, col="red")? ? ? ? panel.lines(lwr,lty=2, col="red")? ? ? ? panel.loess(x,y,...)? ? ? ? panel.rug(x = x[is.na(y)],? ? ? ? ? ? ? ? ? y = y[is.na(x)])? ? ? }? ? ? )
But, unfortunately, this is not what I get when I have the simple plot(model$gam). 

I have also attached a reproducible example in case you want to see for yourself. I hope that someone here has come up with a similar problem and can help me on this.
Thank you very much for your time.
Kind regards,Maria 


   
	[[alternative HTML version deleted]]


From dimitrie.siriopol at yahoo.com  Tue Jun 13 15:02:38 2017
From: dimitrie.siriopol at yahoo.com (Dimitrie Siriopol)
Date: Tue, 13 Jun 2017 13:02:38 +0000 (UTC)
Subject: [R] Classification and Regression Tree for Survival Analysis
References: <357631353.8379175.1497358958387.ref@mail.yahoo.com>
Message-ID: <357631353.8379175.1497358958387@mail.yahoo.com>

I am trying to use the CART in a survival analysis. I have three variables of interest (all 3 ordinal - x, y and z, each of them with 5 categories) from which I want to make smaller groups (just an example 1st category from X variable with the 2nd and 3rd categories from the Y category and 2, 3 and 4 categories from the Z category etc) based on their, let's say, association with mortality.
Now I would also want that this analysis to be adjusted for a number of variables (that I don't want to incorporate in the decision tree, just to take them into consideration in the relationship between the 3 variables and the outcome; I would also want to mention that for this confounders I have missing values - how should this be deal with?), this survival analysis to be stratified and also to use clusters.
I have tried party and rpart packages, but I don't seem to get how to properly do what I want.
Thank you

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun 13 18:59:33 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 13 Jun 2017 09:59:33 -0700
Subject: [R] Classification and Regression Tree for Survival Analysis
In-Reply-To: <357631353.8379175.1497358958387@mail.yahoo.com>
References: <357631353.8379175.1497358958387.ref@mail.yahoo.com>
 <357631353.8379175.1497358958387@mail.yahoo.com>
Message-ID: <CAGxFJbS-Re6w5Scqn8YaNzkHQ-uYz-Qdfq02YTM6HFacvawMbQ@mail.gmail.com>

1. Please read and follow the posting guide below. Your post does not
meet the guidelines.

2. Search before posting!

e.g. on rseek.org: "Regression trees survival analysis"

in which you will find:
 https://cran.r-project.org/web/views/MachineLearning.html


-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 13, 2017 at 6:02 AM, Dimitrie Siriopol via R-help
<r-help at r-project.org> wrote:
> I am trying to use the CART in a survival analysis. I have three variables of interest (all 3 ordinal - x, y and z, each of them with 5 categories) from which I want to make smaller groups (just an example 1st category from X variable with the 2nd and 3rd categories from the Y category and 2, 3 and 4 categories from the Z category etc) based on their, let's say, association with mortality.
> Now I would also want that this analysis to be adjusted for a number of variables (that I don't want to incorporate in the decision tree, just to take them into consideration in the relationship between the 3 variables and the outcome; I would also want to mention that for this confounders I have missing values - how should this be deal with?), this survival analysis to be stratified and also to use clusters.
> I have tried party and rpart packages, but I don't seem to get how to properly do what I want.
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From don-r-help at isis.cs3-inc.com  Tue Jun 13 20:25:54 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Tue, 13 Jun 2017 18:25:54 +0000 (UTC)
Subject: [R] understanding I() in lmer formula
Message-ID: <20170613182554.D49724057F@losangelesyouthorchestra.org>

 Is there a difference between I(x*y) and I(y*x) ?
I have a call to lmer that results in this complaint:
  Error in is.alpha2.subordinate * ~z.min.co.res :  
  non-numeric argument to binary operator
when I change this line:
  I(is.alpha2.subordinate*z.min.co.res)+
to this:
  I(z.min.co.res*is.alpha2.subordinate)+
the complaint goes away.
I'd like to understand why.


From bgunter.4567 at gmail.com  Tue Jun 13 21:12:37 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 13 Jun 2017 12:12:37 -0700
Subject: [R] understanding I() in lmer formula
In-Reply-To: <20170613182554.D49724057F@losangelesyouthorchestra.org>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
Message-ID: <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>

If you don't get a prompt reply here, you might do better posting this
on the r-sig-mixed-models list (for obvious reasons).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 13, 2017 at 11:25 AM, Don Cohen <don-r-help at isis.cs3-inc.com> wrote:
>  Is there a difference between I(x*y) and I(y*x) ?
> I have a call to lmer that results in this complaint:
>   Error in is.alpha2.subordinate * ~z.min.co.res :
>   non-numeric argument to binary operator
> when I change this line:
>   I(is.alpha2.subordinate*z.min.co.res)+
> to this:
>   I(z.min.co.res*is.alpha2.subordinate)+
> the complaint goes away.
> I'd like to understand why.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Stephen.Bond at cibc.com  Tue Jun 13 22:05:20 2017
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Tue, 13 Jun 2017 20:05:20 +0000
Subject: [R] fedback from foreach
Message-ID: <624EC9773CAB044ABA65327271BED9B61885D424@CBMCC-X10-MA01.ad.cibc.com>

Hi useRs,

I am running a foreach loop and hoped to get a small message when it hits a multiple of 1000, but it does not work.

        p <- foreach(i=1:10000, .combine='c') %dopar% {
            if(i%%1000==0) print(i)
            sqrt(i)
        }

What is the proper way to do it.
Thanks everybody.

Stephen B


	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Tue Jun 13 22:15:30 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 13 Jun 2017 23:15:30 +0300
Subject: [R] fedback from foreach
In-Reply-To: <624EC9773CAB044ABA65327271BED9B61885D424@CBMCC-X10-MA01.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B61885D424@CBMCC-X10-MA01.ad.cibc.com>
Message-ID: <24D860B2-F581-435E-B889-7817D8A417B5@gmail.com>

> 
> On 13 Jun 2017, at 23:05, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
> 
> Hi useRs,
> 
> I am running a foreach loop and hoped to get a small message when it hits a multiple of 1000, but it does not work.
> 
>        p <- foreach(i=1:10000, .combine='c') %dopar% {
>            if(i%%1000==0) print(i)
>            sqrt(i)
>        }
> 
> What is the proper way to do it.
> Thanks everybody.
> 
> Stephen B


https://stackoverflow.com/questions/10903787/how-can-i-print-when-using-dopar <https://stackoverflow.com/questions/10903787/how-can-i-print-when-using-dopar>

https://www.r-bloggers.com/monitoring-progress-inside-a-foreach-loop/ <https://www.r-bloggers.com/monitoring-progress-inside-a-foreach-loop/>

https://github.com/berkeley-scf/tutorial-parallel-basics/issues/2 <https://github.com/berkeley-scf/tutorial-parallel-basics/issues/2>

https://sumidiot.wordpress.com/2011/11/05/printing-in-foreachs-dopar/ <https://sumidiot.wordpress.com/2011/11/05/printing-in-foreachs-dopar/>


	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Tue Jun 13 22:28:52 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 13 Jun 2017 22:28:52 +0200 (CEST)
Subject: [R] Classification and Regression Tree for Survival Analysis
In-Reply-To: <357631353.8379175.1497358958387@mail.yahoo.com>
References: <357631353.8379175.1497358958387.ref@mail.yahoo.com>
 <357631353.8379175.1497358958387@mail.yahoo.com>
Message-ID: <alpine.DEB.2.20.1706132215170.15416@paninaro>

On Tue, 13 Jun 2017, Dimitrie Siriopol via R-help wrote:

> I am trying to use the CART in a survival analysis. I have three variables of interest (all 3 ordinal - x, y and z, each of them with 5 categories) from which I want to make smaller groups (just an example 1st category from X variable with the 2nd and 3rd categories from the Y category and 2, 3 and 4 categories from the Z category etc) based on their, let's say, association with mortality.
> Now I would also want that this analysis to be adjusted for a number of variables (that I don't want to incorporate in the decision tree, just to take them into consideration in the relationship between the 3 variables and the outcome; I would also want to mention that for this confounders I have missing values - how should this be deal with?), this survival analysis to be stratified and also to use clusters.
> I have tried party and rpart packages, but I don't seem to get how to properly do what I want.

I don't think that such an analysis is available "out of the box". In 
principle, you can iterate between (a) estimating a survival regression 
with the confounders - given the groups from the tree, and (b) estimating 
the tree - given an offset in the survival regression for the confounders. 
Such a strategy is implemented in the palmtree() function from the 
"partykit" package - however only for lm() and glm() models, not for 
survreg(). But the same idea could be applied in that case as well, e.g., 
using a Weibull distribution.

For incorporating stratification/clustering one could either use clustered 
inference in the variable selection or add some random effect. For lm/glm 
this is provided in the package "glmertree" but I don't think there are 
readily available code blocks to do the same for a survival response.

And as for the missing values in the confounders: I can't think of a good 
strategy for this. One could try generic imputation strategies but it's 
rather unlikely that this does not affect the subsequent regression plus 
tree selection process.

References for palmtree and glmertree:
http://arxiv.org/abs/1612.07498
http://EconPapers.RePEc.org/RePEc:inn:wpaper:2015-10

> Thank you
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sewashm at gmail.com  Tue Jun 13 23:09:27 2017
From: sewashm at gmail.com (Ashta)
Date: Tue, 13 Jun 2017 16:09:27 -0500
Subject: [R] reading data
Message-ID: <CADDFq30PyTkU+QeksEQOKgfWJT-qio5rL+LS6SGiAYJzHTwt9A@mail.gmail.com>

Hi all,

I am using R to extract  data on a regular basis.
However, sometimes using the same script and the same data I am
getting different observation.
The library I am using and how I am reading  it is as follows.

library(stringr)
namelist <- file("Adress1.txt",encoding="ISO-8859-1")
Name <- read.fwf(namelist,
colClasses="character", skip=2,sep="\t",fill=T,
                          width =c(2,8,1,1,1,1,1,1,9,5)+1,col.names=ccol)

Can some one suggest me how track the issue?
Is it the library issue or Java issue?
May I read as free format instead of fixed format?

Thank you in advance


From djvecellio at tamu.edu  Tue Jun 13 22:26:04 2017
From: djvecellio at tamu.edu (Daniel Vecellio)
Date: Tue, 13 Jun 2017 15:26:04 -0500
Subject: [R] S-mode PCAs
Message-ID: <CAK-ZM=AHi-=K=MOp+wznbRkUDgufzqtVW+akeqtGftVoN7XZ8g@mail.gmail.com>

Hi all,

I have a file of average SWE observations for 40 years at over 4,000 points
and am attempting to do a spatiotemporal analysis of the data using PCA,
much like this paper did using snow depth:
http://journals.ametsoc.org/doi/pdf/10.1175/1520-0442%281998%29011%3C0856%3ATCIRWS%3E2.0.CO%3B2

I have followed the code in the link below by my loadings are far too small
(For example, the paper listed above had loading above 0.5 and below -0.5
while my loadings for PC1 go between 0.02 and -0.03).

https://stackoverflow.com/questions/41022927/principal-component-analysis-pca-of-time-series-data-spatial-and-temporal-pat

I have standardized the data in the prcomp function so that a correlation
matrix is used in my study, just like the paper above. Does anyone have any
idea why my loadings might be so off and any suggestions regarding the PCA
functions in R to help solve this problem?

Thanks in advance,
Dan

-- 

*Daniel J. Vecellio*

*Ph.D. Student - Climate Science Lab, **Department of Geography, **Texas
A&M University*

	[[alternative HTML version deleted]]


From mat.worni at gmail.com  Tue Jun 13 22:46:06 2017
From: mat.worni at gmail.com (matthias worni)
Date: Tue, 13 Jun 2017 22:46:06 +0200
Subject: [R] IF LOOOP
Message-ID: <CAFJsnfY74dQh_mmsXcwTsJE8ECW0mfjwSE1SSOjN1_hkgajN=w@mail.gmail.com>

Hey

This should be a rather simple quesiton for some of you. I want to make
some progress in looping...
I have the vector r, which contains single values --> see below:

r
  [1] 1.1717118 1.1605215 1.1522907 1.1422830 1.1065277 1.1165451 1.1163768
1.1048872 1.0848836 1.0627211
 [11] 1.0300964 1.0296879 1.0308194 1.0518188 1.0657229 1.0685514 1.0914881
1.1042577 1.1039351 1.0880163


I would like to take out simply the value "0.990956" from the vector,
printing out the rest of it.  The code is from the internet but does not
seem to work for my vector. Can't figure out why... Thanks for the help

r <- as.vector(lw)
count=0
for (i in r)  {
  if(i == 0.990956) {
    break
  }
    print(i)
  }


Best
Matthias

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Jun 14 01:10:58 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 14 Jun 2017 11:10:58 +1200
Subject: [R] [FORGED]  IF LOOOP
In-Reply-To: <CAFJsnfY74dQh_mmsXcwTsJE8ECW0mfjwSE1SSOjN1_hkgajN=w@mail.gmail.com>
References: <CAFJsnfY74dQh_mmsXcwTsJE8ECW0mfjwSE1SSOjN1_hkgajN=w@mail.gmail.com>
Message-ID: <c79c16a0-9061-37f9-ee43-33e9637c3540@auckland.ac.nz>

On 14/06/17 08:46, matthias worni wrote:
> Hey
> 
> This should be a rather simple quesiton for some of you. I want to make
> some progress in looping...
> I have the vector r, which contains single values --> see below:
> 
> r
>    [1] 1.1717118 1.1605215 1.1522907 1.1422830 1.1065277 1.1165451 1.1163768
> 1.1048872 1.0848836 1.0627211
>   [11] 1.0300964 1.0296879 1.0308194 1.0518188 1.0657229 1.0685514 1.0914881
> 1.1042577 1.1039351 1.0880163
> 
> 
> I would like to take out simply the value "0.990956" from the vector,
> printing out the rest of it.  The code is from the internet but does not
> seem to work for my vector. Can't figure out why... Thanks for the help
> 
> r <- as.vector(lw)
> count=0
> for (i in r)  {
>    if(i == 0.990956) {
>      break
>    }
>      print(i)
>    }

FAQ 7.31

cheers,

Rolf Turner


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dwinsemius at comcast.net  Wed Jun 14 01:41:05 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 13 Jun 2017 16:41:05 -0700
Subject: [R] [FORGED]  IF LOOOP
In-Reply-To: <c79c16a0-9061-37f9-ee43-33e9637c3540@auckland.ac.nz>
References: <CAFJsnfY74dQh_mmsXcwTsJE8ECW0mfjwSE1SSOjN1_hkgajN=w@mail.gmail.com>
 <c79c16a0-9061-37f9-ee43-33e9637c3540@auckland.ac.nz>
Message-ID: <D9EB2BA5-7CB8-4471-8F79-850C85646CE8@comcast.net>


> On Jun 13, 2017, at 4:10 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 14/06/17 08:46, matthias worni wrote:
>> Hey
>> This should be a rather simple quesiton for some of you. I want to make
>> some progress in looping...
>> I have the vector r, which contains single values --> see below:
>> r
>>   [1] 1.1717118 1.1605215 1.1522907 1.1422830 1.1065277 1.1165451 1.1163768
>> 1.1048872 1.0848836 1.0627211
>>  [11] 1.0300964 1.0296879 1.0308194 1.0518188 1.0657229 1.0685514 1.0914881
>> 1.1042577 1.1039351 1.0880163
>> I would like to take out simply the value "0.990956" from the vector,
>> printing out the rest of it.  The code is from the internet but does not
>> seem to work for my vector.

I'm not sure that the source of this code should be considered a trusted foundation for learning R. You should not be using for-loops to modify vectors in this manner.


>> Can't figure out why... Thanks for the help
>> r <- as.vector(lw)

That's probably not needed.

>> count=0
>> for (i in r)  {
>>   if(i == 0.990956) {
>>     break

I suspect you meant to use:

?'next'   # since `break` completely terminates a for-loop.


The ?'help' page has all the "control structures": `for`, `repeat`, `while` and associated boundaries and terminators

Both `break` and `next` are reserved words (names of functions, control tokens), so using the `?` operator requires quoting.

Also that for-next loop would do _nothing_ to the value of r. Printing would not modify the value of `r`.

You should read:

?Reserved

?'for'  # since `for` is also reserved

?print



>>   }
>>     print(i)
>>   }
> 
> FAQ 7.31

After following Rolf's advice ... Try:

r[ all.equal(r, 0.990956) ]

> 


> cheers,
> 
> Rolf Turner

Further note to matthias:
All caps in Subject is considered poor form, as is posting in HTML.

-- 

David Winsemius
Alameda, CA, USA


From jholtman at gmail.com  Wed Jun 14 02:20:22 2017
From: jholtman at gmail.com (jim holtman)
Date: Tue, 13 Jun 2017 20:20:22 -0400
Subject: [R] reading data
In-Reply-To: <CADDFq30PyTkU+QeksEQOKgfWJT-qio5rL+LS6SGiAYJzHTwt9A@mail.gmail.com>
References: <CADDFq30PyTkU+QeksEQOKgfWJT-qio5rL+LS6SGiAYJzHTwt9A@mail.gmail.com>
Message-ID: <CAAxdm-4DNL5mTGpFfGygm=LpZPeSCJ9FXZF1gxgq-tX45uyXTg@mail.gmail.com>

You need to provide reproducible data.  What does the file contain?  Why
are you using 'sep=' when reading fixed format.  You might be able to
attach the '.txt' to your email to help with the problem.  Also you did not
state what the differences that you are seeing.  So help us out here.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Tue, Jun 13, 2017 at 5:09 PM, Ashta <sewashm at gmail.com> wrote:

> Hi all,
>
> I am using R to extract  data on a regular basis.
> However, sometimes using the same script and the same data I am
> getting different observation.
> The library I am using and how I am reading  it is as follows.
>
> library(stringr)
> namelist <- file("Adress1.txt",encoding="ISO-8859-1")
> Name <- read.fwf(namelist,
> colClasses="character", skip=2,sep="\t",fill=T,
>                           width =c(2,8,1,1,1,1,1,1,9,5)+1,col.names=ccol)
>
> Can some one suggest me how track the issue?
> Is it the library issue or Java issue?
> May I read as free format instead of fixed format?
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Jun 14 03:55:06 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 14 Jun 2017 11:55:06 +1000
Subject: [R] IF LOOOP
In-Reply-To: <CAFJsnfY74dQh_mmsXcwTsJE8ECW0mfjwSE1SSOjN1_hkgajN=w@mail.gmail.com>
References: <CAFJsnfY74dQh_mmsXcwTsJE8ECW0mfjwSE1SSOjN1_hkgajN=w@mail.gmail.com>
Message-ID: <CA+8X3fXi6q5OY3LwTEryyRev9GRHHH0v+TsXDL8zFd-n81sMLA@mail.gmail.com>

Hi Matthias.
The first thing I notice is that the vector r:

r<-c(1.1717118,1.1605215,1.1522907,1.1422830,1.1065277,1.1165451,
 1.1163768,1.1048872,1.0848836,1.0627211,1.0300964,1.0296879,
 1.0308194,1.0518188,1.0657229,1.0685514,1.0914881,1.1042577,
 1.1039351,1.0880163)

doesn't contain the value 0.990956. If it ain't there, you can't
remove it. It has already been suggested that the failure of any
explicit value like 0.990956 to equal its displayed representation is
due to machine precision. I'll guess that you really want to remove a
range of values, something like those less than 1.000000. If so, try
this:

r[r>=1]

Jim

On Wed, Jun 14, 2017 at 6:46 AM, matthias worni <mat.worni at gmail.com> wrote:
> Hey
>
> This should be a rather simple quesiton for some of you. I want to make
> some progress in looping...
> I have the vector r, which contains single values --> see below:
>
> r
>   [1] 1.1717118 1.1605215 1.1522907 1.1422830 1.1065277 1.1165451 1.1163768
> 1.1048872 1.0848836 1.0627211
>  [11] 1.0300964 1.0296879 1.0308194 1.0518188 1.0657229 1.0685514 1.0914881
> 1.1042577 1.1039351 1.0880163
>
>
> I would like to take out simply the value "0.990956" from the vector,
> printing out the rest of it.  The code is from the internet but does not
> seem to work for my vector. Can't figure out why... Thanks for the help
>
> r <- as.vector(lw)
> count=0
> for (i in r)  {
>   if(i == 0.990956) {
>     break
>   }
>     print(i)
>   }
>
>
> Best
> Matthias
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Jun 14 12:30:20 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 14 Jun 2017 20:30:20 +1000
Subject: [R] Plot MArginal distribution in the correct place
In-Reply-To: <CAB-TgNtNsuHyAJQvN0qh8=N9mDVCy0c2z1zEGXQOG-D8rcyKnw@mail.gmail.com>
References: <CAB-TgNt4u_r01t3vpBOo471tj-CZSazjL-zbSonyFsQrrQLbtQ@mail.gmail.com>
 <CAB-TgNtFXvxHPCbNWM2UeDeyDAt+56i=m5Mamc6mgFdB2kv3aA@mail.gmail.com>
 <CA+8X3fVP84StrtWD=gg7pUygf2WpSxOx4G1YW42YW-3AR3kfqw@mail.gmail.com>
 <CAB-TgNtyt8WkKa5xaZWZuJjWHriNbpr-XceBoYd2xqRpHX-4zQ@mail.gmail.com>
 <CAB-TgNtNsuHyAJQvN0qh8=N9mDVCy0c2z1zEGXQOG-D8rcyKnw@mail.gmail.com>
Message-ID: <CA+8X3fVkmyBo8zwoaS8XM9EmN9fbBxocJRuOd2t4803m8KTF_g@mail.gmail.com>

Hi Pedro,
If you keep that same margins for the second plot:

par(mar=c(10,0,6,6))
barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")

it looks reasonably well aligned to me. Because you are plotting the
counts of the values in Simulation, the ordinate (vertical axis) of
the bar plot is in quite different units from that of the plot on the
left side.

Jim

On Wed, Jun 14, 2017 at 5:33 PM, Pedro p?ramo <percentil101 at gmail.com> wrote:
> Please can you send me some orientation?
>
> Many thanks in advance.
>
> Only if posible one book o similar example to understand why it is not what
> I try.
>
> El 8 jun. 2017 7:50 PM, "Pedro p?ramo" <percentil101 at gmail.com> escribi?:
>>
>> Many thanks Jim.
>>
>> What I,m trying to show with the fhist plot is the empirical distribution
>> of the values of the left plot simulation.
>>
>> You say:
>> However, I don't think that this plot illustrates quite what you think it
>> does.
>>
>> Can you give me a clue to try to illustrate better if it is not showing
>> what I believe it shows a better way to show it?
>>
>> Many thanks in advance.
>>
>>
>>
>>
>>
>> El 7 jun. 2017 12:08, "Jim Lemon" <drjimlemon at gmail.com> escribi?:
>>
>> Hi Pedro,
>> As a one-off, you just shove the coordinates around a bit:
>>
>> par(mar=c(11,0,6,6))
>> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray",
>>  ylim=c(0,24))
>>
>> However, I don't think that this plot illustrates quite what you think it
>> does.
>>
>> Jim
>>
>>
>> On Wed, Jun 7, 2017 at 4:01 PM, Pedro p?ramo <percentil101 at gmail.com>
>> wrote:
>> > Please, I'm trying to put the right plot higher and centered on the left
>> > values but I don't achive.
>> >
>> > I would appreciate so much your help
>> >
>> > El 6 jun. 2017 22:37, "Pedro p?ramo" <percentil101 at gmail.com> escribi?:
>> >
>> >> Hi all,
>> >>
>> >> I have this code, but the marginal distribution plot doesn?t appear
>> >> aligned with the left plot.
>> >>
>> >>
>> >> I think could be something about layout or par() mar.
>> >>
>> >> The code was programmed by me time ago.
>> >>
>> >> Can anyone help me to get the marginal distribution on the center (more
>> >> higher centered)
>> >>
>> >> id.txt
>> >>
>> >> Could have this code:
>> >>
>> >> 05/01/2016;9335,200195
>> >> 06/01/2016;9197,400391
>> >> 07/01/2016;9059,299805
>> >> 08/01/2016;8909,200195
>> >> 11/01/2016;8886,099609
>> >> 12/01/2016;8915,400391
>> >> 13/01/2016;8934,5
>> >> 14/01/2016;8787,700195
>> >> 15/01/2016;8543,599609
>> >> 18/01/2016;8469,299805
>> >> 19/01/2016;8554,900391
>> >> 20/01/2016;8281,400391
>> >> 21/01/2016;8444,200195
>> >> 22/01/2016;8722,900391
>> >> 25/01/2016;8567,700195
>> >> 26/01/2016;8692,5
>> >> 27/01/2016;8741
>> >>
>> >>
>> >>
>> >> g<-read.table("id.txt", col.names=c("Dateh","LAST"), sep=";", dec=",")
>> >>
>> >> N=5000
>> >> B=24
>> >> ghy<-nrow(g)
>> >> r<-as.numeric(as.character(g$LAST[ghy]))
>> >>
>> >>
>> >> nf<-layout(matrix(c(1,1,1,1,2,2),1,6,byrow=TRUE))
>> >>
>> >> par(mar=c(6,6,6,0.5))
>> >>
>> >> A<-matrix(1:B,B,N);
>> >>
>> >>
>> >>
>> >> sigma<-0.06;
>> >>
>> >>
>> >>
>> >> mu<-0.00;
>> >>
>> >>
>> >> Z<-r*exp((mu-0.5*((sigma)^2)*A) +sigma*(sqrt(A))*matrix(
>> >> rnorm(N*B,0,1),
>> >> B, N))
>> >>
>> >> real1<-g$LAST[1:nrow(g)]
>> >>
>> >> real2<-matrix(NA,nrow(g),N-1)
>> >>
>> >> real<-cbind(real1,real2)
>> >>
>> >>
>> >>
>> >>
>> >> Po<-r*matrix(1,1,N);
>> >>
>> >>
>> >>
>> >> Sim<-rbind(Po,Z)
>> >> Simulation<-rbind(real,Z)
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >> par(mar=c(10,6,6,6))
>> >> matplot(Simulation,type="l",ylim=c(0,40000))
>> >>
>> >> abline(h = 8000, lwd = 2, col = "black")
>> >>
>> >> abline(h = 12000, lwd = 2, col = "black")
>> >> title("Dinamic Montecarlo Simulation 2 years ahead",font=4)
>> >>
>> >> fhist<-hist(Simulation,plot=FALSE)
>> >> par(mar=c(6,0,6,6))
>> >> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
>> >> grid()
>> >> title("Marginal Distribution",font=4)
>> >>
>> >>
>> >> rect(0, 0, 0, 0) # transparent
>> >>
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From percentil101 at gmail.com  Wed Jun 14 09:33:51 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Wed, 14 Jun 2017 09:33:51 +0200
Subject: [R] Plot MArginal distribution in the correct place
In-Reply-To: <CAB-TgNtyt8WkKa5xaZWZuJjWHriNbpr-XceBoYd2xqRpHX-4zQ@mail.gmail.com>
References: <CAB-TgNt4u_r01t3vpBOo471tj-CZSazjL-zbSonyFsQrrQLbtQ@mail.gmail.com>
 <CAB-TgNtFXvxHPCbNWM2UeDeyDAt+56i=m5Mamc6mgFdB2kv3aA@mail.gmail.com>
 <CA+8X3fVP84StrtWD=gg7pUygf2WpSxOx4G1YW42YW-3AR3kfqw@mail.gmail.com>
 <CAB-TgNtyt8WkKa5xaZWZuJjWHriNbpr-XceBoYd2xqRpHX-4zQ@mail.gmail.com>
Message-ID: <CAB-TgNtNsuHyAJQvN0qh8=N9mDVCy0c2z1zEGXQOG-D8rcyKnw@mail.gmail.com>

Please can you send me some orientation?

Many thanks in advance.

Only if posible one book o similar example to understand why it is not what
I try.

El 8 jun. 2017 7:50 PM, "Pedro p?ramo" <percentil101 at gmail.com> escribi?:

> Many thanks Jim.
>
> What I,m trying to show with the fhist plot is the empirical distribution
> of the values of the left plot simulation.
>
> You say:
> However, I don't think that this plot illustrates quite what you think it
> does.
>
> Can you give me a clue to try to illustrate better if it is not showing
> what I believe it shows a better way to show it?
>
> Many thanks in advance.
>
>
>
>
>
> El 7 jun. 2017 12:08, "Jim Lemon" <drjimlemon at gmail.com> escribi?:
>
> Hi Pedro,
> As a one-off, you just shove the coordinates around a bit:
>
> par(mar=c(11,0,6,6))
> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray",
>  ylim=c(0,24))
>
> However, I don't think that this plot illustrates quite what you think it
> does.
>
> Jim
>
>
> On Wed, Jun 7, 2017 at 4:01 PM, Pedro p?ramo <percentil101 at gmail.com>
> wrote:
> > Please, I'm trying to put the right plot higher and centered on the left
> > values but I don't achive.
> >
> > I would appreciate so much your help
> >
> > El 6 jun. 2017 22:37, "Pedro p?ramo" <percentil101 at gmail.com> escribi?:
> >
> >> Hi all,
> >>
> >> I have this code, but the marginal distribution plot doesn?t appear
> >> aligned with the left plot.
> >>
> >>
> >> I think could be something about layout or par() mar.
> >>
> >> The code was programmed by me time ago.
> >>
> >> Can anyone help me to get the marginal distribution on the center (more
> >> higher centered)
> >>
> >> id.txt
> >>
> >> Could have this code:
> >>
> >> 05/01/2016;9335,200195
> >> 06/01/2016;9197,400391
> >> 07/01/2016;9059,299805
> >> 08/01/2016;8909,200195
> >> 11/01/2016;8886,099609
> >> 12/01/2016;8915,400391
> >> 13/01/2016;8934,5
> >> 14/01/2016;8787,700195
> >> 15/01/2016;8543,599609
> >> 18/01/2016;8469,299805
> >> 19/01/2016;8554,900391
> >> 20/01/2016;8281,400391
> >> 21/01/2016;8444,200195
> >> 22/01/2016;8722,900391
> >> 25/01/2016;8567,700195
> >> 26/01/2016;8692,5
> >> 27/01/2016;8741
> >>
> >>
> >>
> >> g<-read.table("id.txt", col.names=c("Dateh","LAST"), sep=";", dec=",")
> >>
> >> N=5000
> >> B=24
> >> ghy<-nrow(g)
> >> r<-as.numeric(as.character(g$LAST[ghy]))
> >>
> >>
> >> nf<-layout(matrix(c(1,1,1,1,2,2),1,6,byrow=TRUE))
> >>
> >> par(mar=c(6,6,6,0.5))
> >>
> >> A<-matrix(1:B,B,N);
> >>
> >>
> >>
> >> sigma<-0.06;
> >>
> >>
> >>
> >> mu<-0.00;
> >>
> >>
> >> Z<-r*exp((mu-0.5*((sigma)^2)*A) +sigma*(sqrt(A))*matrix(
> rnorm(N*B,0,1),
> >> B, N))
> >>
> >> real1<-g$LAST[1:nrow(g)]
> >>
> >> real2<-matrix(NA,nrow(g),N-1)
> >>
> >> real<-cbind(real1,real2)
> >>
> >>
> >>
> >>
> >> Po<-r*matrix(1,1,N);
> >>
> >>
> >>
> >> Sim<-rbind(Po,Z)
> >> Simulation<-rbind(real,Z)
> >>
> >>
> >>
> >>
> >>
> >>
> >> par(mar=c(10,6,6,6))
> >> matplot(Simulation,type="l",ylim=c(0,40000))
> >>
> >> abline(h = 8000, lwd = 2, col = "black")
> >>
> >> abline(h = 12000, lwd = 2, col = "black")
> >> title("Dinamic Montecarlo Simulation 2 years ahead",font=4)
> >>
> >> fhist<-hist(Simulation,plot=FALSE)
> >> par(mar=c(6,0,6,6))
> >> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
> >> grid()
> >> title("Marginal Distribution",font=4)
> >>
> >>
> >> rect(0, 0, 0, 0) # transparent
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From jeanphilippe.fontaine at gssi.infn.it  Wed Jun 14 16:57:41 2017
From: jeanphilippe.fontaine at gssi.infn.it (jean-philippe)
Date: Wed, 14 Jun 2017 16:57:41 +0200
Subject: [R] draw stripes in a circle in R
Message-ID: <59414EE5.7050709@gssi.infn.it>

dear R users,

I would like to fill a circle with yellow stripes instead of a uniform 
yellow color. To draw the circle I used the following command after 
having loaded the (very nice !) plotrix library :

library(plotrix)
pdf("MWE.pdf",width=8, height=8)
plot(seq(-12.5,-8.7,length.out=100),seq(-11.3,-8.3,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
par(new=T)
plot(seq(-12.5,-8.7,length.out=100),seq(-11.7,-8.7,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
par(new=T)
polygon(c(seq(-12.5,-8.7,length.out=100), 
rev(seq(-12.5,-8.7,length.out=100))), c(seq(-11.3,-8.3,length.out=100), 
rev(seq(-11.7,-8.7,length.out=100))),
         col = alpha("red",0.4), border = NA)
par(new=T)
draw.circle(-12.85,-10.9,0.85,nv=1000,border=NULL,col="yellow",lty=1,lwd=1)
dev.off()

It looks a bit ugly since they are not real data, but it is the simplest 
MWE example that I found.


Thanks, best


Jean-Philippe

-- 
Jean-Philippe Fontaine
PhD Student in Astroparticle Physics,
Gran Sasso Science Institute (GSSI),
Viale Francesco Crispi 7,
67100 L'Aquila, Italy
Mobile: +393487128593, +33615653774


From jdnewmil at dcn.davis.ca.us  Wed Jun 14 18:46:16 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Jun 2017 09:46:16 -0700
Subject: [R] draw stripes in a circle in R
In-Reply-To: <59414EE5.7050709@gssi.infn.it>
References: <59414EE5.7050709@gssi.infn.it>
Message-ID: <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>

I don't see a question. If your question is whether R supports pattern fills, AFAIK it does not. If that is not your question, ask one. 
-- 
Sent from my phone. Please excuse my brevity.

On June 14, 2017 7:57:41 AM PDT, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
>dear R users,
>
>I would like to fill a circle with yellow stripes instead of a uniform 
>yellow color. To draw the circle I used the following command after 
>having loaded the (very nice !) plotrix library :
>
>library(plotrix)
>pdf("MWE.pdf",width=8, height=8)
>plot(seq(-12.5,-8.7,length.out=100),seq(-11.3,-8.3,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>par(new=T)
>plot(seq(-12.5,-8.7,length.out=100),seq(-11.7,-8.7,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>par(new=T)
>polygon(c(seq(-12.5,-8.7,length.out=100), 
>rev(seq(-12.5,-8.7,length.out=100))), c(seq(-11.3,-8.3,length.out=100),
>
>rev(seq(-11.7,-8.7,length.out=100))),
>         col = alpha("red",0.4), border = NA)
>par(new=T)
>draw.circle(-12.85,-10.9,0.85,nv=1000,border=NULL,col="yellow",lty=1,lwd=1)
>dev.off()
>
>It looks a bit ugly since they are not real data, but it is the
>simplest 
>MWE example that I found.
>
>
>Thanks, best
>
>
>Jean-Philippe


From jeanphilippe.fontaine at gssi.infn.it  Wed Jun 14 19:09:13 2017
From: jeanphilippe.fontaine at gssi.infn.it (jeanphilippe.fontaine)
Date: Wed, 14 Jun 2017 19:09:13 +0200
Subject: [R] draw stripes in a circle in R
Message-ID: <mjqhv0nf7ywyluhtmhl9do0l.1497460153591@email.android.com>


    
Sorry for that. Yes my question was whether or not and how is it possible to fill a circle of yellow stripes in R? Is it something that I have to precise in the color argument?
Thanks, best


Envoy? depuis mon appareil Samsung

-------- Message d'origine --------
De : Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Date : 14/06/2017  18:46  (GMT+01:00) 
? : r-help at r-project.org, jean-philippe <jeanphilippe.fontaine at gssi.infn.it>, r-help at R-project.org 
Objet : Re: [R] draw stripes in a circle in R 

I don't see a question. If your question is whether R supports pattern fills, AFAIK it does not. If that is not your question, ask one. 
-- 
Sent from my phone. Please excuse my brevity.

On June 14, 2017 7:57:41 AM PDT, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
>dear R users,
>
>I would like to fill a circle with yellow stripes instead of a uniform 
>yellow color. To draw the circle I used the following command after 
>having loaded the (very nice !) plotrix library :
>
>library(plotrix)
>pdf("MWE.pdf",width=8, height=8)
>plot(seq(-12.5,-8.7,length.out=100),seq(-11.3,-8.3,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>par(new=T)
>plot(seq(-12.5,-8.7,length.out=100),seq(-11.7,-8.7,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>par(new=T)
>polygon(c(seq(-12.5,-8.7,length.out=100), 
>rev(seq(-12.5,-8.7,length.out=100))), c(seq(-11.3,-8.3,length.out=100),
>
>rev(seq(-11.7,-8.7,length.out=100))),
>???????? col = alpha("red",0.4), border = NA)
>par(new=T)
>draw.circle(-12.85,-10.9,0.85,nv=1000,border=NULL,col="yellow",lty=1,lwd=1)
>dev.off()
>
>It looks a bit ugly since they are not real data, but it is the
>simplest 
>MWE example that I found.
>
>
>Thanks, best
>
>
>Jean-Philippe

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Jun 14 19:18:39 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Jun 2017 10:18:39 -0700
Subject: [R] draw stripes in a circle in R
In-Reply-To: <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
Message-ID: <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>


> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> I don't see a question. If your question is whether R supports pattern fills, AFAIK it does not. If that is not your question, ask one. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On June 14, 2017 7:57:41 AM PDT, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
>> dear R users,
>> 
>> I would like to fill a circle with yellow stripes instead of a uniform 
>> yellow color. To draw the circle I used the following command after 
>> having loaded the (very nice !) plotrix library :
>> 
>> library(plotrix)
>> pdf("MWE.pdf",width=8, height=8)
>> plot(seq(-12.5,-8.7,length.out=100),seq(-11.3,-8.3,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>> par(new=T)
>> plot(seq(-12.5,-8.7,length.out=100),seq(-11.7,-8.7,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>> par(new=T)
>> polygon(c(seq(-12.5,-8.7,length.out=100), 
>> rev(seq(-12.5,-8.7,length.out=100))), c(seq(-11.3,-8.3,length.out=100),
>> 
>> rev(seq(-11.7,-8.7,length.out=100))),
>>        col = alpha("red",0.4), border = NA)
>> par(new=T)
>> draw.circle(-12.85,-10.9,0.85,nv=1000,border=NULL,col="yellow",lty=1,lwd=1)
>> dev.off()
>> 

Agree that the coding question remains unclear, so not using the offered example but responding to the natural language query. The `polygon` function has 'density' and 'angle' argument that with 'col' and 'lwd' can make slanted fill lines. This is a modification of hte first example on `?polygon`?

x <- c(1:9, 8:1)
y <- c(1, 2*(5:3), 2, -1, 17, 9, 8, 2:9)
op <- par(mfcol = c(3, 1))
for(xpd in c(FALSE, TRUE, NA)) {
    plot(1:10, main = paste("xpd =", xpd))
    box("figure", col = "pink", lwd = 3)
    polygon(x, y, xpd = xpd, col = "orange", density=3, angle=45,  lwd = 5, border = "red")
}

The polygon function is _not_ in pkg::plotrix.



>> It looks a bit ugly since they are not real data, but it is the
>> simplest 
>> MWE example that I found.
>> 
>> 
>> Thanks, best
>> 
>> 
>> Jean-Philippe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Jun 14 19:29:47 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Jun 2017 10:29:47 -0700
Subject: [R] draw stripes in a circle in R
In-Reply-To: <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
 <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
Message-ID: <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>


> On Jun 14, 2017, at 10:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> I don't see a question. If your question is whether R supports pattern fills, AFAIK it does not. If that is not your question, ask one. 
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> On June 14, 2017 7:57:41 AM PDT, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
>>> dear R users,
>>> 
>>> I would like to fill a circle with yellow stripes instead of a uniform 
>>> yellow color. To draw the circle I used the following command after 
>>> having loaded the (very nice !) plotrix library :

I finally understood the question and it needs a hack to the draw.circle function in plotrix since the angle and density arguments don't get passed in:

First get code for draw.circle:

------

draw.circle   # then copy to console and edit

draw.circle2  <- function (x, y, radius, nv = 100, border = NULL, col = NA, lty = 1, 
                           density=NA, angle=45,  lwd = 1 ) 
{
    xylim <- par("usr")
    plotdim <- par("pin")
    ymult <- getYmult()
    angle.inc <- 2 * pi/nv
    angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
    if (length(col) < length(radius)) 
        col <- rep(col, length.out = length(radius))
    for (circle in 1:length(radius)) {
        xv <- cos(angles) * radius[circle] + x
        yv <- sin(angles) * radius[circle] * ymult + y
        polygon(xv, yv, border = border, col = col, lty = lty, density=density, angle=angle,
                lwd = lwd)
    }
    invisible(list(x = xv, y = yv))
}

Now run your call to pdf with draw.circle2 instead of draw.circle

Best;
David.
>>> 
>>> library(plotrix)
>>> pdf("MWE.pdf",width=8, height=8)
>>> plot(seq(-12.5,-8.7,length.out=100),seq(-11.3,-8.3,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>>> par(new=T)
>>> plot(seq(-12.5,-8.7,length.out=100),seq(-11.7,-8.7,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>>> par(new=T)
>>> polygon(c(seq(-12.5,-8.7,length.out=100), 
>>> rev(seq(-12.5,-8.7,length.out=100))), c(seq(-11.3,-8.3,length.out=100),
>>> 
>>> rev(seq(-11.7,-8.7,length.out=100))),
>>>       col = alpha("red",0.4), border = NA)
>>> par(new=T)
>>> draw.circle(-12.85,-10.9,0.85,nv=1000,border=NULL,col="yellow",lty=1,lwd=1)
>>> dev.off()
>>> 
> 
> Agree that the coding question remains unclear, so not using the offered example but responding to the natural language query. The `polygon` function has 'density' and 'angle' argument that with 'col' and 'lwd' can make slanted fill lines. This is a modification of hte first example on `?polygon`?
> 
> x <- c(1:9, 8:1)
> y <- c(1, 2*(5:3), 2, -1, 17, 9, 8, 2:9)
> op <- par(mfcol = c(3, 1))
> for(xpd in c(FALSE, TRUE, NA)) {
>    plot(1:10, main = paste("xpd =", xpd))
>    box("figure", col = "pink", lwd = 3)
>    polygon(x, y, xpd = xpd, col = "orange", density=3, angle=45,  lwd = 5, border = "red")
> }
> 
> The polygon function is _not_ in pkg::plotrix.
> 
> 
> 
>>> It looks a bit ugly since they are not real data, but it is the
>>> simplest 
>>> MWE example that I found.
>>> 
>>> 
>>> Thanks, best
>>> 
>>> 
>>> Jean-Philippe
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sewashm at gmail.com  Wed Jun 14 22:09:53 2017
From: sewashm at gmail.com (Ashta)
Date: Wed, 14 Jun 2017 15:09:53 -0500
Subject: [R] reading data
In-Reply-To: <CAAxdm-4DNL5mTGpFfGygm=LpZPeSCJ9FXZF1gxgq-tX45uyXTg@mail.gmail.com>
References: <CADDFq30PyTkU+QeksEQOKgfWJT-qio5rL+LS6SGiAYJzHTwt9A@mail.gmail.com>
 <CAAxdm-4DNL5mTGpFfGygm=LpZPeSCJ9FXZF1gxgq-tX45uyXTg@mail.gmail.com>
Message-ID: <CADDFq31zhXKdC9MPGD_w-w+A-67KnOn0n9kTcQnZXnG9EAGMSg@mail.gmail.com>

Hi Jim,
With a little  dig on my side , I have found the issue as to why the
script is skipping that file. The file is "ISO-8859 text, with CRLF
line terminators"

The file should be ASCII and I changed using  dos2unix  and CRLF line
terminators is eliminated but still I am not reading it. How can I
read those files  with "ISO-8859 text"?







On Tue, Jun 13, 2017 at 7:20 PM, jim holtman <jholtman at gmail.com> wrote:
> You need to provide reproducible data.  What does the file contain?  Why are
> you using 'sep=' when reading fixed format.  You might be able to attach the
> '.txt' to your email to help with the problem.  Also you did not state what
> the differences that you are seeing.  So help us out here.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Tue, Jun 13, 2017 at 5:09 PM, Ashta <sewashm at gmail.com> wrote:
>>
>> Hi all,
>>
>> I am using R to extract  data on a regular basis.
>> However, sometimes using the same script and the same data I am
>> getting different observation.
>> The library I am using and how I am reading  it is as follows.
>>
>> library(stringr)
>> namelist <- file("Adress1.txt",encoding="ISO-8859-1")
>> Name <- read.fwf(namelist,
>> colClasses="character", skip=2,sep="\t",fill=T,
>>                           width =c(2,8,1,1,1,1,1,1,9,5)+1,col.names=ccol)
>>
>> Can some one suggest me how track the issue?
>> Is it the library issue or Java issue?
>> May I read as free format instead of fixed format?
>>
>> Thank you in advance
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From r.turner at auckland.ac.nz  Wed Jun 14 22:53:21 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 15 Jun 2017 08:53:21 +1200
Subject: [R] [FORGED] Re:  draw stripes in a circle in R
In-Reply-To: <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
 <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
 <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
Message-ID: <37dabc70-deed-a689-7d6e-0c4d4062d18b@auckland.ac.nz>

On 15/06/17 05:29, David Winsemius wrote:
> 
>> On Jun 14, 2017, at 10:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>
>>> I don't see a question. If your question is whether R supports pattern fills, AFAIK it does not. If that is not your question, ask one.
>>> -- 
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On June 14, 2017 7:57:41 AM PDT, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
>>>> dear R users,
>>>>
>>>> I would like to fill a circle with yellow stripes instead of a uniform
>>>> yellow color. To draw the circle I used the following command after
>>>> having loaded the (very nice !) plotrix library :
> 
> I finally understood the question and it needs a hack to the draw.circle function in plotrix since the angle and density arguments don't get passed in:
> 
> First get code for draw.circle:
> 
> ------
> 
> draw.circle   # then copy to console and edit
> 
> draw.circle2  <- function (x, y, radius, nv = 100, border = NULL, col = NA, lty = 1,
>                             density=NA, angle=45,  lwd = 1 )
> {
>      xylim <- par("usr")
>      plotdim <- par("pin")
>      ymult <- getYmult()
>      angle.inc <- 2 * pi/nv
>      angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
>      if (length(col) < length(radius))
>          col <- rep(col, length.out = length(radius))
>      for (circle in 1:length(radius)) {
>          xv <- cos(angles) * radius[circle] + x
>          yv <- sin(angles) * radius[circle] * ymult + y
>          polygon(xv, yv, border = border, col = col, lty = lty, density=density, angle=angle,
>                  lwd = lwd)
>      }
>      invisible(list(x = xv, y = yv))
> }
> 
> Now run your call to pdf with draw.circle2 instead of draw.circle.

This is just idle curiosity, since I'm not really able to contribute 
anything useful, but I can't resist asking:  When I try to run the OP's 
code I get an error:

> Error in alpha("red", 0.4) : could not find function "alpha".

Why does this (apparently) not happen to anyone else?  Why does the 
universe pick on *me*?  What is the function "alpha()"?  Where is it to 
be found?

Searching on "alpha" is of course completely unproductive; there are far 
too many (totally irrelevant) instances.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jeanphilippe.fontaine at gssi.infn.it  Thu Jun 15 00:04:39 2017
From: jeanphilippe.fontaine at gssi.infn.it (jeanphilippe.fontaine)
Date: Thu, 15 Jun 2017 00:04:39 +0200
Subject: [R] [FORGED] Re:  draw stripes in a circle in R
Message-ID: <w9a69ju0mkjkhuuu1eh6oltu.1497477879826@email.android.com>


    




Envoy? depuis mon appareil Samsung

-------- Message d'origine --------
De : Rolf Turner <r.turner at auckland.ac.nz> 
Date : 14/06/2017  22:53  (GMT+01:00) 
? : David Winsemius <dwinsemius at comcast.net> 
Cc : r-help at r-project.org 
Objet : Re: [R] [FORGED] Re:&nbsp; draw stripes in a circle in R 

On 15/06/17 05:29, David Winsemius wrote:
> 
>> On Jun 14, 2017, at 10:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>
>>> I don't see a question. If your question is whether R supports pattern fills, AFAIK it does not. If that is not your question, ask one.
>>> -- 
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On June 14, 2017 7:57:41 AM PDT, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
>>>> dear R users,
>>>>
>>>> I would like to fill a circle with yellow stripes instead of a uniform
>>>> yellow color. To draw the circle I used the following command after
>>>> having loaded the (very nice !) plotrix library :
> 
> I finally understood the question and it needs a hack to the draw.circle function in plotrix since the angle and density arguments don't get passed in:
> 
> First get code for draw.circle:
> 
> ------
> 
> draw.circle?? # then copy to console and edit
> 
> draw.circle2? <- function (x, y, radius, nv = 100, border = NULL, col = NA, lty = 1,
>???????????????????????????? density=NA, angle=45,? lwd = 1 )
> {
>????? xylim <- par("usr")
>????? plotdim <- par("pin")
>????? ymult <- getYmult()
>????? angle.inc <- 2 * pi/nv
>????? angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
>????? if (length(col) < length(radius))
>????????? col <- rep(col, length.out = length(radius))
>????? for (circle in 1:length(radius)) {
>????????? xv <- cos(angles) * radius[circle] + x
>????????? yv <- sin(angles) * radius[circle] * ymult + y
>????????? polygon(xv, yv, border = border, col = col, lty = lty, density=density, angle=angle,
>????????????????? lwd = lwd)
>????? }
>????? invisible(list(x = xv, y = yv))
> }
> 
> Now run your call to pdf with draw.circle2 instead of draw.circle.

This is just idle curiosity, since I'm not really able to contribute 
anything useful, but I can't resist asking:? When I try to run the OP's 
code I get an error:

> Error in alpha("red", 0.4) : could not find function "alpha".

Sorry for the lack of precision, alpha is just to add some transparency to the color. This alpha parameter ranges from 0 fully transparent to 1, full color.I don't remember having loaded any package to use this function, I think it is there in base R.
Why does this (apparently) not happen to anyone else?? Why does the 
universe pick on *me*?? What is the function "alpha()"?? Where is it to 
be found?

Searching on "alpha" is of course completely unproductive; there are far 
too many (totally irrelevant) instances.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Jun 15 00:22:43 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 15 Jun 2017 08:22:43 +1000
Subject: [R] [FORGED] Re: draw stripes in a circle in R
In-Reply-To: <w9a69ju0mkjkhuuu1eh6oltu.1497477879826@email.android.com>
References: <w9a69ju0mkjkhuuu1eh6oltu.1497477879826@email.android.com>
Message-ID: <CA+8X3fU4JAmz1XjxLXofyzGBCGe0e1SeoM2z3TWQtf2vaMWfdw@mail.gmail.com>

Hi Jean-Phillipe,
Thanks for the plug on plotrix. Because of that I will suggest a gross
hack that will do almost what you want:

# your code down to draw.circle
segments(c(-12.7,-12.7),c(-11.2,-10.6),c(-12,-12),
 c(-10.75,-10.15),col="white",lwd=28)
draw.circle(-12.85,-10.9,0.85,nv=1000,border=NULL,
col=NA,lty=1,lwd=1)
box()
dev.off()

Your problem is that plotrix is written in base graphics, which is
simple to understand, but does not support layered graphics. Thus I
have to do the striping over the yellow circle and avoid overwriting
the big red stripe. You should do this using the grid graphic system,
but that would take too large a chunk of my morning to write an
example for you.

To Rolf - It happened to me as well, but because I saw Venus smiling
at me in the sky this morning I was granted the knowledge that it was
a function that had not been properly introduced to us and simply
replaced it with "red". Such are the benefits of evidence-based
astrology.

Jim


On Thu, Jun 15, 2017 at 8:04 AM, jeanphilippe.fontaine
<jeanphilippe.fontaine at gssi.infn.it> wrote:
>
>
>
>
>
>
> Envoy? depuis mon appareil Samsung
>
> -------- Message d'origine --------
> De : Rolf Turner <r.turner at auckland.ac.nz>
> Date : 14/06/2017  22:53  (GMT+01:00)
> ? : David Winsemius <dwinsemius at comcast.net>
> Cc : r-help at r-project.org
> Objet : Re: [R] [FORGED] Re:&nbsp; draw stripes in a circle in R
>
> On 15/06/17 05:29, David Winsemius wrote:
>>
>>> On Jun 14, 2017, at 10:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>
>>>
>>>> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>>
>>>> I don't see a question. If your question is whether R supports pattern fills, AFAIK it does not. If that is not your question, ask one.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On June 14, 2017 7:57:41 AM PDT, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
>>>>> dear R users,
>>>>>
>>>>> I would like to fill a circle with yellow stripes instead of a uniform
>>>>> yellow color. To draw the circle I used the following command after
>>>>> having loaded the (very nice !) plotrix library :
>>
>> I finally understood the question and it needs a hack to the draw.circle function in plotrix since the angle and density arguments don't get passed in:
>>
>> First get code for draw.circle:
>>
>> ------
>>
>> draw.circle   # then copy to console and edit
>>
>> draw.circle2  <- function (x, y, radius, nv = 100, border = NULL, col = NA, lty = 1,
>>                             density=NA, angle=45,  lwd = 1 )
>> {
>>      xylim <- par("usr")
>>      plotdim <- par("pin")
>>      ymult <- getYmult()
>>      angle.inc <- 2 * pi/nv
>>      angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
>>      if (length(col) < length(radius))
>>          col <- rep(col, length.out = length(radius))
>>      for (circle in 1:length(radius)) {
>>          xv <- cos(angles) * radius[circle] + x
>>          yv <- sin(angles) * radius[circle] * ymult + y
>>          polygon(xv, yv, border = border, col = col, lty = lty, density=density, angle=angle,
>>                  lwd = lwd)
>>      }
>>      invisible(list(x = xv, y = yv))
>> }
>>
>> Now run your call to pdf with draw.circle2 instead of draw.circle.
>
> This is just idle curiosity, since I'm not really able to contribute
> anything useful, but I can't resist asking:  When I try to run the OP's
> code I get an error:
>
>> Error in alpha("red", 0.4) : could not find function "alpha".
>
> Sorry for the lack of precision, alpha is just to add some transparency to the color. This alpha parameter ranges from 0 fully transparent to 1, full color.I don't remember having loaded any package to use this function, I think it is there in base R.
> Why does this (apparently) not happen to anyone else?  Why does the
> universe pick on *me*?  What is the function "alpha()"?  Where is it to
> be found?
>
> Searching on "alpha" is of course completely unproductive; there are far
> too many (totally irrelevant) instances.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jun 15 00:27:15 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Jun 2017 15:27:15 -0700
Subject: [R] [FORGED] Re:  draw stripes in a circle in R
In-Reply-To: <37dabc70-deed-a689-7d6e-0c4d4062d18b@auckland.ac.nz>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
 <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
 <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
 <37dabc70-deed-a689-7d6e-0c4d4062d18b@auckland.ac.nz>
Message-ID: <DF43D723-2199-4C60-B49D-DB2FD4E75080@comcast.net>


> On Jun 14, 2017, at 1:53 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 15/06/17 05:29, David Winsemius wrote:
>>> On Jun 14, 2017, at 10:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>> 
>>>> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>> 
>>>> I don't see a question. If your question is whether R supports pattern fills, AFAIK it does not. If that is not your question, ask one.
>>>> -- 
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On June 14, 2017 7:57:41 AM PDT, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
>>>>> dear R users,
>>>>> 
>>>>> I would like to fill a circle with yellow stripes instead of a uniform
>>>>> yellow color. To draw the circle I used the following command after
>>>>> having loaded the (very nice !) plotrix library :
>> I finally understood the question and it needs a hack to the draw.circle function in plotrix since the angle and density arguments don't get passed in:
>> First get code for draw.circle:
>> ------
>> draw.circle   # then copy to console and edit
>> draw.circle2  <- function (x, y, radius, nv = 100, border = NULL, col = NA, lty = 1,
>>                            density=NA, angle=45,  lwd = 1 )
>> {
>>     xylim <- par("usr")
>>     plotdim <- par("pin")
>>     ymult <- getYmult()
>>     angle.inc <- 2 * pi/nv
>>     angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
>>     if (length(col) < length(radius))
>>         col <- rep(col, length.out = length(radius))
>>     for (circle in 1:length(radius)) {
>>         xv <- cos(angles) * radius[circle] + x
>>         yv <- sin(angles) * radius[circle] * ymult + y
>>         polygon(xv, yv, border = border, col = col, lty = lty, density=density, angle=angle,
>>                 lwd = lwd)
>>     }
>>     invisible(list(x = xv, y = yv))
>> }
>> Now run your call to pdf with draw.circle2 instead of draw.circle.
> 
> This is just idle curiosity, since I'm not really able to contribute anything useful, but I can't resist asking:  When I try to run the OP's code I get an error:
> 
>> Error in alpha("red", 0.4) : could not find function "alpha".
> 
> Why does this (apparently) not happen to anyone else?  Why does the universe pick on *me*?  What is the function "alpha()"?  Where is it to be found?

I discovered some time ago that I no longer needed to load the ggplot2 package. I wasn't entirely happy to make this discovery since I stilll cling to the old lattice style. Eventually I figgured out that it was because one of packages that I load in my .Rprofile-file had changed its imports. The `alpha` function I see is from ggplot2. Resistance is futile. I've now been partially assimilated.


> 
> Searching on "alpha" is of course completely unproductive; there are far too many (totally irrelevant) instances.


> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276

David Winsemius
Alameda, CA, USA


From chocold12 at gmail.com  Thu Jun 15 00:40:19 2017
From: chocold12 at gmail.com (lily li)
Date: Wed, 14 Jun 2017 16:40:19 -0600
Subject: [R] about fitting a regression line
Message-ID: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>

Hi R users,

I have some data points (Xi, Yi), and they may follow such a pattern Yi =
cCOS(Xi) + d, how to find the c and d in R? which function to use? Also,
how to get the R2 and p value for this correlation? Thanks for any kind of
help.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Jun 15 00:54:34 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Jun 2017 15:54:34 -0700
Subject: [R] [FORGED] Re:  draw stripes in a circle in R
In-Reply-To: <37dabc70-deed-a689-7d6e-0c4d4062d18b@auckland.ac.nz>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
 <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
 <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
 <37dabc70-deed-a689-7d6e-0c4d4062d18b@auckland.ac.nz>
Message-ID: <8D202E71-39F3-43D9-AAFE-5B0FB14FD5CB@dcn.davis.ca.us>

Package 'scales' has the alpha function... associated with ggplot2. A bit out of place here if that is the origin. Yes, we are squarely in non-reproducible example territory, also known as the Twilight Zone.
-- 
Sent from my phone. Please excuse my brevity.

On June 14, 2017 1:53:21 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>On 15/06/17 05:29, David Winsemius wrote:
>> 
>>> On Jun 14, 2017, at 10:18 AM, David Winsemius
><dwinsemius at comcast.net> wrote:
>>>
>>>
>>>> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>>>
>>>> I don't see a question. If your question is whether R supports
>pattern fills, AFAIK it does not. If that is not your question, ask
>one.
>>>> -- 
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On June 14, 2017 7:57:41 AM PDT, jean-philippe
><jeanphilippe.fontaine at gssi.infn.it> wrote:
>>>>> dear R users,
>>>>>
>>>>> I would like to fill a circle with yellow stripes instead of a
>uniform
>>>>> yellow color. To draw the circle I used the following command
>after
>>>>> having loaded the (very nice !) plotrix library :
>> 
>> I finally understood the question and it needs a hack to the
>draw.circle function in plotrix since the angle and density arguments
>don't get passed in:
>> 
>> First get code for draw.circle:
>> 
>> ------
>> 
>> draw.circle   # then copy to console and edit
>> 
>> draw.circle2  <- function (x, y, radius, nv = 100, border = NULL, col
>= NA, lty = 1,
>>                             density=NA, angle=45,  lwd = 1 )
>> {
>>      xylim <- par("usr")
>>      plotdim <- par("pin")
>>      ymult <- getYmult()
>>      angle.inc <- 2 * pi/nv
>>      angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
>>      if (length(col) < length(radius))
>>          col <- rep(col, length.out = length(radius))
>>      for (circle in 1:length(radius)) {
>>          xv <- cos(angles) * radius[circle] + x
>>          yv <- sin(angles) * radius[circle] * ymult + y
>>          polygon(xv, yv, border = border, col = col, lty = lty,
>density=density, angle=angle,
>>                  lwd = lwd)
>>      }
>>      invisible(list(x = xv, y = yv))
>> }
>> 
>> Now run your call to pdf with draw.circle2 instead of draw.circle.
>
>This is just idle curiosity, since I'm not really able to contribute 
>anything useful, but I can't resist asking:  When I try to run the OP's
>
>code I get an error:
>
>> Error in alpha("red", 0.4) : could not find function "alpha".
>
>Why does this (apparently) not happen to anyone else?  Why does the 
>universe pick on *me*?  What is the function "alpha()"?  Where is it to
>
>be found?
>
>Searching on "alpha" is of course completely unproductive; there are
>far 
>too many (totally irrelevant) instances.
>
>cheers,
>
>Rolf


From macqueen1 at llnl.gov  Thu Jun 15 01:25:44 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 14 Jun 2017 23:25:44 +0000
Subject: [R] about fitting a regression line
In-Reply-To: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
References: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
Message-ID: <8FBED4BA-0E82-4F78-8623-EB272EE45800@llnl.gov>

Start with the lm() function; i.e., see

  ?lm

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 6/14/17, 3:40 PM, "R-help on behalf of lily li" <r-help-bounces at r-project.org on behalf of chocold12 at gmail.com> wrote:

    Hi R users,
    
    I have some data points (Xi, Yi), and they may follow such a pattern Yi =
    cCOS(Xi) + d, how to find the c and d in R? which function to use? Also,
    how to get the R2 and p value for this correlation? Thanks for any kind of
    help.
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From chocold12 at gmail.com  Thu Jun 15 01:28:18 2017
From: chocold12 at gmail.com (lily li)
Date: Wed, 14 Jun 2017 17:28:18 -0600
Subject: [R] about fitting a regression line
In-Reply-To: <8FBED4BA-0E82-4F78-8623-EB272EE45800@llnl.gov>
References: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
 <8FBED4BA-0E82-4F78-8623-EB272EE45800@llnl.gov>
Message-ID: <CAN5afy-yDY5+gF2SrWT=RMkxMcTViN7q7n-R5p+B5U8EXqSiSQ@mail.gmail.com>

Thanks. I thought lm() function is for linear model, such as the
correlation below:
Y= aX + b

On Wed, Jun 14, 2017 at 5:25 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Start with the lm() function; i.e., see
>
>   ?lm
>
> -Don
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
> On 6/14/17, 3:40 PM, "R-help on behalf of lily li" <
> r-help-bounces at r-project.org on behalf of chocold12 at gmail.com> wrote:
>
>     Hi R users,
>
>     I have some data points (Xi, Yi), and they may follow such a pattern
> Yi =
>     cCOS(Xi) + d, how to find the c and d in R? which function to use?
> Also,
>     how to get the R2 and p value for this correlation? Thanks for any
> kind of
>     help.
>
>         [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Jun 15 01:32:12 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 15 Jun 2017 11:32:12 +1200
Subject: [R] [FORGED]  about fitting a regression line
In-Reply-To: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
References: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
Message-ID: <64a1dfed-c5d9-9bc1-53e1-5044fe75d45a@auckland.ac.nz>

On 15/06/17 10:40, lily li wrote:
> Hi R users,
> 
> I have some data points (Xi, Yi), and they may follow such a pattern Yi =
> cCOS(Xi) + d, how to find the c and d in R? which function to use? Also,
> how to get the R2 and p value for this correlation? Thanks for any kind of
> help.

If I understand you correctly (always a dubious conditional):

     fit <- lm(y ~ cos(x))

where y and x are vectors of the y and x values of your data points, 
should answer all of your questions.

I am bewildered that you need to ask.  You have been posting to this 
list for quite a while.  Have you learned nothing about R?  It's time 
that you did.  Read and study carefully "An Introduction to R" from the 
R web site -> Manuals.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Thu Jun 15 01:37:43 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 15 Jun 2017 11:37:43 +1200
Subject: [R] [FORGED] Re:  about fitting a regression line
In-Reply-To: <CAN5afy-yDY5+gF2SrWT=RMkxMcTViN7q7n-R5p+B5U8EXqSiSQ@mail.gmail.com>
References: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
 <8FBED4BA-0E82-4F78-8623-EB272EE45800@llnl.gov>
 <CAN5afy-yDY5+gF2SrWT=RMkxMcTViN7q7n-R5p+B5U8EXqSiSQ@mail.gmail.com>
Message-ID: <f4606048-b614-02ba-2b56-87a56c0086c5@auckland.ac.nz>

On 15/06/17 11:28, lily li wrote:
> Thanks. I thought lm() function is for linear model, such as the
> correlation below:
> Y= aX + b
> 
> On Wed, Jun 14, 2017 at 5:25 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> 
>> Start with the lm() function; i.e., see
>>
>>    ?lm


And you don't think that Y = a*cos(X) + b is a linear model?

The mind boggles.

Well, I guess there is a "subtlety" here.  Linear models are *linear in 
the PARAMETERS of the model*, not in the predictors.

First-year knuckle-draggers get confused about this.  People who are 
using R to do research should be a bit beyond such confusion.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Thu Jun 15 01:41:34 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 15 Jun 2017 11:41:34 +1200
Subject: [R] [FORGED] Re:  draw stripes in a circle in R
In-Reply-To: <DF43D723-2199-4C60-B49D-DB2FD4E75080@comcast.net>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
 <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
 <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
 <37dabc70-deed-a689-7d6e-0c4d4062d18b@auckland.ac.nz>
 <DF43D723-2199-4C60-B49D-DB2FD4E75080@comcast.net>
Message-ID: <c78dba76-d4e2-7751-b747-0b7f30531bc4@auckland.ac.nz>

On 15/06/17 10:27, David Winsemius wrote:
> 
>> On Jun 14, 2017, at 1:53 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

<SNIP>

>> Why does this (apparently) not happen to anyone else?  Why does the
>> universe pick on *me*?  What is the function "alpha()"?  Where is
>> it to be found?
> 
> I discovered some time ago that I no longer needed to load the
> ggplot2 package. I wasn't entirely happy to make this discovery since
> I stilll cling to the old lattice style. Eventually I figgured out
> that it was because one of packages that I load in my .Rprofile-file
> had changed its imports. The `alpha` function I see is from ggplot2.
> Resistance is futile. I've now been partially assimilated.
<SNIP>

N'ya-hah!  The light dawns!  Thank you.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewmil at dcn.davis.ca.us  Thu Jun 15 02:52:46 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Jun 2017 17:52:46 -0700
Subject: [R] [FORGED] Re:  draw stripes in a circle in R
In-Reply-To: <DF43D723-2199-4C60-B49D-DB2FD4E75080@comcast.net>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
 <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
 <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
 <37dabc70-deed-a689-7d6e-0c4d4062d18b@auckland.ac.nz>
 <DF43D723-2199-4C60-B49D-DB2FD4E75080@comcast.net>
Message-ID: <C9AF1791-C8B3-4E98-809C-9EC7082126FA@dcn.davis.ca.us>

Sigh. I never load packages in .Rprofile to avoid the irreproducibility trap. Might seem drastic to some, but I don't feel much pain because I almost always edit my code in a file rather than on the fly at the console, and re-run it frequently from a fresh R process to check my progress. 
-- 
Sent from my phone. Please excuse my brevity.

On June 14, 2017 3:27:15 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Jun 14, 2017, at 1:53 PM, Rolf Turner <r.turner at auckland.ac.nz>
>wrote:
>> 
>> On 15/06/17 05:29, David Winsemius wrote:
>>>> On Jun 14, 2017, at 10:18 AM, David Winsemius
><dwinsemius at comcast.net> wrote:
>>>> 
>>>> 
>>>>> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>>>> 
>>>>> I don't see a question. If your question is whether R supports
>pattern fills, AFAIK it does not. If that is not your question, ask
>one.
>>>>> -- 
>>>>> Sent from my phone. Please excuse my brevity.
>>>>> 
>>>>> On June 14, 2017 7:57:41 AM PDT, jean-philippe
><jeanphilippe.fontaine at gssi.infn.it> wrote:
>>>>>> dear R users,
>>>>>> 
>>>>>> I would like to fill a circle with yellow stripes instead of a
>uniform
>>>>>> yellow color. To draw the circle I used the following command
>after
>>>>>> having loaded the (very nice !) plotrix library :
>>> I finally understood the question and it needs a hack to the
>draw.circle function in plotrix since the angle and density arguments
>don't get passed in:
>>> First get code for draw.circle:
>>> ------
>>> draw.circle   # then copy to console and edit
>>> draw.circle2  <- function (x, y, radius, nv = 100, border = NULL,
>col = NA, lty = 1,
>>>                            density=NA, angle=45,  lwd = 1 )
>>> {
>>>     xylim <- par("usr")
>>>     plotdim <- par("pin")
>>>     ymult <- getYmult()
>>>     angle.inc <- 2 * pi/nv
>>>     angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
>>>     if (length(col) < length(radius))
>>>         col <- rep(col, length.out = length(radius))
>>>     for (circle in 1:length(radius)) {
>>>         xv <- cos(angles) * radius[circle] + x
>>>         yv <- sin(angles) * radius[circle] * ymult + y
>>>         polygon(xv, yv, border = border, col = col, lty = lty,
>density=density, angle=angle,
>>>                 lwd = lwd)
>>>     }
>>>     invisible(list(x = xv, y = yv))
>>> }
>>> Now run your call to pdf with draw.circle2 instead of draw.circle.
>> 
>> This is just idle curiosity, since I'm not really able to contribute
>anything useful, but I can't resist asking:  When I try to run the OP's
>code I get an error:
>> 
>>> Error in alpha("red", 0.4) : could not find function "alpha".
>> 
>> Why does this (apparently) not happen to anyone else?  Why does the
>universe pick on *me*?  What is the function "alpha()"?  Where is it to
>be found?
>
>I discovered some time ago that I no longer needed to load the ggplot2
>package. I wasn't entirely happy to make this discovery since I stilll
>cling to the old lattice style. Eventually I figgured out that it was
>because one of packages that I load in my .Rprofile-file had changed
>its imports. The `alpha` function I see is from ggplot2. Resistance is
>futile. I've now been partially assimilated.
>
>
>> 
>> Searching on "alpha" is of course completely unproductive; there are
>far too many (totally irrelevant) instances.
>
>
>> 
>> cheers,
>> 
>> Rolf
>> 
>> -- 
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>
>David Winsemius
>Alameda, CA, USA


From dwinsemius at comcast.net  Thu Jun 15 03:51:20 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Jun 2017 18:51:20 -0700
Subject: [R] [FORGED] Re:  draw stripes in a circle in R
In-Reply-To: <C9AF1791-C8B3-4E98-809C-9EC7082126FA@dcn.davis.ca.us>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
 <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
 <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
 <37dabc70-deed-a689-7d6e-0c4d4062d18b@auckland.ac.nz>
 <DF43D723-2199-4C60-B49D-DB2FD4E75080@comcast.net>
 <C9AF1791-C8B3-4E98-809C-9EC7082126FA@dcn.davis.ca.us>
Message-ID: <0FA53E19-F7E3-4137-9526-7B549DF843A4@comcast.net>


> On Jun 14, 2017, at 5:52 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Sigh. I never load packages in .Rprofile to avoid the irreproducibility trap. Might seem drastic to some, but I don't feel much pain because I almost always edit my code in a file rather than on the fly at the console, and re-run it frequently from a fresh R process to check my progress. 

Yes, <sigh>. But I am a long-time user of the rms/Hmisc combo, as well as the survival package, so near the top of my .Rprofile is:

require(lattice)
require(sos)
require(rms)

Should I be ashamed of that?

I suppose I should, and I _am_ ashamed of some of the other stuff in there  ....<delete>, <delete> ... and I've been meaning to address my manifold deficiencies w.r.t. irreproducibility by moving to RStudio, but I keep putting it off.

-- 
David.

> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On June 14, 2017 3:27:15 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Jun 14, 2017, at 1:53 PM, Rolf Turner <r.turner at auckland.ac.nz>
>> wrote:
>>> 
>>> On 15/06/17 05:29, David Winsemius wrote:
>>>>> On Jun 14, 2017, at 10:18 AM, David Winsemius
>> <dwinsemius at comcast.net> wrote:
>>>>> 
>>>>> 
>>>>>> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>> 
>>>>>> I don't see a question. If your question is whether R supports
>> pattern fills, AFAIK it does not. If that is not your question, ask
>> one.
>>>>>> -- 
>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>> 
>>>>>> On June 14, 2017 7:57:41 AM PDT, jean-philippe
>> <jeanphilippe.fontaine at gssi.infn.it> wrote:
>>>>>>> dear R users,
>>>>>>> 
>>>>>>> I would like to fill a circle with yellow stripes instead of a
>> uniform
>>>>>>> yellow color. To draw the circle I used the following command
>> after
>>>>>>> having loaded the (very nice !) plotrix library :
>>>> I finally understood the question and it needs a hack to the
>> draw.circle function in plotrix since the angle and density arguments
>> don't get passed in:
>>>> First get code for draw.circle:
>>>> ------
>>>> draw.circle   # then copy to console and edit
>>>> draw.circle2  <- function (x, y, radius, nv = 100, border = NULL,
>> col = NA, lty = 1,
>>>>                           density=NA, angle=45,  lwd = 1 )
>>>> {
>>>>    xylim <- par("usr")
>>>>    plotdim <- par("pin")
>>>>    ymult <- getYmult()
>>>>    angle.inc <- 2 * pi/nv
>>>>    angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
>>>>    if (length(col) < length(radius))
>>>>        col <- rep(col, length.out = length(radius))
>>>>    for (circle in 1:length(radius)) {
>>>>        xv <- cos(angles) * radius[circle] + x
>>>>        yv <- sin(angles) * radius[circle] * ymult + y
>>>>        polygon(xv, yv, border = border, col = col, lty = lty,
>> density=density, angle=angle,
>>>>                lwd = lwd)
>>>>    }
>>>>    invisible(list(x = xv, y = yv))
>>>> }
>>>> Now run your call to pdf with draw.circle2 instead of draw.circle.
>>> 
>>> This is just idle curiosity, since I'm not really able to contribute
>> anything useful, but I can't resist asking:  When I try to run the OP's
>> code I get an error:
>>> 
>>>> Error in alpha("red", 0.4) : could not find function "alpha".
>>> 
>>> Why does this (apparently) not happen to anyone else?  Why does the
>> universe pick on *me*?  What is the function "alpha()"?  Where is it to
>> be found?
>> 
>> I discovered some time ago that I no longer needed to load the ggplot2
>> package. I wasn't entirely happy to make this discovery since I stilll
>> cling to the old lattice style. Eventually I figgured out that it was
>> because one of packages that I load in my .Rprofile-file had changed
>> its imports. The `alpha` function I see is from ggplot2. Resistance is
>> futile. I've now been partially assimilated.
>> 
>> 
>>> 
>>> Searching on "alpha" is of course completely unproductive; there are
>> far too many (totally irrelevant) instances.
>> 
>> 
>>> 
>>> cheers,
>>> 
>>> Rolf
>>> 
>>> -- 
>>> Technical Editor ANZJS
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>> 
>> David Winsemius
>> Alameda, CA, USA

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Thu Jun 15 04:16:18 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 15 Jun 2017 14:16:18 +1200
Subject: [R] [FORGED] Re:  draw stripes in a circle in R
In-Reply-To: <0FA53E19-F7E3-4137-9526-7B549DF843A4@comcast.net>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
 <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
 <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
 <37dabc70-deed-a689-7d6e-0c4d4062d18b@auckland.ac.nz>
 <DF43D723-2199-4C60-B49D-DB2FD4E75080@comcast.net>
 <C9AF1791-C8B3-4E98-809C-9EC7082126FA@dcn.davis.ca.us>
 <0FA53E19-F7E3-4137-9526-7B549DF843A4@comcast.net>
Message-ID: <e9f2f8c6-b23a-0493-693f-8075f7014fc3@auckland.ac.nz>

On 15/06/17 13:51, David Winsemius wrote:
> 
>> On Jun 14, 2017, at 5:52 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Sigh. I never load packages in .Rprofile to avoid the irreproducibility trap. Might seem drastic to some, but I don't feel much pain because I almost always edit my code in a file rather than on the fly at the console, and re-run it frequently from a fresh R process to check my progress.
> 
> Yes, <sigh>. But I am a long-time user of the rms/Hmisc combo, as well as the survival package, so near the top of my .Rprofile is:
> 
> require(lattice)
> require(sos)
> require(rms)
> 
> Should I be ashamed of that?
> 
> I suppose I should, and I _am_ ashamed of some of the other stuff in
> there  ....<delete>, <delete> ... and I've been meaning to address my
> manifold deficiencies w.r.t. irreproducibility by moving to RStudio,
> but I keep putting it off.


This is getting *way* off topic ... but why does using RStudio help with 
the irreproducibility problem?  I thought that RStudio just made it 
easier to point-and-click.  For those who like doing that sort of thing.
(I tend to believe the dictum that a GUI makes it easy to do easy things 
and impossible to do hard things.)

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From petr.pikal at precheza.cz  Thu Jun 15 08:20:09 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 15 Jun 2017 06:20:09 +0000
Subject: [R] about fitting a regression line
In-Reply-To: <CAN5afy-yDY5+gF2SrWT=RMkxMcTViN7q7n-R5p+B5U8EXqSiSQ@mail.gmail.com>
References: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
 <8FBED4BA-0E82-4F78-8623-EB272EE45800@llnl.gov>
 <CAN5afy-yDY5+gF2SrWT=RMkxMcTViN7q7n-R5p+B5U8EXqSiSQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A7A4F@SRVEXCHCM301.precheza.cz>

Hi

But X can be some function like - sin, cos, log, exp...

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> Sent: Thursday, June 15, 2017 1:28 AM
> To: MacQueen, Don <macqueen1 at llnl.gov>
> Cc: R mailing list <r-help at r-project.org>
> Subject: Re: [R] about fitting a regression line
>
> Thanks. I thought lm() function is for linear model, such as the correlation
> below:
> Y= aX + b
>
> On Wed, Jun 14, 2017 at 5:25 PM, MacQueen, Don <macqueen1 at llnl.gov>
> wrote:
>
> > Start with the lm() function; i.e., see
> >
> >   ?lm
> >
> > -Don
> >
> > --
> > Don MacQueen
> >
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> >
> >
> > On 6/14/17, 3:40 PM, "R-help on behalf of lily li" <
> > r-help-bounces at r-project.org on behalf of chocold12 at gmail.com> wrote:
> >
> >     Hi R users,
> >
> >     I have some data points (Xi, Yi), and they may follow such a
> > pattern Yi =
> >     cCOS(Xi) + d, how to find the c and d in R? which function to use?
> > Also,
> >     how to get the R2 and p value for this correlation? Thanks for any
> > kind of
> >     help.
> >
> >         [[alternative HTML version deleted]]
> >
> >     ______________________________________________
> >     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jeanphilippe.fontaine at gssi.infn.it  Thu Jun 15 10:35:19 2017
From: jeanphilippe.fontaine at gssi.infn.it (jean-philippe)
Date: Thu, 15 Jun 2017 10:35:19 +0200
Subject: [R] draw stripes in a circle in R
In-Reply-To: <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
 <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
 <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
Message-ID: <594246C7.7070803@gssi.infn.it>

hi david

Thank you very much for the hack of draw.circle that you proposed me.
I don't understand some part of the code, why do you pass radius as a 
vector in the function (if I understand well the purpose of the for 
loop) ? Also what is ymult?

If I set the radius to the value 0.85 as I wanted (so as a scalar), I 
don't see any difference in the result when I call this function 
draw.circle2, the stripes are not drawn inside the circle. I don't know 
if it is normal.


Thanks, best


Jean-Philippe

On 14/06/2017 19:29, David Winsemius wrote:
>> On Jun 14, 2017, at 10:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>
>>> I don't see a question. If your question is whether R supports pattern fills, AFAIK it does not. If that is not your question, ask one.
>>> -- 
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On June 14, 2017 7:57:41 AM PDT, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
>>>> dear R users,
>>>>
>>>> I would like to fill a circle with yellow stripes instead of a uniform
>>>> yellow color. To draw the circle I used the following command after
>>>> having loaded the (very nice !) plotrix library :
> I finally understood the question and it needs a hack to the draw.circle function in plotrix since the angle and density arguments don't get passed in:
>
> First get code for draw.circle:
>
> ------
>
> draw.circle   # then copy to console and edit
>
> draw.circle2  <- function (x, y, radius, nv = 100, border = NULL, col = NA, lty = 1,
>                             density=NA, angle=45,  lwd = 1 )
> {
>      xylim <- par("usr")
>      plotdim <- par("pin")
>      ymult <- getYmult()
>      angle.inc <- 2 * pi/nv
>      angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
>      if (length(col) < length(radius))
>          col <- rep(col, length.out = length(radius))
>      for (circle in 1:length(radius)) {
>          xv <- cos(angles) * radius[circle] + x
>          yv <- sin(angles) * radius[circle] * ymult + y
>          polygon(xv, yv, border = border, col = col, lty = lty, density=density, angle=angle,
>                  lwd = lwd)
>      }
>      invisible(list(x = xv, y = yv))
> }
>
> Now run your call to pdf with draw.circle2 instead of draw.circle
>
> Best;
> David.
>>>> library(plotrix)
>>>> pdf("MWE.pdf",width=8, height=8)
>>>> plot(seq(-12.5,-8.7,length.out=100),seq(-11.3,-8.3,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>>>> par(new=T)
>>>> plot(seq(-12.5,-8.7,length.out=100),seq(-11.7,-8.7,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>>>> par(new=T)
>>>> polygon(c(seq(-12.5,-8.7,length.out=100),
>>>> rev(seq(-12.5,-8.7,length.out=100))), c(seq(-11.3,-8.3,length.out=100),
>>>>
>>>> rev(seq(-11.7,-8.7,length.out=100))),
>>>>        col = alpha("red",0.4), border = NA)
>>>> par(new=T)
>>>> draw.circle(-12.85,-10.9,0.85,nv=1000,border=NULL,col="yellow",lty=1,lwd=1)
>>>> dev.off()
>>>>
>> Agree that the coding question remains unclear, so not using the offered example but responding to the natural language query. The `polygon` function has 'density' and 'angle' argument that with 'col' and 'lwd' can make slanted fill lines. This is a modification of hte first example on `?polygon`?
>>
>> x <- c(1:9, 8:1)
>> y <- c(1, 2*(5:3), 2, -1, 17, 9, 8, 2:9)
>> op <- par(mfcol = c(3, 1))
>> for(xpd in c(FALSE, TRUE, NA)) {
>>     plot(1:10, main = paste("xpd =", xpd))
>>     box("figure", col = "pink", lwd = 3)
>>     polygon(x, y, xpd = xpd, col = "orange", density=3, angle=45,  lwd = 5, border = "red")
>> }
>>
>> The polygon function is _not_ in pkg::plotrix.
>>
>>
>>
>>>> It looks a bit ugly since they are not real data, but it is the
>>>> simplest
>>>> MWE example that I found.
>>>>
>>>>
>>>> Thanks, best
>>>>
>>>>
>>>> Jean-Philippe
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Jean-Philippe Fontaine
PhD Student in Astroparticle Physics,
Gran Sasso Science Institute (GSSI),
Viale Francesco Crispi 7,
67100 L'Aquila, Italy
Mobile: +393487128593, +33615653774


From S.Ellison at LGCGroup.com  Thu Jun 15 13:18:19 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 15 Jun 2017 12:18:19 +0100
Subject: [R] understanding I() in lmer formula
In-Reply-To: <20170613182554.D49724057F@losangelesyouthorchestra.org>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
Message-ID: <1A8C1289955EF649A09086A153E267240BA3DB2649@GBTEDVPEXCMB04.corp.lgc-group.com>

>  Is there a difference between I(x*y) and I(y*x) ?
> I have a call to lmer that results in this complaint:
>   Error in is.alpha2.subordinate * ~z.min.co.res :

A reproducible example would help ...

In the absence of that, check the classes of the two variables in I() and, if you run the product on the command line, either inside I() or not, what's the class of the result?
If that is order-dependent for the object types you're combining, while I don't know why that might be it would go some way to explaining the outcome.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From zadig_1 at excite.com  Thu Jun 15 17:33:00 2017
From: zadig_1 at excite.com (ce)
Date: Thu, 15 Jun 2017 11:33:00 -0400
Subject: [R] is.null(mylist[1]) and is.null(mylist$a) returns different
	values
Message-ID: <20170615113300.30538@web005.roc2.bluetie.com>

Hi

I have a list :

mylist <- list( a = NULL, b = 1, c = 2 )

> mylist[1]
$a
NULL

> is.null(mylist[1])
[1] FALSE

> is.null(mylist$a)
[1] TRUE

why? I need to use mylist[1] 

From huzefa.khalil at umich.edu  Thu Jun 15 17:39:47 2017
From: huzefa.khalil at umich.edu (Huzefa Khalil)
Date: Thu, 15 Jun 2017 11:39:47 -0400
Subject: [R] is.null(mylist[1]) and is.null(mylist$a) returns different
	values
In-Reply-To: <20170615113300.30538@web005.roc2.bluetie.com>
References: <20170615113300.30538@web005.roc2.bluetie.com>
Message-ID: <CADsG8gOSqaPboQuSEeTMeqChbb9s3ccuDAgjw6p3O15OqhJBTA@mail.gmail.com>

Hi,

Try

> is.null(mylist[[1]])
[1] TRUE

Notice the double square brackets.

From: ?`[`
"The most important distinction between [, [[ and $ is that the [ can
select more than one element whereas the other two select a single
element."

On Thu, Jun 15, 2017 at 11:33 AM, ce <zadig_1 at excite.com> wrote:
> Hi
>
> I have a list :
>
> mylist <- list( a = NULL, b = 1, c = 2 )
>
>> mylist[1]
> $a
> NULL
>
>> is.null(mylist[1])
> [1] FALSE
>
>> is.null(mylist$a)
> [1] TRUE
>
> why? I need to use mylist[1]
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Huzefa Khalil
PhD Candidate,
Department of Political Science,
University of Michigan


From jdnewmil at dcn.davis.ca.us  Thu Jun 15 17:56:37 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 15 Jun 2017 08:56:37 -0700
Subject: [R] is.null(mylist[1]) and is.null(mylist$a) returns
	different	values
In-Reply-To: <CADsG8gOSqaPboQuSEeTMeqChbb9s3ccuDAgjw6p3O15OqhJBTA@mail.gmail.com>
References: <20170615113300.30538@web005.roc2.bluetie.com>
 <CADsG8gOSqaPboQuSEeTMeqChbb9s3ccuDAgjw6p3O15OqhJBTA@mail.gmail.com>
Message-ID: <2EB56D13-1910-4E84-938E-10D50156D94E@dcn.davis.ca.us>

I find that the str function is more helpful for understanding the difference between a null list and a list containing a null list than the implicit print function call that the interpreter invokes when you enter an expression at the console. 

str( mylist[1] )

-- 
Sent from my phone. Please excuse my brevity.

On June 15, 2017 8:39:47 AM PDT, Huzefa Khalil <huzefa.khalil at umich.edu> wrote:
>Hi,
>
>Try
>
>> is.null(mylist[[1]])
>[1] TRUE
>
>Notice the double square brackets.
>
>From: ?`[`
>"The most important distinction between [, [[ and $ is that the [ can
>select more than one element whereas the other two select a single
>element."
>
>On Thu, Jun 15, 2017 at 11:33 AM, ce <zadig_1 at excite.com> wrote:
>> Hi
>>
>> I have a list :
>>
>> mylist <- list( a = NULL, b = 1, c = 2 )
>>
>>> mylist[1]
>> $a
>> NULL
>>
>>> is.null(mylist[1])
>> [1] FALSE
>>
>>> is.null(mylist$a)
>> [1] TRUE
>>
>> why? I need to use mylist[1]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Thu Jun 15 18:06:26 2017
From: zadig_1 at excite.com (ce)
Date: Thu, 15 Jun 2017 12:06:26 -0400
Subject: [R] is.null(mylist[1]) and is.null(mylist$a) returns
	different	values
Message-ID: <20170615120626.5875@web003.roc2.bluetie.com>

Thank you all , very informative, never thought of doing a str( mylist[1] )  

-----Original Message-----
From: "Jeff Newmiller" [jdnewmil at dcn.davis.ca.us]
Date: 06/15/2017 11:56 AM
To: r-help at r-project.org, "Huzefa Khalil" <huzefa.khalil at umich.edu>, "ce" <zadig_1 at excite.com>
Subject: Re: [R] is.null(mylist[1]) and is.null(mylist$a) returns different	values

I find that the str function is more helpful for understanding the difference between a null list and a list containing a null list than the implicit print function call that the interpreter invokes when you enter an expression at the console. 

str( mylist[1] )

-- 
Sent from my phone. Please excuse my brevity.

On June 15, 2017 8:39:47 AM PDT, Huzefa Khalil <huzefa.khalil at umich.edu> wrote:
>Hi,
>
>Try
>
>> is.null(mylist[[1]])
>[1] TRUE
>
>Notice the double square brackets.
>
>From: ?`[`
>"The most important distinction between [, [[ and $ is that the [ can
>select more than one element whereas the other two select a single
>element."
>
>On Thu, Jun 15, 2017 at 11:33 AM, ce <zadig_1 at excite.com> wrote:
>> Hi
>>
>> I have a list :
>>
>> mylist <- list( a = NULL, b = 1, c = 2 )
>>
>>> mylist[1]
>> $a
>> NULL
>>
>>> is.null(mylist[1])
>> [1] FALSE
>>
>>> is.null(mylist$a)
>> [1] TRUE
>>
>> why? I need to use mylist[1]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Jun 15 18:19:47 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 15 Jun 2017 09:19:47 -0700
Subject: [R] is.null(mylist[1]) and is.null(mylist$a) returns different
	values
In-Reply-To: <2EB56D13-1910-4E84-938E-10D50156D94E@dcn.davis.ca.us>
References: <20170615113300.30538@web005.roc2.bluetie.com>
 <CADsG8gOSqaPboQuSEeTMeqChbb9s3ccuDAgjw6p3O15OqhJBTA@mail.gmail.com>
 <2EB56D13-1910-4E84-938E-10D50156D94E@dcn.davis.ca.us>
Message-ID: <CAF8bMcawxtXBOTytmeFvkqskehZ+WxkXLWTrw2nMQAnL5Y8GKg@mail.gmail.com>

By the way, NULL is not a "null list", it has class (and type and mode)
"NULL" not "list".   "NULL" is an odd class, in that it can have only one
instance and hence can never have any attributes.  "list" objects, like
other vector objects, may have length zero, but such objects are not the
same as NULL.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jun 15, 2017 at 8:56 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I find that the str function is more helpful for understanding the
> difference between a null list and a list containing a null list than the
> implicit print function call that the interpreter invokes when you enter an
> expression at the console.
>
> str( mylist[1] )
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 15, 2017 8:39:47 AM PDT, Huzefa Khalil <huzefa.khalil at umich.edu>
> wrote:
> >Hi,
> >
> >Try
> >
> >> is.null(mylist[[1]])
> >[1] TRUE
> >
> >Notice the double square brackets.
> >
> >From: ?`[`
> >"The most important distinction between [, [[ and $ is that the [ can
> >select more than one element whereas the other two select a single
> >element."
> >
> >On Thu, Jun 15, 2017 at 11:33 AM, ce <zadig_1 at excite.com> wrote:
> >> Hi
> >>
> >> I have a list :
> >>
> >> mylist <- list( a = NULL, b = 1, c = 2 )
> >>
> >>> mylist[1]
> >> $a
> >> NULL
> >>
> >>> is.null(mylist[1])
> >> [1] FALSE
> >>
> >>> is.null(mylist$a)
> >> [1] TRUE
> >>
> >> why? I need to use mylist[1]
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Jun 15 19:16:24 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 15 Jun 2017 10:16:24 -0700
Subject: [R] draw stripes in a circle in R
In-Reply-To: <594246C7.7070803@gssi.infn.it>
References: <59414EE5.7050709@gssi.infn.it>
 <F1515505-A7BD-47F3-BF48-B845F942FE11@dcn.davis.ca.us>
 <236952E2-B60F-4F51-A0E6-160645EAB9E0@comcast.net>
 <D9DF6102-148A-4D2B-90E7-B65B07E2CABC@comcast.net>
 <594246C7.7070803@gssi.infn.it>
Message-ID: <0E5E2F15-075F-4006-B1E0-7528DD74AFB5@comcast.net>


> On Jun 15, 2017, at 1:35 AM, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
> 
> hi david
> 
> Thank you very much for the hack of draw.circle that you proposed me.
> I don't understand some part of the code, why do you pass radius as a vector in the function (if I understand well the purpose of the for loop) ? Also what is ymult?
> 
> If I set the radius to the value 0.85 as I wanted (so as a scalar), I don't see any difference in the result when I call this function draw.circle2, the stripes are not drawn inside the circle. I don't know if it is normal.

It certainly wasn't intended. I expected the radius argument to get used repeatedly just as it is in the original function, but remain a scalar. Did you just copy-paste my code or do your own alterations? And did you add the arguments to the new call?

When I use:

Your set-up surrounds this:

 draw.circle2(-12.85,-10.9,0.85,nv=1000,border=NULL,col="yellow",lty=1,lwd=5, density=2, angle=45)

I get the attached pdf:

-------------- next part --------------
A non-text attachment was scrubbed...
Name: MWE.pdf
Type: application/pdf
Size: 9753 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170615/2387defb/attachment.pdf>
-------------- next part --------------


I don't think you are interpreting the code in the same manner as I do.  When hacking someone else code it's probably a good idea to give all the arguments names. That way you uncover errors in the argument passing better because name collision get flagged and the error messages become more meaningful.

Feel free to post annotations using the octothorpe method in between lines to explain how you understand the code.

-- 
David.
> 
> 
> Thanks, best
> 
> 
> Jean-Philippe
> 
> On 14/06/2017 19:29, David Winsemius wrote:
>>> On Jun 14, 2017, at 10:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>> 
>>>> On Jun 14, 2017, at 9:46 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>> 
>>>> I don't see a question. If your question is whether R supports pattern fills, AFAIK it does not. If that is not your question, ask one.
>>>> -- 
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On June 14, 2017 7:57:41 AM PDT, jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
>>>>> dear R users,
>>>>> 
>>>>> I would like to fill a circle with yellow stripes instead of a uniform
>>>>> yellow color. To draw the circle I used the following command after
>>>>> having loaded the (very nice !) plotrix library :
>> I finally understood the question and it needs a hack to the draw.circle function in plotrix since the angle and density arguments don't get passed in:
>> 
>> First get code for draw.circle:
>> 
>> ------
>> 
>> draw.circle   # then copy to console and edit
>> 
>> draw.circle2  <- function (x, y, radius, nv = 100, border = NULL, col = NA, lty = 1,
>>                            density=NA, angle=45,  lwd = 1 )
>> {
>>     xylim <- par("usr")
>>     plotdim <- par("pin")
>>     ymult <- getYmult()
>>     angle.inc <- 2 * pi/nv
>>     angles <- seq(0, 2 * pi - angle.inc, by = angle.inc)
>>     if (length(col) < length(radius))
>>         col <- rep(col, length.out = length(radius))
>>     for (circle in 1:length(radius)) {
>>         xv <- cos(angles) * radius[circle] + x
>>         yv <- sin(angles) * radius[circle] * ymult + y
>>         polygon(xv, yv, border = border, col = col, lty = lty, density=density, angle=angle,
>>                 lwd = lwd)
>>     }
>>     invisible(list(x = xv, y = yv))
>> }
>> 
>> Now run your call to pdf with draw.circle2 instead of draw.circle
>> 
>> Best;
>> David.
>>>>> library(plotrix)
>>>>> pdf("MWE.pdf",width=8, height=8)
>>>>> plot(seq(-12.5,-8.7,length.out=100),seq(-11.3,-8.3,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>>>>> par(new=T)
>>>>> plot(seq(-12.5,-8.7,length.out=100),seq(-11.7,-8.7,length.out=100),type="l",col="red",xlim=c(-12.5,-8.7),ylim=c(-11.5,-8.5))
>>>>> par(new=T)
>>>>> polygon(c(seq(-12.5,-8.7,length.out=100),
>>>>> rev(seq(-12.5,-8.7,length.out=100))), c(seq(-11.3,-8.3,length.out=100),
>>>>> 
>>>>> rev(seq(-11.7,-8.7,length.out=100))),
>>>>>       col = alpha("red",0.4), border = NA)
>>>>> par(new=T)
>>>>> draw.circle(-12.85,-10.9,0.85,nv=1000,border=NULL,col="yellow",lty=1,lwd=1)
>>>>> dev.off()
>>>>> 
>>> Agree that the coding question remains unclear, so not using the offered example but responding to the natural language query. The `polygon` function has 'density' and 'angle' argument that with 'col' and 'lwd' can make slanted fill lines. This is a modification of hte first example on `?polygon`?
>>> 
>>> x <- c(1:9, 8:1)
>>> y <- c(1, 2*(5:3), 2, -1, 17, 9, 8, 2:9)
>>> op <- par(mfcol = c(3, 1))
>>> for(xpd in c(FALSE, TRUE, NA)) {
>>>    plot(1:10, main = paste("xpd =", xpd))
>>>    box("figure", col = "pink", lwd = 3)
>>>    polygon(x, y, xpd = xpd, col = "orange", density=3, angle=45,  lwd = 5, border = "red")
>>> }
>>> 
>>> The polygon function is _not_ in pkg::plotrix.
>>> 
>>> 
>>> 
>>>>> It looks a bit ugly since they are not real data, but it is the
>>>>> simplest
>>>>> MWE example that I found.
>>>>> 
>>>>> 
>>>>> Thanks, best
>>>>> 
>>>>> 
>>>>> Jean-Philippe
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Jean-Philippe Fontaine
> PhD Student in Astroparticle Physics,
> Gran Sasso Science Institute (GSSI),
> Viale Francesco Crispi 7,
> 67100 L'Aquila, Italy
> Mobile: +393487128593, +33615653774
> 

David Winsemius
Alameda, CA, USA


From english.server at gmail.com  Thu Jun 15 14:33:13 2017
From: english.server at gmail.com (Persian Irani)
Date: Thu, 15 Jun 2017 17:03:13 +0430
Subject: [R] Changing font of a certrain column in an excel file
Message-ID: <CAP0cSCS-pxLyD2We_Y3KphbZzKA_FSjYffii7vvueaCT_+tZgA@mail.gmail.com>

Hi all!
I need an example/reference to show me how to change the font of a
certain column in an existing .xlsx  document. Thank you in advance


From don-r-help at isis.cs3-inc.com  Thu Jun 15 15:13:42 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Thu, 15 Jun 2017 13:13:42 +0000
Subject: [R] understanding I() in lmer formula
In-Reply-To: <1A8C1289955EF649A09086A153E267240BA3DB2649@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <1A8C1289955EF649A09086A153E267240BA3DB2649@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <22850.34822.65267.508738@losangelesyouthorchestra.org>

The suggestion to post on R-sig-ME was a good one.
The problem turned out to be a bug in lmer parsing, which is now fixed.

S Ellison writes:
 > >  Is there a difference between I(x*y) and I(y*x) ?
 > > I have a call to lmer that results in this complaint:
 > >   Error in is.alpha2.subordinate * ~z.min.co.res :
 > 
 > A reproducible example would help ...


From ruipbarradas at sapo.pt  Thu Jun 15 17:38:30 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 15 Jun 2017 16:38:30 +0100
Subject: [R] is.null(mylist[1]) and is.null(mylist$a) returns different
 values
In-Reply-To: <20170615113300.30538@web005.roc2.bluetie.com>
References: <20170615113300.30538@web005.roc2.bluetie.com>
Message-ID: <5942A9F6.2040107@sapo.pt>

Hello,

You have to be aware that mylist[1] and mylist[[1]] are different things.


class(mylist[1])
[1] "list"
class(mylist[[1]])
[1] "NULL"


Apparently you want/need the latter:

is.null(mylist[[1]])
[1] TRUE


Hope this helps,

Rui Barradas

Em 15-06-2017 16:33, ce escreveu:
> Hi
>
> I have a list :
>
> mylist <- list( a = NULL, b = 1, c = 2 )
>
>> mylist[1]
> $a
> NULL
>
>> is.null(mylist[1])
> [1] FALSE
>
>> is.null(mylist$a)
> [1] TRUE
>
> why? I need to use mylist[1]
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Massoud.Boroujerdi at glasgow.ac.uk  Thu Jun 15 17:41:14 2017
From: Massoud.Boroujerdi at glasgow.ac.uk (Massoud Boroujerdi)
Date: Thu, 15 Jun 2017 15:41:14 +0000
Subject: [R] is.null(mylist[1]) and is.null(mylist$a) returns
	different	values
In-Reply-To: <20170615113300.30538@web005.roc2.bluetie.com>
References: <20170615113300.30538@web005.roc2.bluetie.com>
Message-ID: <9F092C320C170B4793FC721A68E0EB890FAB4761@CMS12-01.campus.gla.ac.uk>

I think look at the manual

Is.null(mylist[[1]])

Will work

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ce
Sent: 15 June 2017 16:33
To: r-help at r-project.org
Subject: [R] is.null(mylist[1]) and is.null(mylist$a) returns different values

Hi

I have a list :

mylist <- list( a = NULL, b = 1, c = 2 )

> mylist[1]
$a
NULL

> is.null(mylist[1])
[1] FALSE

> is.null(mylist$a)
[1] TRUE

why? I need to use mylist[1]
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From adomalik at sfu.ca  Thu Jun 15 18:53:41 2017
From: adomalik at sfu.ca (Alice Domalik)
Date: Thu, 15 Jun 2017 09:53:41 -0700 (PDT)
Subject: [R] glmmTMB
Message-ID: <654140761.80370528.1497545621308.JavaMail.zimbra@sfu.ca>

Hi List, 

I'm having some trouble finding documentation for the package glmmTMB. 
I would like to fit a zero-truncated poisson, what do I need to specify in "family = " for this distribution? 

Thanks! Alice 

	[[alternative HTML version deleted]]


From rmcgehee at walleyetrading.net  Thu Jun 15 20:03:56 2017
From: rmcgehee at walleyetrading.net (Robert McGehee)
Date: Thu, 15 Jun 2017 18:03:56 +0000
Subject: [R] Estimating Unbiased Standard Deviation with Autocorrelation
Message-ID: <30D28A63376088428E8318DD67FD407F78B0F7@ny-mailstore1.walleyetrading.net>

Hello,
I have a vector of values with significant autocorrelation, and I want to calculate an unbiased standard deviation that adjusts for the autocorrelation. The formula linked below purports to provide what I want:

https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation#Effect_of_autocorrelation_.28serial_correlation.29

However, rather than just implementing this equation in my own function, I figured there is likely already an R function that does this, and perhaps does a better job of handling the subtleties of the adjustment when the ACF itself is estimated from the same data that is used to estimate the sample standard deviation (if there are any).
 
If such a function exists, can anyone point me to it?

Thanks in advance,
Robert


From motyocska at yahoo.com  Thu Jun 15 21:37:21 2017
From: motyocska at yahoo.com (Andras Farkas)
Date: Thu, 15 Jun 2017 19:37:21 +0000 (UTC)
Subject: [R] "reverse" quantile function
References: <561667961.10655178.1497555441927.ref@mail.yahoo.com>
Message-ID: <561667961.10655178.1497555441927@mail.yahoo.com>

Dear All,

we have:

t<-seq(0,24,1) 
a<-10*exp(-0.05*t) 
b<-10*exp(-0.07*t) 
c<-10*exp(-0.1*t) 
d<-10*exp(-0.03*t) 
z<-data.frame(a,b,c,d) 

res<-t(apply(z, 1, quantile, probs=c(0.3))) 



my goal is to do a 'reverse" of the function here that produces "res" on a data frame, ie: to get the answer 0.3 back for the percentile location when I have "res" available to me... For a single vector this would be done using ecdf something like this:

x <- rnorm(100) 
#then I know this value:  
quantile(x,0.33) 
#so do this step
ecdf(x)(quantile(x,0.33)) 
#to get 0.33 back...

 any suggestions on how I could to that for a data frame?

thank you,Andras Farkas


From chocold12 at gmail.com  Thu Jun 15 21:48:04 2017
From: chocold12 at gmail.com (lily li)
Date: Thu, 15 Jun 2017 13:48:04 -0600
Subject: [R] about fitting a regression line
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A7A4F@SRVEXCHCM301.precheza.cz>
References: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
 <8FBED4BA-0E82-4F78-8623-EB272EE45800@llnl.gov>
 <CAN5afy-yDY5+gF2SrWT=RMkxMcTViN7q7n-R5p+B5U8EXqSiSQ@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A7A4F@SRVEXCHCM301.precheza.cz>
Message-ID: <CAN5afy9Quwt66UVjz+uML7gSf=vDye1rki+W8YJzR8R9KrGg8Q@mail.gmail.com>

Thanks for your replies. I tried the regression, but then got a NA value
for the slope. And here is the error message:
Coefficients: (1 not defined because of singularities)


On Thu, Jun 15, 2017 at 12:20 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> But X can be some function like - sin, cos, log, exp...
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> > Sent: Thursday, June 15, 2017 1:28 AM
> > To: MacQueen, Don <macqueen1 at llnl.gov>
> > Cc: R mailing list <r-help at r-project.org>
> > Subject: Re: [R] about fitting a regression line
> >
> > Thanks. I thought lm() function is for linear model, such as the
> correlation
> > below:
> > Y= aX + b
> >
> > On Wed, Jun 14, 2017 at 5:25 PM, MacQueen, Don <macqueen1 at llnl.gov>
> > wrote:
> >
> > > Start with the lm() function; i.e., see
> > >
> > >   ?lm
> > >
> > > -Don
> > >
> > > --
> > > Don MacQueen
> > >
> > > Lawrence Livermore National Laboratory
> > > 7000 East Ave., L-627
> > > Livermore, CA 94550
> > > 925-423-1062
> > >
> > >
> > > On 6/14/17, 3:40 PM, "R-help on behalf of lily li" <
> > > r-help-bounces at r-project.org on behalf of chocold12 at gmail.com> wrote:
> > >
> > >     Hi R users,
> > >
> > >     I have some data points (Xi, Yi), and they may follow such a
> > > pattern Yi =
> > >     cCOS(Xi) + d, how to find the c and d in R? which function to use?
> > > Also,
> > >     how to get the R2 and p value for this correlation? Thanks for any
> > > kind of
> > >     help.
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > >     ______________________________________________
> > >     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >     https://stat.ethz.ch/mailman/listinfo/r-help
> > >     PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html
> > >     and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From cryan at binghamton.edu  Thu Jun 15 22:07:14 2017
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Thu, 15 Jun 2017 16:07:14 -0400
Subject: [R] about fitting a regression line
In-Reply-To: <CAN5afy9Quwt66UVjz+uML7gSf=vDye1rki+W8YJzR8R9KrGg8Q@mail.gmail.com>
References: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
 <8FBED4BA-0E82-4F78-8623-EB272EE45800@llnl.gov>
 <CAN5afy-yDY5+gF2SrWT=RMkxMcTViN7q7n-R5p+B5U8EXqSiSQ@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A7A4F@SRVEXCHCM301.precheza.cz>
 <CAN5afy9Quwt66UVjz+uML7gSf=vDye1rki+W8YJzR8R9KrGg8Q@mail.gmail.com>
Message-ID: <CAM+rpYmSCg1HPioQ_RUknNrk3W8MfvL_PQ_4HQmi-Mt3jC18tg@mail.gmail.com>

Rather than just posting your error message, it helps immensely to post the
code that produced the error--indeed with some small sample data that
reproduces the problem.

x <- rnorm(40)
y <- 0.6 * x + rnorm(40, sd = 0.3)
plot(y ~ x)
model <- lm(y ~ cos(x))
summary(model)
plot(y ~ cos(x))
abline(model, col = "red")

## obviously I am not claiming that this is a meaningful or sensible model
## It's just for illustrative purposes

--Chris Ryan

On Thu, Jun 15, 2017 at 3:48 PM, lily li <chocold12 at gmail.com> wrote:

> Thanks for your replies. I tried the regression, but then got a NA value
> for the slope. And here is the error message:
> Coefficients: (1 not defined because of singularities)
>
>
> On Thu, Jun 15, 2017 at 12:20 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> > Hi
> >
> > But X can be some function like - sin, cos, log, exp...
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily
> li
> > > Sent: Thursday, June 15, 2017 1:28 AM
> > > To: MacQueen, Don <macqueen1 at llnl.gov>
> > > Cc: R mailing list <r-help at r-project.org>
> > > Subject: Re: [R] about fitting a regression line
> > >
> > > Thanks. I thought lm() function is for linear model, such as the
> > correlation
> > > below:
> > > Y= aX + b
> > >
> > > On Wed, Jun 14, 2017 at 5:25 PM, MacQueen, Don <macqueen1 at llnl.gov>
> > > wrote:
> > >
> > > > Start with the lm() function; i.e., see
> > > >
> > > >   ?lm
> > > >
> > > > -Don
> > > >
> > > > --
> > > > Don MacQueen
> > > >
> > > > Lawrence Livermore National Laboratory
> > > > 7000 East Ave., L-627
> > > > Livermore, CA 94550
> > > > 925-423-1062
> > > >
> > > >
> > > > On 6/14/17, 3:40 PM, "R-help on behalf of lily li" <
> > > > r-help-bounces at r-project.org on behalf of chocold12 at gmail.com>
> wrote:
> > > >
> > > >     Hi R users,
> > > >
> > > >     I have some data points (Xi, Yi), and they may follow such a
> > > > pattern Yi =
> > > >     cCOS(Xi) + d, how to find the c and d in R? which function to
> use?
> > > > Also,
> > > >     how to get the R2 and p value for this correlation? Thanks for
> any
> > > > kind of
> > > >     help.
> > > >
> > > >         [[alternative HTML version deleted]]
> > > >
> > > >     ______________________________________________
> > > >     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > > >     https://stat.ethz.ch/mailman/listinfo/r-help
> > > >     PLEASE do read the posting guide http://www.R-project.org/
> > > > posting-guide.html
> > > >     and provide commented, minimal, self-contained, reproducible
> code.
> > > >
> > > >
> > > >
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> > ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie
> > vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> > ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout;
> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> > p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n
> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
> tohoto
> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> > intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> > sender. Delete the contents of this e-mail with all attachments and its
> > copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> > authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> > caused by modifications of the e-mail or by delay with transfer of the
> > email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> > contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> > immediately accept such offer; The sender of this e-mail (offer) excludes
> > any acceptance of the offer on the part of the recipient containing any
> > amendment or variation.
> > - the sender insists on that the respective contract is concluded only
> > upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter
> > into any contracts on behalf of the company except for cases in which
> > he/she is expressly authorized to do so in writing, and such
> authorization
> > or power of attorney is submitted to the recipient or the person
> > represented by the recipient, or the existence of such authorization is
> > known to the recipient of the person represented by the recipient.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Jun 15 22:10:25 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 15 Jun 2017 13:10:25 -0700
Subject: [R] about fitting a regression line
In-Reply-To: <CAN5afy9Quwt66UVjz+uML7gSf=vDye1rki+W8YJzR8R9KrGg8Q@mail.gmail.com>
References: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
 <8FBED4BA-0E82-4F78-8623-EB272EE45800@llnl.gov>
 <CAN5afy-yDY5+gF2SrWT=RMkxMcTViN7q7n-R5p+B5U8EXqSiSQ@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A7A4F@SRVEXCHCM301.precheza.cz>
 <CAN5afy9Quwt66UVjz+uML7gSf=vDye1rki+W8YJzR8R9KrGg8Q@mail.gmail.com>
Message-ID: <CAF8bMcZoOYiJkYV=LMwWvJuw=_Xe+-ANVztVESA20=133eKSLg@mail.gmail.com>

You really have to show what you did to get the result you showed.  E.g.,
something like the following:

> d <- data.frame(x=1:7, y=c(7,4,2,3,6,8,7))
> fit <- lm( y~cos(x), data=d)
> coef(fit)
(Intercept)      cos(x)
   5.079190    3.022805
> sfit <- summary(fit)
> sfit$r.squared
[1] 0.9915548
> with(sfit, pf(fstatistic[1], fstatistic[2], fstatistic[3], lower=FALSE))
       value
2.232099e-06



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jun 15, 2017 at 12:48 PM, lily li <chocold12 at gmail.com> wrote:

> Thanks for your replies. I tried the regression, but then got a NA value
> for the slope. And here is the error message:
> Coefficients: (1 not defined because of singularities)
>
>
> On Thu, Jun 15, 2017 at 12:20 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> > Hi
> >
> > But X can be some function like - sin, cos, log, exp...
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily
> li
> > > Sent: Thursday, June 15, 2017 1:28 AM
> > > To: MacQueen, Don <macqueen1 at llnl.gov>
> > > Cc: R mailing list <r-help at r-project.org>
> > > Subject: Re: [R] about fitting a regression line
> > >
> > > Thanks. I thought lm() function is for linear model, such as the
> > correlation
> > > below:
> > > Y= aX + b
> > >
> > > On Wed, Jun 14, 2017 at 5:25 PM, MacQueen, Don <macqueen1 at llnl.gov>
> > > wrote:
> > >
> > > > Start with the lm() function; i.e., see
> > > >
> > > >   ?lm
> > > >
> > > > -Don
> > > >
> > > > --
> > > > Don MacQueen
> > > >
> > > > Lawrence Livermore National Laboratory
> > > > 7000 East Ave., L-627
> > > > Livermore, CA 94550
> > > > 925-423-1062
> > > >
> > > >
> > > > On 6/14/17, 3:40 PM, "R-help on behalf of lily li" <
> > > > r-help-bounces at r-project.org on behalf of chocold12 at gmail.com>
> wrote:
> > > >
> > > >     Hi R users,
> > > >
> > > >     I have some data points (Xi, Yi), and they may follow such a
> > > > pattern Yi =
> > > >     cCOS(Xi) + d, how to find the c and d in R? which function to
> use?
> > > > Also,
> > > >     how to get the R2 and p value for this correlation? Thanks for
> any
> > > > kind of
> > > >     help.
> > > >
> > > >         [[alternative HTML version deleted]]
> > > >
> > > >     ______________________________________________
> > > >     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > > >     https://stat.ethz.ch/mailman/listinfo/r-help
> > > >     PLEASE do read the posting guide http://www.R-project.org/
> > > > posting-guide.html
> > > >     and provide commented, minimal, self-contained, reproducible
> code.
> > > >
> > > >
> > > >
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> > ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie
> > vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> > ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout;
> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> > p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n
> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
> tohoto
> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> > intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> > sender. Delete the contents of this e-mail with all attachments and its
> > copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> > authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> > caused by modifications of the e-mail or by delay with transfer of the
> > email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> > contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> > immediately accept such offer; The sender of this e-mail (offer) excludes
> > any acceptance of the offer on the part of the recipient containing any
> > amendment or variation.
> > - the sender insists on that the respective contract is concluded only
> > upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter
> > into any contracts on behalf of the company except for cases in which
> > he/she is expressly authorized to do so in writing, and such
> authorization
> > or power of attorney is submitted to the recipient or the person
> > represented by the recipient, or the existence of such authorization is
> > known to the recipient of the person represented by the recipient.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Jun 15 22:32:17 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 15 Jun 2017 13:32:17 -0700
Subject: [R] glmmTMB
In-Reply-To: <654140761.80370528.1497545621308.JavaMail.zimbra@sfu.ca>
References: <654140761.80370528.1497545621308.JavaMail.zimbra@sfu.ca>
Message-ID: <DEDE2751-D73D-4468-BC70-F4AD423AA5B1@comcast.net>


> On Jun 15, 2017, at 9:53 AM, Alice Domalik <adomalik at sfu.ca> wrote:
> 
> Hi List, 
> 
> I'm having some trouble finding documentation for the package glmmTMB. 

I had no trouble finding documentation with the search strategy copied from your sentence: "documentation for the package glmmTMB."

Can you describe what search strategy you used and how the documents that did show up failed to meet your needs?

There appears to be a truncated Poisson "hurdle model" in the examples for the main regression function and discussion of fitting issues at the end of the vignette: https://cran.r-project.org/web/packages/glmmTMB/vignettes/glmmTMB.pdf

It's always possible that I misunderstood the issues here, but that does throw the responsibility back on you to do a better job of explaining your difficulties. Also, this is not really the right forum to post questions about mixed models. There's a SIG for that. 


> I would like to fit a zero-truncated poisson, what do I need to specify in "family = " for this distribution? 
> 
> Thanks! Alice 
> 
> 	[[alternative HTML version deleted]]

Please read the Posting Guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Thu Jun 15 23:57:26 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 16 Jun 2017 07:57:26 +1000
Subject: [R] Changing font of a certrain column in an excel file
In-Reply-To: <CAP0cSCS-pxLyD2We_Y3KphbZzKA_FSjYffii7vvueaCT_+tZgA@mail.gmail.com>
References: <CAP0cSCS-pxLyD2We_Y3KphbZzKA_FSjYffii7vvueaCT_+tZgA@mail.gmail.com>
Message-ID: <CA+8X3fVrjF8RQwdYkx0n6CRk-Bij_226DO7_X6NKBZXM0x2xTg@mail.gmail.com>

Hi Persian,
While this is not a forum for Excel:

Right click on the alphabetic label at the top of the column
Select "Format Cells"
Select the "Font" tab
Pick your font

I will leave it to others to deliver sermons about the moral dangers
of using Excel.

Jim

On Thu, Jun 15, 2017 at 10:33 PM, Persian Irani
<english.server at gmail.com> wrote:
> Hi all!
> I need an example/reference to show me how to change the font of a
> certain column in an existing .xlsx  document. Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Jun 16 00:46:36 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 15 Jun 2017 15:46:36 -0700
Subject: [R] "reverse" quantile function
In-Reply-To: <561667961.10655178.1497555441927@mail.yahoo.com>
References: <561667961.10655178.1497555441927.ref@mail.yahoo.com>
 <561667961.10655178.1497555441927@mail.yahoo.com>
Message-ID: <EE55693D-BB30-4E58-A426-81F5A6E14B39@comcast.net>


> On Jun 15, 2017, at 12:37 PM, Andras Farkas via R-help <r-help at r-project.org> wrote:
> 
> Dear All,
> 
> we have:
> 
> t<-seq(0,24,1) 
> a<-10*exp(-0.05*t) 
> b<-10*exp(-0.07*t) 
> c<-10*exp(-0.1*t) 
> d<-10*exp(-0.03*t) 
> z<-data.frame(a,b,c,d) 
> 
> res<-t(apply(z, 1, quantile, probs=c(0.3))) 
> 
> 
> 
> my goal is to do a 'reverse" of the function here that produces "res" on a data frame, ie: to get the answer 0.3 back for the percentile location when I have "res" available to me... For a single vector this would be done using ecdf something like this:
> 
> x <- rnorm(100) 
> #then I know this value:  
> quantile(x,0.33) 
> #so do this step
> ecdf(x)(quantile(x,0.33)) 
> #to get 0.33 back...
> 
> any suggestions on how I could to that for a data frame?

Can't you just used ecdf and quantile ecdf?

# See ?ecdf page for both functions

> lapply( lapply(z, ecdf), quantile, 0.33)
$a
     33% 
4.475758 

$b
     33% 
3.245151 

$c
     33% 
2.003595 

$d
     33% 
6.173204 
-- 

David Winsemius
Alameda, CA, USA


From motyocska at yahoo.com  Fri Jun 16 01:56:28 2017
From: motyocska at yahoo.com (Andras Farkas)
Date: Thu, 15 Jun 2017 23:56:28 +0000 (UTC)
Subject: [R] "reverse" quantile function
In-Reply-To: <EE55693D-BB30-4E58-A426-81F5A6E14B39@comcast.net>
References: <561667961.10655178.1497555441927.ref@mail.yahoo.com>
 <561667961.10655178.1497555441927@mail.yahoo.com>
 <EE55693D-BB30-4E58-A426-81F5A6E14B39@comcast.net>
Message-ID: <771272843.5615337.1497570988364@mail.yahoo.com>

David,

thanks for the response. In your response the quantile function (if I see correctly)  runs on the columns versus I need to run it on the rows, which is an easy fix, but that is not exactly what I had in mind... essentially we can remove t() from my original code to make "res" look like this:

 res<-apply(z, 1, quantile, probs=c(0.3))

but after all maybe I did not explain myself clear enough so let me try again: the known variables to us in what I am trying to do are the data frame "z' :

 t<-seq(0,24,1) 
 a<-10*exp(-0.05*t) 
 b<-10*exp(-0.07*t) 
 c<-10*exp(-0.1*t) 
d<-10*exp(-0.03*t) 

z<-data.frame(a,b,c,d)

and the vector "res":

res<-c(10.000000,  9.296382,  8.642955,  8.036076 ,7.472374,  6.948723,  6.462233,  6.010223 ,5.590211 

,5.199896 ,4.837147,  4.499989 ,4.186589,  3.895250 ,3.624397,  3.372570,  3.138415,  2.920675 
, 2.718185 ,2.529864 ,2.354708,  2.191786,  2.040233,  1.899247,  1.768084)

and I need to find the probability (probs) , the unknown value, which would result in creating "res", ie: the probs=c(0.3), from: 
res<-apply(z, 1, quantile, probs=c(0.3))... 


a more simplified example assuming :

k<-c(1:100)
f<-30
ecdf(k)(f)

would give us the value of 0.3... so same idea as this, but instead of "k" we have data frame "z", and instead of "f" we have "res", and need to find the value of 0.3... Does that make sense?

much appreciate the help...
  
Andras Farkas, 


On Thursday, June 15, 2017 6:46 PM, David Winsemius <dwinsemius at comcast.net> wrote:




> On Jun 15, 2017, at 12:37 PM, Andras Farkas via R-help <r-help at r-project.org> wrote:
> 
> Dear All,
> 
> we have:
> 
> t<-seq(0,24,1) 
> a<-10*exp(-0.05*t) 
> b<-10*exp(-0.07*t) 
> c<-10*exp(-0.1*t) 
> d<-10*exp(-0.03*t) 
> z<-data.frame(a,b,c,d) 
> 
> res<-t(apply(z, 1, quantile, probs=c(0.3))) 
> 
> 
> 
> my goal is to do a 'reverse" of the function here that produces "res" on a data frame, ie: to get the answer 0.3 back for the percentile location when I have "res" available to me... For a single vector this would be done using ecdf something like this:
> 
> x <- rnorm(100) 
> #then I know this value:  
> quantile(x,0.33) 
> #so do this step
> ecdf(x)(quantile(x,0.33)) 
> #to get 0.33 back...
> 
> any suggestions on how I could to that for a data frame?

Can't you just used ecdf and quantile ecdf?

# See ?ecdf page for both functions

> lapply( lapply(z, ecdf), quantile, 0.33)
$a
     33% 
4.475758 

$b
     33% 
3.245151 

$c
     33% 
2.003595 


$d
     33% 
6.173204 
-- 

David Winsemius
Alameda, CA, USA


From dmck at u.washington.edu  Thu Jun 15 21:51:15 2017
From: dmck at u.washington.edu (Don McKenzie)
Date: Thu, 15 Jun 2017 12:51:15 -0700
Subject: [R] about fitting a regression line
In-Reply-To: <CAN5afy9Quwt66UVjz+uML7gSf=vDye1rki+W8YJzR8R9KrGg8Q@mail.gmail.com>
References: <CAN5afy9ZbzERR+vNrhn4-SaO+xi1OvSvxkb7OqApuwSfAmtB+g@mail.gmail.com>
 <8FBED4BA-0E82-4F78-8623-EB272EE45800@llnl.gov>
 <CAN5afy-yDY5+gF2SrWT=RMkxMcTViN7q7n-R5p+B5U8EXqSiSQ@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A7A4F@SRVEXCHCM301.precheza.cz>
 <CAN5afy9Quwt66UVjz+uML7gSf=vDye1rki+W8YJzR8R9KrGg8Q@mail.gmail.com>
Message-ID: <5ABB77E7-36F2-4E0B-886B-F4DBEDEA197D@u.washington.edu>

Did you perhaps accidentally include your response as a predictor?

> On Jun 15, 2017, at 12:48 PM, lily li <chocold12 at gmail.com> wrote:
> 
> Thanks for your replies. I tried the regression, but then got a NA value
> for the slope. And here is the error message:
> Coefficients: (1 not defined because of singularities)
> 
> 
> On Thu, Jun 15, 2017 at 12:20 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
>> Hi
>> 
>> But X can be some function like - sin, cos, log, exp...
>> 
>> Cheers
>> Petr
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
>>> Sent: Thursday, June 15, 2017 1:28 AM
>>> To: MacQueen, Don <macqueen1 at llnl.gov>
>>> Cc: R mailing list <r-help at r-project.org>
>>> Subject: Re: [R] about fitting a regression line
>>> 
>>> Thanks. I thought lm() function is for linear model, such as the
>> correlation
>>> below:
>>> Y= aX + b
>>> 
>>> On Wed, Jun 14, 2017 at 5:25 PM, MacQueen, Don <macqueen1 at llnl.gov>
>>> wrote:
>>> 
>>>> Start with the lm() function; i.e., see
>>>> 
>>>>  ?lm
>>>> 
>>>> -Don
>>>> 
>>>> --
>>>> Don MacQueen
>>>> 
>>>> Lawrence Livermore National Laboratory
>>>> 7000 East Ave., L-627
>>>> Livermore, CA 94550
>>>> 925-423-1062
>>>> 
>>>> 
>>>> On 6/14/17, 3:40 PM, "R-help on behalf of lily li" <
>>>> r-help-bounces at r-project.org on behalf of chocold12 at gmail.com> wrote:
>>>> 
>>>>    Hi R users,
>>>> 
>>>>    I have some data points (Xi, Yi), and they may follow such a
>>>> pattern Yi =
>>>>    cCOS(Xi) + d, how to find the c and d in R? which function to use?
>>>> Also,
>>>>    how to get the R2 and p value for this correlation? Thanks for any
>>>> kind of
>>>>    help.
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>>    ______________________________________________
>>>>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>>>    PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>>    and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>>> 
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>> 
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> 
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>> 
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




From o_bouldjedri at hotmail.fr  Fri Jun 16 00:05:39 2017
From: o_bouldjedri at hotmail.fr (oussama bouldjedri)
Date: Thu, 15 Jun 2017 22:05:39 +0000
Subject: [R] (no subject)
Message-ID: <AMSPR05MB482C312E20128496F054EB58AC00@AMSPR05MB482.eurprd05.prod.outlook.com>

Hi every one I am working on shiny app using bnlearn for Bayesian networks and using r studio I get a fatal error and when I use R GUI I get this error

** caught segfault ***

address 0xfffffffc0fcd6248, cause 'memory not mapped' Traceback: 1:
.Call("mappred", node = node, fitted = fitted, data = data, n =
as.integer(n), from = from, prob = prob, debug = debug) 2:
map.prediction(node = node, fitted = object, data = data, n =
extra.args$n, from = extra.args$from, prob = prob, debug = debug) 3:
predict.bn.fit(values10$fitted, input$targetvariables, combn2, prob =
TRUE, method = "bayes-lw") 4: predict(values10$fitted,
input$targetvariables, combn2, prob = TRUE, method = "bayes-lw") 5:
t(attr(predict(values10$fitted, input$targetvariables, combn2, prob =
TRUE, method = "bayes-lw"), "prob")) 6: observeEventHandler(...) 7:
..stacktraceon..(observeEventHandler(...)) 8: handlerFunc() 9:
..stacktraceon..(expr) 10: contextFunc() 11: env$runWith(self, func)
12: withReactiveDomain(.domain, { env <- .getReactiveEnvironment()
.graphEnterContext(id) on.exit(.graphExitContext(id), add = TRUE)
env$runWith(self, func)}). ......


I tried to get the latest version of R and rstudio but it still happens

is it my computer memory that is small ?? or something else

thanks in advance



best regards

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 16 03:10:59 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 15 Jun 2017 18:10:59 -0700
Subject: [R] (no subject)
In-Reply-To: <AMSPR05MB482C312E20128496F054EB58AC00@AMSPR05MB482.eurprd05.prod.outlook.com>
References: <AMSPR05MB482C312E20128496F054EB58AC00@AMSPR05MB482.eurprd05.prod.outlook.com>
Message-ID: <055E795B-BE7D-4C2F-A7F1-8E63543A6894@comcast.net>


> On Jun 15, 2017, at 3:05 PM, oussama bouldjedri <o_bouldjedri at hotmail.fr> wrote:
> 
> Hi every one I am working on shiny app using bnlearn for Bayesian networks and using r studio I get a fatal error and when I use R GUI I get this error
> 
> ** caught segfault ***
> 
> address 0xfffffffc0fcd6248, cause 'memory not mapped' Traceback: 1:
> .Call("mappred", node = node, fitted = fitted, data = data, n =
> as.integer(n), from = from, prob = prob, debug = debug) 2:
> map.prediction(node = node, fitted = object, data = data, n =
> extra.args$n, from = extra.args$from, prob = prob, debug = debug) 3:
> predict.bn.fit(values10$fitted, input$targetvariables, combn2, prob =
> TRUE, method = "bayes-lw") 4: predict(values10$fitted,
> input$targetvariables, combn2, prob = TRUE, method = "bayes-lw") 5:
> t(attr(predict(values10$fitted, input$targetvariables, combn2, prob =
> TRUE, method = "bayes-lw"), "prob")) 6: observeEventHandler(...) 7:
> ..stacktraceon..(observeEventHandler(...)) 8: handlerFunc() 9:
> ..stacktraceon..(expr) 10: contextFunc() 11: env$runWith(self, func)
> 12: withReactiveDomain(.domain, { env <- .getReactiveEnvironment()
> .graphEnterContext(id) on.exit(.graphExitContext(id), add = TRUE)
> env$runWith(self, func)}). ......
> 
> 
> I tried to get the latest version of R and rstudio but it still happens
> 
> is it my computer memory that is small ?? or something else

As I already told you on SO, you should send a reproducible example to the maintainer.

> 
> thanks in advance
> 
> 
> 
> best regards
> 
> 	[[alternative HTML version deleted]]

I did not suggest cross-posting to Rhelp, but if you are going to do so in the future, could you please read the posting guide and set up your email client to post in plain text?

(I doubt this error is due to RStudio or R. Shiny ... perhaps. "bnlearn" ... most probably.)

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sunnysingha.analytics at gmail.com  Fri Jun 16 05:53:53 2017
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Fri, 16 Jun 2017 09:23:53 +0530
Subject: [R] Generate correlated expontial distribution -- lamda please guide
Message-ID: <15FF0155-9B3D-4063-A068-1C706D944A98@gmail.com>

Hi,
I need to generate correlated (positive as well as negative) bivariate exponential distribution with rate of 1/5 or any rate
I need some guidance here. Please help. 

Regards,
Sunny

From sunnysingha.analytics at gmail.com  Fri Jun 16 07:18:50 2017
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Fri, 16 Jun 2017 10:48:50 +0530
Subject: [R] Help to simulate data to model pump failure use case
Message-ID: <CANOG_FWurcrSBs8F6C1RbkOOLgjM-z4vSHPSFg-OX7nvdPiNgA@mail.gmail.com>

Hi,
I need help to simulate data to model pump's failure. Below is thought
process to simulate the data:
- For each Pump readings are captured via sensors each minute for period of
3 months. There are 10 pumps in total.
- The failure rate or occurrences of event in 3 months for each Pump is
defined. i.e Pump1 would fail 3 times in 3 months, Pump2 would fail 2 times
in 3 months, etc.
- The failure modes are defined based on the combination of below variables:
   Failure modes::
   -- Bearing damage --> +ve_corr('temprature' + vibration)
   -- Cavitation --> -ve_corr( +ve_corr(discharge_pressure + flow) +
temprature)
   -- worn shafts --> +ve_corr(discharge_pressure + flow)

How should I be generate distributions for the variables listed in the
"failure modes" maintaining the correlation stated above.

Regards,
Sunny

	[[alternative HTML version deleted]]


From sunnysingha.analytics at gmail.com  Fri Jun 16 07:18:50 2017
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Fri, 16 Jun 2017 10:48:50 +0530
Subject: [R] Help to simulate data to model pump failure use case
Message-ID: <CANOG_FWurcrSBs8F6C1RbkOOLgjM-z4vSHPSFg-OX7nvdPiNgA@mail.gmail.com>

Hi,
I need help to simulate data to model pump's failure. Below is thought
process to simulate the data:
- For each Pump readings are captured via sensors each minute for period of
3 months. There are 10 pumps in total.
- The failure rate or occurrences of event in 3 months for each Pump is
defined. i.e Pump1 would fail 3 times in 3 months, Pump2 would fail 2 times
in 3 months, etc.
- The failure modes are defined based on the combination of below variables:
   Failure modes::
   -- Bearing damage --> +ve_corr('temprature' + vibration)
   -- Cavitation --> -ve_corr( +ve_corr(discharge_pressure + flow) +
temprature)
   -- worn shafts --> +ve_corr(discharge_pressure + flow)

How should I be generate distributions for the variables listed in the
"failure modes" maintaining the correlation stated above.

Regards,
Sunny

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Jun 16 10:58:10 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 16 Jun 2017 10:58:10 +0200
Subject: [R] "reverse" quantile function
In-Reply-To: <771272843.5615337.1497570988364@mail.yahoo.com>
References: <561667961.10655178.1497555441927.ref@mail.yahoo.com>
 <561667961.10655178.1497555441927@mail.yahoo.com>
 <EE55693D-BB30-4E58-A426-81F5A6E14B39@comcast.net>
 <771272843.5615337.1497570988364@mail.yahoo.com>
Message-ID: <250A0284-43AA-41D7-80CF-A6C6CC0469EF@gmail.com>

It would depend on which one of the 9 quantile definitions you are using. The discontinuous ones aren't invertible, and the continuous ones won't be either, if there are ties in the data. 

This said, it should just be a matter of setting up the inverse of a piecewise linear function. To set ideas, try 

x <- rnorm(5)
curve(quantile(x,p), xname="p")

The breakpoints for the default quantiles are n points evenly spread on [0,1], including the endpoints; i.e., for n=5, (0, .25, .5, .75, 1) 

So:

x <- rnorm(5)
br <- seq(0, 1, ,5)
qq <- quantile(x, br) ## actually == sort(x)

pfun <- approxfun(qq, br)
(q <- quantile(x, .1234))
pfun(q)


There are variations, e.g. the one-liner

approx(sort(x), seq(0,1,,length(x)), q)$y

-pd


> On 16 Jun 2017, at 01:56 , Andras Farkas via R-help <r-help at r-project.org> wrote:
> 
> David,
> 
> thanks for the response. In your response the quantile function (if I see correctly)  runs on the columns versus I need to run it on the rows, which is an easy fix, but that is not exactly what I had in mind... essentially we can remove t() from my original code to make "res" look like this:
> 
> res<-apply(z, 1, quantile, probs=c(0.3))
> 
> but after all maybe I did not explain myself clear enough so let me try again: the known variables to us in what I am trying to do are the data frame "z' :
> 
> t<-seq(0,24,1) 
> a<-10*exp(-0.05*t) 
> b<-10*exp(-0.07*t) 
> c<-10*exp(-0.1*t) 
> d<-10*exp(-0.03*t) 
> 
> z<-data.frame(a,b,c,d)
> 
> and the vector "res":
> 
> res<-c(10.000000,  9.296382,  8.642955,  8.036076 ,7.472374,  6.948723,  6.462233,  6.010223 ,5.590211 
> 
> ,5.199896 ,4.837147,  4.499989 ,4.186589,  3.895250 ,3.624397,  3.372570,  3.138415,  2.920675 
> , 2.718185 ,2.529864 ,2.354708,  2.191786,  2.040233,  1.899247,  1.768084)
> 
> and I need to find the probability (probs) , the unknown value, which would result in creating "res", ie: the probs=c(0.3), from: 
> res<-apply(z, 1, quantile, probs=c(0.3))... 
> 
> 
> a more simplified example assuming :
> 
> k<-c(1:100)
> f<-30
> ecdf(k)(f)
> 
> would give us the value of 0.3... so same idea as this, but instead of "k" we have data frame "z", and instead of "f" we have "res", and need to find the value of 0.3... Does that make sense?
> 
> much appreciate the help...
> 
> Andras Farkas, 
> 
> 
> On Thursday, June 15, 2017 6:46 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> 
> 
>> On Jun 15, 2017, at 12:37 PM, Andras Farkas via R-help <r-help at r-project.org> wrote:
>> 
>> Dear All,
>> 
>> we have:
>> 
>> t<-seq(0,24,1) 
>> a<-10*exp(-0.05*t) 
>> b<-10*exp(-0.07*t) 
>> c<-10*exp(-0.1*t) 
>> d<-10*exp(-0.03*t) 
>> z<-data.frame(a,b,c,d) 
>> 
>> res<-t(apply(z, 1, quantile, probs=c(0.3))) 
>> 
>> 
>> 
>> my goal is to do a 'reverse" of the function here that produces "res" on a data frame, ie: to get the answer 0.3 back for the percentile location when I have "res" available to me... For a single vector this would be done using ecdf something like this:
>> 
>> x <- rnorm(100) 
>> #then I know this value:  
>> quantile(x,0.33) 
>> #so do this step
>> ecdf(x)(quantile(x,0.33)) 
>> #to get 0.33 back...
>> 
>> any suggestions on how I could to that for a data frame?
> 
> Can't you just used ecdf and quantile ecdf?
> 
> # See ?ecdf page for both functions
> 
>> lapply( lapply(z, ecdf), quantile, 0.33)
> $a
>     33% 
> 4.475758 
> 
> $b
>     33% 
> 3.245151 
> 
> $c
>     33% 
> 2.003595 
> 
> 
> $d
>     33% 
> 6.173204 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From motyocska at yahoo.com  Fri Jun 16 11:33:49 2017
From: motyocska at yahoo.com (Andras Farkas)
Date: Fri, 16 Jun 2017 09:33:49 +0000 (UTC)
Subject: [R] "reverse" quantile function
In-Reply-To: <409056102.11187850.1497605386895@mail.yahoo.com>
References: <561667961.10655178.1497555441927.ref@mail.yahoo.com>
 <561667961.10655178.1497555441927@mail.yahoo.com>
 <EE55693D-BB30-4E58-A426-81F5A6E14B39@comcast.net>
 <771272843.5615337.1497570988364@mail.yahoo.com>
 <250A0284-43AA-41D7-80CF-A6C6CC0469EF@gmail.com>
 <409056102.11187850.1497605386895@mail.yahoo.com>
Message-ID: <853049125.11118109.1497605629803@mail.yahoo.com>


Peter, 

thanks, very nice, this will work for me... could you also help with setting up the code to run the on liner "approx(sort(x), seq(0,1,,length(x)), q)$y" on the rows of a data frame using my example above? So if I cbind z and res, 

df<-cbind(z,res) 

the "x" in your one liner would be the first 4 column values of each row and "q" is the last (5fth) column value of each row.. 

thanks again for all the help, 

Andras Farkas


From motyocska at yahoo.com  Fri Jun 16 14:24:33 2017
From: motyocska at yahoo.com (Andras Farkas)
Date: Fri, 16 Jun 2017 12:24:33 +0000 (UTC)
Subject: [R] "reverse" quantile function
In-Reply-To: <853049125.11118109.1497605629803@mail.yahoo.com>
References: <561667961.10655178.1497555441927.ref@mail.yahoo.com>
 <561667961.10655178.1497555441927@mail.yahoo.com>
 <EE55693D-BB30-4E58-A426-81F5A6E14B39@comcast.net>
 <771272843.5615337.1497570988364@mail.yahoo.com>
 <250A0284-43AA-41D7-80CF-A6C6CC0469EF@gmail.com>
 <409056102.11187850.1497605386895@mail.yahoo.com>
 <853049125.11118109.1497605629803@mail.yahoo.com>
Message-ID: <1203910306.5981284.1497615873090@mail.yahoo.com>

Never mind, I think i figured:

z<-df

apply(df,1,function(x) approx(sort(x[1:4]), seq(0,1,,length(x[1:4])), x[5])$y) 
thanks again for the help
 
Andras Farkas, 


On Friday, June 16, 2017 5:34 AM, Andras Farkas via R-help <r-help at r-project.org> wrote:




Peter, 

thanks, very nice, this will work for me... could you also help with setting up the code to run the on liner "approx(sort(x), seq(0,1,,length(x)), q)$y" on the rows of a data frame using my example above? So if I cbind z and res, 

df<-cbind(z,res) 

the "x" in your one liner would be the first 4 column values of each row and "q" is the last (5fth) column value of each row.. 

thanks again for all the help, 

Andras Farkas

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From motyocska at yahoo.com  Fri Jun 16 11:29:46 2017
From: motyocska at yahoo.com (Andras Farkas)
Date: Fri, 16 Jun 2017 09:29:46 +0000 (UTC)
Subject: [R] "reverse" quantile function
In-Reply-To: <250A0284-43AA-41D7-80CF-A6C6CC0469EF@gmail.com>
References: <561667961.10655178.1497555441927.ref@mail.yahoo.com>
 <561667961.10655178.1497555441927@mail.yahoo.com>
 <EE55693D-BB30-4E58-A426-81F5A6E14B39@comcast.net>
 <771272843.5615337.1497570988364@mail.yahoo.com>
 <250A0284-43AA-41D7-80CF-A6C6CC0469EF@gmail.com>
Message-ID: <409056102.11187850.1497605386895@mail.yahoo.com>

Peter,
thanks, very nice, this will work for me... could you also help with setting up the code to run the on liner "approx(sort(x), seq(0,1,,length(x)), q)$y" on the rows of a data frame using my example above? So if I cbind z and res,?
df<-cbind(z,res)

the "x" in your one liner would be the first 4 column values of each row and "q" is the last (5fth) column value of each row..
thanks again for all the help,?Andras Farkas 

    On Friday, June 16, 2017 4:58 AM, peter dalgaard <pdalgd at gmail.com> wrote:
 

 It would depend on which one of the 9 quantile definitions you are using. The discontinuous ones aren't invertible, and the continuous ones won't be either, if there are ties in the data. 

This said, it should just be a matter of setting up the inverse of a piecewise linear function. To set ideas, try 

x <- rnorm(5)
curve(quantile(x,p), xname="p")

The breakpoints for the default quantiles are n points evenly spread on [0,1], including the endpoints; i.e., for n=5, (0, .25, .5, .75, 1) 

So:

x <- rnorm(5)
br <- seq(0, 1, ,5)
qq <- quantile(x, br) ## actually == sort(x)

pfun <- approxfun(qq, br)
(q <- quantile(x, .1234))
pfun(q)


There are variations, e.g. the one-liner

approx(sort(x), seq(0,1,,length(x)), q)$y

-pd


> On 16 Jun 2017, at 01:56 , Andras Farkas via R-help <r-help at r-project.org> wrote:
> 
> David,
> 
> thanks for the response. In your response the quantile function (if I see correctly)? runs on the columns versus I need to run it on the rows, which is an easy fix, but that is not exactly what I had in mind... essentially we can remove t() from my original code to make "res" look like this:
> 
> res<-apply(z, 1, quantile, probs=c(0.3))
> 
> but after all maybe I did not explain myself clear enough so let me try again: the known variables to us in what I am trying to do are the data frame "z' :
> 
> t<-seq(0,24,1) 
> a<-10*exp(-0.05*t) 
> b<-10*exp(-0.07*t) 
> c<-10*exp(-0.1*t) 
> d<-10*exp(-0.03*t) 
> 
> z<-data.frame(a,b,c,d)
> 
> and the vector "res":
> 
> res<-c(10.000000,? 9.296382,? 8.642955,? 8.036076 ,7.472374,? 6.948723,? 6.462233,? 6.010223 ,5.590211 
> 
> ,5.199896 ,4.837147,? 4.499989 ,4.186589,? 3.895250 ,3.624397,? 3.372570,? 3.138415,? 2.920675 
> , 2.718185 ,2.529864 ,2.354708,? 2.191786,? 2.040233,? 1.899247,? 1.768084)
> 
> and I need to find the probability (probs) , the unknown value, which would result in creating "res", ie: the probs=c(0.3), from: 
> res<-apply(z, 1, quantile, probs=c(0.3))... 
> 
> 
> a more simplified example assuming :
> 
> k<-c(1:100)
> f<-30
> ecdf(k)(f)
> 
> would give us the value of 0.3... so same idea as this, but instead of "k" we have data frame "z", and instead of "f" we have "res", and need to find the value of 0.3... Does that make sense?
> 
> much appreciate the help...
> 
> Andras Farkas, 
> 
> 
> On Thursday, June 15, 2017 6:46 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> 
> 
>> On Jun 15, 2017, at 12:37 PM, Andras Farkas via R-help <r-help at r-project.org> wrote:
>> 
>> Dear All,
>> 
>> we have:
>> 
>> t<-seq(0,24,1) 
>> a<-10*exp(-0.05*t) 
>> b<-10*exp(-0.07*t) 
>> c<-10*exp(-0.1*t) 
>> d<-10*exp(-0.03*t) 
>> z<-data.frame(a,b,c,d) 
>> 
>> res<-t(apply(z, 1, quantile, probs=c(0.3))) 
>> 
>> 
>> 
>> my goal is to do a 'reverse" of the function here that produces "res" on a data frame, ie: to get the answer 0.3 back for the percentile location when I have "res" available to me... For a single vector this would be done using ecdf something like this:
>> 
>> x <- rnorm(100) 
>> #then I know this value:? 
>> quantile(x,0.33) 
>> #so do this step
>> ecdf(x)(quantile(x,0.33)) 
>> #to get 0.33 back...
>> 
>> any suggestions on how I could to that for a data frame?
> 
> Can't you just used ecdf and quantile ecdf?
> 
> # See ?ecdf page for both functions
> 
>> lapply( lapply(z, ecdf), quantile, 0.33)
> $a
>? ? 33% 
> 4.475758 
> 
> $b
>? ? 33% 
> 3.245151 
> 
> $c
>? ? 33% 
> 2.003595 
> 
> 
> $d
>? ? 33% 
> 6.173204 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com










   
	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Fri Jun 16 15:54:56 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Fri, 16 Jun 2017 15:54:56 +0200
Subject: [R] Changing Color of Selected Column Names in Corrplot
Message-ID: <20170616135456.GB8807@chicca2>

Dear All,
Please consider the following example


library(corrplot)
M <- cor(mtcars)
corrplot(M, method="circle", type="lower", diag=F)


Suppose that I want to have the label "mpg" at the top in black
and leave everything else in red.
How can I achieve that?
Cheers

Lorenzo


From mak.hholly at gmail.com  Fri Jun 16 16:33:20 2017
From: mak.hholly at gmail.com (greg holly)
Date: Fri, 16 Jun 2017 10:33:20 -0400
Subject: [R] point size
Message-ID: <CAM9Qe4i6K3sHHg7XXcwLSc0aYosEjjkGOAdU3qq=1JO4mtRrTA@mail.gmail.com>

Hi all;

I am running the following ggplot codes. Runs well. However, I need to
reflect the numeric values of the log10_P to the point size in the graph.

Your help highly appreciated,

Regards,
Greg


p <- ggplot(mydata,  aes(x = X,  y = log10_P)) +
  theme_bw() +theme(panel.border=element_blank())
  + theme(legend.position="top",  axis.text=element_text(size = 8))
  (p1 <- p + geom_point(aes(color = Traits)

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Jun 16 18:08:34 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 16 Jun 2017 16:08:34 +0000
Subject: [R] Changing Color of Selected Column Names in Corrplot
In-Reply-To: <20170616135456.GB8807@chicca2>
References: <20170616135456.GB8807@chicca2>
Message-ID: <d35f8801f95d4ebbb17453f24f86efb0@exch-2p-mbx-w2.ads.tamu.edu>

Hopefully someone has a cleaner approach, but this will work. You have to remove the first column/row labels and print with text():

library(corrplot)
M <- cor(mtcars)
colnames(M)[1] <- ""
rownames(M)[1] <- ""
corrplot(M, method="circle", type="lower", diag=F)
text(1, dim(M)[1] - .1, "mpg", srt=90, xpd=TRUE)

# Replace first row/colnames if you will be using M later
colnames(M)[1] <- "mpg"
rownames(M)[1] <- "mpg"

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Lorenzo Isella
Sent: Friday, June 16, 2017 8:55 AM
To: r-help at r-project.org
Subject: [R] Changing Color of Selected Column Names in Corrplot

Dear All,
Please consider the following example


library(corrplot)
M <- cor(mtcars)
corrplot(M, method="circle", type="lower", diag=F)


Suppose that I want to have the label "mpg" at the top in black
and leave everything else in red.
How can I achieve that?
Cheers

Lorenzo

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Fri Jun 16 18:56:21 2017
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 16 Jun 2017 11:56:21 -0500
Subject: [R] point size
In-Reply-To: <CAM9Qe4i6K3sHHg7XXcwLSc0aYosEjjkGOAdU3qq=1JO4mtRrTA@mail.gmail.com>
References: <CAM9Qe4i6K3sHHg7XXcwLSc0aYosEjjkGOAdU3qq=1JO4mtRrTA@mail.gmail.com>
Message-ID: <CAN5YmCGu07VcpxBfwymbbCvAuP-xHC1T2Xm-gz-XzNUyCB1ohA@mail.gmail.com>

You could add size = log10_P to the aes() inside geom_point().
Untested code below.
See also http://ggplot2.tidyverse.org/reference/geom_point.html

ggplot(mydata,  aes(x = X,  y = log10_P)) +
  theme_bw() +
  theme(panel.border=element_blank(), legend.position="top",
 axis.text=element_text(size = 8)) +
  geom_point(aes(color = Traits, size = log10_P))

Jean

On Fri, Jun 16, 2017 at 9:33 AM, greg holly <mak.hholly at gmail.com> wrote:

> Hi all;
>
> I am running the following ggplot codes. Runs well. However, I need to
> reflect the numeric values of the log10_P to the point size in the graph.
>
> Your help highly appreciated,
>
> Regards,
> Greg
>
>
> p <- ggplot(mydata,  aes(x = X,  y = log10_P)) +
>   theme_bw() +theme(panel.border=element_blank())
>   + theme(legend.position="top",  axis.text=element_text(size = 8))
>   (p1 <- p + geom_point(aes(color = Traits)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Fri Jun 16 20:34:00 2017
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 16 Jun 2017 13:34:00 -0500
Subject: [R] ASA Conference on Statistical Practice - deadline Thursday
Message-ID: <CAN5YmCFYkMW=pGxWFKvuAm7Zga68jqRZT73CxMUPObYPg29LrA@mail.gmail.com>

R Users,

Abstracts are now being accepted for the
     ASA Conference on Statistical Practice
     February 15-17, 2017
     Portland, Oregon USA

The deadline for submission is Thursday June 22.  Presentations will be 35
minutes long and fall into four broad themes:
     Communication, Collaboration, and Career Development
     Data Modeling and Analysis
     Data Science and Big Data
     Software, Programming, and Data Visualization

Abstracts may be submitted at
    https://www.amstat.org/meetings/csp/2018/submitanabstract.cfm

Thank you.

Jean V. Adams
on behalf of the ASA-CSP 2018 Steering Committee


`?.,,  ><(((?>   `?.,,  ><(((?>   `?.,,  ><(((?>

Jean V. Adams
Statistician
U.S. Geological Survey
Great Lakes Science Center
223 East Steinfest Road
Antigo, WI 54409  USA
715-627-4317, ext. 3125  (Office)
715-216-8014  (Cell)
http://www.glsc.usgs.gov
https://www.usgs.gov/staff-profiles/jean-v-adams

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Fri Jun 16 21:52:55 2017
From: mak.hholly at gmail.com (greg holly)
Date: Fri, 16 Jun 2017 15:52:55 -0400
Subject: [R] point size
In-Reply-To: <CAN5YmCGu07VcpxBfwymbbCvAuP-xHC1T2Xm-gz-XzNUyCB1ohA@mail.gmail.com>
References: <CAM9Qe4i6K3sHHg7XXcwLSc0aYosEjjkGOAdU3qq=1JO4mtRrTA@mail.gmail.com>
 <CAN5YmCGu07VcpxBfwymbbCvAuP-xHC1T2Xm-gz-XzNUyCB1ohA@mail.gmail.com>
Message-ID: <CAM9Qe4g4PsV3=B4UOR=rF946Q++n=TZX01pi_rEc_skZuw-h1g@mail.gmail.com>

Perfect. Thanks so much Adams. It is much appreciated.

Greg

On Fri, Jun 16, 2017 at 12:56 PM, Adams, Jean <jvadams at usgs.gov> wrote:

> You could add size = log10_P to the aes() inside geom_point().
> Untested code below.
> See also http://ggplot2.tidyverse.org/reference/geom_point.html
>
> ggplot(mydata,  aes(x = X,  y = log10_P)) +
>   theme_bw() +
>   theme(panel.border=element_blank(), legend.position="top",
>  axis.text=element_text(size = 8)) +
>   geom_point(aes(color = Traits, size = log10_P))
>
> Jean
>
> On Fri, Jun 16, 2017 at 9:33 AM, greg holly <mak.hholly at gmail.com> wrote:
>
>> Hi all;
>>
>> I am running the following ggplot codes. Runs well. However, I need to
>> reflect the numeric values of the log10_P to the point size in the graph.
>>
>> Your help highly appreciated,
>>
>> Regards,
>> Greg
>>
>>
>> p <- ggplot(mydata,  aes(x = X,  y = log10_P)) +
>>   theme_bw() +theme(panel.border=element_blank())
>>   + theme(legend.position="top",  axis.text=element_text(size = 8))
>>   (p1 <- p + geom_point(aes(color = Traits)
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Jun 17 00:59:08 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 17 Jun 2017 10:59:08 +1200
Subject: [R] [FORGED] Generate correlated expontial distribution --
 lamda please guide
In-Reply-To: <15FF0155-9B3D-4063-A068-1C706D944A98@gmail.com>
References: <15FF0155-9B3D-4063-A068-1C706D944A98@gmail.com>
Message-ID: <a101979d-8fe0-104d-3f74-7d2f9c5f20a7@auckland.ac.nz>

On 16/06/17 15:53, Sunny Singha wrote:
> Hi,
> I need to generate correlated (positive as well as negative) bivariate exponential
> distribution with rate of 1/5 or any rate.
> I need some guidance here. Please help.

I believe this question is ill-posed.

(1) My understanding is that there is no "bivariate exponential" 
distribution, or rather that there are many possible definitions. 
(Others, younger and wiser, may correct me or elaborate on this.)

(2) If your requirement is simply to obtain a bivariate distribution 
with exponential marginals and a given correlation between the 
variables, I believe there are a variety of ways.  One way might be to 
use copulas.  Another might be to use "coupling" (see Muirhead, "Aspects 
of Multivariate Statistical Theory", Wiley, p. 43, Ex. 1.7).

Some googling (why didn't you do that?) led me to

> http://r.789695.n4.nabble.com/How-to-generate-bivariate-exponential-distribution-td3596944.html

in which Petr Savicky gives a simple construction.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From tr206 at kent.ac.uk  Sat Jun 17 12:26:14 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sat, 17 Jun 2017 10:26:14 +0000
Subject: [R] Using mfx to create marginal effects
Message-ID: <1497695288709.62755@kent.ac.uk>

Dear all,



I am trying to estimate the marginal effects of a logit regression using the mfx package. It is crucial that the standard errors are clustered at the year level. Hence, the code looks as follows:

marginal.t24.2<-logitmfx(stock.market.crash~crash.t24+bubble.t24+RV.t24,data=Data_logitregression_lags, clustervar1 = "year")

marginal.t24.4<-logitmfx(stock.market.crash~crash.t24+bubble.t24+MP.t24+UTS.t24+UPR.t24+PPI.t24+RV.t24,data=Data_logitregression_lags, clustervar1 = "year")





Is it correct to use clustervar1 = "year" to have year clustered standard errors?

In addition I would like to create a table. I thought that stargazer would be appropriate but the following code is not working:

stargazer(marginal.t24.2, marginal.t24.4, title="Marginal effects result",type="text",out="Marginalt24logit-exportJun2017.txt")



R returns following error:

% Error: Unrecognized object type.



How can I create a table with marginal effects and the corresponding standard errors? Is there an alternative to stargazer?



Thanks for your support in advance.



Kind regards.



	[[alternative HTML version deleted]]


From sonisa at okstate.edu  Sat Jun 17 16:15:43 2017
From: sonisa at okstate.edu (Sharma, Sonisa)
Date: Sat, 17 Jun 2017 14:15:43 +0000
Subject: [R] (no subject)
Message-ID: <SN2PR03MB2207825B11C9CD6EC06D264CDAC60@SN2PR03MB2207.namprd03.prod.outlook.com>

I have 4 years of data and for each year, I have initialize the value so now for fitting the model, I want to remove the initial value and get the model based on remaining data set. Could anyone can help on this?
I want to get linear model based on fourth column and 13th column but need to remove the initial value for each year and each treatment ( the second column I have 1:36) .

Thank you,

Sonisa



1

1

2012-05-24

3120.00000

0.253

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

2

1

2012-05-24

1789.85870

0.143

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

3

1

2012-05-24

1391.48108

0.143

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

4

1

2012-05-24

2080.00000

0.227

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

5

1

2012-05-24

1640.00000

0.223

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

6

1

2012-05-24

3662.57591

0.290

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

7

1

2012-05-24

1280.00000

0.187

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

8

1

2012-05-24

2031.31522

0.250

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

9

1

2012-05-24

1920.00000

0.230

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

10

1

2012-05-24

1280.00000

0.153

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

11

1

2012-05-24

1920.00000

0.230

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

12

1

2012-05-24

3662.57591

0.290

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

13

1

2012-05-24

941.29799

0.093

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

14

1

2012-05-24

1840.00000

0.147

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

15

1

2012-05-24

941.29799

0.093

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

16

1

2012-05-24

1280.00000

0.187

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

17

1

2012-05-24

1391.48108

0.143

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535

0

0

0

0

0

0.000

0.000

0.000

0

3.13

0

0

0

0

173.1

0.0

0.02

0

0.85

2.76

2.80

2.93

2.93

2.93

2.85

2.84

2.82

2.80

0

7965

6264

1701

8

2012 Pasture 9-1

18

1

2012-05-24

1840.00000

0.147

1

2

1

2.1

0

2.18

1260

275

4125

1

0

0

3144

1535



Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


	[[alternative HTML version deleted]]


From mogjibs at gmail.com  Sat Jun 17 16:26:42 2017
From: mogjibs at gmail.com (Mogjib Salek)
Date: Sat, 17 Jun 2017 16:26:42 +0200
Subject: [R] write.dna command
Message-ID: <CAAWqvsekQNZ4TsCCXzeqnwos6CupKwR2Rw-1W=HRE-Vz=mN83A@mail.gmail.com>

Hi all,

I am learning R by "doing". And this is my first post.

I want to use R: 1- to fetch a DNA sequence from a databank (see bellow)
and 2- store it as FASTA file.

The problem: neither an error is prompted nor the fasta file is created.
Testing the code (see bellow), I notice that everything works until
the *"write.dna"
*command - which is not creating the fasta file.

Here is my code:

####Get gene sequence from GenBank and store it as fasta file
####16 June 2017

#1- Set the working directory and make sure the right libraries are
installed
(make sure 'ape' and 'seqinr' packages are installed)

WD <- "~Documents/Scripting/R_Studio/Sequences/"
setwd <- (WD)

#2- Fetch a sequence ( bellow, "enter  manually the desired DNA ID") from
GenBank and store it as fasta file.

      DNAid <- "JF806202"

    # Store the sequence in lst (a list)
      lst <- read.GenBank(DNAid, as.character = T)

      # convert the sequence to fasta format
       write.dna (lst, file = "DNAseq.fasta", format = "fasta", append =
FALSE,
           nbcol= 6, colsep= " ", colw= 10)


Any help will be appreciated.
Thank you.

Kelas

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Jun 17 19:50:50 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 17 Jun 2017 10:50:50 -0700
Subject: [R] (no subject)
In-Reply-To: <SN2PR03MB2207825B11C9CD6EC06D264CDAC60@SN2PR03MB2207.namprd03.prod.outlook.com>
References: <SN2PR03MB2207825B11C9CD6EC06D264CDAC60@SN2PR03MB2207.namprd03.prod.outlook.com>
Message-ID: <5FF4F050-CB8B-4AE4-90C1-CF29E73AEE32@dcn.davis.ca.us>

You desperately need to read the Posting Guide...

A) There is a no homework policy on this list. If this is for a class, stop now and go use the assistance resources offered by your educational institution. 

B) This is a plain text mailing list so the table formatting you saw when you sent this email got stripped leaving a mess for us to be confused by. Use plain text and R code to assemble your question (one useful function for sending data is dput).

C) This is the R-help list, not the R-do-my-work-for-me mailing list. You show us a _small_ example of code with data that gets you part of the way to your desired result or shows what error messages you encountered and clearly describe to us what result you want, and we help you over your hurdle. Some help with reproducible examples [1][2][3]

D) I suspect that you should show us what you have done with data for one year... "initialize the value" is unclear; why you would want to remove values is unclear. The other issue is applying this to multiple years, which should be addressed later. 

Do not assume that reading these highlights absolves you of your obligation to read the Posting Guide. See the footer below. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html

-- 
Sent from my phone. Please excuse my brevity.

On June 17, 2017 7:15:43 AM PDT, "Sharma, Sonisa" <sonisa at okstate.edu> wrote:
>I have 4 years of data and for each year, I have initialize the value
>so now for fitting the model, I want to remove the initial value and
>get the model based on remaining data set. Could anyone can help on
>this?
>I want to get linear model based on fourth column and 13th column but
>need to remove the initial value for each year and each treatment ( the
>second column I have 1:36) .
>
>Thank you,
>
>Sonisa
>
>
>
>1
>
>1
>
>2012-05-24
>
>3120.00000
>
>0.253
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>2
>
>1
>
>2012-05-24
>
>1789.85870
>
>0.143
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>3
>
>1
>
>2012-05-24
>
>1391.48108
>
>0.143
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>4
>
>1
>
>2012-05-24
>
>2080.00000
>
>0.227
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>5
>
>1
>
>2012-05-24
>
>1640.00000
>
>0.223
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>6
>
>1
>
>2012-05-24
>
>3662.57591
>
>0.290
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>7
>
>1
>
>2012-05-24
>
>1280.00000
>
>0.187
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>8
>
>1
>
>2012-05-24
>
>2031.31522
>
>0.250
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>9
>
>1
>
>2012-05-24
>
>1920.00000
>
>0.230
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>10
>
>1
>
>2012-05-24
>
>1280.00000
>
>0.153
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>11
>
>1
>
>2012-05-24
>
>1920.00000
>
>0.230
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>12
>
>1
>
>2012-05-24
>
>3662.57591
>
>0.290
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>13
>
>1
>
>2012-05-24
>
>941.29799
>
>0.093
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>14
>
>1
>
>2012-05-24
>
>1840.00000
>
>0.147
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>15
>
>1
>
>2012-05-24
>
>941.29799
>
>0.093
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>16
>
>1
>
>2012-05-24
>
>1280.00000
>
>0.187
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>17
>
>1
>
>2012-05-24
>
>1391.48108
>
>0.143
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0.000
>
>0.000
>
>0.000
>
>0
>
>3.13
>
>0
>
>0
>
>0
>
>0
>
>173.1
>
>0.0
>
>0.02
>
>0
>
>0.85
>
>2.76
>
>2.80
>
>2.93
>
>2.93
>
>2.93
>
>2.85
>
>2.84
>
>2.82
>
>2.80
>
>0
>
>7965
>
>6264
>
>1701
>
>8
>
>2012 Pasture 9-1
>
>18
>
>1
>
>2012-05-24
>
>1840.00000
>
>0.147
>
>1
>
>2
>
>1
>
>2.1
>
>0
>
>2.18
>
>1260
>
>275
>
>4125
>
>1
>
>0
>
>0
>
>3144
>
>1535
>
>
>
>Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for
>Windows 10
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Jun 17 20:05:04 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 17 Jun 2017 11:05:04 -0700
Subject: [R] write.dna command
In-Reply-To: <CAAWqvsekQNZ4TsCCXzeqnwos6CupKwR2Rw-1W=HRE-Vz=mN83A@mail.gmail.com>
References: <CAAWqvsekQNZ4TsCCXzeqnwos6CupKwR2Rw-1W=HRE-Vz=mN83A@mail.gmail.com>
Message-ID: <1CA3854B-48F3-47A7-B9E7-B3C4D8525A69@dcn.davis.ca.us>

I suspect you meant

WD <- "~/Documents/Scripting/R_Studio/Sequences/"

but I am entirely unfamiliar with the packages you are using, and know nothing about what is on your hard drive. 

For future reference:

A) Read the Posting Guide.  This is a plain text email list, and your html formatting gets removed leaving a mess that is not always readable. 

B) Most frequent users of R change their working directory to where their project files are before they start R. If you are using RStudio, the use of Projects will take care of this for you. Then you don't have to put in your whole working path in the script and you can copy/move your R and data files elsewhere without breaking everything. 
-- 
Sent from my phone. Please excuse my brevity.

On June 17, 2017 7:26:42 AM PDT, Mogjib Salek <mogjibs at gmail.com> wrote:
>Hi all,
>
>I am learning R by "doing". And this is my first post.
>
>I want to use R: 1- to fetch a DNA sequence from a databank (see
>bellow)
>and 2- store it as FASTA file.
>
>The problem: neither an error is prompted nor the fasta file is
>created.
>Testing the code (see bellow), I notice that everything works until
>the *"write.dna"
>*command - which is not creating the fasta file.
>
>Here is my code:
>
>####Get gene sequence from GenBank and store it as fasta file
>####16 June 2017
>
>#1- Set the working directory and make sure the right libraries are
>installed
>(make sure 'ape' and 'seqinr' packages are installed)
>
>WD <- "~Documents/Scripting/R_Studio/Sequences/"
>setwd <- (WD)
>
>#2- Fetch a sequence ( bellow, "enter  manually the desired DNA ID")
>from
>GenBank and store it as fasta file.
>
>      DNAid <- "JF806202"
>
>    # Store the sequence in lst (a list)
>      lst <- read.GenBank(DNAid, as.character = T)
>
>      # convert the sequence to fasta format
>      write.dna (lst, file = "DNAseq.fasta", format = "fasta", append =
>FALSE,
>           nbcol= 6, colsep= " ", colw= 10)
>
>
>Any help will be appreciated.
>Thank you.
>
>Kelas
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From milujisb at gmail.com  Sat Jun 17 20:24:05 2017
From: milujisb at gmail.com (Miluji Sb)
Date: Sat, 17 Jun 2017 20:24:05 +0200
Subject: [R] Prediction with two fixed-effects - large number of IDs
Message-ID: <CAMLwc7MJ6BXWxHOOpc43A0u_hXT+yZTPW5SfCQ09WxvrYXLKMA@mail.gmail.com>

Dear all,

I am running a panel regression with time and location fixed effects:

###

reg1 <- lm(lny ~ factor(id) + factor(year) + x1+ I(x1)^2 + x2+ I(x2)^2 ,
 data=mydata, na.action="na.omit")
###

My goal is to use the estimation for prediction. However, I have 8,500 IDs,
which is resulting in very slow computation. Ideally, I would like to do
the following:

###
reg2 <- felm(lny ~ x1+ I(x1)^2 + x2+ I(x2)^2 | id + year , data=mydata,
na.action="na.omit")
###

However, predict does not work with felm. Is there a way to either make lm
faster or use predict with felm? Is parallelizing an option?

Any help will be appreciated. Thank you!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From wjm1 at caa.columbia.edu  Sat Jun 17 20:37:42 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Sat, 17 Jun 2017 11:37:42 -0700
Subject: [R] write.dna command
In-Reply-To: <1CA3854B-48F3-47A7-B9E7-B3C4D8525A69@dcn.davis.ca.us>
References: <CAAWqvsekQNZ4TsCCXzeqnwos6CupKwR2Rw-1W=HRE-Vz=mN83A@mail.gmail.com>
 <1CA3854B-48F3-47A7-B9E7-B3C4D8525A69@dcn.davis.ca.us>
Message-ID: <CAA99HCzXXPe37595rxOqeMXAXpt-KN5K45bXAdH-yyijJ_3Xdw@mail.gmail.com>

We'll need more information on the packages you're using. Can you post the
output of:

> sessionInfo()

Finally, is this a Bioconductor question? They have their own support site:

https://support.bioconductor.org

HTH,

William Michels, Ph.D.


On Sat, Jun 17, 2017 at 11:05 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I suspect you meant
>
> WD <- "~/Documents/Scripting/R_Studio/Sequences/"
>
> but I am entirely unfamiliar with the packages you are using, and know
> nothing about what is on your hard drive.
>
> For future reference:
>
> A) Read the Posting Guide.  This is a plain text email list, and your html
> formatting gets removed leaving a mess that is not always readable.
>
> B) Most frequent users of R change their working directory to where their
> project files are before they start R. If you are using RStudio, the use of
> Projects will take care of this for you. Then you don't have to put in your
> whole working path in the script and you can copy/move your R and data
> files elsewhere without breaking everything.
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 17, 2017 7:26:42 AM PDT, Mogjib Salek <mogjibs at gmail.com> wrote:
> >Hi all,
> >
> >I am learning R by "doing". And this is my first post.
> >
> >I want to use R: 1- to fetch a DNA sequence from a databank (see
> >bellow)
> >and 2- store it as FASTA file.
> >
> >The problem: neither an error is prompted nor the fasta file is
> >created.
> >Testing the code (see bellow), I notice that everything works until
> >the *"write.dna"
> >*command - which is not creating the fasta file.
> >
> >Here is my code:
> >
> >####Get gene sequence from GenBank and store it as fasta file
> >####16 June 2017
> >
> >#1- Set the working directory and make sure the right libraries are
> >installed
> >(make sure 'ape' and 'seqinr' packages are installed)
> >
> >WD <- "~Documents/Scripting/R_Studio/Sequences/"
> >setwd <- (WD)
> >
> >#2- Fetch a sequence ( bellow, "enter  manually the desired DNA ID")
> >from
> >GenBank and store it as fasta file.
> >
> >      DNAid <- "JF806202"
> >
> >    # Store the sequence in lst (a list)
> >      lst <- read.GenBank(DNAid, as.character = T)
> >
> >      # convert the sequence to fasta format
> >      write.dna (lst, file = "DNAseq.fasta", format = "fasta", append =
> >FALSE,
> >           nbcol= 6, colsep= " ", colw= 10)
> >
> >
> >Any help will be appreciated.
> >Thank you.
> >
> >Kelas
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Jun 17 21:01:35 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 17 Jun 2017 12:01:35 -0700
Subject: [R] Prediction with two fixed-effects - large number of IDs
In-Reply-To: <CAMLwc7MJ6BXWxHOOpc43A0u_hXT+yZTPW5SfCQ09WxvrYXLKMA@mail.gmail.com>
References: <CAMLwc7MJ6BXWxHOOpc43A0u_hXT+yZTPW5SfCQ09WxvrYXLKMA@mail.gmail.com>
Message-ID: <C2F2381D-EAA5-4973-B426-4024E9A8C0BF@dcn.davis.ca.us>

I have no direct experience with such horrific models, but your formula is a mess and Google suggests the biglm package with ffdf. 

Specifically, you should convert your discrete variables to factors before you build the model, particularly since you want to use predict after the fact, for which you will need a new data set with the exact same levels in the factors. 

Also, your use of I() is broken and redundant.  I think formulas

lny ~ id + year + x1 + I(x1^2) + x2 + I(x2^2)

or

lny ~ id + year + x1^2 + x2^2

would obtain the intended prediction results.

-- 
Sent from my phone. Please excuse my brevity.

On June 17, 2017 11:24:05 AM PDT, Miluji Sb <milujisb at gmail.com> wrote:
>Dear all,
>
>I am running a panel regression with time and location fixed effects:
>
>###
>
>reg1 <- lm(lny ~ factor(id) + factor(year) + x1+ I(x1)^2 + x2+ I(x2)^2
>,
> data=mydata, na.action="na.omit")
>###
>
>My goal is to use the estimation for prediction. However, I have 8,500
>IDs,
>which is resulting in very slow computation. Ideally, I would like to
>do
>the following:
>
>###
>reg2 <- felm(lny ~ x1+ I(x1)^2 + x2+ I(x2)^2 | id + year , data=mydata,
>na.action="na.omit")
>###
>
>However, predict does not work with felm. Is there a way to either make
>lm
>faster or use predict with felm? Is parallelizing an option?
>
>Any help will be appreciated. Thank you!
>
>Sincerely,
>
>Milu
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From milujisb at gmail.com  Sat Jun 17 21:21:04 2017
From: milujisb at gmail.com (Miluji Sb)
Date: Sat, 17 Jun 2017 21:21:04 +0200
Subject: [R] Prediction with two fixed-effects - large number of IDs
In-Reply-To: <C2F2381D-EAA5-4973-B426-4024E9A8C0BF@dcn.davis.ca.us>
References: <CAMLwc7MJ6BXWxHOOpc43A0u_hXT+yZTPW5SfCQ09WxvrYXLKMA@mail.gmail.com>
 <C2F2381D-EAA5-4973-B426-4024E9A8C0BF@dcn.davis.ca.us>
Message-ID: <CAMLwc7PbM6_gUhfhSSg6Vbja5o+=LD2QwQ29nqFnNjkENp4P8w@mail.gmail.com>

Dear Jeff,

Thank you so much and apologies for the typo in I() - it was silly.

I will try the biglm package - thanks!

Sincerely,

Milu

On Sat, Jun 17, 2017 at 9:01 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I have no direct experience with such horrific models, but your formula is
> a mess and Google suggests the biglm package with ffdf.
>
> Specifically, you should convert your discrete variables to factors before
> you build the model, particularly since you want to use predict after the
> fact, for which you will need a new data set with the exact same levels in
> the factors.
>
> Also, your use of I() is broken and redundant.  I think formulas
>
> lny ~ id + year + x1 + I(x1^2) + x2 + I(x2^2)
>
> or
>
> lny ~ id + year + x1^2 + x2^2
>
> would obtain the intended prediction results.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 17, 2017 11:24:05 AM PDT, Miluji Sb <milujisb at gmail.com> wrote:
> >Dear all,
> >
> >I am running a panel regression with time and location fixed effects:
> >
> >###
> >
> >reg1 <- lm(lny ~ factor(id) + factor(year) + x1+ I(x1)^2 + x2+ I(x2)^2
> >,
> > data=mydata, na.action="na.omit")
> >###
> >
> >My goal is to use the estimation for prediction. However, I have 8,500
> >IDs,
> >which is resulting in very slow computation. Ideally, I would like to
> >do
> >the following:
> >
> >###
> >reg2 <- felm(lny ~ x1+ I(x1)^2 + x2+ I(x2)^2 | id + year , data=mydata,
> >na.action="na.omit")
> >###
> >
> >However, predict does not work with felm. Is there a way to either make
> >lm
> >faster or use predict with felm? Is parallelizing an option?
> >
> >Any help will be appreciated. Thank you!
> >
> >Sincerely,
> >
> >Milu
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From percentil101 at gmail.com  Sat Jun 17 19:51:55 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Sat, 17 Jun 2017 19:51:55 +0200
Subject: [R] Plot MArginal distribution in the correct place
In-Reply-To: <CA+8X3fVkmyBo8zwoaS8XM9EmN9fbBxocJRuOd2t4803m8KTF_g@mail.gmail.com>
References: <CAB-TgNt4u_r01t3vpBOo471tj-CZSazjL-zbSonyFsQrrQLbtQ@mail.gmail.com>
 <CAB-TgNtFXvxHPCbNWM2UeDeyDAt+56i=m5Mamc6mgFdB2kv3aA@mail.gmail.com>
 <CA+8X3fVP84StrtWD=gg7pUygf2WpSxOx4G1YW42YW-3AR3kfqw@mail.gmail.com>
 <CAB-TgNtyt8WkKa5xaZWZuJjWHriNbpr-XceBoYd2xqRpHX-4zQ@mail.gmail.com>
 <CAB-TgNtNsuHyAJQvN0qh8=N9mDVCy0c2z1zEGXQOG-D8rcyKnw@mail.gmail.com>
 <CA+8X3fVkmyBo8zwoaS8XM9EmN9fbBxocJRuOd2t4803m8KTF_g@mail.gmail.com>
Message-ID: <CAB-TgNuS_iFtYHrZ9RcGMJ-cT5hU6jvwq=X_nwuxRC_G3dE1SA@mail.gmail.com>

Can you suggest a plot on the right side so that the right plot has the
same units of left plot and reflect the counts of the number of time the
values repeat, something like the empirical distribution?



2017-06-14 12:30 GMT+02:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Pedro,
> If you keep that same margins for the second plot:
>
> par(mar=c(10,0,6,6))
> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
>
> it looks reasonably well aligned to me. Because you are plotting the
> counts of the values in Simulation, the ordinate (vertical axis) of
> the bar plot is in quite different units from that of the plot on the
> left side.
>
> Jim
>
> On Wed, Jun 14, 2017 at 5:33 PM, Pedro p?ramo <percentil101 at gmail.com>
> wrote:
> > Please can you send me some orientation?
> >
> > Many thanks in advance.
> >
> > Only if posible one book o similar example to understand why it is not
> what
> > I try.
> >
> > El 8 jun. 2017 7:50 PM, "Pedro p?ramo" <percentil101 at gmail.com>
> escribi?:
> >>
> >> Many thanks Jim.
> >>
> >> What I,m trying to show with the fhist plot is the empirical
> distribution
> >> of the values of the left plot simulation.
> >>
> >> You say:
> >> However, I don't think that this plot illustrates quite what you think
> it
> >> does.
> >>
> >> Can you give me a clue to try to illustrate better if it is not showing
> >> what I believe it shows a better way to show it?
> >>
> >> Many thanks in advance.
> >>
> >>
> >>
> >>
> >>
> >> El 7 jun. 2017 12:08, "Jim Lemon" <drjimlemon at gmail.com> escribi?:
> >>
> >> Hi Pedro,
> >> As a one-off, you just shove the coordinates around a bit:
> >>
> >> par(mar=c(11,0,6,6))
> >> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray",
> >>  ylim=c(0,24))
> >>
> >> However, I don't think that this plot illustrates quite what you think
> it
> >> does.
> >>
> >> Jim
> >>
> >>
> >> On Wed, Jun 7, 2017 at 4:01 PM, Pedro p?ramo <percentil101 at gmail.com>
> >> wrote:
> >> > Please, I'm trying to put the right plot higher and centered on the
> left
> >> > values but I don't achive.
> >> >
> >> > I would appreciate so much your help
> >> >
> >> > El 6 jun. 2017 22:37, "Pedro p?ramo" <percentil101 at gmail.com>
> escribi?:
> >> >
> >> >> Hi all,
> >> >>
> >> >> I have this code, but the marginal distribution plot doesn?t appear
> >> >> aligned with the left plot.
> >> >>
> >> >>
> >> >> I think could be something about layout or par() mar.
> >> >>
> >> >> The code was programmed by me time ago.
> >> >>
> >> >> Can anyone help me to get the marginal distribution on the center
> (more
> >> >> higher centered)
> >> >>
> >> >> id.txt
> >> >>
> >> >> Could have this code:
> >> >>
> >> >> 05/01/2016;9335,200195
> >> >> 06/01/2016;9197,400391
> >> >> 07/01/2016;9059,299805
> >> >> 08/01/2016;8909,200195
> >> >> 11/01/2016;8886,099609
> >> >> 12/01/2016;8915,400391
> >> >> 13/01/2016;8934,5
> >> >> 14/01/2016;8787,700195
> >> >> 15/01/2016;8543,599609
> >> >> 18/01/2016;8469,299805
> >> >> 19/01/2016;8554,900391
> >> >> 20/01/2016;8281,400391
> >> >> 21/01/2016;8444,200195
> >> >> 22/01/2016;8722,900391
> >> >> 25/01/2016;8567,700195
> >> >> 26/01/2016;8692,5
> >> >> 27/01/2016;8741
> >> >>
> >> >>
> >> >>
> >> >> g<-read.table("id.txt", col.names=c("Dateh","LAST"), sep=";",
> dec=",")
> >> >>
> >> >> N=5000
> >> >> B=24
> >> >> ghy<-nrow(g)
> >> >> r<-as.numeric(as.character(g$LAST[ghy]))
> >> >>
> >> >>
> >> >> nf<-layout(matrix(c(1,1,1,1,2,2),1,6,byrow=TRUE))
> >> >>
> >> >> par(mar=c(6,6,6,0.5))
> >> >>
> >> >> A<-matrix(1:B,B,N);
> >> >>
> >> >>
> >> >>
> >> >> sigma<-0.06;
> >> >>
> >> >>
> >> >>
> >> >> mu<-0.00;
> >> >>
> >> >>
> >> >> Z<-r*exp((mu-0.5*((sigma)^2)*A) +sigma*(sqrt(A))*matrix(
> >> >> rnorm(N*B,0,1),
> >> >> B, N))
> >> >>
> >> >> real1<-g$LAST[1:nrow(g)]
> >> >>
> >> >> real2<-matrix(NA,nrow(g),N-1)
> >> >>
> >> >> real<-cbind(real1,real2)
> >> >>
> >> >>
> >> >>
> >> >>
> >> >> Po<-r*matrix(1,1,N);
> >> >>
> >> >>
> >> >>
> >> >> Sim<-rbind(Po,Z)
> >> >> Simulation<-rbind(real,Z)
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >> par(mar=c(10,6,6,6))
> >> >> matplot(Simulation,type="l",ylim=c(0,40000))
> >> >>
> >> >> abline(h = 8000, lwd = 2, col = "black")
> >> >>
> >> >> abline(h = 12000, lwd = 2, col = "black")
> >> >> title("Dinamic Montecarlo Simulation 2 years ahead",font=4)
> >> >>
> >> >> fhist<-hist(Simulation,plot=FALSE)
> >> >> par(mar=c(6,0,6,6))
> >> >> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
> >> >> grid()
> >> >> title("Marginal Distribution",font=4)
> >> >>
> >> >>
> >> >> rect(0, 0, 0, 0) # transparent
> >> >>
> >> >>
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Sun Jun 18 02:10:55 2017
From: chocold12 at gmail.com (lily li)
Date: Sat, 17 Jun 2017 18:10:55 -0600
Subject: [R] About error bars on barplots
Message-ID: <CAN5afy8hgLqoBgbRMw5tZptKrD5aXFmh4j2XYMvdB2a6ixcH+g@mail.gmail.com>

Hi R users,

I have a question about adding uncertainty bars to stacked bar plots.

DF:
  year   A   B   C   Amin  Amax  Bmin  Bmax  Cmin  Cmax
 2009  40  45  15   30      61       23       56      14       17
 2010  36  41  23   26      54       22       51      22       24

I use the code below:

DF.refm = melt(subset(DF[,c(1:4)]),id.vars='year',variable_name='Legend')

fig1 = ggplot(data=DF.refm, aes(x=year,y=value,fill=Legend))+
  geom_bar(stat='identity',size=.5)+ theme_bw()+ xlab('Year')+
ylab('Percent (%)')
print(fig1)

But I don't know how to change it a little bit. For example, how to add the
error bars on the plot, as is shown in the figure below? The error bar for
variable A ranges from Amin to Amax, the same applies to variables B and C.
Thanks for your help.

From r.turner at auckland.ac.nz  Sun Jun 18 02:30:25 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 18 Jun 2017 12:30:25 +1200
Subject: [R] [FORGED]  About error bars on barplots
In-Reply-To: <CAN5afy8hgLqoBgbRMw5tZptKrD5aXFmh4j2XYMvdB2a6ixcH+g@mail.gmail.com>
References: <CAN5afy8hgLqoBgbRMw5tZptKrD5aXFmh4j2XYMvdB2a6ixcH+g@mail.gmail.com>
Message-ID: <06a4519c-7948-6931-c72f-e02f6f5ea886@auckland.ac.nz>

On 18/06/17 12:10, lily li wrote:
> Hi R users,
> 
> I have a question about adding uncertainty bars to stacked bar plots.
> 
> DF:
>    year   A   B   C   Amin  Amax  Bmin  Bmax  Cmin  Cmax
>   2009  40  45  15   30      61       23       56      14       17
>   2010  36  41  23   26      54       22       51      22       24
> 
> I use the code below:
> 
> DF.refm = melt(subset(DF[,c(1:4)]),id.vars='year',variable_name='Legend')
> 
> fig1 = ggplot(data=DF.refm, aes(x=year,y=value,fill=Legend))+
>    geom_bar(stat='identity',size=.5)+ theme_bw()+ xlab('Year')+
> ylab('Percent (%)')
> print(fig1)
> 
> But I don't know how to change it a little bit. For example, how to add the
> error bars on the plot, as is shown in the figure below? The error bar for
> variable A ranges from Amin to Amax, the same applies to variables B and C.
> Thanks for your help.


Your figure did not come through, at least not to me.  You are probably 
doing something fancy, and the mailing list software stripped out the 
figure.  *Do* learn to keep things simple.  _Attach_ figures as *.pdf 
files, for instance.

That being said, to answer your question, my advice (and that of many 
others) is: DON'T.  Error bars on boxplots (such plots are sometimes 
known as "dynamite plots" or "detonator plots") are considered by the 
cognoscenti to be abominations.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From chocold12 at gmail.com  Sun Jun 18 02:35:58 2017
From: chocold12 at gmail.com (lily li)
Date: Sat, 17 Jun 2017 18:35:58 -0600
Subject: [R] [FORGED]  About error bars on barplots
In-Reply-To: <06a4519c-7948-6931-c72f-e02f6f5ea886@auckland.ac.nz>
References: <CAN5afy8hgLqoBgbRMw5tZptKrD5aXFmh4j2XYMvdB2a6ixcH+g@mail.gmail.com>
 <06a4519c-7948-6931-c72f-e02f6f5ea886@auckland.ac.nz>
Message-ID: <CAN5afy8EhxEVz=OysVBh4ZFhXctfnGOFAWRo2fyU_i4giq5pKQ@mail.gmail.com>

Okay, thanks for letting me know. I found the plot from website so thought
there may be a way. I just converted the format of the figure, and
attached. But I don't mean to use it as you suggested. Thanks.

On Sat, Jun 17, 2017 at 6:30 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 18/06/17 12:10, lily li wrote:
>
>> Hi R users,
>>
>> I have a question about adding uncertainty bars to stacked bar plots.
>>
>> DF:
>>    year   A   B   C   Amin  Amax  Bmin  Bmax  Cmin  Cmax
>>   2009  40  45  15   30      61       23       56      14       17
>>   2010  36  41  23   26      54       22       51      22       24
>>
>> I use the code below:
>>
>> DF.refm = melt(subset(DF[,c(1:4)]),id.vars='year',variable_name='Legend')
>>
>> fig1 = ggplot(data=DF.refm, aes(x=year,y=value,fill=Legend))+
>>    geom_bar(stat='identity',size=.5)+ theme_bw()+ xlab('Year')+
>> ylab('Percent (%)')
>> print(fig1)
>>
>> But I don't know how to change it a little bit. For example, how to add
>> the
>> error bars on the plot, as is shown in the figure below? The error bar for
>> variable A ranges from Amin to Amax, the same applies to variables B and
>> C.
>> Thanks for your help.
>>
>
>
> Your figure did not come through, at least not to me.  You are probably
> doing something fancy, and the mailing list software stripped out the
> figure.  *Do* learn to keep things simple.  _Attach_ figures as *.pdf
> files, for instance.
>
> That being said, to answer your question, my advice (and that of many
> others) is: DON'T.  Error bars on boxplots (such plots are sometimes known
> as "dynamite plots" or "detonator plots") are considered by the cognoscenti
> to be abominations.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sample.pdf
Type: application/pdf
Size: 19497 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170617/17d81494/attachment.pdf>

From dwinsemius at comcast.net  Sun Jun 18 04:36:40 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 17 Jun 2017 19:36:40 -0700
Subject: [R] Prediction with two fixed-effects - large number of IDs
In-Reply-To: <C2F2381D-EAA5-4973-B426-4024E9A8C0BF@dcn.davis.ca.us>
References: <CAMLwc7MJ6BXWxHOOpc43A0u_hXT+yZTPW5SfCQ09WxvrYXLKMA@mail.gmail.com>
 <C2F2381D-EAA5-4973-B426-4024E9A8C0BF@dcn.davis.ca.us>
Message-ID: <8ACDB313-1291-4736-97FD-CEC02551E373@comcast.net>


> On Jun 17, 2017, at 12:01 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> I have no direct experience with such horrific models, but your formula is a mess and Google suggests the biglm package with ffdf. 
> 
> Specifically, you should convert your discrete variables to factors before you build the model, particularly since you want to use predict after the fact, for which you will need a new data set with the exact same levels in the factors. 
> 
> Also, your use of I() is broken and redundant.  I think formulas
> 
> lny ~ id + year + x1 + I(x1^2) + x2 + I(x2^2)
> 
> or
> 
> lny ~ id + year + x1^2 + x2^2

This was offered as a formula to `felm` (but with no data example), a package with which I have no experience either, but if experience with `lm` and `glm` is any guide, an inferentially safer approach might be:

   lny ~ id + year + poly(x1,2) + poly(x2,2)

-- 

David


> 
> would obtain the intended prediction results.
> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On June 17, 2017 11:24:05 AM PDT, Miluji Sb <milujisb at gmail.com> wrote:
>> Dear all,
>> 
>> I am running a panel regression with time and location fixed effects:
>> 
>> ###
>> 
>> reg1 <- lm(lny ~ factor(id) + factor(year) + x1+ I(x1)^2 + x2+ I(x2)^2
>> ,
>> data=mydata, na.action="na.omit")
>> ###
>> 
>> My goal is to use the estimation for prediction. However, I have 8,500
>> IDs,
>> which is resulting in very slow computation. Ideally, I would like to
>> do
>> the following:
>> 
>> ###
>> reg2 <- felm(lny ~ x1+ I(x1)^2 + x2+ I(x2)^2 | id + year , data=mydata,
>> na.action="na.omit")
>> ###
>> 
>> However, predict does not work with felm. Is there a way to either make
>> lm
>> faster or use predict with felm? Is parallelizing an option?
>> 
>> Any help will be appreciated. Thank you!
>> 
>> Sincerely,
>> 
>> Milu
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tofighizahra at gmail.com  Sun Jun 18 09:39:51 2017
From: tofighizahra at gmail.com (Zahra Tofighi)
Date: Sun, 18 Jun 2017 12:09:51 +0430
Subject: [R] error for using igraph library: 'edges' must be numeric or
	character
Message-ID: <CAP6isFr2A18_bxkUMuGHedG_8-OWAMuPnSDVq92RBqhmN2vCBg@mail.gmail.com>

hello, i want to use igraph  for drawing graph of my data. First time i try
do it and it was successful. but now i want to test again i got this error:
"edges must be numeric or character". this is my edge list(this is output
from R):
            From            To
1  US20100331312
2  US20100331341
3  US20100330919 US20100041339
4  US20100330919 US20100195590
5  US20100330919 US20110170512
6  US20100330919 US20110312368
7  US20100330919 US20110021152
8  US20100330919 US20110026376
9  US20100330919 US20110028097
10 US20100330919 US20110028098
11 US20100330919 US20110028100
12 US20100330919 US20110028107
13 US20100330919 US20120083303
14 US20100330919 US20120100883
15 US20100330919 US20140038659
16 US20100330919 US20140162715
17 US20100330919 US20150049721
18 US20100330919 US20150257156

 I'm sure they are character. what's my wrong?
with Regard,

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Jun 18 12:47:37 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 18 Jun 2017 20:47:37 +1000
Subject: [R] Plot MArginal distribution in the correct place
In-Reply-To: <CAB-TgNuS_iFtYHrZ9RcGMJ-cT5hU6jvwq=X_nwuxRC_G3dE1SA@mail.gmail.com>
References: <CAB-TgNt4u_r01t3vpBOo471tj-CZSazjL-zbSonyFsQrrQLbtQ@mail.gmail.com>
 <CAB-TgNtFXvxHPCbNWM2UeDeyDAt+56i=m5Mamc6mgFdB2kv3aA@mail.gmail.com>
 <CA+8X3fVP84StrtWD=gg7pUygf2WpSxOx4G1YW42YW-3AR3kfqw@mail.gmail.com>
 <CAB-TgNtyt8WkKa5xaZWZuJjWHriNbpr-XceBoYd2xqRpHX-4zQ@mail.gmail.com>
 <CAB-TgNtNsuHyAJQvN0qh8=N9mDVCy0c2z1zEGXQOG-D8rcyKnw@mail.gmail.com>
 <CA+8X3fVkmyBo8zwoaS8XM9EmN9fbBxocJRuOd2t4803m8KTF_g@mail.gmail.com>
 <CAB-TgNuS_iFtYHrZ9RcGMJ-cT5hU6jvwq=X_nwuxRC_G3dE1SA@mail.gmail.com>
Message-ID: <CA+8X3fUs+m-=YU6d9V4iGhuJx3i5eBvKvA8-EJ7kpj9kDjMwyQ@mail.gmail.com>

As you have categorized the original values, they are different from
the originals. You could include the categories like this, with a bit
of fiddling the margins and y limits for the right hand plot:

x11(width=10)
nf<-layout(matrix(c(1,1,1,1,2,2),1,6,byrow=TRUE))
par(mar=c(10,6,6,6))
matplot(Simulation,type="l",ylim=c(0,40000))
abline(h = 8000, lwd = 2, col = "black")
abline(h = 12000, lwd = 2, col = "black")
title("Dinamic Montecarlo Simulation 2 years ahead",font=4)
fhist<-hist(Simulation,plot=FALSE)
par(mar=c(10,6,6,6))
barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray",
 names.arg=paste(fhist$breaks[1:23],fhist$breaks[2:24],sep="-"),
 las=2,ylim=c(-3,40))
grid()
title("Marginal Distribution",font=4)

Jim



On Sun, Jun 18, 2017 at 3:51 AM, Pedro p?ramo <percentil101 at gmail.com> wrote:
> Can you suggest a plot on the right side so that the right plot has the same
> units of left plot and reflect the counts of the number of time the values
> repeat, something like the empirical distribution?
>


From bgunter.4567 at gmail.com  Sun Jun 18 16:21:03 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 18 Jun 2017 07:21:03 -0700
Subject: [R] error for using igraph library: 'edges' must be numeric or
	character
In-Reply-To: <CAP6isFr2A18_bxkUMuGHedG_8-OWAMuPnSDVq92RBqhmN2vCBg@mail.gmail.com>
References: <CAP6isFr2A18_bxkUMuGHedG_8-OWAMuPnSDVq92RBqhmN2vCBg@mail.gmail.com>
Message-ID: <CAGxFJbTKFrB7gXbva-i8dFi7hsgeq0Y12Z1yyVY_t-mkcPAvMw@mail.gmail.com>

They are probably factors in a data frame. Use str() on your data (a
data frame?) to find out.

If you have not already done so, please spend some time with an R
tutorial or two to learn about factors and, in particular how
read.csv(), read.table(), etc. will cause this to happen, how you can
prevent it, and how to use ?as.character to convert from factor to
character.

A search (e.g. at rseek.org) on something like "R factor or character"
will also probably bring up relevant info.

Cheers,
Bert



Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 18, 2017 at 12:39 AM, Zahra Tofighi <tofighizahra at gmail.com> wrote:
> hello, i want to use igraph  for drawing graph of my data. First time i try
> do it and it was successful. but now i want to test again i got this error:
> "edges must be numeric or character". this is my edge list(this is output
> from R):
>             From            To
> 1  US20100331312
> 2  US20100331341
> 3  US20100330919 US20100041339
> 4  US20100330919 US20100195590
> 5  US20100330919 US20110170512
> 6  US20100330919 US20110312368
> 7  US20100330919 US20110021152
> 8  US20100330919 US20110026376
> 9  US20100330919 US20110028097
> 10 US20100330919 US20110028098
> 11 US20100330919 US20110028100
> 12 US20100330919 US20110028107
> 13 US20100330919 US20120083303
> 14 US20100330919 US20120100883
> 15 US20100330919 US20140038659
> 16 US20100330919 US20140162715
> 17 US20100330919 US20150049721
> 18 US20100330919 US20150257156
>
>  I'm sure they are character. what's my wrong?
> with Regard,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ranjanmano167 at gmail.com  Sun Jun 18 15:24:54 2017
From: ranjanmano167 at gmail.com (Manoranjan Muthusamy)
Date: Sun, 18 Jun 2017 14:24:54 +0100
Subject: [R] R_using non linear regression with constraints
Message-ID: <CANqyHbQJ8-hsKDJ59XkQE06aeJBFFB_-WhCYPPEvRH8N4o90bA@mail.gmail.com>

I am using nlsLM {minpack.lm} to find the values of parameters a and b of
function myfun which give the best fit for the data set, mydata.

mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))

myfun=function(a,b,r,t){
  prd=a*b*(1-exp(-b*r*t))
  return(prd)}

and using nlsLM

myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
                  lower = c(1000,0), upper = c(3000,1))

It works. But now I would like to introduce a constraint which is a*b<1000.
I had a look at the option available in nlsLM to set constraint via
nls.lm.control. But it's not much of help. can somebody help me here or
suggest a different method to to this?

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Jun 18 18:43:11 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Jun 2017 09:43:11 -0700
Subject: [R] R_using non linear regression with constraints
In-Reply-To: <CANqyHbQJ8-hsKDJ59XkQE06aeJBFFB_-WhCYPPEvRH8N4o90bA@mail.gmail.com>
References: <CANqyHbQJ8-hsKDJ59XkQE06aeJBFFB_-WhCYPPEvRH8N4o90bA@mail.gmail.com>
Message-ID: <55935B3C-B8EA-460F-A758-6173F50C0F50@comcast.net>


> On Jun 18, 2017, at 6:24 AM, Manoranjan Muthusamy <ranjanmano167 at gmail.com> wrote:
> 
> I am using nlsLM {minpack.lm} to find the values of parameters a and b of
> function myfun which give the best fit for the data set, mydata.
> 
> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
> 
> myfun=function(a,b,r,t){
>  prd=a*b*(1-exp(-b*r*t))
>  return(prd)}
> 
> and using nlsLM
> 
> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>                  lower = c(1000,0), upper = c(3000,1))
> 
> It works. But now I would like to introduce a constraint which is a*b<1000.

At the moment your coefficients do satisfy that constraint so that dataset is not suitable for testing. A slight modification of the objective function to include the logical constraint as an additional factor does not "break" that particular solution.:

myfun2=function(a,b,r,t){
    prd=a*b*(1-exp(-b*r*t))*(a*b<1000)
    return(prd)}


myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
            lower = c(1000,0), upper = c(3000,1))

#------------------
myfit
Nonlinear regression model
  model: y ~ myfun2(a, b, r = 2, t = x)
   data: mydata
        a         b 
3.000e+03 2.288e-02 
 residual sum-of-squares: 38.02

Number of iterations to convergence: 8 
Achieved convergence tolerance: 1.49e-08
#--

prod(coef(myfit))
#[1] 68.64909  Same as original result.

How nlsLM will handle more difficult problems is not something I have experience with, but obviously one would need to keep the starting values within the feasible domain. However, if your goal was to also remove the upper and lower constraints on a and b, This problem would not be suitably solved by the a*b product without relaxation of the default maxiter:

> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
+             lower = c(0,0), upper = c(9000,1))
> prod(coef(myfit))
[1] 110.4382
> coef(myfit)
           a            b 
9.000000e+03 1.227091e-02 

>  myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
+              lower = c(0,0), upper = c(10^6,1))
Warning message:
In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower = lower,  :
  lmdif: info = -1. Number of iterations has reached `maxiter' == 50.

#---------
 myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
             lower = c(0,0), upper = c(10^6,1), control=list(maxiter=100))
 prod(coef(myfit))

 coef(myfit)
#============


>  prod(coef(myfit))
[1] 780.6732  Significantly different than the solution at default maxiter of 50.
> 
>  coef(myfit)
           a            b 
5.319664e+05 1.467524e-03 
> 
> 


-- 
David.


> I had a look at the option available in nlsLM to set constraint via
> nls.lm.control. But it's not much of help. can somebody help me here or
> suggest a different method to to this?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sun Jun 18 19:29:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 18 Jun 2017 10:29:52 -0700
Subject: [R] R_using non linear regression with constraints
In-Reply-To: <55935B3C-B8EA-460F-A758-6173F50C0F50@comcast.net>
References: <CANqyHbQJ8-hsKDJ59XkQE06aeJBFFB_-WhCYPPEvRH8N4o90bA@mail.gmail.com>
 <55935B3C-B8EA-460F-A758-6173F50C0F50@comcast.net>
Message-ID: <CAGxFJbR-yTBF7aP2n+2MzNDqRg5r9D==2Jy+0K-D_mu0-Du6-w@mail.gmail.com>

https://cran.r-project.org/web/views/Optimization.html

(Cran's optimization task view -- as always, you should search before posting)

In general, nonlinear optimization with nonlinear constraints is hard,
and the strategy used here (multiplying by a*b < 1000) may not work --
it introduces  a discontinuity into the objective function, so
gradient based methods may in particular be problematic.  As usual, if
either John Nash or Ravi Varadhan comment, heed what they suggest. I'm
pretty ignorant.

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 18, 2017 at 9:43 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Jun 18, 2017, at 6:24 AM, Manoranjan Muthusamy <ranjanmano167 at gmail.com> wrote:
>>
>> I am using nlsLM {minpack.lm} to find the values of parameters a and b of
>> function myfun which give the best fit for the data set, mydata.
>>
>> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>>
>> myfun=function(a,b,r,t){
>>  prd=a*b*(1-exp(-b*r*t))
>>  return(prd)}
>>
>> and using nlsLM
>>
>> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>                  lower = c(1000,0), upper = c(3000,1))
>>
>> It works. But now I would like to introduce a constraint which is a*b<1000.
>
> At the moment your coefficients do satisfy that constraint so that dataset is not suitable for testing. A slight modification of the objective function to include the logical constraint as an additional factor does not "break" that particular solution.:
>
> myfun2=function(a,b,r,t){
>     prd=a*b*(1-exp(-b*r*t))*(a*b<1000)
>     return(prd)}
>
>
> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>             lower = c(1000,0), upper = c(3000,1))
>
> #------------------
> myfit
> Nonlinear regression model
>   model: y ~ myfun2(a, b, r = 2, t = x)
>    data: mydata
>         a         b
> 3.000e+03 2.288e-02
>  residual sum-of-squares: 38.02
>
> Number of iterations to convergence: 8
> Achieved convergence tolerance: 1.49e-08
> #--
>
> prod(coef(myfit))
> #[1] 68.64909  Same as original result.
>
> How nlsLM will handle more difficult problems is not something I have experience with, but obviously one would need to keep the starting values within the feasible domain. However, if your goal was to also remove the upper and lower constraints on a and b, This problem would not be suitably solved by the a*b product without relaxation of the default maxiter:
>
>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
> +             lower = c(0,0), upper = c(9000,1))
>> prod(coef(myfit))
> [1] 110.4382
>> coef(myfit)
>            a            b
> 9.000000e+03 1.227091e-02
>
>>  myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
> +              lower = c(0,0), upper = c(10^6,1))
> Warning message:
> In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower = lower,  :
>   lmdif: info = -1. Number of iterations has reached `maxiter' == 50.
>
> #---------
>  myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>              lower = c(0,0), upper = c(10^6,1), control=list(maxiter=100))
>  prod(coef(myfit))
>
>  coef(myfit)
> #============
>
>
>>  prod(coef(myfit))
> [1] 780.6732  Significantly different than the solution at default maxiter of 50.
>>
>>  coef(myfit)
>            a            b
> 5.319664e+05 1.467524e-03
>>
>>
>
>
> --
> David.
>
>
>> I had a look at the option available in nlsLM to set constraint via
>> nls.lm.control. But it's not much of help. can somebody help me here or
>> suggest a different method to to this?
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From profjcnash at gmail.com  Sun Jun 18 20:52:16 2017
From: profjcnash at gmail.com (J C Nash)
Date: Sun, 18 Jun 2017 14:52:16 -0400
Subject: [R] R_using non linear regression with constraints
In-Reply-To: <CAGxFJbR-yTBF7aP2n+2MzNDqRg5r9D==2Jy+0K-D_mu0-Du6-w@mail.gmail.com>
References: <CANqyHbQJ8-hsKDJ59XkQE06aeJBFFB_-WhCYPPEvRH8N4o90bA@mail.gmail.com>
 <55935B3C-B8EA-460F-A758-6173F50C0F50@comcast.net>
 <CAGxFJbR-yTBF7aP2n+2MzNDqRg5r9D==2Jy+0K-D_mu0-Du6-w@mail.gmail.com>
Message-ID: <20a31ecb-74a0-a90e-db44-33d127ff5387@gmail.com>

I ran the following script. I satisfied the constraint by
making a*b a single parameter, which isn't always possible.
I also ran nlxb() from nlsr package, and this gives singular
values of the Jacobian. In the unconstrained case, the svs are
pretty awful, and I wouldn't trust the results as a model, though
the minimum is probably OK. The constrained result has a much
larger sum of squares.

Notes:
1) nlsr has been flagged with a check error by CRAN (though it
is in the vignette, and also mentions pandoc a couple of times).
I'm working to purge the "bug", and found one on our part, but
not necessarily all the issues.
2) I used nlxb that requires an expression for the model. nlsLM
can use a function because it is using derivative approximations,
while nlxb actually gets a symbolic or automatic derivative if
it can, else squawks.

JN

#  Here's the script #
#
# Manoranjan Muthusamy <ranjanmano167 at gmail.com>
#

library(minpack.lm)
mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))

myfun=function(a,b,r,t){
   prd=a*b*(1-exp(-b*r*t))
   return(prd)}

# and using nlsLM

myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
                   lower = c(1000,0), upper = c(3000,1))
summary(myfit)
library(nlsr)
r <- 2
myfitj=nlxb(y~a*b*(1-exp(-b*r*x)),data=mydata,start=list(a=2000,b=0.05), trace=TRUE)
summary(myfitj)
print(myfitj)

myfitj2<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05), trace=TRUE)
summary(myfitj2)
print(myfitj2)

myfitj2b<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05),
                 trace=TRUE, upper=c(1000, Inf))
summary(myfitj2b)
print(myfitj2b)
# End of script #

On 2017-06-18 01:29 PM, Bert Gunter wrote:
> https://cran.r-project.org/web/views/Optimization.html
> 
> (Cran's optimization task view -- as always, you should search before posting)
> 
> In general, nonlinear optimization with nonlinear constraints is hard,
> and the strategy used here (multiplying by a*b < 1000) may not work --
> it introduces  a discontinuity into the objective function, so
> gradient based methods may in particular be problematic.  As usual, if
> either John Nash or Ravi Varadhan comment, heed what they suggest. I'm
> pretty ignorant.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, Jun 18, 2017 at 9:43 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>> On Jun 18, 2017, at 6:24 AM, Manoranjan Muthusamy <ranjanmano167 at gmail.com> wrote:
>>>
>>> I am using nlsLM {minpack.lm} to find the values of parameters a and b of
>>> function myfun which give the best fit for the data set, mydata.
>>>
>>> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>>>
>>> myfun=function(a,b,r,t){
>>>   prd=a*b*(1-exp(-b*r*t))
>>>   return(prd)}
>>>
>>> and using nlsLM
>>>
>>> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>                   lower = c(1000,0), upper = c(3000,1))
>>>
>>> It works. But now I would like to introduce a constraint which is a*b<1000.
>>
>> At the moment your coefficients do satisfy that constraint so that dataset is not suitable for testing. A slight modification of the objective function to include the logical constraint as an additional factor does not "break" that particular solution.:
>>
>> myfun2=function(a,b,r,t){
>>      prd=a*b*(1-exp(-b*r*t))*(a*b<1000)
>>      return(prd)}
>>
>>
>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>              lower = c(1000,0), upper = c(3000,1))
>>
>> #------------------
>> myfit
>> Nonlinear regression model
>>    model: y ~ myfun2(a, b, r = 2, t = x)
>>     data: mydata
>>          a         b
>> 3.000e+03 2.288e-02
>>   residual sum-of-squares: 38.02
>>
>> Number of iterations to convergence: 8
>> Achieved convergence tolerance: 1.49e-08
>> #--
>>
>> prod(coef(myfit))
>> #[1] 68.64909  Same as original result.
>>
>> How nlsLM will handle more difficult problems is not something I have experience with, but obviously one would need to keep the starting values within the feasible domain. However, if your goal was to also remove the upper and lower constraints on a and b, This problem would not be suitably solved by the a*b product without relaxation of the default maxiter:
>>
>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>> +             lower = c(0,0), upper = c(9000,1))
>>> prod(coef(myfit))
>> [1] 110.4382
>>> coef(myfit)
>>             a            b
>> 9.000000e+03 1.227091e-02
>>
>>>   myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>> +              lower = c(0,0), upper = c(10^6,1))
>> Warning message:
>> In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower = lower,  :
>>    lmdif: info = -1. Number of iterations has reached `maxiter' == 50.
>>
>> #---------
>>   myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>               lower = c(0,0), upper = c(10^6,1), control=list(maxiter=100))
>>   prod(coef(myfit))
>>
>>   coef(myfit)
>> #============
>>
>>
>>>   prod(coef(myfit))
>> [1] 780.6732  Significantly different than the solution at default maxiter of 50.
>>>
>>>   coef(myfit)
>>             a            b
>> 5.319664e+05 1.467524e-03
>>>
>>>
>>
>>
>> --
>> David.
>>
>>
>>> I had a look at the option available in nlsLM to set constraint via
>>> nls.lm.control. But it's not much of help. can somebody help me here or
>>> suggest a different method to to this?
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Mon Jun 19 00:09:32 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Jun 2017 15:09:32 -0700
Subject: [R] R_using non linear regression with constraints
In-Reply-To: <20a31ecb-74a0-a90e-db44-33d127ff5387@gmail.com>
References: <CANqyHbQJ8-hsKDJ59XkQE06aeJBFFB_-WhCYPPEvRH8N4o90bA@mail.gmail.com>
 <55935B3C-B8EA-460F-A758-6173F50C0F50@comcast.net>
 <CAGxFJbR-yTBF7aP2n+2MzNDqRg5r9D==2Jy+0K-D_mu0-Du6-w@mail.gmail.com>
 <20a31ecb-74a0-a90e-db44-33d127ff5387@gmail.com>
Message-ID: <45BF66A5-CC6D-4EEB-8EDF-C0ECE668F144@comcast.net>

Dear Dr Nash;

> On Jun 18, 2017, at 11:52 AM, J C Nash <profjcnash at gmail.com> wrote:
> 
> I ran the following script. I satisfied the constraint by
> making a*b a single parameter, which isn't always possible.
> I also ran nlxb() from nlsr package, and this gives singular
> values of the Jacobian. In the unconstrained case, the svs are
> pretty awful, and I wouldn't trust the results as a model, though
> the minimum is probably OK. The constrained result has a much
> larger sum of squares.

I have version 2017.2.19 of nlsr on my Mac. Not sure what version is throwing errors.
> 
> Notes:
> 1) nlsr has been flagged with a check error by CRAN (though it
> is in the vignette, and also mentions pandoc a couple of times).
> I'm working to purge the "bug", and found one on our part, but
> not necessarily all the issues.
> 2) I used nlxb that requires an expression for the model. nlsLM
> can use a function because it is using derivative approximations,
> while nlxb actually gets a symbolic or automatic derivative if
> it can, else squawks.

I think of such problems as potentially searching for the maximum along a constraint boundary as a problem at an intersection of a family 2 surfaces in the "a cross b" space, in this case the surface ( a*b = 1000 ) and the family of curves that are implicitly defined by a*b*(1-exp(-b*r*t)) with r fixed and t <- mydata$x.

The intersection of these two geometric structures ( a constraint surface and a family parametrized by a and b) is in my construction  the problem domain.

I can see where an algorithm might erroneously return a "satisfied" results when it was following an iterative path to the edge of the constraint boundary but was prematurely "seeing the task as complete". Can you comment on the logical difficulties and solutions to surmounting such error after such an event occurs?

Sincerely;
David Winsemius

 
> 
> JN
> 
> #  Here's the script #
> #
> # Manoranjan Muthusamy <ranjanmano167 at gmail.com>
> #
> 
> library(minpack.lm)
> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
> 
> myfun=function(a,b,r,t){
>  prd=a*b*(1-exp(-b*r*t))
>  return(prd)}
> 
> # and using nlsLM
> 
> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>                  lower = c(1000,0), upper = c(3000,1))
> summary(myfit)
> library(nlsr)
> r <- 2
> myfitj=nlxb(y~a*b*(1-exp(-b*r*x)),data=mydata,start=list(a=2000,b=0.05), trace=TRUE)
> summary(myfitj)
> print(myfitj)
> 
> myfitj2<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05), trace=TRUE)
> summary(myfitj2)
> print(myfitj2)
> 
> myfitj2b<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05),
>                trace=TRUE, upper=c(1000, Inf))
> summary(myfitj2b)
> print(myfitj2b)
> # End of script #
> 
> On 2017-06-18 01:29 PM, Bert Gunter wrote:
>> https://cran.r-project.org/web/views/Optimization.html
>> (Cran's optimization task view -- as always, you should search before posting)
>> In general, nonlinear optimization with nonlinear constraints is hard,
>> and the strategy used here (multiplying by a*b < 1000) may not work --
>> it introduces  a discontinuity into the objective function, so
>> gradient based methods may in particular be problematic.  As usual, if
>> either John Nash or Ravi Varadhan comment, heed what they suggest. I'm
>> pretty ignorant.
>> Cheers,
>> Bert
>> Bert Gunter
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> On Sun, Jun 18, 2017 at 9:43 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>>> On Jun 18, 2017, at 6:24 AM, Manoranjan Muthusamy <ranjanmano167 at gmail.com> wrote:
>>>> 
>>>> I am using nlsLM {minpack.lm} to find the values of parameters a and b of
>>>> function myfun which give the best fit for the data set, mydata.
>>>> 
>>>> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>>>> 
>>>> myfun=function(a,b,r,t){
>>>>  prd=a*b*(1-exp(-b*r*t))
>>>>  return(prd)}
>>>> 
>>>> and using nlsLM
>>>> 
>>>> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>                  lower = c(1000,0), upper = c(3000,1))
>>>> 
>>>> It works. But now I would like to introduce a constraint which is a*b<1000.
>>> 
>>> At the moment your coefficients do satisfy that constraint so that dataset is not suitable for testing. A slight modification of the objective function to include the logical constraint as an additional factor does not "break" that particular solution.:
>>> 
>>> myfun2=function(a,b,r,t){
>>>     prd=a*b*(1-exp(-b*r*t))*(a*b<1000)
>>>     return(prd)}
>>> 
>>> 
>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>             lower = c(1000,0), upper = c(3000,1))
>>> 
>>> #------------------
>>> myfit
>>> Nonlinear regression model
>>>   model: y ~ myfun2(a, b, r = 2, t = x)
>>>    data: mydata
>>>         a         b
>>> 3.000e+03 2.288e-02
>>>  residual sum-of-squares: 38.02
>>> 
>>> Number of iterations to convergence: 8
>>> Achieved convergence tolerance: 1.49e-08
>>> #--
>>> 
>>> prod(coef(myfit))
>>> #[1] 68.64909  Same as original result.
>>> 
>>> How nlsLM will handle more difficult problems is not something I have experience with, but obviously one would need to keep the starting values within the feasible domain. However, if your goal was to also remove the upper and lower constraints on a and b, This problem would not be suitably solved by the a*b product without relaxation of the default maxiter:
>>> 
>>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>> +             lower = c(0,0), upper = c(9000,1))
>>>> prod(coef(myfit))
>>> [1] 110.4382
>>>> coef(myfit)
>>>            a            b
>>> 9.000000e+03 1.227091e-02
>>> 
>>>>  myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>> +              lower = c(0,0), upper = c(10^6,1))
>>> Warning message:
>>> In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower = lower,  :
>>>   lmdif: info = -1. Number of iterations has reached `maxiter' == 50.
>>> 
>>> #---------
>>>  myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>              lower = c(0,0), upper = c(10^6,1), control=list(maxiter=100))
>>>  prod(coef(myfit))
>>> 
>>>  coef(myfit)
>>> #============
>>> 
>>> 
>>>>  prod(coef(myfit))
>>> [1] 780.6732  Significantly different than the solution at default maxiter of 50.
>>>> 
>>>>  coef(myfit)
>>>            a            b
>>> 5.319664e+05 1.467524e-03
>>>> 
>>>> 
>>> 
>>> 
>>> --
>>> David.
>>> 
>>> 
>>>> I had a look at the option available in nlsLM to set constraint via
>>>> nls.lm.control. But it's not much of help. can somebody help me here or
>>>> suggest a different method to to this?
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Mon Jun 19 00:23:34 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 18 Jun 2017 15:23:34 -0700 (PDT)
Subject: [R] R_using non linear regression with constraints
In-Reply-To: <20a31ecb-74a0-a90e-db44-33d127ff5387@gmail.com>
References: <CANqyHbQJ8-hsKDJ59XkQE06aeJBFFB_-WhCYPPEvRH8N4o90bA@mail.gmail.com>
 <55935B3C-B8EA-460F-A758-6173F50C0F50@comcast.net>
 <CAGxFJbR-yTBF7aP2n+2MzNDqRg5r9D==2Jy+0K-D_mu0-Du6-w@mail.gmail.com>
 <20a31ecb-74a0-a90e-db44-33d127ff5387@gmail.com>
Message-ID: <alpine.BSF.2.00.1706181345060.53145@pedal.dcn.davis.ca.us>

I am not as expert as John, but I thought it worth pointing out that the 
variable substitution technique gives up one set of constraints for 
another (b=0 in this case). I also find that plots help me see what is 
going on, so here is my reproducible example (note inclusion of library 
calls for completeness). Note that NONE of the optimizers mentioned so far
appear to be finding the true best fit. The fact that myfun() yields 0 
always if t=0 and that condition is within the data given seems likely to 
be part of the problem. I don't know how to resolve this... perhaps John 
will look at it again.

David: Your thinking makes fine sense if you are using a Monte Carlo or 
brute force solution, but the fact that it creates a discontinuity in 
the objective function will confuse any optimizer that uses analytic or 
numerically estimated slopes.

##----------begin
library(minpack.lm)
library(ggplot2)

mydata <- data.frame( x = c( 0, 5, 9, 13, 17, 20 )
                     , y = c( 0, 11, 20, 29, 38, 45 )
                     )

myfun <- function( a, b, r, t ) {
   a * b * ( 1 - exp( -b * r * t ) )
}

objdta <- expand.grid( a = seq( 1000, 3000, by=20 )
                      , b = seq( -0.01, 1, 0.01 )
                      , rowidx = seq.int( nrow( mydata ) )
                      )
objdta[ , c( "y", "t" ) ] <- mydata[ objdta$rowidx
                                    , c( "y", "x" ) ]
objdta$tf <- factor( objdta$t )
objdta$myfun <- with( objdta
                     , myfun( a = a, b = b, r = 2, t = t )
                     )
objdtass <- aggregate( ( objdta$myfun - objdta$y )^2
                      , objdta[ , c( "a", "b" ) ]
                      , FUN = function( x )
                               sum( x, na.rm=TRUE )
                      )
objdtassmin <- objdtass[ which.min( objdtass$x ), ]

myfit <- nlsLM( y ~ myfun( a, b, r=2, t=x )
               , data = mydata
               , start = list( a = 2000
                             , b = 0.05
                             )
               , lower = c( 1000, 0 )
               , upper = c( 3000, 1 )
               )
a <- as.vector( coef( myfit )[ "a" ] )
b <- as.vector( coef( myfit )[ "b" ] )

brks <- c( 500, 1e7, 2e7, 3e7, 4e7 )
ggplot( objdtass, aes( x=a, y=b, z = x, fill=x ) ) +
     geom_tile() +
     geom_contour( breaks= brks ) +
     geom_point( x=a, y=b, colour="red" ) +
     geom_point( x=objdtassmin$a
               , y=objdtassmin$b
               , colour="green" ) +
     scale_fill_continuous( name="SumSq", breaks = brks )
# Green point is brute-force solution
# Red point is optimizer solution for myfun

##############

myfun2 <- function( a, log1ab, r, t ) {
   ab <- 1000 - exp( log1ab )
   ab * ( 1 - exp( -ab/a * r * t ) )
}

objdta$log1ab <- with( objdta, log( 1000 - a * b ) )
objdta$myfun2 <- with( objdta
                      , myfun2( a = a
                              , log1ab = log1ab
                              , r = 2
                              , t = t
                              )
                      )
objdtass2 <- aggregate( ( objdta$myfun2 - objdta$y )^2
                       , objdta[ , c( "a", "b" ) ]
                       , FUN = function( x )
                                if ( all( is.na( x ) ) ) NA
                                else sum( x, na.rm=TRUE )
                       )
objdtass2min <- objdtass2[ which.min( objdtass2$x ), ]

myfit2 <- nlsLM( y ~ myfun2( a, log1ab, r = 2, t = x )
                , data = mydata
                , start = list( a = 2000
                              , log1ab = 4.60517
                              )
                , lower = c( 1000, 0 )
                , upper = c( 3000, 8.0063 )
                )
a2 <- as.vector( coef( myfit2 )[ "a" ] )
b2 <- ( 1000
       - exp( as.vector( coef( myfit2 )[ "log1ab" ] ) )
       ) / a

brks <- c( 500, 1e6, 2e6, 3e6, 4e6 )
ggplot( objdtass2, aes( x=a, y=b, z = x, fill=x ) ) +
     geom_tile() +
     geom_contour( breaks = brks ) +
     geom_point( x=a2, y=b2, colour="red" ) +
     geom_point( x=objdtass2min$a
               , y=objdtass2min$b
               , colour="green" ) +
     scale_fill_continuous( name="SumSq", breaks = brks )
# Green point is brute-force solution
# Red point is optimizer solution for myfun2

##----------end

On Sun, 18 Jun 2017, J C Nash wrote:

> I ran the following script. I satisfied the constraint by
> making a*b a single parameter, which isn't always possible.
> I also ran nlxb() from nlsr package, and this gives singular
> values of the Jacobian. In the unconstrained case, the svs are
> pretty awful, and I wouldn't trust the results as a model, though
> the minimum is probably OK. The constrained result has a much
> larger sum of squares.
>
> Notes:
> 1) nlsr has been flagged with a check error by CRAN (though it
> is in the vignette, and also mentions pandoc a couple of times).
> I'm working to purge the "bug", and found one on our part, but
> not necessarily all the issues.
> 2) I used nlxb that requires an expression for the model. nlsLM
> can use a function because it is using derivative approximations,
> while nlxb actually gets a symbolic or automatic derivative if
> it can, else squawks.
>
> JN
>
> #  Here's the script #
> #
> # Manoranjan Muthusamy <ranjanmano167 at gmail.com>
> #
>
> library(minpack.lm)
> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>
> myfun=function(a,b,r,t){
>  prd=a*b*(1-exp(-b*r*t))
>  return(prd)}
>
> # and using nlsLM
>
> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>                  lower = c(1000,0), upper = c(3000,1))
> summary(myfit)
> library(nlsr)
> r <- 2
> myfitj=nlxb(y~a*b*(1-exp(-b*r*x)),data=mydata,start=list(a=2000,b=0.05), 
> trace=TRUE)
> summary(myfitj)
> print(myfitj)
>
> myfitj2<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05), 
> trace=TRUE)
> summary(myfitj2)
> print(myfitj2)
>
> myfitj2b<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05),
>                trace=TRUE, upper=c(1000, Inf))
> summary(myfitj2b)
> print(myfitj2b)
> # End of script #
>
> On 2017-06-18 01:29 PM, Bert Gunter wrote:
>> https://cran.r-project.org/web/views/Optimization.html
>> 
>> (Cran's optimization task view -- as always, you should search before 
>> posting)
>> 
>> In general, nonlinear optimization with nonlinear constraints is hard,
>> and the strategy used here (multiplying by a*b < 1000) may not work --
>> it introduces  a discontinuity into the objective function, so
>> gradient based methods may in particular be problematic.  As usual, if
>> either John Nash or Ravi Varadhan comment, heed what they suggest. I'm
>> pretty ignorant.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Sun, Jun 18, 2017 at 9:43 AM, David Winsemius <dwinsemius at comcast.net> 
>> wrote:
>>> 
>>>> On Jun 18, 2017, at 6:24 AM, Manoranjan Muthusamy 
>>>> <ranjanmano167 at gmail.com> wrote:
>>>> 
>>>> I am using nlsLM {minpack.lm} to find the values of parameters a and b of
>>>> function myfun which give the best fit for the data set, mydata.
>>>> 
>>>> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>>>> 
>>>> myfun=function(a,b,r,t){
>>>>   prd=a*b*(1-exp(-b*r*t))
>>>>   return(prd)}
>>>> 
>>>> and using nlsLM
>>>> 
>>>> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>                   lower = c(1000,0), upper = c(3000,1))
>>>> 
>>>> It works. But now I would like to introduce a constraint which is 
>>>> a*b<1000.
>>> 
>>> At the moment your coefficients do satisfy that constraint so that dataset 
>>> is not suitable for testing. A slight modification of the objective 
>>> function to include the logical constraint as an additional factor does 
>>> not "break" that particular solution.:
>>> 
>>> myfun2=function(a,b,r,t){
>>>      prd=a*b*(1-exp(-b*r*t))*(a*b<1000)
>>>      return(prd)}
>>> 
>>> 
>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>              lower = c(1000,0), upper = c(3000,1))
>>> 
>>> #------------------
>>> myfit
>>> Nonlinear regression model
>>>    model: y ~ myfun2(a, b, r = 2, t = x)
>>>     data: mydata
>>>          a         b
>>> 3.000e+03 2.288e-02
>>>   residual sum-of-squares: 38.02
>>> 
>>> Number of iterations to convergence: 8
>>> Achieved convergence tolerance: 1.49e-08
>>> #--
>>> 
>>> prod(coef(myfit))
>>> #[1] 68.64909  Same as original result.
>>> 
>>> How nlsLM will handle more difficult problems is not something I have 
>>> experience with, but obviously one would need to keep the starting values 
>>> within the feasible domain. However, if your goal was to also remove the 
>>> upper and lower constraints on a and b, This problem would not be suitably 
>>> solved by the a*b product without relaxation of the default maxiter:
>>> 
>>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>> +             lower = c(0,0), upper = c(9000,1))
>>>> prod(coef(myfit))
>>> [1] 110.4382
>>>> coef(myfit)
>>>             a            b
>>> 9.000000e+03 1.227091e-02
>>>
>>>>   myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>> +              lower = c(0,0), upper = c(10^6,1))
>>> Warning message:
>>> In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower = 
>>> lower,  :
>>>    lmdif: info = -1. Number of iterations has reached `maxiter' == 50.
>>> 
>>> #---------
>>>   myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>               lower = c(0,0), upper = c(10^6,1), 
>>> control=list(maxiter=100))
>>>   prod(coef(myfit))
>>>
>>>   coef(myfit)
>>> #============
>>> 
>>>
>>>>   prod(coef(myfit))
>>> [1] 780.6732  Significantly different than the solution at default maxiter 
>>> of 50.
>>>>
>>>>   coef(myfit)
>>>             a            b
>>> 5.319664e+05 1.467524e-03
>>>> 
>>>> 
>>> 
>>> 
>>> --
>>> David.
>>> 
>>> 
>>>> I had a look at the option available in nlsLM to set constraint via
>>>> nls.lm.control. But it's not much of help. can somebody help me here or
>>>> suggest a different method to to this?
>>>>
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From profjcnash at gmail.com  Mon Jun 19 00:47:49 2017
From: profjcnash at gmail.com (J C Nash)
Date: Sun, 18 Jun 2017 18:47:49 -0400
Subject: [R] R_using non linear regression with constraints
In-Reply-To: <alpine.BSF.2.00.1706181345060.53145@pedal.dcn.davis.ca.us>
References: <CANqyHbQJ8-hsKDJ59XkQE06aeJBFFB_-WhCYPPEvRH8N4o90bA@mail.gmail.com>
 <55935B3C-B8EA-460F-A758-6173F50C0F50@comcast.net>
 <CAGxFJbR-yTBF7aP2n+2MzNDqRg5r9D==2Jy+0K-D_mu0-Du6-w@mail.gmail.com>
 <20a31ecb-74a0-a90e-db44-33d127ff5387@gmail.com>
 <alpine.BSF.2.00.1706181345060.53145@pedal.dcn.davis.ca.us>
Message-ID: <01118db1-a424-d6e7-edf7-7c9ed95a9c87@gmail.com>

I've seen a number of problems like this over the years. The fact that the singular values of the Jacobian have
a ration larger than the usual convergence tolerances can mean the codes stop well before the best fit. That is
the "numerical analyst" view. David and Jeff have given geometric and statistical arguments. All views are useful,
but it takes some time to sort them all out and make sense of the problem as a whole. Right now I'm getting ready
to go to UseR!, so probably won't have time to spend sorting things out, though I'll have a go if I get time.

David: Did you get a crash with the Mac version of nlsr? (You have the latest version I uploaded to CRAN.)
I don't have Mac, just Linux and a very ancient Win XP. I suspect the latter is too old to take seriously. I use 
Win-Builder for package checks. I don't think there's anything seriously wrong with nlsr functions, but there is
more to be done to the vignettes and better manual pages are always desirable. It is the vignettes that are
popping up warnings on CRAN checks, and I'll see if I can fix those.

Cheers, JN


On 2017-06-18 06:23 PM, Jeff Newmiller wrote:
> I am not as expert as John, but I thought it worth pointing out that the variable substitution technique gives up one 
> set of constraints for another (b=0 in this case). I also find that plots help me see what is going on, so here is my 
> reproducible example (note inclusion of library calls for completeness). Note that NONE of the optimizers mentioned so far
> appear to be finding the true best fit. The fact that myfun() yields 0 always if t=0 and that condition is within the 
> data given seems likely to be part of the problem. I don't know how to resolve this... perhaps John will look at it again.
> 
> David: Your thinking makes fine sense if you are using a Monte Carlo or brute force solution, but the fact that it 
> creates a discontinuity in the objective function will confuse any optimizer that uses analytic or numerically estimated 
> slopes.
> 
> ##----------begin
> library(minpack.lm)
> library(ggplot2)
> 
> mydata <- data.frame( x = c( 0, 5, 9, 13, 17, 20 )
>                      , y = c( 0, 11, 20, 29, 38, 45 )
>                      )
> 
> myfun <- function( a, b, r, t ) {
>    a * b * ( 1 - exp( -b * r * t ) )
> }
> 
> objdta <- expand.grid( a = seq( 1000, 3000, by=20 )
>                       , b = seq( -0.01, 1, 0.01 )
>                       , rowidx = seq.int( nrow( mydata ) )
>                       )
> objdta[ , c( "y", "t" ) ] <- mydata[ objdta$rowidx
>                                     , c( "y", "x" ) ]
> objdta$tf <- factor( objdta$t )
> objdta$myfun <- with( objdta
>                      , myfun( a = a, b = b, r = 2, t = t )
>                      )
> objdtass <- aggregate( ( objdta$myfun - objdta$y )^2
>                       , objdta[ , c( "a", "b" ) ]
>                       , FUN = function( x )
>                                sum( x, na.rm=TRUE )
>                       )
> objdtassmin <- objdtass[ which.min( objdtass$x ), ]
> 
> myfit <- nlsLM( y ~ myfun( a, b, r=2, t=x )
>                , data = mydata
>                , start = list( a = 2000
>                              , b = 0.05
>                              )
>                , lower = c( 1000, 0 )
>                , upper = c( 3000, 1 )
>                )
> a <- as.vector( coef( myfit )[ "a" ] )
> b <- as.vector( coef( myfit )[ "b" ] )
> 
> brks <- c( 500, 1e7, 2e7, 3e7, 4e7 )
> ggplot( objdtass, aes( x=a, y=b, z = x, fill=x ) ) +
>      geom_tile() +
>      geom_contour( breaks= brks ) +
>      geom_point( x=a, y=b, colour="red" ) +
>      geom_point( x=objdtassmin$a
>                , y=objdtassmin$b
>                , colour="green" ) +
>      scale_fill_continuous( name="SumSq", breaks = brks )
> # Green point is brute-force solution
> # Red point is optimizer solution for myfun
> 
> ##############
> 
> myfun2 <- function( a, log1ab, r, t ) {
>    ab <- 1000 - exp( log1ab )
>    ab * ( 1 - exp( -ab/a * r * t ) )
> }
> 
> objdta$log1ab <- with( objdta, log( 1000 - a * b ) )
> objdta$myfun2 <- with( objdta
>                       , myfun2( a = a
>                               , log1ab = log1ab
>                               , r = 2
>                               , t = t
>                               )
>                       )
> objdtass2 <- aggregate( ( objdta$myfun2 - objdta$y )^2
>                        , objdta[ , c( "a", "b" ) ]
>                        , FUN = function( x )
>                                 if ( all( is.na( x ) ) ) NA
>                                 else sum( x, na.rm=TRUE )
>                        )
> objdtass2min <- objdtass2[ which.min( objdtass2$x ), ]
> 
> myfit2 <- nlsLM( y ~ myfun2( a, log1ab, r = 2, t = x )
>                 , data = mydata
>                 , start = list( a = 2000
>                               , log1ab = 4.60517
>                               )
>                 , lower = c( 1000, 0 )
>                 , upper = c( 3000, 8.0063 )
>                 )
> a2 <- as.vector( coef( myfit2 )[ "a" ] )
> b2 <- ( 1000
>        - exp( as.vector( coef( myfit2 )[ "log1ab" ] ) )
>        ) / a
> 
> brks <- c( 500, 1e6, 2e6, 3e6, 4e6 )
> ggplot( objdtass2, aes( x=a, y=b, z = x, fill=x ) ) +
>      geom_tile() +
>      geom_contour( breaks = brks ) +
>      geom_point( x=a2, y=b2, colour="red" ) +
>      geom_point( x=objdtass2min$a
>                , y=objdtass2min$b
>                , colour="green" ) +
>      scale_fill_continuous( name="SumSq", breaks = brks )
> # Green point is brute-force solution
> # Red point is optimizer solution for myfun2
> 
> ##----------end
> 
> On Sun, 18 Jun 2017, J C Nash wrote:
> 
>> I ran the following script. I satisfied the constraint by
>> making a*b a single parameter, which isn't always possible.
>> I also ran nlxb() from nlsr package, and this gives singular
>> values of the Jacobian. In the unconstrained case, the svs are
>> pretty awful, and I wouldn't trust the results as a model, though
>> the minimum is probably OK. The constrained result has a much
>> larger sum of squares.
>>
>> Notes:
>> 1) nlsr has been flagged with a check error by CRAN (though it
>> is in the vignette, and also mentions pandoc a couple of times).
>> I'm working to purge the "bug", and found one on our part, but
>> not necessarily all the issues.
>> 2) I used nlxb that requires an expression for the model. nlsLM
>> can use a function because it is using derivative approximations,
>> while nlxb actually gets a symbolic or automatic derivative if
>> it can, else squawks.
>>
>> JN
>>
>> #  Here's the script #
>> #
>> # Manoranjan Muthusamy <ranjanmano167 at gmail.com>
>> #
>>
>> library(minpack.lm)
>> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>>
>> myfun=function(a,b,r,t){
>>  prd=a*b*(1-exp(-b*r*t))
>>  return(prd)}
>>
>> # and using nlsLM
>>
>> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>                  lower = c(1000,0), upper = c(3000,1))
>> summary(myfit)
>> library(nlsr)
>> r <- 2
>> myfitj=nlxb(y~a*b*(1-exp(-b*r*x)),data=mydata,start=list(a=2000,b=0.05), trace=TRUE)
>> summary(myfitj)
>> print(myfitj)
>>
>> myfitj2<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05), trace=TRUE)
>> summary(myfitj2)
>> print(myfitj2)
>>
>> myfitj2b<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05),
>>                trace=TRUE, upper=c(1000, Inf))
>> summary(myfitj2b)
>> print(myfitj2b)
>> # End of script #
>>
>> On 2017-06-18 01:29 PM, Bert Gunter wrote:
>>> https://cran.r-project.org/web/views/Optimization.html
>>>
>>> (Cran's optimization task view -- as always, you should search before posting)
>>>
>>> In general, nonlinear optimization with nonlinear constraints is hard,
>>> and the strategy used here (multiplying by a*b < 1000) may not work --
>>> it introduces  a discontinuity into the objective function, so
>>> gradient based methods may in particular be problematic.  As usual, if
>>> either John Nash or Ravi Varadhan comment, heed what they suggest. I'm
>>> pretty ignorant.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>>
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sun, Jun 18, 2017 at 9:43 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>
>>>>> On Jun 18, 2017, at 6:24 AM, Manoranjan Muthusamy <ranjanmano167 at gmail.com> wrote:
>>>>>
>>>>> I am using nlsLM {minpack.lm} to find the values of parameters a and b of
>>>>> function myfun which give the best fit for the data set, mydata.
>>>>>
>>>>> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>>>>>
>>>>> myfun=function(a,b,r,t){
>>>>>   prd=a*b*(1-exp(-b*r*t))
>>>>>   return(prd)}
>>>>>
>>>>> and using nlsLM
>>>>>
>>>>> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>>                   lower = c(1000,0), upper = c(3000,1))
>>>>>
>>>>> It works. But now I would like to introduce a constraint which is a*b<1000.
>>>>
>>>> At the moment your coefficients do satisfy that constraint so that dataset is not suitable for testing. A slight 
>>>> modification of the objective function to include the logical constraint as an additional factor does not "break" 
>>>> that particular solution.:
>>>>
>>>> myfun2=function(a,b,r,t){
>>>>      prd=a*b*(1-exp(-b*r*t))*(a*b<1000)
>>>>      return(prd)}
>>>>
>>>>
>>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>              lower = c(1000,0), upper = c(3000,1))
>>>>
>>>> #------------------
>>>> myfit
>>>> Nonlinear regression model
>>>>    model: y ~ myfun2(a, b, r = 2, t = x)
>>>>     data: mydata
>>>>          a         b
>>>> 3.000e+03 2.288e-02
>>>>   residual sum-of-squares: 38.02
>>>>
>>>> Number of iterations to convergence: 8
>>>> Achieved convergence tolerance: 1.49e-08
>>>> #--
>>>>
>>>> prod(coef(myfit))
>>>> #[1] 68.64909  Same as original result.
>>>>
>>>> How nlsLM will handle more difficult problems is not something I have experience with, but obviously one would need 
>>>> to keep the starting values within the feasible domain. However, if your goal was to also remove the upper and lower 
>>>> constraints on a and b, This problem would not be suitably solved by the a*b product without relaxation of the 
>>>> default maxiter:
>>>>
>>>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>> +             lower = c(0,0), upper = c(9000,1))
>>>>> prod(coef(myfit))
>>>> [1] 110.4382
>>>>> coef(myfit)
>>>>             a            b
>>>> 9.000000e+03 1.227091e-02
>>>>
>>>>>   myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>> +              lower = c(0,0), upper = c(10^6,1))
>>>> Warning message:
>>>> In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower = lower,  :
>>>>    lmdif: info = -1. Number of iterations has reached `maxiter' == 50.
>>>>
>>>> #---------
>>>>   myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>               lower = c(0,0), upper = c(10^6,1), control=list(maxiter=100))
>>>>   prod(coef(myfit))
>>>>
>>>>   coef(myfit)
>>>> #============
>>>>
>>>>
>>>>>   prod(coef(myfit))
>>>> [1] 780.6732  Significantly different than the solution at default maxiter of 50.
>>>>>
>>>>>   coef(myfit)
>>>>             a            b
>>>> 5.319664e+05 1.467524e-03
>>>>>
>>>>>
>>>>
>>>>
>>>> -- 
>>>> David.
>>>>
>>>>
>>>>> I had a look at the option available in nlsLM to set constraint via
>>>>> nls.lm.control. But it's not much of help. can somebody help me here or
>>>>> suggest a different method to to this?
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From dwinsemius at comcast.net  Mon Jun 19 08:40:48 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Jun 2017 23:40:48 -0700
Subject: [R] R_using non linear regression with constraints
In-Reply-To: <01118db1-a424-d6e7-edf7-7c9ed95a9c87@gmail.com>
References: <CANqyHbQJ8-hsKDJ59XkQE06aeJBFFB_-WhCYPPEvRH8N4o90bA@mail.gmail.com>
 <55935B3C-B8EA-460F-A758-6173F50C0F50@comcast.net>
 <CAGxFJbR-yTBF7aP2n+2MzNDqRg5r9D==2Jy+0K-D_mu0-Du6-w@mail.gmail.com>
 <20a31ecb-74a0-a90e-db44-33d127ff5387@gmail.com>
 <alpine.BSF.2.00.1706181345060.53145@pedal.dcn.davis.ca.us>
 <01118db1-a424-d6e7-edf7-7c9ed95a9c87@gmail.com>
Message-ID: <D9FA79A5-AC18-4570-B84D-6A15D6529165@comcast.net>


> On Jun 18, 2017, at 3:47 PM, J C Nash <profjcnash at gmail.com> wrote:
> 
> I've seen a number of problems like this over the years. The fact that the singular values of the Jacobian have
> a ration larger than the usual convergence tolerances can mean the codes stop well before the best fit. That is
> the "numerical analyst" view. David and Jeff have given geometric and statistical arguments. All views are useful,
> but it takes some time to sort them all out and make sense of the problem as a whole. Right now I'm getting ready
> to go to UseR!, so probably won't have time to spend sorting things out, though I'll have a go if I get time.
> 
> David: Did you get a crash with the Mac version of nlsr? (You have the latest version I uploaded to CRAN.)

No. Everything proceeded without error.

> summary(myfitj)
$residuals
[1]  0.000000  0.229245  0.189927  0.130466  0.050909 -0.271920
attr(,"gradient")
              a      b
[1,] 0.0000e+00      0
[2,] 7.9014e-07  79784
[3,] 1.4207e-06 143370
[4,] 2.0498e-06 206741
[5,] 2.6774e-06 269898
[6,] 3.1473e-06 317126

$sigma
[1] 0.21341

$df
[1] 2 4

$cov.unscaled
   a  b
a NA NA
b NA NA

$param
    Estimate Std. Error t value Pr(>|t|)
a 1.4212e+07         NA      NA       NA
b 2.8129e-04         NA      NA       NA

$resname
[1] "myfitj"

$ssquares
[1] 0.18218

$nobs
[1] 6

$ct
[1] " " " "

$mt
[1] " " " "

$Sd
[1] 4.9301e+05 2.7070e-09

$gr
         [,1]
a -1.1226e-09
b -2.0297e-01

$jeval
[1] 525

$feval
[1] 656

attr(,"pkgname")
[1] "nlsr"
attr(,"class")
[1] "summary.nlsr"
> print(myfitj)
nlsr object: x 
residual sumsquares =  0.18218  on  6 observations
    after  525    Jacobian and  656 function evaluations
  name            coeff          SE       tstat      pval      gradient    JSingval   
a               14211701            NA         NA         NA  -1.123e-09      493005  
b            0.000281292            NA         NA         NA      -0.203   2.707e-09  

And (after considerable "verbosity":

> summary(myfitj2)
$residuals
[1]  0.000000  0.195004  0.149715  0.103277  0.055691 -0.230752
attr(,"gradient")
             ab       b
[1,] 0.00000000       0
[2,] 0.00016034  698106
[3,] 0.00028859 1256430
[4,] 0.00041682 1814611
[5,] 0.00054504 2372649
[6,] 0.00064119 2791083

$sigma
[1] 0.1785

$df
[1] 2 4

$cov.unscaled
   ab  b
ab NA NA
b  NA NA

$param
     Estimate Std. Error t value Pr(>|t|)
ab 6.9822e+04         NA      NA       NA
b  1.6035e-05         NA      NA       NA

$resname
[1] "myfitj2"

$ssquares
[1] 0.12746

$nobs
[1] 6

$ct
[1] " " " "

$mt
[1] " " " "

$Sd
[1] 4.3293e+06 6.2886e-08

$gr
          [,1]
ab -8.2085e-08
b  -2.6333e+02

$jeval
[1] 736

$feval
[1] 1024

attr(,"pkgname")
[1] "nlsr"
attr(,"class")
[1] "summary.nlsr"
> print(myfitj2)
nlsr object: x 
residual sumsquares =  0.12746  on  6 observations
    after  736    Jacobian and  1024 function evaluations
  name            coeff          SE       tstat      pval      gradient    JSingval   
ab               69821.8            NA         NA         NA  -8.208e-08     4329320  
b             1.6035e-05            NA         NA         NA      -263.3   6.289e-08  

The estimates were the same order of magnitude but off by a factor of 3 or so. I wondered whether some sort of scaling would have improved the estimates. I did try plotting the geometric picture I imagined using `persp`, but my R-fu was weak.

Best;
David.



> I don't have Mac, just Linux and a very ancient Win XP. I suspect the latter is too old to take seriously. I use Win-Builder for package checks. I don't think there's anything seriously wrong with nlsr functions, but there is
> more to be done to the vignettes and better manual pages are always desirable. It is the vignettes that are
> popping up warnings on CRAN checks, and I'll see if I can fix those.
> 
> Cheers, JN
> 
> 
> On 2017-06-18 06:23 PM, Jeff Newmiller wrote:
>> I am not as expert as John, but I thought it worth pointing out that the variable substitution technique gives up one set of constraints for another (b=0 in this case). I also find that plots help me see what is going on, so here is my reproducible example (note inclusion of library calls for completeness). Note that NONE of the optimizers mentioned so far
>> appear to be finding the true best fit. The fact that myfun() yields 0 always if t=0 and that condition is within the data given seems likely to be part of the problem. I don't know how to resolve this... perhaps John will look at it again.
>> David: Your thinking makes fine sense if you are using a Monte Carlo or brute force solution, but the fact that it creates a discontinuity in the objective function will confuse any optimizer that uses analytic or numerically estimated slopes.
>> ##----------begin
>> library(minpack.lm)
>> library(ggplot2)
>> mydata <- data.frame( x = c( 0, 5, 9, 13, 17, 20 )
>>                     , y = c( 0, 11, 20, 29, 38, 45 )
>>                     )
>> myfun <- function( a, b, r, t ) {
>>   a * b * ( 1 - exp( -b * r * t ) )
>> }
>> objdta <- expand.grid( a = seq( 1000, 3000, by=20 )
>>                      , b = seq( -0.01, 1, 0.01 )
>>                      , rowidx = seq.int( nrow( mydata ) )
>>                      )
>> objdta[ , c( "y", "t" ) ] <- mydata[ objdta$rowidx
>>                                    , c( "y", "x" ) ]
>> objdta$tf <- factor( objdta$t )
>> objdta$myfun <- with( objdta
>>                     , myfun( a = a, b = b, r = 2, t = t )
>>                     )
>> objdtass <- aggregate( ( objdta$myfun - objdta$y )^2
>>                      , objdta[ , c( "a", "b" ) ]
>>                      , FUN = function( x )
>>                               sum( x, na.rm=TRUE )
>>                      )
>> objdtassmin <- objdtass[ which.min( objdtass$x ), ]
>> myfit <- nlsLM( y ~ myfun( a, b, r=2, t=x )
>>               , data = mydata
>>               , start = list( a = 2000
>>                             , b = 0.05
>>                             )
>>               , lower = c( 1000, 0 )
>>               , upper = c( 3000, 1 )
>>               )
>> a <- as.vector( coef( myfit )[ "a" ] )
>> b <- as.vector( coef( myfit )[ "b" ] )
>> brks <- c( 500, 1e7, 2e7, 3e7, 4e7 )
>> ggplot( objdtass, aes( x=a, y=b, z = x, fill=x ) ) +
>>     geom_tile() +
>>     geom_contour( breaks= brks ) +
>>     geom_point( x=a, y=b, colour="red" ) +
>>     geom_point( x=objdtassmin$a
>>               , y=objdtassmin$b
>>               , colour="green" ) +
>>     scale_fill_continuous( name="SumSq", breaks = brks )
>> # Green point is brute-force solution
>> # Red point is optimizer solution for myfun
>> ##############
>> myfun2 <- function( a, log1ab, r, t ) {
>>   ab <- 1000 - exp( log1ab )
>>   ab * ( 1 - exp( -ab/a * r * t ) )
>> }
>> objdta$log1ab <- with( objdta, log( 1000 - a * b ) )
>> objdta$myfun2 <- with( objdta
>>                      , myfun2( a = a
>>                              , log1ab = log1ab
>>                              , r = 2
>>                              , t = t
>>                              )
>>                      )
>> objdtass2 <- aggregate( ( objdta$myfun2 - objdta$y )^2
>>                       , objdta[ , c( "a", "b" ) ]
>>                       , FUN = function( x )
>>                                if ( all( is.na( x ) ) ) NA
>>                                else sum( x, na.rm=TRUE )
>>                       )
>> objdtass2min <- objdtass2[ which.min( objdtass2$x ), ]
>> myfit2 <- nlsLM( y ~ myfun2( a, log1ab, r = 2, t = x )
>>                , data = mydata
>>                , start = list( a = 2000
>>                              , log1ab = 4.60517
>>                              )
>>                , lower = c( 1000, 0 )
>>                , upper = c( 3000, 8.0063 )
>>                )
>> a2 <- as.vector( coef( myfit2 )[ "a" ] )
>> b2 <- ( 1000
>>       - exp( as.vector( coef( myfit2 )[ "log1ab" ] ) )
>>       ) / a
>> brks <- c( 500, 1e6, 2e6, 3e6, 4e6 )
>> ggplot( objdtass2, aes( x=a, y=b, z = x, fill=x ) ) +
>>     geom_tile() +
>>     geom_contour( breaks = brks ) +
>>     geom_point( x=a2, y=b2, colour="red" ) +
>>     geom_point( x=objdtass2min$a
>>               , y=objdtass2min$b
>>               , colour="green" ) +
>>     scale_fill_continuous( name="SumSq", breaks = brks )
>> # Green point is brute-force solution
>> # Red point is optimizer solution for myfun2
>> ##----------end
>> On Sun, 18 Jun 2017, J C Nash wrote:
>>> I ran the following script. I satisfied the constraint by
>>> making a*b a single parameter, which isn't always possible.
>>> I also ran nlxb() from nlsr package, and this gives singular
>>> values of the Jacobian. In the unconstrained case, the svs are
>>> pretty awful, and I wouldn't trust the results as a model, though
>>> the minimum is probably OK. The constrained result has a much
>>> larger sum of squares.
>>> 
>>> Notes:
>>> 1) nlsr has been flagged with a check error by CRAN (though it
>>> is in the vignette, and also mentions pandoc a couple of times).
>>> I'm working to purge the "bug", and found one on our part, but
>>> not necessarily all the issues.
>>> 2) I used nlxb that requires an expression for the model. nlsLM
>>> can use a function because it is using derivative approximations,
>>> while nlxb actually gets a symbolic or automatic derivative if
>>> it can, else squawks.
>>> 
>>> JN
>>> 
>>> #  Here's the script #
>>> #
>>> # Manoranjan Muthusamy <ranjanmano167 at gmail.com>
>>> #
>>> 
>>> library(minpack.lm)
>>> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>>> 
>>> myfun=function(a,b,r,t){
>>> prd=a*b*(1-exp(-b*r*t))
>>> return(prd)}
>>> 
>>> # and using nlsLM
>>> 
>>> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>                 lower = c(1000,0), upper = c(3000,1))
>>> summary(myfit)
>>> library(nlsr)
>>> r <- 2
>>> myfitj=nlxb(y~a*b*(1-exp(-b*r*x)),data=mydata,start=list(a=2000,b=0.05), trace=TRUE)
>>> summary(myfitj)
>>> print(myfitj)
>>> 
>>> myfitj2<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05), trace=TRUE)
>>> summary(myfitj2)
>>> print(myfitj2)
>>> 
>>> myfitj2b<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05),
>>>               trace=TRUE, upper=c(1000, Inf))
>>> summary(myfitj2b)
>>> print(myfitj2b)
>>> # End of script #
>>> 
>>> On 2017-06-18 01:29 PM, Bert Gunter wrote:
>>>> https://cran.r-project.org/web/views/Optimization.html
>>>> 
>>>> (Cran's optimization task view -- as always, you should search before posting)
>>>> 
>>>> In general, nonlinear optimization with nonlinear constraints is hard,
>>>> and the strategy used here (multiplying by a*b < 1000) may not work --
>>>> it introduces  a discontinuity into the objective function, so
>>>> gradient based methods may in particular be problematic.  As usual, if
>>>> either John Nash or Ravi Varadhan comment, heed what they suggest. I'm
>>>> pretty ignorant.
>>>> 
>>>> Cheers,
>>>> Bert
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> 
>>>> On Sun, Jun 18, 2017 at 9:43 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>> 
>>>>>> On Jun 18, 2017, at 6:24 AM, Manoranjan Muthusamy <ranjanmano167 at gmail.com> wrote:
>>>>>> 
>>>>>> I am using nlsLM {minpack.lm} to find the values of parameters a and b of
>>>>>> function myfun which give the best fit for the data set, mydata.
>>>>>> 
>>>>>> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>>>>>> 
>>>>>> myfun=function(a,b,r,t){
>>>>>>  prd=a*b*(1-exp(-b*r*t))
>>>>>>  return(prd)}
>>>>>> 
>>>>>> and using nlsLM
>>>>>> 
>>>>>> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>>>                  lower = c(1000,0), upper = c(3000,1))
>>>>>> 
>>>>>> It works. But now I would like to introduce a constraint which is a*b<1000.
>>>>> 
>>>>> At the moment your coefficients do satisfy that constraint so that dataset is not suitable for testing. A slight modification of the objective function to include the logical constraint as an additional factor does not "break" that particular solution.:
>>>>> 
>>>>> myfun2=function(a,b,r,t){
>>>>>     prd=a*b*(1-exp(-b*r*t))*(a*b<1000)
>>>>>     return(prd)}
>>>>> 
>>>>> 
>>>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>>             lower = c(1000,0), upper = c(3000,1))
>>>>> 
>>>>> #------------------
>>>>> myfit
>>>>> Nonlinear regression model
>>>>>   model: y ~ myfun2(a, b, r = 2, t = x)
>>>>>    data: mydata
>>>>>         a         b
>>>>> 3.000e+03 2.288e-02
>>>>>  residual sum-of-squares: 38.02
>>>>> 
>>>>> Number of iterations to convergence: 8
>>>>> Achieved convergence tolerance: 1.49e-08
>>>>> #--
>>>>> 
>>>>> prod(coef(myfit))
>>>>> #[1] 68.64909  Same as original result.
>>>>> 
>>>>> How nlsLM will handle more difficult problems is not something I have experience with, but obviously one would need to keep the starting values within the feasible domain. However, if your goal was to also remove the upper and lower constraints on a and b, This problem would not be suitably solved by the a*b product without relaxation of the default maxiter:
>>>>> 
>>>>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>> +             lower = c(0,0), upper = c(9000,1))
>>>>>> prod(coef(myfit))
>>>>> [1] 110.4382
>>>>>> coef(myfit)
>>>>>            a            b
>>>>> 9.000000e+03 1.227091e-02
>>>>> 
>>>>>>  myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>> +              lower = c(0,0), upper = c(10^6,1))
>>>>> Warning message:
>>>>> In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower = lower,  :
>>>>>   lmdif: info = -1. Number of iterations has reached `maxiter' == 50.
>>>>> 
>>>>> #---------
>>>>>  myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>>              lower = c(0,0), upper = c(10^6,1), control=list(maxiter=100))
>>>>>  prod(coef(myfit))
>>>>> 
>>>>>  coef(myfit)
>>>>> #============
>>>>> 
>>>>> 
>>>>>>  prod(coef(myfit))
>>>>> [1] 780.6732  Significantly different than the solution at default maxiter of 50.
>>>>>> 
>>>>>>  coef(myfit)
>>>>>            a            b
>>>>> 5.319664e+05 1.467524e-03
>>>>>> 
>>>>>> 
>>>>> 
>>>>> 
>>>>> -- 
>>>>> David.
>>>>> 
>>>>> 
>>>>>> I had a look at the option available in nlsLM to set constraint via
>>>>>> nls.lm.control. But it's not much of help. can somebody help me here or
>>>>>> suggest a different method to to this?
>>>>>> 
>>>>>>       [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------

David Winsemius
Alameda, CA, USA


From paulbernal07 at gmail.com  Mon Jun 19 21:07:25 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Mon, 19 Jun 2017 14:07:25 -0500
Subject: [R] How to Transform a Factor Variable into a Date
Message-ID: <CAMOcQfMjpRU9KE7JEi=eXmu0jzhnx6QeBBBDPaEtWpOZo11AYA@mail.gmail.com>

Dear all,

Hope you are doing great. I have a .csv file that I read into R, the .csv
file consistss of two fields (TransitDate and CargoTons).

The TransitDate I formatted from Excel in the fashion mmm-yy (e.g.:
Apr-2013). However R does not recognize the field TransitDate as a date
field.

Here is the code:

library(lubridate)

Dataset <- read.table("U:/NEWCargoData.csv", header=TRUE, sep=",",
na.strings="NA", dec=".", strip.white=TRUE)

DatasetFrame <- data.frame(Dataset)

DatasetFrame$TransitDate <- as.Date(DatasetFrame$TransitDate, format =
"%b-%y")


Now, when I do DatasetFrame[1,1], the following happens:


> DatasetFrame[1,1]
[1] NA
>
> DatasetFrame[2,1]
[1] NA
>

Now when I do:

> Dataset[1,1] #this is the dataset as was read from my computer
[1] Jun-11
62 Levels: Apr-13 Apr-14 Apr-15 Apr-16 Apr-17 Aug-13 Aug-14 Aug-15 Aug-16
Dec-12 Dec-13 Dec-14 ... Sep-16
>

I am also attaching the .csv file for your reference. How can I do to get R
to convert TransitDate into an actual date  field? R is not recognizing it
as a date.

Any help will be greatly appreciated,

Best regards,

Paul

From brukalinis at gmail.com  Mon Jun 19 13:57:06 2017
From: brukalinis at gmail.com (Madison Lincoln)
Date: Mon, 19 Jun 2017 13:57:06 +0200
Subject: [R] quantreg::rq.fit.hogg crashing at random
In-Reply-To: <CAP05FR-WFeEAh6hw3_qPJtYjH127ccZy43SXHNu1m5mAvTbkcw@mail.gmail.com>
References: <CAP05FR-WFeEAh6hw3_qPJtYjH127ccZy43SXHNu1m5mAvTbkcw@mail.gmail.com>
Message-ID: <CAP05FR-kub5ZthuajTLiU0RovrgeoHvG2=E_5_XkLGmTEnACxQ@mail.gmail.com>

Dear all,

I am using the "rq.fit.hogg" function from the "quantreg" package. I have
two problems with it.

First (less importantly), it gives an error at its default values with
error message "Error in if (n2 != length(r)) stop("R and r of incompatible
dimension") : argument is of length zero". I solve this by commenting four
lines in the code. I.e. I define a new function "rq.fit.hogg2" that is the
same as "rq.fit.hogg" but with four lines commented. You will see this in
my code at the end of this post. I understand why this solution works, so
it is not really a problem right now.

Second (importantly), "rq.fit.hogg" crashes frequently. The message I get
is "R for Windows GUI front-end has stopped working. A problem cause the
program to stop working correctly. Windows will close the program and
notify you if a solution is available."

I don't know how to provide a reproducible example of the crash because the
function seems to crash at random. That is, I generate some data (with a
fixed seed so that I can replicate it exactly), input into the function,
and sometimes it crashes but sometimes not. If I create a loop over
different seeds and run the function once in each iteration, sometimes it
crashes on the first iteration while sometimes it goes fine for some 20
iterations and crashes only then.

I am including the code with the loop that should eventually produce a
crash. If it does not, try running it again; that worked every time for me.
I am also including session info and locale info.

Please help me. Thank you!

Kind regards,


*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*

Here are my session details etc.:

> Sys.getlocale()
[1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United
States.1252"

> sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 14393)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] quantreg_5.33 SparseM_1.77  MASS_7.3-47

loaded via a namespace (and not attached):
[1] compiler_3.4.0     Matrix_1.2-10      MatrixModels_0.4-1 grid_3.4.0

[5] lattice_0.20-35

*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*

Here is the code that crashes:

#-----Here I redefine the function as described in my first paragraph

rq.fit.hogg2 = function (x, y, taus = c(0.1, 0.3, 0.5), weights = c(0.7,
0.2, 0.1), R = NULL, r = NULL, beta = 0.99995, eps = 1e-06)
{
    n <- length(y)
    n2 <- nrow(R)
    m <- length(taus)
    p <- ncol(x) + m
    if (n != nrow(x))
        stop("x and y don't match n")
    if (m != length(weights))
        stop("taus and weights differ in length")
    if (any(taus < eps) || any(taus > 1 - eps))
        stop("taus outside (0,1)")
    W <- diag(weights)
    if (m == 1)
        W <- weights
    x <- as.matrix(x)
    X <- cbind(kronecker(W, rep(1, n)), kronecker(weights, x))
    y <- kronecker(weights, y)
    rhs <- c(weights * (1 - taus) * n, sum(weights * (1 - taus)) *
        apply(x, 2, sum))
#    if (n2 != length(r))
#        stop("R and r of incompatible dimension")
#    if (ncol(R) != p)
#        stop("R and X of incompatible dimension")
    d <- rep(1, m * n)
    u <- rep(1, m * n)
    if (length(r)) {
        wn1 <- rep(0, 10 * m * n)
        wn1[1:(m * n)] <- 0.5
        wn2 <- rep(0, 6 * n2)
        wn2[1:n2] <- 1
        z <- .Fortran("rqfnc", as.integer(m * n), as.integer(n2),
            as.integer(p), a1 = as.double(t(as.matrix(X))), c1 =
as.double(-y),
            a2 = as.double(t(as.matrix(R))), c2 = as.double(-r),
            rhs = as.double(rhs), d1 = double(m * n), d2 = double(n2),
            as.double(u), beta = as.double(beta), eps = as.double(eps),
            wn1 = as.double(wn1), wn2 = as.double(wn2), wp = double((p +
                3) * p), it.count = integer(3), info = integer(1))
    }
    else {
        wn <- rep(0, 10 * m * n)
        wn[1:(m * n)] <- 0.5
        z <- .Fortran("rqfnb", as.integer(m * n), as.integer(p),
            a = as.double(t(as.matrix(X))), c = as.double(-y),
            rhs = as.double(rhs), d = as.double(d), as.double(u),
            beta = as.double(beta), eps = as.double(eps), wn =
as.double(wn),
            wp = double((p + 3) * p), it.count = integer(2),
            info = integer(1))
    }
    if (z$info != 0)
        warning(paste("Info = ", z$info, "in stepy: singular design:
iterations ",
            z$it.count[1]))
    coefficients <- -z$wp[1:p]
    if (any(is.na(coefficients)))
        stop("NA coefs:  infeasible problem?")
    list(coefficients = coefficients, nit = z$it.count, flag = z$info)
}

#----- Here is the main program that crashes

library(MASS)
library(quantreg)

M=1e3; n=1e3; p=15; type=8; K=10 # no. of replications, sample size,
dimension of beta, type of quantile estimator, number of quantiles
distributions=c("norm","t1","t2","t3","t5","logistic","
exponential","Weibull")
method.wqr="fn" # interior point method; if "fn" then roughly matches with
method.cqr="ip"

# Create the covariance matrix of X
Sigma=matrix(NA,p,p); for(i in 1:p) for(j in 1:p) Sigma[i,j]=0.5^(abs(i-j))
# Generate X (common across all simulations)
set.seed(0); X=mvrnorm(n=n,mu=rep(0,p),Sigma=Sigma)

Binvlist=list()
for(k in 1:K){
 tau=cumsum(rep(1/(k+1),k))
 Ai=matrix(rep(tau,k),nrow=k,ncol=k,byrow=TRUE)
 Aj=matrix(rep(tau,k),nrow=k,ncol=k,byrow=FALSE)
 Amin=pmin(Ai,Aj) # Amin=Ai; Amin[Ai>Aj]=Aj[Ai>Aj]
 Ax=tau %*% t(tau)
 B=Amin-Ax
 Binvlist[[k]]=solve(B)
}

for(m in 1:M){

mse_wqr_list=mse_cqr_list=list()
j=0; for(distr in distributions){

 j=j+1
 #print(distributions[col])
 mse_wqr_list[[j]]=mse_cqr_list[[j]]=matrix(NA,M,K)
 set.seed(m); beta=rnorm(p)
 set.seed(m+1000000000)
 if(distr=="norm"       ) eps=rnorm(n)
 if(substr(x=distr,start=1,stop=1)=="t"){
df=as.numeric(substr(x=distr,start=2,stop=nchar(distr)));
eps=rt(n,df=df) }
 if(distr=="logistic"   ) eps=rlogis(n)
 if(distr=="exponential") eps=rexp(n)
 if(distr=="Weibull"    ) eps=rweibull(n,shape=1.5)
 y=X%*%beta+eps
 model=lm(y~X); res=model$res; d=density(res)

 mse_wqr=mse_cqr=rep(NA,K)
 for(k in 1:K){

  #----- Find estimated optimal weights
  tau=cumsum(rep(1/(k+1),k))
  Binv=Binvlist[[k]]
   q = quantile(res,probs=tau,type=type) # Hyndman recommends `type=8` for
the `quantile` function
   tmp=as.numeric(c(d$x,q)); ranks=rank(tmp);
below=tail(ranks,length(q))-c(1:length(q));
above=below+1
   v = d$y[below] * (q-d$x[below])/(d$x[above]-d$x[below]) + d$y[above] *
(d$x[above]-q)/(d$x[above]-d$x[below])
   if(k==1) V = matrix(v,1,1) else V = diag(v)
  w_CQR = Binv %*% v; w_CQR = w_CQR / sum(w_CQR)

  #----- Use the estimated optimal weights to actually estimate beta (with
EQR and CQR) and evaluate how well it does
  print(paste(m, distr, k)); readline()
  ################ THE NEXT LINE CRASHES AT RANDOM:
  fit_cqr=try( rq.fit.hogg2(x=cbind(X),y=y,taus=tau,weights=c(w_CQR)) )

 } # for(k in 1:K)

} # for(distr in distributions)

} # for(m in 1:M)

	[[alternative HTML version deleted]]


From shelby_leonard26 at yahoo.com  Mon Jun 19 18:29:30 2017
From: shelby_leonard26 at yahoo.com (Shelby Leonard)
Date: Mon, 19 Jun 2017 16:29:30 +0000 (UTC)
Subject: [R] mixed models lmer function help!!
References: <205314894.1478790.1497889770829.ref@mail.yahoo.com>
Message-ID: <205314894.1478790.1497889770829@mail.yahoo.com>

Hi,I have tumor growth curve data for a bunch of different mice in various groups. I want to compare the growth curves of the different groups to see if timing of drug delivery changed tumor growth.I am trying to run a mixed models with repeated measures over time with each mouse as a random effect with linear and quadratic terms for time.This took me a long time to figure out and I just wanted to make sure I did it correctly and I am interpreting it correctly. This is the code I ran
Rtumor<-lmer(volume~Group+Time+(1|Subject), data=Rtumor)summary(Rtumor)Rtumor.null=lmer(volume~Time+(1|Subject), data=Rtumor, REML=FALSE)Rtumor.full=lmer(volume~Group+Time+(1|Subject), data=Rtumor, REML=FALSE)anova(Rtumor.null,Rtumor.full)
Here is my output?Rtumor<-lmer(volume~Group+Time+(1|Subject), data=Rtumor)> summary(Rtumor)Linear mixed model fit by REML ['lmerMod']Formula: volume ~ Group + Time + (1 | Subject)? ?Data: Rtumor
REML criterion at convergence: 1541.2
Scaled residuals:?? ? Min ? ? ?1Q ?Median ? ? ?3Q ? ? Max?-1.8006 -0.6348 -0.0658 ?0.3903 ?4.7551?
Random effects:?Groups ? Name ? ? ? ?Variance ?Std.Dev.??Subject ?(Intercept) 3.197e-09 5.654e-05?Residual ? ? ? ? ? ? 3.348e+05 5.786e+02Number of obs: 101, groups: ?Subject, 11
Fixed effects:? ? ? ? ? ? Estimate Std. Error t value(Intercept) -495.520 ? ?303.619 ?-1.632Group ? ? ? ? 24.350 ? ?115.615 ? 0.211Time ? ? ? ? ?79.653 ? ? ?7.886 ?10.101
Correlation of Fixed Effects:? ? ? (Intr) Group?Group -0.933 ? ? ??Time ?-0.300 -0.007
> Rtumor.null=lmer(volume~Time+(1|Subject), data=Rtumor, REML=FALSE)> Rtumor.full=lmer(volume~Group+Time+(1|Subject), data=Rtumor, REML=FALSE)> anova(Rtumor.null,Rtumor.full)Data: RtumorModels:Rtumor.null: volume ~ Time + (1 | Subject)Rtumor.full: volume ~ Group + Time + (1 | Subject)? ? ? ? ? ? Df ? ?AIC ? ?BIC ?logLik deviance ?Chisq Chi Df Pr(>Chisq)Rtumor.null ?4 1576.5 1586.9 -784.24 ? 1568.5 ? ? ? ? ? ? ? ? ? ? ? ??Rtumor.full ?5 1578.4 1591.5 -784.22 ? 1568.4 0.0457 ? ? ?1 ? ? 0.8307There were 50 or more warnings (use warnings() to see the first 50)


My questions are1) Did I do this correctly?2) Do I still need to run it again with quadratic terms for time?, If so, how do I do this?3) If I am understanding these results correctly, they say There is no difference between these groups on volume growth curves
	[[alternative HTML version deleted]]


From wjm1 at caa.columbia.edu  Mon Jun 19 21:15:17 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Mon, 19 Jun 2017 12:15:17 -0700
Subject: [R] write.dna command
In-Reply-To: <CAAWqvsekQNZ4TsCCXzeqnwos6CupKwR2Rw-1W=HRE-Vz=mN83A@mail.gmail.com>
References: <CAAWqvsekQNZ4TsCCXzeqnwos6CupKwR2Rw-1W=HRE-Vz=mN83A@mail.gmail.com>
Message-ID: <CAA99HCxhJHAhO3MyJxQtSPKSnX17LUnVHM=-QM+HLwJWvMjqsA@mail.gmail.com>

Hi Mogjib,

Does the following solve your issue?

> setwd(WD)



On Sat, Jun 17, 2017 at 7:26 AM, Mogjib Salek <mogjibs at gmail.com> wrote:

> Hi all,
>
> I am learning R by "doing". And this is my first post.
>
> I want to use R: 1- to fetch a DNA sequence from a databank (see bellow)
> and 2- store it as FASTA file.
>
> The problem: neither an error is prompted nor the fasta file is created.
> Testing the code (see bellow), I notice that everything works until
> the *"write.dna"
> *command - which is not creating the fasta file.
>
> Here is my code:
>
> ####Get gene sequence from GenBank and store it as fasta file
> ####16 June 2017
>
> #1- Set the working directory and make sure the right libraries are
> installed
> (make sure 'ape' and 'seqinr' packages are installed)
>
> WD <- "~Documents/Scripting/R_Studio/Sequences/"
> setwd <- (WD)
>
> #2- Fetch a sequence ( bellow, "enter  manually the desired DNA ID") from
> GenBank and store it as fasta file.
>
>       DNAid <- "JF806202"
>
>     # Store the sequence in lst (a list)
>       lst <- read.GenBank(DNAid, as.character = T)
>
>       # convert the sequence to fasta format
>        write.dna (lst, file = "DNAseq.fasta", format = "fasta", append =
> FALSE,
>            nbcol= 6, colsep= " ", colw= 10)
>
>
> Any help will be appreciated.
> Thank you.
>
> Kelas
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cryan at binghamton.edu  Mon Jun 19 21:30:30 2017
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Mon, 19 Jun 2017 15:30:30 -0400
Subject: [R] How to Transform a Factor Variable into a Date
In-Reply-To: <CAMOcQfMjpRU9KE7JEi=eXmu0jzhnx6QeBBBDPaEtWpOZo11AYA@mail.gmail.com>
References: <CAMOcQfMjpRU9KE7JEi=eXmu0jzhnx6QeBBBDPaEtWpOZo11AYA@mail.gmail.com>
Message-ID: <CAM+rpY=_51aVjS3x5ntrN_UGaQK06kPsiEbvQL_w96Z8tg-3Dw@mail.gmail.com>

A couple thoughts:

1. converting factors into dates often requires that they be converted to
character first.

2. you don't really have dates; you have just months and years

3. therefore perhaps the as.yearmon() function in the zoo package could help

library(zoo)
my.factor <- factor("Feb 2017")
as.yearmon(my.factor)  ## gets around the factor-vs-character issue


On Mon, Jun 19, 2017 at 3:07 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear all,
>
> Hope you are doing great. I have a .csv file that I read into R, the .csv
> file consistss of two fields (TransitDate and CargoTons).
>
> The TransitDate I formatted from Excel in the fashion mmm-yy (e.g.:
> Apr-2013). However R does not recognize the field TransitDate as a date
> field.
>
> Here is the code:
>
> library(lubridate)
>
> Dataset <- read.table("U:/NEWCargoData.csv", header=TRUE, sep=",",
> na.strings="NA", dec=".", strip.white=TRUE)
>
> DatasetFrame <- data.frame(Dataset)
>
> DatasetFrame$TransitDate <- as.Date(DatasetFrame$TransitDate, format =
> "%b-%y")
>
>
> Now, when I do DatasetFrame[1,1], the following happens:
>
>
> > DatasetFrame[1,1]
> [1] NA
> >
> > DatasetFrame[2,1]
> [1] NA
> >
>
> Now when I do:
>
> > Dataset[1,1] #this is the dataset as was read from my computer
> [1] Jun-11
> 62 Levels: Apr-13 Apr-14 Apr-15 Apr-16 Apr-17 Aug-13 Aug-14 Aug-15 Aug-16
> Dec-12 Dec-13 Dec-14 ... Sep-16
> >
>
> I am also attaching the .csv file for your reference. How can I do to get R
> to convert TransitDate into an actual date  field? R is not recognizing it
> as a date.
>
> Any help will be greatly appreciated,
>
> Best regards,
>
> Paul
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Jun 19 22:05:39 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 19 Jun 2017 21:05:39 +0100
Subject: [R] How to Transform a Factor Variable into a Date
In-Reply-To: <CAM+rpY=_51aVjS3x5ntrN_UGaQK06kPsiEbvQL_w96Z8tg-3Dw@mail.gmail.com>
References: <CAMOcQfMjpRU9KE7JEi=eXmu0jzhnx6QeBBBDPaEtWpOZo11AYA@mail.gmail.com>
 <CAM+rpY=_51aVjS3x5ntrN_UGaQK06kPsiEbvQL_w96Z8tg-3Dw@mail.gmail.com>
Message-ID: <59482E93.7020807@sapo.pt>

Hello,

Another way of getting dates, of class 'Date', is to paste a day "01" 
into what the op has.
To the op:
1) Your attachment didn't come through, R-Help doesn't accept the 
extension .csv, use .txt
2) When you read your data in using function read.csv the result already 
is a data.frame so the instruction

DatasetFrame <- data.frame(Dataset)

is not needed.
3) You can read the data and create a data.frame without the problem of 
getting factors instead of characters, just set option

stringsAsFactors = FALSE

in your calls to read.*

And now some code. Note that I've made up some data, since we don't have 
the .csv file.


x <- "Jun-11"
Dataset <- data.frame(x)
str(Dataset)

tmp <- paste("01", as.character(Dataset$x), sep = "-")
Dataset$x <- as.Date(tmp, format = "%d-%b-%y")
str(Dataset)


Hope this helps,

Rui Barradas

Em 19-06-2017 20:30, Christopher W Ryan escreveu:
> A couple thoughts:
>
> 1. converting factors into dates often requires that they be converted to
> character first.
>
> 2. you don't really have dates; you have just months and years
>
> 3. therefore perhaps the as.yearmon() function in the zoo package could help
>
> library(zoo)
> my.factor <- factor("Feb 2017")
> as.yearmon(my.factor)  ## gets around the factor-vs-character issue
>
>
> On Mon, Jun 19, 2017 at 3:07 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
>
>> Dear all,
>>
>> Hope you are doing great. I have a .csv file that I read into R, the .csv
>> file consistss of two fields (TransitDate and CargoTons).
>>
>> The TransitDate I formatted from Excel in the fashion mmm-yy (e.g.:
>> Apr-2013). However R does not recognize the field TransitDate as a date
>> field.
>>
>> Here is the code:
>>
>> library(lubridate)
>>
>> Dataset <- read.table("U:/NEWCargoData.csv", header=TRUE, sep=",",
>> na.strings="NA", dec=".", strip.white=TRUE)
>>
>> DatasetFrame <- data.frame(Dataset)
>>
>> DatasetFrame$TransitDate <- as.Date(DatasetFrame$TransitDate, format =
>> "%b-%y")
>>
>>
>> Now, when I do DatasetFrame[1,1], the following happens:
>>
>>
>>> DatasetFrame[1,1]
>> [1] NA
>>>
>>> DatasetFrame[2,1]
>> [1] NA
>>>
>>
>> Now when I do:
>>
>>> Dataset[1,1] #this is the dataset as was read from my computer
>> [1] Jun-11
>> 62 Levels: Apr-13 Apr-14 Apr-15 Apr-16 Apr-17 Aug-13 Aug-14 Aug-15 Aug-16
>> Dec-12 Dec-13 Dec-14 ... Sep-16
>>>
>>
>> I am also attaching the .csv file for your reference. How can I do to get R
>> to convert TransitDate into an actual date  field? R is not recognizing it
>> as a date.
>>
>> Any help will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Mon Jun 19 22:06:00 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 19 Jun 2017 20:06:00 +0000
Subject: [R] How to Transform a Factor Variable into a Date
References: <CAMOcQfMjpRU9KE7JEi=eXmu0jzhnx6QeBBBDPaEtWpOZo11AYA@mail.gmail.com> 
Message-ID: <9e77acc8624848daaa15b9be22d7c259@exch-2p-mbx-w2.ads.tamu.edu>

The R list does not recognize .csv files so your attachment got stripped. It is picky that way. Tacking .txt to the end might trick it into preserving the attachment.

Dataset <- read.table()

created a data.frame called Dataset so the second command was redundant. Probably better would be read.csv() which automatically uses "," as the separator. Also including the argument as.is=TRUE will prevent conversion of character fields to factors. Then your conversion to dates should work once you add a day to the month-year format (e.g. first of the month or middle of the month):

> Test <- read.csv(text='"TransitDate", "CargoTons"
+ "Apr-2013", 50
+ "Jun-2013", 40
+ "Jul-2013", 30', as.is=TRUE)
> Test$TransitDate <- as.Date(paste0("01-", Test$TransitDate), "%d-%b-%Y")
> str(Test)
'data.frame':   3 obs. of  2 variables:
 $ TransitDate: Date, format: "2013-04-01" "2013-06-01" ...
 $ CargoTons  : int  50 40 30
> Test
  TransitDate CargoTons
1  2013-04-01        50
2  2013-06-01        40
3  2013-07-01        30

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Bernal
Sent: Monday, June 19, 2017 2:07 PM
To: r-help at r-project.org
Subject: [R] How to Transform a Factor Variable into a Date

Dear all,

Hope you are doing great. I have a .csv file that I read into R, the .csv
file consistss of two fields (TransitDate and CargoTons).

The TransitDate I formatted from Excel in the fashion mmm-yy (e.g.:
Apr-2013). However R does not recognize the field TransitDate as a date
field.

Here is the code:

library(lubridate)

Dataset <- read.table("U:/NEWCargoData.csv", header=TRUE, sep=",",
na.strings="NA", dec=".", strip.white=TRUE)

DatasetFrame <- data.frame(Dataset)

DatasetFrame$TransitDate <- as.Date(DatasetFrame$TransitDate, format =
"%b-%y")


Now, when I do DatasetFrame[1,1], the following happens:


> DatasetFrame[1,1]
[1] NA
>
> DatasetFrame[2,1]
[1] NA
>

Now when I do:

> Dataset[1,1] #this is the dataset as was read from my computer
[1] Jun-11
62 Levels: Apr-13 Apr-14 Apr-15 Apr-16 Apr-17 Aug-13 Aug-14 Aug-15 Aug-16
Dec-12 Dec-13 Dec-14 ... Sep-16
>

I am also attaching the .csv file for your reference. How can I do to get R
to convert TransitDate into an actual date  field? R is not recognizing it
as a date.

Any help will be greatly appreciated,

Best regards,

Paul
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Jun 19 22:08:40 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Jun 2017 13:08:40 -0700
Subject: [R] mixed models lmer function help!!
In-Reply-To: <205314894.1478790.1497889770829@mail.yahoo.com>
References: <205314894.1478790.1497889770829.ref@mail.yahoo.com>
 <205314894.1478790.1497889770829@mail.yahoo.com>
Message-ID: <CAGxFJbS+t_qdG5YZ-LqoPGX3YTCO0Cx9NR6LKUgmLts=x6UXFg@mail.gmail.com>

1. A mess, because you failed to read and follow the posting guide:
This is a **plain text** mailing list, which means that html can get
mangled, as you have demonstrated.

2. And wrong list: the r-sig-mixed-models list is where this would be
more suitable.

Cheers,

Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 19, 2017 at 9:29 AM, Shelby Leonard via R-help
<r-help at r-project.org> wrote:
> Hi,I have tumor growth curve data for a bunch of different mice in various groups. I want to compare the growth curves of the different groups to see if timing of drug delivery changed tumor growth.I am trying to run a mixed models with repeated measures over time with each mouse as a random effect with linear and quadratic terms for time.This took me a long time to figure out and I just wanted to make sure I did it correctly and I am interpreting it correctly. This is the code I ran
> Rtumor<-lmer(volume~Group+Time+(1|Subject), data=Rtumor)summary(Rtumor)Rtumor.null=lmer(volume~Time+(1|Subject), data=Rtumor, REML=FALSE)Rtumor.full=lmer(volume~Group+Time+(1|Subject), data=Rtumor, REML=FALSE)anova(Rtumor.null,Rtumor.full)
> Here is my output Rtumor<-lmer(volume~Group+Time+(1|Subject), data=Rtumor)> summary(Rtumor)Linear mixed model fit by REML ['lmerMod']Formula: volume ~ Group + Time + (1 | Subject)   Data: Rtumor
> REML criterion at convergence: 1541.2
> Scaled residuals:     Min      1Q  Median      3Q     Max -1.8006 -0.6348 -0.0658  0.3903  4.7551
> Random effects: Groups   Name        Variance  Std.Dev.  Subject  (Intercept) 3.197e-09 5.654e-05 Residual             3.348e+05 5.786e+02Number of obs: 101, groups:  Subject, 11
> Fixed effects:            Estimate Std. Error t value(Intercept) -495.520    303.619  -1.632Group         24.350    115.615   0.211Time          79.653      7.886  10.101
> Correlation of Fixed Effects:      (Intr) Group Group -0.933       Time  -0.300 -0.007
>> Rtumor.null=lmer(volume~Time+(1|Subject), data=Rtumor, REML=FALSE)> Rtumor.full=lmer(volume~Group+Time+(1|Subject), data=Rtumor, REML=FALSE)> anova(Rtumor.null,Rtumor.full)Data: RtumorModels:Rtumor.null: volume ~ Time + (1 | Subject)Rtumor.full: volume ~ Group + Time + (1 | Subject)            Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)Rtumor.null  4 1576.5 1586.9 -784.24   1568.5                         Rtumor.full  5 1578.4 1591.5 -784.22   1568.4 0.0457      1     0.8307There were 50 or more warnings (use warnings() to see the first 50)
>
>
> My questions are1) Did I do this correctly?2) Do I still need to run it again with quadratic terms for time?, If so, how do I do this?3) If I am understanding these results correctly, they say There is no difference between these groups on volume growth curves
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From andrluis at ualberta.ca  Tue Jun 20 03:30:52 2017
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Mon, 19 Jun 2017 19:30:52 -0600
Subject: [R] Help with the plot function
Message-ID: <CAHxKz8Yk9A7sJtHh1BFFkAyS8sEr-HsObjQM23OSKM3FFTWJQA@mail.gmail.com>

Dear friends,

I have the following dataframe:

YEAR <- c(1996 , 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004 )
T_MAR <- c(2.8, 6.5, 5.4,2.4, 4, 4.1, 3, 4.4, 4.5)
T_APR <- c(5.7, 7.8, 7.7, 4.6, 4.7, 6.2,5.7, 5.9, 7)
T_MAY <- c(7, 8.8, 10, 6, 5.5, 7.6, 8.5, 7.3, 10.2)
BUD <- c(87, 98, 93, 85, 89, 91, 87, 92, 92)
BUD_SE <- c(3.6, 2, 2.4, 4, 2.4, 2.4, 4, 2.4, 3)
g1 <- data.frame(YEAR, T_MAR, T_APR, T_MAY, BUD, BUD_SE)

###PLOT
dev.new(width=6.5, height=5)
par (cex=1, family="sans", mar=c(5,5,5,5.5))
plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F, xlim=c(1996,2004),
ylim=c(0,12), data=g1)

title(ylab="Temperature (?C)",xlab="Year")
axis(1, at=seq(1996, 2004, 2))
axis(2, at=c(0,3,6,9,12), las=2)
par(new=T)
plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19, ylim=c(60,100),data=g1)
axis(4, las=2)
mtext("Bud Break (Julian Day)", side=4, padj=4)
arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05, angle=90)
arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05, angle=90)



However, I'd like to draw a multi-panel graph with budbreak on the top (as
it is), and with the temperatures for March, April, and May on the bottom,
with their respective legends.

I was wondering if you could help me out with this.

Thanks a million for your help.

-- 
Andre

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun 20 03:41:06 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Jun 2017 18:41:06 -0700
Subject: [R] Help with the plot function
In-Reply-To: <CAHxKz8Yk9A7sJtHh1BFFkAyS8sEr-HsObjQM23OSKM3FFTWJQA@mail.gmail.com>
References: <CAHxKz8Yk9A7sJtHh1BFFkAyS8sEr-HsObjQM23OSKM3FFTWJQA@mail.gmail.com>
Message-ID: <CAGxFJbSv-W=RGKJMGL8UN+k0dCo7xh59VHkbA0La9pjLVZT00A@mail.gmail.com>

See

?layout
?split.screen
?par  (the mfrow and mfcol values)

depending exactly on what you want to do and how you want to do it.
Essentially, these all allow you to make separate plots at different
regions of the device.


Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 19, 2017 at 6:30 PM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Dear friends,
>
> I have the following dataframe:
>
> YEAR <- c(1996 , 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004 )
> T_MAR <- c(2.8, 6.5, 5.4,2.4, 4, 4.1, 3, 4.4, 4.5)
> T_APR <- c(5.7, 7.8, 7.7, 4.6, 4.7, 6.2,5.7, 5.9, 7)
> T_MAY <- c(7, 8.8, 10, 6, 5.5, 7.6, 8.5, 7.3, 10.2)
> BUD <- c(87, 98, 93, 85, 89, 91, 87, 92, 92)
> BUD_SE <- c(3.6, 2, 2.4, 4, 2.4, 2.4, 4, 2.4, 3)
> g1 <- data.frame(YEAR, T_MAR, T_APR, T_MAY, BUD, BUD_SE)
>
> ###PLOT
> dev.new(width=6.5, height=5)
> par (cex=1, family="sans", mar=c(5,5,5,5.5))
> plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F, xlim=c(1996,2004),
> ylim=c(0,12), data=g1)
>
> title(ylab="Temperature (?C)",xlab="Year")
> axis(1, at=seq(1996, 2004, 2))
> axis(2, at=c(0,3,6,9,12), las=2)
> par(new=T)
> plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19, ylim=c(60,100),data=g1)
> axis(4, las=2)
> mtext("Bud Break (Julian Day)", side=4, padj=4)
> arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05, angle=90)
> arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05, angle=90)
>
>
>
> However, I'd like to draw a multi-panel graph with budbreak on the top (as
> it is), and with the temperatures for March, April, and May on the bottom,
> with their respective legends.
>
> I was wondering if you could help me out with this.
>
> Thanks a million for your help.
>
> --
> Andre
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From andrluis at ualberta.ca  Tue Jun 20 04:01:19 2017
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Mon, 19 Jun 2017 20:01:19 -0600
Subject: [R] Help with the plot function
In-Reply-To: <CAGxFJbSv-W=RGKJMGL8UN+k0dCo7xh59VHkbA0La9pjLVZT00A@mail.gmail.com>
References: <CAHxKz8Yk9A7sJtHh1BFFkAyS8sEr-HsObjQM23OSKM3FFTWJQA@mail.gmail.com>
 <CAGxFJbSv-W=RGKJMGL8UN+k0dCo7xh59VHkbA0La9pjLVZT00A@mail.gmail.com>
Message-ID: <CAHxKz8aaVqceSXRoCkrbht7TAEnQ-agaz37t9=wj6gnV7KoOAA@mail.gmail.com>

I'm trying to recreate a graph similar to the last one found on this link:
https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/7362679/6c_-_line_plots_with_error_bars.pdf

The difference is that I want budbreak on the top, and the temperatures at
the bottom.

I tried to set par before each graph and include lines, with no avail.

Thanks, Bert.

Andre

On Mon, Jun 19, 2017 at 7:41 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> See
>
> ?layout
> ?split.screen
> ?par  (the mfrow and mfcol values)
>
> depending exactly on what you want to do and how you want to do it.
> Essentially, these all allow you to make separate plots at different
> regions of the device.
>
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 19, 2017 at 6:30 PM, Andr? Luis Neves <andrluis at ualberta.ca>
> wrote:
> > Dear friends,
> >
> > I have the following dataframe:
> >
> > YEAR <- c(1996 , 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004 )
> > T_MAR <- c(2.8, 6.5, 5.4,2.4, 4, 4.1, 3, 4.4, 4.5)
> > T_APR <- c(5.7, 7.8, 7.7, 4.6, 4.7, 6.2,5.7, 5.9, 7)
> > T_MAY <- c(7, 8.8, 10, 6, 5.5, 7.6, 8.5, 7.3, 10.2)
> > BUD <- c(87, 98, 93, 85, 89, 91, 87, 92, 92)
> > BUD_SE <- c(3.6, 2, 2.4, 4, 2.4, 2.4, 4, 2.4, 3)
> > g1 <- data.frame(YEAR, T_MAR, T_APR, T_MAY, BUD, BUD_SE)
> >
> > ###PLOT
> > dev.new(width=6.5, height=5)
> > par (cex=1, family="sans", mar=c(5,5,5,5.5))
> > plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F, xlim=c(1996,2004),
> > ylim=c(0,12), data=g1)
> >
> > title(ylab="Temperature (?C)",xlab="Year")
> > axis(1, at=seq(1996, 2004, 2))
> > axis(2, at=c(0,3,6,9,12), las=2)
> > par(new=T)
> > plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19, ylim=c(60,100),data=g1)
> > axis(4, las=2)
> > mtext("Bud Break (Julian Day)", side=4, padj=4)
> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05, angle=90)
> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05, angle=90)
> >
> >
> >
> > However, I'd like to draw a multi-panel graph with budbreak on the top
> (as
> > it is), and with the temperatures for March, April, and May on the
> bottom,
> > with their respective legends.
> >
> > I was wondering if you could help me out with this.
> >
> > Thanks a million for your help.
> >
> > --
> > Andre
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Andre

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun 20 05:53:28 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Jun 2017 20:53:28 -0700
Subject: [R] Help with the plot function
In-Reply-To: <CAHxKz8aaVqceSXRoCkrbht7TAEnQ-agaz37t9=wj6gnV7KoOAA@mail.gmail.com>
References: <CAHxKz8Yk9A7sJtHh1BFFkAyS8sEr-HsObjQM23OSKM3FFTWJQA@mail.gmail.com>
 <CAGxFJbSv-W=RGKJMGL8UN+k0dCo7xh59VHkbA0La9pjLVZT00A@mail.gmail.com>
 <CAHxKz8aaVqceSXRoCkrbht7TAEnQ-agaz37t9=wj6gnV7KoOAA@mail.gmail.com>
Message-ID: <CAGxFJbTjJawKjFsv655yf9vxf5GXJ_jVOn9a2-wAvyhweEfn6w@mail.gmail.com>

1. Did you study the functions (esp. ?layout) to which I referred you?

2. Show us your code! -- "to no avail" is meaningless!

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 19, 2017 at 7:01 PM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> I'm trying to recreate a graph similar to the last one found on this link:
> https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/7362679/6c_-_line_plots_with_error_bars.pdf
>
> The difference is that I want budbreak on the top, and the temperatures at
> the bottom.
>
> I tried to set par before each graph and include lines, with no avail.
>
> Thanks, Bert.
>
> Andre
>
> On Mon, Jun 19, 2017 at 7:41 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> See
>>
>> ?layout
>> ?split.screen
>> ?par  (the mfrow and mfcol values)
>>
>> depending exactly on what you want to do and how you want to do it.
>> Essentially, these all allow you to make separate plots at different
>> regions of the device.
>>
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Jun 19, 2017 at 6:30 PM, Andr? Luis Neves <andrluis at ualberta.ca>
>> wrote:
>> > Dear friends,
>> >
>> > I have the following dataframe:
>> >
>> > YEAR <- c(1996 , 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004 )
>> > T_MAR <- c(2.8, 6.5, 5.4,2.4, 4, 4.1, 3, 4.4, 4.5)
>> > T_APR <- c(5.7, 7.8, 7.7, 4.6, 4.7, 6.2,5.7, 5.9, 7)
>> > T_MAY <- c(7, 8.8, 10, 6, 5.5, 7.6, 8.5, 7.3, 10.2)
>> > BUD <- c(87, 98, 93, 85, 89, 91, 87, 92, 92)
>> > BUD_SE <- c(3.6, 2, 2.4, 4, 2.4, 2.4, 4, 2.4, 3)
>> > g1 <- data.frame(YEAR, T_MAR, T_APR, T_MAY, BUD, BUD_SE)
>> >
>> > ###PLOT
>> > dev.new(width=6.5, height=5)
>> > par (cex=1, family="sans", mar=c(5,5,5,5.5))
>> > plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F, xlim=c(1996,2004),
>> > ylim=c(0,12), data=g1)
>> >
>> > title(ylab="Temperature (?C)",xlab="Year")
>> > axis(1, at=seq(1996, 2004, 2))
>> > axis(2, at=c(0,3,6,9,12), las=2)
>> > par(new=T)
>> > plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19, ylim=c(60,100),data=g1)
>> > axis(4, las=2)
>> > mtext("Bud Break (Julian Day)", side=4, padj=4)
>> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05,
>> > angle=90)
>> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05, angle=90)
>> >
>> >
>> >
>> > However, I'd like to draw a multi-panel graph with budbreak on the top
>> > (as
>> > it is), and with the temperatures for March, April, and May on the
>> > bottom,
>> > with their respective legends.
>> >
>> > I was wondering if you could help me out with this.
>> >
>> > Thanks a million for your help.
>> >
>> > --
>> > Andre
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Andre


From andrluis at ualberta.ca  Tue Jun 20 06:29:27 2017
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Mon, 19 Jun 2017 22:29:27 -0600
Subject: [R] Help with the plot function
In-Reply-To: <CAGxFJbTjJawKjFsv655yf9vxf5GXJ_jVOn9a2-wAvyhweEfn6w@mail.gmail.com>
References: <CAHxKz8Yk9A7sJtHh1BFFkAyS8sEr-HsObjQM23OSKM3FFTWJQA@mail.gmail.com>
 <CAGxFJbSv-W=RGKJMGL8UN+k0dCo7xh59VHkbA0La9pjLVZT00A@mail.gmail.com>
 <CAHxKz8aaVqceSXRoCkrbht7TAEnQ-agaz37t9=wj6gnV7KoOAA@mail.gmail.com>
 <CAGxFJbTjJawKjFsv655yf9vxf5GXJ_jVOn9a2-wAvyhweEfn6w@mail.gmail.com>
Message-ID: <CAHxKz8YLgOZTvRKTiYLxVTsTfh+jc1s2AaAq43Nh2M8_ka9dxA@mail.gmail.com>

Hi, Bert:
Yes, I studied the functions you suggested, but I didn't get to adapt it to
my example whose reproducible code I sent in my first email.

Here it is the code of the functions I studies:

## par
par(mfrow = c(2, 3))
par(cex = 0.6)
par(mar = c(3, 3, 0, 0), oma = c(1, 1, 1, 1))
for (i in 1:6) {
 plot(1, 1, type = "n")
mtext(letters[i], side = 3, line = -1, adj = 0.1, cex = 0.6)}


par(mfrow = c(2, 3))
par(cex = 0.6)
par(mar = c(0, 0, 0, 0), oma = c(4, 4, 0.5, 0.5))
par(tcl = -0.25)
par(mgp = c(2, 0.6, 0))

for (i in 1:6) {
      plot(1, axes = FALSE, type = "n")
      mtext(letters[i], side = 3, line=-1,adj=0.1,cex=0.6, col = "grey40")
  if (i %in% c(4, 5, 6))
    axis(1, col = "grey40", col.axis = "grey20", at = seq(0.6,
                                                          1.2, 0.2))
  if (i %in% c(1, 4))
    axis(2, col = "grey40", col.axis = "grey20", at = seq(0.6,
                                                          1.2, 0.2))
  box(col = "grey60")}

## Layout

m <- rbind(c(1, 1), c(2, 3))
m
layout(m)
layout.show(3)
layout(m)
par(mar = c(3, 3, 0, 0))
for (i in 1:3) plot(1, 1, type = "n")

Thank you,

Andre


On Mon, Jun 19, 2017 at 9:53 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> 1. Did you study the functions (esp. ?layout) to which I referred you?
>
> 2. Show us your code! -- "to no avail" is meaningless!
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 19, 2017 at 7:01 PM, Andr? Luis Neves <andrluis at ualberta.ca>
> wrote:
> > I'm trying to recreate a graph similar to the last one found on this
> link:
> > https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/
> 7362679/6c_-_line_plots_with_error_bars.pdf
> >
> > The difference is that I want budbreak on the top, and the temperatures
> at
> > the bottom.
> >
> > I tried to set par before each graph and include lines, with no avail.
> >
> > Thanks, Bert.
> >
> > Andre
> >
> > On Mon, Jun 19, 2017 at 7:41 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>
> >> See
> >>
> >> ?layout
> >> ?split.screen
> >> ?par  (the mfrow and mfcol values)
> >>
> >> depending exactly on what you want to do and how you want to do it.
> >> Essentially, these all allow you to make separate plots at different
> >> regions of the device.
> >>
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Mon, Jun 19, 2017 at 6:30 PM, Andr? Luis Neves <andrluis at ualberta.ca
> >
> >> wrote:
> >> > Dear friends,
> >> >
> >> > I have the following dataframe:
> >> >
> >> > YEAR <- c(1996 , 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004 )
> >> > T_MAR <- c(2.8, 6.5, 5.4,2.4, 4, 4.1, 3, 4.4, 4.5)
> >> > T_APR <- c(5.7, 7.8, 7.7, 4.6, 4.7, 6.2,5.7, 5.9, 7)
> >> > T_MAY <- c(7, 8.8, 10, 6, 5.5, 7.6, 8.5, 7.3, 10.2)
> >> > BUD <- c(87, 98, 93, 85, 89, 91, 87, 92, 92)
> >> > BUD_SE <- c(3.6, 2, 2.4, 4, 2.4, 2.4, 4, 2.4, 3)
> >> > g1 <- data.frame(YEAR, T_MAR, T_APR, T_MAY, BUD, BUD_SE)
> >> >
> >> > ###PLOT
> >> > dev.new(width=6.5, height=5)
> >> > par (cex=1, family="sans", mar=c(5,5,5,5.5))
> >> > plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F, xlim=c(1996,2004),
> >> > ylim=c(0,12), data=g1)
> >> >
> >> > title(ylab="Temperature (?C)",xlab="Year")
> >> > axis(1, at=seq(1996, 2004, 2))
> >> > axis(2, at=c(0,3,6,9,12), las=2)
> >> > par(new=T)
> >> > plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19,
> ylim=c(60,100),data=g1)
> >> > axis(4, las=2)
> >> > mtext("Bud Break (Julian Day)", side=4, padj=4)
> >> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05,
> >> > angle=90)
> >> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05,
> angle=90)
> >> >
> >> >
> >> >
> >> > However, I'd like to draw a multi-panel graph with budbreak on the top
> >> > (as
> >> > it is), and with the temperatures for March, April, and May on the
> >> > bottom,
> >> > with their respective legends.
> >> >
> >> > I was wondering if you could help me out with this.
> >> >
> >> > Thanks a million for your help.
> >> >
> >> > --
> >> > Andre
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > --
> > Andre
>



-- 
Andre

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Jun 20 08:38:06 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 20 Jun 2017 06:38:06 +0000
Subject: [R] Help with the plot function
In-Reply-To: <CAHxKz8YLgOZTvRKTiYLxVTsTfh+jc1s2AaAq43Nh2M8_ka9dxA@mail.gmail.com>
References: <CAHxKz8Yk9A7sJtHh1BFFkAyS8sEr-HsObjQM23OSKM3FFTWJQA@mail.gmail.com>
 <CAGxFJbSv-W=RGKJMGL8UN+k0dCo7xh59VHkbA0La9pjLVZT00A@mail.gmail.com>
 <CAHxKz8aaVqceSXRoCkrbht7TAEnQ-agaz37t9=wj6gnV7KoOAA@mail.gmail.com>
 <CAGxFJbTjJawKjFsv655yf9vxf5GXJ_jVOn9a2-wAvyhweEfn6w@mail.gmail.com>
 <CAHxKz8YLgOZTvRKTiYLxVTsTfh+jc1s2AaAq43Nh2M8_ka9dxA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A856D@SRVEXCHCM301.precheza.cz>

Hi

You are quite close. With slight modification of your code:

par(mfrow = c(2, 1))
par(cex = 0.6)
par(mar = c(0, 0, 0, 0), oma = c(4, 4, 0.5, 0.5))
par(tcl = -0.25)
par(mgp = c(2, 0.6, 0))

plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19, ylim=c(60,100),data=g1)
axis(4, las=2)
mtext("Bud Break (Julian Day)", side=4, padj=4)
arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05, angle=90)
arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05, angle=90)

plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F, xlim=c(1996,2004), ylim=c(0,12), data=g1)

title(ylab="Temperature (?C)",xlab="Year")
axis(1, at=seq(1996, 2004, 2))
axis(2, at=c(0,3,6,9,12), las=2)

I am quite close to what you probably expect. You need modify axes and their annotation, which is left for your training.

Cheers
Petr

>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Andr? Luis
> Neves
> Sent: Tuesday, June 20, 2017 6:29 AM
> To: Bert Gunter <bgunter.4567 at gmail.com>
> Cc: R mailing list <r-help at r-project.org>
> Subject: Re: [R] Help with the plot function
>
> Hi, Bert:
> Yes, I studied the functions you suggested, but I didn't get to adapt it to
> my example whose reproducible code I sent in my first email.
>
> Here it is the code of the functions I studies:
>
> ## par
> par(mfrow = c(2, 3))
> par(cex = 0.6)
> par(mar = c(3, 3, 0, 0), oma = c(1, 1, 1, 1))
> for (i in 1:6) {
>  plot(1, 1, type = "n")
> mtext(letters[i], side = 3, line = -1, adj = 0.1, cex = 0.6)}
>
>
> par(mfrow = c(2, 3))
> par(cex = 0.6)
> par(mar = c(0, 0, 0, 0), oma = c(4, 4, 0.5, 0.5))
> par(tcl = -0.25)
> par(mgp = c(2, 0.6, 0))
>
> for (i in 1:6) {
>       plot(1, axes = FALSE, type = "n")
>       mtext(letters[i], side = 3, line=-1,adj=0.1,cex=0.6, col = "grey40")
>   if (i %in% c(4, 5, 6))
>     axis(1, col = "grey40", col.axis = "grey20", at = seq(0.6,
>                                                           1.2, 0.2))
>   if (i %in% c(1, 4))
>     axis(2, col = "grey40", col.axis = "grey20", at = seq(0.6,
>                                                           1.2, 0.2))
>   box(col = "grey60")}
>
> ## Layout
>
> m <- rbind(c(1, 1), c(2, 3))
> m
> layout(m)
> layout.show(3)
> layout(m)
> par(mar = c(3, 3, 0, 0))
> for (i in 1:3) plot(1, 1, type = "n")
>
> Thank you,
>
> Andre
>
>
> On Mon, Jun 19, 2017 at 9:53 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
> > 1. Did you study the functions (esp. ?layout) to which I referred you?
> >
> > 2. Show us your code! -- "to no avail" is meaningless!
> >
> > -- Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, Jun 19, 2017 at 7:01 PM, Andr? Luis Neves <andrluis at ualberta.ca>
> > wrote:
> > > I'm trying to recreate a graph similar to the last one found on this
> > link:
> > > https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/
> > 7362679/6c_-_line_plots_with_error_bars.pdf
> > >
> > > The difference is that I want budbreak on the top, and the temperatures
> > at
> > > the bottom.
> > >
> > > I tried to set par before each graph and include lines, with no avail.
> > >
> > > Thanks, Bert.
> > >
> > > Andre
> > >
> > > On Mon, Jun 19, 2017 at 7:41 PM, Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> > >>
> > >> See
> > >>
> > >> ?layout
> > >> ?split.screen
> > >> ?par  (the mfrow and mfcol values)
> > >>
> > >> depending exactly on what you want to do and how you want to do it.
> > >> Essentially, these all allow you to make separate plots at different
> > >> regions of the device.
> > >>
> > >>
> > >> Cheers,
> > >> Bert
> > >>
> > >>
> > >>
> > >>
> > >> Bert Gunter
> > >>
> > >> "The trouble with having an open mind is that people keep coming along
> > >> and sticking things into it."
> > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >>
> > >>
> > >> On Mon, Jun 19, 2017 at 6:30 PM, Andr? Luis Neves
> <andrluis at ualberta.ca
> > >
> > >> wrote:
> > >> > Dear friends,
> > >> >
> > >> > I have the following dataframe:
> > >> >
> > >> > YEAR <- c(1996 , 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004 )
> > >> > T_MAR <- c(2.8, 6.5, 5.4,2.4, 4, 4.1, 3, 4.4, 4.5)
> > >> > T_APR <- c(5.7, 7.8, 7.7, 4.6, 4.7, 6.2,5.7, 5.9, 7)
> > >> > T_MAY <- c(7, 8.8, 10, 6, 5.5, 7.6, 8.5, 7.3, 10.2)
> > >> > BUD <- c(87, 98, 93, 85, 89, 91, 87, 92, 92)
> > >> > BUD_SE <- c(3.6, 2, 2.4, 4, 2.4, 2.4, 4, 2.4, 3)
> > >> > g1 <- data.frame(YEAR, T_MAR, T_APR, T_MAY, BUD, BUD_SE)
> > >> >
> > >> > ###PLOT
> > >> > dev.new(width=6.5, height=5)
> > >> > par (cex=1, family="sans", mar=c(5,5,5,5.5))
> > >> > plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F, xlim=c(1996,2004),
> > >> > ylim=c(0,12), data=g1)
> > >> >
> > >> > title(ylab="Temperature (?C)",xlab="Year")
> > >> > axis(1, at=seq(1996, 2004, 2))
> > >> > axis(2, at=c(0,3,6,9,12), las=2)
> > >> > par(new=T)
> > >> > plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19,
> > ylim=c(60,100),data=g1)
> > >> > axis(4, las=2)
> > >> > mtext("Bud Break (Julian Day)", side=4, padj=4)
> > >> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05,
> > >> > angle=90)
> > >> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05,
> > angle=90)
> > >> >
> > >> >
> > >> >
> > >> > However, I'd like to draw a multi-panel graph with budbreak on the top
> > >> > (as
> > >> > it is), and with the temperatures for March, April, and May on the
> > >> > bottom,
> > >> > with their respective legends.
> > >> >
> > >> > I was wondering if you could help me out with this.
> > >> >
> > >> > Thanks a million for your help.
> > >> >
> > >> > --
> > >> > Andre
> > >> >
> > >> >         [[alternative HTML version deleted]]
> > >> >
> > >> > ______________________________________________
> > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > PLEASE do read the posting guide
> > >> > http://www.R-project.org/posting-guide.html
> > >> > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > >
> > > --
> > > Andre
> >
>
>
>
> --
> Andre
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From andrluis at ualberta.ca  Tue Jun 20 09:12:22 2017
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Tue, 20 Jun 2017 01:12:22 -0600
Subject: [R] Help with the plot function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A856D@SRVEXCHCM301.precheza.cz>
References: <CAHxKz8Yk9A7sJtHh1BFFkAyS8sEr-HsObjQM23OSKM3FFTWJQA@mail.gmail.com>
 <CAGxFJbSv-W=RGKJMGL8UN+k0dCo7xh59VHkbA0La9pjLVZT00A@mail.gmail.com>
 <CAHxKz8aaVqceSXRoCkrbht7TAEnQ-agaz37t9=wj6gnV7KoOAA@mail.gmail.com>
 <CAGxFJbTjJawKjFsv655yf9vxf5GXJ_jVOn9a2-wAvyhweEfn6w@mail.gmail.com>
 <CAHxKz8YLgOZTvRKTiYLxVTsTfh+jc1s2AaAq43Nh2M8_ka9dxA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A856D@SRVEXCHCM301.precheza.cz>
Message-ID: <CAHxKz8a33BSqoJncVC3u=MDepdW9CdWQsx39nDK0FUVjyQB+qQ@mail.gmail.com>

Dear all,

I found the last example of this link (
https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/7362679/6c_-_line_plots_with_error_bars.pdf)
very similar to the one I need to make for my paper, and I think I got what
I wanted by applying some of the suggestions of this mail list.

Here it is the code I devised (maybe there will be further improvements
from the list):


YEAR <- c(1996 , 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004 )
T_MAR <- c(2.8, 6.5, 5.4,2.4, 4, 4.1, 3, 4.4, 4.5)
T_APR <- c(5.7, 7.8, 7.7, 4.6, 4.7, 6.2,5.7, 5.9, 7)
T_MAY <- c(7, 8.8, 10, 6, 5.5, 7.6, 8.5, 7.3, 10.2)
BUD <- c(87, 98, 93, 85, 89, 91, 87, 92, 92)
BUD_SE <- c(3.6, 2, 2.4, 4, 2.4, 2.4, 4, 2.4, 3)
g1 <- data.frame(YEAR, T_MAR, T_APR, T_MAY, BUD, BUD_SE)

par(mar=c(5,5,5,5))
plot(YEAR,T_MAR,pch=0,type="b",col="green",yaxt="n",ylim=c(-15,12),ylab="")
lines(T_MAR~YEAR, type="o", pch=19, col="green")
lines(T_APR~YEAR, type="o", pch=19, col="red")
lines(T_MAY~YEAR, type="o", pch=19, col="blue")
axis(side=2, at=c(0,6,12))
mtext("Temperature (?C)", side = 2, line=2.5, at=6)
legend(1999,14, bty="n",
       lty = c(1,1,1),
       lwd = c(2,2,2),
       pch = c(19,19,19),
       col = c("green","red","blue"), legend = c("March","April","May"))

par(new=TRUE)

plot(YEAR,BUD, pch=1,type="b",col="blue",yaxt="n",ylim=c(105,50), ylab="")
arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05, angle=90)
arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05, angle=90)
axis(side=4, at=c(100,90,80), labels=c("80","90","100"),las=1)
mtext("Bud Break (Julian Day)", side = 4, line=2.5, at=90, padj=0)
abline(h=78)


Thanks for the insight and help as to the functions I needed to take a look
at.

Andre


On Tue, Jun 20, 2017 at 12:38 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> You are quite close. With slight modification of your code:
>
> par(mfrow = c(2, 1))
> par(cex = 0.6)
> par(mar = c(0, 0, 0, 0), oma = c(4, 4, 0.5, 0.5))
> par(tcl = -0.25)
> par(mgp = c(2, 0.6, 0))
>
> plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19, ylim=c(60,100),data=g1)
> axis(4, las=2)
> mtext("Bud Break (Julian Day)", side=4, padj=4)
> arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05, angle=90)
> arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05, angle=90)
>
> plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F, xlim=c(1996,2004),
> ylim=c(0,12), data=g1)
>
> title(ylab="Temperature (?C)",xlab="Year")
> axis(1, at=seq(1996, 2004, 2))
> axis(2, at=c(0,3,6,9,12), las=2)
>
> I am quite close to what you probably expect. You need modify axes and
> their annotation, which is left for your training.
>
> Cheers
> Petr
>
> >
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Andr?
> Luis
> > Neves
> > Sent: Tuesday, June 20, 2017 6:29 AM
> > To: Bert Gunter <bgunter.4567 at gmail.com>
> > Cc: R mailing list <r-help at r-project.org>
> > Subject: Re: [R] Help with the plot function
> >
> > Hi, Bert:
> > Yes, I studied the functions you suggested, but I didn't get to adapt it
> to
> > my example whose reproducible code I sent in my first email.
> >
> > Here it is the code of the functions I studies:
> >
> > ## par
> > par(mfrow = c(2, 3))
> > par(cex = 0.6)
> > par(mar = c(3, 3, 0, 0), oma = c(1, 1, 1, 1))
> > for (i in 1:6) {
> >  plot(1, 1, type = "n")
> > mtext(letters[i], side = 3, line = -1, adj = 0.1, cex = 0.6)}
> >
> >
> > par(mfrow = c(2, 3))
> > par(cex = 0.6)
> > par(mar = c(0, 0, 0, 0), oma = c(4, 4, 0.5, 0.5))
> > par(tcl = -0.25)
> > par(mgp = c(2, 0.6, 0))
> >
> > for (i in 1:6) {
> >       plot(1, axes = FALSE, type = "n")
> >       mtext(letters[i], side = 3, line=-1,adj=0.1,cex=0.6, col =
> "grey40")
> >   if (i %in% c(4, 5, 6))
> >     axis(1, col = "grey40", col.axis = "grey20", at = seq(0.6,
> >                                                           1.2, 0.2))
> >   if (i %in% c(1, 4))
> >     axis(2, col = "grey40", col.axis = "grey20", at = seq(0.6,
> >                                                           1.2, 0.2))
> >   box(col = "grey60")}
> >
> > ## Layout
> >
> > m <- rbind(c(1, 1), c(2, 3))
> > m
> > layout(m)
> > layout.show(3)
> > layout(m)
> > par(mar = c(3, 3, 0, 0))
> > for (i in 1:3) plot(1, 1, type = "n")
> >
> > Thank you,
> >
> > Andre
> >
> >
> > On Mon, Jun 19, 2017 at 9:53 PM, Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> >
> > > 1. Did you study the functions (esp. ?layout) to which I referred you?
> > >
> > > 2. Show us your code! -- "to no avail" is meaningless!
> > >
> > > -- Bert
> > >
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> > > and sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Mon, Jun 19, 2017 at 7:01 PM, Andr? Luis Neves <
> andrluis at ualberta.ca>
> > > wrote:
> > > > I'm trying to recreate a graph similar to the last one found on this
> > > link:
> > > > https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/
> > > 7362679/6c_-_line_plots_with_error_bars.pdf
> > > >
> > > > The difference is that I want budbreak on the top, and the
> temperatures
> > > at
> > > > the bottom.
> > > >
> > > > I tried to set par before each graph and include lines, with no
> avail.
> > > >
> > > > Thanks, Bert.
> > > >
> > > > Andre
> > > >
> > > > On Mon, Jun 19, 2017 at 7:41 PM, Bert Gunter <bgunter.4567 at gmail.com
> >
> > > wrote:
> > > >>
> > > >> See
> > > >>
> > > >> ?layout
> > > >> ?split.screen
> > > >> ?par  (the mfrow and mfcol values)
> > > >>
> > > >> depending exactly on what you want to do and how you want to do it.
> > > >> Essentially, these all allow you to make separate plots at different
> > > >> regions of the device.
> > > >>
> > > >>
> > > >> Cheers,
> > > >> Bert
> > > >>
> > > >>
> > > >>
> > > >>
> > > >> Bert Gunter
> > > >>
> > > >> "The trouble with having an open mind is that people keep coming
> along
> > > >> and sticking things into it."
> > > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > > >>
> > > >>
> > > >> On Mon, Jun 19, 2017 at 6:30 PM, Andr? Luis Neves
> > <andrluis at ualberta.ca
> > > >
> > > >> wrote:
> > > >> > Dear friends,
> > > >> >
> > > >> > I have the following dataframe:
> > > >> >
> > > >> > YEAR <- c(1996 , 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004 )
> > > >> > T_MAR <- c(2.8, 6.5, 5.4,2.4, 4, 4.1, 3, 4.4, 4.5)
> > > >> > T_APR <- c(5.7, 7.8, 7.7, 4.6, 4.7, 6.2,5.7, 5.9, 7)
> > > >> > T_MAY <- c(7, 8.8, 10, 6, 5.5, 7.6, 8.5, 7.3, 10.2)
> > > >> > BUD <- c(87, 98, 93, 85, 89, 91, 87, 92, 92)
> > > >> > BUD_SE <- c(3.6, 2, 2.4, 4, 2.4, 2.4, 4, 2.4, 3)
> > > >> > g1 <- data.frame(YEAR, T_MAR, T_APR, T_MAY, BUD, BUD_SE)
> > > >> >
> > > >> > ###PLOT
> > > >> > dev.new(width=6.5, height=5)
> > > >> > par (cex=1, family="sans", mar=c(5,5,5,5.5))
> > > >> > plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F,
> xlim=c(1996,2004),
> > > >> > ylim=c(0,12), data=g1)
> > > >> >
> > > >> > title(ylab="Temperature (?C)",xlab="Year")
> > > >> > axis(1, at=seq(1996, 2004, 2))
> > > >> > axis(2, at=c(0,3,6,9,12), las=2)
> > > >> > par(new=T)
> > > >> > plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19,
> > > ylim=c(60,100),data=g1)
> > > >> > axis(4, las=2)
> > > >> > mtext("Bud Break (Julian Day)", side=4, padj=4)
> > > >> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05,
> > > >> > angle=90)
> > > >> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05,
> > > angle=90)
> > > >> >
> > > >> >
> > > >> >
> > > >> > However, I'd like to draw a multi-panel graph with budbreak on
> the top
> > > >> > (as
> > > >> > it is), and with the temperatures for March, April, and May on the
> > > >> > bottom,
> > > >> > with their respective legends.
> > > >> >
> > > >> > I was wondering if you could help me out with this.
> > > >> >
> > > >> > Thanks a million for your help.
> > > >> >
> > > >> > --
> > > >> > Andre
> > > >> >
> > > >> >         [[alternative HTML version deleted]]
> > > >> >
> > > >> > ______________________________________________
> > > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> > PLEASE do read the posting guide
> > > >> > http://www.R-project.org/posting-guide.html
> > > >> > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > >
> > > >
> > > >
> > > > --
> > > > Andre
> > >
> >
> >
> >
> > --
> > Andre
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>



-- 
Andre

	[[alternative HTML version deleted]]


From highstat at highstat.com  Tue Jun 20 09:26:54 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 20 Jun 2017 08:26:54 +0100
Subject: [R] New book: Spatial,
 Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA
Message-ID: <61d9cbca-53b4-4ef3-2a1d-345f993eefa3@highstat.com>

We are pleased to announce the following book:

Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA
Authors: Zuur, Ieno, Saveliev


Book website: www.highstat.com
Paperback or EBook can be order (exclusively) from www.highstat.com
TOC: http://highstat.com/Books/BGS/SpatialTemp/Zuuretal2017_TOCOnline.pdf


Summary: We explain how to apply linear regression models, generalised 
linear models (GLM), and generalised linear mixed-effects models (GLMM) 
to spatial, temporal, and spatial-temporal data.


Outline
In Chapter 2 we discuss an important topic: dependency. Ignoring this 
means that we have pseudoreplication. We present a series of examples 
and discuss how dependency can manifest itself.

We briefly discuss frequentist tools that are available for the analysis 
of temporal and spatial data in Chapters 3 and 4, and we will conclude 
that their application is rather limited, especially if non-Gaussian 
distributions are required. We will therefore consider alternative 
models, but these require Bayesian techniques.

In Chapter 5 we discuss linear mixed-effects models to analyse 
hierarchical (i.e. clustered or nested) data, and in Chapter 6 we 
outline how we add spatial and spatial-temporal dependency to regression 
models via spatial (and/or temporal) correlated random effects.

In Chapter 7 we introduce Bayesian analysis, Markov chain Monte Carlo 
techniques (MCMC), and Integrated Nested Laplace Approximation (INLA). 
INLA allows us to apply models to spatial, temporal, or spatial-temporal 
data.

In Chapters 8 through 16 we present a series of INLA examples. We start 
by applying linear regression and mixed-effects models in INLA (Chapters 
8 and 9), followed by GLM examples in Chapter 10. In Chapters 11 through 
13 we show how to apply GLM models on spatial data. In Chapter 14 we 
discuss time-series techniques and how to implement them in INLA. 
Finally, in Chapters 15 and 16 we analyse spatial-temporal models in INLA.





-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com


-- 

Dr. Alain F. Zuur



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From andrluis at ualberta.ca  Tue Jun 20 10:00:33 2017
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Tue, 20 Jun 2017 02:00:33 -0600
Subject: [R] Help with the plot function
In-Reply-To: <CAHxKz8a33BSqoJncVC3u=MDepdW9CdWQsx39nDK0FUVjyQB+qQ@mail.gmail.com>
References: <CAHxKz8Yk9A7sJtHh1BFFkAyS8sEr-HsObjQM23OSKM3FFTWJQA@mail.gmail.com>
 <CAGxFJbSv-W=RGKJMGL8UN+k0dCo7xh59VHkbA0La9pjLVZT00A@mail.gmail.com>
 <CAHxKz8aaVqceSXRoCkrbht7TAEnQ-agaz37t9=wj6gnV7KoOAA@mail.gmail.com>
 <CAGxFJbTjJawKjFsv655yf9vxf5GXJ_jVOn9a2-wAvyhweEfn6w@mail.gmail.com>
 <CAHxKz8YLgOZTvRKTiYLxVTsTfh+jc1s2AaAq43Nh2M8_ka9dxA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A856D@SRVEXCHCM301.precheza.cz>
 <CAHxKz8a33BSqoJncVC3u=MDepdW9CdWQsx39nDK0FUVjyQB+qQ@mail.gmail.com>
Message-ID: <CAHxKz8YEGOH8-i=FA8tAk97FR1Vq13zvPX09gCBUmbgtPLC+nQ@mail.gmail.com>

Hi, Petr,

Indeed, your code is much better than the one I presented. I made small
editings.

par(mfrow = c(2, 1))
par(cex = 0.6)
par(mar = c(0, 0, 0, 0), oma = c(7, 7, 0.5, 5))
par(tcl = -0.25)
par(mgp = c(2, 0.6, 0))

plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19, ylim=c(60,100),data=g1)
axis(2, las=2)
mtext("Bud Break (Julian Day)", side=2, padj=-3)
arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05, angle=90)
arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05, angle=90)

plot(T_MAR~YEAR, type="n", pch=19, ann=F, axes=F, xlim=c(1996,2004),
ylim=c(0,12), data=g1)
lines(T_MAR~YEAR, type="o", pch=0, lty=2)
lines(T_APR~YEAR, type="o", pch=8, lty=3)
lines(T_MAY~YEAR, type="o", pch=2, lty=4)

axis(1, at=seq(1996, 2004, 2))
axis(2, at=c(0,3,6,9,12), las=2)
mtext("Year", side=1, padj=4)
mtext("Temperature (?C)", side=2, padj=-3)

legend(1999,10, bty="n",
       lty = c(2,3,4),
       lwd = c(2,2,2),
       pch = c(0,8,2),
       legend = c("March","April","May"))

Thank you very much,

Andre


On Tue, Jun 20, 2017 at 1:12 AM, Andr? Luis Neves <andrluis at ualberta.ca>
wrote:

> Dear all,
>
> I found the last example of this link (https://sites.ualberta.ca/~
> lkgray/uploads/7/3/6/2/7362679/6c_-_line_plots_with_error_bars.pdf) very
> similar to the one I need to make for my paper, and I think I got what I
> wanted by applying some of the suggestions of this mail list.
>
> Here it is the code I devised (maybe there will be further improvements
> from the list):
>
>
> YEAR <- c(1996 , 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004 )
> T_MAR <- c(2.8, 6.5, 5.4,2.4, 4, 4.1, 3, 4.4, 4.5)
> T_APR <- c(5.7, 7.8, 7.7, 4.6, 4.7, 6.2,5.7, 5.9, 7)
> T_MAY <- c(7, 8.8, 10, 6, 5.5, 7.6, 8.5, 7.3, 10.2)
> BUD <- c(87, 98, 93, 85, 89, 91, 87, 92, 92)
> BUD_SE <- c(3.6, 2, 2.4, 4, 2.4, 2.4, 4, 2.4, 3)
> g1 <- data.frame(YEAR, T_MAR, T_APR, T_MAY, BUD, BUD_SE)
>
> par(mar=c(5,5,5,5))
> plot(YEAR,T_MAR,pch=0,type="b",col="green",yaxt="n",ylim=c(-
> 15,12),ylab="")
> lines(T_MAR~YEAR, type="o", pch=19, col="green")
> lines(T_APR~YEAR, type="o", pch=19, col="red")
> lines(T_MAY~YEAR, type="o", pch=19, col="blue")
> axis(side=2, at=c(0,6,12))
> mtext("Temperature (?C)", side = 2, line=2.5, at=6)
> legend(1999,14, bty="n",
>        lty = c(1,1,1),
>        lwd = c(2,2,2),
>        pch = c(19,19,19),
>        col = c("green","red","blue"), legend = c("March","April","May"))
>
> par(new=TRUE)
>
> plot(YEAR,BUD, pch=1,type="b",col="blue",yaxt="n",ylim=c(105,50), ylab="")
> arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05, angle=90)
> arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05, angle=90)
> axis(side=4, at=c(100,90,80), labels=c("80","90","100"),las=1)
> mtext("Bud Break (Julian Day)", side = 4, line=2.5, at=90, padj=0)
> abline(h=78)
>
>
> Thanks for the insight and help as to the functions I needed to take a
> look at.
>
> Andre
>
>
> On Tue, Jun 20, 2017 at 12:38 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
>> Hi
>>
>> You are quite close. With slight modification of your code:
>>
>> par(mfrow = c(2, 1))
>> par(cex = 0.6)
>> par(mar = c(0, 0, 0, 0), oma = c(4, 4, 0.5, 0.5))
>> par(tcl = -0.25)
>> par(mgp = c(2, 0.6, 0))
>>
>> plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19, ylim=c(60,100),data=g1)
>> axis(4, las=2)
>> mtext("Bud Break (Julian Day)", side=4, padj=4)
>> arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05, angle=90)
>> arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05, angle=90)
>>
>> plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F, xlim=c(1996,2004),
>> ylim=c(0,12), data=g1)
>>
>> title(ylab="Temperature (?C)",xlab="Year")
>> axis(1, at=seq(1996, 2004, 2))
>> axis(2, at=c(0,3,6,9,12), las=2)
>>
>> I am quite close to what you probably expect. You need modify axes and
>> their annotation, which is left for your training.
>>
>> Cheers
>> Petr
>>
>> >
>>
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Andr?
>> Luis
>> > Neves
>> > Sent: Tuesday, June 20, 2017 6:29 AM
>> > To: Bert Gunter <bgunter.4567 at gmail.com>
>> > Cc: R mailing list <r-help at r-project.org>
>> > Subject: Re: [R] Help with the plot function
>> >
>> > Hi, Bert:
>> > Yes, I studied the functions you suggested, but I didn't get to adapt
>> it to
>> > my example whose reproducible code I sent in my first email.
>> >
>> > Here it is the code of the functions I studies:
>> >
>> > ## par
>> > par(mfrow = c(2, 3))
>> > par(cex = 0.6)
>> > par(mar = c(3, 3, 0, 0), oma = c(1, 1, 1, 1))
>> > for (i in 1:6) {
>> >  plot(1, 1, type = "n")
>> > mtext(letters[i], side = 3, line = -1, adj = 0.1, cex = 0.6)}
>> >
>> >
>> > par(mfrow = c(2, 3))
>> > par(cex = 0.6)
>> > par(mar = c(0, 0, 0, 0), oma = c(4, 4, 0.5, 0.5))
>> > par(tcl = -0.25)
>> > par(mgp = c(2, 0.6, 0))
>> >
>> > for (i in 1:6) {
>> >       plot(1, axes = FALSE, type = "n")
>> >       mtext(letters[i], side = 3, line=-1,adj=0.1,cex=0.6, col =
>> "grey40")
>> >   if (i %in% c(4, 5, 6))
>> >     axis(1, col = "grey40", col.axis = "grey20", at = seq(0.6,
>> >                                                           1.2, 0.2))
>> >   if (i %in% c(1, 4))
>> >     axis(2, col = "grey40", col.axis = "grey20", at = seq(0.6,
>> >                                                           1.2, 0.2))
>> >   box(col = "grey60")}
>> >
>> > ## Layout
>> >
>> > m <- rbind(c(1, 1), c(2, 3))
>> > m
>> > layout(m)
>> > layout.show(3)
>> > layout(m)
>> > par(mar = c(3, 3, 0, 0))
>> > for (i in 1:3) plot(1, 1, type = "n")
>> >
>> > Thank you,
>> >
>> > Andre
>> >
>> >
>> > On Mon, Jun 19, 2017 at 9:53 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> > wrote:
>> >
>> > > 1. Did you study the functions (esp. ?layout) to which I referred you?
>> > >
>> > > 2. Show us your code! -- "to no avail" is meaningless!
>> > >
>> > > -- Bert
>> > >
>> > >
>> > > Bert Gunter
>> > >
>> > > "The trouble with having an open mind is that people keep coming along
>> > > and sticking things into it."
>> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> > >
>> > >
>> > > On Mon, Jun 19, 2017 at 7:01 PM, Andr? Luis Neves <
>> andrluis at ualberta.ca>
>> > > wrote:
>> > > > I'm trying to recreate a graph similar to the last one found on this
>> > > link:
>> > > > https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/
>> > > 7362679/6c_-_line_plots_with_error_bars.pdf
>> > > >
>> > > > The difference is that I want budbreak on the top, and the
>> temperatures
>> > > at
>> > > > the bottom.
>> > > >
>> > > > I tried to set par before each graph and include lines, with no
>> avail.
>> > > >
>> > > > Thanks, Bert.
>> > > >
>> > > > Andre
>> > > >
>> > > > On Mon, Jun 19, 2017 at 7:41 PM, Bert Gunter <
>> bgunter.4567 at gmail.com>
>> > > wrote:
>> > > >>
>> > > >> See
>> > > >>
>> > > >> ?layout
>> > > >> ?split.screen
>> > > >> ?par  (the mfrow and mfcol values)
>> > > >>
>> > > >> depending exactly on what you want to do and how you want to do it.
>> > > >> Essentially, these all allow you to make separate plots at
>> different
>> > > >> regions of the device.
>> > > >>
>> > > >>
>> > > >> Cheers,
>> > > >> Bert
>> > > >>
>> > > >>
>> > > >>
>> > > >>
>> > > >> Bert Gunter
>> > > >>
>> > > >> "The trouble with having an open mind is that people keep coming
>> along
>> > > >> and sticking things into it."
>> > > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> > > >>
>> > > >>
>> > > >> On Mon, Jun 19, 2017 at 6:30 PM, Andr? Luis Neves
>> > <andrluis at ualberta.ca
>> > > >
>> > > >> wrote:
>> > > >> > Dear friends,
>> > > >> >
>> > > >> > I have the following dataframe:
>> > > >> >
>> > > >> > YEAR <- c(1996 , 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004 )
>> > > >> > T_MAR <- c(2.8, 6.5, 5.4,2.4, 4, 4.1, 3, 4.4, 4.5)
>> > > >> > T_APR <- c(5.7, 7.8, 7.7, 4.6, 4.7, 6.2,5.7, 5.9, 7)
>> > > >> > T_MAY <- c(7, 8.8, 10, 6, 5.5, 7.6, 8.5, 7.3, 10.2)
>> > > >> > BUD <- c(87, 98, 93, 85, 89, 91, 87, 92, 92)
>> > > >> > BUD_SE <- c(3.6, 2, 2.4, 4, 2.4, 2.4, 4, 2.4, 3)
>> > > >> > g1 <- data.frame(YEAR, T_MAR, T_APR, T_MAY, BUD, BUD_SE)
>> > > >> >
>> > > >> > ###PLOT
>> > > >> > dev.new(width=6.5, height=5)
>> > > >> > par (cex=1, family="sans", mar=c(5,5,5,5.5))
>> > > >> > plot(T_MAR~YEAR, type="l", pch=19, ann=F, axes=F,
>> xlim=c(1996,2004),
>> > > >> > ylim=c(0,12), data=g1)
>> > > >> >
>> > > >> > title(ylab="Temperature (?C)",xlab="Year")
>> > > >> > axis(1, at=seq(1996, 2004, 2))
>> > > >> > axis(2, at=c(0,3,6,9,12), las=2)
>> > > >> > par(new=T)
>> > > >> > plot(BUD~YEAR, type="o", ann=F, axes=F, pch=19,
>> > > ylim=c(60,100),data=g1)
>> > > >> > axis(4, las=2)
>> > > >> > mtext("Bud Break (Julian Day)", side=4, padj=4)
>> > > >> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD + g1$BUD_SE, length=0.05,
>> > > >> > angle=90)
>> > > >> > arrows(g1$YEAR,g1$BUD, g1$YEAR,g1$BUD-g1$BUD_SE, length=0.05,
>> > > angle=90)
>> > > >> >
>> > > >> >
>> > > >> >
>> > > >> > However, I'd like to draw a multi-panel graph with budbreak on
>> the top
>> > > >> > (as
>> > > >> > it is), and with the temperatures for March, April, and May on
>> the
>> > > >> > bottom,
>> > > >> > with their respective legends.
>> > > >> >
>> > > >> > I was wondering if you could help me out with this.
>> > > >> >
>> > > >> > Thanks a million for your help.
>> > > >> >
>> > > >> > --
>> > > >> > Andre
>> > > >> >
>> > > >> >         [[alternative HTML version deleted]]
>> > > >> >
>> > > >> > ______________________________________________
>> > > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> > > >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >> > PLEASE do read the posting guide
>> > > >> > http://www.R-project.org/posting-guide.html
>> > > >> > and provide commented, minimal, self-contained, reproducible
>> code.
>> > > >
>> > > >
>> > > >
>> > > >
>> > > > --
>> > > > Andre
>> > >
>> >
>> >
>> >
>> > --
>> > Andre
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>> strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to
>> enter into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
>
>
>
> --
> Andre
>



-- 
Andre

	[[alternative HTML version deleted]]


From leonardomalaguti27 at gmail.com  Tue Jun 20 07:06:53 2017
From: leonardomalaguti27 at gmail.com (Leonardo Malaguti)
Date: Tue, 20 Jun 2017 15:06:53 +1000
Subject: [R]  Help
Message-ID: <CAJtR53UAiEvzFpqk5ZnEYmLywp_DaTWEzVAv+jkUJgwFhkdZFA@mail.gmail.com>

Dear expert friends,
I'm pretty young of this world and  my question at your eyes can be petty
easy.
I'll need to change the name of the levels inside a column of my data-frame

levels(ind.davis$Ageclass) <- c("adult", "Juvanile", "sub-adult")
names(ind.davis$Ageclass) <- c("Adult", "Juvenile", "Sub-adult")
that is what I tried but of course doesn't work.

Thanks,
have a wonderful day,
Leo

	[[alternative HTML version deleted]]


From mails00000 at gmail.com  Tue Jun 20 09:44:13 2017
From: mails00000 at gmail.com (Wolfgang K)
Date: Tue, 20 Jun 2017 09:44:13 +0200
Subject: [R] translate formula into R code
Message-ID: <CABMnCvML5NZz+DhZxvsbX25cU7jdoCjYEW3HGubP11pv6XY3-A@mail.gmail.com>

Hello,

I am trying to implement the following formula using for loops and vectors.
I am sure you can use some fancy R code to solve this but I would like to
keep it simple and stick to for and vector/array if that is possible.

TP = 200;
RL = 50;
TPR1 = TP - RL;
TPR2 = TP + RL;
PPO = 0;

LSS = 0.1;

counter = 1;

for(i in res) {

  # Even
  if(counter %% 2 == 1) {
    ls = abs((sum(LSS)* TP)) / (TPR1 - PPO);
    LSS = c(LSS,ls);

  }

  # Odd
  if(counter %% 2 == 0) {

    ls = abs((sum(LSS)* TPR2)) / (TP - PPO);
    LSS = c(LSS,ls);

  }
}
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Unbenannt.PNG
Type: image/png
Size: 146426 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170620/29699747/attachment.png>

From nyshaw at outlook.com  Tue Jun 20 07:21:14 2017
From: nyshaw at outlook.com (Y S)
Date: Tue, 20 Jun 2017 05:21:14 +0000
Subject: [R] How to write an estimated seasonal ARIMA model from R output?
Message-ID: <PS1PR03MB15319DF11A3F76DC844FDA6CC6C50@PS1PR03MB1531.apcprd03.prod.outlook.com>

I'm trying to use the following command.
arima (x, order = c(p,d,q), seasonal =list(order=c(P,D,Q), period=s)

How can I write an estimated seasonal ARIMA model from the outputs. To be specifically, which sign to use? I know R uses a different signs from S plus.

Is it correct that the model is:
(1-ar1*B-ar2*B^2-...)(1-sar1*B^s-sar2*B^2s-....)(1-B)^d(1-B^s)^D X_t=(1+ma1*B+ma2*B^2+...)(1+sma1*B^s+sma2*B^2s+....) a_t

For example:
> m1=arima(koeps,order=c(0,1,1),seasonal=list(order=c(0,1,1),period=4))
> m1
Call:
arima(x = koeps, order = c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 4))
Coefficients:
          ma1     sma1
      -0.4096  -0.8203
s.e.   0.0866   0.0743

Should the estimated model be written as:
(1-B)(1-B^4) X_t=(1-0.4096B)(1-0.8203B^4) a_t
or (1-B)(1-B^4) X_t=(1+0.4096B)(1+0.8203B^4) a_t

Thanks!


	[[alternative HTML version deleted]]


From xujiao.mycafe at gmail.com  Tue Jun 20 10:01:45 2017
From: xujiao.mycafe at gmail.com (Mars Xu)
Date: Tue, 20 Jun 2017 16:01:45 +0800
Subject: [R] Can I use tabu search for minimization problem ?
Message-ID: <E7AC6431-5A81-42EA-B83C-EEDB6312EC1B@gmail.com>

Hi all,
	I want to use tabu search to solve my minimization problem. but tabu search in R is for maximization, so I turn my function from f to -f? but the eUtilityKeep always be 0 from the second position. I have go through a part of source code found that it always give the default value to compare,

move <- ifelse(maxTaboo > maxNontaboo & maxTaboo > aspiration, 
                         ifelse(length(which(neighboursEUtility == maxTaboo)) == 1, 
                                which(neighboursEUtility == maxTaboo), sample(which(neighboursEUtility == maxTaboo), 1)),  
                         ifelse(length(which(neighboursEUtility == maxNontaboo & tabuList == 0)) == 1, 
                                which(neighboursEUtility == maxNontaboo & tabuList == 0), sample(which(neighboursEUtility == maxNontaboo & tabuList == 0), 1)))

this cause the 0 value. 

How can I use it to get my minimization value using tabu search in R ?

Thanks .

From yogesh2cute at gmail.com  Tue Jun 20 07:18:24 2017
From: yogesh2cute at gmail.com (Yogesh Gupta)
Date: Tue, 20 Jun 2017 14:18:24 +0900
Subject: [R] error while creating a simple graph
Message-ID: <CAAjHrnNpo6aK=7cmKQYPM-g=5pxajf4GmVx5BEQq7A=6tVGa+A@mail.gmail.com>

Dear All,

I am learning R so it's a very simple problem but I do not understand while
I am not able to generate a graph from two vectors.

when I type this code, it generates a very nice graph.

 pdf("mygraph.pdf")
> attach(mtcars)
> plot(wt,mpg)
> abline(lm(mpg~wt))
> title("Regreesion of mpg")
> detach(mtcars)
> dev.off()

But I am trying to create a graph from this code, it generates a pdf with
nothing.


> dev.new()
> pdf("test.pdf")
> x <- c(1,3,6,9,12)
> y <- c(1.5,2,7,8,15)
> plot(x,y)


Thanks
Yogesh

	[[alternative HTML version deleted]]


From cryan at binghamton.edu  Tue Jun 20 15:23:18 2017
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Tue, 20 Jun 2017 09:23:18 -0400
Subject: [R] Help
In-Reply-To: <CAJtR53UAiEvzFpqk5ZnEYmLywp_DaTWEzVAv+jkUJgwFhkdZFA@mail.gmail.com>
References: <CAJtR53UAiEvzFpqk5ZnEYmLywp_DaTWEzVAv+jkUJgwFhkdZFA@mail.gmail.com>
Message-ID: <CAM+rpYnF8JG1G8_V+khHX91qHeNa0JPEuis5SVWwCB2-a87fMQ@mail.gmail.com>

Leonardo--

R-help can be a very useful resource. Some suggestions to use it well:

1. use an informative subject line, not "help"
2. include a "minimal working example:" a *little* data, the code that,
with those data, reproduces your problem, and the error message that
resulted.

As to your particular question, at this point I can only guess, but for
starters it would probably help to show the output of

str(ind.davis)

--Chris Ryan

On Tue, Jun 20, 2017 at 1:06 AM, Leonardo Malaguti <
leonardomalaguti27 at gmail.com> wrote:

> Dear expert friends,
> I'm pretty young of this world and  my question at your eyes can be petty
> easy.
> I'll need to change the name of the levels inside a column of my data-frame
>
> levels(ind.davis$Ageclass) <- c("adult", "Juvanile", "sub-adult")
> names(ind.davis$Ageclass) <- c("Adult", "Juvenile", "Sub-adult")
> that is what I tried but of course doesn't work.
>
> Thanks,
> have a wonderful day,
> Leo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Tue Jun 20 15:26:44 2017
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Tue, 20 Jun 2017 16:26:44 +0300
Subject: [R] Help
In-Reply-To: <CAJtR53UAiEvzFpqk5ZnEYmLywp_DaTWEzVAv+jkUJgwFhkdZFA@mail.gmail.com>
References: <CAJtR53UAiEvzFpqk5ZnEYmLywp_DaTWEzVAv+jkUJgwFhkdZFA@mail.gmail.com>
Message-ID: <CAJ=0CtDy8r-LQXvPpnw_a7KbQkMrii1cNv-08EUBX=_XPa9fGA@mail.gmail.com>

One solution, among many, involving recoding. There is a function in
package QCA called recode()
(similar, but in my opinion more flexible than the same function recode()
in package car)

> library(QCA)
> ind.davis$Ageclass <- recode(ind.davis$Ageclass, "adult = Adult; Juvanile
 = Juvenile; sub-adult = Sub-adult", as.factor.result = TRUE)

Should work, although untested (your example is not replicable).

Hope this helps,
Adrian

On Tue, Jun 20, 2017 at 8:06 AM, Leonardo Malaguti <
leonardomalaguti27 at gmail.com> wrote:

> Dear expert friends,
> I'm pretty young of this world and  my question at your eyes can be petty
> easy.
> I'll need to change the name of the levels inside a column of my data-frame
>
> levels(ind.davis$Ageclass) <- c("adult", "Juvanile", "sub-adult")
> names(ind.davis$Ageclass) <- c("Adult", "Juvenile", "Sub-adult")
> that is what I tried but of course doesn't work.
>
> Thanks,
> have a wonderful day,
> Leo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr. 90-92
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From es at enricoschumann.net  Tue Jun 20 15:42:29 2017
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 20 Jun 2017 15:42:29 +0200
Subject: [R] Can I use tabu search for minimization problem ?
In-Reply-To: <E7AC6431-5A81-42EA-B83C-EEDB6312EC1B@gmail.com>
Message-ID: <20170620154229.Horde._TrLtiljR4uUhM3E0VpoBgV@webmail.your-server.de>


Zitat von Mars Xu <xujiao.mycafe at gmail.com>:

> Hi all,
> 	I want to use tabu search to solve my minimization problem. but  
> tabu search in R is for maximization, so I turn my function from f  
> to -f? but the eUtilityKeep always be 0 from the second position. I  
> have go through a part of source code found that it always give the  
> default value to compare,
>
> move <- ifelse(maxTaboo > maxNontaboo & maxTaboo > aspiration,
>                          ifelse(length(which(neighboursEUtility ==  
> maxTaboo)) == 1,
>                                 which(neighboursEUtility ==  
> maxTaboo), sample(which(neighboursEUtility == maxTaboo), 1)),
>                          ifelse(length(which(neighboursEUtility ==  
> maxNontaboo & tabuList == 0)) == 1,
>                                 which(neighboursEUtility ==  
> maxNontaboo & tabuList == 0), sample(which(neighboursEUtility ==  
> maxNontaboo & tabuList == 0), 1)))
>
> this cause the 0 value.
>
> How can I use it to get my minimization value using tabu search in R ?
>
> Thanks .

If you want people to help you, provide a minimal (or, at least, small)
reproducible code example. In particular, tell people what package(s)
you are using.


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From jdnewmil at dcn.davis.ca.us  Tue Jun 20 15:46:17 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 20 Jun 2017 06:46:17 -0700
Subject: [R] translate formula into R code
In-Reply-To: <CABMnCvML5NZz+DhZxvsbX25cU7jdoCjYEW3HGubP11pv6XY3-A@mail.gmail.com>
References: <CABMnCvML5NZz+DhZxvsbX25cU7jdoCjYEW3HGubP11pv6XY3-A@mail.gmail.com>
Message-ID: <ABBE8564-DC07-430D-953E-221E61A83022@dcn.davis.ca.us>

This is an excellent exercise for you, the beginner. If you explicitly want a line-by-line translation and don't want to use the strengths of R (vectorization/functions) then there isn't much point in asking us to read the Introduction to R document that comes with the software for you. 

Please read the Posting Guide before posting again... your failure to switch your email client to plain text is going to lead to corruption of your question by the time w we see it eventually. 

PS you did not define what "res" is...
-- 
Sent from my phone. Please excuse my brevity.

On June 20, 2017 12:44:13 AM PDT, Wolfgang K <mails00000 at gmail.com> wrote:
>Hello,
>
>I am trying to implement the following formula using for loops and
>vectors.
>I am sure you can use some fancy R code to solve this but I would like
>to
>keep it simple and stick to for and vector/array if that is possible.
>
>TP = 200;
>RL = 50;
>TPR1 = TP - RL;
>TPR2 = TP + RL;
>PPO = 0;
>
>LSS = 0.1;
>
>counter = 1;
>
>for(i in res) {
>
>  # Even
>  if(counter %% 2 == 1) {
>    ls = abs((sum(LSS)* TP)) / (TPR1 - PPO);
>    LSS = c(LSS,ls);
>
>  }
>
>  # Odd
>  if(counter %% 2 == 0) {
>
>    ls = abs((sum(LSS)* TPR2)) / (TP - PPO);
>    LSS = c(LSS,ls);
>
>  }
>}


From petr.pikal at precheza.cz  Tue Jun 20 16:16:51 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 20 Jun 2017 14:16:51 +0000
Subject: [R] error while creating a simple graph
In-Reply-To: <CAAjHrnNpo6aK=7cmKQYPM-g=5pxajf4GmVx5BEQq7A=6tVGa+A@mail.gmail.com>
References: <CAAjHrnNpo6aK=7cmKQYPM-g=5pxajf4GmVx5BEQq7A=6tVGa+A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A86D0@SRVEXCHCM301.precheza.cz>

Hi

Did you close pdf device by

dev.off()

?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Yogesh Gupta
> Sent: Tuesday, June 20, 2017 7:18 AM
> To: r-help at r-project.org
> Subject: [R] error while creating a simple graph
>
> Dear All,
>
> I am learning R so it's a very simple problem but I do not understand while I am
> not able to generate a graph from two vectors.
>
> when I type this code, it generates a very nice graph.
>
>  pdf("mygraph.pdf")
> > attach(mtcars)
> > plot(wt,mpg)
> > abline(lm(mpg~wt))
> > title("Regreesion of mpg")
> > detach(mtcars)
> > dev.off()
>
> But I am trying to create a graph from this code, it generates a pdf with
> nothing.
>
>
> > dev.new()
> > pdf("test.pdf")
> > x <- c(1,3,6,9,12)
> > y <- c(1.5,2,7,8,15)
> > plot(x,y)
>
>
> Thanks
> Yogesh
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ruipbarradas at sapo.pt  Tue Jun 20 16:18:31 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 20 Jun 2017 15:18:31 +0100
Subject: [R] error while creating a simple graph
In-Reply-To: <CAAjHrnNpo6aK=7cmKQYPM-g=5pxajf4GmVx5BEQq7A=6tVGa+A@mail.gmail.com>
References: <CAAjHrnNpo6aK=7cmKQYPM-g=5pxajf4GmVx5BEQq7A=6tVGa+A@mail.gmail.com>
Message-ID: <59492EB7.7020907@sapo.pt>

Hello,

You don't need dev.new, but you need to tell R that the plot is finished 
by calling dev.off after the plot command.

Hope this helps,

Rui Barradas

Em 20-06-2017 06:18, Yogesh Gupta escreveu:
> Dear All,
>
> I am learning R so it's a very simple problem but I do not understand while
> I am not able to generate a graph from two vectors.
>
> when I type this code, it generates a very nice graph.
>
>   pdf("mygraph.pdf")
>> attach(mtcars)
>> plot(wt,mpg)
>> abline(lm(mpg~wt))
>> title("Regreesion of mpg")
>> detach(mtcars)
>> dev.off()
>
> But I am trying to create a graph from this code, it generates a pdf with
> nothing.
>
>
>> dev.new()
>> pdf("test.pdf")
>> x <- c(1,3,6,9,12)
>> y <- c(1.5,2,7,8,15)
>> plot(x,y)
>
>
> Thanks
> Yogesh
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Tue Jun 20 16:38:23 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 20 Jun 2017 07:38:23 -0700
Subject: [R] translate formula into R code
In-Reply-To: <CABMnCvM0vLepOKJE4g58BiSJog55TZPwk8BekXO-XEXwVgjEWA@mail.gmail.com>
References: <CABMnCvML5NZz+DhZxvsbX25cU7jdoCjYEW3HGubP11pv6XY3-A@mail.gmail.com>
 <ABBE8564-DC07-430D-953E-221E61A83022@dcn.davis.ca.us>
 <CABMnCvM0vLepOKJE4g58BiSJog55TZPwk8BekXO-XEXwVgjEWA@mail.gmail.com>
Message-ID: <004A8690-9C35-4F6C-BFE4-BAEEDA6A90EF@dcn.davis.ca.us>

Cc'd back to the list... always use reply-all.

You say res should have been LSS but LSS is a scalar so the for loop will only run once. What does a successful output look like for a sample input? How do you (we) know when success has been achieved?

In fact, what is the formula you want to implement?  If your code below is the definition of your "formula" then we are left with no destination. You either need to add a reference (paper citation?) or a set of inputs and corresponding outputs. 

Here are some resources that describe how to make a reproducible example [1][2][3]:

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html
-- 
Sent from my phone. Please excuse my brevity.

On June 20, 2017 7:01:23 AM PDT, Wolfgang K <mails00000 at gmail.com> wrote:
>Hi,
>
>well, I know how to use for-loop and create vectors. That is not the
>point. However, implementing this code is - at least for me - not as
>trivial as it seems since you have changes in the signs as well as
>changes in multiplication by TPR1 and TPR2. I spent hours trying to
>get this peace of code sorted out but I just don't get it working. I
>managed to calculate the first two values L2 and L3 but no more. Since
>I am not advanced in R, I was asking for help with basic functions
>which I do know already.
>
>Yes I changed so much that I forgot to change res back to LSS.
>
>2017-06-20 15:46 GMT+02:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>> This is an excellent exercise for you, the beginner. If you
>explicitly want a line-by-line translation and don't want to use the
>strengths of R (vectorization/functions) then there isn't much point in
>asking us to read the Introduction to R document that comes with the
>software for you.
>>
>> Please read the Posting Guide before posting again... your failure to
>switch your email client to plain text is going to lead to corruption
>of your question by the time w we see it eventually.
>>
>> PS you did not define what "res" is...
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On June 20, 2017 12:44:13 AM PDT, Wolfgang K <mails00000 at gmail.com>
>wrote:
>>>Hello,
>>>
>>>I am trying to implement the following formula using for loops and
>>>vectors.
>>>I am sure you can use some fancy R code to solve this but I would
>like
>>>to
>>>keep it simple and stick to for and vector/array if that is possible.
>>>
>>>TP = 200;
>>>RL = 50;
>>>TPR1 = TP - RL;
>>>TPR2 = TP + RL;
>>>PPO = 0;
>>>
>>>LSS = 0.1;
>>>
>>>counter = 1;
>>>
>>>for(i in res) {
>>>
>>>  # Even
>>>  if(counter %% 2 == 1) {
>>>    ls = abs((sum(LSS)* TP)) / (TPR1 - PPO);
>>>    LSS = c(LSS,ls);
>>>
>>>  }
>>>
>>>  # Odd
>>>  if(counter %% 2 == 0) {
>>>
>>>    ls = abs((sum(LSS)* TPR2)) / (TP - PPO);
>>>    LSS = c(LSS,ls);
>>>
>>>  }
>>>}


From dcarlson at tamu.edu  Tue Jun 20 17:39:35 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 20 Jun 2017 15:39:35 +0000
Subject: [R] Help
In-Reply-To: <CAM+rpYnF8JG1G8_V+khHX91qHeNa0JPEuis5SVWwCB2-a87fMQ@mail.gmail.com>
References: <CAJtR53UAiEvzFpqk5ZnEYmLywp_DaTWEzVAv+jkUJgwFhkdZFA@mail.gmail.com>
 <CAM+rpYnF8JG1G8_V+khHX91qHeNa0JPEuis5SVWwCB2-a87fMQ@mail.gmail.com>
Message-ID: <73e73e5d99104b06986352310f63772b@exch-2p-mbx-w2.ads.tamu.edu>

As Chris points out, we do not know what the factor labels were before you tried to change them. The levels() function should have worked as long as it included all of the factor levels in the same order. The names() function lists the names of an object. For a data frame that is the column headings. Vectors like ind.davis$Ageclass do not have names:

> set.seed(42)     # Create some random data
> ind.davis <- data.frame(ID=1:10, Ageclass=sample(c("A", "J", "S"), 10, replace=TRUE))
> str(ind.davis)
'data.frame':   10 obs. of  2 variables:
 $ ID      : int  1 2 3 4 5 6 7 8 9 10
 $ Ageclass: Factor w/ 3 levels "A","J","S": 3 3 1 3 2 2 3 1 2 3
> levels(ind.davis$Ageclass)
[1] "A" "J" "S"
> names(ind.davis$Ageclass)
NULL
> names(ind.davis)
[1] "ID"       "Ageclass"
> levels(ind.davis$Ageclass) <- c("Adult", "Juvenile", "Sub-adult")
> levels(ind.davis$Ageclass)
[1] "Adult"     "Juvenile"  "Sub-adult"
> str(ind.davis)
'data.frame':   10 obs. of  2 variables:
 $ ID      : int  1 2 3 4 5 6 7 8 9 10
 $ Ageclass: Factor w/ 3 levels "Adult","Juvenile",..: 3 3 1 3 2 2 3 1 2 3


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Christopher W Ryan
Sent: Tuesday, June 20, 2017 8:23 AM
To: R-help <r-help at r-project.org>
Subject: Re: [R] Help

Leonardo--

R-help can be a very useful resource. Some suggestions to use it well:

1. use an informative subject line, not "help"
2. include a "minimal working example:" a *little* data, the code that,
with those data, reproduces your problem, and the error message that
resulted.

As to your particular question, at this point I can only guess, but for
starters it would probably help to show the output of

str(ind.davis)

--Chris Ryan

On Tue, Jun 20, 2017 at 1:06 AM, Leonardo Malaguti <
leonardomalaguti27 at gmail.com> wrote:

> Dear expert friends,
> I'm pretty young of this world and  my question at your eyes can be petty
> easy.
> I'll need to change the name of the levels inside a column of my data-frame
>
> levels(ind.davis$Ageclass) <- c("adult", "Juvanile", "sub-adult")
> names(ind.davis$Ageclass) <- c("Adult", "Juvenile", "Sub-adult")
> that is what I tried but of course doesn't work.
>
> Thanks,
> have a wonderful day,
> Leo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jsorkin at som.umaryland.edu  Tue Jun 20 16:19:34 2017
From: jsorkin at som.umaryland.edu (Sorkin, John)
Date: Tue, 20 Jun 2017 14:19:34 +0000
Subject: [R] by can not find transpose function
Message-ID: <BY2PR0301MB06163E6FBF7C756F905281DDE2C50@BY2PR0301MB0616.namprd03.prod.outlook.com>

I am trying to transpose a dataframe by its first column using the by statement using the t function. When I use the by function, I get a message,

Error in FUN(X[[i]], ...) : could not find function "FUN"

I don't think I have a syntax error in my by statement because the by statment works using the print function.

Data and an executable example follows:

phonydata2 <- structure(list(INTRVNTN = c("CONTROL", "CONTROL", "CONTROL",
"MPR+NMES+HPRO", "CONTROL", "CONTROL", "CONTROL", "CONTROL",
"MPR+NMES+HPRO", "MPR+NMES+HPRO", "CONTROL", "CONTROL", "CONTROL",
"MPR+NMES+HPRO", "MPR+NMES+HPRO", "MPR+NMES+HPRO", "CONTROL",
"MPR+NMES+HPRO", "MPR+NMES+HPRO", "CONTROL", "MPR+NMES+HPRO",
"CONTROL", "CONTROL", "MPR+NMES+HPRO", "CONTROL", "CONTROL",
"CONTROL", "MPR+NMES+HPRO", "CONTROL", "MPR+NMES+HPRO", "MPR+NMES+HPRO",
"MPR+NMES+HPRO"), HGDOM1_MW1 = c(NA, NA, NA, NA, NA, NA, 17,
30, 27.5, 12, 16, 16, 14, NA, 33, NA, 12, 25, NA, NA, 6, NA,
13.5, 10, 1, NA, 12, 18, NA, NA, NA, NA), HGDOM1_W1 = c(8, NA,
NA, 4, NA, NA, 18, NA, 26.5, 22, 14, 8, NA, NA, 33, NA, 15, NA,
4, 9, 18, NA, 14, 16, 2, NA, 18, 15, NA, NA, NA, NA)), .Names = c("INTRVNTN",
"HGDOM1_MW1", "HGDOM1_W1"), class = "data.frame", row.names = c(NA,
-32L))

phonydata2

# This works
by(phonydata2[,2:3],phonydata2[,1],print)
# This gives and error message.
by(phonydata2[,2:3],phonydata2[,1],t)

Thank you,
John








John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


	[[alternative HTML version deleted]]


From rainer_krug at icloud.com  Tue Jun 20 16:04:03 2017
From: rainer_krug at icloud.com (Rainer Krug)
Date: Tue, 20 Jun 2017 16:04:03 +0200
Subject: [R] error while creating a simple graph
In-Reply-To: <CAAjHrnNpo6aK=7cmKQYPM-g=5pxajf4GmVx5BEQq7A=6tVGa+A@mail.gmail.com>
References: <CAAjHrnNpo6aK=7cmKQYPM-g=5pxajf4GmVx5BEQq7A=6tVGa+A@mail.gmail.com>
Message-ID: <06F07515-48A6-492F-A0CE-5A9EAA87A5DD@icloud.com>


> On 20 Jun 2017, at 07:18, Yogesh Gupta <yogesh2cute at gmail.com> wrote:
> 
> Dear All,
> 
> I am learning R so it's a very simple problem but I do not understand while
> I am not able to generate a graph from two vectors.
> 
> when I type this code, it generates a very nice graph.
> 
> pdf("mygraph.pdf")
>> attach(mtcars)
>> plot(wt,mpg)
>> abline(lm(mpg~wt))
>> title("Regreesion of mpg")
>> detach(mtcars)
>> dev.off()
> 
> But I am trying to create a graph from this code, it generates a pdf with
> nothing.
> 
> 
>> dev.new()
>> pdf("test.pdf")
>> x <- c(1,3,6,9,12)
>> y <- c(1.5,2,7,8,15)
>> plot(x,y)
> 

As in your first example, you have to with of the device by using dev.off(). Only then is the pdf completed.

Rainer
> 
> Thanks
> Yogesh
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Jun 20 18:18:00 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 20 Jun 2017 09:18:00 -0700
Subject: [R] by can not find transpose function
In-Reply-To: <BY2PR0301MB06163E6FBF7C756F905281DDE2C50@BY2PR0301MB0616.namprd03.prod.outlook.com>
References: <BY2PR0301MB06163E6FBF7C756F905281DDE2C50@BY2PR0301MB0616.namprd03.prod.outlook.com>
Message-ID: <03718419-89E8-4397-94C0-90153F4D992E@comcast.net>


> On Jun 20, 2017, at 7:19 AM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> 
> I am trying to transpose a dataframe by its first column using the by statement using the t function. When I use the by function, I get a message,
> 
> Error in FUN(X[[i]], ...) : could not find function "FUN"
> 
> I don't think I have a syntax error in my by statement because the by statment works using the print function.
> 
> Data and an executable example follows:
> 
> phonydata2 <- structure(list(INTRVNTN = c("CONTROL", "CONTROL", "CONTROL",
> "MPR+NMES+HPRO", "CONTROL", "CONTROL", "CONTROL", "CONTROL",
> "MPR+NMES+HPRO", "MPR+NMES+HPRO", "CONTROL", "CONTROL", "CONTROL",
> "MPR+NMES+HPRO", "MPR+NMES+HPRO", "MPR+NMES+HPRO", "CONTROL",
> "MPR+NMES+HPRO", "MPR+NMES+HPRO", "CONTROL", "MPR+NMES+HPRO",
> "CONTROL", "CONTROL", "MPR+NMES+HPRO", "CONTROL", "CONTROL",
> "CONTROL", "MPR+NMES+HPRO", "CONTROL", "MPR+NMES+HPRO", "MPR+NMES+HPRO",
> "MPR+NMES+HPRO"), HGDOM1_MW1 = c(NA, NA, NA, NA, NA, NA, 17,
> 30, 27.5, 12, 16, 16, 14, NA, 33, NA, 12, 25, NA, NA, 6, NA,
> 13.5, 10, 1, NA, 12, 18, NA, NA, NA, NA), HGDOM1_W1 = c(8, NA,
> NA, 4, NA, NA, 18, NA, 26.5, 22, 14, 8, NA, NA, 33, NA, 15, NA,
> 4, 9, 18, NA, 14, 16, 2, NA, 18, 15, NA, NA, NA, NA)), .Names = c("INTRVNTN",
> "HGDOM1_MW1", "HGDOM1_W1"), class = "data.frame", row.names = c(NA,
> -32L))
> 
> phonydata2
> 
> # This works
> by(phonydata2[,2:3],phonydata2[,1],print)
> # This gives and error message.
> by(phonydata2[,2:3],phonydata2[,1],t)

It only gives an error message if you redefined `t`. It runs perfectly fine in there is no data-object in your workspace named `t`.


> 
> Thank you,
> John
> 
> 
> 
> 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Tue Jun 20 19:35:05 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 20 Jun 2017 18:35:05 +0100
Subject: [R] by can not find transpose function
In-Reply-To: <03718419-89E8-4397-94C0-90153F4D992E@comcast.net>
References: <BY2PR0301MB06163E6FBF7C756F905281DDE2C50@BY2PR0301MB0616.namprd03.prod.outlook.com>
 <03718419-89E8-4397-94C0-90153F4D992E@comcast.net>
Message-ID: <59495CC9.9060409@sapo.pt>

Hello,
Works fine also with me:

 > by(phonydata2[,2:3],phonydata2[,1],t)
phonydata2[, 1]: CONTROL
             1  2  3  5  6  7  8 11 12 13 17 20 22   23 25 26 27 29
HGDOM1_MW1 NA NA NA NA NA 17 30 16 16 14 12 NA NA 13.5  1 NA 12 NA
HGDOM1_W1   8 NA NA NA NA 18 NA 14  8 NA 15  9 NA 14.0  2 NA 18 NA
------------------------------------------------------------
phonydata2[, 1]: MPR+NMES+HPRO
             4    9 10 14 15 16 18 19 21 24 28 30 31 32
HGDOM1_MW1 NA 27.5 12 NA 33 NA 25 NA  6 10 18 NA NA NA
HGDOM1_W1   4 26.5 22 NA 33 NA NA  4 18 16 15 NA NA NA
 >
 > t <- 1:10
 > by(phonydata2[,2:3],phonydata2[,1],t)
Error in FUN(data[x, , drop = FALSE], ...) :
   could not find function "FUN"

 >
 > sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.0


Hope this helps,

Rui Barradas

Em 20-06-2017 17:18, David Winsemius escreveu:
>
>> On Jun 20, 2017, at 7:19 AM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>>
>> I am trying to transpose a dataframe by its first column using the by statement using the t function. When I use the by function, I get a message,
>>
>> Error in FUN(X[[i]], ...) : could not find function "FUN"
>>
>> I don't think I have a syntax error in my by statement because the by statment works using the print function.
>>
>> Data and an executable example follows:
>>
>> phonydata2 <- structure(list(INTRVNTN = c("CONTROL", "CONTROL", "CONTROL",
>> "MPR+NMES+HPRO", "CONTROL", "CONTROL", "CONTROL", "CONTROL",
>> "MPR+NMES+HPRO", "MPR+NMES+HPRO", "CONTROL", "CONTROL", "CONTROL",
>> "MPR+NMES+HPRO", "MPR+NMES+HPRO", "MPR+NMES+HPRO", "CONTROL",
>> "MPR+NMES+HPRO", "MPR+NMES+HPRO", "CONTROL", "MPR+NMES+HPRO",
>> "CONTROL", "CONTROL", "MPR+NMES+HPRO", "CONTROL", "CONTROL",
>> "CONTROL", "MPR+NMES+HPRO", "CONTROL", "MPR+NMES+HPRO", "MPR+NMES+HPRO",
>> "MPR+NMES+HPRO"), HGDOM1_MW1 = c(NA, NA, NA, NA, NA, NA, 17,
>> 30, 27.5, 12, 16, 16, 14, NA, 33, NA, 12, 25, NA, NA, 6, NA,
>> 13.5, 10, 1, NA, 12, 18, NA, NA, NA, NA), HGDOM1_W1 = c(8, NA,
>> NA, 4, NA, NA, 18, NA, 26.5, 22, 14, 8, NA, NA, 33, NA, 15, NA,
>> 4, 9, 18, NA, 14, 16, 2, NA, 18, 15, NA, NA, NA, NA)), .Names = c("INTRVNTN",
>> "HGDOM1_MW1", "HGDOM1_W1"), class = "data.frame", row.names = c(NA,
>> -32L))
>>
>> phonydata2
>>
>> # This works
>> by(phonydata2[,2:3],phonydata2[,1],print)
>> # This gives and error message.
>> by(phonydata2[,2:3],phonydata2[,1],t)
>
> It only gives an error message if you redefined `t`. It runs perfectly fine in there is no data-object in your workspace named `t`.
>
>
>>
>> Thank you,
>> John
>>
>>
>>
>>
>>
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Tue Jun 20 20:01:45 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 20 Jun 2017 18:01:45 +0000
Subject: [R] translate formula into R code
In-Reply-To: <004A8690-9C35-4F6C-BFE4-BAEEDA6A90EF@dcn.davis.ca.us>
References: <CABMnCvML5NZz+DhZxvsbX25cU7jdoCjYEW3HGubP11pv6XY3-A@mail.gmail.com>
 <ABBE8564-DC07-430D-953E-221E61A83022@dcn.davis.ca.us>
 <CABMnCvM0vLepOKJE4g58BiSJog55TZPwk8BekXO-XEXwVgjEWA@mail.gmail.com>
 <004A8690-9C35-4F6C-BFE4-BAEEDA6A90EF@dcn.davis.ca.us>
Message-ID: <57741f36d18e442f86fdc6798ac9f50b@exch-2p-mbx-w2.ads.tamu.edu>

The attached png file shows the expected output. The loop is complicated because the values multiplied shift in value and sign so your effort to sum the values along the way fails. It we compute the first two values directly and create arrays to handle the changing multipliers, the loop is pretty simple:

> TP <- 200
> RL <- 50
> TPR1 <- TP - RL
> TPR2 <- TP + RL
> PPO <- 0
> LSS <- 0.1
> res <- 3:10
> L <- array(0, 10)
> L[1] <- .1
> L[2] <- abs(L[1] * TP) / (TPR1 - PPO)
> rows <- rbind(rep(c(-TP, TPR1), 5), rep(c(TP, -TPR2), 5))
> rows # These are the alternating values that are multiplied by L
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,] -200  150 -200  150 -200  150 -200  150 -200   150
[2,]  200 -250  200 -250  200 -250  200 -250  200  -250
> dnom <- c(TPR1 - PPO, TP - PPO)
> dnom  # These are the alternating denominators
[1] 150 200
> 
> for (i in res) {
+     r <- i %% 2 + 1
+     s <- seq_len(i-1)
+     L[i] <- abs(sum(L[s] * rows[r, s]))/ dnom[r]
+ }
> L
 [1] 0.10000000 0.13333333 0.06666667 0.08888889 0.11111111 0.14814815 0.18518519
 [8] 0.24691358 0.30864198 0.41152263

Matches the values in your png.


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Newmiller
Sent: Tuesday, June 20, 2017 9:38 AM
To: Wolfgang K <mails00000 at gmail.com>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] translate formula into R code

Cc'd back to the list... always use reply-all.

You say res should have been LSS but LSS is a scalar so the for loop will only run once. What does a successful output look like for a sample input? How do you (we) know when success has been achieved?

In fact, what is the formula you want to implement?  If your code below is the definition of your "formula" then we are left with no destination. You either need to add a reference (paper citation?) or a set of inputs and corresponding outputs. 

Here are some resources that describe how to make a reproducible example [1][2][3]:

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html
-- 
Sent from my phone. Please excuse my brevity.

On June 20, 2017 7:01:23 AM PDT, Wolfgang K <mails00000 at gmail.com> wrote:
>Hi,
>
>well, I know how to use for-loop and create vectors. That is not the
>point. However, implementing this code is - at least for me - not as
>trivial as it seems since you have changes in the signs as well as
>changes in multiplication by TPR1 and TPR2. I spent hours trying to
>get this peace of code sorted out but I just don't get it working. I
>managed to calculate the first two values L2 and L3 but no more. Since
>I am not advanced in R, I was asking for help with basic functions
>which I do know already.
>
>Yes I changed so much that I forgot to change res back to LSS.
>
>2017-06-20 15:46 GMT+02:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>> This is an excellent exercise for you, the beginner. If you
>explicitly want a line-by-line translation and don't want to use the
>strengths of R (vectorization/functions) then there isn't much point in
>asking us to read the Introduction to R document that comes with the
>software for you.
>>
>> Please read the Posting Guide before posting again... your failure to
>switch your email client to plain text is going to lead to corruption
>of your question by the time w we see it eventually.
>>
>> PS you did not define what "res" is...
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On June 20, 2017 12:44:13 AM PDT, Wolfgang K <mails00000 at gmail.com>
>wrote:
>>>Hello,
>>>
>>>I am trying to implement the following formula using for loops and
>>>vectors.
>>>I am sure you can use some fancy R code to solve this but I would
>like
>>>to
>>>keep it simple and stick to for and vector/array if that is possible.
>>>
>>>TP = 200;
>>>RL = 50;
>>>TPR1 = TP - RL;
>>>TPR2 = TP + RL;
>>>PPO = 0;
>>>
>>>LSS = 0.1;
>>>
>>>counter = 1;
>>>
>>>for(i in res) {
>>>
>>>  # Even
>>>  if(counter %% 2 == 1) {
>>>    ls = abs((sum(LSS)* TP)) / (TPR1 - PPO);
>>>    LSS = c(LSS,ls);
>>>
>>>  }
>>>
>>>  # Odd
>>>  if(counter %% 2 == 0) {
>>>
>>>    ls = abs((sum(LSS)* TPR2)) / (TP - PPO);
>>>    LSS = c(LSS,ls);
>>>
>>>  }
>>>}

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Tue Jun 20 21:29:13 2017
From: alaios at yahoo.com (Alaios)
Date: Tue, 20 Jun 2017 19:29:13 +0000 (UTC)
Subject: [R] 3D plot with coordinates
References: <785827371.2565807.1497986953355.ref@mail.yahoo.com>
Message-ID: <785827371.2565807.1497986953355@mail.yahoo.com>

HelloI have three x,y,z vectors (lets say each is set as ?rnorm(360)). So each one is having 360 elements each one correpsonding to angular coordinates (1 degree, 2 degrees, 3 degrees,.... 360 degrees) and I want to plot those on the xyz axes that have degress.
Is there a function or library to look at R cran? The ideal will be that after plotting I will be able to rotate the shape.
I would like to thank you in advance for your helpRegardsAlex
	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue Jun 20 21:49:00 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 20 Jun 2017 21:49:00 +0200
Subject: [R] 3D plot with coordinates
In-Reply-To: <785827371.2565807.1497986953355@mail.yahoo.com>
References: <785827371.2565807.1497986953355.ref@mail.yahoo.com>
 <785827371.2565807.1497986953355@mail.yahoo.com>
Message-ID: <f324b460-dd59-5722-bcac-61e7bf5c1f9d@statistik.tu-dortmund.de>

package rgl.

Best,
Uwe Ligges


On 20.06.2017 21:29, Alaios via R-help wrote:
> HelloI have three x,y,z vectors (lets say each is set as  rnorm(360)). So each one is having 360 elements each one correpsonding to angular coordinates (1 degree, 2 degrees, 3 degrees,.... 360 degrees) and I want to plot those on the xyz axes that have degress.
> Is there a function or library to look at R cran? The ideal will be that after plotting I will be able to rotate the shape.
> I would like to thank you in advance for your helpRegardsAlex
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From profjcnash at gmail.com  Tue Jun 20 22:58:11 2017
From: profjcnash at gmail.com (J C Nash)
Date: Tue, 20 Jun 2017 16:58:11 -0400
Subject: [R] R_using non linear regression with constraints
In-Reply-To: <alpine.BSF.2.00.1706181345060.53145@pedal.dcn.davis.ca.us>
References: <CANqyHbQJ8-hsKDJ59XkQE06aeJBFFB_-WhCYPPEvRH8N4o90bA@mail.gmail.com>
 <55935B3C-B8EA-460F-A758-6173F50C0F50@comcast.net>
 <CAGxFJbR-yTBF7aP2n+2MzNDqRg5r9D==2Jy+0K-D_mu0-Du6-w@mail.gmail.com>
 <20a31ecb-74a0-a90e-db44-33d127ff5387@gmail.com>
 <alpine.BSF.2.00.1706181345060.53145@pedal.dcn.davis.ca.us>
Message-ID: <8a8adca3-e411-ea82-4086-a8a36b9b0c00@gmail.com>

I took another look at the problem.

Essentially there isn't enough information in the data to estimate the parameters. What there is
doesn't have the right shape for the model.

You can see this by plotting the data -- essentially a straight line.

Get the slope as follows:

    rr <- mean(mydata$y/mydata$x, na.rm=TRUE)

    rr

    mydata$yx <- mydata$y - rr*mydata$x

    with(mydata, plot(x, yx))

Shows that the curve is bending the wrong way for the model.

More data is needed, especially at larger values of x.

JN

On 2017-06-18 06:23 PM, Jeff Newmiller wrote:
> I am not as expert as John, but I thought it worth pointing out that the variable substitution technique gives up one 
> set of constraints for another (b=0 in this case). I also find that plots help me see what is going on, so here is my 
> reproducible example (note inclusion of library calls for completeness). Note that NONE of the optimizers mentioned so far
> appear to be finding the true best fit. The fact that myfun() yields 0 always if t=0 and that condition is within the 
> data given seems likely to be part of the problem. I don't know how to resolve this... perhaps John will look at it again.
> 
> David: Your thinking makes fine sense if you are using a Monte Carlo or brute force solution, but the fact that it 
> creates a discontinuity in the objective function will confuse any optimizer that uses analytic or numerically estimated 
> slopes.
> 
> ##----------begin
> library(minpack.lm)
> library(ggplot2)
> 
> mydata <- data.frame( x = c( 0, 5, 9, 13, 17, 20 )
>                      , y = c( 0, 11, 20, 29, 38, 45 )
>                      )
> 
> myfun <- function( a, b, r, t ) {
>    a * b * ( 1 - exp( -b * r * t ) )
> }
> 
> objdta <- expand.grid( a = seq( 1000, 3000, by=20 )
>                       , b = seq( -0.01, 1, 0.01 )
>                       , rowidx = seq.int( nrow( mydata ) )
>                       )
> objdta[ , c( "y", "t" ) ] <- mydata[ objdta$rowidx
>                                     , c( "y", "x" ) ]
> objdta$tf <- factor( objdta$t )
> objdta$myfun <- with( objdta
>                      , myfun( a = a, b = b, r = 2, t = t )
>                      )
> objdtass <- aggregate( ( objdta$myfun - objdta$y )^2
>                       , objdta[ , c( "a", "b" ) ]
>                       , FUN = function( x )
>                                sum( x, na.rm=TRUE )
>                       )
> objdtassmin <- objdtass[ which.min( objdtass$x ), ]
> 
> myfit <- nlsLM( y ~ myfun( a, b, r=2, t=x )
>                , data = mydata
>                , start = list( a = 2000
>                              , b = 0.05
>                              )
>                , lower = c( 1000, 0 )
>                , upper = c( 3000, 1 )
>                )
> a <- as.vector( coef( myfit )[ "a" ] )
> b <- as.vector( coef( myfit )[ "b" ] )
> 
> brks <- c( 500, 1e7, 2e7, 3e7, 4e7 )
> ggplot( objdtass, aes( x=a, y=b, z = x, fill=x ) ) +
>      geom_tile() +
>      geom_contour( breaks= brks ) +
>      geom_point( x=a, y=b, colour="red" ) +
>      geom_point( x=objdtassmin$a
>                , y=objdtassmin$b
>                , colour="green" ) +
>      scale_fill_continuous( name="SumSq", breaks = brks )
> # Green point is brute-force solution
> # Red point is optimizer solution for myfun
> 
> ##############
> 
> myfun2 <- function( a, log1ab, r, t ) {
>    ab <- 1000 - exp( log1ab )
>    ab * ( 1 - exp( -ab/a * r * t ) )
> }
> 
> objdta$log1ab <- with( objdta, log( 1000 - a * b ) )
> objdta$myfun2 <- with( objdta
>                       , myfun2( a = a
>                               , log1ab = log1ab
>                               , r = 2
>                               , t = t
>                               )
>                       )
> objdtass2 <- aggregate( ( objdta$myfun2 - objdta$y )^2
>                        , objdta[ , c( "a", "b" ) ]
>                        , FUN = function( x )
>                                 if ( all( is.na( x ) ) ) NA
>                                 else sum( x, na.rm=TRUE )
>                        )
> objdtass2min <- objdtass2[ which.min( objdtass2$x ), ]
> 
> myfit2 <- nlsLM( y ~ myfun2( a, log1ab, r = 2, t = x )
>                 , data = mydata
>                 , start = list( a = 2000
>                               , log1ab = 4.60517
>                               )
>                 , lower = c( 1000, 0 )
>                 , upper = c( 3000, 8.0063 )
>                 )
> a2 <- as.vector( coef( myfit2 )[ "a" ] )
> b2 <- ( 1000
>        - exp( as.vector( coef( myfit2 )[ "log1ab" ] ) )
>        ) / a
> 
> brks <- c( 500, 1e6, 2e6, 3e6, 4e6 )
> ggplot( objdtass2, aes( x=a, y=b, z = x, fill=x ) ) +
>      geom_tile() +
>      geom_contour( breaks = brks ) +
>      geom_point( x=a2, y=b2, colour="red" ) +
>      geom_point( x=objdtass2min$a
>                , y=objdtass2min$b
>                , colour="green" ) +
>      scale_fill_continuous( name="SumSq", breaks = brks )
> # Green point is brute-force solution
> # Red point is optimizer solution for myfun2
> 
> ##----------end
> 
> On Sun, 18 Jun 2017, J C Nash wrote:
> 
>> I ran the following script. I satisfied the constraint by
>> making a*b a single parameter, which isn't always possible.
>> I also ran nlxb() from nlsr package, and this gives singular
>> values of the Jacobian. In the unconstrained case, the svs are
>> pretty awful, and I wouldn't trust the results as a model, though
>> the minimum is probably OK. The constrained result has a much
>> larger sum of squares.
>>
>> Notes:
>> 1) nlsr has been flagged with a check error by CRAN (though it
>> is in the vignette, and also mentions pandoc a couple of times).
>> I'm working to purge the "bug", and found one on our part, but
>> not necessarily all the issues.
>> 2) I used nlxb that requires an expression for the model. nlsLM
>> can use a function because it is using derivative approximations,
>> while nlxb actually gets a symbolic or automatic derivative if
>> it can, else squawks.
>>
>> JN
>>
>> #  Here's the script #
>> #
>> # Manoranjan Muthusamy <ranjanmano167 at gmail.com>
>> #
>>
>> library(minpack.lm)
>> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>>
>> myfun=function(a,b,r,t){
>>  prd=a*b*(1-exp(-b*r*t))
>>  return(prd)}
>>
>> # and using nlsLM
>>
>> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>                  lower = c(1000,0), upper = c(3000,1))
>> summary(myfit)
>> library(nlsr)
>> r <- 2
>> myfitj=nlxb(y~a*b*(1-exp(-b*r*x)),data=mydata,start=list(a=2000,b=0.05), trace=TRUE)
>> summary(myfitj)
>> print(myfitj)
>>
>> myfitj2<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05), trace=TRUE)
>> summary(myfitj2)
>> print(myfitj2)
>>
>> myfitj2b<-nlxb(y~ab*(1-exp(-b*r*x)),data=mydata,start=list(ab=2000*0.05,b=0.05),
>>                trace=TRUE, upper=c(1000, Inf))
>> summary(myfitj2b)
>> print(myfitj2b)
>> # End of script #
>>
>> On 2017-06-18 01:29 PM, Bert Gunter wrote:
>>> https://cran.r-project.org/web/views/Optimization.html
>>>
>>> (Cran's optimization task view -- as always, you should search before posting)
>>>
>>> In general, nonlinear optimization with nonlinear constraints is hard,
>>> and the strategy used here (multiplying by a*b < 1000) may not work --
>>> it introduces  a discontinuity into the objective function, so
>>> gradient based methods may in particular be problematic.  As usual, if
>>> either John Nash or Ravi Varadhan comment, heed what they suggest. I'm
>>> pretty ignorant.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>>
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sun, Jun 18, 2017 at 9:43 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>
>>>>> On Jun 18, 2017, at 6:24 AM, Manoranjan Muthusamy <ranjanmano167 at gmail.com> wrote:
>>>>>
>>>>> I am using nlsLM {minpack.lm} to find the values of parameters a and b of
>>>>> function myfun which give the best fit for the data set, mydata.
>>>>>
>>>>> mydata=data.frame(x=c(0,5,9,13,17,20),y = c(0,11,20,29,38,45))
>>>>>
>>>>> myfun=function(a,b,r,t){
>>>>>   prd=a*b*(1-exp(-b*r*t))
>>>>>   return(prd)}
>>>>>
>>>>> and using nlsLM
>>>>>
>>>>> myfit=nlsLM(y~myfun(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>>                   lower = c(1000,0), upper = c(3000,1))
>>>>>
>>>>> It works. But now I would like to introduce a constraint which is a*b<1000.
>>>>
>>>> At the moment your coefficients do satisfy that constraint so that dataset is not suitable for testing. A slight 
>>>> modification of the objective function to include the logical constraint as an additional factor does not "break" 
>>>> that particular solution.:
>>>>
>>>> myfun2=function(a,b,r,t){
>>>>      prd=a*b*(1-exp(-b*r*t))*(a*b<1000)
>>>>      return(prd)}
>>>>
>>>>
>>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>              lower = c(1000,0), upper = c(3000,1))
>>>>
>>>> #------------------
>>>> myfit
>>>> Nonlinear regression model
>>>>    model: y ~ myfun2(a, b, r = 2, t = x)
>>>>     data: mydata
>>>>          a         b
>>>> 3.000e+03 2.288e-02
>>>>   residual sum-of-squares: 38.02
>>>>
>>>> Number of iterations to convergence: 8
>>>> Achieved convergence tolerance: 1.49e-08
>>>> #--
>>>>
>>>> prod(coef(myfit))
>>>> #[1] 68.64909  Same as original result.
>>>>
>>>> How nlsLM will handle more difficult problems is not something I have experience with, but obviously one would need 
>>>> to keep the starting values within the feasible domain. However, if your goal was to also remove the upper and lower 
>>>> constraints on a and b, This problem would not be suitably solved by the a*b product without relaxation of the 
>>>> default maxiter:
>>>>
>>>>> myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>> +             lower = c(0,0), upper = c(9000,1))
>>>>> prod(coef(myfit))
>>>> [1] 110.4382
>>>>> coef(myfit)
>>>>             a            b
>>>> 9.000000e+03 1.227091e-02
>>>>
>>>>>   myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>> +              lower = c(0,0), upper = c(10^6,1))
>>>> Warning message:
>>>> In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower = lower,  :
>>>>    lmdif: info = -1. Number of iterations has reached `maxiter' == 50.
>>>>
>>>> #---------
>>>>   myfit=nlsLM(y~myfun2(a,b,r=2,t=x),data=mydata,start=list(a=2000,b=0.05),
>>>>               lower = c(0,0), upper = c(10^6,1), control=list(maxiter=100))
>>>>   prod(coef(myfit))
>>>>
>>>>   coef(myfit)
>>>> #============
>>>>
>>>>
>>>>>   prod(coef(myfit))
>>>> [1] 780.6732  Significantly different than the solution at default maxiter of 50.
>>>>>
>>>>>   coef(myfit)
>>>>             a            b
>>>> 5.319664e+05 1.467524e-03
>>>>>
>>>>>
>>>>
>>>>
>>>> -- 
>>>> David.
>>>>
>>>>
>>>>> I had a look at the option available in nlsLM to set constraint via
>>>>> nls.lm.control. But it's not much of help. can somebody help me here or
>>>>> suggest a different method to to this?
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From chocold12 at gmail.com  Wed Jun 21 01:17:59 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Jun 2017 17:17:59 -0600
Subject: [R] fitting cosine curve
Message-ID: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>

Hi R users,

I have a question about fitting a cosine curve. I don't know how to set the
approximate starting values. Besides, does the method work for sine curve
as well? Thanks.

Part of the dataset is in the following:
y=c(16.82, 16.72, 16.63, 16.47, 16.84, 16.25, 16.15, 16.83, 17.41, 17.67,
17.62, 17.81, 17.91, 17.85, 17.70, 17.67, 17.45, 17.58, 16.99, 17.10)
t=c(7,  37,  58,  79,  96, 110, 114, 127, 146, 156, 161, 169, 176, 182,
190, 197, 209, 218, 232, 240)

I use the method to fit a curve, but it is different from the real curve,
which can be seen in the figure.
linFit  <- lm(y ~ cos(t))
fullFit <- nls(y ~ A*cos(omega*t+C) + B,
start=list(A=coef(linFit)[1],B=coef(linFit)[2],C=0,omega=.4)) #omega cannot
be set to 1, don't know why.
co <- coef(fullFit)
fit <- function(x, a, b, c, d) {a*cos(b*x+c)+d}
plot(x=t, y=y)
curve(fit(x, a=co['A'], b=co['omega'], c=co['C'],d=co['B']), add=TRUE
,lwd=2, col="steelblue")
-------------- next part --------------
A non-text attachment was scrubbed...
Name: curve1.pdf
Type: application/pdf
Size: 29634 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170620/a99f7d8f/attachment.pdf>

From drjimlemon at gmail.com  Wed Jun 21 01:45:16 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 21 Jun 2017 09:45:16 +1000
Subject: [R] fitting cosine curve
In-Reply-To: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
References: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
Message-ID: <CA+8X3fUPPMracvU7UXe45z_r1OaFc0nJrXC0N52=tP94T2KUww@mail.gmail.com>

Hi lily,
You can get fairly good starting values just by eyeballing the curves:

plot(y)
lines(supsmu(1:20,y))
lines(0.6*cos((1:20)/3+0.6*pi)+17.2)

Jim


On Wed, Jun 21, 2017 at 9:17 AM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
>
> I have a question about fitting a cosine curve. I don't know how to set the
> approximate starting values. Besides, does the method work for sine curve
> as well? Thanks.
>
> Part of the dataset is in the following:
> y=c(16.82, 16.72, 16.63, 16.47, 16.84, 16.25, 16.15, 16.83, 17.41, 17.67,
> 17.62, 17.81, 17.91, 17.85, 17.70, 17.67, 17.45, 17.58, 16.99, 17.10)
> t=c(7,  37,  58,  79,  96, 110, 114, 127, 146, 156, 161, 169, 176, 182,
> 190, 197, 209, 218, 232, 240)
>
> I use the method to fit a curve, but it is different from the real curve,
> which can be seen in the figure.
> linFit  <- lm(y ~ cos(t))
> fullFit <- nls(y ~ A*cos(omega*t+C) + B,
> start=list(A=coef(linFit)[1],B=coef(linFit)[2],C=0,omega=.4)) #omega cannot
> be set to 1, don't know why.
> co <- coef(fullFit)
> fit <- function(x, a, b, c, d) {a*cos(b*x+c)+d}
> plot(x=t, y=y)
> curve(fit(x, a=co['A'], b=co['omega'], c=co['C'],d=co['B']), add=TRUE
> ,lwd=2, col="steelblue")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Wed Jun 21 01:49:43 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Jun 2017 17:49:43 -0600
Subject: [R] fitting cosine curve
In-Reply-To: <CA+8X3fUPPMracvU7UXe45z_r1OaFc0nJrXC0N52=tP94T2KUww@mail.gmail.com>
References: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
 <CA+8X3fUPPMracvU7UXe45z_r1OaFc0nJrXC0N52=tP94T2KUww@mail.gmail.com>
Message-ID: <CAN5afy99ykBWs7-K6X-hM2e_uNCm+TM=XG2--QwNHZ-_JcwzMw@mail.gmail.com>

Thanks, that is cool. But would there be a way that can approximate the
curve by trying more starting values automatically?

On Tue, Jun 20, 2017 at 5:45 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi lily,
> You can get fairly good starting values just by eyeballing the curves:
>
> plot(y)
> lines(supsmu(1:20,y))
> lines(0.6*cos((1:20)/3+0.6*pi)+17.2)
>
> Jim
>
>
> On Wed, Jun 21, 2017 at 9:17 AM, lily li <chocold12 at gmail.com> wrote:
> > Hi R users,
> >
> > I have a question about fitting a cosine curve. I don't know how to set
> the
> > approximate starting values. Besides, does the method work for sine curve
> > as well? Thanks.
> >
> > Part of the dataset is in the following:
> > y=c(16.82, 16.72, 16.63, 16.47, 16.84, 16.25, 16.15, 16.83, 17.41, 17.67,
> > 17.62, 17.81, 17.91, 17.85, 17.70, 17.67, 17.45, 17.58, 16.99, 17.10)
> > t=c(7,  37,  58,  79,  96, 110, 114, 127, 146, 156, 161, 169, 176, 182,
> > 190, 197, 209, 218, 232, 240)
> >
> > I use the method to fit a curve, but it is different from the real curve,
> > which can be seen in the figure.
> > linFit  <- lm(y ~ cos(t))
> > fullFit <- nls(y ~ A*cos(omega*t+C) + B,
> > start=list(A=coef(linFit)[1],B=coef(linFit)[2],C=0,omega=.4)) #omega
> cannot
> > be set to 1, don't know why.
> > co <- coef(fullFit)
> > fit <- function(x, a, b, c, d) {a*cos(b*x+c)+d}
> > plot(x=t, y=y)
> > curve(fit(x, a=co['A'], b=co['omega'], c=co['C'],d=co['B']), add=TRUE
> > ,lwd=2, col="steelblue")
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Jun 21 02:36:07 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 21 Jun 2017 12:36:07 +1200
Subject: [R] [FORGED] How to write an estimated seasonal ARIMA model
 from R output?
In-Reply-To: <PS1PR03MB15319DF11A3F76DC844FDA6CC6C50@PS1PR03MB1531.apcprd03.prod.outlook.com>
References: <PS1PR03MB15319DF11A3F76DC844FDA6CC6C50@PS1PR03MB1531.apcprd03.prod.outlook.com>
Message-ID: <42b1ba79-7eab-c8d5-4c11-deea2cfc0c88@auckland.ac.nz>

On 20/06/17 17:21, Y S wrote:
> I'm trying to use the following command.
> arima (x, order = c(p,d,q), seasonal =list(order=c(P,D,Q), period=s)
> 
> How can I write an estimated seasonal ARIMA model from the outputs. To be specifically, which sign to use? I know R uses a different signs from S plus.
> 
> Is it correct that the model is:
> (1-ar1*B-ar2*B^2-...)(1-sar1*B^s-sar2*B^2s-....)(1-B)^d(1-B^s)^D X_t=(1+ma1*B+ma2*B^2+...)(1+sma1*B^s+sma2*B^2s+....) a_t
> 
> For example:
>> m1=arima(koeps,order=c(0,1,1),seasonal=list(order=c(0,1,1),period=4))
>> m1
> Call:
> arima(x = koeps, order = c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 4))
> Coefficients:
>            ma1     sma1
>        -0.4096  -0.8203
> s.e.   0.0866   0.0743
> 
> Should the estimated model be written as:
> (1-B)(1-B^4) X_t=(1-0.4096B)(1-0.8203B^4) a_t
> or (1-B)(1-B^4) X_t=(1+0.4096B)(1+0.8203B^4) a_t
> 
> Thanks!

Please do not post in html, although this doesn't seem to have messed 
things up too badly in this instance.

The help for arima() says:

> The definition used here has
> 
> X[t] = a[1]X[t-1] + ? + a[p]X[t-p] + e[t] + b[1]e[t-1] + ? + b[q]e[t-q]

so your first possibility, i.e.

(1-B)(1-B^4) X_t=(1-0.4096B)(1-0.8203B^4) a_t

is the correct one.

This stuff *does* get confusing; parity errors keep creeping in!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From tofighizahra at gmail.com  Tue Jun 20 20:15:23 2017
From: tofighizahra at gmail.com (Zahra Tofighi)
Date: Tue, 20 Jun 2017 22:45:23 +0430
Subject: [R] Problem with shortestPath in igraph and qgraph
Message-ID: <CAP6isFpV_6d354NP3N-VgNaYsyDi6e-qOX=6gaKxBTUTT=Q2iA@mail.gmail.com>

hello,

I have a graph and i use qgraph package to calculate centrality parameters.
Now I want to know the maximum value of shortest path for each vertex with
discarding the Inf value in short pathes. For this I use the
ShortestPathLengths of centrality function in qgraph. but when I want to
get the maximum the result is wrong. here is my code:

cen<-centrality(Q)

tmp3<-cen$ShortestPathLengths
shp<-matrix(1:ncol(tmp3),ncol(tmp3),1)for(i in ncol(tmp3)){
shp[i,]=max(tmp3[i,][tmp3[i,]!=Inf)}

when I display the valu of shp the result is same as initial value (form
one to ncol). I also test with shortest.paths function. the result was
same. what is my wrong?

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Jun 21 02:52:10 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 21 Jun 2017 10:52:10 +1000
Subject: [R] fitting cosine curve
In-Reply-To: <CAN5afy-x5SaN2mbbgX+HJ2UOnLq6uLk-yLhjVegTkDY4CBk2nQ@mail.gmail.com>
References: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
 <CA+8X3fUPPMracvU7UXe45z_r1OaFc0nJrXC0N52=tP94T2KUww@mail.gmail.com>
 <CAN5afy99ykBWs7-K6X-hM2e_uNCm+TM=XG2--QwNHZ-_JcwzMw@mail.gmail.com>
 <CAN5afy-x5SaN2mbbgX+HJ2UOnLq6uLk-yLhjVegTkDY4CBk2nQ@mail.gmail.com>
Message-ID: <CA+8X3fXufDQCn1N8qzG1VmxU80tU_AFA36FLRuNQeR9OgesWaw@mail.gmail.com>

What I did was to plot your initial values, then plot the smoothed
values and guess the constants. That is, I got an "eyeball" fit to the
smoothed values. As I have described this as "gross cheating" in the
past, you should either split your data, estimate on one subset and
then test on another, or estimate on your data and test on a
replication. If you get pretty much the same values, you can be
reasonably confident that they are reliable.

Jim

On Wed, Jun 21, 2017 at 9:52 AM, lily li <chocold12 at gmail.com> wrote:
> For example, how do you know the value 0.6, and the frequency within cos?
>
> On Tue, Jun 20, 2017 at 5:49 PM, lily li <chocold12 at gmail.com> wrote:
>>
>> Thanks, that is cool. But would there be a way that can approximate the
>> curve by trying more starting values automatically?
>>
>> On Tue, Jun 20, 2017 at 5:45 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi lily,
>>> You can get fairly good starting values just by eyeballing the curves:
>>>
>>> plot(y)
>>> lines(supsmu(1:20,y))
>>> lines(0.6*cos((1:20)/3+0.6*pi)+17.2)
>>>
>>> Jim
>>>
>>>
>>> On Wed, Jun 21, 2017 at 9:17 AM, lily li <chocold12 at gmail.com> wrote:
>>> > Hi R users,
>>> >
>>> > I have a question about fitting a cosine curve. I don't know how to set
>>> > the
>>> > approximate starting values. Besides, does the method work for sine
>>> > curve
>>> > as well? Thanks.
>>> >
>>> > Part of the dataset is in the following:
>>> > y=c(16.82, 16.72, 16.63, 16.47, 16.84, 16.25, 16.15, 16.83, 17.41,
>>> > 17.67,
>>> > 17.62, 17.81, 17.91, 17.85, 17.70, 17.67, 17.45, 17.58, 16.99, 17.10)
>>> > t=c(7,  37,  58,  79,  96, 110, 114, 127, 146, 156, 161, 169, 176, 182,
>>> > 190, 197, 209, 218, 232, 240)
>>> >
>>> > I use the method to fit a curve, but it is different from the real
>>> > curve,
>>> > which can be seen in the figure.
>>> > linFit  <- lm(y ~ cos(t))
>>> > fullFit <- nls(y ~ A*cos(omega*t+C) + B,
>>> > start=list(A=coef(linFit)[1],B=coef(linFit)[2],C=0,omega=.4)) #omega
>>> > cannot
>>> > be set to 1, don't know why.
>>> > co <- coef(fullFit)
>>> > fit <- function(x, a, b, c, d) {a*cos(b*x+c)+d}
>>> > plot(x=t, y=y)
>>> > curve(fit(x, a=co['A'], b=co['omega'], c=co['C'],d=co['B']), add=TRUE
>>> > ,lwd=2, col="steelblue")
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From Scott.Waichler at pnnl.gov  Wed Jun 21 02:00:58 2017
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Wed, 21 Jun 2017 00:00:58 +0000
Subject: [R] customizing color key with plot3D
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881BA45D91@EX10MBOX03.pnnl.gov>

Hi, I am doing composite plots with the package plot3D.  One of my variables is qualitative and indexed to integers, and I would like the legend for it to have labels located at the integer values (midpoints), and not at the breaks between classes.  In the example below, the Elev Classes legend has labels at the breaks and nothing at the midpoints.  How can I show the class labels at 1:3, and not the breaks?

library(plot3D)
persp3D(z = volcano, zlim = c(-60, 200), phi = 20,
        colkey = list(length = 0.2, width = 0.4, shift = 0.15,
        cex.axis = 0.8, cex.clab = 0.85), lighting = TRUE, lphi = 90,
        clab = c("","height","m"), bty = "f", plot = FALSE)
# classify the volcano elevations with 3 classes
elev.classes <- matrix(findInterval(volcano, vec = seq(50, 200, by=50)), nrow=nrow(volcano), ncol=ncol(volcano))
class.colors <- c("red", "blue", "green")
# add as image with own color key, at bottom
image3D(z = -60, colvar = elev.classes, add = TRUE,
        col = class.colors, breaks = seq(0.5, 3.5, by=1), 
        colkey = list(length = 0.2, width = 0.4, shift = -0.15,
                      cex.axis = 0.8, cex.clab = 0.85, addlines=TRUE, tick=FALSE, 
                      at = 1:3, labels=paste("Class", 1:3)),
        clab = c("","Elev Classes"), plot = TRUE)

Thanks,
Scott

Scott Waichler
Pacific Northwest National Laboratory
Richland, Washington, USA
scott.waichler at pnnl.gov


From chocold12 at gmail.com  Wed Jun 21 04:18:07 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Jun 2017 20:18:07 -0600
Subject: [R] fitting cosine curve
In-Reply-To: <22857.52725.872950.40838@losangelesyouthorchestra.org>
References: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
 <CA+8X3fUPPMracvU7UXe45z_r1OaFc0nJrXC0N52=tP94T2KUww@mail.gmail.com>
 <CAN5afy99ykBWs7-K6X-hM2e_uNCm+TM=XG2--QwNHZ-_JcwzMw@mail.gmail.com>
 <CAN5afy-x5SaN2mbbgX+HJ2UOnLq6uLk-yLhjVegTkDY4CBk2nQ@mail.gmail.com>
 <CA+8X3fXufDQCn1N8qzG1VmxU80tU_AFA36FLRuNQeR9OgesWaw@mail.gmail.com>
 <22857.52725.872950.40838@losangelesyouthorchestra.org>
Message-ID: <CAN5afy83==aVgy29seW6BJrUyWDA_GmhvN6qfCrPTrqMnF=w3Q@mail.gmail.com>

Thanks. I will do a trial first. Also, is it okay to have the datasets that
have only part of the cycle, or better to have equal or more than one
cycle? That is to say, I cannot have the complete datasets sometimes.

On Tue, Jun 20, 2017 at 7:37 PM, Don Cohen <don-r-help at isis.cs3-inc.com>
wrote:

>
> If you know the period and want to fit phase and amplitude, this is
> equivalent to fitting a * sin + b * cos
>
>  > >>> > I don't know how to set the approximate starting values.
>
> I'm not sure what you meant by that, but I suspect it's related to
> phase and amplitude.
>
>  > >>> > Besides, does the method work for sine curve as well?
>
> sin is the same as cos with a different phase
> Any combination of a and b above = c * sin (theta + d) for
> some value of c and d and = e * cos (theta + f) for some value
> of e and f.
> Also for any c,d and for any e,f there is an a,b.
> the c and e are what I'm calling amplitude, the d and f are what
> I'm calling phase.
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Wed Jun 21 06:06:23 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Jun 2017 22:06:23 -0600
Subject: [R] fitting cosine curve
In-Reply-To: <22857.52725.872950.40838@losangelesyouthorchestra.org>
References: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
 <CA+8X3fUPPMracvU7UXe45z_r1OaFc0nJrXC0N52=tP94T2KUww@mail.gmail.com>
 <CAN5afy99ykBWs7-K6X-hM2e_uNCm+TM=XG2--QwNHZ-_JcwzMw@mail.gmail.com>
 <CAN5afy-x5SaN2mbbgX+HJ2UOnLq6uLk-yLhjVegTkDY4CBk2nQ@mail.gmail.com>
 <CA+8X3fXufDQCn1N8qzG1VmxU80tU_AFA36FLRuNQeR9OgesWaw@mail.gmail.com>
 <22857.52725.872950.40838@losangelesyouthorchestra.org>
Message-ID: <CAN5afy9hLd3b_T=4cML=atu9Y8HDOBSw9BEQQ-f-_3=pn=k4ag@mail.gmail.com>

I'm trying the different parameters, but don't know what the error is:
Error in nlsModel(formula, mf, start, wts) :
  singular gradient matrix at initial parameter estimates

Thanks for any suggestions.

On Tue, Jun 20, 2017 at 7:37 PM, Don Cohen <don-r-help at isis.cs3-inc.com>
wrote:

>
> If you know the period and want to fit phase and amplitude, this is
> equivalent to fitting a * sin + b * cos
>
>  > >>> > I don't know how to set the approximate starting values.
>
> I'm not sure what you meant by that, but I suspect it's related to
> phase and amplitude.
>
>  > >>> > Besides, does the method work for sine curve as well?
>
> sin is the same as cos with a different phase
> Any combination of a and b above = c * sin (theta + d) for
> some value of c and d and = e * cos (theta + f) for some value
> of e and f.
> Also for any c,d and for any e,f there is an a,b.
> the c and e are what I'm calling amplitude, the d and f are what
> I'm calling phase.
>

	[[alternative HTML version deleted]]


From ccberry at ucsd.edu  Wed Jun 21 06:24:18 2017
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Tue, 20 Jun 2017 21:24:18 -0700
Subject: [R] fitting cosine curve
In-Reply-To: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
References: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
Message-ID: <alpine.OSX.2.20.1706202046300.1717@charles-berrys-macbook.local>

On Tue, 20 Jun 2017, lily li wrote:

> Hi R users,
>
> I have a question about fitting a cosine curve. I don't know how to set the
> approximate starting values.

See

         Y.L. Tong (1976) Biometrics 32:85-94

The method is known as `cosinor' analysis.  It takes advantage of the 
*intrinsic* linearity of y = a + b * cos( omega*t - c ), when omega is 
given.

It you are scratching your head saying 'that thing is not linear', you 
need to go back to your linear models text and review what `linearity' 
actually refers to.  Also, reading the Tong paper is recomended as you 
will need the transformations given there in any case.

What you end up doing is fitting

 	fit <- lm(y~cos(t.times.omega)+sin(t.times.omega))

and then transforming coef(fit) to get back a, b, and c. So, you only need 
to have omega. If it is not obvious what value to use,  then that will be 
more of a challenge.

The paper gives asymptotics for the dispersion matrix of (a, b, c), I 
recall.

> Besides, does the method work for sine curve as well?

Seriously? See

https://en.wikipedia.org/wiki/List_of_trigonometric_identities#Shifts_and_periodicity

HTH,

Chuck


From don-r-help at isis.cs3-inc.com  Wed Jun 21 03:37:57 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Wed, 21 Jun 2017 01:37:57 +0000
Subject: [R] fitting cosine curve
In-Reply-To: <CA+8X3fXufDQCn1N8qzG1VmxU80tU_AFA36FLRuNQeR9OgesWaw@mail.gmail.com>
References: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
 <CA+8X3fUPPMracvU7UXe45z_r1OaFc0nJrXC0N52=tP94T2KUww@mail.gmail.com>
 <CAN5afy99ykBWs7-K6X-hM2e_uNCm+TM=XG2--QwNHZ-_JcwzMw@mail.gmail.com>
 <CAN5afy-x5SaN2mbbgX+HJ2UOnLq6uLk-yLhjVegTkDY4CBk2nQ@mail.gmail.com>
 <CA+8X3fXufDQCn1N8qzG1VmxU80tU_AFA36FLRuNQeR9OgesWaw@mail.gmail.com>
Message-ID: <22857.52725.872950.40838@losangelesyouthorchestra.org>


If you know the period and want to fit phase and amplitude, this is
equivalent to fitting a * sin + b * cos

 > >>> > I don't know how to set the approximate starting values.

I'm not sure what you meant by that, but I suspect it's related to
phase and amplitude.

 > >>> > Besides, does the method work for sine curve as well? 

sin is the same as cos with a different phase
Any combination of a and b above = c * sin (theta + d) for
some value of c and d and = e * cos (theta + f) for some value
of e and f.
Also for any c,d and for any e,f there is an a,b.
the c and e are what I'm calling amplitude, the d and f are what
I'm calling phase.


From jdnewmil at dcn.davis.ca.us  Wed Jun 21 07:05:56 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 20 Jun 2017 22:05:56 -0700
Subject: [R] Problem with shortestPath in igraph and qgraph
In-Reply-To: <CAP6isFpV_6d354NP3N-VgNaYsyDi6e-qOX=6gaKxBTUTT=Q2iA@mail.gmail.com>
References: <CAP6isFpV_6d354NP3N-VgNaYsyDi6e-qOX=6gaKxBTUTT=Q2iA@mail.gmail.com>
Message-ID: <639F9E5A-FDF6-474E-B678-A0BEB0D84745@dcn.davis.ca.us>

Hard to follow data analysis without data. Try making your example reproducible [1][2][3] and post in plain text (a setting in your emailer). Read the Posting Guide mentioned in the footer to avoid other posting pitfalls. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html

-- 
Sent from my phone. Please excuse my brevity.

On June 20, 2017 11:15:23 AM PDT, Zahra Tofighi <tofighizahra at gmail.com> wrote:
>hello,
>
>I have a graph and i use qgraph package to calculate centrality
>parameters.
>Now I want to know the maximum value of shortest path for each vertex
>with
>discarding the Inf value in short pathes. For this I use the
>ShortestPathLengths of centrality function in qgraph. but when I want
>to
>get the maximum the result is wrong. here is my code:
>
>cen<-centrality(Q)
>
>tmp3<-cen$ShortestPathLengths
>shp<-matrix(1:ncol(tmp3),ncol(tmp3),1)for(i in ncol(tmp3)){
>shp[i,]=max(tmp3[i,][tmp3[i,]!=Inf)}
>
>when I display the valu of shp the result is same as initial value
>(form
>one to ncol). I also test with shortest.paths function. the result was
>same. what is my wrong?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From andreas.leha at med.uni-goettingen.de  Wed Jun 21 10:05:33 2017
From: andreas.leha at med.uni-goettingen.de (Andreas Leha)
Date: Wed, 21 Jun 2017 10:05:33 +0200
Subject: [R] encoding/locale problem with ssh -X
Message-ID: <87podxlq9e.fsf@ukes-ams26-134.ams.med.uni.goettingen.de>

Hi all,

I am struggling with remote R sessions and a (I suspect) locale related
encoding problem:  Using the X11 device (X11forwarding enabled),
whenever I try to plot something containing umlauts using ggplot2, I am
seeing sth like

,----
| Error in grid.Call(L_stringMetric, as.graphicsAnnot(x$label)) :
|   invalid use of -61 < 0 in 'X11_MetricInfo' 
`----

Using base graphics is fine as is plotting to another device (pdf, say).

Here is some code to reproduce:

,----
| plot(1:10, 1:10, main = "gr??e")
| ## this works
| 
| library("ggplot2")
| qplot(1:10, 1:10)
| ## this works still
| 
| qplot(1:10, 1:10) + xlab("gr??e")
| ## ERROR
`----


My setup:
- locally:
  Linux (Debian GNU/Linux 9)
- remotely
  Linux (RHEL Server release 7.3 (Maipo)

(Maybe) relevant bits of my .ssh/config:

,----
| Host theserver
|      HostName XXX.XXX.XXX.XXX
|      ForwardX11 yes
|      ForwardX11Timeout 596h
|      IdentityFile ~/.ssh/id_rsa
|      IdentitiesOnly yes
|      ForwardAgent yes
|      ServerAliveInterval 300
`----

Thanks in advance for your help!

Best,
Andreas


From patrick.giraudoux at univ-fcomte.fr  Wed Jun 21 10:35:15 2017
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Wed, 21 Jun 2017 10:35:15 +0200
Subject: [R] Getting a 404 error reading CRAN mirror repository
Message-ID: <97b427fc-6995-907f-f52e-51d20b16a3d2@univ-fcomte.fr>

Dear all,

I try to get a CRAN mirror repository working on my Ubuntu trusty 
plateform. So, including e.g.:

deb https://mirror.ibcp.fr/pub/CRAN/bin/linux/ubuntu trusty universe

in /etc/apt/source.lst

However, on every mirror tried I get:

Err https://mirror.ibcp.fr trusty/universe amd64 Packages
   HttpError404
Err https://mirror.ibcp.fr trusty/universe i386 Packages
   HttpError404

Can someone figure out what is going wrong ?

Best,

Patrick



	[[alternative HTML version deleted]]


From yogesh2cute at gmail.com  Wed Jun 21 06:42:15 2017
From: yogesh2cute at gmail.com (Yogesh Gupta)
Date: Wed, 21 Jun 2017 13:42:15 +0900
Subject: [R] getting error while trying to make dendogram based on gene
	expression
Message-ID: <CAAjHrnNk4C45xv2+jJs3r9cTWcASJOXxSek8p3SGJr+X4LhvTw@mail.gmail.com>

I am trying to make dendogram based on gene expression matrix , but getting
some error:

I
countMatrix = read.table("count.row.txt",header=T,sep='\t',check.names=F)

colnames(countMatrix)

count_matrix <- countMatrix[,-1]                   #  remove first column
(gene names)
rownames(count_matrix) <- countMatrix[,1]     #added first column gene
names as rownames)

> nonzero_row <- count_matrix[rowSums(count_matrix) > 0, # removed row sum
0 across all sample

> x1= as.matrix(nonzero_row)                    # converted data into matrix

> x=log2(x1+1)                                          # converted into
log value
> d <- dist(x, method="euclidean")

> h <- hclust(d, method="complete")


*Error:*

 *** caught segfault ***
address 0x7fa39060af28, cause 'memory not mapped'

Traceback:
 1: hclust(d, method = "complete")

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:

Thanks
Yogesh

	[[alternative HTML version deleted]]


From nijmeijer at posthuma-partners.nl  Tue Jun 20 15:21:21 2017
From: nijmeijer at posthuma-partners.nl (Marco Nijmeijer)
Date: Tue, 20 Jun 2017 13:21:21 +0000
Subject: [R] [R-pkgs] lmvar
Message-ID: <903D714CE6472F47A170461900DF9C874E19B20D@PPEXCHDC01.pp.local>

The package 'lmvar' (https://CRAN.R-project.org/package=lmvar) fits a model which is linear in the expected value and log-linear in the variance. The fit is like the classical linear fit implemented in 'lm' but lifts the assumption of a constant variance which is implicit in 'lm'. Instead, different observations can have different variances.

The package comes with utility functions known also for 'lm' objects. Examples are the functions summary, coef, fitted, predict, vcov,  and AIC. To facilitate analysis, there is a function to carry out cross-validations. The vignette 'Introduction to the package' provides an introduction, the vignette 'Math details' provides  mathematical background.

Version 1.2.1 is now available. Please send bugs, requests and comments to the package maintainer.

Regards,
Marco Nijmeijer

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From shaunpwilkinson at gmail.com  Mon Jun 19 08:20:04 2017
From: shaunpwilkinson at gmail.com (Shaun Wilkinson)
Date: Mon, 19 Jun 2017 15:20:04 +0900
Subject: [R] [R-pkgs] New package: phylogram
Message-ID: <CAAiuAp=BEoGcjEE=pngo4Z7hrK-+2ZVLaXaQn1KJ_JjxZ=TN+A@mail.gmail.com>

Dear all,
I'd like to introduce a new R package called *phylogram,* for working with
evolutionary trees as deeply-nested lists known as "dendrogram" objects.

The package provides functions for importing and exporting phylogenetic
trees in the Newick parenthetic text format, as well as several functions
for command-line tree manipulation.

With an emphasis on speed and computational efficiency, the *phylogram* package
also includes tools for rapidly computing distance matrices, and building
large trees using fast alignment-free k-mer counting and divisive
clustering. While not guaranteed to produce sufficiently accurate
phylogenetic trees for taxonomic purposes, this offers an efficient means
of clustering large trees for a variety of other applications including
tree-based sequence weighting, guide trees for progressive multiple
sequence alignment, and other recursive operations such as classification
tree learning.

Any feedback is warmly welcomed.

vignette:
https://cran.r-project.org/web/packages/phylogram/vignettes/phylogram-vignette.html
development version: https://github.com/shaunpwilkinson/phylogram
bug reports: https://github.com/shaunpwilkinson/phylogram/issues
google group:  https://groups.google.com/group/phylogram

Best regards,
Shaun Wilkinson

Email: shaunpwilkinson at gmail.com
Twitter: @wilkinshau

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From alaios at yahoo.com  Wed Jun 21 11:23:39 2017
From: alaios at yahoo.com (Alaios)
Date: Wed, 21 Jun 2017 09:23:39 +0000 (UTC)
Subject: [R] 3D plot with coordinates
References: <523123308.3027789.1498037019855.ref@mail.yahoo.com>
Message-ID: <523123308.3027789.1498037019855@mail.yahoo.com>

Thanks a lot for the reply.After ?looking at different parts of the code today I was able to start with simple 2D polar plots as the attached pdf file. ?In case the attachment is not visible I used the plot.polar function to create something like that.https://vijaybarve.files.wordpress.com/2013/04/polarplot-05.png
Now the idea now will be to put three of those (for X,Y,Z) in a 3d rotatable plane. I tried the rgl function but is not clear how I can use directly polar coordinates to draw the points at the three different planes.?
Any ideas on that?
Thanks a lot.RegardsAlex

    On Tuesday, June 20, 2017 9:49 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
 

 package rgl.

Best,
Uwe Ligges


On 20.06.2017 21:29, Alaios via R-help wrote:
> HelloI have three x,y,z vectors (lets say each is set as? rnorm(360)). So each one is having 360 elements each one correpsonding to angular coordinates (1 degree, 2 degrees, 3 degrees,.... 360 degrees) and I want to plot those on the xyz axes that have degress.
> Is there a function or library to look at R cran? The ideal will be that after plotting I will be able to rotate the shape.
> I would like to thank you in advance for your helpRegardsAlex
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


   
-------------- next part --------------
A non-text attachment was scrubbed...
Name: XNoSink.pdf
Type: application/pdf
Size: 9099 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170621/7fa22202/attachment.pdf>

From murdoch.duncan at gmail.com  Wed Jun 21 13:07:23 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 21 Jun 2017 07:07:23 -0400
Subject: [R] 3D plot with coordinates
In-Reply-To: <523123308.3027789.1498037019855@mail.yahoo.com>
References: <523123308.3027789.1498037019855.ref@mail.yahoo.com>
 <523123308.3027789.1498037019855@mail.yahoo.com>
Message-ID: <4afa3ad4-8123-7650-03a2-e4f742a713a2@gmail.com>

On 21/06/2017 5:23 AM, Alaios via R-help wrote:
> Thanks a lot for the reply.After  looking at different parts of the code today I was able to start with simple 2D polar plots as the attached pdf file.  In case the attachment is not visible I used the plot.polar function to create something like that.https://vijaybarve.files.wordpress.com/2013/04/polarplot-05.png
> Now the idea now will be to put three of those (for X,Y,Z) in a 3d rotatable plane. I tried the rgl function but is not clear how I can use directly polar coordinates to draw the points at the three different planes.
> Any ideas on that?

You can't easily do what you're trying to do.  You have 6 coordinates to 
display:  the 3 angles and values corresponding to each of them.  You 
need to suppress something.

If the values for matching angles correspond to each other (e.g. x=23 
degrees and y=23 degrees and z=23 degrees all correspond to the same 
observation), then I'd suggest suppressing the angles.  Just do a 
scatterplot of the 3 corresponding values.  It might make sense to join 
them (to make a path as the angles change), and perhaps to colour the 
path to indicate the angle (or plot text along the path to show it).

Duncan Murdoch

> Thanks a lot.RegardsAlex
>
>     On Tuesday, June 20, 2017 9:49 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>
>
>  package rgl.
>
> Best,
> Uwe Ligges
>
>
> On 20.06.2017 21:29, Alaios via R-help wrote:
>> HelloI have three x,y,z vectors (lets say each is set as  rnorm(360)). So each one is having 360 elements each one correpsonding to angular coordinates (1 degree, 2 degrees, 3 degrees,.... 360 degrees) and I want to plot those on the xyz axes that have degress.
>> Is there a function or library to look at R cran? The ideal will be that after plotting I will be able to rotate the shape.
>> I would like to thank you in advance for your helpRegardsAlex
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From profjcnash at gmail.com  Wed Jun 21 14:17:47 2017
From: profjcnash at gmail.com (J C Nash)
Date: Wed, 21 Jun 2017 08:17:47 -0400
Subject: [R] fitting cosine curve
In-Reply-To: <CAN5afy9hLd3b_T=4cML=atu9Y8HDOBSw9BEQQ-f-_3=pn=k4ag@mail.gmail.com>
References: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
 <CA+8X3fUPPMracvU7UXe45z_r1OaFc0nJrXC0N52=tP94T2KUww@mail.gmail.com>
 <CAN5afy99ykBWs7-K6X-hM2e_uNCm+TM=XG2--QwNHZ-_JcwzMw@mail.gmail.com>
 <CAN5afy-x5SaN2mbbgX+HJ2UOnLq6uLk-yLhjVegTkDY4CBk2nQ@mail.gmail.com>
 <CA+8X3fXufDQCn1N8qzG1VmxU80tU_AFA36FLRuNQeR9OgesWaw@mail.gmail.com>
 <22857.52725.872950.40838@losangelesyouthorchestra.org>
 <CAN5afy9hLd3b_T=4cML=atu9Y8HDOBSw9BEQQ-f-_3=pn=k4ag@mail.gmail.com>
Message-ID: <bbb28996-8911-0bd2-2b87-1471420a199b@gmail.com>

Using a more stable nonlinear modeling tool will also help, but key is to get
the periodicity right.

y=c(16.82, 16.72, 16.63, 16.47, 16.84, 16.25, 16.15, 16.83, 17.41, 17.67,
17.62, 17.81, 17.91, 17.85, 17.70, 17.67, 17.45, 17.58, 16.99, 17.10)
t=c(7,  37,  58,  79,  96, 110, 114, 127, 146, 156, 161, 169, 176, 182,
190, 197, 209, 218, 232, 240)

lidata <- data.frame(y=y, t=t)

#I use the method to fit a curve, but it is different from the real curve,
#which can be seen in the figure.
linFit  <- lm(y ~ cos(t))
library(nlsr)
#fullFit <- nls(y ~ A*cos(omega*t+C) + B,
#start=list(A=coef(linFit)[1],B=coef(linFit)[2],C=0,omega=.4))
#omega cannot be set to 1, don't know why.
fullFit <- nlxb(y ~ A*cos(omega*t+C) + B, data=lidata,
  start=list(A=coef(linFit)[1],B=coef(linFit)[2],C=0,omega=.04), trace=TRUE)
co <- coef(fullFit)
fit <- function(x, a, b, c, d) {a*cos(b*x+c)+d}
plot(x=t, y=y)
curve(fit(x, a=co['A'], b=co['omega'], c=co['C'],d=co['B']), add=TRUE
,lwd=2, col="steelblue")
jstart <- list(A=20, B=100, C=0, omega=0.01)
jfit <- nlxb(y ~ A*cos(omega*t+C) + B, data=lidata,
         start=jstart, trace=TRUE)
co <- coef(jfit)
fit <- function(x, a, b, c, d) {a*cos(b*x+c)+d}
plot(x=t, y=y)
curve(fit(x, a=co['A'], b=co['omega'], c=co['C'],d=co['B']), add=TRUE
       ,lwd=2, col="steelblue")

JN

On 2017-06-21 12:06 AM, lily li wrote:
> I'm trying the different parameters, but don't know what the error is:
> Error in nlsModel(formula, mf, start, wts) :
>    singular gradient matrix at initial parameter estimates
> 
> Thanks for any suggestions.
> 
> On Tue, Jun 20, 2017 at 7:37 PM, Don Cohen <don-r-help at isis.cs3-inc.com>
> wrote:
> 
>>
>> If you know the period and want to fit phase and amplitude, this is
>> equivalent to fitting a * sin + b * cos
>>
>>   > >>> > I don't know how to set the approximate starting values.
>>
>> I'm not sure what you meant by that, but I suspect it's related to
>> phase and amplitude.
>>
>>   > >>> > Besides, does the method work for sine curve as well?
>>
>> sin is the same as cos with a different phase
>> Any combination of a and b above = c * sin (theta + d) for
>> some value of c and d and = e * cos (theta + f) for some value
>> of e and f.
>> Also for any c,d and for any e,f there is an a,b.
>> the c and e are what I'm calling amplitude, the d and f are what
>> I'm calling phase.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alaios at yahoo.com  Wed Jun 21 15:16:53 2017
From: alaios at yahoo.com (Alaios)
Date: Wed, 21 Jun 2017 13:16:53 +0000 (UTC)
Subject: [R] 3D plot with coordinates
In-Reply-To: <4afa3ad4-8123-7650-03a2-e4f742a713a2@gmail.com>
References: <523123308.3027789.1498037019855.ref@mail.yahoo.com>
 <523123308.3027789.1498037019855@mail.yahoo.com>
 <4afa3ad4-8123-7650-03a2-e4f742a713a2@gmail.com>
Message-ID: <2082695275.376356.1498051013890@mail.yahoo.com>

Thanks Duncan for the replyI can not suppress anything these are radiation pattern measurements that are typically are taken at X,Y and Z planes. See an example here, where I want to plot the measurements for the red, green and blue planes (so the image below withouth the 3d green structure inside)https://www.researchgate.net/publication/258391165/figure/fig7/AS:322947316240401 at 1454008048835/Radiation-pattern-of-Archimedean-spiral-antenna-a-3D-and-b-elevation-cuts-at-phi.png?

I am quite confident that there is a tool in R to help me do this 3D plot, and even better rotatable.
Thanks for the reply to allAlex 

    On Wednesday, June 21, 2017 1:07 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
 

 On 21/06/2017 5:23 AM, Alaios via R-help wrote:
> Thanks a lot for the reply.After? looking at different parts of the code today I was able to start with simple 2D polar plots as the attached pdf file.? In case the attachment is not visible I used the plot.polar function to create something like that.https://vijaybarve.files.wordpress.com/2013/04/polarplot-05.png
> Now the idea now will be to put three of those (for X,Y,Z) in a 3d rotatable plane. I tried the rgl function but is not clear how I can use directly polar coordinates to draw the points at the three different planes.
> Any ideas on that?

You can't easily do what you're trying to do.? You have 6 coordinates to 
display:? the 3 angles and values corresponding to each of them.? You 
need to suppress something.

If the values for matching angles correspond to each other (e.g. x=23 
degrees and y=23 degrees and z=23 degrees all correspond to the same 
observation), then I'd suggest suppressing the angles.? Just do a 
scatterplot of the 3 corresponding values.? It might make sense to join 
them (to make a path as the angles change), and perhaps to colour the 
path to indicate the angle (or plot text along the path to show it).

Duncan Murdoch

> Thanks a lot.RegardsAlex
>
>? ? On Tuesday, June 20, 2017 9:49 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>
>
>? package rgl.
>
> Best,
> Uwe Ligges
>
>
> On 20.06.2017 21:29, Alaios via R-help wrote:
>> HelloI have three x,y,z vectors (lets say each is set as? rnorm(360)). So each one is having 360 elements each one correpsonding to angular coordinates (1 degree, 2 degrees, 3 degrees,.... 360 degrees) and I want to plot those on the xyz axes that have degress.
>> Is there a function or library to look at R cran? The ideal will be that after plotting I will be able to rotate the shape.
>> I would like to thank you in advance for your helpRegardsAlex
>>? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



   
	[[alternative HTML version deleted]]


From tofighizahra at gmail.com  Wed Jun 21 11:19:14 2017
From: tofighizahra at gmail.com (Zahra Tofighi)
Date: Wed, 21 Jun 2017 13:49:14 +0430
Subject: [R] Problem with shortestPath in igraph and qgraph
In-Reply-To: <639F9E5A-FDF6-474E-B678-A0BEB0D84745@dcn.davis.ca.us>
References: <CAP6isFpV_6d354NP3N-VgNaYsyDi6e-qOX=6gaKxBTUTT=Q2iA@mail.gmail.com>
 <639F9E5A-FDF6-474E-B678-A0BEB0D84745@dcn.davis.ca.us>
Message-ID: <CAP6isFoiFbWErifT0EdVJ167bUc9aK5_-WQQnokLmUxS7rzyLA@mail.gmail.com>

I hope this new post be according to  your tips.
My database is big so i upload it in Dropbox and here is the link to
download it:
https://www.dropbox.com/pri/get/cognitiveEdges.csv?_subject_uid=680429290&w=AADQFwqcK-l66BiR4hcJayEc8dFbn0YNHdzeJ7ErqiKr1g

and here is code to run in R studio (3.4.0) :
 rm(list = ls())
library("igraph")
library("qgraph")
library("data.table")
links <- read.csv("C:/result21/CognitiveEdges.csv", header=T, as.is=T) #
Address of file
nrow(links); nrow(unique(links[,c("From", "To")]))
nrow(unique(links[,c("From", "To")]))
net <- graph_from_data_frame(d=links, directed=T)
Q<-qgraph(as_adjacency_matrix(net))
cen<-centrality(Q)
 tmp3 <- shortest.paths(net,V(net),V(net))
cen<-centrality(Q)
tmp3<-cen$ShortestPathLengths
re<-function(tmp3){
shp<-matrix(1:ncol(tmp3),ncol(tmp3),1)
for(i in ncol(tmp3))
{
shp[i,]<-max(tmp3[i,][tmp3[i,]!=Inf])}
return(shp)
}
mm<-re(tmp3)### my problem is here Line 21
max(tmp3[1,][tmp3[1,]!=Inf]) # line 22

my problem is at line 21. Why the result of mm[1,] is not same as line 22??
for other elements of mm also i didn't get the true result.
With Regards,

On Wed, Jun 21, 2017 at 9:35 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Hard to follow data analysis without data. Try making your example
> reproducible [1][2][3] and post in plain text (a setting in your emailer).
> Read the Posting Guide mentioned in the footer to avoid other posting
> pitfalls.
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-
> a-great-r-reproducible-example
>
> [2] http://adv-r.had.co.nz/Reproducibility.html
>
> [3] https://cran.r-project.org/web/packages/reprex/index.html
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 20, 2017 11:15:23 AM PDT, Zahra Tofighi <tofighizahra at gmail.com>
> wrote:
> >hello,
> >
> >I have a graph and i use qgraph package to calculate centrality
> >parameters.
> >Now I want to know the maximum value of shortest path for each vertex
> >with
> >discarding the Inf value in short pathes. For this I use the
> >ShortestPathLengths of centrality function in qgraph. but when I want
> >to
> >get the maximum the result is wrong. here is my code:
> >
> >cen<-centrality(Q)
> >
> >tmp3<-cen$ShortestPathLengths
> >shp<-matrix(1:ncol(tmp3),ncol(tmp3),1)for(i in ncol(tmp3)){
> >shp[i,]=max(tmp3[i,][tmp3[i,]!=Inf)}
> >
> >when I display the valu of shp the result is same as initial value
> >(form
> >one to ncol). I also test with shortest.paths function. the result was
> >same. what is my wrong?
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From SDai9 at its.jnj.com  Wed Jun 21 15:24:22 2017
From: SDai9 at its.jnj.com (Dai, Shengyu [HCSUS])
Date: Wed, 21 Jun 2017 13:24:22 +0000
Subject: [R] R and Tableau Compatibility
Message-ID: <64DE9B53935A66478F4E062D29E1C3558D7061@ITSUSRAGMDGF04.jnj.com>

Good morning R helpers,

I hope this email finds you well.

Recently, I am thinking of using R with connection to Tableau. I search information online but I did not see any official documentations about these compatibilities. I have Tableau version 10.1 and I wonder which versionS of R is compatible to this Tableau version.

Thank you very much. Your quick assistance will be appreciated.

Best,
Shengyu





	[[alternative HTML version deleted]]


From margotneyret at gmail.com  Wed Jun 21 15:56:45 2017
From: margotneyret at gmail.com (Margot Neyret)
Date: Wed, 21 Jun 2017 15:56:45 +0200
Subject: [R] Permutations in RDA for repeated measures, using how()
Message-ID: <c780ce28-4ce4-4b50-8a35-aa1d8c4fbcdc@Canary>

Dear all,

I am using RDA to study plant communities in various land uses (variable LU with values M, U, etc.). For each land use, I sample 3 to 5 fields (M1, M2, U1, U2, etc). I make 5 measurements for both plant communities and environmental variables in each field.
I repeat the process every 6 months to study the effect of time and season (D16 for dry season 2017, R16 for rainy season 2016, etc). For field M1 for instance, I have the values for the field_in_season M1-D16, M1-R16, M1-D17.

My 5 measurements are interdependent; and there is also temporal dependance for the field_in_season within the fields.

When I want to test the significance of my RDA, I should thus constrain the permutation to take this into account.

If I am correct (if not please tell me so), in linear models I should write :
> lme(Y ~ X, random = ~1|Field_in_season/Field)

>From various reads, I understand that in RDA I should not only use the strata = Plot argument, but allow for permutation of measurements within field_in_season, and for permutations among Field_in_season. So that would be :

> rda_repeated = anova(rda(Community~LU + Humidity, data = env), by = 'term', permutation = how(within = Within(type = "series", mirror = TRUE), plots = Plots(strata = Field_in_season, type = "series"), blocks = Field))

Is that right ? In the output I get very similar results and ?Permutation : free? in both cases, which dos not seem right.

Thanks,
Margot

??????
??????

> Community = matrix(ncol = 10,nrow = 1350)
> colnames(Community) = letters[1:10]
> for (i in letters[1:10]){
> Community[,i] = rpois(135, 3)
}

> Season = rep(c('D16', 'R16','D17'), each = 450)
> LU = rep(c('M', 'U', 'O'), each = 15, length.out = 1350)
> Field = paste(LU, rep(c(1:3), each = 50), sep = '')
> Field_in_season = paste(Field,Season, sep = '-')
> Humidity = rnorm(n=1350, mean = 100)
> env = data.frame(Season, LU, Field, Field_in_season)

> library(FactoMineR)

> anova(rda(Community~LU + Humidity, data = env), by = 'term?) # Without specification for permutations

> anova(rda(Community~LU + Humidity, data = env), by = 'term?, # With restricted permutations
permutation = how(within = Within(type = "series", mirror = TRUE),
plots = Plots(strata = Field_in_season, type = "series"),
blocks = Field))

Permutation test for rda under reduced model
Terms added sequentially (first to last)
Permutation: free
Number of permutations: 999

Model: rda(formula = Community ~ LU + Humidity, data = env)
Df Variance F Pr(>F)
LU 2 0.4427 9.7954 0.001 ***
Humidity 1 0.0283 1.2508 0.247
Residual 1346 30.4150
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


	[[alternative HTML version deleted]]


From Scott.Waichler at pnnl.gov  Wed Jun 21 16:28:40 2017
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Wed, 21 Jun 2017 14:28:40 +0000
Subject: [R] customizing color key with plot3D
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881BA45E20@EX10MBOX03.pnnl.gov>

Karline,

Thank you for your help.  I discovered that in addition to including clim, I needed to omit breaks.  This code uses one of your other examples as a starting point and works as intended:

persp3D(z = volcano, zlim = c(-60, 200), phi = 20,
        colkey = list(length = 0.2, width = 0.4, shift = 0.15,
        cex.axis = 0.8, cex.clab = 0.85), lighting = TRUE, lphi = 90,
        clab = c("","height","m"), bty = "f", plot = FALSE)
elev.classes <- matrix(findInterval(volcano, vec = seq(50, 200, by=50)), nrow=nrow(volcano), ncol=ncol(volcano))
class.colors <- c("red", "blue", "green")
# add as image with own color key, at bottom
image3D(z = -60, colvar = elev.classes, add = TRUE,
        col = class.colors, #breaks = seq(0.5, 3.5, by=1),
        clim=c(1,3), 
        colkey = list(length = 0.2, width = 0.4, shift = -0.15,
                      cex.axis = 0.8, cex.clab = 0.85, addlines=TRUE, tick=FALSE, 
                      at = c(1.33, 2, 2.66), labels=paste("Class", 1:3)),
        clab = c("","Elev Classes"), plot = TRUE)

Your package plot3D is a huge help to me.  Previously I had to use a completely different software, VisIt, to do these kinds of composite plots.  R is my preferred tool and it is great to finally be able to do these at "home".

Thanks,
Scott Waichler
scott.waichler at pnnl.gov
Pacific Northwest National Laboratory
Richland, Washington, USA

> -----Original Message-----
> From: Karline Soetaert [mailto:Karline.Soetaert at nioz.nl]
> Sent: Wednesday, June 21, 2017 4:16 AM
> To: Waichler, Scott R
> Subject: RE: customizing color key with plot3D
> 
> There is an example in the colkey help file:
> 
> example(colkey)
> 
> will show it ( working on the iris dataset)
> 
> I think the basic thing is that you can use "at"  to position the labels but then
> you also have to specify clim , i.e. "at = c(1.33, 2, 2.66), clim = c(0.5,3.5), col =
> jetc.col(3)...."
> 
> Here is the example:
> 
> with(iris, scatter3D(x = Sepal.Length, y = Sepal.Width,
>     z = Petal.Length, colvar = as.integer(Species),
>    col = c("orange", "green", "lightblue"), pch = 16, cex = 2,
>     clim = c(1, 3), ticktype = "detailed", phi = 20,
>     xlab = "Sepal Length", ylab = "Sepal Width",
>     zlab = "Petal Length",  main = "iris",
>     colkey = list(at = c(1.33, 2, 2.66), side = 1,
>    addlines = TRUE, length = 0.5, width = 0.5,
>    labels = c("setosa", "versicolor", "virginica") )))
> 
> 
> hope it helps,
> 
> 
> Karline
> 
> -----Original Message-----
> From: Waichler, Scott R [mailto:Scott.Waichler at pnnl.gov]
> Sent: woensdag 21 juni 2017 2:01
> To: R. Help <r-help at r-project.org>
> Cc: Karline Soetaert <Karline.Soetaert at nioz.nl>
> Subject: customizing color key with plot3D
> 
> Hi, I am doing composite plots with the package plot3D.  One of my
> variables is qualitative and indexed to integers, and I would like the legend
> for it to have labels located at the integer values (midpoints), and not at the
> breaks between classes.  In the example below, the Elev Classes legend has
> labels at the breaks and nothing at the midpoints.  How can I show the class
> labels at 1:3, and not the breaks?
> 
> library(plot3D)
> persp3D(z = volcano, zlim = c(-60, 200), phi = 20,
>         colkey = list(length = 0.2, width = 0.4, shift = 0.15,
>         cex.axis = 0.8, cex.clab = 0.85), lighting = TRUE, lphi = 90,
>         clab = c("","height","m"), bty = "f", plot = FALSE) # classify the volcano
> elevations with 3 classes elev.classes <- matrix(findInterval(volcano, vec =
> seq(50, 200, by=50)), nrow=nrow(volcano), ncol=ncol(volcano)) class.colors
> <- c("red", "blue", "green") # add as image with own color key, at bottom
> image3D(z = -60, colvar = elev.classes, add = TRUE,
>         col = class.colors, breaks = seq(0.5, 3.5, by=1),
>         colkey = list(length = 0.2, width = 0.4, shift = -0.15,
>                       cex.axis = 0.8, cex.clab = 0.85, addlines=TRUE, tick=FALSE,
>                       at = 1:3, labels=paste("Class", 1:3)),
>         clab = c("","Elev Classes"), plot = TRUE)
> 
> Thanks,
> Scott
> 
> Scott Waichler
> Pacific Northwest National Laboratory
> Richland, Washington, USA
> scott.waichler at pnnl.gov


From dwinsemius at comcast.net  Wed Jun 21 16:43:25 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Jun 2017 07:43:25 -0700
Subject: [R] R and Tableau Compatibility
In-Reply-To: <64DE9B53935A66478F4E062D29E1C3558D7061@ITSUSRAGMDGF04.jnj.com>
References: <64DE9B53935A66478F4E062D29E1C3558D7061@ITSUSRAGMDGF04.jnj.com>
Message-ID: <0373476D-4F0A-4573-89C0-2866CA255992@comcast.net>


> On Jun 21, 2017, at 6:24 AM, Dai, Shengyu [HCSUS] <SDai9 at its.jnj.com> wrote:
> 
> Good morning R helpers,
> 
> I hope this email finds you well.
> 
> Recently, I am thinking of using R with connection to Tableau. I search information online but I did not see any official documentations about these compatibilities. I have Tableau version 10.1 and I wonder which versionS of R is compatible to this Tableau version.

Not sure what you are expecting. When I go to the Tableau website and search their "Support" links I almost immediately find:

https://www.tableau.com/search#q=r&t=support

Following a link with the word "configuring" I see:

http://kb.tableau.com/articles/HowTo/configuring-tableau-server-for-r-and-rserve

.... which says to use the current version of R. Since you are using a closed-source, commercial product., you really should be asking this question on their support portal.

> 
> Thank you very much. Your quick assistance will be appreciated.
> 
> Best,
> Shengyu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ccberry at ucsd.edu  Wed Jun 21 18:48:41 2017
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Wed, 21 Jun 2017 09:48:41 -0700
Subject: [R] fitting cosine curve
In-Reply-To: <bbb28996-8911-0bd2-2b87-1471420a199b@gmail.com>
References: <CAN5afy8_J-nZz0jrr0=O4s=6r5iTMTaypg19jPgtfveOgMDw6g@mail.gmail.com>
 <CA+8X3fUPPMracvU7UXe45z_r1OaFc0nJrXC0N52=tP94T2KUww@mail.gmail.com>
 <CAN5afy99ykBWs7-K6X-hM2e_uNCm+TM=XG2--QwNHZ-_JcwzMw@mail.gmail.com>
 <CAN5afy-x5SaN2mbbgX+HJ2UOnLq6uLk-yLhjVegTkDY4CBk2nQ@mail.gmail.com>
 <CA+8X3fXufDQCn1N8qzG1VmxU80tU_AFA36FLRuNQeR9OgesWaw@mail.gmail.com>
 <22857.52725.872950.40838@losangelesyouthorchestra.org>
 <CAN5afy9hLd3b_T=4cML=atu9Y8HDOBSw9BEQQ-f-_3=pn=k4ag@mail.gmail.com>
 <bbb28996-8911-0bd2-2b87-1471420a199b@gmail.com>
Message-ID: <alpine.OSX.2.20.1706210924040.919@charles-berrys-macbook.local>

On Wed, 21 Jun 2017, J C Nash wrote:

> Using a more stable nonlinear modeling tool will also help, but key is to get
> the periodicity right.
>

The model is linear up to omega after transformation as Don and I noted.

Taking a guess that 2*pi/240 = 0.0262 is about right for omega:

> rsq <- function(x) {t2<-t*x;summary(lm(y~cos(t2)+sin(t2)))$r.squared}
> vrsq <- Vectorize(rsq)
> optimise(rsq, c(0.8,1.2)*2*pi/240,maximum=TRUE)
$maximum
[1] 0.02794878

$objective
[1] 0.8127072

> curve(vrsq,0.025,0.03)
>

Isn't this stable enough?

And as you note

plot(lm(y~cos(t*0.0279)+sin(t*0.0279)))

reveals lack-of-fit.

Of course there are some other issues not addressed here such as 
possible autoregression.

HTH,

Chuck

> y=c(16.82, 16.72, 16.63, 16.47, 16.84, 16.25, 16.15, 16.83, 17.41, 17.67,
> 17.62, 17.81, 17.91, 17.85, 17.70, 17.67, 17.45, 17.58, 16.99, 17.10)
> t=c(7,  37,  58,  79,  96, 110, 114, 127, 146, 156, 161, 169, 176, 182,
> 190, 197, 209, 218, 232, 240)
>
> lidata <- data.frame(y=y, t=t)
>
> #I use the method to fit a curve, but it is different from the real curve,
> #which can be seen in the figure.
> linFit  <- lm(y ~ cos(t))
> library(nlsr)
> #fullFit <- nls(y ~ A*cos(omega*t+C) + B,
> #start=list(A=coef(linFit)[1],B=coef(linFit)[2],C=0,omega=.4))
> #omega cannot be set to 1, don't know why.
> fullFit <- nlxb(y ~ A*cos(omega*t+C) + B, data=lidata,
> start=list(A=coef(linFit)[1],B=coef(linFit)[2],C=0,omega=.04), trace=TRUE)
> co <- coef(fullFit)
> fit <- function(x, a, b, c, d) {a*cos(b*x+c)+d}
> plot(x=t, y=y)
> curve(fit(x, a=co['A'], b=co['omega'], c=co['C'],d=co['B']), add=TRUE
> ,lwd=2, col="steelblue")
> jstart <- list(A=20, B=100, C=0, omega=0.01)
> jfit <- nlxb(y ~ A*cos(omega*t+C) + B, data=lidata,
>        start=jstart, trace=TRUE)
> co <- coef(jfit)
> fit <- function(x, a, b, c, d) {a*cos(b*x+c)+d}
> plot(x=t, y=y)
> curve(fit(x, a=co['A'], b=co['omega'], c=co['C'],d=co['B']), add=TRUE
>      ,lwd=2, col="steelblue")
>
> JN
>
> On 2017-06-21 12:06 AM, lily li wrote:
>> I'm trying the different parameters, but don't know what the error is:
>> Error in nlsModel(formula, mf, start, wts) :
>>    singular gradient matrix at initial parameter estimates
>> 
>> Thanks for any suggestions.
>> 
>> On Tue, Jun 20, 2017 at 7:37 PM, Don Cohen <don-r-help at isis.cs3-inc.com>
>> wrote:
>> 
>>> 
>>> If you know the period and want to fit phase and amplitude, this is
>>> equivalent to fitting a * sin + b * cos
>>>
>>>   > >>> > I don't know how to set the approximate starting values.
>>> 
>>> I'm not sure what you meant by that, but I suspect it's related to
>>> phase and amplitude.
>>>
>>>   > >>> > Besides, does the method work for sine curve as well?
>>> 
>>> sin is the same as cos with a different phase
>>> Any combination of a and b above = c * sin (theta + d) for
>>> some value of c and d and = e * cos (theta + f) for some value
>>> of e and f.
>>> Also for any c,d and for any e,f there is an a,b.
>>> the c and e are what I'm calling amplitude, the d and f are what
>>> I'm calling phase.
>>> 
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>

Charles C. Berry                 Dept of Family Medicine & Public Health
cberry at ucsd edu               UC San Diego / La Jolla, CA 92093-0901
http://biostat.ucsd.edu/ccberry.htm


From ahmedatia80 at gmail.com  Wed Jun 21 20:19:49 2017
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Wed, 21 Jun 2017 20:19:49 +0200
Subject: [R] Help/ Mathematics
Message-ID: <CAG6S0OknML6GVEdhV17gTK7kQn0WLNhgLMJULp12Wxme7eNM3g@mail.gmail.com>

Hi R users,

I need your help to write a code in r that does the following
calculation from three different datasets;

ac = 1/sum (NPP from date 1 to date 2, dataset=1) * (biomass at date 2
-biomass at date 1, dataset = 2) + (littfall at date 2, dataset=3).

all the dates are in yr-month-day format. Which library or function
Should I use to tell R do these calculations of these variables at
different dates.

I appreciate your help.

Ahmed Attia, Ph.D.
Agronomist & Soil Scientist


From eric.weine at truqua.com  Wed Jun 21 16:16:49 2017
From: eric.weine at truqua.com (Eric Weine)
Date: Wed, 21 Jun 2017 09:16:49 -0500
Subject: [R] Cross-Validation for Zero-Inflated Models
Message-ID: <1E3ACDE6-49DF-4D78-ADC7-1C88EB085672@truqua.com>

Lara:

I see you sent this email to the R helpdesk a really long time ago, but I was just wondering if you ever got an answer to this question. I was just thinking that I would build my own cross validation function, but if you figured out a way to do this automatically, could you let me know?

Thanks,

Eric Weine.

From evan.cooch at gmail.com  Wed Jun 21 18:11:10 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 21 Jun 2017 12:11:10 -0400
Subject: [R] selecting dataframe columns based on substring of col name(s)
Message-ID: <dbecd23c-aa72-f3ec-8032-a16485a3195c@gmail.com>

Suppose I have the following sort of dataframe, where each column name 
has a common structure: prefix, followed by a number (for this example, 
col1, col2, col3 and col4):

  d = data.frame( col1=runif(10), col2=runif(10), 
col3=runif(10),col4=runif(10))

What I haven't been able to suss out is how to efficiently 
'extract/manipulate/play with' columns from the data frame, making use 
of this common structure.

Suppose, for example, I want to 'work with' col2, col3, and col4. Now, I 
could subset the dataframe d in any number of ways -- for example

piece <- d[,c("col2","col3","col4")]

Works as expected, but for *big* problems (where I might have dozens -> 
hundreds of columns -- often the case with big design matrices output by 
some linear models program or another), having to write them all out 
using c("col2","col3",...."colXXXXX") takes a lot of time. What I'm 
wondering about is if there is a way to simply select over the "changing 
part" of the column name (you can do this relatively easily in a data 
step in SAS, for example). Heuristically, something like:

piece <- df[,col2:col4]

where the heuristic col2:col4 is interpreted as col2 -> col4 (parse the 
prefix 'col', and then simply select over the changing suffic -- i.e., 
column number).

Now, if I use the "to" function in the lessR package, I can get there 
from here fairly easily:

piece <- d[,to("col",4,from=2,same.size=FALSE)]

But, is there a better way? Beyond 'efficiency' (ease of 
implementation), part of what constitutes 'better' might be something in 
base R, rather than relying on a package?

Thanks in advance...


From mash at econs.umass.edu  Wed Jun 21 17:08:30 2017
From: mash at econs.umass.edu (Michael Ash)
Date: Wed, 21 Jun 2017 11:08:30 -0400
Subject: [R] Advanced bootstrap question
Message-ID: <CAKTWfUOqZwzwi9ZJrytg2MZY2UhQ1iktc8fn0chyX1oiwzknuw@mail.gmail.com>

I have an advanced question about bootstrapping.

There are two datasets.  In each bootstrap iteration, I would like to
sample
One observation per cluster from the first dataset.
N observations with replacement from the second dataset.

Right now I am using dplyr::sample_n() for first dataset, with this
sampling embedded in the program that boot() from the boot package is
running to sample the second dataset and produce the estimates.

I would prefer to do the entire sampling in the boot() part as opposed to
embedding the sample_n() statement.  The reason is so that the "original"
results will indeed be on the full data rather than on a particular sample
from the first dataset.

Any thoughts on how to implement? I think that this involves using strata
and weights to "fool" boot to sample from a concatenation of the two
datasets. The two datasets have entirely different contents (variable and
numbers of observations.  MWE follows:


library(boot)
library(car)
library(dplyr)

(first.df  <- data.frame(cluster=gl(2,2,4),z=seq(1,2)))
(second.df  <- data.frame(y=1:2))

boot_script  <- function(X,d) {
    zbar  <- mean(sample_n(group_by(first.df,cluster),1)$z)
    return( c(zbar,  zbar * mean(X[d,"y"]) ))
}

## Results based on the original data
(original.zbar  <- mean(first.df$z))
mean(original.zbar * second.df[,"y"])

## Bootstrapped results
## Problem: "Original" is itself based on a sampling
for( i in c(1:10)) {
    b  <- boot(second.df, boot_script, R=100)
    print(summary(b))
}





Thank you very much.

-- 
Michael Ash, Chair, Department of Economics
Professor of Economics and Public Policy
University of Massachusetts Amherst
Email mash at econs.umass.edu
Tel +1-413-545-4815 <(413)%20545-4815> Twitter https://twitter.com/
michaelaoash

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jun 21 20:54:03 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 21 Jun 2017 11:54:03 -0700
Subject: [R] selecting dataframe columns based on substring of col
	name(s)
In-Reply-To: <dbecd23c-aa72-f3ec-8032-a16485a3195c@gmail.com>
References: <dbecd23c-aa72-f3ec-8032-a16485a3195c@gmail.com>
Message-ID: <9107DD22-B429-420C-A69E-B662444872EE@dcn.davis.ca.us>

d[ , paste( "col", 2:4 ) ]

or

d[ , sprintf( "col%d", 2:4 ) ]

or

d[ , grep( "^col[234]$", names( d ) ]

Each approach has different ways of being flexible.
-- 
Sent from my phone. Please excuse my brevity.

On June 21, 2017 9:11:10 AM PDT, Evan Cooch <evan.cooch at gmail.com> wrote:
>Suppose I have the following sort of dataframe, where each column name 
>has a common structure: prefix, followed by a number (for this example,
>
>col1, col2, col3 and col4):
>
>  d = data.frame( col1=runif(10), col2=runif(10), 
>col3=runif(10),col4=runif(10))
>
>What I haven't been able to suss out is how to efficiently 
>'extract/manipulate/play with' columns from the data frame, making use 
>of this common structure.
>
>Suppose, for example, I want to 'work with' col2, col3, and col4. Now,
>I 
>could subset the dataframe d in any number of ways -- for example
>
>piece <- d[,c("col2","col3","col4")]
>
>Works as expected, but for *big* problems (where I might have dozens ->
>
>hundreds of columns -- often the case with big design matrices output
>by 
>some linear models program or another), having to write them all out 
>using c("col2","col3",...."colXXXXX") takes a lot of time. What I'm 
>wondering about is if there is a way to simply select over the
>"changing 
>part" of the column name (you can do this relatively easily in a data 
>step in SAS, for example). Heuristically, something like:
>
>piece <- df[,col2:col4]
>
>where the heuristic col2:col4 is interpreted as col2 -> col4 (parse the
>
>prefix 'col', and then simply select over the changing suffic -- i.e., 
>column number).
>
>Now, if I use the "to" function in the lessR package, I can get there 
>from here fairly easily:
>
>piece <- d[,to("col",4,from=2,same.size=FALSE)]
>
>But, is there a better way? Beyond 'efficiency' (ease of 
>implementation), part of what constitutes 'better' might be something
>in 
>base R, rather than relying on a package?
>
>Thanks in advance...
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Jun 21 20:54:49 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 21 Jun 2017 11:54:49 -0700
Subject: [R] Help/ Mathematics
In-Reply-To: <CAG6S0OknML6GVEdhV17gTK7kQn0WLNhgLMJULp12Wxme7eNM3g@mail.gmail.com>
References: <CAG6S0OknML6GVEdhV17gTK7kQn0WLNhgLMJULp12Wxme7eNM3g@mail.gmail.com>
Message-ID: <CAGxFJbSXA8wZ9M0XHMYzUa-3urp7jG72nh45M_OFWQV73gEyBA@mail.gmail.com>

We expect posters to have made an effort to learn R and show us code
that they have tried. We do not provide free software development. The
"Introduction to R" tutorial that ships with the software is one place
to start, but there are many good web tutorials also available. Just
search.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 21, 2017 at 11:19 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> Hi R users,
>
> I need your help to write a code in r that does the following
> calculation from three different datasets;
>
> ac = 1/sum (NPP from date 1 to date 2, dataset=1) * (biomass at date 2
> -biomass at date 1, dataset = 2) + (littfall at date 2, dataset=3).
>
> all the dates are in yr-month-day format. Which library or function
> Should I use to tell R do these calculations of these variables at
> different dates.
>
> I appreciate your help.
>
> Ahmed Attia, Ph.D.
> Agronomist & Soil Scientist
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shivipmp82 at gmail.com  Wed Jun 21 21:05:01 2017
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Wed, 21 Jun 2017 19:05:01 +0000 (UTC)
Subject: [R] R and Tableau Compatibility
In-Reply-To: <0373476D-4F0A-4573-89C0-2866CA255992@comcast.net>
References: <64DE9B53935A66478F4E062D29E1C3558D7061@ITSUSRAGMDGF04.jnj.com>
 <0373476D-4F0A-4573-89C0-2866CA255992@comcast.net>
Message-ID: <1886396027.676909.1498071901256@mail.yahoo.com>

 blockquote, div.yahoo_quoted { margin-left: 0 !important; border-left:1px #715FFA solid !important; padding-left:1ex !important; background-color:white !important; } R and Tableau can easily get connected with their latest versions. I have been using both for my case.?10.1 version of tableau can connect to R studio you have to write your scripts in R and then call those in tableau.?
Thanks.


Sent from Yahoo Mail for iPhone


On Wednesday, June 21, 2017, 8:13 PM, David Winsemius <dwinsemius at comcast.net> wrote:


> On Jun 21, 2017, at 6:24 AM, Dai, Shengyu [HCSUS] <SDai9 at its.jnj.com> wrote:
> 
> Good morning R helpers,
> 
> I hope this email finds you well.
> 
> Recently, I am thinking of using R with connection to Tableau. I search information online but I did not see any official documentations about these compatibilities. I have Tableau version 10.1 and I wonder which versionS of R is compatible to this Tableau version.

Not sure what you are expecting. When I go to the Tableau website and search their "Support" links I almost immediately find:

https://www.tableau.com/search#q=r&t=support

Following a link with the word "configuring" I see:

http://kb.tableau.com/articles/HowTo/configuring-tableau-server-for-r-and-rserve

.... which says to use the current version of R. Since you are using a closed-source, commercial product., you really should be asking this question on their support portal.

> 
> Thank you very much. Your quick assistance will be appreciated.
> 
> Best,
> Shengyu
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jun 21 21:08:50 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 21 Jun 2017 12:08:50 -0700
Subject: [R] selecting dataframe columns based on substring of col
	name(s)
In-Reply-To: <dbecd23c-aa72-f3ec-8032-a16485a3195c@gmail.com>
References: <dbecd23c-aa72-f3ec-8032-a16485a3195c@gmail.com>
Message-ID: <CAGxFJbRyZOgfyjGT5k3a_DuisqNWi7zQ9enzERLcwKmBzr=_qw@mail.gmail.com>

Assume there 100 columns, named col1, col2,..., col100 in data frame d
+ maybe some more columns with various names preceding them. You want
col21 to col72.

nm <- names(d)
d[, which(nm == "col21"): which(nm == "col72") ]

## NB : if all you have is col1 to col100 the d[, 23:72] works fine.

See any good tutorial on R for how to index matrix like structures in R.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 21, 2017 at 9:11 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
> Suppose I have the following sort of dataframe, where each column name has a
> common structure: prefix, followed by a number (for this example, col1,
> col2, col3 and col4):
>
>  d = data.frame( col1=runif(10), col2=runif(10),
> col3=runif(10),col4=runif(10))
>
> What I haven't been able to suss out is how to efficiently
> 'extract/manipulate/play with' columns from the data frame, making use of
> this common structure.
>
> Suppose, for example, I want to 'work with' col2, col3, and col4. Now, I
> could subset the dataframe d in any number of ways -- for example
>
> piece <- d[,c("col2","col3","col4")]
>
> Works as expected, but for *big* problems (where I might have dozens ->
> hundreds of columns -- often the case with big design matrices output by
> some linear models program or another), having to write them all out using
> c("col2","col3",...."colXXXXX") takes a lot of time. What I'm wondering
> about is if there is a way to simply select over the "changing part" of the
> column name (you can do this relatively easily in a data step in SAS, for
> example). Heuristically, something like:
>
> piece <- df[,col2:col4]
>
> where the heuristic col2:col4 is interpreted as col2 -> col4 (parse the
> prefix 'col', and then simply select over the changing suffic -- i.e.,
> column number).
>
> Now, if I use the "to" function in the lessR package, I can get there from
> here fairly easily:
>
> piece <- d[,to("col",4,from=2,same.size=FALSE)]
>
> But, is there a better way? Beyond 'efficiency' (ease of implementation),
> part of what constitutes 'better' might be something in base R, rather than
> relying on a package?
>
> Thanks in advance...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Wed Jun 21 21:20:42 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Wed, 21 Jun 2017 21:20:42 +0200
Subject: [R] Segmentation Fault when Installing Some Packages
Message-ID: <20170621192042.5n3pncj5fau3evbt@chicca>

Dear All,
I have a fresh Debian Stretch (now the official Debian stable)
installation on my machine.
Based on what written here

https://cran.r-project.org/bin/linux/debian/#debian-jessie-stable

I added the line

deb https://stat.ethz.ch/CRAN/bin/linux/debian stretch-cran34/

to my sources in order to have a backport of R 3.4.

The issue is that I am now experiencing some troubles to install some
packages from cran which did not give me any trouble in the past.
The worst is that all I get is an uninformative segmentation fault
error.
For instance, consider the RJSDMX package

> install.packages("RJSDMX")
Installing package into ?/usr/local/lib/R/site-library?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
trying URL 'https://lib.ugent.be/CRAN/src/contrib/RJSDMX_1.7.tar.gz'
Content type 'application/x-gzip' length 155642 bytes (151 KB)
==================================================
downloaded 151 KB

* installing *source* package ?RJSDMX? ...
** package ?RJSDMX? successfully unpacked and MD5 sums checked
** R
** demo
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
Segmentation fault
ERROR: loading failed
* removing ?/usr/local/lib/R/site-library/RJSDMX?

The downloaded source packages are in
	?/tmp/RtmpkjeaiB/downloaded_packages?
Warning message:
In install.packages("RJSDMX") :
  installation of package ?RJSDMX? had non-zero exit status



or the openNLP data

> install.packages("openNLPdata")
Installing package into ?/usr/local/lib/R/site-library?
(as ?lib? is unspecified)
trying URL 'https://lib.ugent.be/CRAN/src/contrib/openNLPdata_1.5.3-2.tar.gz'
Content type 'application/x-gzip' length 7318681 bytes (7.0 MB)
==================================================
downloaded 7.0 MB

* installing *source* package ?openNLPdata? ...
** package ?openNLPdata? successfully unpacked and MD5 sums checked
** R
** inst
** preparing package for lazy loading
** help
No man pages found in package  ?openNLPdata? 
*** installing help indices
** building package indices
** testing if installed package can be loaded
Segmentation fault
ERROR: loading failed
* removing ?/usr/local/lib/R/site-library/openNLPdata?

The downloaded source packages are in
	?/tmp/RtmpkjeaiB/downloaded_packages?
Warning message:
In install.packages("openNLPdata") :
  installation of package ?openNLPdata? had non-zero exit status


I enclose also my sessionInfo data

> sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.7.0
LAPACK: /usr/lib/lapack/liblapack.so.3.7.0

locale:
 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C             
 [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8    
 [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8   
 [7] LC_PAPER=en_GB.utf8       LC_NAME=C                
 [9] LC_ADDRESS=C              LC_TELEPHONE=C           
[11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C      

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.4.0 tools_3.4.0    tcltk_3.4.0   


Is anybody else having similar troubles?
I would like to add that I can install other fairly complicated
packages (like tidyverse), so I am really puzzled.
Any suggestion is welcome.
Many thanks

Lorenzo


From dwinsemius at comcast.net  Wed Jun 21 21:28:20 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Jun 2017 12:28:20 -0700
Subject: [R] selecting dataframe columns based on substring of col
	name(s)
In-Reply-To: <dbecd23c-aa72-f3ec-8032-a16485a3195c@gmail.com>
References: <dbecd23c-aa72-f3ec-8032-a16485a3195c@gmail.com>
Message-ID: <0F177FA6-B4E4-4DB4-835A-9CBBF5A5B435@comcast.net>


> On Jun 21, 2017, at 9:11 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
> 
> Suppose I have the following sort of dataframe, where each column name has a common structure: prefix, followed by a number (for this example, col1, col2, col3 and col4):
> 
> d = data.frame( col1=runif(10), col2=runif(10), col3=runif(10),col4=runif(10))
> 
> What I haven't been able to suss out is how to efficiently 'extract/manipulate/play with' columns from the data frame, making use of this common structure.
> 
> Suppose, for example, I want to 'work with' col2, col3, and col4. Now, I could subset the dataframe d in any number of ways -- for example
> 
> piece <- d[,c("col2","col3","col4")]
> 
> Works as expected, but for *big* problems (where I might have dozens -> hundreds of columns -- often the case with big design matrices output by some linear models program or another), having to write them all out using c("col2","col3",...."colXXXXX") takes a lot of time. What I'm wondering about is if there is a way to simply select over the "changing part" of the column name (you can do this relatively easily in a data step in SAS, for example). Heuristically, something like:
> 
> piece <- df[,col2:col4]
> 
> where the heuristic col2:col4 is interpreted as col2 -> col4 (parse the prefix 'col', and then simply select over the changing suffic -- i.e., column number).
> 
> Now, if I use the "to" function in the lessR package, I can get there from here fairly easily:
> 
> piece <- d[,to("col",4,from=2,same.size=FALSE)]
> 
> But, is there a better way? Beyond 'efficiency' (ease of implementation), part of what constitutes 'better' might be something in base R, rather than relying on a package?

After staring at the code for the base function subset with a thought to hacking it to do this I realized that should be already part of the evaluation result from its current form:

 names(airquality)
#[1] "Ozone"   "Solar.R" "Wind"    "Temp"    "Month"   "Day"  

subset(airquality, 
          Temp > 90,             # this is the row selection
          select = Ozone:Solar.R) # and this selects columns
#--------
    Ozone Solar.R
42     NA     259
43     NA     250
69     97     267
70     97     272
75     NA     291
102    NA     222
120    76     203
121   118     225
122    84     237
123    85     188
124    96     167
125    78     197
126    73     183
127    91     189

Bert's advice to work with the numbers is good, but conversion to numeric designations of columns inside the `select`-expression is actually what is occurring inside `subset`.

-- 

David Winsemius
Alameda, CA, USA


From marine.regis at hotmail.fr  Wed Jun 21 21:48:24 2017
From: marine.regis at hotmail.fr (Marine Regis)
Date: Wed, 21 Jun 2017 19:48:24 +0000
Subject: [R] How to apply a system of ordinary differential equations to a
 cell grid?
Message-ID: <HE1PR07MB11947F77F8138EF94D16A84FE2DA0@HE1PR07MB1194.eurprd07.prod.outlook.com>

Hello,

I am developing an agent-based model to simulate the spread of infectious diseases in heterogeneous landscapes composed of habitat polygons (or clumps of connected cells). To simplify the model, I consider a habitat grid (or raster) containing the polygon ID of each cell. In addition, I have epidemiological parameters associated with each polygon ID. At each time step, the parameter values change in the polygon. Thus, the data frame ?landscape? (see below) is updated at each time step. Here is an example at t = 0:

landscape <- data.frame(polygon_ID = seq(1, 10, by = 1),
                        beta = sample(c(100, 200, 400, 600), 10, replace = TRUE),
                        gamma = sample(c(25, 26, 27, 28), 10, replace = TRUE))

To study the disease dynamics, I also am developing a compartmental model based on a system of ordinary differential equations (ODEs). Here is an example to represent the system of ODEs:

solve_sir_model <- function (times, parameters) {

  sir_model <- function (times, states, parameters) {

    with(as.list(c(states, parameters)), {

      dSdt <- -beta*S*I
      dIdt <- beta*S*I-gamma*I
      dRdt <- gamma*I
      dNdt <- dSdt + dIdt + dRdt

      return(list(c(dSdt, dIdt, dRdt, dNdt)))

    })
  }

  states <- c(S = 99, I = 1, R = 0, N = 100)
  return(ode(y = states, times = times, func = sir_model, parms = parameters))
}

require(deSolve)
output <- as.data.frame(solve_sir_model(times = seq(0, 5, by = 1), parameters = c(beta = 400, gamma = 28)))

Here is my question: at each time step, is it possible to apply the system of ODEs to each habitat polygon (thus each row) in the data frame ?landscape?? I am using lsoda as an ODE solver. Do I need to use another solver to apply the ODEs at each time step?

Thank you very much for your advice.
Have a nice day
Marine


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Jun 21 22:30:39 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Jun 2017 13:30:39 -0700
Subject: [R] How to apply a system of ordinary differential equations to
	a cell grid?
In-Reply-To: <HE1PR07MB11947F77F8138EF94D16A84FE2DA0@HE1PR07MB1194.eurprd07.prod.outlook.com>
References: <HE1PR07MB11947F77F8138EF94D16A84FE2DA0@HE1PR07MB1194.eurprd07.prod.outlook.com>
Message-ID: <7D9087F2-C6D5-446E-984C-65B757069986@comcast.net>


> On Jun 21, 2017, at 12:48 PM, Marine Regis <marine.regis at hotmail.fr> wrote:
> 
> Hello,
> 
> I am developing an agent-based model to simulate the spread of infectious diseases in heterogeneous landscapes composed of habitat polygons (or clumps of connected cells). To simplify the model, I consider a habitat grid (or raster) containing the polygon ID of each cell. In addition, I have epidemiological parameters associated with each polygon ID. At each time step, the parameter values change in the polygon. Thus, the data frame ?landscape? (see below) is updated at each time step. Here is an example at t = 0:
> 
> landscape <- data.frame(polygon_ID = seq(1, 10, by = 1),
>                        beta = sample(c(100, 200, 400, 600), 10, replace = TRUE),
>                        gamma = sample(c(25, 26, 27, 28), 10, replace = TRUE))
> 
> To study the disease dynamics, I also am developing a compartmental model based on a system of ordinary differential equations (ODEs). Here is an example to represent the system of ODEs:
> 
> solve_sir_model <- function (times, parameters) {
> 
>  sir_model <- function (times, states, parameters) {
> 
>    with(as.list(c(states, parameters)), {
> 
>      dSdt <- -beta*S*I
>      dIdt <- beta*S*I-gamma*I
>      dRdt <- gamma*I
>      dNdt <- dSdt + dIdt + dRdt
> 
>      return(list(c(dSdt, dIdt, dRdt, dNdt)))
> 
>    })
>  }
> 
>  states <- c(S = 99, I = 1, R = 0, N = 100)
>  return(ode(y = states, times = times, func = sir_model, parms = parameters))
> }
> 
> require(deSolve)
> output <- as.data.frame(solve_sir_model(times = seq(0, 5, by = 1), parameters = c(beta = 400, gamma = 28)))
> 
> Here is my question: at each time step, is it possible to apply the system of ODEs to each habitat polygon (thus each row) in the data frame ?landscape?? I am using lsoda as an ODE solver. Do I need to use another solver to apply the ODEs at each time step?
> 
> Thank you very much for your advice.
> Have a nice day
> Marine
> 

There's also ode.2D in the same package {deSolve} and it's help page has a 2-d diffusion example that might be cognate.

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From Mike.Conklin at gfk.com  Wed Jun 21 22:39:15 2017
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Wed, 21 Jun 2017 20:39:15 +0000
Subject: [R]  Missing dependencies in pkg installs
Message-ID: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>

I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).

R version 3.4.0 (2017-04-21)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)

Matrix products: default
BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so

locale:
[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
[9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] dplyr_0.7.0 shiny_1.0.3

loaded via a namespace (and not attached):
[1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
[5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
[9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
[13] mime_0.5         rlang_0.1.1
>


If I try and install Hmisc for example I get the following errors:
for the first error ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'  I did not find the R Installation and Administration Manual helpful.


> install.packages("Hmisc")
Installing package into '/usr/lib64/R/library'
(as 'lib' is unspecified)
also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'

trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
==================================================
downloaded 3.5 MB

trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
Content type 'application/x-gzip' length 21914 bytes (21 KB)
==================================================
downloaded 21 KB

trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
Content type 'application/x-gzip' length 34688 bytes (33 KB)
==================================================
downloaded 33 KB

trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
Content type 'application/x-gzip' length 94095 bytes (91 KB)
==================================================
downloaded 91 KB

trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
==================================================
downloaded 1007 KB

trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
==================================================
downloaded 2.1 MB

trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
Content type 'application/x-gzip' length 152095 bytes (148 KB)
==================================================
downloaded 148 KB

trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
==================================================
downloaded 1.7 MB

trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
Content type 'application/x-gzip' length 702759 bytes (686 KB)
==================================================
downloaded 686 KB

* installing *source* package 'stringi' ...
** package 'stringi' successfully unpacked and MD5 sums checked
ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
* removing '/usr/lib64/R/library/stringi'
ERROR: dependency 'stringi' is not available for package 'stringr'
* removing '/usr/lib64/R/library/stringr'
ERROR: dependency 'stringr' is not available for package 'evaluate'
* removing '/usr/lib64/R/library/evaluate'
ERROR: dependency 'stringr' is not available for package 'reshape2'
* removing '/usr/lib64/R/library/reshape2'
ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
* removing '/usr/lib64/R/library/knitr'
ERROR: dependency 'reshape2' is not available for package 'ggplot2'
* removing '/usr/lib64/R/library/ggplot2'
ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
* removing '/usr/lib64/R/library/htmlTable'
ERROR: dependency 'ggplot2' is not available for package 'viridis'
* removing '/usr/lib64/R/library/viridis'
ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
* removing '/usr/lib64/R/library/Hmisc'


Any help is appreciated.
--
W. Michael Conklin
Executive Vice President
Marketing & Data Sciences - North America
GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
T +1 763 417 4545 | M +1 612 567 8287
www.gfk.com<http://www.gfk.com/>


	[[alternative HTML version deleted]]


From alejandrocasella74 at gmail.com  Wed Jun 21 22:30:06 2017
From: alejandrocasella74 at gmail.com (Alejandro Cayetano Casella)
Date: Wed, 21 Jun 2017 15:30:06 -0500
Subject: [R] Help with packages
Message-ID: <CAKVscO8zahSF5afU8a6WNNMgdNMAVbKD2SmqV61+sHyFfNyx2Q@mail.gmail.com>

Hi, I want to download the packages into R in my personal computer  and
this is what appears on the screen:
> utils:::menuInstallPkgs()
Warning in install.packages(NULL, .libPaths()[1L], dependencies = NA, type
= type) :
  'lib = "C:/Program Files/R/R-3.4.0/library"' is not writable
Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
type) :
  unable to create ?C:\Users\Alejandro\Documents/R/win-library/3.4?
In addition: Warning message:
In dir.create(userdir, recursive = TRUE) :
  cannot create dir 'C:\Users\Alejandro\Documents\R\win-library', reason
'No such file or directory'

Can you help me?
Thank you.

	[[alternative HTML version deleted]]


From esawiek at gmail.com  Wed Jun 21 23:50:39 2017
From: esawiek at gmail.com (Ek Esawi)
Date: Wed, 21 Jun 2017 17:50:39 -0400
Subject: [R] Counting with multiple criteria using data table
Message-ID: <CA+ZkTxuof1BjxK9AAWwKmw594rB0p5LUL-B_tD31rbWLzZYdJg@mail.gmail.com>

I have a data.table which is shown below. I want to count combinations of
columns on i and count on j with by. A few examples are given below the
table.



I want to:

all months to show on the output including those that they have zero value

I want the three statements combined in on if possible so the output will
be one data table; that is the outputs are next to each other as manually
illustrated on the last part (desired output).





Thanks--EK





> Test

     Color Grade Value  Month Day

 1: yellow     A    20    May   1

 2:  green     B    25   June   2

 3:  green     A    10  April   3

 4:  black     A    17 August   3

 5:    red     C     5    May   5

 6: orange     D     0   June  13

 7: orange     E    12  April   5

 8: orange     F    11 August   8

 9: orange     F    99  April  23

10: orange     F    70    May   7

11:  black     A    77   June  11

12:  green     B    87 August  33

13:  black     A    79  April   9

14:  green     A    68    May  14

15:  black     C    90   June  31

16:  green     D    79 August  11

17:  black     E   101  April  17

18:    red     F    90   June  21

19:    red     F   112 August  13

20:    red     F   101  April  20

> Test[Color=="green"&Grade=="A", .N, by=Month]

   Month N

1: April 1

2:   May 1

> Test[Color=="orange"&Grade=="F", .N, by=Month]

    Month N

1: August 1

2:  April 1

3:    May 1



> Test[Color=="orange"&Grade=="F", .N, by=Month]

    Month     N

1: August     1

2:  April     1

3:    May     1

> Test[Color=="red"&Grade=="F", .N, by=Month]

    Month N

1:   June 1

2: August 1

3:  April 1



Desired output

                N1           N2           N3

April       1              1              1

May       1              1              1

June        0              0              0

August 0                1              1

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Jun 22 00:24:32 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 22 Jun 2017 08:24:32 +1000
Subject: [R] Help/ Mathematics
In-Reply-To: <CAG6S0OknML6GVEdhV17gTK7kQn0WLNhgLMJULp12Wxme7eNM3g@mail.gmail.com>
References: <CAG6S0OknML6GVEdhV17gTK7kQn0WLNhgLMJULp12Wxme7eNM3g@mail.gmail.com>
Message-ID: <CA+8X3fVjFR_HO-DbJhJDrm4=R4y=aZ5mi51agxT55dXeU0n-jA@mail.gmail.com>

Hi Ahmed,
Your problem appears trivial as you have already specified the form of
the calculation.

Learn how to "extract" specified elements from a data structure:

# first value
sum(dataset1$NPP[dataset1$date >= date1 &
 dataset1$date <= date2])
# second value
dataset2$biomass[dataset2$date == date2] -
 dataset2$biomass[dataset2$date == date1]
# third value
dataset3$littfall[dataset3$date == date2]

Note that you may have to convert character strings to dates to do the
above - see a function like "as.Date". Obviously I do not know the
actual names of your datasets and I am assuming that the variable
names you have given are the actual ones.

Jim


On Thu, Jun 22, 2017 at 4:19 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> Hi R users,
>
> I need your help to write a code in r that does the following
> calculation from three different datasets;
>
> ac = 1/sum (NPP from date 1 to date 2, dataset=1) * (biomass at date 2
> -biomass at date 1, dataset = 2) + (littfall at date 2, dataset=3).
>
> all the dates are in yr-month-day format. Which library or function
> Should I use to tell R do these calculations of these variables at
> different dates.
>
> I appreciate your help.
>
> Ahmed Attia, Ph.D.
> Agronomist & Soil Scientist
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Jun 22 01:16:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 21 Jun 2017 16:16:36 -0700
Subject: [R] Counting with multiple criteria using data table
In-Reply-To: <CA+ZkTxuof1BjxK9AAWwKmw594rB0p5LUL-B_tD31rbWLzZYdJg@mail.gmail.com>
References: <CA+ZkTxuof1BjxK9AAWwKmw594rB0p5LUL-B_tD31rbWLzZYdJg@mail.gmail.com>
Message-ID: <CAGxFJbQzzzc6ffSJY2fGE2YDTApgb+S1+3As9hsKY-tQNrFTTg@mail.gmail.com>

Have you gone through any R tutorials? If not, why not? If so, maybe
you need to spend some more time with them.

It looks like you want us to do your work for you. We don't do this.
See (and follow) the posting guide below for what we might do (we're
volunteers, so no guarantees).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 21, 2017 at 2:50 PM, Ek Esawi <esawiek at gmail.com> wrote:
> I have a data.table which is shown below. I want to count combinations of
> columns on i and count on j with by. A few examples are given below the
> table.
>
>
>
> I want to:
>
> all months to show on the output including those that they have zero value
>
> I want the three statements combined in on if possible so the output will
> be one data table; that is the outputs are next to each other as manually
> illustrated on the last part (desired output).
>
>
>
>
>
> Thanks--EK
>
>
>
>
>
>> Test
>
>      Color Grade Value  Month Day
>
>  1: yellow     A    20    May   1
>
>  2:  green     B    25   June   2
>
>  3:  green     A    10  April   3
>
>  4:  black     A    17 August   3
>
>  5:    red     C     5    May   5
>
>  6: orange     D     0   June  13
>
>  7: orange     E    12  April   5
>
>  8: orange     F    11 August   8
>
>  9: orange     F    99  April  23
>
> 10: orange     F    70    May   7
>
> 11:  black     A    77   June  11
>
> 12:  green     B    87 August  33
>
> 13:  black     A    79  April   9
>
> 14:  green     A    68    May  14
>
> 15:  black     C    90   June  31
>
> 16:  green     D    79 August  11
>
> 17:  black     E   101  April  17
>
> 18:    red     F    90   June  21
>
> 19:    red     F   112 August  13
>
> 20:    red     F   101  April  20
>
>> Test[Color=="green"&Grade=="A", .N, by=Month]
>
>    Month N
>
> 1: April 1
>
> 2:   May 1
>
>> Test[Color=="orange"&Grade=="F", .N, by=Month]
>
>     Month N
>
> 1: August 1
>
> 2:  April 1
>
> 3:    May 1
>
>
>
>> Test[Color=="orange"&Grade=="F", .N, by=Month]
>
>     Month     N
>
> 1: August     1
>
> 2:  April     1
>
> 3:    May     1
>
>> Test[Color=="red"&Grade=="F", .N, by=Month]
>
>     Month N
>
> 1:   June 1
>
> 2: August 1
>
> 3:  April 1
>
>
>
> Desired output
>
>                 N1           N2           N3
>
> April       1              1              1
>
> May       1              1              1
>
> June        0              0              0
>
> August 0                1              1
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Jun 22 02:20:59 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 21 Jun 2017 17:20:59 -0700
Subject: [R] Help with packages
In-Reply-To: <CAKVscO8zahSF5afU8a6WNNMgdNMAVbKD2SmqV61+sHyFfNyx2Q@mail.gmail.com>
References: <CAKVscO8zahSF5afU8a6WNNMgdNMAVbKD2SmqV61+sHyFfNyx2Q@mail.gmail.com>
Message-ID: <1DA48217-D5AC-4025-B237-61797745846F@dcn.davis.ca.us>

Whatever you do, don't use "Run As Administrator" to install R unless you know exactly why and how you plan to fix the resulting mess. 

It is normal not to be able to update the library under Program Files. It is not normal (in my experience) to have problems creating the library under your Documents directory. 

One thing that looks odd with your error message is the presence of slashes going  backward (\) as Windows likes and forward (/) as Mac/Linux prefer. Since strings in R use backslash as an escape character, this can sometimes indicate failure to specify the path correctly, but not always. Forward slashes for directory separators usually work within R even on Windows, which means you don't need to escape the backslash ("\\")... but this is a sample of output rather than input so might be just fine. 

Alternatively, you may be missing one of

C:/Users/Alejandro/
C:/Users/Alejandro/Documents/

or the permissions on 

C:/Users/Alejandro/Documents/R/

might be preventing R from modifying it. 

-- 
Sent from my phone. Please excuse my brevity.

On June 21, 2017 1:30:06 PM PDT, Alejandro Cayetano Casella <alejandrocasella74 at gmail.com> wrote:
>Hi, I want to download the packages into R in my personal computer  and
>this is what appears on the screen:
>> utils:::menuInstallPkgs()
>Warning in install.packages(NULL, .libPaths()[1L], dependencies = NA,
>type
>= type) :
>  'lib = "C:/Program Files/R/R-3.4.0/library"' is not writable
>Error in install.packages(NULL, .libPaths()[1L], dependencies = NA,
>type =
>type) :
>  unable to create ?C:\Users\Alejandro\Documents/R/win-library/3.4?
>In addition: Warning message:
>In dir.create(userdir, recursive = TRUE) :
> cannot create dir 'C:\Users\Alejandro\Documents\R\win-library', reason
>'No such file or directory'
>
>Can you help me?
>Thank you.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jun 22 02:33:17 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Jun 2017 17:33:17 -0700
Subject: [R] Help/ Mathematics
In-Reply-To: <CAG6S0OknML6GVEdhV17gTK7kQn0WLNhgLMJULp12Wxme7eNM3g@mail.gmail.com>
References: <CAG6S0OknML6GVEdhV17gTK7kQn0WLNhgLMJULp12Wxme7eNM3g@mail.gmail.com>
Message-ID: <E94AADD0-ECE8-45EB-90D8-C505FD2AB307@comcast.net>


> On Jun 21, 2017, at 11:19 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> 
> Hi R users,
> 
> I need your help to write a code in r that does the following
> calculation from three different datasets;
> 
> ac = 1/sum (NPP from date 1 to date 2, dataset=1) * (biomass at date 2
> -biomass at date 1, dataset = 2) + (littfall at date 2, dataset=3).

To do this in R you could learn to use the "sqldf"-package since you seem familiar with that syntax. I'm not and so it's rank speculation on my part that such an expression would be meaningful in one or another flavor of SQL.

Or you could use either `match` or `merge`, assuming the dates of the various datasets are congruent.


> 
> all the dates are in yr-month-day format.

The "YYYY-MM-DD" format is the standard format in R. You might not even need to convert to the Date-class.


> Which library or function
> Should I use to tell R do these calculations of these variables at
> different dates.
> 
> I appreciate your help.
> 
> Ahmed Attia, Ph.D.
> Agronomist & Soil Scientist
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Jun 22 02:58:38 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Jun 2017 17:58:38 -0700
Subject: [R] Counting with multiple criteria using data table
In-Reply-To: <CA+ZkTxuof1BjxK9AAWwKmw594rB0p5LUL-B_tD31rbWLzZYdJg@mail.gmail.com>
References: <CA+ZkTxuof1BjxK9AAWwKmw594rB0p5LUL-B_tD31rbWLzZYdJg@mail.gmail.com>
Message-ID: <BBDE7D95-D9C3-4DD8-9000-F6C8BE24F093@comcast.net>


> On Jun 21, 2017, at 2:50 PM, Ek Esawi <esawiek at gmail.com> wrote:
> 
> I have a data.table which is shown below. I want to count combinations of
> columns on i and count on j with by. A few examples are given below the
> table.
> 
> 
> 
> I want to:
> 
> all months to show on the output including those that they have zero value
> 
> I want the three statements combined in on if possible so the output will
> be one data table; that is the outputs are next to each other as manually
> illustrated on the last part (desired output).
> 
> 
> 
> 
> 
> Thanks--EK
> 
> 
> 
> 
> 
>> Test
> 
>     Color Grade Value  Month Day
> 
> 1: yellow     A    20    May   1
> 
> 2:  green     B    25   June   2
> 
> 3:  green     A    10  April   3
> 
> 4:  black     A    17 August   3
> 
> 5:    red     C     5    May   5
> 
> 6: orange     D     0   June  13
> 
> 7: orange     E    12  April   5
> 
> 8: orange     F    11 August   8
> 
> 9: orange     F    99  April  23
> 
> 10: orange     F    70    May   7
> 
> 11:  black     A    77   June  11
> 
> 12:  green     B    87 August  33
> 
> 13:  black     A    79  April   9
> 
> 14:  green     A    68    May  14
> 
> 15:  black     C    90   June  31
> 
> 16:  green     D    79 August  11
> 
> 17:  black     E   101  April  17
> 
> 18:    red     F    90   June  21
> 
> 19:    red     F   112 August  13
> 
> 20:    red     F   101  April  20

You should have offered the output of:

 dput(Test)

> 
>> Test[Color=="green"&Grade=="A", .N, by=Month]
> 
>   Month N
> 
> 1: April 1
> 
> 2:   May 1
> 
>> Test[Color=="orange"&Grade=="F", .N, by=Month]
> 
>    Month N
> 
> 1: August 1
> 
> 2:  April 1
> 
> 3:    May 1
> 
> 
> 
>> Test[Color=="orange"&Grade=="F", .N, by=Month]
> 
>    Month     N
> 
> 1: August     1
> 
> 2:  April     1
> 
> 3:    May     1
> 
>> Test[Color=="red"&Grade=="F", .N, by=Month]
> 
>    Month N
> 
> 1:   June 1
> 
> 2: August 1
> 
> 3:  April 1
> 
> 
> 
> Desired output
> 
>                N1           N2           N3
> 
> April       1              1              1
> 
> May       1              1              1
> 
> June        0              0              0
> 
> August 0                1              1

I count 4 data.tables and a total of 11 items so why only 3 columns and 9 items?

Were you tabulating colors by month?

> Test[ (Color=="green"&Grade=="A") | 
(Color=="red"&Grade=="F") |
(Color=="orange"&Grade=="F")|
(Color=="orange"&Grade=="F")|
(Color=="red"&Grade=="F") ,        table(Month, Color)]
        Color
Month    green orange red
  April      1      1   1
  August     0      1   1
  June       0      0   1
  May        1      1   0
> 


> 
> 	[[alternative HTML version deleted]]

Rhelp is plain-text. Do read the Posting Guide:

Another possibility:

 Test[(Color=="green"&Grade=="A") |    These are the conditions separated by logical OR's in the first argument to `[data.table`
      (Color=="red"&Grade=="F") |
      (Color=="orange"&Grade=="F")|
      (Color=="orange"&Grade=="F")|
      (Color=="red"&Grade=="F") ,          table(Month, Grade)]


        Grade
Month    A F
  April  1 2
  August 0 2
  June   0 1
  May    1 1


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Jun 22 03:04:13 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Jun 2017 18:04:13 -0700
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
Message-ID: <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>


> On Jun 21, 2017, at 1:39 PM, Conklin, Mike (GfK) <Mike.Conklin at gfk.com> wrote:
> 
> I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).
> 
> R version 3.4.0 (2017-04-21)
> Platform: x86_64-redhat-linux-gnu (64-bit)

I'd make sure you have reviewed this:

https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essential-programs-and-libraries

Best;
David.

> Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)
> 
> Matrix products: default
> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] dplyr_0.7.0 shiny_1.0.3
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
> [5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
> [9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
> [13] mime_0.5         rlang_0.1.1
>> 
> 
> 
> If I try and install Hmisc for example I get the following errors:
> for the first error ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'  I did not find the R Installation and Administration Manual helpful.
> 
> 
>> install.packages("Hmisc")
> Installing package into '/usr/lib64/R/library'
> (as 'lib' is unspecified)
> also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'
> 
> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
> ==================================================
> downloaded 3.5 MB
> 
> trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
> Content type 'application/x-gzip' length 21914 bytes (21 KB)
> ==================================================
> downloaded 21 KB
> 
> trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
> Content type 'application/x-gzip' length 34688 bytes (33 KB)
> ==================================================
> downloaded 33 KB
> 
> trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
> Content type 'application/x-gzip' length 94095 bytes (91 KB)
> ==================================================
> downloaded 91 KB
> 
> trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
> Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
> ==================================================
> downloaded 1007 KB
> 
> trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
> Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
> ==================================================
> downloaded 2.1 MB
> 
> trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
> Content type 'application/x-gzip' length 152095 bytes (148 KB)
> ==================================================
> downloaded 148 KB
> 
> trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
> Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
> ==================================================
> downloaded 1.7 MB
> 
> trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
> Content type 'application/x-gzip' length 702759 bytes (686 KB)
> ==================================================
> downloaded 686 KB
> 
> * installing *source* package 'stringi' ...
> ** package 'stringi' successfully unpacked and MD5 sums checked
> ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
> * removing '/usr/lib64/R/library/stringi'
> ERROR: dependency 'stringi' is not available for package 'stringr'
> * removing '/usr/lib64/R/library/stringr'
> ERROR: dependency 'stringr' is not available for package 'evaluate'
> * removing '/usr/lib64/R/library/evaluate'
> ERROR: dependency 'stringr' is not available for package 'reshape2'
> * removing '/usr/lib64/R/library/reshape2'
> ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
> * removing '/usr/lib64/R/library/knitr'
> ERROR: dependency 'reshape2' is not available for package 'ggplot2'
> * removing '/usr/lib64/R/library/ggplot2'
> ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
> * removing '/usr/lib64/R/library/htmlTable'
> ERROR: dependency 'ggplot2' is not available for package 'viridis'
> * removing '/usr/lib64/R/library/viridis'
> ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
> * removing '/usr/lib64/R/library/Hmisc'
> 
> 
> Any help is appreciated.
> --
> W. Michael Conklin
> Executive Vice President
> Marketing & Data Sciences - North America
> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
> T +1 763 417 4545 | M +1 612 567 8287
> www.gfk.com<http://www.gfk.com/>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Thu Jun 22 03:09:58 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 21 Jun 2017 18:09:58 -0700
Subject: [R] Counting with multiple criteria using data table
In-Reply-To: <CAGxFJbQzzzc6ffSJY2fGE2YDTApgb+S1+3As9hsKY-tQNrFTTg@mail.gmail.com>
References: <CA+ZkTxuof1BjxK9AAWwKmw594rB0p5LUL-B_tD31rbWLzZYdJg@mail.gmail.com>
 <CAGxFJbQzzzc6ffSJY2fGE2YDTApgb+S1+3As9hsKY-tQNrFTTg@mail.gmail.com>
Message-ID: <413156F3-67F2-42D8-8BB2-1A133367B29A@dcn.davis.ca.us>

To be fair, the OP did provide brief snippets of data.table usage below the data dump indicating some level of effort, but posted it all in HTML (what you see we do not see), did not make the example reproducible (dput is great, and library calls really clear things up [1][2][3]), and this looks suspiciously like homework  (not on topic here, see the Posting Guide).

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html
-- 
Sent from my phone. Please excuse my brevity.

On June 21, 2017 4:16:36 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Have you gone through any R tutorials? If not, why not? If so, maybe
>you need to spend some more time with them.
>
>It looks like you want us to do your work for you. We don't do this.
>See (and follow) the posting guide below for what we might do (we're
>volunteers, so no guarantees).
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Wed, Jun 21, 2017 at 2:50 PM, Ek Esawi <esawiek at gmail.com> wrote:
>> I have a data.table which is shown below. I want to count
>combinations of
>> columns on i and count on j with by. A few examples are given below
>the
>> table.
>>
>>
>>
>> I want to:
>>
>> all months to show on the output including those that they have zero
>value
>>
>> I want the three statements combined in on if possible so the output
>will
>> be one data table; that is the outputs are next to each other as
>manually
>> illustrated on the last part (desired output).
>>
>>
>>
>>
>>
>> Thanks--EK
>>
>>
>>
>>
>>
>>> Test
>>
>>      Color Grade Value  Month Day
>>
>>  1: yellow     A    20    May   1
>>
>>  2:  green     B    25   June   2
>>
>>  3:  green     A    10  April   3
>>
>>  4:  black     A    17 August   3
>>
>>  5:    red     C     5    May   5
>>
>>  6: orange     D     0   June  13
>>
>>  7: orange     E    12  April   5
>>
>>  8: orange     F    11 August   8
>>
>>  9: orange     F    99  April  23
>>
>> 10: orange     F    70    May   7
>>
>> 11:  black     A    77   June  11
>>
>> 12:  green     B    87 August  33
>>
>> 13:  black     A    79  April   9
>>
>> 14:  green     A    68    May  14
>>
>> 15:  black     C    90   June  31
>>
>> 16:  green     D    79 August  11
>>
>> 17:  black     E   101  April  17
>>
>> 18:    red     F    90   June  21
>>
>> 19:    red     F   112 August  13
>>
>> 20:    red     F   101  April  20
>>
>>> Test[Color=="green"&Grade=="A", .N, by=Month]
>>
>>    Month N
>>
>> 1: April 1
>>
>> 2:   May 1
>>
>>> Test[Color=="orange"&Grade=="F", .N, by=Month]
>>
>>     Month N
>>
>> 1: August 1
>>
>> 2:  April 1
>>
>> 3:    May 1
>>
>>
>>
>>> Test[Color=="orange"&Grade=="F", .N, by=Month]
>>
>>     Month     N
>>
>> 1: August     1
>>
>> 2:  April     1
>>
>> 3:    May     1
>>
>>> Test[Color=="red"&Grade=="F", .N, by=Month]
>>
>>     Month N
>>
>> 1:   June 1
>>
>> 2: August 1
>>
>> 3:  April 1
>>
>>
>>
>> Desired output
>>
>>                 N1           N2           N3
>>
>> April       1              1              1
>>
>> May       1              1              1
>>
>> June        0              0              0
>>
>> August 0                1              1
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Jun 22 03:27:25 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 21 Jun 2017 18:27:25 -0700
Subject: [R] Cross-Validation for Zero-Inflated Models
In-Reply-To: <1E3ACDE6-49DF-4D78-ADC7-1C88EB085672@truqua.com>
References: <1E3ACDE6-49DF-4D78-ADC7-1C88EB085672@truqua.com>
Message-ID: <74188424-3609-439D-A7C9-7C51389F1F9D@dcn.davis.ca.us>

1) Helpdesk implies people whose job it is to provide support. R-help is a mailing list in which users help each other when they have spare time. 

2) You sent an email to the R-help mailing list, not to Lara, whoever that is. I suggest you figure out what her email address is and send your question to her directly, or read the Posting Guide mentioned below and then pose an entirely new question of your own to the list. There is a lot of existing research and packages related to cross-validation, but you are going to need to illustrate why you think the usual tools are not sufficient. Have you looked at the CRAN Task Views?

3) Email only has linkage to other email when they follow as replies... you did not reply to her email, so no one reading your email (quite likely even Lara, if she is even still on the list) has any idea what question you are referring to. 

-- 
Sent from my phone. Please excuse my brevity.

On June 21, 2017 7:16:49 AM PDT, Eric Weine <eric.weine at truqua.com> wrote:
>Lara:
>
>I see you sent this email to the R helpdesk a really long time ago, but
>I was just wondering if you ever got an answer to this question. I was
>just thinking that I would build my own cross validation function, but
>if you figured out a way to do this automatically, could you let me
>know?
>
>Thanks,
>
>Eric Weine.
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marine.regis at hotmail.fr  Thu Jun 22 05:06:13 2017
From: marine.regis at hotmail.fr (Marine Regis)
Date: Thu, 22 Jun 2017 03:06:13 +0000
Subject: [R] How to apply a system of ordinary differential equations to
 a cell grid?
In-Reply-To: <7D9087F2-C6D5-446E-984C-65B757069986@comcast.net>
References: <HE1PR07MB11947F77F8138EF94D16A84FE2DA0@HE1PR07MB1194.eurprd07.prod.outlook.com>,
 <7D9087F2-C6D5-446E-984C-65B757069986@comcast.net>
Message-ID: <AM3PR07MB11852E438459DBA165E3BD31E2DB0@AM3PR07MB1185.eurprd07.prod.outlook.com>

Thank you very much for your answer. I'm not sure if I can use the function ode.2 because it's a solver for 2-D partial differential equation problems. My equations don't contain diffusion parameters.


Thank you for your help

Marine


________________________________
De : David Winsemius <dwinsemius at comcast.net>
Envoy? : mercredi 21 juin 2017 22:30
? : Marine Regis
Cc : r-help at r-project.org
Objet : Re: [R] How to apply a system of ordinary differential equations to a cell grid?


> On Jun 21, 2017, at 12:48 PM, Marine Regis <marine.regis at hotmail.fr> wrote:
>
> Hello,
>
> I am developing an agent-based model to simulate the spread of infectious diseases in heterogeneous landscapes composed of habitat polygons (or clumps of connected cells). To simplify the model, I consider a habitat grid (or raster) containing the polygon ID of each cell. In addition, I have epidemiological parameters associated with each polygon ID. At each time step, the parameter values change in the polygon. Thus, the data frame ?landscape? (see below) is updated at each time step. Here is an example at t = 0:
>
> landscape <- data.frame(polygon_ID = seq(1, 10, by = 1),
>                        beta = sample(c(100, 200, 400, 600), 10, replace = TRUE),
>                        gamma = sample(c(25, 26, 27, 28), 10, replace = TRUE))
>
> To study the disease dynamics, I also am developing a compartmental model based on a system of ordinary differential equations (ODEs). Here is an example to represent the system of ODEs:
>
> solve_sir_model <- function (times, parameters) {
>
>  sir_model <- function (times, states, parameters) {
>
>    with(as.list(c(states, parameters)), {
>
>      dSdt <- -beta*S*I
>      dIdt <- beta*S*I-gamma*I
>      dRdt <- gamma*I
>      dNdt <- dSdt + dIdt + dRdt
>
>      return(list(c(dSdt, dIdt, dRdt, dNdt)))
>
>    })
>  }
>
>  states <- c(S = 99, I = 1, R = 0, N = 100)
>  return(ode(y = states, times = times, func = sir_model, parms = parameters))
> }
>
> require(deSolve)
> output <- as.data.frame(solve_sir_model(times = seq(0, 5, by = 1), parameters = c(beta = 400, gamma = 28)))
>
> Here is my question: at each time step, is it possible to apply the system of ODEs to each habitat polygon (thus each row) in the data frame ?landscape?? I am using lsoda as an ODE solver. Do I need to use another solver to apply the ODEs at each time step?
>
> Thank you very much for your advice.
> Have a nice day
> Marine
>

There's also ode.2D in the same package {deSolve} and it's help page has a 2-d diffusion example that might be cognate.

>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
R-help Info Page - Homepage - SfS ? Seminar for Statistics<https://stat.ethz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Thu Jun 22 06:01:37 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 22 Jun 2017 05:01:37 +0100
Subject: [R] Hunting a histogram variant
In-Reply-To: <7D9087F2-C6D5-446E-984C-65B757069986@comcast.net>
References: <HE1PR07MB11947F77F8138EF94D16A84FE2DA0@HE1PR07MB1194.eurprd07.prod.outlook.com>,
 <7D9087F2-C6D5-446E-984C-65B757069986@comcast.net>
Message-ID: <D381B11E-C295-4443-BFBE-2CCCC1C00172@LGCGroup.com>


I'm looking for a histogram variant in which data points are plotted as labelled rectangles 'piled up' to form a histogram. I've posted an example at https://www.dropbox.com/s/ozi8bhdn5kqaufm/labelled_histogram.png?dl=0

It seems to have a long pedigree, as I see it (as in this example) in documents going back beyond the '80s. But I've not seen it in recent textbooks. So it may be one of those older graphical displays that's just fallen out of use. 

General questions:
i) Does this thing have a name?
ii) Can anyone point me to a literature source for it? 

... and the R question:
ii) Is it already hiding somewhere in an R package?*

S Ellison

*If it's not, I'll be adding it to one, hence the hunt for due credit/sources



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From bgunter.4567 at gmail.com  Thu Jun 22 06:16:56 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 21 Jun 2017 21:16:56 -0700
Subject: [R] Hunting a histogram variant
In-Reply-To: <D381B11E-C295-4443-BFBE-2CCCC1C00172@LGCGroup.com>
References: <HE1PR07MB11947F77F8138EF94D16A84FE2DA0@HE1PR07MB1194.eurprd07.prod.outlook.com>
 <7D9087F2-C6D5-446E-984C-65B757069986@comcast.net>
 <D381B11E-C295-4443-BFBE-2CCCC1C00172@LGCGroup.com>
Message-ID: <CAGxFJbQh4dysNRkHBLRG8V2Qdh4t8aJRQ-u2XdUWnZt6cY1aHQ@mail.gmail.com>

?stem

for something close and built in.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 21, 2017 at 9:01 PM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>
> I'm looking for a histogram variant in which data points are plotted as labelled rectangles 'piled up' to form a histogram. I've posted an example at https://www.dropbox.com/s/ozi8bhdn5kqaufm/labelled_histogram.png?dl=0
>
> It seems to have a long pedigree, as I see it (as in this example) in documents going back beyond the '80s. But I've not seen it in recent textbooks. So it may be one of those older graphical displays that's just fallen out of use.
>
> General questions:
> i) Does this thing have a name?
> ii) Can anyone point me to a literature source for it?
>
> ... and the R question:
> ii) Is it already hiding somewhere in an R package?*
>
> S Ellison
>
> *If it's not, I'll be adding it to one, hence the hunt for due credit/sources
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:8}}


From rmh at temple.edu  Thu Jun 22 06:29:57 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 22 Jun 2017 00:29:57 -0400
Subject: [R] Hunting a histogram variant
In-Reply-To: <D381B11E-C295-4443-BFBE-2CCCC1C00172@LGCGroup.com>
References: <HE1PR07MB11947F77F8138EF94D16A84FE2DA0@HE1PR07MB1194.eurprd07.prod.outlook.com>
 <7D9087F2-C6D5-446E-984C-65B757069986@comcast.net>
 <D381B11E-C295-4443-BFBE-2CCCC1C00172@LGCGroup.com>
Message-ID: <CAGx1TMAm0dgZRu6tVMdAncpOsfnRxQCzTJtvcVN1LbH_pP=kzQ@mail.gmail.com>

Two things to look at are

?monthplot
which shows seasonal subseries plotted on an overall plot.
The parallel to your example is small histograms plotted on an overall plot.
That goes back (through the reference in the Blue Book (Becker,
Chambers, and Wilks)) to
Bill Cleveland and Irma Terpenning in JASA 77, 377, 52-62 (1982).

Starting from scratch I would be inclined to build your design
directly in grid, to place the
subgraphs in the main graph, and then I would use lattice to design
the subgraphs.
See Paul Murrell's book Figure 7.18 (First Edition) showing plots of
temperature for
cities in Australia.

Rich

On Thu, Jun 22, 2017 at 12:01 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>
> I'm looking for a histogram variant in which data points are plotted as labelled rectangles 'piled up' to form a histogram. I've posted an example at https://www.dropbox.com/s/ozi8bhdn5kqaufm/labelled_histogram.png?dl=0
>
> It seems to have a long pedigree, as I see it (as in this example) in documents going back beyond the '80s. But I've not seen it in recent textbooks. So it may be one of those older graphical displays that's just fallen out of use.
>
> General questions:
> i) Does this thing have a name?
> ii) Can anyone point me to a literature source for it?
>
> ... and the R question:
> ii) Is it already hiding somewhere in an R package?*
>
> S Ellison
>
> *If it's not, I'll be adding it to one, hence the hunt for due credit/sources
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:8}}


From drjimlemon at gmail.com  Thu Jun 22 07:17:06 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 22 Jun 2017 15:17:06 +1000
Subject: [R] Hunting a histogram variant
In-Reply-To: <D381B11E-C295-4443-BFBE-2CCCC1C00172@LGCGroup.com>
References: <HE1PR07MB11947F77F8138EF94D16A84FE2DA0@HE1PR07MB1194.eurprd07.prod.outlook.com>
 <7D9087F2-C6D5-446E-984C-65B757069986@comcast.net>
 <D381B11E-C295-4443-BFBE-2CCCC1C00172@LGCGroup.com>
Message-ID: <CA+8X3fV1ZVGB1u9wYjvYbuYNaBt=rmGW2O_LLXywC1YJj022RA@mail.gmail.com>

Hi,
This looks very much like a waffle plot, which can be performed with
color2D.matplot in the plotrix package. At the moment, the function
fill.corner is used to produce the matrix, but this could be
generalized to produce any shape of "waffle". The value display is
already part of color2D.matplot.

Jim

On Thu, Jun 22, 2017 at 2:01 PM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>
> I'm looking for a histogram variant in which data points are plotted as labelled rectangles 'piled up' to form a histogram. I've posted an example at https://www.dropbox.com/s/ozi8bhdn5kqaufm/labelled_histogram.png?dl=0
>
> It seems to have a long pedigree, as I see it (as in this example) in documents going back beyond the '80s. But I've not seen it in recent textbooks. So it may be one of those older graphical displays that's just fallen out of use.
>
> General questions:
> i) Does this thing have a name?
> ii) Can anyone point me to a literature source for it?
>
> ... and the R question:
> ii) Is it already hiding somewhere in an R package?*
>
> S Ellison
>
> *If it's not, I'll be adding it to one, hence the hunt for due credit/sources
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:8}}


From drjimlemon at gmail.com  Thu Jun 22 07:19:26 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 22 Jun 2017 15:19:26 +1000
Subject: [R] Hunting a histogram variant
In-Reply-To: <D381B11E-C295-4443-BFBE-2CCCC1C00172@LGCGroup.com>
References: <HE1PR07MB11947F77F8138EF94D16A84FE2DA0@HE1PR07MB1194.eurprd07.prod.outlook.com>
 <7D9087F2-C6D5-446E-984C-65B757069986@comcast.net>
 <D381B11E-C295-4443-BFBE-2CCCC1C00172@LGCGroup.com>
Message-ID: <CA+8X3fWcyrBHAwE=TEMfB4m1ZkyZfx-CT0krtn9Thwg-qV_0Mw@mail.gmail.com>

and I almost forgot Derek Ogle's histStack again in the plotrix package.

Jim

On Thu, Jun 22, 2017 at 2:01 PM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>
> I'm looking for a histogram variant in which data points are plotted as labelled rectangles 'piled up' to form a histogram. I've posted an example at https://www.dropbox.com/s/ozi8bhdn5kqaufm/labelled_histogram.png?dl=0
>
> It seems to have a long pedigree, as I see it (as in this example) in documents going back beyond the '80s. But I've not seen it in recent textbooks. So it may be one of those older graphical displays that's just fallen out of use.
>
> General questions:
> i) Does this thing have a name?
> ii) Can anyone point me to a literature source for it?
>
> ... and the R question:
> ii) Is it already hiding somewhere in an R package?*
>
> S Ellison
>
> *If it's not, I'll be adding it to one, hence the hunt for due credit/sources
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:8}}


From alaios at yahoo.com  Thu Jun 22 09:15:12 2017
From: alaios at yahoo.com (Alaios)
Date: Thu, 22 Jun 2017 07:15:12 +0000 (UTC)
Subject: [R] 3D plot with coordinates
In-Reply-To: <2082695275.376356.1498051013890@mail.yahoo.com>
References: <523123308.3027789.1498037019855.ref@mail.yahoo.com>
 <523123308.3027789.1498037019855@mail.yahoo.com>
 <4afa3ad4-8123-7650-03a2-e4f742a713a2@gmail.com>
 <2082695275.376356.1498051013890@mail.yahoo.com>
Message-ID: <1197087957.3879434.1498115712185@mail.yahoo.com>

Thanks. So after searching 4 hours last night it looks like that there is no R package that can do this right now. Any other ideas or suggestions might be helpful.RegardsAlex 

    On Wednesday, June 21, 2017 3:21 PM, Alaios via R-help <r-help at r-project.org> wrote:
 

 Thanks Duncan for the replyI can not suppress anything these are radiation pattern measurements that are typically are taken at X,Y and Z planes. See an example here, where I want to plot the measurements for the red, green and blue planes (so the image below withouth the 3d green structure inside)https://www.researchgate.net/publication/258391165/figure/fig7/AS:322947316240401 at 1454008048835/Radiation-pattern-of-Archimedean-spiral-antenna-a-3D-and-b-elevation-cuts-at-phi.png?

I am quite confident that there is a tool in R to help me do this 3D plot, and even better rotatable.
Thanks for the reply to allAlex 

? ? On Wednesday, June 21, 2017 1:07 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
 

 On 21/06/2017 5:23 AM, Alaios via R-help wrote:
> Thanks a lot for the reply.After? looking at different parts of the code today I was able to start with simple 2D polar plots as the attached pdf file.? In case the attachment is not visible I used the plot.polar function to create something like that.https://vijaybarve.files.wordpress.com/2013/04/polarplot-05.png
> Now the idea now will be to put three of those (for X,Y,Z) in a 3d rotatable plane. I tried the rgl function but is not clear how I can use directly polar coordinates to draw the points at the three different planes.
> Any ideas on that?

You can't easily do what you're trying to do.? You have 6 coordinates to 
display:? the 3 angles and values corresponding to each of them.? You 
need to suppress something.

If the values for matching angles correspond to each other (e.g. x=23 
degrees and y=23 degrees and z=23 degrees all correspond to the same 
observation), then I'd suggest suppressing the angles.? Just do a 
scatterplot of the 3 corresponding values.? It might make sense to join 
them (to make a path as the angles change), and perhaps to colour the 
path to indicate the angle (or plot text along the path to show it).

Duncan Murdoch

> Thanks a lot.RegardsAlex
>
>? ? On Tuesday, June 20, 2017 9:49 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>
>
>? package rgl.
>
> Best,
> Uwe Ligges
>
>
> On 20.06.2017 21:29, Alaios via R-help wrote:
>> HelloI have three x,y,z vectors (lets say each is set as? rnorm(360)). So each one is having 360 elements each one correpsonding to angular coordinates (1 degree, 2 degrees, 3 degrees,.... 360 degrees) and I want to plot those on the xyz axes that have degress.
>> Is there a function or library to look at R cran? The ideal will be that after plotting I will be able to rotate the shape.
>> I would like to thank you in advance for your helpRegardsAlex
>>? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Jun 22 09:38:56 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Jun 2017 09:38:56 +0200
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
Message-ID: <22859.29712.207244.909859@stat.math.ethz.ch>

>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>     on Wed, 21 Jun 2017 18:04:13 -0700 writes:

    >> On Jun 21, 2017, at 1:39 PM, Conklin, Mike (GfK) <Mike.Conklin at gfk.com> wrote:
    >> 
    >> I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).
    >> 
    >> R version 3.4.0 (2017-04-21)
    >> Platform: x86_64-redhat-linux-gnu (64-bit)

    > I'd make sure you have reviewed this:

    > https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essential-programs-and-libraries

yes,  but see also below ..

    > Best;
    > David.

    >> Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)
    >> 
    >> Matrix products: default
    >> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
    >> 
    >> locale:
    >> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
    >> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
    >> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
    >> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
    >> [9] LC_ADDRESS=C               LC_TELEPHONE=C
    >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
    >> 
    >> attached base packages:
    >> [1] stats     graphics  grDevices utils     datasets  methods   base
    >> 
    >> other attached packages:
    >> [1] dplyr_0.7.0 shiny_1.0.3
    >> 
    >> loaded via a namespace (and not attached):
    >> [1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
    >> [5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
    >> [9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
    >> [13] mime_0.5         rlang_0.1.1
    >>> 
    >> 
    >> 
    >> If I try and install Hmisc for example I get the following errors:
    >> for the first error ERROR: 'configure' exists but is not executable -- 
    >> see the 'R Installation and dministration Manual'  I did
    >> not find the R Installation and Administration Manual
    >> helpful.

why?  It does assume you spend some time understanding what it
is talking about.
OTOH, it is  *THE*  official document on the topic, written and
constantly updated by the  R core team.

Anyway:   " ERROR: 'configure' exists but is not executable "

is I think a crucial piece of information .. it's from stringi's
installation failure, and the top level directory of stringi (1.1-5)
in a Unix like (ls -l with user group names removed) looks like:

  -rw-r--r--.         1451 Apr  7 15:08 DESCRIPTION
  -rw-r--r--.         6207 Apr  7 11:21 INSTALL
  -rw-r--r--.         3580 Mar 21 13:29 LICENSE
  -rw-r--r--.        63692 Apr  7 15:08 MD5
  -rw-r--r--.         6204 Oct 24  2016 NAMESPACE
  -rw-r--r--.        22407 Apr  7 11:44 NEWS
  drwxr-xr-x.         8192 Mar 28 10:26 R
  -rwxr-xr-x.           66 Apr  2  2015 cleanup
  -rw-rw-r--.        32193 Apr  8 05:46 config.log
  -rwxrwxr-x.        40648 Apr  8 05:46 config.status
  -rwxr-xr-x.       173757 Apr  7 11:43 configure
  -rw-r--r--.          669 Jun 23  2015 configure.win
  drwxr-xr-x.          512 Apr  7 11:50 inst
  drwxr-xr-x.         8192 Mar 28 10:26 man
  drwxr-xr-x.        16384 Apr  8 05:47 src

Note the "x"s  in the 'configure' line's " -rwxr-xr-x. ": 
This means the file is executable and a reasonable shell can
just "call the file" and it will be executed, but that's the
part which failed for you.

.. this *is* peculiar as it looks like some of the standard Unix
tools may be misbehaving for you .. I assume it could be some OS
security "feature" playing against you..

    >> 
    >> 
    >>> install.packages("Hmisc")
    >> Installing package into '/usr/lib64/R/library'
    >> (as 'lib' is unspecified)
    >> also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'
    >> 
    >> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
    >> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
    >> ==================================================
    >> downloaded 3.5 MB
    >> 
    >> trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
    >> Content type 'application/x-gzip' length 21914 bytes (21 KB)
    >> ==================================================
    >> downloaded 21 KB
    >> 
    >> trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
    >> Content type 'application/x-gzip' length 34688 bytes (33 KB)
    >> ==================================================
    >> downloaded 33 KB
    >> 
    >> trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
    >> Content type 'application/x-gzip' length 94095 bytes (91 KB)
    >> ==================================================
    >> downloaded 91 KB
    >> 
    >> trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
    >> Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
    >> ==================================================
    >> downloaded 1007 KB
    >> 
    >> trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
    >> Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
    >> ==================================================
    >> downloaded 2.1 MB
    >> 
    >> trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
    >> Content type 'application/x-gzip' length 152095 bytes (148 KB)
    >> ==================================================
    >> downloaded 148 KB
    >> 
    >> trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
    >> Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
    >> ==================================================
    >> downloaded 1.7 MB
    >> 
    >> trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
    >> Content type 'application/x-gzip' length 702759 bytes (686 KB)
    >> ==================================================
    >> downloaded 686 KB
    >> 
    >> * installing *source* package 'stringi' ...
    >> ** package 'stringi' successfully unpacked and MD5 sums checked
    >> ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
    >> * removing '/usr/lib64/R/library/stringi'
    >> ERROR: dependency 'stringi' is not available for package 'stringr'
    >> * removing '/usr/lib64/R/library/stringr'
    >> ERROR: dependency 'stringr' is not available for package 'evaluate'
    >> * removing '/usr/lib64/R/library/evaluate'
    >> ERROR: dependency 'stringr' is not available for package 'reshape2'
    >> * removing '/usr/lib64/R/library/reshape2'
    >> ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
    >> * removing '/usr/lib64/R/library/knitr'
    >> ERROR: dependency 'reshape2' is not available for package 'ggplot2'
    >> * removing '/usr/lib64/R/library/ggplot2'
    >> ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
    >> * removing '/usr/lib64/R/library/htmlTable'
    >> ERROR: dependency 'ggplot2' is not available for package 'viridis'
    >> * removing '/usr/lib64/R/library/viridis'
    >> ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
    >> * removing '/usr/lib64/R/library/Hmisc'
    >> 
    >> 
    >> Any help is appreciated.
    >> --
    >> W. Michael Conklin
    >> Executive Vice President
    >> Marketing & Data Sciences - North America
    >> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
    >> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
    >> T +1 763 417 4545 | M +1 612 567 8287
    >> www.gfk.com<http://www.gfk.com/>
    >> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > David Winsemius
    > Alameda, CA, USA

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From ahmedatia80 at gmail.com  Thu Jun 22 10:13:26 2017
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Thu, 22 Jun 2017 10:13:26 +0200
Subject: [R] Help/ Mathematics
In-Reply-To: <CA+8X3fVjFR_HO-DbJhJDrm4=R4y=aZ5mi51agxT55dXeU0n-jA@mail.gmail.com>
References: <CAG6S0OknML6GVEdhV17gTK7kQn0WLNhgLMJULp12Wxme7eNM3g@mail.gmail.com>
 <CA+8X3fVjFR_HO-DbJhJDrm4=R4y=aZ5mi51agxT55dXeU0n-jA@mail.gmail.com>
Message-ID: <CAG6S0OnuV1VY-eVXogYoi2N48RrPE+dEcfVk5nj1v7v1wAx13g@mail.gmail.com>

Hi Jim,

Thank you very much, this was so helpful.

GPP_Ahmed13$Date <- as.Date(GPP_Ahmed13$Date, '%Y/%m/%d')
Litterfall_Ahmed97$Date <- as.Date(Litterfall_Ahmed97$Date, '%Y/%m/%d')
leafbiom97$Date <- as.Date( leafbiom97$Date, '%Y/%m/%d')

(leafbiom97$LeafBiog[leafbiom97$Date == "2012-02-12"] -
  leafbiom97$LeafBiog[leafbiom97$Date == "2010-03-15"]+
  Litterfall_Ahmed97$littperiod[Litterfall_Ahmed97$Date =="2011-04-08"])/
  (sum(GPP_Ahmed13$GPP[GPP_Ahmed13$Date >= "2010-03-12" &
  GPP_Ahmed13$Date <= "2012-04-12"])/2)


Best regards

Ahmed
Ahmed Attia, Ph.D.
Agronomist & Soil Scientist






On Thu, Jun 22, 2017 at 12:24 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Ahmed,
> Your problem appears trivial as you have already specified the form of
> the calculation.
>
> Learn how to "extract" specified elements from a data structure:
>
> # first value
> sum(dataset1$NPP[dataset1$date >= date1 &
>  dataset1$date <= date2])
> # second value
> dataset2$biomass[dataset2$date == date2] -
>  dataset2$biomass[dataset2$date == date1]
> # third value
> dataset3$littfall[dataset3$date == date2]
>
> Note that you may have to convert character strings to dates to do the
> above - see a function like "as.Date". Obviously I do not know the
> actual names of your datasets and I am assuming that the variable
> names you have given are the actual ones.
>
> Jim
>
>
> On Thu, Jun 22, 2017 at 4:19 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>> Hi R users,
>>
>> I need your help to write a code in r that does the following
>> calculation from three different datasets;
>>
>> ac = 1/sum (NPP from date 1 to date 2, dataset=1) * (biomass at date 2
>> -biomass at date 1, dataset = 2) + (littfall at date 2, dataset=3).
>>
>> all the dates are in yr-month-day format. Which library or function
>> Should I use to tell R do these calculations of these variables at
>> different dates.
>>
>> I appreciate your help.
>>
>> Ahmed Attia, Ph.D.
>> Agronomist & Soil Scientist
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Jun 22 11:27:23 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Jun 2017 05:27:23 -0400
Subject: [R] 3D plot with coordinates
In-Reply-To: <1197087957.3879434.1498115712185@mail.yahoo.com>
References: <523123308.3027789.1498037019855.ref@mail.yahoo.com>
 <523123308.3027789.1498037019855@mail.yahoo.com>
 <4afa3ad4-8123-7650-03a2-e4f742a713a2@gmail.com>
 <2082695275.376356.1498051013890@mail.yahoo.com>
 <1197087957.3879434.1498115712185@mail.yahoo.com>
Message-ID: <00b59691-af44-8f07-7cbc-5bc04eea2390@gmail.com>

On 22/06/2017 3:15 AM, Alaios wrote:
> Thanks. So after searching 4 hours last night it looks like that there
> is no R package that can do this right now. Any other ideas or
> suggestions might be helpful.

I don't know what you want the display to look like, but if you want it 
to be rotatable, rgl is probably the right package to use.

It doesn't directly support the coordinate system you're using, so you 
need to figure out where you want your points (or line segments) plotted 
in Euclidean coordinates, and write your own function to plot those. 
For example, to plot (r, theta) in polar coordinates in the XY plane, 
use (x = r*cos(theta), y = r*sin(theta), z = 0).

Duncan Murdoch

> Regards
> Alex
>
>
> On Wednesday, June 21, 2017 3:21 PM, Alaios via R-help
> <r-help at r-project.org> wrote:
>
>
> Thanks Duncan for the replyI can not suppress anything these are
> radiation pattern measurements that are typically are taken at X,Y and Z
> planes. See an example here, where I want to plot the measurements for
> the red, green and blue planes (so the image below withouth the 3d green
> structure
> inside)https://www.researchgate.net/publication/258391165/figure/fig7/AS:322947316240401 at 1454008048835/Radiation-pattern-of-Archimedean-spiral-antenna-a-3D-and-b-elevation-cuts-at-phi.png
> <https://www.researchgate.net/publication/258391165/figure/fig7/AS:322947316240401 at 1454008048835/Radiation-pattern-of-Archimedean-spiral-antenna-a-3D-and-b-elevation-cuts-at-phi.png%C2%A0>
>
> I am quite confident that there is a tool in R to help me do this 3D
> plot, and even better rotatable.
> Thanks for the reply to allAlex
>
>     On Wednesday, June 21, 2017 1:07 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>
> On 21/06/2017 5:23 AM, Alaios via R-help wrote:
>> Thanks a lot for the reply.After  looking at different parts of the
> code today I was able to start with simple 2D polar plots as the
> attached pdf file.  In case the attachment is not visible I used the
> plot.polar function to create something like
> that.https://vijaybarve.files.wordpress.com/2013/04/polarplot-05.png
>> Now the idea now will be to put three of those (for X,Y,Z) in a 3d
> rotatable plane. I tried the rgl function but is not clear how I can use
> directly polar coordinates to draw the points at the three different planes.
>> Any ideas on that?
>
> You can't easily do what you're trying to do.  You have 6 coordinates to
> display:  the 3 angles and values corresponding to each of them.  You
> need to suppress something.
>
> If the values for matching angles correspond to each other (e.g. x=23
> degrees and y=23 degrees and z=23 degrees all correspond to the same
> observation), then I'd suggest suppressing the angles.  Just do a
> scatterplot of the 3 corresponding values.  It might make sense to join
> them (to make a path as the angles change), and perhaps to colour the
> path to indicate the angle (or plot text along the path to show it).
>
> Duncan Murdoch
>
>> Thanks a lot.RegardsAlex
>>
>>    On Tuesday, June 20, 2017 9:49 PM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de
> <mailto:ligges at statistik.tu-dortmund.de>> wrote:
>>
>>
>>  package rgl.
>>
>> Best,
>> Uwe Ligges
>>
>>
>> On 20.06.2017 21:29, Alaios via R-help wrote:
>>> HelloI have three x,y,z vectors (lets say each is set as
> rnorm(360)). So each one is having 360 elements each one correpsonding
> to angular coordinates (1 degree, 2 degrees, 3 degrees,.... 360 degrees)
> and I want to plot those on the xyz axes that have degress.
>>> Is there a function or library to look at R cran? The ideal will be
> that after plotting I will be able to rotate the shape.
>>> I would like to thank you in advance for your helpRegardsAlex
>>>    [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
>>
>
>
>
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>


From pdalgd at gmail.com  Thu Jun 22 12:15:13 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 22 Jun 2017 12:15:13 +0200
Subject: [R] Hunting a histogram variant
In-Reply-To: <CAGxFJbQh4dysNRkHBLRG8V2Qdh4t8aJRQ-u2XdUWnZt6cY1aHQ@mail.gmail.com>
References: <HE1PR07MB11947F77F8138EF94D16A84FE2DA0@HE1PR07MB1194.eurprd07.prod.outlook.com>
 <7D9087F2-C6D5-446E-984C-65B757069986@comcast.net>
 <D381B11E-C295-4443-BFBE-2CCCC1C00172@LGCGroup.com>
 <CAGxFJbQh4dysNRkHBLRG8V2Qdh4t8aJRQ-u2XdUWnZt6cY1aHQ@mail.gmail.com>
Message-ID: <C175B765-5AAF-4C5C-8509-CA34D34C91AF@gmail.com>

Hmmno... The labels on a stem-and-leaf plots are the values. This is just the measurement number: Observations #2,5,6,9 from level 1 had a temperature between 89 and 90, making up the penultimate column of that histogram.

I would conjecture that, like stem-and-leaf, this has fallen out of favour because it doesn't scale well to larger samples. It is fine with 64 observations like this, but with (say) four times as many boxes, you'd lose all legibility.

-pd 

> On 22 Jun 2017, at 06:16 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ?stem
> 
> for something close and built in.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Jun 21, 2017 at 9:01 PM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>> 
>> I'm looking for a histogram variant in which data points are plotted as labelled rectangles 'piled up' to form a histogram. I've posted an example at https://www.dropbox.com/s/ozi8bhdn5kqaufm/labelled_histogram.png?dl=0
>> 
>> It seems to have a long pedigree, as I see it (as in this example) in documents going back beyond the '80s. But I've not seen it in recent textbooks. So it may be one of those older graphical displays that's just fallen out of use.
>> 
>> General questions:
>> i) Does this thing have a name?
>> ii) Can anyone point me to a literature source for it?
>> 
>> ... and the R question:
>> ii) Is it already hiding somewhere in an R package?*
>> 
>> S Ellison
>> 
>> *If it's not, I'll be adding it to one, hence the hunt for due credit/sources
>> 
>> 
>> 
>> *******************************************************************
>> This email and any attachments are confidential. Any u...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From evan.cooch at gmail.com  Thu Jun 22 14:47:09 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 22 Jun 2017 08:47:09 -0400
Subject: [R] selecting dataframe columns based on substring of col
	name(s)
In-Reply-To: <0F177FA6-B4E4-4DB4-835A-9CBBF5A5B435@comcast.net>
References: <dbecd23c-aa72-f3ec-8032-a16485a3195c@gmail.com>
 <0F177FA6-B4E4-4DB4-835A-9CBBF5A5B435@comcast.net>
Message-ID: <0d70a302-f93c-dee4-61ef-48d036780986@gmail.com>

Thanks to all the good suggestions/solutions to the original problem.

On 6/21/2017 3:28 PM, David Winsemius wrote:
>> On Jun 21, 2017, at 9:11 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
>>
>> Suppose I have the following sort of dataframe, where each column name has a common structure: prefix, followed by a number (for this example, col1, col2, col3 and col4):
>>
>> d = data.frame( col1=runif(10), col2=runif(10), col3=runif(10),col4=runif(10))
>>
>> What I haven't been able to suss out is how to efficiently 'extract/manipulate/play with' columns from the data frame, making use of this common structure.
>>
>> Suppose, for example, I want to 'work with' col2, col3, and col4. Now, I could subset the dataframe d in any number of ways -- for example
>>
>> piece <- d[,c("col2","col3","col4")]
>>
>> Works as expected, but for *big* problems (where I might have dozens -> hundreds of columns -- often the case with big design matrices output by some linear models program or another), having to write them all out using c("col2","col3",...."colXXXXX") takes a lot of time. What I'm wondering about is if there is a way to simply select over the "changing part" of the column name (you can do this relatively easily in a data step in SAS, for example). Heuristically, something like:
>>
>> piece <- df[,col2:col4]
>>
>> where the heuristic col2:col4 is interpreted as col2 -> col4 (parse the prefix 'col', and then simply select over the changing suffic -- i.e., column number).
>>
>> Now, if I use the "to" function in the lessR package, I can get there from here fairly easily:
>>
>> piece <- d[,to("col",4,from=2,same.size=FALSE)]
>>
>> But, is there a better way? Beyond 'efficiency' (ease of implementation), part of what constitutes 'better' might be something in base R, rather than relying on a package?
> After staring at the code for the base function subset with a thought to hacking it to do this I realized that should be already part of the evaluation result from its current form:
>
>   names(airquality)
> #[1] "Ozone"   "Solar.R" "Wind"    "Temp"    "Month"   "Day"
>
> subset(airquality,
>            Temp > 90,             # this is the row selection
>            select = Ozone:Solar.R) # and this selects columns
> #--------
>      Ozone Solar.R
> 42     NA     259
> 43     NA     250
> 69     97     267
> 70     97     272
> 75     NA     291
> 102    NA     222
> 120    76     203
> 121   118     225
> 122    84     237
> 123    85     188
> 124    96     167
> 125    78     197
> 126    73     183
> 127    91     189
>
> Bert's advice to work with the numbers is good, but conversion to numeric designations of columns inside the `select`-expression is actually what is occurring inside `subset`.
>


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Jun 22 15:23:22 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Jun 2017 09:23:22 -0400
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <22859.29712.207244.909859@stat.math.ethz.ch>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
Message-ID: <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>

The "configure exists but is not executable" problem is somewhat common 
on Windows, because there's usually no such thing as an executable bit 
there.  (Cygwin does something to fake one, but Windows generally 
doesn't.)  If you create a tarball there by default you get no 
executable bits marked in it.

For a long time, R CMD build has dealt with this issue by using the 
internal tar() function.  It corrects the executable bit with a warning 
during the build.

So if people are getting that error, something has gone wrong.  A few 
guesses:

  - They are on Linux but using a mount of a Windows volume that doesn't 
preserve the bit.

  - They are using a tarball produced in some strange way on Windows, 
e.g. by calling tar directly instead of R CMD build.

  - There's a bug in R in detecting the executable bit.

Martin saw configure marked executable in the tarball from CRAN, which 
means the second is unlikely (unless it was very recently fixed), but 
the first is still possible.  One test is to manually expand the 
tarball, then use both ls and R's test to see if the executable bit is 
set and is detected by R.  For example, after downloading 
stringi_1.1.5.tar.gz you expand it using

tar zxvf stringi_1.1.5.tar.gz

and use

ls -l stringi/configure

to see if the system thinks it is executable, and in R,

file_test("-x", "stringi/configure")

to see what R sees.

Duncan Murdoch

On 22/06/2017 3:38 AM, Martin Maechler wrote:
>>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>>     on Wed, 21 Jun 2017 18:04:13 -0700 writes:
>
>     >> On Jun 21, 2017, at 1:39 PM, Conklin, Mike (GfK) <Mike.Conklin at gfk.com> wrote:
>     >>
>     >> I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).
>     >>
>     >> R version 3.4.0 (2017-04-21)
>     >> Platform: x86_64-redhat-linux-gnu (64-bit)
>
>     > I'd make sure you have reviewed this:
>
>     > https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essential-programs-and-libraries
>
> yes,  but see also below ..
>
>     > Best;
>     > David.
>
>     >> Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)
>     >>
>     >> Matrix products: default
>     >> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
>     >>
>     >> locale:
>     >> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>     >> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>     >> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>     >> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>     >> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>     >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>     >>
>     >> attached base packages:
>     >> [1] stats     graphics  grDevices utils     datasets  methods   base
>     >>
>     >> other attached packages:
>     >> [1] dplyr_0.7.0 shiny_1.0.3
>     >>
>     >> loaded via a namespace (and not attached):
>     >> [1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
>     >> [5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
>     >> [9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
>     >> [13] mime_0.5         rlang_0.1.1
>     >>>
>     >>
>     >>
>     >> If I try and install Hmisc for example I get the following errors:
>     >> for the first error ERROR: 'configure' exists but is not executable --
>     >> see the 'R Installation and dministration Manual'  I did
>     >> not find the R Installation and Administration Manual
>     >> helpful.
>
> why?  It does assume you spend some time understanding what it
> is talking about.
> OTOH, it is  *THE*  official document on the topic, written and
> constantly updated by the  R core team.
>
> Anyway:   " ERROR: 'configure' exists but is not executable "
>
> is I think a crucial piece of information .. it's from stringi's
> installation failure, and the top level directory of stringi (1.1-5)
> in a Unix like (ls -l with user group names removed) looks like:
>
>   -rw-r--r--.         1451 Apr  7 15:08 DESCRIPTION
>   -rw-r--r--.         6207 Apr  7 11:21 INSTALL
>   -rw-r--r--.         3580 Mar 21 13:29 LICENSE
>   -rw-r--r--.        63692 Apr  7 15:08 MD5
>   -rw-r--r--.         6204 Oct 24  2016 NAMESPACE
>   -rw-r--r--.        22407 Apr  7 11:44 NEWS
>   drwxr-xr-x.         8192 Mar 28 10:26 R
>   -rwxr-xr-x.           66 Apr  2  2015 cleanup
>   -rw-rw-r--.        32193 Apr  8 05:46 config.log
>   -rwxrwxr-x.        40648 Apr  8 05:46 config.status
>   -rwxr-xr-x.       173757 Apr  7 11:43 configure
>   -rw-r--r--.          669 Jun 23  2015 configure.win
>   drwxr-xr-x.          512 Apr  7 11:50 inst
>   drwxr-xr-x.         8192 Mar 28 10:26 man
>   drwxr-xr-x.        16384 Apr  8 05:47 src
>
> Note the "x"s  in the 'configure' line's " -rwxr-xr-x. ":
> This means the file is executable and a reasonable shell can
> just "call the file" and it will be executed, but that's the
> part which failed for you.
>
> .. this *is* peculiar as it looks like some of the standard Unix
> tools may be misbehaving for you .. I assume it could be some OS
> security "feature" playing against you..
>
>     >>
>     >>
>     >>> install.packages("Hmisc")
>     >> Installing package into '/usr/lib64/R/library'
>     >> (as 'lib' is unspecified)
>     >> also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>     >> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
>     >> ==================================================
>     >> downloaded 3.5 MB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
>     >> Content type 'application/x-gzip' length 21914 bytes (21 KB)
>     >> ==================================================
>     >> downloaded 21 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
>     >> Content type 'application/x-gzip' length 34688 bytes (33 KB)
>     >> ==================================================
>     >> downloaded 33 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
>     >> Content type 'application/x-gzip' length 94095 bytes (91 KB)
>     >> ==================================================
>     >> downloaded 91 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
>     >> Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
>     >> ==================================================
>     >> downloaded 1007 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
>     >> Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
>     >> ==================================================
>     >> downloaded 2.1 MB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
>     >> Content type 'application/x-gzip' length 152095 bytes (148 KB)
>     >> ==================================================
>     >> downloaded 148 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
>     >> Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
>     >> ==================================================
>     >> downloaded 1.7 MB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
>     >> Content type 'application/x-gzip' length 702759 bytes (686 KB)
>     >> ==================================================
>     >> downloaded 686 KB
>     >>
>     >> * installing *source* package 'stringi' ...
>     >> ** package 'stringi' successfully unpacked and MD5 sums checked
>     >> ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
>     >> * removing '/usr/lib64/R/library/stringi'
>     >> ERROR: dependency 'stringi' is not available for package 'stringr'
>     >> * removing '/usr/lib64/R/library/stringr'
>     >> ERROR: dependency 'stringr' is not available for package 'evaluate'
>     >> * removing '/usr/lib64/R/library/evaluate'
>     >> ERROR: dependency 'stringr' is not available for package 'reshape2'
>     >> * removing '/usr/lib64/R/library/reshape2'
>     >> ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
>     >> * removing '/usr/lib64/R/library/knitr'
>     >> ERROR: dependency 'reshape2' is not available for package 'ggplot2'
>     >> * removing '/usr/lib64/R/library/ggplot2'
>     >> ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
>     >> * removing '/usr/lib64/R/library/htmlTable'
>     >> ERROR: dependency 'ggplot2' is not available for package 'viridis'
>     >> * removing '/usr/lib64/R/library/viridis'
>     >> ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
>     >> * removing '/usr/lib64/R/library/Hmisc'
>     >>
>     >>
>     >> Any help is appreciated.
>     >> --
>     >> W. Michael Conklin
>     >> Executive Vice President
>     >> Marketing & Data Sciences - North America
>     >> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
>     >> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
>     >> T +1 763 417 4545 | M +1 612 567 8287
>     >> www.gfk.com<http://www.gfk.com/>
>     >>
>     >>
>     >> [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>
>     > David Winsemius
>     > Alameda, CA, USA
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Mike.Conklin at gfk.com  Thu Jun 22 17:15:12 2017
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Thu, 22 Jun 2017 15:15:12 +0000
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
 <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
Message-ID: <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>

Following Duncan's instructions I find that the system and R find that configure IS executable but if trying to install via install.packages I get the same error.
I also tried using R CMD INSTALL from the terminal and install.packages with a local file pointing to the very same tar.gz file that shows the executable bit set. All result in the same "configure is not executable" result.

[meconk at dcex1102shinypr ~]$ ls -l stringi/configure
-rwxr-xr-x 1 meconk meconk 173757 Apr  7 11:43 stringi/configure
[meconk at dcex1102shinypr ~]$ sudo R
[sudo] password for meconk:

R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-redhat-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> getwd()
[1] "/home/meconk"
> file_test("-x","stringi/configure")
stringi/configure
             TRUE
> install.packages("stringi")                                                   Installing package into '/usr/lib64/R/library'
(as 'lib' is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
==================================================
downloaded 3.5 MB

* installing *source* package 'stringi' ...
** package 'stringi' successfully unpacked and MD5 sums checked
ERROR: 'configure' exists but is not executable -- see the 'R Installation and Administration Manual'
* removing '/usr/lib64/R/library/stringi'

The downloaded source packages are in
        '/tmp/Rtmpxw9twb/downloaded_packages'
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("stringi") :
  installation of package 'stringi' had non-zero exit status

--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK 
T +1 763 417 4545 | M +1 612 567 8287 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Thursday, June 22, 2017 8:23 AM
To: Martin Maechler; David Winsemius
Cc: r-help at r-project.org
Subject: Re: [R] Missing dependencies in pkg installs

The "configure exists but is not executable" problem is somewhat common on Windows, because there's usually no such thing as an executable bit there.  (Cygwin does something to fake one, but Windows generally
doesn't.)  If you create a tarball there by default you get no executable bits marked in it.

For a long time, R CMD build has dealt with this issue by using the internal tar() function.  It corrects the executable bit with a warning during the build.

So if people are getting that error, something has gone wrong.  A few
guesses:

  - They are on Linux but using a mount of a Windows volume that doesn't preserve the bit.

  - They are using a tarball produced in some strange way on Windows, e.g. by calling tar directly instead of R CMD build.

  - There's a bug in R in detecting the executable bit.

Martin saw configure marked executable in the tarball from CRAN, which means the second is unlikely (unless it was very recently fixed), but the first is still possible.  One test is to manually expand the tarball, then use both ls and R's test to see if the executable bit is set and is detected by R.  For example, after downloading stringi_1.1.5.tar.gz you expand it using

tar zxvf stringi_1.1.5.tar.gz

and use

ls -l stringi/configure

to see if the system thinks it is executable, and in R,

file_test("-x", "stringi/configure")

to see what R sees.

Duncan Murdoch

On 22/06/2017 3:38 AM, Martin Maechler wrote:
>>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>>     on Wed, 21 Jun 2017 18:04:13 -0700 writes:
>
>     >> On Jun 21, 2017, at 1:39 PM, Conklin, Mike (GfK) <Mike.Conklin at gfk.com> wrote:
>     >>
>     >> I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).
>     >>
>     >> R version 3.4.0 (2017-04-21)
>     >> Platform: x86_64-redhat-linux-gnu (64-bit)
>
>     > I'd make sure you have reviewed this:
>
>     > 
> https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essentia
> l-programs-and-libraries
>
> yes,  but see also below ..
>
>     > Best;
>     > David.
>
>     >> Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)
>     >>
>     >> Matrix products: default
>     >> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
>     >>
>     >> locale:
>     >> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>     >> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>     >> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>     >> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>     >> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>     >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>     >>
>     >> attached base packages:
>     >> [1] stats     graphics  grDevices utils     datasets  methods   base
>     >>
>     >> other attached packages:
>     >> [1] dplyr_0.7.0 shiny_1.0.3
>     >>
>     >> loaded via a namespace (and not attached):
>     >> [1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
>     >> [5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
>     >> [9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
>     >> [13] mime_0.5         rlang_0.1.1
>     >>>
>     >>
>     >>
>     >> If I try and install Hmisc for example I get the following errors:
>     >> for the first error ERROR: 'configure' exists but is not executable --
>     >> see the 'R Installation and dministration Manual'  I did
>     >> not find the R Installation and Administration Manual
>     >> helpful.
>
> why?  It does assume you spend some time understanding what it is 
> talking about.
> OTOH, it is  *THE*  official document on the topic, written and 
> constantly updated by the  R core team.
>
> Anyway:   " ERROR: 'configure' exists but is not executable "
>
> is I think a crucial piece of information .. it's from stringi's 
> installation failure, and the top level directory of stringi (1.1-5) 
> in a Unix like (ls -l with user group names removed) looks like:
>
>   -rw-r--r--.         1451 Apr  7 15:08 DESCRIPTION
>   -rw-r--r--.         6207 Apr  7 11:21 INSTALL
>   -rw-r--r--.         3580 Mar 21 13:29 LICENSE
>   -rw-r--r--.        63692 Apr  7 15:08 MD5
>   -rw-r--r--.         6204 Oct 24  2016 NAMESPACE
>   -rw-r--r--.        22407 Apr  7 11:44 NEWS
>   drwxr-xr-x.         8192 Mar 28 10:26 R
>   -rwxr-xr-x.           66 Apr  2  2015 cleanup
>   -rw-rw-r--.        32193 Apr  8 05:46 config.log
>   -rwxrwxr-x.        40648 Apr  8 05:46 config.status
>   -rwxr-xr-x.       173757 Apr  7 11:43 configure
>   -rw-r--r--.          669 Jun 23  2015 configure.win
>   drwxr-xr-x.          512 Apr  7 11:50 inst
>   drwxr-xr-x.         8192 Mar 28 10:26 man
>   drwxr-xr-x.        16384 Apr  8 05:47 src
>
> Note the "x"s  in the 'configure' line's " -rwxr-xr-x. ":
> This means the file is executable and a reasonable shell can just 
> "call the file" and it will be executed, but that's the part which 
> failed for you.
>
> .. this *is* peculiar as it looks like some of the standard Unix tools 
> may be misbehaving for you .. I assume it could be some OS security 
> "feature" playing against you..
>
>     >>
>     >>
>     >>> install.packages("Hmisc")
>     >> Installing package into '/usr/lib64/R/library'
>     >> (as 'lib' is unspecified)
>     >> also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>     >> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
>     >> ==================================================
>     >> downloaded 3.5 MB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
>     >> Content type 'application/x-gzip' length 21914 bytes (21 KB)
>     >> ==================================================
>     >> downloaded 21 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
>     >> Content type 'application/x-gzip' length 34688 bytes (33 KB)
>     >> ==================================================
>     >> downloaded 33 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
>     >> Content type 'application/x-gzip' length 94095 bytes (91 KB)
>     >> ==================================================
>     >> downloaded 91 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
>     >> Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
>     >> ==================================================
>     >> downloaded 1007 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
>     >> Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
>     >> ==================================================
>     >> downloaded 2.1 MB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
>     >> Content type 'application/x-gzip' length 152095 bytes (148 KB)
>     >> ==================================================
>     >> downloaded 148 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
>     >> Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
>     >> ==================================================
>     >> downloaded 1.7 MB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
>     >> Content type 'application/x-gzip' length 702759 bytes (686 KB)
>     >> ==================================================
>     >> downloaded 686 KB
>     >>
>     >> * installing *source* package 'stringi' ...
>     >> ** package 'stringi' successfully unpacked and MD5 sums checked
>     >> ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
>     >> * removing '/usr/lib64/R/library/stringi'
>     >> ERROR: dependency 'stringi' is not available for package 'stringr'
>     >> * removing '/usr/lib64/R/library/stringr'
>     >> ERROR: dependency 'stringr' is not available for package 'evaluate'
>     >> * removing '/usr/lib64/R/library/evaluate'
>     >> ERROR: dependency 'stringr' is not available for package 'reshape2'
>     >> * removing '/usr/lib64/R/library/reshape2'
>     >> ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
>     >> * removing '/usr/lib64/R/library/knitr'
>     >> ERROR: dependency 'reshape2' is not available for package 'ggplot2'
>     >> * removing '/usr/lib64/R/library/ggplot2'
>     >> ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
>     >> * removing '/usr/lib64/R/library/htmlTable'
>     >> ERROR: dependency 'ggplot2' is not available for package 'viridis'
>     >> * removing '/usr/lib64/R/library/viridis'
>     >> ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
>     >> * removing '/usr/lib64/R/library/Hmisc'
>     >>
>     >>
>     >> Any help is appreciated.
>     >> --
>     >> W. Michael Conklin
>     >> Executive Vice President
>     >> Marketing & Data Sciences - North America
>     >> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
>     >> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
>     >> T +1 763 417 4545 | M +1 612 567 8287
>     >> www.gfk.com<http://www.gfk.com/>
>     >>
>     >>
>     >> [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>
>     > David Winsemius
>     > Alameda, CA, USA
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Mike.Conklin at gfk.com  Thu Jun 22 18:00:06 2017
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Thu, 22 Jun 2017 16:00:06 +0000
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
 <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
 <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
Message-ID: <89283461424843f3adc4b04fac3c8db0@IPXW-EXPCM02.gfk.com>

also it seems to be no issue to execute configure from the command line  ./configure

--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK 
T +1 763 417 4545 | M +1 612 567 8287 


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Conklin, Mike (GfK)
Sent: Thursday, June 22, 2017 10:15 AM
To: Duncan Murdoch; Martin Maechler; David Winsemius
Cc: r-help at r-project.org
Subject: Re: [R] Missing dependencies in pkg installs

Following Duncan's instructions I find that the system and R find that configure IS executable but if trying to install via install.packages I get the same error.
I also tried using R CMD INSTALL from the terminal and install.packages with a local file pointing to the very same tar.gz file that shows the executable bit set. All result in the same "configure is not executable" result.

[meconk at dcex1102shinypr ~]$ ls -l stringi/configure -rwxr-xr-x 1 meconk meconk 173757 Apr  7 11:43 stringi/configure [meconk at dcex1102shinypr ~]$ sudo R [sudo] password for meconk:

R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-redhat-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and 'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or 'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> getwd()
[1] "/home/meconk"
> file_test("-x","stringi/configure")
stringi/configure
             TRUE
> install.packages("stringi")                                                   Installing package into '/usr/lib64/R/library'
(as 'lib' is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
Content type 'application/x-gzip' length 3645872 bytes (3.5 MB) ==================================================
downloaded 3.5 MB

* installing *source* package 'stringi' ...
** package 'stringi' successfully unpacked and MD5 sums checked
ERROR: 'configure' exists but is not executable -- see the 'R Installation and Administration Manual'
* removing '/usr/lib64/R/library/stringi'

The downloaded source packages are in
        '/tmp/Rtmpxw9twb/downloaded_packages'
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("stringi") :
  installation of package 'stringi' had non-zero exit status

--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK
T +1 763 417 4545 | M +1 612 567 8287 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Thursday, June 22, 2017 8:23 AM
To: Martin Maechler; David Winsemius
Cc: r-help at r-project.org
Subject: Re: [R] Missing dependencies in pkg installs

The "configure exists but is not executable" problem is somewhat common on Windows, because there's usually no such thing as an executable bit there.  (Cygwin does something to fake one, but Windows generally
doesn't.)  If you create a tarball there by default you get no executable bits marked in it.

For a long time, R CMD build has dealt with this issue by using the internal tar() function.  It corrects the executable bit with a warning during the build.

So if people are getting that error, something has gone wrong.  A few
guesses:

  - They are on Linux but using a mount of a Windows volume that doesn't preserve the bit.

  - They are using a tarball produced in some strange way on Windows, e.g. by calling tar directly instead of R CMD build.

  - There's a bug in R in detecting the executable bit.

Martin saw configure marked executable in the tarball from CRAN, which means the second is unlikely (unless it was very recently fixed), but the first is still possible.  One test is to manually expand the tarball, then use both ls and R's test to see if the executable bit is set and is detected by R.  For example, after downloading stringi_1.1.5.tar.gz you expand it using

tar zxvf stringi_1.1.5.tar.gz

and use

ls -l stringi/configure

to see if the system thinks it is executable, and in R,

file_test("-x", "stringi/configure")

to see what R sees.

Duncan Murdoch

On 22/06/2017 3:38 AM, Martin Maechler wrote:
>>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>>     on Wed, 21 Jun 2017 18:04:13 -0700 writes:
>
>     >> On Jun 21, 2017, at 1:39 PM, Conklin, Mike (GfK) <Mike.Conklin at gfk.com> wrote:
>     >>
>     >> I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).
>     >>
>     >> R version 3.4.0 (2017-04-21)
>     >> Platform: x86_64-redhat-linux-gnu (64-bit)
>
>     > I'd make sure you have reviewed this:
>
>     >
> https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essentia
> l-programs-and-libraries
>
> yes,  but see also below ..
>
>     > Best;
>     > David.
>
>     >> Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)
>     >>
>     >> Matrix products: default
>     >> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
>     >>
>     >> locale:
>     >> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>     >> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>     >> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>     >> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>     >> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>     >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>     >>
>     >> attached base packages:
>     >> [1] stats     graphics  grDevices utils     datasets  methods   base
>     >>
>     >> other attached packages:
>     >> [1] dplyr_0.7.0 shiny_1.0.3
>     >>
>     >> loaded via a namespace (and not attached):
>     >> [1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
>     >> [5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
>     >> [9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
>     >> [13] mime_0.5         rlang_0.1.1
>     >>>
>     >>
>     >>
>     >> If I try and install Hmisc for example I get the following errors:
>     >> for the first error ERROR: 'configure' exists but is not executable --
>     >> see the 'R Installation and dministration Manual'  I did
>     >> not find the R Installation and Administration Manual
>     >> helpful.
>
> why?  It does assume you spend some time understanding what it is 
> talking about.
> OTOH, it is  *THE*  official document on the topic, written and 
> constantly updated by the  R core team.
>
> Anyway:   " ERROR: 'configure' exists but is not executable "
>
> is I think a crucial piece of information .. it's from stringi's 
> installation failure, and the top level directory of stringi (1.1-5) 
> in a Unix like (ls -l with user group names removed) looks like:
>
>   -rw-r--r--.         1451 Apr  7 15:08 DESCRIPTION
>   -rw-r--r--.         6207 Apr  7 11:21 INSTALL
>   -rw-r--r--.         3580 Mar 21 13:29 LICENSE
>   -rw-r--r--.        63692 Apr  7 15:08 MD5
>   -rw-r--r--.         6204 Oct 24  2016 NAMESPACE
>   -rw-r--r--.        22407 Apr  7 11:44 NEWS
>   drwxr-xr-x.         8192 Mar 28 10:26 R
>   -rwxr-xr-x.           66 Apr  2  2015 cleanup
>   -rw-rw-r--.        32193 Apr  8 05:46 config.log
>   -rwxrwxr-x.        40648 Apr  8 05:46 config.status
>   -rwxr-xr-x.       173757 Apr  7 11:43 configure
>   -rw-r--r--.          669 Jun 23  2015 configure.win
>   drwxr-xr-x.          512 Apr  7 11:50 inst
>   drwxr-xr-x.         8192 Mar 28 10:26 man
>   drwxr-xr-x.        16384 Apr  8 05:47 src
>
> Note the "x"s  in the 'configure' line's " -rwxr-xr-x. ":
> This means the file is executable and a reasonable shell can just 
> "call the file" and it will be executed, but that's the part which 
> failed for you.
>
> .. this *is* peculiar as it looks like some of the standard Unix tools 
> may be misbehaving for you .. I assume it could be some OS security 
> "feature" playing against you..
>
>     >>
>     >>
>     >>> install.packages("Hmisc")
>     >> Installing package into '/usr/lib64/R/library'
>     >> (as 'lib' is unspecified)
>     >> also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>     >> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
>     >> ==================================================
>     >> downloaded 3.5 MB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
>     >> Content type 'application/x-gzip' length 21914 bytes (21 KB)
>     >> ==================================================
>     >> downloaded 21 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
>     >> Content type 'application/x-gzip' length 34688 bytes (33 KB)
>     >> ==================================================
>     >> downloaded 33 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
>     >> Content type 'application/x-gzip' length 94095 bytes (91 KB)
>     >> ==================================================
>     >> downloaded 91 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
>     >> Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
>     >> ==================================================
>     >> downloaded 1007 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
>     >> Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
>     >> ==================================================
>     >> downloaded 2.1 MB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
>     >> Content type 'application/x-gzip' length 152095 bytes (148 KB)
>     >> ==================================================
>     >> downloaded 148 KB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
>     >> Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
>     >> ==================================================
>     >> downloaded 1.7 MB
>     >>
>     >> trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
>     >> Content type 'application/x-gzip' length 702759 bytes (686 KB)
>     >> ==================================================
>     >> downloaded 686 KB
>     >>
>     >> * installing *source* package 'stringi' ...
>     >> ** package 'stringi' successfully unpacked and MD5 sums checked
>     >> ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
>     >> * removing '/usr/lib64/R/library/stringi'
>     >> ERROR: dependency 'stringi' is not available for package 'stringr'
>     >> * removing '/usr/lib64/R/library/stringr'
>     >> ERROR: dependency 'stringr' is not available for package 'evaluate'
>     >> * removing '/usr/lib64/R/library/evaluate'
>     >> ERROR: dependency 'stringr' is not available for package 'reshape2'
>     >> * removing '/usr/lib64/R/library/reshape2'
>     >> ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
>     >> * removing '/usr/lib64/R/library/knitr'
>     >> ERROR: dependency 'reshape2' is not available for package 'ggplot2'
>     >> * removing '/usr/lib64/R/library/ggplot2'
>     >> ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
>     >> * removing '/usr/lib64/R/library/htmlTable'
>     >> ERROR: dependency 'ggplot2' is not available for package 'viridis'
>     >> * removing '/usr/lib64/R/library/viridis'
>     >> ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
>     >> * removing '/usr/lib64/R/library/Hmisc'
>     >>
>     >>
>     >> Any help is appreciated.
>     >> --
>     >> W. Michael Conklin
>     >> Executive Vice President
>     >> Marketing & Data Sciences - North America
>     >> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
>     >> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
>     >> T +1 763 417 4545 | M +1 612 567 8287
>     >> www.gfk.com<http://www.gfk.com/>
>     >>
>     >>
>     >> [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>
>     > David Winsemius
>     > Alameda, CA, USA
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Jun 22 18:08:47 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Jun 2017 12:08:47 -0400
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
 <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
 <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
Message-ID: <37b169a8-a0c8-ea11-2925-7cc09777a203@gmail.com>

On 22/06/2017 11:15 AM, Conklin, Mike (GfK) wrote:
> Following Duncan's instructions I find that the system and R find that configure IS executable but if trying to install via install.packages I get the same error.
> I also tried using R CMD INSTALL from the terminal and install.packages with a local file pointing to the very same tar.gz file that shows the executable bit set. All result in the same "configure is not executable" result.
>

That's very mysterious.  This is hard to debug, because R runs a 
separate process to do the installs.  If you want to track this down you 
can debug the code as follows.

1.  Manually download the tarball, using any method (perhaps 
download.packages("stringi", destdir = ".", type = "source").

2.  In R, run

debug(tools:::.install_packages)
tools:::.install_packages("stringi_1.1.5.tar.gz")

You can single step until you see the message, and try to diagnose why 
it is happening.

Watch out, this function will exit R at the end.

Duncan Murdoch

> [meconk at dcex1102shinypr ~]$ ls -l stringi/configure
> -rwxr-xr-x 1 meconk meconk 173757 Apr  7 11:43 stringi/configure
> [meconk at dcex1102shinypr ~]$ sudo R
> [sudo] password for meconk:
>
> R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
> Copyright (C) 2017 The R Foundation for Statistical Computing
> Platform: x86_64-redhat-linux-gnu (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>   Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> [Previously saved workspace restored]
>
>> getwd()
> [1] "/home/meconk"
>> file_test("-x","stringi/configure")
> stringi/configure
>              TRUE
>> install.packages("stringi")                                                   Installing package into '/usr/lib64/R/library'
> (as 'lib' is unspecified)
> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
> ==================================================
> downloaded 3.5 MB
>
> * installing *source* package 'stringi' ...
> ** package 'stringi' successfully unpacked and MD5 sums checked
> ERROR: 'configure' exists but is not executable -- see the 'R Installation and Administration Manual'
> * removing '/usr/lib64/R/library/stringi'
>
> The downloaded source packages are in
>         '/tmp/Rtmpxw9twb/downloaded_packages'
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("stringi") :
>   installation of package 'stringi' had non-zero exit status
>
> --
> W. Michael Conklin
> EVP Marketing & Data Sciences
> GfK
> T +1 763 417 4545 | M +1 612 567 8287
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Thursday, June 22, 2017 8:23 AM
> To: Martin Maechler; David Winsemius
> Cc: r-help at r-project.org
> Subject: Re: [R] Missing dependencies in pkg installs
>
> The "configure exists but is not executable" problem is somewhat common on Windows, because there's usually no such thing as an executable bit there.  (Cygwin does something to fake one, but Windows generally
> doesn't.)  If you create a tarball there by default you get no executable bits marked in it.
>
> For a long time, R CMD build has dealt with this issue by using the internal tar() function.  It corrects the executable bit with a warning during the build.
>
> So if people are getting that error, something has gone wrong.  A few
> guesses:
>
>   - They are on Linux but using a mount of a Windows volume that doesn't preserve the bit.
>
>   - They are using a tarball produced in some strange way on Windows, e.g. by calling tar directly instead of R CMD build.
>
>   - There's a bug in R in detecting the executable bit.
>
> Martin saw configure marked executable in the tarball from CRAN, which means the second is unlikely (unless it was very recently fixed), but the first is still possible.  One test is to manually expand the tarball, then use both ls and R's test to see if the executable bit is set and is detected by R.  For example, after downloading stringi_1.1.5.tar.gz you expand it using
>
> tar zxvf stringi_1.1.5.tar.gz
>
> and use
>
> ls -l stringi/configure
>
> to see if the system thinks it is executable, and in R,
>
> file_test("-x", "stringi/configure")
>
> to see what R sees.
>
> Duncan Murdoch
>
> On 22/06/2017 3:38 AM, Martin Maechler wrote:
>>>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>>>     on Wed, 21 Jun 2017 18:04:13 -0700 writes:
>>
>>     >> On Jun 21, 2017, at 1:39 PM, Conklin, Mike (GfK) <Mike.Conklin at gfk.com> wrote:
>>     >>
>>     >> I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).
>>     >>
>>     >> R version 3.4.0 (2017-04-21)
>>     >> Platform: x86_64-redhat-linux-gnu (64-bit)
>>
>>     > I'd make sure you have reviewed this:
>>
>>     >
>> https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essentia
>> l-programs-and-libraries
>>
>> yes,  but see also below ..
>>
>>     > Best;
>>     > David.
>>
>>     >> Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)
>>     >>
>>     >> Matrix products: default
>>     >> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
>>     >>
>>     >> locale:
>>     >> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>     >> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>     >> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>     >> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>     >> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>     >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>     >>
>>     >> attached base packages:
>>     >> [1] stats     graphics  grDevices utils     datasets  methods   base
>>     >>
>>     >> other attached packages:
>>     >> [1] dplyr_0.7.0 shiny_1.0.3
>>     >>
>>     >> loaded via a namespace (and not attached):
>>     >> [1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
>>     >> [5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
>>     >> [9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
>>     >> [13] mime_0.5         rlang_0.1.1
>>     >>>
>>     >>
>>     >>
>>     >> If I try and install Hmisc for example I get the following errors:
>>     >> for the first error ERROR: 'configure' exists but is not executable --
>>     >> see the 'R Installation and dministration Manual'  I did
>>     >> not find the R Installation and Administration Manual
>>     >> helpful.
>>
>> why?  It does assume you spend some time understanding what it is
>> talking about.
>> OTOH, it is  *THE*  official document on the topic, written and
>> constantly updated by the  R core team.
>>
>> Anyway:   " ERROR: 'configure' exists but is not executable "
>>
>> is I think a crucial piece of information .. it's from stringi's
>> installation failure, and the top level directory of stringi (1.1-5)
>> in a Unix like (ls -l with user group names removed) looks like:
>>
>>   -rw-r--r--.         1451 Apr  7 15:08 DESCRIPTION
>>   -rw-r--r--.         6207 Apr  7 11:21 INSTALL
>>   -rw-r--r--.         3580 Mar 21 13:29 LICENSE
>>   -rw-r--r--.        63692 Apr  7 15:08 MD5
>>   -rw-r--r--.         6204 Oct 24  2016 NAMESPACE
>>   -rw-r--r--.        22407 Apr  7 11:44 NEWS
>>   drwxr-xr-x.         8192 Mar 28 10:26 R
>>   -rwxr-xr-x.           66 Apr  2  2015 cleanup
>>   -rw-rw-r--.        32193 Apr  8 05:46 config.log
>>   -rwxrwxr-x.        40648 Apr  8 05:46 config.status
>>   -rwxr-xr-x.       173757 Apr  7 11:43 configure
>>   -rw-r--r--.          669 Jun 23  2015 configure.win
>>   drwxr-xr-x.          512 Apr  7 11:50 inst
>>   drwxr-xr-x.         8192 Mar 28 10:26 man
>>   drwxr-xr-x.        16384 Apr  8 05:47 src
>>
>> Note the "x"s  in the 'configure' line's " -rwxr-xr-x. ":
>> This means the file is executable and a reasonable shell can just
>> "call the file" and it will be executed, but that's the part which
>> failed for you.
>>
>> .. this *is* peculiar as it looks like some of the standard Unix tools
>> may be misbehaving for you .. I assume it could be some OS security
>> "feature" playing against you..
>>
>>     >>
>>     >>
>>     >>> install.packages("Hmisc")
>>     >> Installing package into '/usr/lib64/R/library'
>>     >> (as 'lib' is unspecified)
>>     >> also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>>     >> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
>>     >> ==================================================
>>     >> downloaded 3.5 MB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
>>     >> Content type 'application/x-gzip' length 21914 bytes (21 KB)
>>     >> ==================================================
>>     >> downloaded 21 KB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
>>     >> Content type 'application/x-gzip' length 34688 bytes (33 KB)
>>     >> ==================================================
>>     >> downloaded 33 KB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
>>     >> Content type 'application/x-gzip' length 94095 bytes (91 KB)
>>     >> ==================================================
>>     >> downloaded 91 KB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
>>     >> Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
>>     >> ==================================================
>>     >> downloaded 1007 KB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
>>     >> Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
>>     >> ==================================================
>>     >> downloaded 2.1 MB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
>>     >> Content type 'application/x-gzip' length 152095 bytes (148 KB)
>>     >> ==================================================
>>     >> downloaded 148 KB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
>>     >> Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
>>     >> ==================================================
>>     >> downloaded 1.7 MB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
>>     >> Content type 'application/x-gzip' length 702759 bytes (686 KB)
>>     >> ==================================================
>>     >> downloaded 686 KB
>>     >>
>>     >> * installing *source* package 'stringi' ...
>>     >> ** package 'stringi' successfully unpacked and MD5 sums checked
>>     >> ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
>>     >> * removing '/usr/lib64/R/library/stringi'
>>     >> ERROR: dependency 'stringi' is not available for package 'stringr'
>>     >> * removing '/usr/lib64/R/library/stringr'
>>     >> ERROR: dependency 'stringr' is not available for package 'evaluate'
>>     >> * removing '/usr/lib64/R/library/evaluate'
>>     >> ERROR: dependency 'stringr' is not available for package 'reshape2'
>>     >> * removing '/usr/lib64/R/library/reshape2'
>>     >> ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
>>     >> * removing '/usr/lib64/R/library/knitr'
>>     >> ERROR: dependency 'reshape2' is not available for package 'ggplot2'
>>     >> * removing '/usr/lib64/R/library/ggplot2'
>>     >> ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
>>     >> * removing '/usr/lib64/R/library/htmlTable'
>>     >> ERROR: dependency 'ggplot2' is not available for package 'viridis'
>>     >> * removing '/usr/lib64/R/library/viridis'
>>     >> ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
>>     >> * removing '/usr/lib64/R/library/Hmisc'
>>     >>
>>     >>
>>     >> Any help is appreciated.
>>     >> --
>>     >> W. Michael Conklin
>>     >> Executive Vice President
>>     >> Marketing & Data Sciences - North America
>>     >> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
>>     >> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
>>     >> T +1 763 417 4545 | M +1 612 567 8287
>>     >> www.gfk.com<http://www.gfk.com/>
>>     >>
>>     >>
>>     >> [[alternative HTML version deleted]]
>>     >>
>>     >> ______________________________________________
>>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>     >> and provide commented, minimal, self-contained, reproducible code.
>>
>>     > David Winsemius
>>     > Alameda, CA, USA
>>
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>     > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ahmedatia80 at gmail.com  Thu Jun 22 18:50:29 2017
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Thu, 22 Jun 2017 18:50:29 +0200
Subject: [R] For loop
Message-ID: <CAG6S0Om2_FQyOJ-7L+aSqiUbT0-inm-opiCEVFY3NaugPoFYXg@mail.gmail.com>

Hello R users,

The code below is for loop in R that I want to do to following
calculation at each time i and i-1 in 2:75 dataset
(Litterfall_Ahmed97).


ac = ((LeafBiog at date i
-LeafBiog at date i-1, dataset = leafbiom97) + (littperiod at date i,
dataset= Litterfall_Ahmed97))/(sum (GPP from date i-1 to date i,
dataset=GPP_Ahmed13)/2) .

#code for loop

GPP_Ahmed13$Date <- as.Date(GPP_Ahmed13$Date, '%Y/%m/%d')
Litterfall_Ahmed97$Date <- as.Date(Litterfall_Ahmed97$Date, '%Y/%m/%d')
leafbiom97$Date <- as.Date( leafbiom97$Date, '%Y/%m/%d')
for (i in 2:75){
  (leafbiom97$LeafBiog[leafbiom97$Date == "i"] -
     leafbiom97$LeafBiog[leafbiom97$Date == "i-1"]+
     Litterfall_Ahmed97$littperiod[Litterfall_Ahmed97$Date =="i"])/
    (sum(GPP_Ahmed13$GPP[GPP_Ahmed13$Date >= "i-1" &
                           GPP_Ahmed13$Date <= "i"])/2)
}


#Error in charToDate(x) :

Thanks for your help


Ahmed Attia, Ph.D.
Agronomist & Soil Scientist


From ruipbarradas at sapo.pt  Thu Jun 22 19:15:42 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 22 Jun 2017 18:15:42 +0100
Subject: [R] For loop
In-Reply-To: <CAG6S0Om2_FQyOJ-7L+aSqiUbT0-inm-opiCEVFY3NaugPoFYXg@mail.gmail.com>
References: <CAG6S0Om2_FQyOJ-7L+aSqiUbT0-inm-opiCEVFY3NaugPoFYXg@mail.gmail.com>
Message-ID: <594BFB3E.2030909@sapo.pt>

Hello,

Without correcting your code, it's obvious that the expressions like 
leafbiom97$Date == "i" and all others with"i" and "i - 1" are wrong.
leafbiom97$Date is of class Date, not character. And, besides,
for(i in ...) makes of i a numeric variable that has nothing to do with 
"i". This "i" will remain the character string "i" for all iterations of 
the loop.

Hope this helps,

Rui Barradas

Em 22-06-2017 17:50, Ahmed Attia escreveu:
> leafbiom97$Date == "i"


From NordlDJ at dshs.wa.gov  Thu Jun 22 19:59:33 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 22 Jun 2017 17:59:33 +0000
Subject: [R] For loop
In-Reply-To: <CAG6S0Om2_FQyOJ-7L+aSqiUbT0-inm-opiCEVFY3NaugPoFYXg@mail.gmail.com>
References: <CAG6S0Om2_FQyOJ-7L+aSqiUbT0-inm-opiCEVFY3NaugPoFYXg@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643EC729A@WAXMXOLYMB025.WAX.wa.lcl>

For a reproducible example, you need to give us some example data, at least

dput(head(leafbiom97))
dput(head(Litterfall_Ahmed97))
dput(head(GPP_Ahmed13))


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ahmed
> Attia
> Sent: Thursday, June 22, 2017 9:50 AM
> To: r-help
> Subject: [R] For loop
> 
> Hello R users,
> 
> The code below is for loop in R that I want to do to following
> calculation at each time i and i-1 in 2:75 dataset
> (Litterfall_Ahmed97).
> 
> 
> ac = ((LeafBiog at date i
> -LeafBiog at date i-1, dataset = leafbiom97) + (littperiod at date i,
> dataset= Litterfall_Ahmed97))/(sum (GPP from date i-1 to date i,
> dataset=GPP_Ahmed13)/2) .
> 
> #code for loop
> 
> GPP_Ahmed13$Date <- as.Date(GPP_Ahmed13$Date, '%Y/%m/%d')
> Litterfall_Ahmed97$Date <- as.Date(Litterfall_Ahmed97$Date, '%Y/%m/%d')
> leafbiom97$Date <- as.Date( leafbiom97$Date, '%Y/%m/%d')
> for (i in 2:75){
>   (leafbiom97$LeafBiog[leafbiom97$Date == "i"] -
>      leafbiom97$LeafBiog[leafbiom97$Date == "i-1"]+
>      Litterfall_Ahmed97$littperiod[Litterfall_Ahmed97$Date =="i"])/
>     (sum(GPP_Ahmed13$GPP[GPP_Ahmed13$Date >= "i-1" &
>                            GPP_Ahmed13$Date <= "i"])/2)
> }
> 
> 
> #Error in charToDate(x) :
> 
> Thanks for your help
> 
> 
> Ahmed Attia, Ph.D.
> Agronomist & Soil Scientist
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Mike.Conklin at gfk.com  Thu Jun 22 21:42:45 2017
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Thu, 22 Jun 2017 19:42:45 +0000
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <37b169a8-a0c8-ea11-2925-7cc09777a203@gmail.com>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
 <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
 <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
 <37b169a8-a0c8-ea11-2925-7cc09777a203@gmail.com>
Message-ID: <10a0d0f4d1f9448ca6a6140146943f13@IPXW-EXPCM02.gfk.com>

Not much progress..... I step through debug and it gets to the do.install() function which immediately errors with the same "configuration not executable" error.

So, made a tempfunc that was a copy of tools:::.install_packages and edited the file_test("-x","configure") line to return a TRUE

now I get a Permission Denied error (even if I run as root)

> tempfunc("/home/meconk/stringi_1.1.5.tar.gz")
* installing to library '/usr/lib64/R/library'
* installing *source* package 'stringi' ...
** package 'stringi' successfully unpacked and MD5 sums checked
sh: ./configure: Permission denied
ERROR: configuration failed for package 'stringi'
* removing '/usr/lib64/R/library/stringi'
Error in do_exit(status = status) : .install_packages() exit status 1
Error in do_exit(status = status) : .install_packages() exit status 1

--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK 
T +1 763 417 4545 | M +1 612 567 8287 


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Thursday, June 22, 2017 11:09 AM
To: Conklin, Mike (GfK); Martin Maechler; David Winsemius
Cc: r-help at r-project.org
Subject: Re: [R] Missing dependencies in pkg installs

On 22/06/2017 11:15 AM, Conklin, Mike (GfK) wrote:
> Following Duncan's instructions I find that the system and R find that configure IS executable but if trying to install via install.packages I get the same error.
> I also tried using R CMD INSTALL from the terminal and install.packages with a local file pointing to the very same tar.gz file that shows the executable bit set. All result in the same "configure is not executable" result.
>

That's very mysterious.  This is hard to debug, because R runs a separate process to do the installs.  If you want to track this down you can debug the code as follows.

1.  Manually download the tarball, using any method (perhaps download.packages("stringi", destdir = ".", type = "source").

2.  In R, run

debug(tools:::.install_packages)
tools:::.install_packages("stringi_1.1.5.tar.gz")

You can single step until you see the message, and try to diagnose why it is happening.

Watch out, this function will exit R at the end.

Duncan Murdoch

> [meconk at dcex1102shinypr ~]$ ls -l stringi/configure -rwxr-xr-x 1 
> meconk meconk 173757 Apr  7 11:43 stringi/configure 
> [meconk at dcex1102shinypr ~]$ sudo R [sudo] password for meconk:
>
> R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
> Copyright (C) 2017 The R Foundation for Statistical Computing
> Platform: x86_64-redhat-linux-gnu (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>   Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and 'citation()' on how to 
> cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or 
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> [Previously saved workspace restored]
>
>> getwd()
> [1] "/home/meconk"
>> file_test("-x","stringi/configure")
> stringi/configure
>              TRUE
>> install.packages("stringi")                                                   Installing package into '/usr/lib64/R/library'
> (as 'lib' is unspecified)
> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB) 
> ==================================================
> downloaded 3.5 MB
>
> * installing *source* package 'stringi' ...
> ** package 'stringi' successfully unpacked and MD5 sums checked
> ERROR: 'configure' exists but is not executable -- see the 'R Installation and Administration Manual'
> * removing '/usr/lib64/R/library/stringi'
>
> The downloaded source packages are in
>         '/tmp/Rtmpxw9twb/downloaded_packages'
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("stringi") :
>   installation of package 'stringi' had non-zero exit status
>
> --
> W. Michael Conklin
> EVP Marketing & Data Sciences
> GfK
> T +1 763 417 4545 | M +1 612 567 8287
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan 
> Murdoch
> Sent: Thursday, June 22, 2017 8:23 AM
> To: Martin Maechler; David Winsemius
> Cc: r-help at r-project.org
> Subject: Re: [R] Missing dependencies in pkg installs
>
> The "configure exists but is not executable" problem is somewhat 
> common on Windows, because there's usually no such thing as an 
> executable bit there.  (Cygwin does something to fake one, but Windows 
> generally
> doesn't.)  If you create a tarball there by default you get no executable bits marked in it.
>
> For a long time, R CMD build has dealt with this issue by using the internal tar() function.  It corrects the executable bit with a warning during the build.
>
> So if people are getting that error, something has gone wrong.  A few
> guesses:
>
>   - They are on Linux but using a mount of a Windows volume that doesn't preserve the bit.
>
>   - They are using a tarball produced in some strange way on Windows, e.g. by calling tar directly instead of R CMD build.
>
>   - There's a bug in R in detecting the executable bit.
>
> Martin saw configure marked executable in the tarball from CRAN, which 
> means the second is unlikely (unless it was very recently fixed), but 
> the first is still possible.  One test is to manually expand the 
> tarball, then use both ls and R's test to see if the executable bit is 
> set and is detected by R.  For example, after downloading 
> stringi_1.1.5.tar.gz you expand it using
>
> tar zxvf stringi_1.1.5.tar.gz
>
> and use
>
> ls -l stringi/configure
>
> to see if the system thinks it is executable, and in R,
>
> file_test("-x", "stringi/configure")
>
> to see what R sees.
>
> Duncan Murdoch
>
> On 22/06/2017 3:38 AM, Martin Maechler wrote:
>>>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>>>     on Wed, 21 Jun 2017 18:04:13 -0700 writes:
>>
>>     >> On Jun 21, 2017, at 1:39 PM, Conklin, Mike (GfK) <Mike.Conklin at gfk.com> wrote:
>>     >>
>>     >> I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).
>>     >>
>>     >> R version 3.4.0 (2017-04-21)
>>     >> Platform: x86_64-redhat-linux-gnu (64-bit)
>>
>>     > I'd make sure you have reviewed this:
>>
>>     >
>> https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essenti
>> a
>> l-programs-and-libraries
>>
>> yes,  but see also below ..
>>
>>     > Best;
>>     > David.
>>
>>     >> Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)
>>     >>
>>     >> Matrix products: default
>>     >> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
>>     >>
>>     >> locale:
>>     >> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>     >> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>     >> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>     >> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>     >> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>     >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>     >>
>>     >> attached base packages:
>>     >> [1] stats     graphics  grDevices utils     datasets  methods   base
>>     >>
>>     >> other attached packages:
>>     >> [1] dplyr_0.7.0 shiny_1.0.3
>>     >>
>>     >> loaded via a namespace (and not attached):
>>     >> [1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
>>     >> [5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
>>     >> [9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
>>     >> [13] mime_0.5         rlang_0.1.1
>>     >>>
>>     >>
>>     >>
>>     >> If I try and install Hmisc for example I get the following errors:
>>     >> for the first error ERROR: 'configure' exists but is not executable --
>>     >> see the 'R Installation and dministration Manual'  I did
>>     >> not find the R Installation and Administration Manual
>>     >> helpful.
>>
>> why?  It does assume you spend some time understanding what it is 
>> talking about.
>> OTOH, it is  *THE*  official document on the topic, written and 
>> constantly updated by the  R core team.
>>
>> Anyway:   " ERROR: 'configure' exists but is not executable "
>>
>> is I think a crucial piece of information .. it's from stringi's 
>> installation failure, and the top level directory of stringi (1.1-5) 
>> in a Unix like (ls -l with user group names removed) looks like:
>>
>>   -rw-r--r--.         1451 Apr  7 15:08 DESCRIPTION
>>   -rw-r--r--.         6207 Apr  7 11:21 INSTALL
>>   -rw-r--r--.         3580 Mar 21 13:29 LICENSE
>>   -rw-r--r--.        63692 Apr  7 15:08 MD5
>>   -rw-r--r--.         6204 Oct 24  2016 NAMESPACE
>>   -rw-r--r--.        22407 Apr  7 11:44 NEWS
>>   drwxr-xr-x.         8192 Mar 28 10:26 R
>>   -rwxr-xr-x.           66 Apr  2  2015 cleanup
>>   -rw-rw-r--.        32193 Apr  8 05:46 config.log
>>   -rwxrwxr-x.        40648 Apr  8 05:46 config.status
>>   -rwxr-xr-x.       173757 Apr  7 11:43 configure
>>   -rw-r--r--.          669 Jun 23  2015 configure.win
>>   drwxr-xr-x.          512 Apr  7 11:50 inst
>>   drwxr-xr-x.         8192 Mar 28 10:26 man
>>   drwxr-xr-x.        16384 Apr  8 05:47 src
>>
>> Note the "x"s  in the 'configure' line's " -rwxr-xr-x. ":
>> This means the file is executable and a reasonable shell can just 
>> "call the file" and it will be executed, but that's the part which 
>> failed for you.
>>
>> .. this *is* peculiar as it looks like some of the standard Unix 
>> tools may be misbehaving for you .. I assume it could be some OS 
>> security "feature" playing against you..
>>
>>     >>
>>     >>
>>     >>> install.packages("Hmisc")
>>     >> Installing package into '/usr/lib64/R/library'
>>     >> (as 'lib' is unspecified)
>>     >> also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>>     >> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
>>     >> ==================================================
>>     >> downloaded 3.5 MB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
>>     >> Content type 'application/x-gzip' length 21914 bytes (21 KB)
>>     >> ==================================================
>>     >> downloaded 21 KB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
>>     >> Content type 'application/x-gzip' length 34688 bytes (33 KB)
>>     >> ==================================================
>>     >> downloaded 33 KB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
>>     >> Content type 'application/x-gzip' length 94095 bytes (91 KB)
>>     >> ==================================================
>>     >> downloaded 91 KB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
>>     >> Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
>>     >> ==================================================
>>     >> downloaded 1007 KB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
>>     >> Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
>>     >> ==================================================
>>     >> downloaded 2.1 MB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
>>     >> Content type 'application/x-gzip' length 152095 bytes (148 KB)
>>     >> ==================================================
>>     >> downloaded 148 KB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
>>     >> Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
>>     >> ==================================================
>>     >> downloaded 1.7 MB
>>     >>
>>     >> trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
>>     >> Content type 'application/x-gzip' length 702759 bytes (686 KB)
>>     >> ==================================================
>>     >> downloaded 686 KB
>>     >>
>>     >> * installing *source* package 'stringi' ...
>>     >> ** package 'stringi' successfully unpacked and MD5 sums checked
>>     >> ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
>>     >> * removing '/usr/lib64/R/library/stringi'
>>     >> ERROR: dependency 'stringi' is not available for package 'stringr'
>>     >> * removing '/usr/lib64/R/library/stringr'
>>     >> ERROR: dependency 'stringr' is not available for package 'evaluate'
>>     >> * removing '/usr/lib64/R/library/evaluate'
>>     >> ERROR: dependency 'stringr' is not available for package 'reshape2'
>>     >> * removing '/usr/lib64/R/library/reshape2'
>>     >> ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
>>     >> * removing '/usr/lib64/R/library/knitr'
>>     >> ERROR: dependency 'reshape2' is not available for package 'ggplot2'
>>     >> * removing '/usr/lib64/R/library/ggplot2'
>>     >> ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
>>     >> * removing '/usr/lib64/R/library/htmlTable'
>>     >> ERROR: dependency 'ggplot2' is not available for package 'viridis'
>>     >> * removing '/usr/lib64/R/library/viridis'
>>     >> ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
>>     >> * removing '/usr/lib64/R/library/Hmisc'
>>     >>
>>     >>
>>     >> Any help is appreciated.
>>     >> --
>>     >> W. Michael Conklin
>>     >> Executive Vice President
>>     >> Marketing & Data Sciences - North America
>>     >> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
>>     >> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
>>     >> T +1 763 417 4545 | M +1 612 567 8287
>>     >> www.gfk.com<http://www.gfk.com/>
>>     >>
>>     >>
>>     >> [[alternative HTML version deleted]]
>>     >>
>>     >> ______________________________________________
>>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>     >> and provide commented, minimal, self-contained, reproducible code.
>>
>>     > David Winsemius
>>     > Alameda, CA, USA
>>
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>     > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Thu Jun 22 22:06:12 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Jun 2017 16:06:12 -0400
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <10a0d0f4d1f9448ca6a6140146943f13@IPXW-EXPCM02.gfk.com>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
 <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
 <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
 <37b169a8-a0c8-ea11-2925-7cc09777a203@gmail.com>
 <10a0d0f4d1f9448ca6a6140146943f13@IPXW-EXPCM02.gfk.com>
Message-ID: <33a2feb8-94d0-24a4-4f58-30be332ee492@gmail.com>

On 22/06/2017 3:42 PM, Conklin, Mike (GfK) wrote:
> Not much progress..... I step through debug and it gets to the do.install() function which immediately errors with the same "configuration not executable" error.

I believe that is a locally defined function, which means you can set a 
breakpoint within it but only if R is compiled with source info, or you 
can manually call debug(do_install) after it has been created (typically 
just before it is called is a safe place to do this), and do the usual 
process.

It's still very mysterious to me why configure is losing its executable 
bit.  What I would do if I could reproduce this would be to run right up 
to the file_test("-x","configure") line, then print my working 
directory, and ctrl-Z out of R to look at the files there.  That should 
confirm that configure is not executable.

Then the hard part is figuring out why it isn't....

Duncan

>
> So, made a tempfunc that was a copy of tools:::.install_packages and edited the file_test("-x","configure") line to return a TRUE
>
> now I get a Permission Denied error (even if I run as root)
>
>> tempfunc("/home/meconk/stringi_1.1.5.tar.gz")
> * installing to library '/usr/lib64/R/library'
> * installing *source* package 'stringi' ...
> ** package 'stringi' successfully unpacked and MD5 sums checked
> sh: ./configure: Permission denied
> ERROR: configuration failed for package 'stringi'
> * removing '/usr/lib64/R/library/stringi'
> Error in do_exit(status = status) : .install_packages() exit status 1
> Error in do_exit(status = status) : .install_packages() exit status 1
>
> --
> W. Michael Conklin
> EVP Marketing & Data Sciences
> GfK
> T +1 763 417 4545 | M +1 612 567 8287
>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Thursday, June 22, 2017 11:09 AM
> To: Conklin, Mike (GfK); Martin Maechler; David Winsemius
> Cc: r-help at r-project.org
> Subject: Re: [R] Missing dependencies in pkg installs
>
> On 22/06/2017 11:15 AM, Conklin, Mike (GfK) wrote:
>> Following Duncan's instructions I find that the system and R find that configure IS executable but if trying to install via install.packages I get the same error.
>> I also tried using R CMD INSTALL from the terminal and install.packages with a local file pointing to the very same tar.gz file that shows the executable bit set. All result in the same "configure is not executable" result.
>>
>
> That's very mysterious.  This is hard to debug, because R runs a separate process to do the installs.  If you want to track this down you can debug the code as follows.
>
> 1.  Manually download the tarball, using any method (perhaps download.packages("stringi", destdir = ".", type = "source").
>
> 2.  In R, run
>
> debug(tools:::.install_packages)
> tools:::.install_packages("stringi_1.1.5.tar.gz")
>
> You can single step until you see the message, and try to diagnose why it is happening.
>
> Watch out, this function will exit R at the end.
>
> Duncan Murdoch
>
>> [meconk at dcex1102shinypr ~]$ ls -l stringi/configure -rwxr-xr-x 1
>> meconk meconk 173757 Apr  7 11:43 stringi/configure
>> [meconk at dcex1102shinypr ~]$ sudo R [sudo] password for meconk:
>>
>> R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
>> Copyright (C) 2017 The R Foundation for Statistical Computing
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>   Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and 'citation()' on how to
>> cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> [Previously saved workspace restored]
>>
>>> getwd()
>> [1] "/home/meconk"
>>> file_test("-x","stringi/configure")
>> stringi/configure
>>              TRUE
>>> install.packages("stringi")                                                   Installing package into '/usr/lib64/R/library'
>> (as 'lib' is unspecified)
>> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
>> ==================================================
>> downloaded 3.5 MB
>>
>> * installing *source* package 'stringi' ...
>> ** package 'stringi' successfully unpacked and MD5 sums checked
>> ERROR: 'configure' exists but is not executable -- see the 'R Installation and Administration Manual'
>> * removing '/usr/lib64/R/library/stringi'
>>
>> The downloaded source packages are in
>>         '/tmp/Rtmpxw9twb/downloaded_packages'
>> Updating HTML index of packages in '.Library'
>> Making 'packages.html' ... done
>> Warning message:
>> In install.packages("stringi") :
>>   installation of package 'stringi' had non-zero exit status
>>
>> --
>> W. Michael Conklin
>> EVP Marketing & Data Sciences
>> GfK
>> T +1 763 417 4545 | M +1 612 567 8287
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
>> Murdoch
>> Sent: Thursday, June 22, 2017 8:23 AM
>> To: Martin Maechler; David Winsemius
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Missing dependencies in pkg installs
>>
>> The "configure exists but is not executable" problem is somewhat
>> common on Windows, because there's usually no such thing as an
>> executable bit there.  (Cygwin does something to fake one, but Windows
>> generally
>> doesn't.)  If you create a tarball there by default you get no executable bits marked in it.
>>
>> For a long time, R CMD build has dealt with this issue by using the internal tar() function.  It corrects the executable bit with a warning during the build.
>>
>> So if people are getting that error, something has gone wrong.  A few
>> guesses:
>>
>>   - They are on Linux but using a mount of a Windows volume that doesn't preserve the bit.
>>
>>   - They are using a tarball produced in some strange way on Windows, e.g. by calling tar directly instead of R CMD build.
>>
>>   - There's a bug in R in detecting the executable bit.
>>
>> Martin saw configure marked executable in the tarball from CRAN, which
>> means the second is unlikely (unless it was very recently fixed), but
>> the first is still possible.  One test is to manually expand the
>> tarball, then use both ls and R's test to see if the executable bit is
>> set and is detected by R.  For example, after downloading
>> stringi_1.1.5.tar.gz you expand it using
>>
>> tar zxvf stringi_1.1.5.tar.gz
>>
>> and use
>>
>> ls -l stringi/configure
>>
>> to see if the system thinks it is executable, and in R,
>>
>> file_test("-x", "stringi/configure")
>>
>> to see what R sees.
>>
>> Duncan Murdoch
>>
>> On 22/06/2017 3:38 AM, Martin Maechler wrote:
>>>>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>>>>     on Wed, 21 Jun 2017 18:04:13 -0700 writes:
>>>
>>>     >> On Jun 21, 2017, at 1:39 PM, Conklin, Mike (GfK) <Mike.Conklin at gfk.com> wrote:
>>>     >>
>>>     >> I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).
>>>     >>
>>>     >> R version 3.4.0 (2017-04-21)
>>>     >> Platform: x86_64-redhat-linux-gnu (64-bit)
>>>
>>>     > I'd make sure you have reviewed this:
>>>
>>>     >
>>> https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essenti
>>> a
>>> l-programs-and-libraries
>>>
>>> yes,  but see also below ..
>>>
>>>     > Best;
>>>     > David.
>>>
>>>     >> Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)
>>>     >>
>>>     >> Matrix products: default
>>>     >> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
>>>     >>
>>>     >> locale:
>>>     >> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>     >> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>     >> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>     >> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>     >> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>     >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>     >>
>>>     >> attached base packages:
>>>     >> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>     >>
>>>     >> other attached packages:
>>>     >> [1] dplyr_0.7.0 shiny_1.0.3
>>>     >>
>>>     >> loaded via a namespace (and not attached):
>>>     >> [1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
>>>     >> [5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
>>>     >> [9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
>>>     >> [13] mime_0.5         rlang_0.1.1
>>>     >>>
>>>     >>
>>>     >>
>>>     >> If I try and install Hmisc for example I get the following errors:
>>>     >> for the first error ERROR: 'configure' exists but is not executable --
>>>     >> see the 'R Installation and dministration Manual'  I did
>>>     >> not find the R Installation and Administration Manual
>>>     >> helpful.
>>>
>>> why?  It does assume you spend some time understanding what it is
>>> talking about.
>>> OTOH, it is  *THE*  official document on the topic, written and
>>> constantly updated by the  R core team.
>>>
>>> Anyway:   " ERROR: 'configure' exists but is not executable "
>>>
>>> is I think a crucial piece of information .. it's from stringi's
>>> installation failure, and the top level directory of stringi (1.1-5)
>>> in a Unix like (ls -l with user group names removed) looks like:
>>>
>>>   -rw-r--r--.         1451 Apr  7 15:08 DESCRIPTION
>>>   -rw-r--r--.         6207 Apr  7 11:21 INSTALL
>>>   -rw-r--r--.         3580 Mar 21 13:29 LICENSE
>>>   -rw-r--r--.        63692 Apr  7 15:08 MD5
>>>   -rw-r--r--.         6204 Oct 24  2016 NAMESPACE
>>>   -rw-r--r--.        22407 Apr  7 11:44 NEWS
>>>   drwxr-xr-x.         8192 Mar 28 10:26 R
>>>   -rwxr-xr-x.           66 Apr  2  2015 cleanup
>>>   -rw-rw-r--.        32193 Apr  8 05:46 config.log
>>>   -rwxrwxr-x.        40648 Apr  8 05:46 config.status
>>>   -rwxr-xr-x.       173757 Apr  7 11:43 configure
>>>   -rw-r--r--.          669 Jun 23  2015 configure.win
>>>   drwxr-xr-x.          512 Apr  7 11:50 inst
>>>   drwxr-xr-x.         8192 Mar 28 10:26 man
>>>   drwxr-xr-x.        16384 Apr  8 05:47 src
>>>
>>> Note the "x"s  in the 'configure' line's " -rwxr-xr-x. ":
>>> This means the file is executable and a reasonable shell can just
>>> "call the file" and it will be executed, but that's the part which
>>> failed for you.
>>>
>>> .. this *is* peculiar as it looks like some of the standard Unix
>>> tools may be misbehaving for you .. I assume it could be some OS
>>> security "feature" playing against you..
>>>
>>>     >>
>>>     >>
>>>     >>> install.packages("Hmisc")
>>>     >> Installing package into '/usr/lib64/R/library'
>>>     >> (as 'lib' is unspecified)
>>>     >> also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>>>     >> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
>>>     >> ==================================================
>>>     >> downloaded 3.5 MB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
>>>     >> Content type 'application/x-gzip' length 21914 bytes (21 KB)
>>>     >> ==================================================
>>>     >> downloaded 21 KB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
>>>     >> Content type 'application/x-gzip' length 34688 bytes (33 KB)
>>>     >> ==================================================
>>>     >> downloaded 33 KB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
>>>     >> Content type 'application/x-gzip' length 94095 bytes (91 KB)
>>>     >> ==================================================
>>>     >> downloaded 91 KB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
>>>     >> Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
>>>     >> ==================================================
>>>     >> downloaded 1007 KB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
>>>     >> Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
>>>     >> ==================================================
>>>     >> downloaded 2.1 MB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
>>>     >> Content type 'application/x-gzip' length 152095 bytes (148 KB)
>>>     >> ==================================================
>>>     >> downloaded 148 KB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
>>>     >> Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
>>>     >> ==================================================
>>>     >> downloaded 1.7 MB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
>>>     >> Content type 'application/x-gzip' length 702759 bytes (686 KB)
>>>     >> ==================================================
>>>     >> downloaded 686 KB
>>>     >>
>>>     >> * installing *source* package 'stringi' ...
>>>     >> ** package 'stringi' successfully unpacked and MD5 sums checked
>>>     >> ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
>>>     >> * removing '/usr/lib64/R/library/stringi'
>>>     >> ERROR: dependency 'stringi' is not available for package 'stringr'
>>>     >> * removing '/usr/lib64/R/library/stringr'
>>>     >> ERROR: dependency 'stringr' is not available for package 'evaluate'
>>>     >> * removing '/usr/lib64/R/library/evaluate'
>>>     >> ERROR: dependency 'stringr' is not available for package 'reshape2'
>>>     >> * removing '/usr/lib64/R/library/reshape2'
>>>     >> ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
>>>     >> * removing '/usr/lib64/R/library/knitr'
>>>     >> ERROR: dependency 'reshape2' is not available for package 'ggplot2'
>>>     >> * removing '/usr/lib64/R/library/ggplot2'
>>>     >> ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
>>>     >> * removing '/usr/lib64/R/library/htmlTable'
>>>     >> ERROR: dependency 'ggplot2' is not available for package 'viridis'
>>>     >> * removing '/usr/lib64/R/library/viridis'
>>>     >> ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
>>>     >> * removing '/usr/lib64/R/library/Hmisc'
>>>     >>
>>>     >>
>>>     >> Any help is appreciated.
>>>     >> --
>>>     >> W. Michael Conklin
>>>     >> Executive Vice President
>>>     >> Marketing & Data Sciences - North America
>>>     >> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
>>>     >> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
>>>     >> T +1 763 417 4545 | M +1 612 567 8287
>>>     >> www.gfk.com<http://www.gfk.com/>
>>>     >>
>>>     >>
>>>     >> [[alternative HTML version deleted]]
>>>     >>
>>>     >> ______________________________________________
>>>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>>>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>     >> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>     > David Winsemius
>>>     > Alameda, CA, USA
>>>
>>>     > ______________________________________________
>>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>     > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From Mike.Conklin at gfk.com  Thu Jun 22 23:02:51 2017
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Thu, 22 Jun 2017 21:02:51 +0000
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <33a2feb8-94d0-24a4-4f58-30be332ee492@gmail.com>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
 <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
 <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
 <37b169a8-a0c8-ea11-2925-7cc09777a203@gmail.com>
 <10a0d0f4d1f9448ca6a6140146943f13@IPXW-EXPCM02.gfk.com>
 <33a2feb8-94d0-24a4-4f58-30be332ee492@gmail.com>
Message-ID: <6105f59fa7ab44a9bf882a2c7fbc2e2f@IPXW-EXPCM02.gfk.com>

I am using debug on the .install_packages function...stepping through. Once the temporary folder is created and the tar file expanded I run file_test and get a FALSE back indicating that the configure file is not executable.

[1] "/tmp/RtmpMM6iC1/R.INSTALLc5ca415e4310/stringi"
Browse[2]> dir(new)
 [1] "DESCRIPTION"   "INSTALL"       "LICENSE"       "MD5"
 [5] "NAMESPACE"     "NEWS"          "R"             "cleanup"
 [9] "configure"     "configure.win" "inst"          "man"
[13] "src"
Browse[2]> test_file("-x",paste0(new,"/configure")
+ )
Error in test_file("-x", paste0(new, "/configure")) :
  could not find function "test_file"
Browse[2]> file_test("-x",paste0(new,"/configure"))
/tmp/RtmpMM6iC1/R.INSTALLc5ca415e4310/stringi/configure
                                                  FALSE


However, at the same time, in a separate session I have the system look at the very same file and clearly the execution bit is set.


[root at dcex1102shinypr ~]# ls -l /tmp/RtmpMM6iC1/R.INSTALLc5ca415e4310/stringi
total 312
-rwxr-xr-x 1 root root     66 Apr  2  2015 cleanup
-rwxr-xr-x 1 root root 173757 Apr  7 11:43 configure
-rw-r--r-- 1 root root    669 Jun 23  2015 configure.win
-rw-r--r-- 1 root root   1451 Apr  7 15:08 DESCRIPTION
drwxr-xr-x 2 root root     35 Jun 22 22:26 inst
-rw-r--r-- 1 root root   6207 Apr  7 11:21 INSTALL
-rw-r--r-- 1 root root   3580 Mar 21 13:29 LICENSE
drwxr-xr-x 2 root root   4096 Jun 22 22:26 man
-rw-r--r-- 1 root root  63692 Apr  7 15:08 MD5
-rw-r--r-- 1 root root   6204 Oct 24  2016 NAMESPACE
-rw-r--r-- 1 root root  22407 Apr  7 11:44 NEWS
drwxr-xr-x 2 root root   4096 Jun 22 22:26 R
drwxr-xr-x 3 root root   8192 Jun 22 22:26 src
[root at dcex1102shinypr ~]#


If I CTRL-Z out of R in the first session I confirm the same result - the system shows the file as executable

--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK 
T +1 763 417 4545 | M +1 612 567 8287 


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Thursday, June 22, 2017 3:06 PM
To: Conklin, Mike (GfK); Martin Maechler; David Winsemius
Cc: r-help at r-project.org
Subject: Re: [R] Missing dependencies in pkg installs

On 22/06/2017 3:42 PM, Conklin, Mike (GfK) wrote:
> Not much progress..... I step through debug and it gets to the do.install() function which immediately errors with the same "configuration not executable" error.

I believe that is a locally defined function, which means you can set a breakpoint within it but only if R is compiled with source info, or you can manually call debug(do_install) after it has been created (typically just before it is called is a safe place to do this), and do the usual process.

It's still very mysterious to me why configure is losing its executable bit.  What I would do if I could reproduce this would be to run right up to the file_test("-x","configure") line, then print my working directory, and ctrl-Z out of R to look at the files there.  That should confirm that configure is not executable.

Then the hard part is figuring out why it isn't....

Duncan

>
> So, made a tempfunc that was a copy of tools:::.install_packages and 
> edited the file_test("-x","configure") line to return a TRUE
>
> now I get a Permission Denied error (even if I run as root)
>
>> tempfunc("/home/meconk/stringi_1.1.5.tar.gz")
> * installing to library '/usr/lib64/R/library'
> * installing *source* package 'stringi' ...
> ** package 'stringi' successfully unpacked and MD5 sums checked
> sh: ./configure: Permission denied
> ERROR: configuration failed for package 'stringi'
> * removing '/usr/lib64/R/library/stringi'
> Error in do_exit(status = status) : .install_packages() exit status 1 
> Error in do_exit(status = status) : .install_packages() exit status 1
>
> --
> W. Michael Conklin
> EVP Marketing & Data Sciences
> GfK
> T +1 763 417 4545 | M +1 612 567 8287
>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Thursday, June 22, 2017 11:09 AM
> To: Conklin, Mike (GfK); Martin Maechler; David Winsemius
> Cc: r-help at r-project.org
> Subject: Re: [R] Missing dependencies in pkg installs
>
> On 22/06/2017 11:15 AM, Conklin, Mike (GfK) wrote:
>> Following Duncan's instructions I find that the system and R find that configure IS executable but if trying to install via install.packages I get the same error.
>> I also tried using R CMD INSTALL from the terminal and install.packages with a local file pointing to the very same tar.gz file that shows the executable bit set. All result in the same "configure is not executable" result.
>>
>
> That's very mysterious.  This is hard to debug, because R runs a separate process to do the installs.  If you want to track this down you can debug the code as follows.
>
> 1.  Manually download the tarball, using any method (perhaps download.packages("stringi", destdir = ".", type = "source").
>
> 2.  In R, run
>
> debug(tools:::.install_packages)
> tools:::.install_packages("stringi_1.1.5.tar.gz")
>
> You can single step until you see the message, and try to diagnose why it is happening.
>
> Watch out, this function will exit R at the end.
>
> Duncan Murdoch
>
>> [meconk at dcex1102shinypr ~]$ ls -l stringi/configure -rwxr-xr-x 1 
>> meconk meconk 173757 Apr  7 11:43 stringi/configure 
>> [meconk at dcex1102shinypr ~]$ sudo R [sudo] password for meconk:
>>
>> R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
>> Copyright (C) 2017 The R Foundation for Statistical Computing
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>   Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and 'citation()' on how to 
>> cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or 
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> [Previously saved workspace restored]
>>
>>> getwd()
>> [1] "/home/meconk"
>>> file_test("-x","stringi/configure")
>> stringi/configure
>>              TRUE
>>> install.packages("stringi")                                                   Installing package into '/usr/lib64/R/library'
>> (as 'lib' is unspecified)
>> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB) 
>> ==================================================
>> downloaded 3.5 MB
>>
>> * installing *source* package 'stringi' ...
>> ** package 'stringi' successfully unpacked and MD5 sums checked
>> ERROR: 'configure' exists but is not executable -- see the 'R Installation and Administration Manual'
>> * removing '/usr/lib64/R/library/stringi'
>>
>> The downloaded source packages are in
>>         '/tmp/Rtmpxw9twb/downloaded_packages'
>> Updating HTML index of packages in '.Library'
>> Making 'packages.html' ... done
>> Warning message:
>> In install.packages("stringi") :
>>   installation of package 'stringi' had non-zero exit status
>>
>> --
>> W. Michael Conklin
>> EVP Marketing & Data Sciences
>> GfK
>> T +1 763 417 4545 | M +1 612 567 8287
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
>> Duncan Murdoch
>> Sent: Thursday, June 22, 2017 8:23 AM
>> To: Martin Maechler; David Winsemius
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Missing dependencies in pkg installs
>>
>> The "configure exists but is not executable" problem is somewhat 
>> common on Windows, because there's usually no such thing as an 
>> executable bit there.  (Cygwin does something to fake one, but 
>> Windows generally
>> doesn't.)  If you create a tarball there by default you get no executable bits marked in it.
>>
>> For a long time, R CMD build has dealt with this issue by using the internal tar() function.  It corrects the executable bit with a warning during the build.
>>
>> So if people are getting that error, something has gone wrong.  A few
>> guesses:
>>
>>   - They are on Linux but using a mount of a Windows volume that doesn't preserve the bit.
>>
>>   - They are using a tarball produced in some strange way on Windows, e.g. by calling tar directly instead of R CMD build.
>>
>>   - There's a bug in R in detecting the executable bit.
>>
>> Martin saw configure marked executable in the tarball from CRAN, 
>> which means the second is unlikely (unless it was very recently 
>> fixed), but the first is still possible.  One test is to manually 
>> expand the tarball, then use both ls and R's test to see if the 
>> executable bit is set and is detected by R.  For example, after 
>> downloading stringi_1.1.5.tar.gz you expand it using
>>
>> tar zxvf stringi_1.1.5.tar.gz
>>
>> and use
>>
>> ls -l stringi/configure
>>
>> to see if the system thinks it is executable, and in R,
>>
>> file_test("-x", "stringi/configure")
>>
>> to see what R sees.
>>
>> Duncan Murdoch
>>
>> On 22/06/2017 3:38 AM, Martin Maechler wrote:
>>>>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>>>>     on Wed, 21 Jun 2017 18:04:13 -0700 writes:
>>>
>>>     >> On Jun 21, 2017, at 1:39 PM, Conklin, Mike (GfK) <Mike.Conklin at gfk.com> wrote:
>>>     >>
>>>     >> I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).
>>>     >>
>>>     >> R version 3.4.0 (2017-04-21)
>>>     >> Platform: x86_64-redhat-linux-gnu (64-bit)
>>>
>>>     > I'd make sure you have reviewed this:
>>>
>>>     >
>>> https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essent
>>> i
>>> a
>>> l-programs-and-libraries
>>>
>>> yes,  but see also below ..
>>>
>>>     > Best;
>>>     > David.
>>>
>>>     >> Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)
>>>     >>
>>>     >> Matrix products: default
>>>     >> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
>>>     >>
>>>     >> locale:
>>>     >> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>     >> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>     >> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>     >> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>     >> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>     >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>     >>
>>>     >> attached base packages:
>>>     >> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>     >>
>>>     >> other attached packages:
>>>     >> [1] dplyr_0.7.0 shiny_1.0.3
>>>     >>
>>>     >> loaded via a namespace (and not attached):
>>>     >> [1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
>>>     >> [5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
>>>     >> [9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
>>>     >> [13] mime_0.5         rlang_0.1.1
>>>     >>>
>>>     >>
>>>     >>
>>>     >> If I try and install Hmisc for example I get the following errors:
>>>     >> for the first error ERROR: 'configure' exists but is not executable --
>>>     >> see the 'R Installation and dministration Manual'  I did
>>>     >> not find the R Installation and Administration Manual
>>>     >> helpful.
>>>
>>> why?  It does assume you spend some time understanding what it is 
>>> talking about.
>>> OTOH, it is  *THE*  official document on the topic, written and 
>>> constantly updated by the  R core team.
>>>
>>> Anyway:   " ERROR: 'configure' exists but is not executable "
>>>
>>> is I think a crucial piece of information .. it's from stringi's 
>>> installation failure, and the top level directory of stringi (1.1-5) 
>>> in a Unix like (ls -l with user group names removed) looks like:
>>>
>>>   -rw-r--r--.         1451 Apr  7 15:08 DESCRIPTION
>>>   -rw-r--r--.         6207 Apr  7 11:21 INSTALL
>>>   -rw-r--r--.         3580 Mar 21 13:29 LICENSE
>>>   -rw-r--r--.        63692 Apr  7 15:08 MD5
>>>   -rw-r--r--.         6204 Oct 24  2016 NAMESPACE
>>>   -rw-r--r--.        22407 Apr  7 11:44 NEWS
>>>   drwxr-xr-x.         8192 Mar 28 10:26 R
>>>   -rwxr-xr-x.           66 Apr  2  2015 cleanup
>>>   -rw-rw-r--.        32193 Apr  8 05:46 config.log
>>>   -rwxrwxr-x.        40648 Apr  8 05:46 config.status
>>>   -rwxr-xr-x.       173757 Apr  7 11:43 configure
>>>   -rw-r--r--.          669 Jun 23  2015 configure.win
>>>   drwxr-xr-x.          512 Apr  7 11:50 inst
>>>   drwxr-xr-x.         8192 Mar 28 10:26 man
>>>   drwxr-xr-x.        16384 Apr  8 05:47 src
>>>
>>> Note the "x"s  in the 'configure' line's " -rwxr-xr-x. ":
>>> This means the file is executable and a reasonable shell can just 
>>> "call the file" and it will be executed, but that's the part which 
>>> failed for you.
>>>
>>> .. this *is* peculiar as it looks like some of the standard Unix 
>>> tools may be misbehaving for you .. I assume it could be some OS 
>>> security "feature" playing against you..
>>>
>>>     >>
>>>     >>
>>>     >>> install.packages("Hmisc")
>>>     >> Installing package into '/usr/lib64/R/library'
>>>     >> (as 'lib' is unspecified)
>>>     >> also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>>>     >> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
>>>     >> ==================================================
>>>     >> downloaded 3.5 MB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
>>>     >> Content type 'application/x-gzip' length 21914 bytes (21 KB)
>>>     >> ==================================================
>>>     >> downloaded 21 KB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
>>>     >> Content type 'application/x-gzip' length 34688 bytes (33 KB)
>>>     >> ==================================================
>>>     >> downloaded 33 KB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
>>>     >> Content type 'application/x-gzip' length 94095 bytes (91 KB)
>>>     >> ==================================================
>>>     >> downloaded 91 KB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
>>>     >> Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
>>>     >> ==================================================
>>>     >> downloaded 1007 KB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
>>>     >> Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
>>>     >> ==================================================
>>>     >> downloaded 2.1 MB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
>>>     >> Content type 'application/x-gzip' length 152095 bytes (148 KB)
>>>     >> ==================================================
>>>     >> downloaded 148 KB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
>>>     >> Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
>>>     >> ==================================================
>>>     >> downloaded 1.7 MB
>>>     >>
>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
>>>     >> Content type 'application/x-gzip' length 702759 bytes (686 KB)
>>>     >> ==================================================
>>>     >> downloaded 686 KB
>>>     >>
>>>     >> * installing *source* package 'stringi' ...
>>>     >> ** package 'stringi' successfully unpacked and MD5 sums checked
>>>     >> ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
>>>     >> * removing '/usr/lib64/R/library/stringi'
>>>     >> ERROR: dependency 'stringi' is not available for package 'stringr'
>>>     >> * removing '/usr/lib64/R/library/stringr'
>>>     >> ERROR: dependency 'stringr' is not available for package 'evaluate'
>>>     >> * removing '/usr/lib64/R/library/evaluate'
>>>     >> ERROR: dependency 'stringr' is not available for package 'reshape2'
>>>     >> * removing '/usr/lib64/R/library/reshape2'
>>>     >> ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
>>>     >> * removing '/usr/lib64/R/library/knitr'
>>>     >> ERROR: dependency 'reshape2' is not available for package 'ggplot2'
>>>     >> * removing '/usr/lib64/R/library/ggplot2'
>>>     >> ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
>>>     >> * removing '/usr/lib64/R/library/htmlTable'
>>>     >> ERROR: dependency 'ggplot2' is not available for package 'viridis'
>>>     >> * removing '/usr/lib64/R/library/viridis'
>>>     >> ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
>>>     >> * removing '/usr/lib64/R/library/Hmisc'
>>>     >>
>>>     >>
>>>     >> Any help is appreciated.
>>>     >> --
>>>     >> W. Michael Conklin
>>>     >> Executive Vice President
>>>     >> Marketing & Data Sciences - North America
>>>     >> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
>>>     >> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
>>>     >> T +1 763 417 4545 | M +1 612 567 8287
>>>     >> www.gfk.com<http://www.gfk.com/>
>>>     >>
>>>     >>
>>>     >> [[alternative HTML version deleted]]
>>>     >>
>>>     >> ______________________________________________
>>>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>>>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>     >> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>     > David Winsemius
>>>     > Alameda, CA, USA
>>>
>>>     > ______________________________________________
>>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>     > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From murdoch.duncan at gmail.com  Fri Jun 23 00:51:22 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Jun 2017 18:51:22 -0400
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <6105f59fa7ab44a9bf882a2c7fbc2e2f@IPXW-EXPCM02.gfk.com>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
 <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
 <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
 <37b169a8-a0c8-ea11-2925-7cc09777a203@gmail.com>
 <10a0d0f4d1f9448ca6a6140146943f13@IPXW-EXPCM02.gfk.com>
 <33a2feb8-94d0-24a4-4f58-30be332ee492@gmail.com>
 <6105f59fa7ab44a9bf882a2c7fbc2e2f@IPXW-EXPCM02.gfk.com>
Message-ID: <ef8c365a-2960-88f7-9504-9cfd84150e66@gmail.com>

On 22/06/2017 5:02 PM, Conklin, Mike (GfK) wrote:
> I am using debug on the .install_packages function...stepping through. Once the temporary folder is created and the tar file expanded I run file_test and get a FALSE back indicating that the configure file is not executable.

I don't know what is causing this bug.  Perhaps a Linux user can 
reproduce it and fix it.

Here's what I see:

file_test("-x") calls file.access(filename, 1L).  That in turn calls the 
C library function access(..., X_OK).  The ... is the name of the file, 
translated into the local encoding and expanded.  As far as I can see, 
that means ... should be exactly the string below.
>
> [1] "/tmp/RtmpMM6iC1/R.INSTALLc5ca415e4310/stringi"

The only thing I can think of is that your system is protecting you from 
executing a newly created file until some sort of virus or other check 
is done.  (This is common on Windows, but I've never heard of it before 
on Linux.)

Hopefully someone else can help...

Duncan Murdoch

> Browse[2]> dir(new)
>  [1] "DESCRIPTION"   "INSTALL"       "LICENSE"       "MD5"
>  [5] "NAMESPACE"     "NEWS"          "R"             "cleanup"
>  [9] "configure"     "configure.win" "inst"          "man"
> [13] "src"
> Browse[2]> test_file("-x",paste0(new,"/configure")
> + )
> Error in test_file("-x", paste0(new, "/configure")) :
>   could not find function "test_file"
> Browse[2]> file_test("-x",paste0(new,"/configure"))
> /tmp/RtmpMM6iC1/R.INSTALLc5ca415e4310/stringi/configure
>                                                   FALSE
>
>
> However, at the same time, in a separate session I have the system look at the very same file and clearly the execution bit is set.
>
>
> [root at dcex1102shinypr ~]# ls -l /tmp/RtmpMM6iC1/R.INSTALLc5ca415e4310/stringi
> total 312
> -rwxr-xr-x 1 root root     66 Apr  2  2015 cleanup
> -rwxr-xr-x 1 root root 173757 Apr  7 11:43 configure
> -rw-r--r-- 1 root root    669 Jun 23  2015 configure.win
> -rw-r--r-- 1 root root   1451 Apr  7 15:08 DESCRIPTION
> drwxr-xr-x 2 root root     35 Jun 22 22:26 inst
> -rw-r--r-- 1 root root   6207 Apr  7 11:21 INSTALL
> -rw-r--r-- 1 root root   3580 Mar 21 13:29 LICENSE
> drwxr-xr-x 2 root root   4096 Jun 22 22:26 man
> -rw-r--r-- 1 root root  63692 Apr  7 15:08 MD5
> -rw-r--r-- 1 root root   6204 Oct 24  2016 NAMESPACE
> -rw-r--r-- 1 root root  22407 Apr  7 11:44 NEWS
> drwxr-xr-x 2 root root   4096 Jun 22 22:26 R
> drwxr-xr-x 3 root root   8192 Jun 22 22:26 src
> [root at dcex1102shinypr ~]#
>
>
> If I CTRL-Z out of R in the first session I confirm the same result - the system shows the file as executable
>
> --
> W. Michael Conklin
> EVP Marketing & Data Sciences
> GfK
> T +1 763 417 4545 | M +1 612 567 8287
>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Thursday, June 22, 2017 3:06 PM
> To: Conklin, Mike (GfK); Martin Maechler; David Winsemius
> Cc: r-help at r-project.org
> Subject: Re: [R] Missing dependencies in pkg installs
>
> On 22/06/2017 3:42 PM, Conklin, Mike (GfK) wrote:
>> Not much progress..... I step through debug and it gets to the do.install() function which immediately errors with the same "configuration not executable" error.
>
> I believe that is a locally defined function, which means you can set a breakpoint within it but only if R is compiled with source info, or you can manually call debug(do_install) after it has been created (typically just before it is called is a safe place to do this), and do the usual process.
>
> It's still very mysterious to me why configure is losing its executable bit.  What I would do if I could reproduce this would be to run right up to the file_test("-x","configure") line, then print my working directory, and ctrl-Z out of R to look at the files there.  That should confirm that configure is not executable.
>
> Then the hard part is figuring out why it isn't....
>
> Duncan
>
>>
>> So, made a tempfunc that was a copy of tools:::.install_packages and
>> edited the file_test("-x","configure") line to return a TRUE
>>
>> now I get a Permission Denied error (even if I run as root)
>>
>>> tempfunc("/home/meconk/stringi_1.1.5.tar.gz")
>> * installing to library '/usr/lib64/R/library'
>> * installing *source* package 'stringi' ...
>> ** package 'stringi' successfully unpacked and MD5 sums checked
>> sh: ./configure: Permission denied
>> ERROR: configuration failed for package 'stringi'
>> * removing '/usr/lib64/R/library/stringi'
>> Error in do_exit(status = status) : .install_packages() exit status 1
>> Error in do_exit(status = status) : .install_packages() exit status 1
>>
>> --
>> W. Michael Conklin
>> EVP Marketing & Data Sciences
>> GfK
>> T +1 763 417 4545 | M +1 612 567 8287
>>
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Thursday, June 22, 2017 11:09 AM
>> To: Conklin, Mike (GfK); Martin Maechler; David Winsemius
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Missing dependencies in pkg installs
>>
>> On 22/06/2017 11:15 AM, Conklin, Mike (GfK) wrote:
>>> Following Duncan's instructions I find that the system and R find that configure IS executable but if trying to install via install.packages I get the same error.
>>> I also tried using R CMD INSTALL from the terminal and install.packages with a local file pointing to the very same tar.gz file that shows the executable bit set. All result in the same "configure is not executable" result.
>>>
>>
>> That's very mysterious.  This is hard to debug, because R runs a separate process to do the installs.  If you want to track this down you can debug the code as follows.
>>
>> 1.  Manually download the tarball, using any method (perhaps download.packages("stringi", destdir = ".", type = "source").
>>
>> 2.  In R, run
>>
>> debug(tools:::.install_packages)
>> tools:::.install_packages("stringi_1.1.5.tar.gz")
>>
>> You can single step until you see the message, and try to diagnose why it is happening.
>>
>> Watch out, this function will exit R at the end.
>>
>> Duncan Murdoch
>>
>>> [meconk at dcex1102shinypr ~]$ ls -l stringi/configure -rwxr-xr-x 1
>>> meconk meconk 173757 Apr  7 11:43 stringi/configure
>>> [meconk at dcex1102shinypr ~]$ sudo R [sudo] password for meconk:
>>>
>>> R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
>>> Copyright (C) 2017 The R Foundation for Statistical Computing
>>> Platform: x86_64-redhat-linux-gnu (64-bit)
>>>
>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>> You are welcome to redistribute it under certain conditions.
>>> Type 'license()' or 'licence()' for distribution details.
>>>
>>>   Natural language support but running in an English locale
>>>
>>> R is a collaborative project with many contributors.
>>> Type 'contributors()' for more information and 'citation()' on how to
>>> cite R or R packages in publications.
>>>
>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>> 'help.start()' for an HTML browser interface to help.
>>> Type 'q()' to quit R.
>>>
>>> [Previously saved workspace restored]
>>>
>>>> getwd()
>>> [1] "/home/meconk"
>>>> file_test("-x","stringi/configure")
>>> stringi/configure
>>>              TRUE
>>>> install.packages("stringi")                                                   Installing package into '/usr/lib64/R/library'
>>> (as 'lib' is unspecified)
>>> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>>> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
>>> ==================================================
>>> downloaded 3.5 MB
>>>
>>> * installing *source* package 'stringi' ...
>>> ** package 'stringi' successfully unpacked and MD5 sums checked
>>> ERROR: 'configure' exists but is not executable -- see the 'R Installation and Administration Manual'
>>> * removing '/usr/lib64/R/library/stringi'
>>>
>>> The downloaded source packages are in
>>>         '/tmp/Rtmpxw9twb/downloaded_packages'
>>> Updating HTML index of packages in '.Library'
>>> Making 'packages.html' ... done
>>> Warning message:
>>> In install.packages("stringi") :
>>>   installation of package 'stringi' had non-zero exit status
>>>
>>> --
>>> W. Michael Conklin
>>> EVP Marketing & Data Sciences
>>> GfK
>>> T +1 763 417 4545 | M +1 612 567 8287
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> Duncan Murdoch
>>> Sent: Thursday, June 22, 2017 8:23 AM
>>> To: Martin Maechler; David Winsemius
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Missing dependencies in pkg installs
>>>
>>> The "configure exists but is not executable" problem is somewhat
>>> common on Windows, because there's usually no such thing as an
>>> executable bit there.  (Cygwin does something to fake one, but
>>> Windows generally
>>> doesn't.)  If you create a tarball there by default you get no executable bits marked in it.
>>>
>>> For a long time, R CMD build has dealt with this issue by using the internal tar() function.  It corrects the executable bit with a warning during the build.
>>>
>>> So if people are getting that error, something has gone wrong.  A few
>>> guesses:
>>>
>>>   - They are on Linux but using a mount of a Windows volume that doesn't preserve the bit.
>>>
>>>   - They are using a tarball produced in some strange way on Windows, e.g. by calling tar directly instead of R CMD build.
>>>
>>>   - There's a bug in R in detecting the executable bit.
>>>
>>> Martin saw configure marked executable in the tarball from CRAN,
>>> which means the second is unlikely (unless it was very recently
>>> fixed), but the first is still possible.  One test is to manually
>>> expand the tarball, then use both ls and R's test to see if the
>>> executable bit is set and is detected by R.  For example, after
>>> downloading stringi_1.1.5.tar.gz you expand it using
>>>
>>> tar zxvf stringi_1.1.5.tar.gz
>>>
>>> and use
>>>
>>> ls -l stringi/configure
>>>
>>> to see if the system thinks it is executable, and in R,
>>>
>>> file_test("-x", "stringi/configure")
>>>
>>> to see what R sees.
>>>
>>> Duncan Murdoch
>>>
>>> On 22/06/2017 3:38 AM, Martin Maechler wrote:
>>>>>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>>>>>     on Wed, 21 Jun 2017 18:04:13 -0700 writes:
>>>>
>>>>     >> On Jun 21, 2017, at 1:39 PM, Conklin, Mike (GfK) <Mike.Conklin at gfk.com> wrote:
>>>>     >>
>>>>     >> I have a Ubuntu server with an R installation that has 384 packages installed.  We are trying to replicate the system on a Red Hat Enterprise server. I downloaded the list of packages from the Ubuntu machine and read it into an R session on the new machine. Then I ran install.packages(listofpackages).  Now I have 352 packages on the new machine but several very common packages (like much of the tidyverse, ggplot2, Hmisc) failed to install because of missing dependencies (most of which are the other packages that failed to install).
>>>>     >>
>>>>     >> R version 3.4.0 (2017-04-21)
>>>>     >> Platform: x86_64-redhat-linux-gnu (64-bit)
>>>>
>>>>     > I'd make sure you have reviewed this:
>>>>
>>>>     >
>>>> https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essent
>>>> i
>>>> a
>>>> l-programs-and-libraries
>>>>
>>>> yes,  but see also below ..
>>>>
>>>>     > Best;
>>>>     > David.
>>>>
>>>>     >> Running under: Red Hat Enterprise Linux Server 7.2 (Maipo)
>>>>     >>
>>>>     >> Matrix products: default
>>>>     >> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
>>>>     >>
>>>>     >> locale:
>>>>     >> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>>     >> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>>     >> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>>     >> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>>     >> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>>     >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>     >>
>>>>     >> attached base packages:
>>>>     >> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>     >>
>>>>     >> other attached packages:
>>>>     >> [1] dplyr_0.7.0 shiny_1.0.3
>>>>     >>
>>>>     >> loaded via a namespace (and not attached):
>>>>     >> [1] compiler_3.4.0   magrittr_1.5     assertthat_0.2.0 R6_2.2.2
>>>>     >> [5] htmltools_0.3.6  tools_3.4.0      glue_1.1.1       tibble_1.3.3
>>>>     >> [9] Rcpp_0.12.11     digest_0.6.12    xtable_1.8-2     httpuv_1.3.3
>>>>     >> [13] mime_0.5         rlang_0.1.1
>>>>     >>>
>>>>     >>
>>>>     >>
>>>>     >> If I try and install Hmisc for example I get the following errors:
>>>>     >> for the first error ERROR: 'configure' exists but is not executable --
>>>>     >> see the 'R Installation and dministration Manual'  I did
>>>>     >> not find the R Installation and Administration Manual
>>>>     >> helpful.
>>>>
>>>> why?  It does assume you spend some time understanding what it is
>>>> talking about.
>>>> OTOH, it is  *THE*  official document on the topic, written and
>>>> constantly updated by the  R core team.
>>>>
>>>> Anyway:   " ERROR: 'configure' exists but is not executable "
>>>>
>>>> is I think a crucial piece of information .. it's from stringi's
>>>> installation failure, and the top level directory of stringi (1.1-5)
>>>> in a Unix like (ls -l with user group names removed) looks like:
>>>>
>>>>   -rw-r--r--.         1451 Apr  7 15:08 DESCRIPTION
>>>>   -rw-r--r--.         6207 Apr  7 11:21 INSTALL
>>>>   -rw-r--r--.         3580 Mar 21 13:29 LICENSE
>>>>   -rw-r--r--.        63692 Apr  7 15:08 MD5
>>>>   -rw-r--r--.         6204 Oct 24  2016 NAMESPACE
>>>>   -rw-r--r--.        22407 Apr  7 11:44 NEWS
>>>>   drwxr-xr-x.         8192 Mar 28 10:26 R
>>>>   -rwxr-xr-x.           66 Apr  2  2015 cleanup
>>>>   -rw-rw-r--.        32193 Apr  8 05:46 config.log
>>>>   -rwxrwxr-x.        40648 Apr  8 05:46 config.status
>>>>   -rwxr-xr-x.       173757 Apr  7 11:43 configure
>>>>   -rw-r--r--.          669 Jun 23  2015 configure.win
>>>>   drwxr-xr-x.          512 Apr  7 11:50 inst
>>>>   drwxr-xr-x.         8192 Mar 28 10:26 man
>>>>   drwxr-xr-x.        16384 Apr  8 05:47 src
>>>>
>>>> Note the "x"s  in the 'configure' line's " -rwxr-xr-x. ":
>>>> This means the file is executable and a reasonable shell can just
>>>> "call the file" and it will be executed, but that's the part which
>>>> failed for you.
>>>>
>>>> .. this *is* peculiar as it looks like some of the standard Unix
>>>> tools may be misbehaving for you .. I assume it could be some OS
>>>> security "feature" playing against you..
>>>>
>>>>     >>
>>>>     >>
>>>>     >>> install.packages("Hmisc")
>>>>     >> Installing package into '/usr/lib64/R/library'
>>>>     >> (as 'lib' is unspecified)
>>>>     >> also installing the dependencies 'stringi', 'evaluate', 'reshape2', 'stringr', knitr', 'ggplot2', 'htmlTable', 'viridis'
>>>>     >>
>>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringi_1.1.5.tar.gz'
>>>>     >> Content type 'application/x-gzip' length 3645872 bytes (3.5 MB)
>>>>     >> ==================================================
>>>>     >> downloaded 3.5 MB
>>>>     >>
>>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/evaluate_0.10.tar.gz'
>>>>     >> Content type 'application/x-gzip' length 21914 bytes (21 KB)
>>>>     >> ==================================================
>>>>     >> downloaded 21 KB
>>>>     >>
>>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/reshape2_1.4.2.tar.gz'
>>>>     >> Content type 'application/x-gzip' length 34688 bytes (33 KB)
>>>>     >> ==================================================
>>>>     >> downloaded 33 KB
>>>>     >>
>>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/stringr_1.2.0.tar.gz'
>>>>     >> Content type 'application/x-gzip' length 94095 bytes (91 KB)
>>>>     >> ==================================================
>>>>     >> downloaded 91 KB
>>>>     >>
>>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/knitr_1.16.tar.gz'
>>>>     >> Content type 'application/x-gzip' length 1031259 bytes (1007 KB)
>>>>     >> ==================================================
>>>>     >> downloaded 1007 KB
>>>>     >>
>>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/ggplot2_2.2.1.tar.gz'
>>>>     >> Content type 'application/x-gzip' length 2213308 bytes (2.1 MB)
>>>>     >> ==================================================
>>>>     >> downloaded 2.1 MB
>>>>     >>
>>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/htmlTable_1.9.tar.gz'
>>>>     >> Content type 'application/x-gzip' length 152095 bytes (148 KB)
>>>>     >> ==================================================
>>>>     >> downloaded 148 KB
>>>>     >>
>>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/viridis_0.4.0.tar.gz'
>>>>     >> Content type 'application/x-gzip' length 1787731 bytes (1.7 MB)
>>>>     >> ==================================================
>>>>     >> downloaded 1.7 MB
>>>>     >>
>>>>     >> trying URL 'https://cloud.r-project.org/src/contrib/Hmisc_4.0-3.tar.gz'
>>>>     >> Content type 'application/x-gzip' length 702759 bytes (686 KB)
>>>>     >> ==================================================
>>>>     >> downloaded 686 KB
>>>>     >>
>>>>     >> * installing *source* package 'stringi' ...
>>>>     >> ** package 'stringi' successfully unpacked and MD5 sums checked
>>>>     >> ERROR: 'configure' exists but is not executable -- see the 'R Installation and dministration Manual'
>>>>     >> * removing '/usr/lib64/R/library/stringi'
>>>>     >> ERROR: dependency 'stringi' is not available for package 'stringr'
>>>>     >> * removing '/usr/lib64/R/library/stringr'
>>>>     >> ERROR: dependency 'stringr' is not available for package 'evaluate'
>>>>     >> * removing '/usr/lib64/R/library/evaluate'
>>>>     >> ERROR: dependency 'stringr' is not available for package 'reshape2'
>>>>     >> * removing '/usr/lib64/R/library/reshape2'
>>>>     >> ERROR: dependencies 'evaluate', 'stringr' are not available for package 'knitr'
>>>>     >> * removing '/usr/lib64/R/library/knitr'
>>>>     >> ERROR: dependency 'reshape2' is not available for package 'ggplot2'
>>>>     >> * removing '/usr/lib64/R/library/ggplot2'
>>>>     >> ERROR: dependencies 'stringr', 'knitr' are not available for package 'htmlTable
>>>>     >> * removing '/usr/lib64/R/library/htmlTable'
>>>>     >> ERROR: dependency 'ggplot2' is not available for package 'viridis'
>>>>     >> * removing '/usr/lib64/R/library/viridis'
>>>>     >> ERROR: dependencies 'ggplot2', 'htmlTable', 'viridis' are not available for pacage 'Hmisc'
>>>>     >> * removing '/usr/lib64/R/library/Hmisc'
>>>>     >>
>>>>     >>
>>>>     >> Any help is appreciated.
>>>>     >> --
>>>>     >> W. Michael Conklin
>>>>     >> Executive Vice President
>>>>     >> Marketing & Data Sciences - North America
>>>>     >> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
>>>>     >> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
>>>>     >> T +1 763 417 4545 | M +1 612 567 8287
>>>>     >> www.gfk.com<http://www.gfk.com/>
>>>>     >>
>>>>     >>
>>>>     >> [[alternative HTML version deleted]]
>>>>     >>
>>>>     >> ______________________________________________
>>>>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>     >> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>     > David Winsemius
>>>>     > Alameda, CA, USA
>>>>
>>>>     > ______________________________________________
>>>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>     > and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>


From fsmairura at yahoo.com  Thu Jun 22 06:15:25 2017
From: fsmairura at yahoo.com (Franklin Mairura)
Date: Thu, 22 Jun 2017 04:15:25 +0000 (UTC)
Subject: [R] Back to back barplot
References: <1450394646.3789674.1498104925719.ref@mail.yahoo.com>
Message-ID: <1450394646.3789674.1498104925719@mail.yahoo.com>

Dear Gentlemen, i want to create a back-to back barplot in R, close to a pyramid chart, but with categories, please help;
Here is a sample, 
Franklin.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 8108 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170622/75cf841c/attachment.png>

From yogesh2cute at gmail.com  Thu Jun 22 10:22:11 2017
From: yogesh2cute at gmail.com (Yogesh Gupta)
Date: Thu, 22 Jun 2017 17:22:11 +0900
Subject: [R] Getting error in dendogram based on gene expression
Message-ID: <CAAjHrnMX18U9Lam+gj+eb=OTN1YWhB5+yTxTKV04CDAG1aoR9g@mail.gmail.com>

Dear All,

I am trying to make dendogram based on gene expression matrix , but getting
some error:

I
countMatrix = read.table("count.row.txt",header=T,sep='\t',check.names=F)

colnames(countMatrix)

count_matrix <- countMatrix[,-1]                   #  remove first column
(gene names)
rownames(count_matrix) <- countMatrix[,1]     #added first column gene
names as rownames)

> nonzero_row <- count_matrix[rowSums(count_matrix) > 0, # removed row sum
0 across all sample

> x1= as.matrix(nonzero_row)                    # converted data into matrix

> x=log2(x1+1)                                          # converted into
log value
> d <- dist(x, method="euclidean")

> h <- hclust(d, method="complete")


*Error:*

 *** caught segfault ***
address 0x7fa39060af28, cause 'memory not mapped'

Traceback:
 1: hclust(d, method = "complete")

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:

Thanks
Yogesh
-- 
*Yogesh Gupta*
*Postdoctoral Researcher*
*Department of Biological Science*
*Seoul National University*
*Seoul, South Korea*

	[[alternative HTML version deleted]]


From c-luescher at hispeed.ch  Thu Jun 22 10:48:36 2017
From: c-luescher at hispeed.ch (=?utf-8?Q?C=C3=A9line_L=C3=BCscher?=)
Date: Thu, 22 Jun 2017 10:48:36 +0200
Subject: [R] Help: ifelse selection for x,y coordinates
Message-ID: <20170622104840.bkod1v00j3nJAqD01kof3k@vie01a-pemc-psmtp-pe01>

Hi everyone,
My database has 3 columns?: the x coordinates, the y coordinates and the value of G for every individual (20 in total). I would like to have the x,y coordinates of individuals, Under these conditions?: the distance to the reference coordinates must be under or equal to 50 meters + the value of G must be bigger or equal to 16.

Here?s what I?ve done first?:

> kk<- function(x, y) 
+ { 
+   coordx<-data$x.Koordinate[data$G==24]
+   coordy<-data$y.Koordinate[data$G==24]
+   x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate,0)
+   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate,0)
+   return(c(x,y))
+ }
> kk(data$x.Koordinate, data$y.Koordinate)
 [1]      0      0      0      0      0 205550 205550      0 205600 205600      0      0      0      0      0      0      0
[18] 604100      0 604150 604100      0

The problem here is that we can not clearly see the difference between the coordinates for x and the ones for y.

Then I tried?this?:
> kk<- function(x, y) 
+ { 
+   coordx<-data$x.Koordinate[data$G==24]
+   coordy<-data$y.Koordinate[data$G==24]
+   x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate," ")
+   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate," ")
+   return(list(x,y))
+ }
> kk(data$x.Koordinate, data$y.Koordinate)
[[1]]
 [1] " "      " "      " "      " "      " "      "205550" "205550" " "      "205600" "205600" " "     
?
[[2]]
 [1] " "      " "      " "      " "      " "      " "      "604100" " "      "604150" "604100" " "     
?
>

Where we can see better the two levels related to the x and y coordinates. 

My question is simple?: Is it possible for this function to return the values in a form like x,y or x y?? (without any 0, or ???, or space) Or should I use another R function to obtain this result??

Thank you for your help, and sorry for the English mistakes,
C.


Gesendet von Mail f?r Windows 10


	[[alternative HTML version deleted]]


From tedwin183 at comcast.net  Thu Jun 22 18:55:14 2017
From: tedwin183 at comcast.net (Edwin Burgess)
Date: Thu, 22 Jun 2017 11:55:14 -0500
Subject: [R] Differences between SPSS and R on probit analysis
Message-ID: <42498EAF-618D-4418-8DBE-A2C24131DA98@comcast.net>

Hi Bianca,


I hope you?ve solved your problem with SPSS and R probit analysis, but if you haven?t, I have your solution:

Based on the output you?ve given, I see that your residual deviance is under-dispersed (that the ratio of residual deviance to residual deviance df does is less than 1). However, you?ve told R to treat your dispersion parameter as 1 (you did this by using the ?family = binomial? argument). Instead, if you use ?family=quasibinomial? you allow the dispersion parameter to be estimated. This changes how the variance, SE, etc are calculated. Modeling it this way is akin to the SPSS method, and thus produces nearly-identical results. You may still see very, very minor differences in chi square goodness of fit, and 95% CI of the doses/concentrations, etc. but this is due to differences in rounding under the hood of the software.


Hope this helps!

 
Edwin R. Burgess IV, Ph.D.



	[[alternative HTML version deleted]]


From adeepak at apple.com  Thu Jun 22 20:22:57 2017
From: adeepak at apple.com (Amrith Deepak)
Date: Thu, 22 Jun 2017 11:22:57 -0700
Subject: [R] Question
Message-ID: <7AD2B015-5E10-47DA-9E73-5B51B2ED93B0@apple.com>

Hi,

I am using Spark and the Sparklyr library in R. 

I have a file with several lines. For example 

A               B       C    
awer.ttp.net    Code    554
abcd.ttp.net    Code    747
asdf.ttp.net    Part    554
xyz.ttp.net     Part    747
I want to split just column A of the table and I want a new row added to the table D, with values awe, abcd, asdf, and xyz. I am trying to use a command in the sparkly library to do that. If that?s not possible, can you please show me another way to do it.


Thanks,
Amrith
	[[alternative HTML version deleted]]


From lawfom at gmail.com  Thu Jun 22 21:52:27 2017
From: lawfom at gmail.com (Lawrence Fomundam)
Date: Thu, 22 Jun 2017 07:52:27 -1200
Subject: [R] Accessing Pointers
Message-ID: <CAPTd6jJi3v+U7MFfFoPGc0aUW-Vckfxr=0JFLP44BWfi=boPkg@mail.gmail.com>

Hello,

I am relatively new to R and would like to access the document my pointer
is pointing to in the following line of code.  Need some help.

#install.packages('xml2')
library('xml2')
pg1 <- read_html("www.msn.com")
str(pg1)
ptr <- pg1[[2]]

	[[alternative HTML version deleted]]


From gliddeca at science.oregonstate.edu  Thu Jun 22 23:12:40 2017
From: gliddeca at science.oregonstate.edu (Caroline)
Date: Thu, 22 Jun 2017 14:12:40 -0700
Subject: [R] MODISTools Help
Message-ID: <DEA13EBF-7DBA-49AF-9013-7352C97EF3CA@science.oregonstate.edu>

I am using MODIS Tools and am having a lot of difficulty troubleshooting my code. 

I am a PhD student studying African buffalo in Kruger National Park, South Africa. The study I am currently working on involves a herd of 200 African buffalo caught every six months for 4 years. I am trying to use EVI and NDVI to assess seasonal variation thus I would like mean EVI and NDVI for each observation (each time each buffalo was captured). I have capture date, lat and long for each observation. 

However, when using ?250m_16_days_pixel_reliability? as my quality control band I keep getting the warning message:

Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product = "MOD13Q1",  :
  Only single data point that passed the quality screen: cannot summarise

When using ?250m_16_days_VI_Quality? as my quality control band I keep getting the warning message: 

Error in QualityCheck(Data = band.time.series, QualityScores = QA.time.series,  : 
  QualityScores not all in range of MOD13Q1's QC: 0-3

I seem to get this message with all subsets of my data (I have tried running all of my data at once and then just one data point at a time). I have also tried using wider date ranges as well as wider size ranges (in case the pixel reliability is poor within a certain area or time frame) but still get the same messages. 
	[[alternative HTML version deleted]]


From hamidib at musc.edu  Thu Jun 22 16:20:16 2017
From: hamidib at musc.edu (Hamidi, Bashir)
Date: Thu, 22 Jun 2017 14:20:16 +0000
Subject: [R] HPC R configure not recognizing zlib
Message-ID: <04F8E99C-5D40-422F-9947-8B5266BD9745@musc.edu>

System: Red Hat Enterprise Linux Server release 6.5 (Santiago)

I?ve installed zlib 1.2.11 on the home folder of a Red Hat HPC as part of the process for installing R base 3.4.0.

I get this error even after successful install of zlib
checking for inflateInit2_ in -lz... no
checking whether zlib support suffices... configure: error: zlib library and headers are required

 I?ve checked R documentation and configure file for the issue of R requiring version newer than 1.2.6 but not lexicographically recognizing 1.2.11 as >1.2.6, and that particular bug was patched in 3.4.

Any suggestion and/or input would be much appreciated.

Regards,


Bashir




	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 23 01:15:49 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 22 Jun 2017 16:15:49 -0700
Subject: [R] Question
In-Reply-To: <7AD2B015-5E10-47DA-9E73-5B51B2ED93B0@apple.com>
References: <7AD2B015-5E10-47DA-9E73-5B51B2ED93B0@apple.com>
Message-ID: <172EB92C-8BDA-4C5E-9429-E345063B7225@comcast.net>


> On Jun 22, 2017, at 11:22 AM, Amrith Deepak <adeepak at apple.com> wrote:
> 
> Hi,
> 
> I am using Spark and the Sparklyr library in R. 
> 
> I have a file with several lines. For example 
> 
> A               B       C    
> awer.ttp.net    Code    554
> abcd.ttp.net    Code    747
> asdf.ttp.net    Part    554
> xyz.ttp.net     Part    747
> I want to split just column A of the table and I want a new row added to the table D, with values awe, abcd, asdf, and xyz. I am trying to use a command in the sparkly library to do that. If that?s not possible, can you please show me another way to do it.
> 

Something along lines of:

dfrm$D <-  sapply( strsplit( dfrm$A, "\\.") , "[[", 1)



> Thanks,
> Amrith
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Jun 23 01:26:11 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 22 Jun 2017 16:26:11 -0700
Subject: [R] Accessing Pointers
In-Reply-To: <CAPTd6jJi3v+U7MFfFoPGc0aUW-Vckfxr=0JFLP44BWfi=boPkg@mail.gmail.com>
References: <CAPTd6jJi3v+U7MFfFoPGc0aUW-Vckfxr=0JFLP44BWfi=boPkg@mail.gmail.com>
Message-ID: <6908B29D-C883-4512-A4AF-E74FA1FFC037@comcast.net>


> On Jun 22, 2017, at 12:52 PM, Lawrence Fomundam <lawfom at gmail.com> wrote:
> 
> Hello,
> 
> I am relatively new to R and would like to access the document my pointer

"my pointer"?


> is pointing to in the following line of code.  Need some help.
> 
> #install.packages('xml2')
> library('xml2')
> pg1 <- read_html("www.msn.com")

Error: 'www.msn.com' does not exist in current working directory ('/Users/davidwinsemius').


> str(pg1)
> ptr <- pg1[[2]]
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From roy.mendelssohn at noaa.gov  Fri Jun 23 01:34:10 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 22 Jun 2017 16:34:10 -0700
Subject: [R] Accessing Pointers
In-Reply-To: <6908B29D-C883-4512-A4AF-E74FA1FFC037@comcast.net>
References: <CAPTd6jJi3v+U7MFfFoPGc0aUW-Vckfxr=0JFLP44BWfi=boPkg@mail.gmail.com>
 <6908B29D-C883-4512-A4AF-E74FA1FFC037@comcast.net>
Message-ID: <16B1DABB-5075-4755-B8B8-2875245D3108@noaa.gov>

Hi Lawrence:
> On Jun 22, 2017, at 4:26 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> 
>> is pointing to in the following line of code.  Need some help.
>> 
>> #install.packages('xml2')
>> library('xml2')
>> pg1 <- read_html("www.msn.com")
> 
> Error: 'www.msn.com' does not exist in current working directory ('/Users/davidwinsemius').
> 
> 

I suggest you do:

?read_html

and peruse it carefully.  You are not passing it a URL.

> library('xml2')
> pg1 <- read_html("http://www.msn.com")
> str(pg1)
List of 2
 $ node:<externalptr> 
 $ doc :<externalptr> 
 - attr(*, "class")= chr [1:2] "xml_document" "xml_node"


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From bgunter.4567 at gmail.com  Fri Jun 23 01:38:51 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 22 Jun 2017 16:38:51 -0700
Subject: [R] MODISTools Help
In-Reply-To: <DEA13EBF-7DBA-49AF-9013-7352C97EF3CA@science.oregonstate.edu>
References: <DEA13EBF-7DBA-49AF-9013-7352C97EF3CA@science.oregonstate.edu>
Message-ID: <CAGxFJbTOwu6GaU8ozKKyAm9uCim_21u9UOb1RcCcr-TjnYNx0g@mail.gmail.com>

This is a specialized package that fairly few of us are likely to have
familiarity with, especialy when you have not followed the posting
guide (below) and posted code and a reproducible example.

That said, a web search on R MODIS appeared to bring up relevant hits,
including a MODIS tutorial. Have you tried that?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 22, 2017 at 2:12 PM, Caroline
<gliddeca at science.oregonstate.edu> wrote:
> I am using MODIS Tools and am having a lot of difficulty troubleshooting my code.
>
> I am a PhD student studying African buffalo in Kruger National Park, South Africa. The study I am currently working on involves a herd of 200 African buffalo caught every six months for 4 years. I am trying to use EVI and NDVI to assess seasonal variation thus I would like mean EVI and NDVI for each observation (each time each buffalo was captured). I have capture date, lat and long for each observation.
>
> However, when using ?250m_16_days_pixel_reliability? as my quality control band I keep getting the warning message:
>
> Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product = "MOD13Q1",  :
>   Only single data point that passed the quality screen: cannot summarise
>
> When using ?250m_16_days_VI_Quality? as my quality control band I keep getting the warning message:
>
> Error in QualityCheck(Data = band.time.series, QualityScores = QA.time.series,  :
>   QualityScores not all in range of MOD13Q1's QC: 0-3
>
> I seem to get this message with all subsets of my data (I have tried running all of my data at once and then just one data point at a time). I have also tried using wider date ranges as well as wider size ranges (in case the pixel reliability is poor within a certain area or time frame) but still get the same messages.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Jun 23 01:46:34 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 22 Jun 2017 16:46:34 -0700
Subject: [R] Back to back barplot
In-Reply-To: <1450394646.3789674.1498104925719@mail.yahoo.com>
References: <1450394646.3789674.1498104925719.ref@mail.yahoo.com>
 <1450394646.3789674.1498104925719@mail.yahoo.com>
Message-ID: <CAGxFJbStTTsTSjQMSq=hLitE9S=95Vuicd3b7SHunAPV5PYszQ@mail.gmail.com>

Do a web search on "pyramid plot R" . That appeared to bring up
relevant resources.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 21, 2017 at 9:15 PM, Franklin Mairura via R-help
<r-help at r-project.org> wrote:
> Dear Gentlemen, i want to create a back-to back barplot in R, close to a pyramid chart, but with categories, please help;
> Here is a sample,
> Franklin.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Jun 23 01:50:57 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 22 Jun 2017 16:50:57 -0700
Subject: [R] MODISTools Help
In-Reply-To: <20297B7C-B925-4FB0-A3C7-B77076019B98@science.oregonstate.edu>
References: <DEA13EBF-7DBA-49AF-9013-7352C97EF3CA@science.oregonstate.edu>
 <CAGxFJbTOwu6GaU8ozKKyAm9uCim_21u9UOb1RcCcr-TjnYNx0g@mail.gmail.com>
 <20297B7C-B925-4FB0-A3C7-B77076019B98@science.oregonstate.edu>
Message-ID: <CAGxFJbQeqzMDg7VEmbdbABfdL-i1FciOiy_98StNe402zZ-_Dg@mail.gmail.com>

1. You should always cc the list unless there is a clear reason not to.

2. You still have failed to follow the posting guide: You say you have
difficulty troubleshooting your code, but you have shown us no code.
You got an error message that seems explicit, but with neither code
nor data, I do not know whether anyone can make sense of it. In any
case, I certainly cannot.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 22, 2017 at 4:41 PM, Caroline
<gliddeca at science.oregonstate.edu> wrote:
> Hi Bert,
>
> I have spent a lot of time searching the web for my error message and have gone through multiple tutorials. I have not found anything relevant to my error message which is why I posted on R-help.
>
> Caroline
>
>> On Jun 22, 2017, at 4:38 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> This is a specialized package that fairly few of us are likely to have
>> familiarity with, especialy when you have not followed the posting
>> guide (below) and posted code and a reproducible example.
>>
>> That said, a web search on R MODIS appeared to bring up relevant hits,
>> including a MODIS tutorial. Have you tried that?
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Jun 22, 2017 at 2:12 PM, Caroline
>> <gliddeca at science.oregonstate.edu> wrote:
>>> I am using MODIS Tools and am having a lot of difficulty troubleshooting my code.
>>>
>>> I am a PhD student studying African buffalo in Kruger National Park, South Africa. The study I am currently working on involves a herd of 200 African buffalo caught every six months for 4 years. I am trying to use EVI and NDVI to assess seasonal variation thus I would like mean EVI and NDVI for each observation (each time each buffalo was captured). I have capture date, lat and long for each observation.
>>>
>>> However, when using ?250m_16_days_pixel_reliability? as my quality control band I keep getting the warning message:
>>>
>>> Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product = "MOD13Q1",  :
>>>  Only single data point that passed the quality screen: cannot summarise
>>>
>>> When using ?250m_16_days_VI_Quality? as my quality control band I keep getting the warning message:
>>>
>>> Error in QualityCheck(Data = band.time.series, QualityScores = QA.time.series,  :
>>>  QualityScores not all in range of MOD13Q1's QC: 0-3
>>>
>>> I seem to get this message with all subsets of my data (I have tried running all of my data at once and then just one data point at a time). I have also tried using wider date ranges as well as wider size ranges (in case the pixel reliability is poor within a certain area or time frame) but still get the same messages.
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Fri Jun 23 01:52:49 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 22 Jun 2017 16:52:49 -0700
Subject: [R] Question
In-Reply-To: <7AD2B015-5E10-47DA-9E73-5B51B2ED93B0@apple.com>
References: <7AD2B015-5E10-47DA-9E73-5B51B2ED93B0@apple.com>
Message-ID: <2F77FD58-2847-4501-A7D8-B6F81AE66E89@dcn.davis.ca.us>

Rows are horizontal, columns are vertical. 

You really need to spend some time with an R tutorial.

dta <- read.table( "yourfile", header=TRUE, as.is=TRUE )
dta2 <- dta
dta2$D <- c( "awe", "abcd", "asdf", "xyz" )
dta2 <- dta2[ , c( "A", "D" ) ]
-- 
Sent from my phone. Please excuse my brevity.

On June 22, 2017 11:22:57 AM PDT, Amrith Deepak <adeepak at apple.com> wrote:
>Hi,
>
>I am using Spark and the Sparklyr library in R. 
>
>I have a file with several lines. For example 
>
>A               B       C    
>awer.ttp.net    Code    554
>abcd.ttp.net    Code    747
>asdf.ttp.net    Part    554
>xyz.ttp.net     Part    747
>I want to split just column A of the table and I want a new row added
>to the table D, with values awe, abcd, asdf, and xyz. I am trying to
>use a command in the sparkly library to do that. If that?s not
>possible, can you please show me another way to do it.
>
>
>Thanks,
>Amrith
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gliddeca at science.oregonstate.edu  Fri Jun 23 02:05:18 2017
From: gliddeca at science.oregonstate.edu (Caroline)
Date: Thu, 22 Jun 2017 17:05:18 -0700
Subject: [R] MODISTools Help
In-Reply-To: <CAGxFJbQeqzMDg7VEmbdbABfdL-i1FciOiy_98StNe402zZ-_Dg@mail.gmail.com>
References: <DEA13EBF-7DBA-49AF-9013-7352C97EF3CA@science.oregonstate.edu>
 <CAGxFJbTOwu6GaU8ozKKyAm9uCim_21u9UOb1RcCcr-TjnYNx0g@mail.gmail.com>
 <20297B7C-B925-4FB0-A3C7-B77076019B98@science.oregonstate.edu>
 <CAGxFJbQeqzMDg7VEmbdbABfdL-i1FciOiy_98StNe402zZ-_Dg@mail.gmail.com>
Message-ID: <9E61B562-C9FF-4B1E-AA0A-C129C8A9D3A2@science.oregonstate.edu>

##MODISTools example
library(MODISTools)
library(lubridate)
setwd('~/Documents/Modis data')

#####MODISTools with buffalo data

###Read in data rename for easier coding
tbdata <- read.csv('~/Desktop/All TB data for EVI, NDVI.csv')
firstobs <- subset(tbdata, capture.ID == 'B1-1108')
firstobs <- firstobs[,c(1,2,2,3,4)]
colnames(firstobs) <- c('id', 'start.date','end.date','lat','long')

###change date format and change start date to previous 14 days
firstobs$start.date <- dmy(firstobs$start.date)
firstobs$end.date <- dmy(firstobs$end.date)
firstobs$start.date <- firstobs[,2] - as.difftime(14, unit='days') ###time frame now spands two weeks

###define parameters 
product <- "MOD13Q1"
bands <- c('250m_16_days_EVI', '250m_16_days_NDVI', '250m_16_days_VI_Quality')
pixel <- c(0,0)

###define data
period <- data.frame(lat=firstobs$lat, long=firstobs$long, start.date =firstobs$start.date, end.date = firstobs$end.date, id=firstobs$id)


###MODISSubsets
MODISSubsets(LoadDat = period, Products = product, Bands=bands, Size=pixel, SaveDir='.', StartDate=T)


###MODISSummaries
MODISSummaries(LoadDat = period, FileSep=',',Product='MOD13Q1', Bands = '250m_16_days_EVI', ValidRange=c(-2000,10000), NoDataFill=-3000, ScaleFactor = 0.0001, StartDate = TRUE, Interpolate = T, QualityScreen = TRUE, QualityThreshold = 0, QualityBand = '250m_16_days_VI_Quality')


> On Jun 22, 2017, at 4:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> 1. You should always cc the list unless there is a clear reason not to.
> 
> 2. You still have failed to follow the posting guide: You say you have
> difficulty troubleshooting your code, but you have shown us no code.
> You got an error message that seems explicit, but with neither code
> nor data, I do not know whether anyone can make sense of it. In any
> case, I certainly cannot.
> 
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Jun 22, 2017 at 4:41 PM, Caroline
> <gliddeca at science.oregonstate.edu> wrote:
>> Hi Bert,
>> 
>> I have spent a lot of time searching the web for my error message and have gone through multiple tutorials. I have not found anything relevant to my error message which is why I posted on R-help.
>> 
>> Caroline
>> 
>>> On Jun 22, 2017, at 4:38 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 
>>> This is a specialized package that fairly few of us are likely to have
>>> familiarity with, especialy when you have not followed the posting
>>> guide (below) and posted code and a reproducible example.
>>> 
>>> That said, a web search on R MODIS appeared to bring up relevant hits,
>>> including a MODIS tutorial. Have you tried that?
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Thu, Jun 22, 2017 at 2:12 PM, Caroline
>>> <gliddeca at science.oregonstate.edu> wrote:
>>>> I am using MODIS Tools and am having a lot of difficulty troubleshooting my code.
>>>> 
>>>> I am a PhD student studying African buffalo in Kruger National Park, South Africa. The study I am currently working on involves a herd of 200 African buffalo caught every six months for 4 years. I am trying to use EVI and NDVI to assess seasonal variation thus I would like mean EVI and NDVI for each observation (each time each buffalo was captured). I have capture date, lat and long for each observation.
>>>> 
>>>> However, when using ?250m_16_days_pixel_reliability? as my quality control band I keep getting the warning message:
>>>> 
>>>> Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product = "MOD13Q1",  :
>>>> Only single data point that passed the quality screen: cannot summarise
>>>> 
>>>> When using ?250m_16_days_VI_Quality? as my quality control band I keep getting the warning message:
>>>> 
>>>> Error in QualityCheck(Data = band.time.series, QualityScores = QA.time.series,  :
>>>> QualityScores not all in range of MOD13Q1's QC: 0-3
>>>> 
>>>> I seem to get this message with all subsets of my data (I have tried running all of my data at once and then just one data point at a time). I have also tried using wider date ranges as well as wider size ranges (in case the pixel reliability is poor within a certain area or time frame) but still get the same messages.
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 


	[[alternative HTML version deleted]]


From don-r-help at isis.cs3-inc.com  Fri Jun 23 01:18:24 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Thu, 22 Jun 2017 23:18:24 +0000
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <ef8c365a-2960-88f7-9504-9cfd84150e66@gmail.com>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
 <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
 <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
 <37b169a8-a0c8-ea11-2925-7cc09777a203@gmail.com>
 <10a0d0f4d1f9448ca6a6140146943f13@IPXW-EXPCM02.gfk.com>
 <33a2feb8-94d0-24a4-4f58-30be332ee492@gmail.com>
 <6105f59fa7ab44a9bf882a2c7fbc2e2f@IPXW-EXPCM02.gfk.com>
 <ef8c365a-2960-88f7-9504-9cfd84150e66@gmail.com>
Message-ID: <22860.20544.997952.539978@losangelesyouthorchestra.org>

Duncan Murdoch writes:
 > On 22/06/2017 5:02 PM, Conklin, Mike (GfK) wrote:
 > > I am using debug on the .install_packages function...stepping through. Once the temporary folder is created and the tar file expanded I run file_test and get a FALSE back indicating that the configure file is not executable.
 > 
 > I don't know what is causing this bug.  Perhaps a Linux user can 
 > reproduce it and fix it.
 > 
 > Here's what I see:
 > 
 > file_test("-x") calls file.access(filename, 1L).  That in turn calls the 
 > C library function access(..., X_OK).  The ... is the name of the file, 
 > translated into the local encoding and expanded.  As far as I can see, 
 > that means ... should be exactly the string below.
 > >
 > > [1] "/tmp/RtmpMM6iC1/R.INSTALLc5ca415e4310/stringi"
 > 
 > The only thing I can think of is that your system is protecting you from 
 > executing a newly created file until some sort of virus or other check 
 > is done.  (This is common on Windows, but I've never heard of it before 
 > on Linux.)

Just a thought - are you running SELinux ?
Check the log files for refusals to run programs.


From adeepak at apple.com  Fri Jun 23 01:20:36 2017
From: adeepak at apple.com (Amrith Deepak)
Date: Thu, 22 Jun 2017 16:20:36 -0700
Subject: [R] Question
In-Reply-To: <172EB92C-8BDA-4C5E-9429-E345063B7225@comcast.net>
References: <7AD2B015-5E10-47DA-9E73-5B51B2ED93B0@apple.com>
 <172EB92C-8BDA-4C5E-9429-E345063B7225@comcast.net>
Message-ID: <7954ADC1-4924-4B44-BF19-E01580B3E83A@apple.com>

This function won?t work with objects in spark as you can?t do a dfda$a in spark as it?s not stored as a local variable.

Thanks,
Amrith

> On Jun 22, 2017, at 4:15 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jun 22, 2017, at 11:22 AM, Amrith Deepak <adeepak at apple.com> wrote:
>> 
>> Hi,
>> 
>> I am using Spark and the Sparklyr library in R. 
>> 
>> I have a file with several lines. For example 
>> 
>> A               B       C    
>> awer.ttp.net    Code    554
>> abcd.ttp.net    Code    747
>> asdf.ttp.net    Part    554
>> xyz.ttp.net     Part    747
>> I want to split just column A of the table and I want a new row added to the table D, with values awe, abcd, asdf, and xyz. I am trying to use a command in the sparkly library to do that. If that?s not possible, can you please show me another way to do it.
>> 
> 
> Something along lines of:
> 
> dfrm$D <-  sapply( strsplit( dfrm$A, "\\.") , "[[", 1)
> 
> 
> 
>> Thanks,
>> Amrith
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gliddeca at science.oregonstate.edu  Fri Jun 23 01:44:59 2017
From: gliddeca at science.oregonstate.edu (Caroline)
Date: Thu, 22 Jun 2017 16:44:59 -0700
Subject: [R] MODISTools help - with reproducible examples
Message-ID: <6D55A8BB-2AAB-4225-B10E-690D9AFE5714@science.oregonstate.edu>

I am using the R-package MODISTools (different than MODIS) and am having a lot of difficulty troubleshooting my code. I have spent awhile going through MODISTools tutorials, searching for my error code, looking at the source code. However, I have not been able to find any relevant information related to my error message. 

The study I am currently working on involves a herd of 200 African buffalo caught every six months for 4 years. I am trying to use EVI and NDVI to assess seasonal variation thus I would like mean EVI and NDVI for each observation (each time each buffalo was captured). I have capture date, lat and long for each observation. 

However, when using ?250m_16_days_pixel_reliability? as my quality control band I keep getting the warning message:

Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product = "MOD13Q1",  :
  Only single data point that passed the quality screen: cannot summarise

When using ?250m_16_days_VI_Quality? as my quality control band I keep getting the warning message: 

Error in QualityCheck(Data = band.time.series, QualityScores = QA.time.series,  : 
  QualityScores not all in range of MOD13Q1's QC: 0-3

I seem to get this message with all subsets of my data (I have tried running all of my data at once and then just one data point at a time). I have also tried using wider date ranges as well as wider size ranges (in case the pixel reliability is poor within a certain area or time frame) but still get the same messages. 

I have attached the data file I have been using as well as my code (subsetted to just one animal so the run time is faster) 

Has anyone seen this error message before/have any suggestions for why I may be getting these errors?



From adeepak at apple.com  Fri Jun 23 02:00:59 2017
From: adeepak at apple.com (Amrith Deepak)
Date: Thu, 22 Jun 2017 17:00:59 -0700
Subject: [R] Question
In-Reply-To: <2F77FD58-2847-4501-A7D8-B6F81AE66E89@dcn.davis.ca.us>
References: <7AD2B015-5E10-47DA-9E73-5B51B2ED93B0@apple.com>
 <2F77FD58-2847-4501-A7D8-B6F81AE66E89@dcn.davis.ca.us>
Message-ID: <EC2BF46E-50F5-42EF-8AC4-2C41408FC9FE@apple.com>

Sorry, I don?t think you understand my problem. dta = spark_read_csv(sc,?data_tbl?,?extension/file",delimiter = "|")

dta is just a pointer to spark where the data is stored. I am using sparklyr to run this on spark. I?m not running it locally so I can?t use the $. I know how to do this locally in R.

Thanks,
Amrith

> On Jun 22, 2017, at 4:52 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Rows are horizontal, columns are vertical. 
> 
> You really need to spend some time with an R tutorial.
> 
> dta <- read.table( "yourfile", header=TRUE, as.is=TRUE )
> dta2 <- dta
> dta2$D <- c( "awe", "abcd", "asdf", "xyz" )
> dta2 <- dta2[ , c( "A", "D" ) ]
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On June 22, 2017 11:22:57 AM PDT, Amrith Deepak <adeepak at apple.com> wrote:
>> Hi,
>> 
>> I am using Spark and the Sparklyr library in R. 
>> 
>> I have a file with several lines. For example 
>> 
>> A               B       C    
>> awer.ttp.net    Code    554
>> abcd.ttp.net    Code    747
>> asdf.ttp.net    Part    554
>> xyz.ttp.net     Part    747
>> I want to split just column A of the table and I want a new row added
>> to the table D, with values awe, abcd, asdf, and xyz. I am trying to
>> use a command in the sparkly library to do that. If that?s not
>> possible, can you please show me another way to do it.
>> 
>> 
>> Thanks,
>> Amrith
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 23 05:25:05 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 22 Jun 2017 20:25:05 -0700
Subject: [R] MODISTools help - with reproducible examples
In-Reply-To: <6D55A8BB-2AAB-4225-B10E-690D9AFE5714@science.oregonstate.edu>
References: <6D55A8BB-2AAB-4225-B10E-690D9AFE5714@science.oregonstate.edu>
Message-ID: <68AB503B-EC6F-470B-B03A-36C3F9D8741A@comcast.net>


> On Jun 22, 2017, at 4:44 PM, Caroline <gliddeca at science.oregonstate.edu> wrote:
> 
> I am using the R-package MODISTools (different than MODIS) and am having a lot of difficulty troubleshooting my code. I have spent awhile going through MODISTools tutorials, searching for my error code, looking at the source code. However, I have not been able to find any relevant information related to my error message. 
> 
> The study I am currently working on involves a herd of 200 African buffalo caught every six months for 4 years. I am trying to use EVI and NDVI to assess seasonal variation thus I would like mean EVI and NDVI for each observation (each time each buffalo was captured). I have capture date, lat and long for each observation. 
> 
> However, when using ?250m_16_days_pixel_reliability? as my quality control band I keep getting the warning message:
> 
> Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product = "MOD13Q1",  :
>  Only single data point that passed the quality screen: cannot summarise
> 
> When using ?250m_16_days_VI_Quality? as my quality control band I keep getting the warning message: 
> 
> Error in QualityCheck(Data = band.time.series, QualityScores = QA.time.series,  : 
>  QualityScores not all in range of MOD13Q1's QC: 0-3
> 
> I seem to get this message with all subsets of my data (I have tried running all of my data at once and then just one data point at a time). I have also tried using wider date ranges as well as wider size ranges (in case the pixel reliability is poor within a certain area or time frame) but still get the same messages. 
> 
> I have attached the data file I have been using as well as my code (subsetted to just one animal so the run time is faster) 
> 
> Has anyone seen this error message before/have any suggestions for why I may be getting these errors?

I don't and you have not provided the accepted means to investigate which would be code and data . Have you contacted the package maintainer?

-- 

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Fri Jun 23 05:27:57 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 23 Jun 2017 13:27:57 +1000
Subject: [R] Help: ifelse selection for x,y coordinates
In-Reply-To: <20170622104840.bkod1v00j3nJAqD01kof3k@vie01a-pemc-psmtp-pe01>
References: <20170622104840.bkod1v00j3nJAqD01kof3k@vie01a-pemc-psmtp-pe01>
Message-ID: <CA+8X3fXRbgmadK5cpJ3aAjGN_2gLDSQAb9y+x15RudZbs+pFBQ@mail.gmail.com>

Hi Celine,
Perhaps if you modify your return value like this:

xy<-as.data.frame(list(x,y))
names(xy)<-c("x","y")
return(xy)

Jim

On Thu, Jun 22, 2017 at 6:48 PM, C?line L?scher <c-luescher at hispeed.ch> wrote:
> Hi everyone,
> My database has 3 columns : the x coordinates, the y coordinates and the value of G for every individual (20 in total). I would like to have the x,y coordinates of individuals, Under these conditions : the distance to the reference coordinates must be under or equal to 50 meters + the value of G must be bigger or equal to 16.
>
> Here?s what I?ve done first :
>
>> kk<- function(x, y)
> + {
> +   coordx<-data$x.Koordinate[data$G==24]
> +   coordy<-data$y.Koordinate[data$G==24]
> +   x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate,0)
> +   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate,0)
> +   return(c(x,y))
> + }
>> kk(data$x.Koordinate, data$y.Koordinate)
>  [1]      0      0      0      0      0 205550 205550      0 205600 205600      0      0      0      0      0      0      0
> [18] 604100      0 604150 604100      0
>
> The problem here is that we can not clearly see the difference between the coordinates for x and the ones for y.
>
> Then I tried this :
>> kk<- function(x, y)
> + {
> +   coordx<-data$x.Koordinate[data$G==24]
> +   coordy<-data$y.Koordinate[data$G==24]
> +   x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate," ")
> +   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate," ")
> +   return(list(x,y))
> + }
>> kk(data$x.Koordinate, data$y.Koordinate)
> [[1]]
>  [1] " "      " "      " "      " "      " "      "205550" "205550" " "      "205600" "205600" " "
>
> [[2]]
>  [1] " "      " "      " "      " "      " "      " "      "604100" " "      "604150" "604100" " "
>
>>
>
> Where we can see better the two levels related to the x and y coordinates.
>
> My question is simple : Is it possible for this function to return the values in a form like x,y or x y ? (without any 0, or ? ?, or space) Or should I use another R function to obtain this result ?
>
> Thank you for your help, and sorry for the English mistakes,
> C.
>
>
> Gesendet von Mail f?r Windows 10
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri Jun 23 06:18:14 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 22 Jun 2017 21:18:14 -0700
Subject: [R] Question
In-Reply-To: <7954ADC1-4924-4B44-BF19-E01580B3E83A@apple.com>
References: <7AD2B015-5E10-47DA-9E73-5B51B2ED93B0@apple.com>
 <172EB92C-8BDA-4C5E-9429-E345063B7225@comcast.net>
 <7954ADC1-4924-4B44-BF19-E01580B3E83A@apple.com>
Message-ID: <CECEC98B-DA90-447E-A428-2EC97B5051F0@dcn.davis.ca.us>

This is not a Spark-help mailing list, either. 
-- 
Sent from my phone. Please excuse my brevity.

On June 22, 2017 4:20:36 PM PDT, Amrith Deepak <adeepak at apple.com> wrote:
>This function won?t work with objects in spark as you can?t do a dfda$a
>in spark as it?s not stored as a local variable.
>
>Thanks,
>Amrith
>
>> On Jun 22, 2017, at 4:15 PM, David Winsemius <dwinsemius at comcast.net>
>wrote:
>> 
>> 
>>> On Jun 22, 2017, at 11:22 AM, Amrith Deepak <adeepak at apple.com>
>wrote:
>>> 
>>> Hi,
>>> 
>>> I am using Spark and the Sparklyr library in R. 
>>> 
>>> I have a file with several lines. For example 
>>> 
>>> A               B       C    
>>> awer.ttp.net    Code    554
>>> abcd.ttp.net    Code    747
>>> asdf.ttp.net    Part    554
>>> xyz.ttp.net     Part    747
>>> I want to split just column A of the table and I want a new row
>added to the table D, with values awe, abcd, asdf, and xyz. I am trying
>to use a command in the sparkly library to do that. If that?s not
>possible, can you please show me another way to do it.
>>> 
>> 
>> Something along lines of:
>> 
>> dfrm$D <-  sapply( strsplit( dfrm$A, "\\.") , "[[", 1)
>> 
>> 
>> 
>>> Thanks,
>>> Amrith
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From c-luescher at hispeed.ch  Fri Jun 23 07:30:39 2017
From: c-luescher at hispeed.ch (=?utf-8?Q?C=C3=A9line_L=C3=BCscher?=)
Date: Fri, 23 Jun 2017 07:30:39 +0200
Subject: [R] Help: ifelse selection for x,y coordinates
In-Reply-To: <CA+8X3fXRbgmadK5cpJ3aAjGN_2gLDSQAb9y+x15RudZbs+pFBQ@mail.gmail.com>
References: <20170622104840.bkod1v00j3nJAqD01kof3k@vie01a-pemc-psmtp-pe01>
 <CA+8X3fXRbgmadK5cpJ3aAjGN_2gLDSQAb9y+x15RudZbs+pFBQ@mail.gmail.com>
Message-ID: <20170623073048.c5Wh1v00w3c2ZEY015WjyY@vie01a-pemc-psmtp-pe01>

Hi Jim,

Thank you very much for the answer?! The result is really better with this??

Here is the code?:
> kk<- function(x.Koordinate, y.Koordinate, data=data) 
+ { 
+   coordx<-data$x.Koordinate[data$G==24]
+   coordy<-data$y.Koordinate[data$G==24]
+   x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate," ")
+   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate," ")
+   xy<-as.data.frame(list(x,y))
+   names(xy)<-c("x","y")
+   return(xy)
+ }
> kk(x.Koordinate, y.Koordinate, data=data)
        x      y
1               
2               
3               
4               
5               
6  205550       
7  205550 604100
8               
9  205600 604150
10 205600 604100

Best regards,
C.


Gesendet von Mail f?r Windows 10

Von: Jim Lemon
Gesendet: vendredi, 23 juin 2017 05:28
An: C?line L?scher
Cc: r-help at r-project.org
Betreff: Re: [R] Help: ifelse selection for x,y coordinates

Hi Celine,
Perhaps if you modify your return value like this:

xy<-as.data.frame(list(x,y))
names(xy)<-c("x","y")
return(xy)

Jim

On Thu, Jun 22, 2017 at 6:48 PM, C?line L?scher <c-luescher at hispeed.ch> wrote:
> Hi everyone,
> My database has 3 columns : the x coordinates, the y coordinates and the value of G for every individual (20 in total). I would like to have the x,y coordinates of individuals, Under these conditions : the distance to the reference coordinates must be under or equal to 50 meters + the value of G must be bigger or equal to 16.
>
> Here?s what I?ve done first :
>
>> kk<- function(x, y)
> + {
> +   coordx<-data$x.Koordinate[data$G==24]
> +   coordy<-data$y.Koordinate[data$G==24]
> +   x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate,0)
> +   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate,0)
> +   return(c(x,y))
> + }
>> kk(data$x.Koordinate, data$y.Koordinate)
>  [1]      0      0      0      0      0 205550 205550      0 205600 205600      0      0      0      0      0      0      0
> [18] 604100      0 604150 604100      0
>
> The problem here is that we can not clearly see the difference between the coordinates for x and the ones for y.
>
> Then I tried this :
>> kk<- function(x, y)
> + {
> +   coordx<-data$x.Koordinate[data$G==24]
> +   coordy<-data$y.Koordinate[data$G==24]
> +   x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate," ")
> +   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate," ")
> +   return(list(x,y))
> + }
>> kk(data$x.Koordinate, data$y.Koordinate)
> [[1]]
>  [1] " "      " "      " "      " "      " "      "205550" "205550" " "      "205600" "205600" " "
>
> [[2]]
>  [1] " "      " "      " "      " "      " "      " "      "604100" " "      "604150" "604100" " "
>
>>
>
> Where we can see better the two levels related to the x and y coordinates.
>
> My question is simple : Is it possible for this function to return the values in a form like x,y or x y ? (without any 0, or ? ?, or space) Or should I use another R function to obtain this result ?
>
> Thank you for your help, and sorry for the English mistakes,
> C.
>
>
> Gesendet von Mail f?r Windows 10
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From peter.anthoni at kit.edu  Fri Jun 23 07:38:48 2017
From: peter.anthoni at kit.edu (Anthoni, Peter (IMK))
Date: Fri, 23 Jun 2017 05:38:48 +0000
Subject: [R] Help: ifelse selection for x,y coordinates
In-Reply-To: <20170623073048.c5Wh1v00w3c2ZEY015WjyY@vie01a-pemc-psmtp-pe01>
References: <20170622104840.bkod1v00j3nJAqD01kof3k@vie01a-pemc-psmtp-pe01>
 <CA+8X3fXRbgmadK5cpJ3aAjGN_2gLDSQAb9y+x15RudZbs+pFBQ@mail.gmail.com>
 <20170623073048.c5Wh1v00w3c2ZEY015WjyY@vie01a-pemc-psmtp-pe01>
Message-ID: <A380DCF5-28D4-4C8E-B7AD-94994E9DBE4C@kit.edu>

Hi Celine,

what about removing the unwanted after you made the x and y
x<-x[x>0]  # or x<-x[x>0&&y>0], ditto for y, x[x!=""] in your ifelse (... ,"") case

if x and y will not have the same length afterwards you need to make that list thingy.

cheers
Peter



On 23. Jun 2017, at 07:30, C?line L?scher <c-luescher at hispeed.ch<mailto:c-luescher at hispeed.ch>> wrote:

Hi Jim,

Thank you very much for the answer ! The result is really better with this ?

Here is the code :
kk<- function(x.Koordinate, y.Koordinate, data=data)
+ {
+   coordx<-data$x.Koordinate[data$G==24]
+   coordy<-data$y.Koordinate[data$G==24]
+   x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate," ")
+   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate," ")
+   xy<-as.data.frame(list(x,y))
+   names(xy)<-c("x","y")
+   return(xy)
+ }
kk(x.Koordinate, y.Koordinate, data=data)
       x      y
1
2
3
4
5
6  205550
7  205550 604100
8
9  205600 604150
10 205600 604100

Best regards,
C.


Gesendet von Mail f?r Windows 10

Von: Jim Lemon
Gesendet: vendredi, 23 juin 2017 05:28
An: C?line L?scher
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Betreff: Re: [R] Help: ifelse selection for x,y coordinates

Hi Celine,
Perhaps if you modify your return value like this:

xy<-as.data.frame(list(x,y))
names(xy)<-c("x","y")
return(xy)

Jim

On Thu, Jun 22, 2017 at 6:48 PM, C?line L?scher <c-luescher at hispeed.ch<mailto:c-luescher at hispeed.ch>> wrote:
Hi everyone,
My database has 3 columns : the x coordinates, the y coordinates and the value of G for every individual (20 in total). I would like to have the x,y coordinates of individuals, Under these conditions : the distance to the reference coordinates must be under or equal to 50 meters + the value of G must be bigger or equal to 16.

Here?s what I?ve done first :

kk<- function(x, y)
+ {
+   coordx<-data$x.Koordinate[data$G==24]
+   coordy<-data$y.Koordinate[data$G==24]
+   x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate,0)
+   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate,0)
+   return(c(x,y))
+ }
kk(data$x.Koordinate, data$y.Koordinate)
[1]      0      0      0      0      0 205550 205550      0 205600 205600      0      0      0      0      0      0      0
[18] 604100      0 604150 604100      0

The problem here is that we can not clearly see the difference between the coordinates for x and the ones for y.

Then I tried this :
kk<- function(x, y)
+ {
+   coordx<-data$x.Koordinate[data$G==24]
+   coordy<-data$y.Koordinate[data$G==24]
+   x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate," ")
+   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate," ")
+   return(list(x,y))
+ }
kk(data$x.Koordinate, data$y.Koordinate)
[[1]]
[1] " "      " "      " "      " "      " "      "205550" "205550" " "      "205600" "205600" " "

[[2]]
[1] " "      " "      " "      " "      " "      " "      "604100" " "      "604150" "604100" " "



Where we can see better the two levels related to the x and y coordinates.

My question is simple : Is it possible for this function to return the values in a form like x,y or x y ? (without any 0, or ? ?, or space) Or should I use another R function to obtain this result ?

Thank you for your help, and sorry for the English mistakes,
C.


Gesendet von Mail f?r Windows 10


       [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From andreas.leha at med.uni-goettingen.de  Fri Jun 23 09:24:44 2017
From: andreas.leha at med.uni-goettingen.de (Andreas Leha)
Date: Fri, 23 Jun 2017 09:24:44 +0200
Subject: [R] encoding/locale problem with ssh -X
References: <87podxlq9e.fsf@ukes-ams26-134.ams.med.uni.goettingen.de>
Message-ID: <87vannrwsj.fsf@ukes-ams26-134.ams.med.uni.goettingen.de>

Hi Paul,

Thanks for following this up!

It used to be R version 3.3.1

I updated to R version 3.4.0

Now everything seems to work!

Many thanks!

Best,
Andreas



On 23/06/17 03:02, Paul Murrell wrote:
> Hi
> 
> What version of R do you have (on the remote machine) ?
> 
> I can replicate this with ...
> 
> x11(type="Xlib")
> library(grid)
> convertHeight(stringDescent("gr??e"), "in")
> 
> ... on R 3.2.5, but not on, e.g., R 3.4.0 (just running R locally in
> both cases).
> 
> Paul
> 
> On 21/06/17 20:05, Andreas Leha wrote:
>> Hi all,
>>
>> I am struggling with remote R sessions and a (I suspect) locale related
>> encoding problem:  Using the X11 device (X11forwarding enabled),
>> whenever I try to plot something containing umlauts using ggplot2, I am
>> seeing sth like
>>
>> ,----
>> | Error in grid.Call(L_stringMetric, as.graphicsAnnot(x$label)) :
>> |   invalid use of -61 < 0 in 'X11_MetricInfo'
>> `----
>>
>> Using base graphics is fine as is plotting to another device (pdf, say).
>>
>> Here is some code to reproduce:
>>
>> ,----
>> | plot(1:10, 1:10, main = "gr??e")
>> | ## this works
>> |
>> | library("ggplot2")
>> | qplot(1:10, 1:10)
>> | ## this works still
>> |
>> | qplot(1:10, 1:10) + xlab("gr??e")
>> | ## ERROR
>> `----
>>
>>
>> My setup:
>> - locally:
>>    Linux (Debian GNU/Linux 9)
>> - remotely
>>    Linux (RHEL Server release 7.3 (Maipo)
>>
>> (Maybe) relevant bits of my .ssh/config:
>>
>> ,----
>> | Host theserver
>> |      HostName XXX.XXX.XXX.XXX
>> |      ForwardX11 yes
>> |      ForwardX11Timeout 596h
>> |      IdentityFile ~/.ssh/id_rsa
>> |      IdentitiesOnly yes
>> |      ForwardAgent yes
>> |      ServerAliveInterval 300
>> `----
>>
>> Thanks in advance for your help!
>>
>> Best,
>> Andreas
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From c-luescher at hispeed.ch  Fri Jun 23 10:05:22 2017
From: c-luescher at hispeed.ch (=?utf-8?Q?C=C3=A9line_L=C3=BCscher?=)
Date: Fri, 23 Jun 2017 10:05:22 +0200
Subject: [R] Help: ifelse selection for x,y coordinates
In-Reply-To: <A380DCF5-28D4-4C8E-B7AD-94994E9DBE4C@kit.edu>
References: <20170622104840.bkod1v00j3nJAqD01kof3k@vie01a-pemc-psmtp-pe01>
 <CA+8X3fXRbgmadK5cpJ3aAjGN_2gLDSQAb9y+x15RudZbs+pFBQ@mail.gmail.com>
 <20170623073048.c5Wh1v00w3c2ZEY015WjyY@vie01a-pemc-psmtp-pe01>
 <A380DCF5-28D4-4C8E-B7AD-94994E9DBE4C@kit.edu>
Message-ID: <20170623100528.c85R1v02E3nPLke0185TuZ@vie01a-pemc-psmtp-pe01>

Hi Peter?!

Thanks for your answer?! Indeed it is really better without the empty rows. Unfortunately I did?nt archieve to do it with your propositions, but with this one?:

> kk<- function(x.Koordinate, y.Koordinate, data=data) 
+ { 
+   coordx<-data$x.Koordinate[data$G==24]
+   coordy<-data$y.Koordinate[data$G==24]
+   x<- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate,NA)
+   y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate,NA)
+   xy<-as.data.frame(list(x,y))
+   names(xy)<-c("x","y")
+   return(xy)
+ }
> kk1<-kk(x.Koordinate, y.Koordinate, data=data)
> kk1<-kk1[rowSums(is.na(kk1)) != ncol(kk1),]
> kk1
        x      y
6  205550     NA
7  205550 604100
9  205600 604150
10 205600 604100


Now it looks great??

Regards,
C.


Gesendet von Mail f?r Windows 10

Von: Anthoni, Peter (IMK)
Gesendet: vendredi, 23 juin 2017 07:39
An: C?line L?scher
Cc: r-help at r-project.org
Betreff: Re: [R] Help: ifelse selection for x,y coordinates

Hi Celine,

what about removing the unwanted after you made the x and y 
x<-x[x>0] ?# or x<-x[x>0&&y>0], ditto for y, x[x!=""] in your ifelse (... ,"") case

if x and y will not have the same length afterwards you need to make that list thingy.

cheers
Peter


On 23. Jun 2017, at 07:30, C?line L?scher <c-luescher at hispeed.ch> wrote:

Hi Jim,

Thank you very much for the answer?! The result is really better with this??

Here is the code?:

kk<- function(x.Koordinate, y.Koordinate, data=data)?
+ {?
+ ??coordx<-data$x.Koordinate[data$G==24]
+ ??coordy<-data$y.Koordinate[data$G==24]
+ ??x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate," ")
+ ??y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate," ")
+ ??xy<-as.data.frame(list(x,y))
+ ??names(xy)<-c("x","y")
+ ??return(xy)
+ }

kk(x.Koordinate, y.Koordinate, data=data)
???????x ?????y
1 ??????????????
2 ??????????????
3 ??????????????
4 ??????????????
5 ??????????????
6 ?205550 ??????
7 ?205550 604100
8 ??????????????
9 ?205600 604150
10 205600 604100

Best regards,
C.


Gesendet von Mail f?r Windows 10

Von: Jim Lemon
Gesendet: vendredi, 23 juin 2017 05:28
An: C?line L?scher
Cc:?r-help at r-project.org
Betreff: Re: [R] Help: ifelse selection for x,y coordinates

Hi Celine,
Perhaps if you modify your return value like this:

xy<-as.data.frame(list(x,y))
names(xy)<-c("x","y")
return(xy)

Jim

On Thu, Jun 22, 2017 at 6:48 PM, C?line L?scher <c-luescher at hispeed.ch> wrote:

Hi everyone,
My database has 3 columns : the x coordinates, the y coordinates and the value of G for every individual (20 in total). I would like to have the x,y coordinates of individuals, Under these conditions : the distance to the reference coordinates must be under or equal to 50 meters + the value of G must be bigger or equal to 16.

Here?s what I?ve done first :


kk<- function(x, y)
+ {
+ ??coordx<-data$x.Koordinate[data$G==24]
+ ??coordy<-data$y.Koordinate[data$G==24]
+ ??x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate,0)
+ ??y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate,0)
+ ??return(c(x,y))
+ }

kk(data$x.Koordinate, data$y.Koordinate)
[1] ?????0 ?????0 ?????0 ?????0 ?????0 205550 205550 ?????0 205600 205600 ?????0 ?????0 ?????0 ?????0 ?????0 ?????0 ?????0
[18] 604100 ?????0 604150 604100 ?????0

The problem here is that we can not clearly see the difference between the coordinates for x and the ones for y.

Then I tried this :

kk<- function(x, y)
+ {
+ ??coordx<-data$x.Koordinate[data$G==24]
+ ??coordy<-data$y.Koordinate[data$G==24]
+ ??x <- ifelse(data$x.Koordinate>coordx-51 & data$G>15,data$x.Koordinate," ")
+ ??y<-ifelse(data$y.Koordinate>coordy-51 & data$G>15,data$y.Koordinate," ")
+ ??return(list(x,y))
+ }

kk(data$x.Koordinate, data$y.Koordinate)
[[1]]
[1] " " ?????" " ?????" " ?????" " ?????" " ?????"205550" "205550" " " ?????"205600" "205600" " "

[[2]]
[1] " " ?????" " ?????" " ?????" " ?????" " ?????" " ?????"604100" " " ?????"604150" "604100" " "




Where we can see better the two levels related to the x and y coordinates.

My question is simple : Is it possible for this function to return the values in a form like x,y or x y ? (without any 0, or ? ?, or space) Or should I use another R function to obtain this result ?

Thank you for your help, and sorry for the English mistakes,
C.


Gesendet von Mail f?r Windows 10


???????[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide?http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Jun 23 11:23:15 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 23 Jun 2017 11:23:15 +0200
Subject: [R] getting error while trying to make dendogram based on
	gene	expression
In-Reply-To: <CAAjHrnNk4C45xv2+jJs3r9cTWcASJOXxSek8p3SGJr+X4LhvTw@mail.gmail.com>
References: <CAAjHrnNk4C45xv2+jJs3r9cTWcASJOXxSek8p3SGJr+X4LhvTw@mail.gmail.com>
Message-ID: <22860.56835.964333.115602@stat.math.ethz.ch>

>>>>> Yogesh Gupta <yogesh2cute at gmail.com>
>>>>>     on Wed, 21 Jun 2017 13:42:15 +0900 writes:

    > I am trying to make dendogram based on gene expression matrix , but getting
    > some error:

    > I
    > countMatrix = read.table("count.row.txt",header=T,sep='\t',check.names=F)

    > colnames(countMatrix)

    > count_matrix <- countMatrix[,-1]                   #  remove first column
    > (gene names)
    > rownames(count_matrix) <- countMatrix[,1]     #added first column gene
    > names as rownames)

    >> nonzero_row <- count_matrix[rowSums(count_matrix) > 0, # removed row sum
    > 0 across all sample

    >> x1= as.matrix(nonzero_row)                    # converted data into matrix

    >> x=log2(x1+1)                                          # converted into
    > log value
    >> d <- dist(x, method="euclidean")

    >> h <- hclust(d, method="complete")


    > *Error:*

    > *** caught segfault ***
    > address 0x7fa39060af28, cause 'memory not mapped'

    > Traceback:
    > 1: hclust(d, method = "complete")

    > Possible actions:
    > 1: abort (with core dump, if enabled)
    > 2: normal R exit
    > 3: exit R without saving workspace
    > 4: exit R saving workspace
    > Selection:

This looks like a problem that should not happen.
Though it could be that it's just too large a problem (for your
hardware, or "in general").
However, we cannot reproduce what you show above.

To help us help you please provide (to this mailing list!)

   - a (minimal) reproducible example
   - sessionInfo()

It is best to take time to carefully read
   https://www.r-proejct.org/help.html

and/or then just search "reproducible example R" :
       http://lmgtfy.com/?q=reproducible+example+R

Martin


    > Thanks
    > Yogesh


From Mike.Conklin at gfk.com  Fri Jun 23 15:50:04 2017
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Fri, 23 Jun 2017 13:50:04 +0000
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <22860.20544.997952.539978@losangelesyouthorchestra.org>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
 <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
 <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
 <37b169a8-a0c8-ea11-2925-7cc09777a203@gmail.com>
 <10a0d0f4d1f9448ca6a6140146943f13@IPXW-EXPCM02.gfk.com>
 <33a2feb8-94d0-24a4-4f58-30be332ee492@gmail.com>
 <6105f59fa7ab44a9bf882a2c7fbc2e2f@IPXW-EXPCM02.gfk.com>
 <ef8c365a-2960-88f7-9504-9cfd84150e66@gmail.com>
 <22860.20544.997952.539978@losangelesyouthorchestra.org>
Message-ID: <36fe980f336f431f8b46ab0a444cdbb0@IPXW-EXPCM02.gfk.com>

I had the same thought in the shower this morning but I was disappointed to find that SElinux was disabled on the system.  My next step will be to install a previous version of R on the system.  My problem is that I am planning a shiny server installation and at least half of the apps on the current system depend on these libraries that will not install.
--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK 
T +1 763 417 4545 | M +1 612 567 8287 

-----Original Message-----
From: Don Cohen [mailto:don-r-help at isis.cs3-inc.com] 
Sent: Thursday, June 22, 2017 6:18 PM
To: Duncan Murdoch
Cc: Conklin, Mike (GfK); Martin Maechler; r-help at r-project.org
Subject: Re: [R] Missing dependencies in pkg installs

Duncan Murdoch writes:
 > On 22/06/2017 5:02 PM, Conklin, Mike (GfK) wrote:
 > > I am using debug on the .install_packages function...stepping through. Once the temporary folder is created and the tar file expanded I run file_test and get a FALSE back indicating that the configure file is not executable.
 >
 > I don't know what is causing this bug.  Perhaps a Linux user can  > reproduce it and fix it.
 >
 > Here's what I see:
 >
 > file_test("-x") calls file.access(filename, 1L).  That in turn calls the  > C library function access(..., X_OK).  The ... is the name of the file,  > translated into the local encoding and expanded.  As far as I can see,  > that means ... should be exactly the string below.
 > >
 > > [1] "/tmp/RtmpMM6iC1/R.INSTALLc5ca415e4310/stringi"
 >
 > The only thing I can think of is that your system is protecting you from  > executing a newly created file until some sort of virus or other check  > is done.  (This is common on Windows, but I've never heard of it before  > on Linux.)

Just a thought - are you running SELinux ?
Check the log files for refusals to run programs.


From gliddeca at science.oregonstate.edu  Fri Jun 23 15:54:48 2017
From: gliddeca at science.oregonstate.edu (Caroline)
Date: Fri, 23 Jun 2017 06:54:48 -0700
Subject: [R] MODISTools help - with reproducible examples
In-Reply-To: <68AB503B-EC6F-470B-B03A-36C3F9D8741A@comcast.net>
References: <6D55A8BB-2AAB-4225-B10E-690D9AFE5714@science.oregonstate.edu>
 <68AB503B-EC6F-470B-B03A-36C3F9D8741A@comcast.net>
Message-ID: <53EEF327-EE9D-4630-90E3-C5D801082F75@science.oregonstate.edu>

I have and they have not yet replied - however that was only two or three days ago. 

I have included a code example. 
> On Jun 22, 2017, at 8:25 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Jun 22, 2017, at 4:44 PM, Caroline <gliddeca at science.oregonstate.edu> wrote:
>> 
>> I am using the R-package MODISTools (different than MODIS) and am having a lot of difficulty troubleshooting my code. I have spent awhile going through MODISTools tutorials, searching for my error code, looking at the source code. However, I have not been able to find any relevant information related to my error message. 
>> 
>> The study I am currently working on involves a herd of 200 African buffalo caught every six months for 4 years. I am trying to use EVI and NDVI to assess seasonal variation thus I would like mean EVI and NDVI for each observation (each time each buffalo was captured). I have capture date, lat and long for each observation. 
>> 
>> However, when using ?250m_16_days_pixel_reliability? as my quality control band I keep getting the warning message:
>> 
>> Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product = "MOD13Q1",  :
>> Only single data point that passed the quality screen: cannot summarise
>> 
>> When using ?250m_16_days_VI_Quality? as my quality control band I keep getting the warning message: 
>> 
>> Error in QualityCheck(Data = band.time.series, QualityScores = QA.time.series,  : 
>> QualityScores not all in range of MOD13Q1's QC: 0-3
>> 
>> I seem to get this message with all subsets of my data (I have tried running all of my data at once and then just one data point at a time). I have also tried using wider date ranges as well as wider size ranges (in case the pixel reliability is poor within a certain area or time frame) but still get the same messages. 
>> 
>> I have attached the data file I have been using as well as my code (subsetted to just one animal so the run time is faster) 
>> 
>> Has anyone seen this error message before/have any suggestions for why I may be getting these errors?
> 
> I don't and you have not provided the accepted means to investigate which would be code and data . Have you contacted the package maintainer?
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA


	[[alternative HTML version deleted]]


From fromnorden at gmail.com  Fri Jun 23 16:17:39 2017
From: fromnorden at gmail.com (Andreu Ferrero)
Date: Fri, 23 Jun 2017 16:17:39 +0200
Subject: [R] Plot survival curves after coxph() with frailty() random
	effects terms
Message-ID: <CAH2QH=dOuUJRtAD0Tvy0UNPv2er7Ox_54a+DfffvxSGjTtb1FQ@mail.gmail.com>

I would like to plot a survival curves of a group with different categories
after running a Cox model with frailty() random effects terms.

I just could display a survival plot of the covariable?s mean.



Here an example:



library(survival)

fit<-coxph(Surv(time, status) ~ sex+  frailty(litter, dist='gamma',
method='em'), rats)

summary(fit )

suf<-survfit(fit)

plot(suf,  xscale=1, xlab = "Days", ylab="Survival", conf.int=FALSE)

lines(suf[1], lwd=2)

Warning message:

In `[.survfit`(suf, 1) : survfit object has only a single survival curve



#But if I use the next code I get the 2 groups.

surv_group <- survfit(Surv(time, status) ~ sex, rats)

lines(surv_group[1:2], lwd=2, conf.int=FALSE)




However, I am not sure about these 2 curves are well done, appropriate.

If any of you could help?



-- 
Andreu Ferrero Gregori

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Jun 23 16:37:07 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 23 Jun 2017 07:37:07 -0700
Subject: [R] MODISTools help - with reproducible examples
In-Reply-To: <53EEF327-EE9D-4630-90E3-C5D801082F75@science.oregonstate.edu>
References: <6D55A8BB-2AAB-4225-B10E-690D9AFE5714@science.oregonstate.edu>
 <68AB503B-EC6F-470B-B03A-36C3F9D8741A@comcast.net>
 <53EEF327-EE9D-4630-90E3-C5D801082F75@science.oregonstate.edu>
Message-ID: <3CA2E3C1-07A9-4870-A3C0-D6B6BE10E3BC@dcn.davis.ca.us>

Please read up [1][2][3] on what constitutes reproducibility.  A sample of data that triggers the problem is essential. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html
-- 
Sent from my phone. Please excuse my brevity.

On June 23, 2017 6:54:48 AM PDT, Caroline <gliddeca at science.oregonstate.edu> wrote:
>I have and they have not yet replied - however that was only two or
>three days ago. 
>
>I have included a code example. 
>> On Jun 22, 2017, at 8:25 PM, David Winsemius <dwinsemius at comcast.net>
>wrote:
>> 
>>> 
>>> On Jun 22, 2017, at 4:44 PM, Caroline
><gliddeca at science.oregonstate.edu> wrote:
>>> 
>>> I am using the R-package MODISTools (different than MODIS) and am
>having a lot of difficulty troubleshooting my code. I have spent awhile
>going through MODISTools tutorials, searching for my error code,
>looking at the source code. However, I have not been able to find any
>relevant information related to my error message. 
>>> 
>>> The study I am currently working on involves a herd of 200 African
>buffalo caught every six months for 4 years. I am trying to use EVI and
>NDVI to assess seasonal variation thus I would like mean EVI and NDVI
>for each observation (each time each buffalo was captured). I have
>capture date, lat and long for each observation. 
>>> 
>>> However, when using ?250m_16_days_pixel_reliability? as my quality
>control band I keep getting the warning message:
>>> 
>>> Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product =
>"MOD13Q1",  :
>>> Only single data point that passed the quality screen: cannot
>summarise
>>> 
>>> When using ?250m_16_days_VI_Quality? as my quality control band I
>keep getting the warning message: 
>>> 
>>> Error in QualityCheck(Data = band.time.series, QualityScores =
>QA.time.series,  : 
>>> QualityScores not all in range of MOD13Q1's QC: 0-3
>>> 
>>> I seem to get this message with all subsets of my data (I have tried
>running all of my data at once and then just one data point at a time).
>I have also tried using wider date ranges as well as wider size ranges
>(in case the pixel reliability is poor within a certain area or time
>frame) but still get the same messages. 
>>> 
>>> I have attached the data file I have been using as well as my code
>(subsetted to just one animal so the run time is faster) 
>>> 
>>> Has anyone seen this error message before/have any suggestions for
>why I may be getting these errors?
>> 
>> I don't and you have not provided the accepted means to investigate
>which would be code and data . Have you contacted the package
>maintainer?
>> 
>> -- 
>> 
>> David Winsemius
>> Alameda, CA, USA
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gliddeca at science.oregonstate.edu  Fri Jun 23 16:50:57 2017
From: gliddeca at science.oregonstate.edu (Caroline)
Date: Fri, 23 Jun 2017 07:50:57 -0700
Subject: [R] MODISTools help - with reproducible examples
In-Reply-To: <3CA2E3C1-07A9-4870-A3C0-D6B6BE10E3BC@dcn.davis.ca.us>
References: <6D55A8BB-2AAB-4225-B10E-690D9AFE5714@science.oregonstate.edu>
 <68AB503B-EC6F-470B-B03A-36C3F9D8741A@comcast.net>
 <53EEF327-EE9D-4630-90E3-C5D801082F75@science.oregonstate.edu>
 <3CA2E3C1-07A9-4870-A3C0-D6B6BE10E3BC@dcn.davis.ca.us>
Message-ID: <33DF0BA4-8AC1-4148-BAC5-066247596604@science.oregonstate.edu>

In case anyone else experiences the same error:

The package creators responded and the issue was that I was using time frames between 14-30 days. EVI and NDVI are only calculated every 16 days so using that time span entailed that there was only one pixel per observation. I expanded my timeframe to 32 days and my analysis now works. 

I.E. changed:

firstobs$start.date <- firstobs[,2] - as.difftime(14, unit='days') ###time frame now spands two weeks

To

firstobs$start.date <- firstobs[,2] - as.difftime(32, unit='days') ###time frame now stands 32 days

Where first obs is the data set that contains the date that the data was collected, latitude, and longitude of collection site from one observation. I used the date the data was collected as the end date and transformed the date the data was collected to 32 days prior as the start date. 

firstobs before transformation:

 id start.date  end.date       lat   long
2 B1-1108  28-Nov-08 28-Nov-08 -25.07324 31.936

firstobs after transformation

 id start.date   end.date       lat   long
2 B1-1108 2008-10-27 2008-11-28 -25.07324 31.936

The key point is that the time frame used for analysis should be greater than or equal to 32 days. 

> On Jun 23, 2017, at 7:37 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Please read up [1][2][3] on what constitutes reproducibility.  A sample of data that triggers the problem is essential. 
> 
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> 
> [2] http://adv-r.had.co.nz/Reproducibility.html
> 
> [3] https://cran.r-project.org/web/packages/reprex/index.html
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On June 23, 2017 6:54:48 AM PDT, Caroline <gliddeca at science.oregonstate.edu> wrote:
>> I have and they have not yet replied - however that was only two or
>> three days ago. 
>> 
>> I have included a code example. 
>>> On Jun 22, 2017, at 8:25 PM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>>> 
>>>> 
>>>> On Jun 22, 2017, at 4:44 PM, Caroline
>> <gliddeca at science.oregonstate.edu> wrote:
>>>> 
>>>> I am using the R-package MODISTools (different than MODIS) and am
>> having a lot of difficulty troubleshooting my code. I have spent awhile
>> going through MODISTools tutorials, searching for my error code,
>> looking at the source code. However, I have not been able to find any
>> relevant information related to my error message. 
>>>> 
>>>> The study I am currently working on involves a herd of 200 African
>> buffalo caught every six months for 4 years. I am trying to use EVI and
>> NDVI to assess seasonal variation thus I would like mean EVI and NDVI
>> for each observation (each time each buffalo was captured). I have
>> capture date, lat and long for each observation. 
>>>> 
>>>> However, when using ?250m_16_days_pixel_reliability? as my quality
>> control band I keep getting the warning message:
>>>> 
>>>> Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product =
>> "MOD13Q1",  :
>>>> Only single data point that passed the quality screen: cannot
>> summarise
>>>> 
>>>> When using ?250m_16_days_VI_Quality? as my quality control band I
>> keep getting the warning message: 
>>>> 
>>>> Error in QualityCheck(Data = band.time.series, QualityScores =
>> QA.time.series,  : 
>>>> QualityScores not all in range of MOD13Q1's QC: 0-3
>>>> 
>>>> I seem to get this message with all subsets of my data (I have tried
>> running all of my data at once and then just one data point at a time).
>> I have also tried using wider date ranges as well as wider size ranges
>> (in case the pixel reliability is poor within a certain area or time
>> frame) but still get the same messages. 
>>>> 
>>>> I have attached the data file I have been using as well as my code
>> (subsetted to just one animal so the run time is faster) 
>>>> 
>>>> Has anyone seen this error message before/have any suggestions for
>> why I may be getting these errors?
>>> 
>>> I don't and you have not provided the accepted means to investigate
>> which would be code and data . Have you contacted the package
>> maintainer?
>>> 
>>> -- 
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From saubhagya at gatech.edu  Fri Jun 23 17:19:08 2017
From: saubhagya at gatech.edu (Rathore, Saubhagya Singh)
Date: Fri, 23 Jun 2017 15:19:08 +0000
Subject: [R] R version 3.3.2,
 Windows 10: Applying a function to each possible pair of rows from
 two different data-frames
In-Reply-To: <mailman.2763.1498229198.47836.r-help@r-project.org>
References: <mailman.2763.1498229198.47836.r-help@r-project.org>
Message-ID: <DM5PR07MB3179182A78ED597F88709C7BCFD80@DM5PR07MB3179.namprd07.prod.outlook.com>

For certain reason, the content was not visible in the last mail, so posting it again. 

Dear Members, 

I have two different dataframes with a different number of rows. I need to apply a set of functions to each possible combination of rows with one row coming from 1st dataframe and other from 2nd dataframe. Though I am able to perform this task using for loops, I feel that there must be a more efficient way to do it. An example case is given below. D1 and D2 are two dataframes. I need to evaluate D3 with one column as the Euclidean distance in the x-y plane and second column as squared difference of z values, of each row pair from D1 and D2.

D1<-data.frame(x=1:5,y=6:10,z=rnorm(5))
D2<-data.frame(x=19:30,y=41:52,z=rnorm(12))
D3<-data.frame(distance=integer(0),difference=integer(0))

for (i in 1:nrow(D1)){

for (j in 1:nrow(D2))  {

temp<-data.frame(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),difference=(D1[i,3]-D2[j,3])^2)
D3<-rbind(D3,temp)
}
}

Thank you

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of r-help-owner at r-project.org
Sent: Friday, June 23, 2017 10:47 AM
To: Rathore, Saubhagya Singh <saubhagya at gatech.edu>
Subject: R version 3.3.2, Windows 10: Applying a function to each possible pair of rows from two different data-frames

The message's content type was not explicitly allowed


From ruipbarradas at sapo.pt  Fri Jun 23 17:35:05 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 23 Jun 2017 16:35:05 +0100
Subject: [R] R version 3.3.2,
 Windows 10: Applying a function to each possible pair of rows from
 two different data-frames
In-Reply-To: <DM5PR07MB3179182A78ED597F88709C7BCFD80@DM5PR07MB3179.namprd07.prod.outlook.com>
References: <mailman.2763.1498229198.47836.r-help@r-project.org>
 <DM5PR07MB3179182A78ED597F88709C7BCFD80@DM5PR07MB3179.namprd07.prod.outlook.com>
Message-ID: <594D3529.3050106@sapo.pt>

Hello,

The obvious way would be to preallocate the resulting data.frame, to 
expand an empty one on each iteration being a time expensive operation.

n <- nrow(expand.grid(1:nrow(D1), 1:nrow(D2)))
D4 <- data.frame(distance=integer(n),difference=integer(n))
k <- 0
for (i in 1:nrow(D1)){
	for (j in 1:nrow(D2))  {
		k <- k + 1
		D4[k, ] <- 
c(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),difference=(D1[i,3]-D2[j,3])^2)
	}
}

identical(D3, D4)

Hope this helps,

Rui Barradas

Em 23-06-2017 16:19, Rathore, Saubhagya Singh escreveu:
> For certain reason, the content was not visible in the last mail, so posting it again.
>
> Dear Members,
>
> I have two different dataframes with a different number of rows. I need to apply a set of functions to each possible combination of rows with one row coming from 1st dataframe and other from 2nd dataframe. Though I am able to perform this task using for loops, I feel that there must be a more efficient way to do it. An example case is given below. D1 and D2 are two dataframes. I need to evaluate D3 with one column as the Euclidean distance in the x-y plane and second column as squared difference of z values, of each row pair from D1 and D2.
>
> D1<-data.frame(x=1:5,y=6:10,z=rnorm(5))
> D2<-data.frame(x=19:30,y=41:52,z=rnorm(12))
> D3<-data.frame(distance=integer(0),difference=integer(0))
>
> for (i in 1:nrow(D1)){
>
> for (j in 1:nrow(D2))  {
>
> temp<-data.frame(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),difference=(D1[i,3]-D2[j,3])^2)
> D3<-rbind(D3,temp)
> }
> }
>
> Thank you
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of r-help-owner at r-project.org
> Sent: Friday, June 23, 2017 10:47 AM
> To: Rathore, Saubhagya Singh <saubhagya at gatech.edu>
> Subject: R version 3.3.2, Windows 10: Applying a function to each possible pair of rows from two different data-frames
>
> The message's content type was not explicitly allowed
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rbaer at atsu.edu  Fri Jun 23 17:49:55 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Fri, 23 Jun 2017 10:49:55 -0500
Subject: [R] MODISTools Help
In-Reply-To: <9E61B562-C9FF-4B1E-AA0A-C129C8A9D3A2@science.oregonstate.edu>
References: <DEA13EBF-7DBA-49AF-9013-7352C97EF3CA@science.oregonstate.edu>
 <CAGxFJbTOwu6GaU8ozKKyAm9uCim_21u9UOb1RcCcr-TjnYNx0g@mail.gmail.com>
 <20297B7C-B925-4FB0-A3C7-B77076019B98@science.oregonstate.edu>
 <CAGxFJbQeqzMDg7VEmbdbABfdL-i1FciOiy_98StNe402zZ-_Dg@mail.gmail.com>
 <9E61B562-C9FF-4B1E-AA0A-C129C8A9D3A2@science.oregonstate.edu>
Message-ID: <815a4427-2d96-db44-426a-0ceed9653314@atsu.edu>



On 6/22/2017 7:05 PM, Caroline wrote:
> ##MODISTools example
> library(MODISTools)
> library(lubridate)
> setwd('~/Documents/Modis data')
>
> #####MODISTools with buffalo data
>
> ###Read in data rename for easier coding
> tbdata <- read.csv('~/Desktop/All TB data for EVI, NDVI.csv')
Since this dataset is only on your desktop it cannot help us reproduce 
your error.  Can you supply a small dataset that cause the
error you are talking about?

One way to do this is to use supply the results of
dput(tbdata)
if it is small enough.  If not, maybe create a subset of the data and 
then use dput()

Did you get the problem when you tried with the tutorial Bert suggested?
> firstobs <- subset(tbdata, capture.ID == 'B1-1108')
> firstobs <- firstobs[,c(1,2,2,3,4)]
> colnames(firstobs) <- c('id', 'start.date','end.date','lat','long')
>
> ###change date format and change start date to previous 14 days
> firstobs$start.date <- dmy(firstobs$start.date)
> firstobs$end.date <- dmy(firstobs$end.date)
> firstobs$start.date <- firstobs[,2] - as.difftime(14, unit='days') ###time frame now spands two weeks
>
> ###define parameters
> product <- "MOD13Q1"
> bands <- c('250m_16_days_EVI', '250m_16_days_NDVI', '250m_16_days_VI_Quality')
> pixel <- c(0,0)
>
> ###define data
> period <- data.frame(lat=firstobs$lat, long=firstobs$long, start.date =firstobs$start.date, end.date = firstobs$end.date, id=firstobs$id)
>
>
> ###MODISSubsets
> MODISSubsets(LoadDat = period, Products = product, Bands=bands, Size=pixel, SaveDir='.', StartDate=T)
>
>
> ###MODISSummaries
> MODISSummaries(LoadDat = period, FileSep=',',Product='MOD13Q1', Bands = '250m_16_days_EVI', ValidRange=c(-2000,10000), NoDataFill=-3000, ScaleFactor = 0.0001, StartDate = TRUE, Interpolate = T, QualityScreen = TRUE, QualityThreshold = 0, QualityBand = '250m_16_days_VI_Quality')
>
>
>> On Jun 22, 2017, at 4:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> 1. You should always cc the list unless there is a clear reason not to.
>>
>> 2. You still have failed to follow the posting guide: You say you have
>> difficulty troubleshooting your code, but you have shown us no code.
>> You got an error message that seems explicit, but with neither code
>> nor data, I do not know whether anyone can make sense of it. In any
>> case, I certainly cannot.
>>
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Jun 22, 2017 at 4:41 PM, Caroline
>> <gliddeca at science.oregonstate.edu> wrote:
>>> Hi Bert,
>>>
>>> I have spent a lot of time searching the web for my error message and have gone through multiple tutorials. I have not found anything relevant to my error message which is why I posted on R-help.
>>>
>>> Caroline
>>>
>>>> On Jun 22, 2017, at 4:38 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>
>>>> This is a specialized package that fairly few of us are likely to have
>>>> familiarity with, especialy when you have not followed the posting
>>>> guide (below) and posted code and a reproducible example.
>>>>
>>>> That said, a web search on R MODIS appeared to bring up relevant hits,
>>>> including a MODIS tutorial. Have you tried that?
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Thu, Jun 22, 2017 at 2:12 PM, Caroline
>>>> <gliddeca at science.oregonstate.edu> wrote:
>>>>> I am using MODIS Tools and am having a lot of difficulty troubleshooting my code.
>>>>>
>>>>> I am a PhD student studying African buffalo in Kruger National Park, South Africa. The study I am currently working on involves a herd of 200 African buffalo caught every six months for 4 years. I am trying to use EVI and NDVI to assess seasonal variation thus I would like mean EVI and NDVI for each observation (each time each buffalo was captured). I have capture date, lat and long for each observation.
>>>>>
>>>>> However, when using ?250m_16_days_pixel_reliability? as my quality control band I keep getting the warning message:
>>>>>
>>>>> Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product = "MOD13Q1",  :
>>>>> Only single data point that passed the quality screen: cannot summarise
>>>>>
>>>>> When using ?250m_16_days_VI_Quality? as my quality control band I keep getting the warning message:
>>>>>
>>>>> Error in QualityCheck(Data = band.time.series, QualityScores = QA.time.series,  :
>>>>> QualityScores not all in range of MOD13Q1's QC: 0-3
>>>>>
>>>>> I seem to get this message with all subsets of my data (I have tried running all of my data at once and then just one data point at a time). I have also tried using wider date ranges as well as wider size ranges (in case the pixel reliability is poor within a certain area or time frame) but still get the same messages.
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 


--
Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
660-626-2321 Department
660-626-2965 FAX


From erinm.hodgess at gmail.com  Fri Jun 23 17:56:53 2017
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 23 Jun 2017 10:56:53 -0500
Subject: [R] R and Paraview
Message-ID: <CACxE24kcWAuQ9RoFBzoiyTjrsvrYkiqy3aP+u1wBgVmtp=3Baw@mail.gmail.com>

Hello!

Are there any packages in R that work with the visualization tool Paraview,
please?  I looked via Google and couldn't find any but wanted to double
check before I started work on such a thing.

Thanks,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Fri Jun 23 18:02:38 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 23 Jun 2017 17:02:38 +0100
Subject: [R] R version 3.3.2,
 Windows 10: Applying a function to each possible pair of rows from
 two different data-frames
In-Reply-To: <594D3529.3050106@sapo.pt>
References: <mailman.2763.1498229198.47836.r-help@r-project.org>
 <DM5PR07MB3179182A78ED597F88709C7BCFD80@DM5PR07MB3179.namprd07.prod.outlook.com>
 <594D3529.3050106@sapo.pt>
Message-ID: <594D3B9E.1050602@sapo.pt>

Hello,

Another way would be

n <- nrow(expand.grid(1:nrow(D1), 1:nrow(D2)))
D5 <- data.frame(distance=integer(n),difference=integer(n))

D5[] <- do.call(rbind, lapply(seq_len(nrow(D1)), function(i) 
t(sapply(seq_len(nrow(D2)), function(j){
	 
c(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),difference=(D1[i,3]-D2[j,3])^2)
	}
))))

identical(D3, D5)


In my first answer I forgot to say that constructs like 1:nrow(...) or 
more generally 1:m are error prone. If m == 0 you will have the 
perfectly legal loop for(i in 1:0) but an illegal zero index.
The solution is to use ?seq_len or ?seq_along (same help page). Like 
this: for(i in seq_len(m)). In your case m is either nrow(D1) or nrow(D2).

Hope this helps,

Rui Barradas



Em 23-06-2017 16:35, Rui Barradas escreveu:
> Hello,
>
> The obvious way would be to preallocate the resulting data.frame, to
> expand an empty one on each iteration being a time expensive operation.
>
> n <- nrow(expand.grid(1:nrow(D1), 1:nrow(D2)))
> D4 <- data.frame(distance=integer(n),difference=integer(n))
> k <- 0
> for (i in 1:nrow(D1)){
>      for (j in 1:nrow(D2))  {
>          k <- k + 1
>          D4[k, ] <-
> c(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),difference=(D1[i,3]-D2[j,3])^2)
>
>      }
> }
>
> identical(D3, D4)
>
> Hope this helps,
>
> Rui Barradas
>
> Em 23-06-2017 16:19, Rathore, Saubhagya Singh escreveu:
>> For certain reason, the content was not visible in the last mail, so
>> posting it again.
>>
>> Dear Members,
>>
>> I have two different dataframes with a different number of rows. I
>> need to apply a set of functions to each possible combination of rows
>> with one row coming from 1st dataframe and other from 2nd dataframe.
>> Though I am able to perform this task using for loops, I feel that
>> there must be a more efficient way to do it. An example case is given
>> below. D1 and D2 are two dataframes. I need to evaluate D3 with one
>> column as the Euclidean distance in the x-y plane and second column as
>> squared difference of z values, of each row pair from D1 and D2.
>>
>> D1<-data.frame(x=1:5,y=6:10,z=rnorm(5))
>> D2<-data.frame(x=19:30,y=41:52,z=rnorm(12))
>> D3<-data.frame(distance=integer(0),difference=integer(0))
>>
>> for (i in 1:nrow(D1)){
>>
>> for (j in 1:nrow(D2))  {
>>
>> temp<-data.frame(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),difference=(D1[i,3]-D2[j,3])^2)
>>
>> D3<-rbind(D3,temp)
>> }
>> }
>>
>> Thank you
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> r-help-owner at r-project.org
>> Sent: Friday, June 23, 2017 10:47 AM
>> To: Rathore, Saubhagya Singh <saubhagya at gatech.edu>
>> Subject: R version 3.3.2, Windows 10: Applying a function to each
>> possible pair of rows from two different data-frames
>>
>> The message's content type was not explicitly allowed
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_grt at yahoo.fr  Fri Jun 23 18:21:45 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Fri, 23 Jun 2017 18:21:45 +0200
Subject: [R] optim() has a non-consistent way to send parameter for
 different methods
Message-ID: <74b073ca-4be0-fd9e-7881-98beea334aa3@yahoo.fr>

When optim() is used with method="BFGS", the name of parameters within 
the vector are transmitted (see below, first example).

When method="Brent", the name of parameter (only one parameter can be 
fitted with Brent method) is not transmitted. As there is only one, of 
course, we know which parameter it is, but it makes things 
non-consistent between methods.

It would be better that same convention is used for different method.

Marc

Tested in R-3.4.0

For example, here:

@@@@@@@@@@@
Method BFGS
@@@@@@@@@@@

# The names of values in par are transmitted
fitnorm_meansd<-function(par, val) {
   print(par)
   -sum(dnorm(x=val, mean=par["mean"], sd=par["sd"], log = TRUE))
}

val <- rnorm(100, mean=20, sd=2)
p<-c(mean=20, sd=2)
result<-optim(par=p, fn=fitnorm_meansd, val=val, method="BFGS")

The print(par) shows the named vector:
 > result<-optim(par=p, fn=fitnorm_meansd, val=val, method="BFGS")
mean   sd
   20    2
   mean     sd
20.001  2.000
   mean     sd
19.999  2.000
   mean     sd
20.000  2.001
etc...

@@@@@@@@@@@
Method Brent
@@@@@@@@@@@

# The name of value in par is not transmitted

fitnorm_mean<-function(par, val) {
   print(par)
   -sum(dnorm(x=val, mean=par, sd=2, log = TRUE))
}

val <- rnorm(100, mean=20, sd=2)
p<-c(mean=20)
result<-optim(par=p, fn=fitnorm_mean, val=val, method="Brent", lower=10, 
upper=30)


The print(par) does not show named vector:
 > result<-optim(par=p, fn=fitnorm_mean, val=val, method="Brent", 
lower=10, upper=30)
[1] 17.63932
[1] 22.36068


From yann.desjeux at inra.fr  Wed Jun 21 17:26:29 2017
From: yann.desjeux at inra.fr (Yann Desjeux)
Date: Wed, 21 Jun 2017 17:26:29 +0200
Subject: [R] [R-pkgs] New R package on CRAN: sfadv (v 1.0.1)
In-Reply-To: <02810bae-1a85-a4be-eece-d3a01c9f15c2@inra.fr>
References: <02810bae-1a85-a4be-eece-d3a01c9f15c2@inra.fr>
Message-ID: <44efc443-a00e-41fc-b213-94ce411cb66a@inra.fr>

Dear R users,


I am happy to announce that the R package 'sfadv: Advanced Methods for 
Stochastic Frontier Analysis' is now available on CRAN 
(https://CRAN.R-project.org/package=sfadv).

This package allows stochastic frontier analysis with advanced methods.
Particularly it implements newly developped method proposed by Latruffe 
et al. (2017) <doi:10.1093/ajae/aaw077> considering stochastic frontier 
analysis with technical inefficiency effects and endogeneity of one input.

Best regards,

Yann

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dreamscollector9 at gmail.com  Fri Jun 23 11:26:32 2017
From: dreamscollector9 at gmail.com (Dreams Collector)
Date: Fri, 23 Jun 2017 11:26:32 +0200
Subject: [R] Paired Weighted Wilcoxon test in R
Message-ID: <57B68802-850B-4B14-AD89-9713AC93DD67@gmail.com>

Dear R-users,

I?m trying to perform a non-parametric statistical pairwise comparison of two samples "x" and "y" using the Wilcoxon test in R, but each of the pairs have a weight associated.

An example of my data is the following one:

set.seed(9)
x <- sample(x = c(1:100), size = 20, replace = TRUE)
y <- sample(x = c(1:100), size = 20, replace = TRUE)
weight <- runif(n = 20)
data <- data.frame(x = x, y = y, weight = weight)

I?m new with statistical tests. I?ve read this other post about a similar issue:

http://r.789695.n4.nabble.com/Weighted-Mann-Whitney-Wilcoxon-Test-td4695699.html <http://r.789695.n4.nabble.com/Weighted-Mann-Whitney-Wilcoxon-Test-td4695699.html>

But I?m not sure if I can use the packages/works cited there.

Any help/comment would be fantastic for me.

Thank you!
	[[alternative HTML version deleted]]


From jsorkin at som.umaryland.edu  Fri Jun 23 13:06:53 2017
From: jsorkin at som.umaryland.edu (Sorkin, John)
Date: Fri, 23 Jun 2017 11:06:53 +0000
Subject: [R] Piecewise continuous logistic regression with one knot
Message-ID: <BY2PR0301MB06161C3F98A6B1C9561F9FC7E2D80@BY2PR0301MB0616.namprd03.prod.outlook.com>

How can I fit a piecewise continuous logistic regression with a single free knot (i.e. the knot is not specified; the model produce an estimate of the value of the knot).


Thank you,

John




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


	[[alternative HTML version deleted]]


From jayjay.1988 at hotmail.nl  Fri Jun 23 14:53:42 2017
From: jayjay.1988 at hotmail.nl (Jay Zola)
Date: Fri, 23 Jun 2017 12:53:42 +0000
Subject: [R] Comparing pooled proportions(complication and reoperation
 rates) of different treatment modalities
Message-ID: <VI1PR0501MB255798662C9F78C86548AB1D8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>

Dear sir/madame,


I am currently writing a meta-analysis on the complication and reoperation rates of 5 different treatment modalities after a distal radius fracture. I was able to pool the rates of the 5 different rates using R. Now I have to compare the pooled rates of the 4 treatment modalities with the golden standard separately. I though the chi squared test would be the best method. How do I do that using r. The R code I have used for the former calculation are added as a Word-file attachment. Your help would be highly appreciated.


Yours sincerely,


Student

From dwinsemius at comcast.net  Fri Jun 23 20:18:13 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 23 Jun 2017 11:18:13 -0700
Subject: [R] Comparing pooled proportions(complication and reoperation
	rates) of different treatment modalities
In-Reply-To: <VI1PR0501MB255798662C9F78C86548AB1D8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
References: <VI1PR0501MB255798662C9F78C86548AB1D8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
Message-ID: <FD8F4D70-CB3C-45D9-92F3-17BD008C7CF1@comcast.net>


> On Jun 23, 2017, at 5:53 AM, Jay Zola <jayjay.1988 at hotmail.nl> wrote:
> 
> Dear sir/madame,
> 
> 
> I am currently writing a meta-analysis on the complication and reoperation rates of 5 different treatment modalities after a distal radius fracture. I was able to pool the rates of the 5 different rates using R. Now I have to compare the pooled rates of the 4 treatment modalities with the golden standard separately. I though the chi squared test would be the best method. How do I do that using r. The R code I have used for the former calculation are added as a Word-file attachment.

Not an acceptable format to the listserv program. Policy is set by the host institution. Use plain text.

> Your help would be highly appreciated.
> 
> 
> Yours sincerely,
> 
> 
> Student
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Fri Jun 23 20:40:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 23 Jun 2017 11:40:52 -0700
Subject: [R] Piecewise continuous logistic regression with one knot
In-Reply-To: <BY2PR0301MB06161C3F98A6B1C9561F9FC7E2D80@BY2PR0301MB0616.namprd03.prod.outlook.com>
References: <BY2PR0301MB06161C3F98A6B1C9561F9FC7E2D80@BY2PR0301MB0616.namprd03.prod.outlook.com>
Message-ID: <CAGxFJbS2PhBHB1UdrZ8bOpKqn0s+rNE-ZVxormLZXwR5SeP8xA@mail.gmail.com>

A quick web search on "piecewise regression R" immediately brought up
(the fairly well known) package "segmented" which fits segmented
glm's.


-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 23, 2017 at 4:06 AM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> How can I fit a piecewise continuous logistic regression with a single free knot (i.e. the knot is not specified; the model produce an estimate of the value of the knot).
>
>
> Thank you,
>
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Jun 23 21:19:55 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 23 Jun 2017 12:19:55 -0700
Subject: [R] R version 3.3.2,
 Windows 10: Applying a function to each possible pair of rows from
 two different data-frames
In-Reply-To: <DM5PR07MB3179182A78ED597F88709C7BCFD80@DM5PR07MB3179.namprd07.prod.outlook.com>
References: <mailman.2763.1498229198.47836.r-help@r-project.org>
 <DM5PR07MB3179182A78ED597F88709C7BCFD80@DM5PR07MB3179.namprd07.prod.outlook.com>
Message-ID: <CAGxFJbQ6V4SmVjruMh=gmS5AXi2Bv5Atuj7Za2cOcMjpk0GXMQ@mail.gmail.com>

You appear to be trying to write C code in R. Don't do this. If you
can trade off space for efficiency, the calculation can be easily
vectorized (assuming I correctly understand what you want to do, of
course).

set.seed(135) ## for reproducibility
D1<-data.frame(x=1:5,y=6:10,z=rnorm(5))
D2<-data.frame(x=19:30,y=41:52,z=rnorm(12))

D.all <-merge(D1,D2, by.x=NULL,by.y=NULL) ## Cartesian product of the two frames

D.all$distance <- sqrt(rowSums((D.all[,1:2] - D.all[,4:5])^2)) ## note
use of rowSums
D.all$difference <- (D.all[,3] - D.all[,6])^2

D.all



Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 23, 2017 at 8:19 AM, Rathore, Saubhagya Singh
<saubhagya at gatech.edu> wrote:
> For certain reason, the content was not visible in the last mail, so posting it again.
>
> Dear Members,
>
> I have two different dataframes with a different number of rows. I need to apply a set of functions to each possible combination of rows with one row coming from 1st dataframe and other from 2nd dataframe. Though I am able to perform this task using for loops, I feel that there must be a more efficient way to do it. An example case is given below. D1 and D2 are two dataframes. I need to evaluate D3 with one column as the Euclidean distance in the x-y plane and second column as squared difference of z values, of each row pair from D1 and D2.
>
> D1<-data.frame(x=1:5,y=6:10,z=rnorm(5))
> D2<-data.frame(x=19:30,y=41:52,z=rnorm(12))
> D3<-data.frame(distance=integer(0),difference=integer(0))
>
> for (i in 1:nrow(D1)){
>
> for (j in 1:nrow(D2))  {
>
> temp<-data.frame(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),difference=(D1[i,3]-D2[j,3])^2)
> D3<-rbind(D3,temp)
> }
> }
>
> Thank you
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of r-help-owner at r-project.org
> Sent: Friday, June 23, 2017 10:47 AM
> To: Rathore, Saubhagya Singh <saubhagya at gatech.edu>
> Subject: R version 3.3.2, Windows 10: Applying a function to each possible pair of rows from two different data-frames
>
> The message's content type was not explicitly allowed
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From saubhagya at gatech.edu  Fri Jun 23 21:48:32 2017
From: saubhagya at gatech.edu (Rathore, Saubhagya Singh)
Date: Fri, 23 Jun 2017 19:48:32 +0000
Subject: [R] R version 3.3.2,
 Windows 10: Applying a function to each possible pair of rows from
 two different data-frames
In-Reply-To: <594D3B9E.1050602@sapo.pt>
References: <mailman.2763.1498229198.47836.r-help@r-project.org>
 <DM5PR07MB3179182A78ED597F88709C7BCFD80@DM5PR07MB3179.namprd07.prod.outlook.com>
 <594D3529.3050106@sapo.pt> <594D3B9E.1050602@sapo.pt>
Message-ID: <DM5PR07MB317987845139279C5B307671CFD80@DM5PR07MB3179.namprd07.prod.outlook.com>

Thank you very much Mr. Barradas for your suggestions. I feel embarrassed for not pre-allocating D3. Just pre-allocating D3 significantly reduced my run-time for code. My actual problem has both D1 and D2 consisting of 600 observations each.  Your second suggestion of using do.call proved to be better than using nested for loops. The run-times for my problem from both the methods are presented below.

1) Nested Loop with pre-allocation: 
#    user  system elapsed 
# 1199.89   14.08 1215.75

2) expand.grid- do.cal
# user  system elapsed 
# 131.56    0.00  131.61

Thank you again for your generous help.

-----Original Message-----
From: Rui Barradas [mailto:ruipbarradas at sapo.pt] 
Sent: Friday, June 23, 2017 12:03 PM
To: Rathore, Saubhagya Singh <saubhagya at gatech.edu>; r-help-owner at r-project.org; r-help at r-project.org
Subject: Re: [R] R version 3.3.2, Windows 10: Applying a function to each possible pair of rows from two different data-frames

Hello,

Another way would be

n <- nrow(expand.grid(1:nrow(D1), 1:nrow(D2)))
D5 <- data.frame(distance=integer(n),difference=integer(n))

D5[] <- do.call(rbind, lapply(seq_len(nrow(D1)), function(i) t(sapply(seq_len(nrow(D2)), function(j){
	 
c(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),difference=(D1[i,3]-D2[j,3])^2)
	}
))))

identical(D3, D5)


In my first answer I forgot to say that constructs like 1:nrow(...) or more generally 1:m are error prone. If m == 0 you will have the perfectly legal loop for(i in 1:0) but an illegal zero index.
The solution is to use ?seq_len or ?seq_along (same help page). Like
this: for(i in seq_len(m)). In your case m is either nrow(D1) or nrow(D2).

Hope this helps,

Rui Barradas



Em 23-06-2017 16:35, Rui Barradas escreveu:
> Hello,
>
> The obvious way would be to preallocate the resulting data.frame, to 
> expand an empty one on each iteration being a time expensive operation.
>
> n <- nrow(expand.grid(1:nrow(D1), 1:nrow(D2)))
> D4 <- data.frame(distance=integer(n),difference=integer(n))
> k <- 0
> for (i in 1:nrow(D1)){
>      for (j in 1:nrow(D2))  {
>          k <- k + 1
>          D4[k, ] <-
> c(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),difference=(D1[i,3]-D2[j
> ,3])^2)
>
>      }
> }
>
> identical(D3, D4)
>
> Hope this helps,
>
> Rui Barradas
>
> Em 23-06-2017 16:19, Rathore, Saubhagya Singh escreveu:
>> For certain reason, the content was not visible in the last mail, so 
>> posting it again.
>>
>> Dear Members,
>>
>> I have two different dataframes with a different number of rows. I 
>> need to apply a set of functions to each possible combination of rows 
>> with one row coming from 1st dataframe and other from 2nd dataframe.
>> Though I am able to perform this task using for loops, I feel that 
>> there must be a more efficient way to do it. An example case is given 
>> below. D1 and D2 are two dataframes. I need to evaluate D3 with one 
>> column as the Euclidean distance in the x-y plane and second column 
>> as squared difference of z values, of each row pair from D1 and D2.
>>
>> D1<-data.frame(x=1:5,y=6:10,z=rnorm(5))
>> D2<-data.frame(x=19:30,y=41:52,z=rnorm(12))
>> D3<-data.frame(distance=integer(0),difference=integer(0))
>>
>> for (i in 1:nrow(D1)){
>>
>> for (j in 1:nrow(D2))  {
>>
>> temp<-data.frame(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),differen
>> ce=(D1[i,3]-D2[j,3])^2)
>>
>> D3<-rbind(D3,temp)
>> }
>> }
>>
>> Thank you
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
>> r-help-owner at r-project.org
>> Sent: Friday, June 23, 2017 10:47 AM
>> To: Rathore, Saubhagya Singh <saubhagya at gatech.edu>
>> Subject: R version 3.3.2, Windows 10: Applying a function to each 
>> possible pair of rows from two different data-frames
>>
>> The message's content type was not explicitly allowed
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From saubhagya at gatech.edu  Fri Jun 23 21:53:32 2017
From: saubhagya at gatech.edu (Rathore, Saubhagya Singh)
Date: Fri, 23 Jun 2017 19:53:32 +0000
Subject: [R] R version 3.3.2,
 Windows 10: Applying a function to each possible pair of rows from
 two different data-frames
In-Reply-To: <CAGxFJbQ6V4SmVjruMh=gmS5AXi2Bv5Atuj7Za2cOcMjpk0GXMQ@mail.gmail.com>
References: <mailman.2763.1498229198.47836.r-help@r-project.org>
 <DM5PR07MB3179182A78ED597F88709C7BCFD80@DM5PR07MB3179.namprd07.prod.outlook.com>
 <CAGxFJbQ6V4SmVjruMh=gmS5AXi2Bv5Atuj7Za2cOcMjpk0GXMQ@mail.gmail.com>
Message-ID: <DM5PR07MB3179B35164438521781DD62ECFD80@DM5PR07MB3179.namprd07.prod.outlook.com>

Thank you very much Mr. Gunter for making me realize the power vectorization. I need to work lot more to exploit this strength of R. I applied your suggested method to my problem where D1 and D2 has 600 observations each. The time was significant reduced compared to the fasted working code I had (user:61, system: 0.01 ,  elapsed: 0.62).

Thank you again for your generous help. 
Saubhagya
  
-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Friday, June 23, 2017 3:20 PM
To: Rathore, Saubhagya Singh <saubhagya at gatech.edu>
Cc: r-help at r-project.org
Subject: Re: [R] R version 3.3.2, Windows 10: Applying a function to each possible pair of rows from two different data-frames

You appear to be trying to write C code in R. Don't do this. If you can trade off space for efficiency, the calculation can be easily vectorized (assuming I correctly understand what you want to do, of course).

set.seed(135) ## for reproducibility
D1<-data.frame(x=1:5,y=6:10,z=rnorm(5))
D2<-data.frame(x=19:30,y=41:52,z=rnorm(12))

D.all <-merge(D1,D2, by.x=NULL,by.y=NULL) ## Cartesian product of the two frames

D.all$distance <- sqrt(rowSums((D.all[,1:2] - D.all[,4:5])^2)) ## note use of rowSums D.all$difference <- (D.all[,3] - D.all[,6])^2

D.all



Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 23, 2017 at 8:19 AM, Rathore, Saubhagya Singh <saubhagya at gatech.edu> wrote:
> For certain reason, the content was not visible in the last mail, so posting it again.
>
> Dear Members,
>
> I have two different dataframes with a different number of rows. I need to apply a set of functions to each possible combination of rows with one row coming from 1st dataframe and other from 2nd dataframe. Though I am able to perform this task using for loops, I feel that there must be a more efficient way to do it. An example case is given below. D1 and D2 are two dataframes. I need to evaluate D3 with one column as the Euclidean distance in the x-y plane and second column as squared difference of z values, of each row pair from D1 and D2.
>
> D1<-data.frame(x=1:5,y=6:10,z=rnorm(5))
> D2<-data.frame(x=19:30,y=41:52,z=rnorm(12))
> D3<-data.frame(distance=integer(0),difference=integer(0))
>
> for (i in 1:nrow(D1)){
>
> for (j in 1:nrow(D2))  {
>
> temp<-data.frame(distance=sqrt(sum((D1[i,1:2]-D2[j,1:2])^2)),differenc
> e=(D1[i,3]-D2[j,3])^2)
> D3<-rbind(D3,temp)
> }
> }
>
> Thank you
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
> r-help-owner at r-project.org
> Sent: Friday, June 23, 2017 10:47 AM
> To: Rathore, Saubhagya Singh <saubhagya at gatech.edu>
> Subject: R version 3.3.2, Windows 10: Applying a function to each 
> possible pair of rows from two different data-frames
>
> The message's content type was not explicitly allowed
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From Mike.Conklin at gfk.com  Fri Jun 23 23:37:42 2017
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Fri, 23 Jun 2017 21:37:42 +0000
Subject: [R] Missing dependencies in pkg installs
In-Reply-To: <36fe980f336f431f8b46ab0a444cdbb0@IPXW-EXPCM02.gfk.com>
References: <4f246018a77f4669bd286f4858749546@IPXW-EXPCM02.gfk.com>
 <175B8DCA-009B-43DD-A208-420150BBBA12@comcast.net>
 <22859.29712.207244.909859@stat.math.ethz.ch>
 <e07c0731-1da3-6873-31c3-b0066f7eb8cb@gmail.com>
 <ffebcdc0ef21438db6c0725819403f81@IPXW-EXPCM02.gfk.com>
 <37b169a8-a0c8-ea11-2925-7cc09777a203@gmail.com>
 <10a0d0f4d1f9448ca6a6140146943f13@IPXW-EXPCM02.gfk.com>
 <33a2feb8-94d0-24a4-4f58-30be332ee492@gmail.com>
 <6105f59fa7ab44a9bf882a2c7fbc2e2f@IPXW-EXPCM02.gfk.com>
 <ef8c365a-2960-88f7-9504-9cfd84150e66@gmail.com>
 <22860.20544.997952.539978@losangelesyouthorchestra.org>,
 <36fe980f336f431f8b46ab0a444cdbb0@IPXW-EXPCM02.gfk.com>
Message-ID: <1498253862158.47650@gfk.com>

Checked all the permissions, and it appears that file_test returns a FALSE and system(ls -l) shows it is executable, so the problem seems to be in R and it's relationship to RHEL.  I tried installing R3.3.3 to see if the older version would install stringi and had the same problem so it doesn't appear to be R3.4 related.  I am now reaching out to some other sources who may have installed R on similar systems.


________________________________________
From: Conklin, Mike (GfK)
Sent: Friday, June 23, 2017 8:50 AM
To: Don Cohen; Duncan Murdoch
Cc: Martin Maechler; r-help at r-project.org
Subject: RE: [R] Missing dependencies in pkg installs

I had the same thought in the shower this morning but I was disappointed to find that SElinux was disabled on the system.  My next step will be to install a previous version of R on the system.  My problem is that I am planning a shiny server installation and at least half of the apps on the current system depend on these libraries that will not install.
--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK
T +1 763 417 4545 | M +1 612 567 8287

-----Original Message-----
From: Don Cohen [mailto:don-r-help at isis.cs3-inc.com]
Sent: Thursday, June 22, 2017 6:18 PM
To: Duncan Murdoch
Cc: Conklin, Mike (GfK); Martin Maechler; r-help at r-project.org
Subject: Re: [R] Missing dependencies in pkg installs

Duncan Murdoch writes:
 > On 22/06/2017 5:02 PM, Conklin, Mike (GfK) wrote:
 > > I am using debug on the .install_packages function...stepping through. Once the temporary folder is created and the tar file expanded I run file_test and get a FALSE back indicating that the configure file is not executable.
 >
 > I don't know what is causing this bug.  Perhaps a Linux user can  > reproduce it and fix it.
 >
 > Here's what I see:
 >
 > file_test("-x") calls file.access(filename, 1L).  That in turn calls the  > C library function access(..., X_OK).  The ... is the name of the file,  > translated into the local encoding and expanded.  As far as I can see,  > that means ... should be exactly the string below.
 > >
 > > [1] "/tmp/RtmpMM6iC1/R.INSTALLc5ca415e4310/stringi"
 >
 > The only thing I can think of is that your system is protecting you from  > executing a newly created file until some sort of virus or other check  > is done.  (This is common on Windows, but I've never heard of it before  > on Linux.)

Just a thought - are you running SELinux ?
Check the log files for refusals to run programs.


From gliddeca at science.oregonstate.edu  Fri Jun 23 23:47:25 2017
From: gliddeca at science.oregonstate.edu (Caroline)
Date: Fri, 23 Jun 2017 14:47:25 -0700
Subject: [R] MODISTools Help
In-Reply-To: <815a4427-2d96-db44-426a-0ceed9653314@atsu.edu>
References: <DEA13EBF-7DBA-49AF-9013-7352C97EF3CA@science.oregonstate.edu>
 <CAGxFJbTOwu6GaU8ozKKyAm9uCim_21u9UOb1RcCcr-TjnYNx0g@mail.gmail.com>
 <20297B7C-B925-4FB0-A3C7-B77076019B98@science.oregonstate.edu>
 <CAGxFJbQeqzMDg7VEmbdbABfdL-i1FciOiy_98StNe402zZ-_Dg@mail.gmail.com>
 <9E61B562-C9FF-4B1E-AA0A-C129C8A9D3A2@science.oregonstate.edu>
 <815a4427-2d96-db44-426a-0ceed9653314@atsu.edu>
Message-ID: <4457C976-E7CE-41D4-A9E9-77E2166FA810@science.oregonstate.edu>

In case anyone else experiences the same error: 

The package creators responded and the issue was that I was using time frames between 14-30 days. EVI and NDVI are only calculated every 16 days so using that time span entailed that there was only one pixel per observation. I expanded my timeframe to 32 days and my analysis now works. 

I.E. changed: 

firstobs$start.date <- firstobs[,2] - as.difftime(14, unit='days') ###time frame now spands two weeks 

To 

firstobs$start.date <- firstobs[,2] - as.difftime(32, unit='days') ###time frame now stands 32 days 

Where first obs is the data set that contains the date that the data was collected, latitude, and longitude of collection site from one observation. I used the date the data was collected as the end date and transformed the date the data was collected to 32 days prior as the start date. 

firstobs before transformation: 

 id            start.date  end.date       lat        long 
B1-1108  28-Nov-08 28-Nov-08 -25.07324 31.936 

firstobs after transformation 

 id          start.date     end.date       lat          long 
B1-1108 2008-10-27 2008-11-28 -25.07324 31.936 
> On Jun 23, 2017, at 8:49 AM, Robert Baer <rbaer at atsu.edu> wrote:
> 
> 
> 
> On 6/22/2017 7:05 PM, Caroline wrote:
>> ##MODISTools example
>> library(MODISTools)
>> library(lubridate)
>> setwd('~/Documents/Modis data')
>> 
>> #####MODISTools with buffalo data
>> 
>> ###Read in data rename for easier coding
>> tbdata <- read.csv('~/Desktop/All TB data for EVI, NDVI.csv')
> Since this dataset is only on your desktop it cannot help us reproduce your error.  Can you supply a small dataset that cause the
> error you are talking about?
> 
> One way to do this is to use supply the results of
> dput(tbdata)
> if it is small enough.  If not, maybe create a subset of the data and then use dput()
> 
> Did you get the problem when you tried with the tutorial Bert suggested?
>> firstobs <- subset(tbdata, capture.ID == 'B1-1108')
>> firstobs <- firstobs[,c(1,2,2,3,4)]
>> colnames(firstobs) <- c('id', 'start.date','end.date','lat','long')
>> 
>> ###change date format and change start date to previous 14 days
>> firstobs$start.date <- dmy(firstobs$start.date)
>> firstobs$end.date <- dmy(firstobs$end.date)
>> firstobs$start.date <- firstobs[,2] - as.difftime(14, unit='days') ###time frame now spands two weeks
>> 
>> ###define parameters
>> product <- "MOD13Q1"
>> bands <- c('250m_16_days_EVI', '250m_16_days_NDVI', '250m_16_days_VI_Quality')
>> pixel <- c(0,0)
>> 
>> ###define data
>> period <- data.frame(lat=firstobs$lat, long=firstobs$long, start.date =firstobs$start.date, end.date = firstobs$end.date, id=firstobs$id)
>> 
>> 
>> ###MODISSubsets
>> MODISSubsets(LoadDat = period, Products = product, Bands=bands, Size=pixel, SaveDir='.', StartDate=T)
>> 
>> 
>> ###MODISSummaries
>> MODISSummaries(LoadDat = period, FileSep=',',Product='MOD13Q1', Bands = '250m_16_days_EVI', ValidRange=c(-2000,10000), NoDataFill=-3000, ScaleFactor = 0.0001, StartDate = TRUE, Interpolate = T, QualityScreen = TRUE, QualityThreshold = 0, QualityBand = '250m_16_days_VI_Quality')
>> 
>> 
>>> On Jun 22, 2017, at 4:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 
>>> 1. You should always cc the list unless there is a clear reason not to.
>>> 
>>> 2. You still have failed to follow the posting guide: You say you have
>>> difficulty troubleshooting your code, but you have shown us no code.
>>> You got an error message that seems explicit, but with neither code
>>> nor data, I do not know whether anyone can make sense of it. In any
>>> case, I certainly cannot.
>>> 
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Thu, Jun 22, 2017 at 4:41 PM, Caroline
>>> <gliddeca at science.oregonstate.edu> wrote:
>>>> Hi Bert,
>>>> 
>>>> I have spent a lot of time searching the web for my error message and have gone through multiple tutorials. I have not found anything relevant to my error message which is why I posted on R-help.
>>>> 
>>>> Caroline
>>>> 
>>>>> On Jun 22, 2017, at 4:38 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>> 
>>>>> This is a specialized package that fairly few of us are likely to have
>>>>> familiarity with, especialy when you have not followed the posting
>>>>> guide (below) and posted code and a reproducible example.
>>>>> 
>>>>> That said, a web search on R MODIS appeared to bring up relevant hits,
>>>>> including a MODIS tutorial. Have you tried that?
>>>>> 
>>>>> Cheers,
>>>>> Bert
>>>>> 
>>>>> 
>>>>> Bert Gunter
>>>>> 
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> 
>>>>> 
>>>>> On Thu, Jun 22, 2017 at 2:12 PM, Caroline
>>>>> <gliddeca at science.oregonstate.edu> wrote:
>>>>>> I am using MODIS Tools and am having a lot of difficulty troubleshooting my code.
>>>>>> 
>>>>>> I am a PhD student studying African buffalo in Kruger National Park, South Africa. The study I am currently working on involves a herd of 200 African buffalo caught every six months for 4 years. I am trying to use EVI and NDVI to assess seasonal variation thus I would like mean EVI and NDVI for each observation (each time each buffalo was captured). I have capture date, lat and long for each observation.
>>>>>> 
>>>>>> However, when using ?250m_16_days_pixel_reliability? as my quality control band I keep getting the warning message:
>>>>>> 
>>>>>> Warning in MODISSummaries(LoadDat = period, FileSep = ",", Product = "MOD13Q1",  :
>>>>>> Only single data point that passed the quality screen: cannot summarise
>>>>>> 
>>>>>> When using ?250m_16_days_VI_Quality? as my quality control band I keep getting the warning message:
>>>>>> 
>>>>>> Error in QualityCheck(Data = band.time.series, QualityScores = QA.time.series,  :
>>>>>> QualityScores not all in range of MOD13Q1's QC: 0-3
>>>>>> 
>>>>>> I seem to get this message with all subsets of my data (I have tried running all of my data at once and then just one data point at a time). I have also tried using wider date ranges as well as wider size ranges (in case the pixel reliability is poor within a certain area or time frame) but still get the same messages.
>>>>>>       [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> 
> 
> --
> Robert W. Baer, Ph.D.
> Professor of Physiology
> Kirksville College of Osteopathic Medicine
> A T Still University of Health Sciences
> 800 W. Jefferson St
> Kirksville, MO 63501
> 660-626-2321 Department
> 660-626-2965 FAX


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun 23 20:33:19 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 23 Jun 2017 11:33:19 -0700
Subject: [R] Comparing pooled proportions(complication and reoperation
 rates) of different treatment modalities
In-Reply-To: <VI1PR0501MB255798662C9F78C86548AB1D8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
References: <VI1PR0501MB255798662C9F78C86548AB1D8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
Message-ID: <CAGxFJbS_RVii8TARUEHEuThgQC8zSiBX6y1XKuZhKuuaEzu4xQ@mail.gmail.com>

Probably the wrong list. R-help is concerned with R programming, not
statistics methodology questions, although the intersection can be
nonempty.

I suggest you post on stats.stackexchange.com instead, which *is*
concerned with statistics methodology questions.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 23, 2017 at 5:53 AM, Jay Zola <jayjay.1988 at hotmail.nl> wrote:
> Dear sir/madame,
>
>
> I am currently writing a meta-analysis on the complication and reoperation rates of 5 different treatment modalities after a distal radius fracture. I was able to pool the rates of the 5 different rates using R. Now I have to compare the pooled rates of the 4 treatment modalities with the golden standard separately. I though the chi squared test would be the best method. How do I do that using r. The R code I have used for the former calculation are added as a Word-file attachment. Your help would be highly appreciated.
>
>
> Yours sincerely,
>
>
> Student
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Lewis.Leslie at cranfield.ac.uk  Fri Jun 23 21:12:56 2017
From: Lewis.Leslie at cranfield.ac.uk (Leslie, Lewis)
Date: Fri, 23 Jun 2017 19:12:56 +0000
Subject: [R] DEA: BCC input oriented
Message-ID: <HE1PR0101MB224966D086593669F0FFEF86CAD80@HE1PR0101MB2249.eurprd01.prod.exchangelabs.com>

Dear R users,

If anyone could give me a hand coding some airline finance data that I want to do a DEA on using a BCC input oriented primal code that would be much appreciated.

Kind regards,

Lewis Leslie

Get Outlook for iOS<https://aka.ms/o0ukef>

	[[alternative HTML version deleted]]


From dengxianda2007 at hotmail.com  Fri Jun 23 21:26:49 2017
From: dengxianda2007 at hotmail.com (xianda deng)
Date: Fri, 23 Jun 2017 19:26:49 +0000
Subject: [R] Execute R codes without installing R environment
Message-ID: <DM5PR12MB1402AA306C5E5CDA7B6BDF50D9D80@DM5PR12MB1402.namprd12.prod.outlook.com>

Hi,


I have some issues with running R in our server and hope you would like to help me.


My Target: Running R codes without installing R environment in our server. Server OS: windows


my attempts: I tried to build the R codes into a Binary package with R studio, but I don't how to execute the binary package(*.zip file).


My questions:  1. Is this a correct solution, which builds the R codes into a binary file, to run a R codes without installing R environment?

                             2. If answer for question 1 is yes, how should I execute or call the R script?

                            3. Is any another way to achieve my goal?


Thanks!


Sincerely


Daniel

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun 23 21:38:09 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 23 Jun 2017 12:38:09 -0700
Subject: [R] Comparing pooled proportions(complication and reoperation
 rates) of different treatment modalities
In-Reply-To: <VI1PR0501MB25572135C80F228C8AF8CC9E8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
References: <VI1PR0501MB255798662C9F78C86548AB1D8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
 <CAGxFJbS_RVii8TARUEHEuThgQC8zSiBX6y1XKuZhKuuaEzu4xQ@mail.gmail.com>
 <VI1PR0501MB255750014CFB0FF982A46A1F8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
 <CAGxFJbQRqreMorE6UgE0SaKSzxmjTZHQP0KeGFobcpNUNLYxLQ@mail.gmail.com>
 <VI1PR0501MB25572135C80F228C8AF8CC9E8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
Message-ID: <CAGxFJbSmpJ+Fd=_y35DDwwYzfhw20x_stOPVs9n==RDLp7y-Dg@mail.gmail.com>

1. You neglected to cc r-help!

2. Word files are **not** text files.


-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jun 23, 2017 at 12:23 PM, Jay Zola <jayjay.1988 at hotmail.nl> wrote:

> Dear sir,
>
>
> This is the link of the page were I asked my question initially before I
> was redirected to the r-help mailing list. Hopefully someone can help me
> with my question. I read the guideline on not posting binary files and
> therefore taught it was ok to send text files like word files. I do
> apologize.
>
>
> Yours sincerely,
>
>
> Anand
>
>
>
> https://stats.stackexchange.com/questions/286920/
> comparing-pooled-propotions-using-r-for-a-meta-analysis
>
>
> <https://stats.stackexchange.com/questions/286920/comparing-pooled-propotions-using-r-for-a-meta-analysis>
> Comparing pooled propotions using R for a meta-analysis
> <https://stats.stackexchange.com/questions/286920/comparing-pooled-propotions-using-r-for-a-meta-analysis>
> stats.stackexchange.com
> For a meta-analysis I have pooled single proportions(complication rates)
> of several treatment methods. Now I would like to compare them(the 4
> treatment modalities separately with the golden standar...
>
>
>
>
>
> ------------------------------
> *Van:* Bert Gunter <bgunter.4567 at gmail.com>
> *Verzonden:* vrijdag 23 juni 2017 20:51
> *Aan:* Jay Zola
> *Onderwerp:* Re: [R] Comparing pooled proportions(complication and
> reoperation rates) of different treatment modalities
>
> Then you will have to at least read and follow the posting guide,
> which you have not done. As you have been told, your current post is
> unacceptable.
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Jun 23, 2017 at 11:41 AM, Jay Zola <jayjay.1988 at hotmail.nl> wrote:
> > Dear sir,
> >
> > I have posted it on stats.stackexchange. But got the answer to post it
> on this place. I added my question to r-help before it was posted later in
> the evening. Somebody checked the question and taught it was appropriate
> for r-help. Your help would be highly appreciated. And Thank you for your
> fast reply.
> >
> > Yours sincerely,
> >
> > Jay
> >
> >
>

	[[alternative HTML version deleted]]


From jayjay.1988 at hotmail.nl  Fri Jun 23 21:59:51 2017
From: jayjay.1988 at hotmail.nl (Jay Zola)
Date: Fri, 23 Jun 2017 19:59:51 +0000
Subject: [R] Comparing pooled proportions(complication and reoperation
 rates) of different treatment modalities
In-Reply-To: <FD8F4D70-CB3C-45D9-92F3-17BD008C7CF1@comcast.net>
References: <VI1PR0501MB255798662C9F78C86548AB1D8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>,
 <FD8F4D70-CB3C-45D9-92F3-17BD008C7CF1@comcast.net>
Message-ID: <VI1PR0501MB25573C4B6F4E068E405FB1A68AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>

Dear sir/madame,


Currently I am writing a meta analysis on complications and reoperations of 5 treatment modalities after an extra-articular distal radius fracture. The treatment modalities are EF, IMN, KW, VPO and PC as the golden standard. We have included 22 studies, 10 RCTs and 12 prospective studies. All examining different treatment methods. We retrieved the data out of these studies and pooled the complication and reoperation rates(n/N). Now we want to compare the pooled proportion of each treatment modality to the golden standard of PC(plaster casting). So I want to do 4 separate comparisons using the chi squared method. I looked it up online and at the meta package guide(meta is the package I used), but wasn't able to find useful information. I first posted my question onto the stats.stackexchange website but was redirected to the mailing list of r-help. I have added a picture of the most important parts of the code (not the egger's regression, funnel, trim and fill and outcome.pdf parts of it because it didn't fit). I have added the data in excel and spss file to my dropbox, and added the complete Rcode to a Word file in my dropbox as well. The links below will refer you to them as preferred by the posting guide. Hopefully someone can help me.


Thank you very much.



Excel datafile: https://www.dropbox.com/s/19402gt0x1agt9f/Excel%20file%20Distal%20Radius%20Fracture%20basic.xlsx?dl=0

Excel file Distal Radius Fracture basic.xlsx<https://www.dropbox.com/s/19402gt0x1agt9f/Excel%20file%20Distal%20Radius%20Fracture%20basic.xlsx?dl=0>
www.dropbox.com
Shared with Dropbox



SPSS datafile: https://www.dropbox.com/s/h81pphxkfk74hzo/Meta-Analyse%20Complications%20and%20Reoperations.sav?dl=0

[https://cfl.dropboxstatic.com/static/images/icons128/page_white.png]<https://www.dropbox.com/s/h81pphxkfk74hzo/Meta-Analyse%20Complications%20and%20Reoperations.sav?dl=0>

Meta-Analyse Complications and Reoperations.sav<https://www.dropbox.com/s/h81pphxkfk74hzo/Meta-Analyse%20Complications%20and%20Reoperations.sav?dl=0>
www.dropbox.com
Shared with Dropbox


Rcode file Word: https://www.dropbox.com/s/67pnfpi10qu110v/R%20code%20voor%20forrest%20en%20funnel%20plots.rtf?dl=0

[https://cfl.dropboxstatic.com/static/images/icons128/page_white_word.png]<https://www.dropbox.com/s/67pnfpi10qu110v/R%20code%20voor%20forrest%20en%20funnel%20plots.rtf?dl=0>

R code voor forrest en funnel plots.rtf<https://www.dropbox.com/s/67pnfpi10qu110v/R%20code%20voor%20forrest%20en%20funnel%20plots.rtf?dl=0>
www.dropbox.com
Shared with Dropbox





https://stats.stackexchange.com/questions/286920/comparing-pooled-propotions-using-r-for-a-meta-analysis

[https://cdn.sstatic.net/Sites/stats/img/apple-touch-icon at 2.png?v=344f57aa10cc]<https://stats.stackexchange.com/questions/286920/comparing-pooled-propotions-using-r-for-a-meta-analysis>

Comparing pooled propotions using R for a meta-analysis<https://stats.stackexchange.com/questions/286920/comparing-pooled-propotions-using-r-for-a-meta-analysis>
stats.stackexchange.com
For a meta-analysis I have pooled single proportions(complication rates) of several treatment methods. Now I would like to compare them(the 4 treatment modalities separately with the golden standar...







________________________________
Van: David Winsemius <dwinsemius at comcast.net>
Verzonden: vrijdag 23 juni 2017 20:18
Aan: Jay Zola
CC: r-help at r-project.org
Onderwerp: Re: [R] Comparing pooled proportions(complication and reoperation rates) of different treatment modalities


> On Jun 23, 2017, at 5:53 AM, Jay Zola <jayjay.1988 at hotmail.nl> wrote:
>
> Dear sir/madame,
>
>
> I am currently writing a meta-analysis on the complication and reoperation rates of 5 different treatment modalities after a distal radius fracture. I was able to pool the rates of the 5 different rates using R. Now I have to compare the pooled rates of the 4 treatment modalities with the golden standard separately. I though the chi squared test would be the best method. How do I do that using r. The R code I have used for the former calculation are added as a Word-file attachment.

Not an acceptable format to the listserv program. Policy is set by the host institution. Use plain text.

> Your help would be highly appreciated.
>
>
> Yours sincerely,
>
>
> Student
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help


thz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


	[[alternative HTML version deleted]]


From m.ashton at enduringinvestments.com  Fri Jun 23 22:00:58 2017
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Fri, 23 Jun 2017 20:00:58 +0000
Subject: [R] Simple control structure issue
Message-ID: <6d666c5f81924c539a00f86b3859aa07@MBX084-W1-CA-3.exch084.serverpod.net>

I am having a hard time with 'next'. I come from the "sloppy" school that learned BASIC with Goto.

Conceptually next seems pretty straightforward. I just can't get it to work correctly in my code. Here's a stripped down version:

WhichRunNow<-"Daily"
Cnums=c(0,1,"2b3")
Cpers=c("Daily","Daily","Weekly")

for (j in (1:length(Cnums))) {
     If (!identical(Cpers[j],WhichRunNow)){
           next
           }
     print(j)
}

So, this should print the number "3", which it does. It prints 3 because "WhichRunNow" is "Daily", and only for j=3 is Cpers[j] not identical to "Daily". But R seems very unhappy with how it gets there:

> WhichRunNow<-"Daily"
> Cnums=c(0,1,"2b3")
> Cpers=c("Daily","Daily","Weekly")
>
> for (j in (1:length(Cnums))) {
+ If (!identical(Cpers[j],WhichRunNow)){
Error: unexpected '{' in:
"for (j in (1:length(Cnums))) {
If (!identical(Cpers[j],WhichRunNow)){"
> next
Error: no loop for break/next, jumping to top level
> }
Error: unexpected '}' in "}"
> print(j)
[1] 3
> }
Error: unexpected '}' in "}"
>

Obviously something with my syntax, but I can't see what I'm doing wrong!


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat Jun 24 00:14:37 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 23 Jun 2017 15:14:37 -0700
Subject: [R] Simple control structure issue
In-Reply-To: <6d666c5f81924c539a00f86b3859aa07@MBX084-W1-CA-3.exch084.serverpod.net>
References: <6d666c5f81924c539a00f86b3859aa07@MBX084-W1-CA-3.exch084.serverpod.net>
Message-ID: <CAF8bMcb=tZw--gGT5drW2bP1rodiya2uWwKLxBVfgzyRObKzFg@mail.gmail.com>

R is a case-sensitive language: 'if' (lowercase 'i') is a keyword and 'If'
(uppercase 'I') is not.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jun 23, 2017 at 1:00 PM, Michael Ashton <
m.ashton at enduringinvestments.com> wrote:

> I am having a hard time with 'next'. I come from the "sloppy" school that
> learned BASIC with Goto.
>
> Conceptually next seems pretty straightforward. I just can't get it to
> work correctly in my code. Here's a stripped down version:
>
> WhichRunNow<-"Daily"
> Cnums=c(0,1,"2b3")
> Cpers=c("Daily","Daily","Weekly")
>
> for (j in (1:length(Cnums))) {
>      If (!identical(Cpers[j],WhichRunNow)){
>            next
>            }
>      print(j)
> }
>
> So, this should print the number "3", which it does. It prints 3 because
> "WhichRunNow" is "Daily", and only for j=3 is Cpers[j] not identical to
> "Daily". But R seems very unhappy with how it gets there:
>
> > WhichRunNow<-"Daily"
> > Cnums=c(0,1,"2b3")
> > Cpers=c("Daily","Daily","Weekly")
> >
> > for (j in (1:length(Cnums))) {
> + If (!identical(Cpers[j],WhichRunNow)){
> Error: unexpected '{' in:
> "for (j in (1:length(Cnums))) {
> If (!identical(Cpers[j],WhichRunNow)){"
> > next
> Error: no loop for break/next, jumping to top level
> > }
> Error: unexpected '}' in "}"
> > print(j)
> [1] 3
> > }
> Error: unexpected '}' in "}"
> >
>
> Obviously something with my syntax, but I can't see what I'm doing wrong!
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m.ashton at enduringinvestments.com  Sat Jun 24 00:18:30 2017
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Fri, 23 Jun 2017 22:18:30 +0000
Subject: [R] Simple control structure issue
In-Reply-To: <CAF8bMcb=tZw--gGT5drW2bP1rodiya2uWwKLxBVfgzyRObKzFg@mail.gmail.com>
References: <6d666c5f81924c539a00f86b3859aa07@MBX084-W1-CA-3.exch084.serverpod.net>
 <CAF8bMcb=tZw--gGT5drW2bP1rodiya2uWwKLxBVfgzyRObKzFg@mail.gmail.com>
Message-ID: <23c9176050f446cf852cab064cf8bc91@MBX084-W1-CA-3.exch084.serverpod.net>

SONOFAGUN?I?m a bit embarrassed. Thanks Bill!

From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Friday, June 23, 2017 6:15 PM
To: Michael Ashton
Cc: r-help at r-project.org
Subject: Re: [R] Simple control structure issue

R is a case-sensitive language: 'if' (lowercase 'i') is a keyword and 'If' (uppercase 'I') is not.

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Fri, Jun 23, 2017 at 1:00 PM, Michael Ashton <m.ashton at enduringinvestments.com<mailto:m.ashton at enduringinvestments.com>> wrote:
I am having a hard time with 'next'. I come from the "sloppy" school that learned BASIC with Goto.

Conceptually next seems pretty straightforward. I just can't get it to work correctly in my code. Here's a stripped down version:

WhichRunNow<-"Daily"
Cnums=c(0,1,"2b3")
Cpers=c("Daily","Daily","Weekly")

for (j in (1:length(Cnums))) {
     If (!identical(Cpers[j],WhichRunNow)){
           next
           }
     print(j)
}

So, this should print the number "3", which it does. It prints 3 because "WhichRunNow" is "Daily", and only for j=3 is Cpers[j] not identical to "Daily". But R seems very unhappy with how it gets there:

> WhichRunNow<-"Daily"
> Cnums=c(0,1,"2b3")
> Cpers=c("Daily","Daily","Weekly")
>
> for (j in (1:length(Cnums))) {
+ If (!identical(Cpers[j],WhichRunNow)){
Error: unexpected '{' in:
"for (j in (1:length(Cnums))) {
If (!identical(Cpers[j],WhichRunNow)){"
> next
Error: no loop for break/next, jumping to top level
> }
Error: unexpected '}' in "}"
> print(j)
[1] 3
> }
Error: unexpected '}' in "}"
>

Obviously something with my syntax, but I can't see what I'm doing wrong!


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Jun 24 09:57:39 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 24 Jun 2017 17:57:39 +1000
Subject: [R] Paired Weighted Wilcoxon test in R
In-Reply-To: <57B68802-850B-4B14-AD89-9713AC93DD67@gmail.com>
References: <57B68802-850B-4B14-AD89-9713AC93DD67@gmail.com>
Message-ID: <CA+8X3fV_iuuTEet7Yu4nZdbuWkcciKuWkH0BFvSOhPxMiqgQZg@mail.gmail.com>

Hi DC9,
As no one has answered, I would say that as both the survey package
and Professor Lumley are widely respected, that is as good as it gets.

Jim

On Fri, Jun 23, 2017 at 7:26 PM, Dreams Collector
<dreamscollector9 at gmail.com> wrote:
> Dear R-users,
>
> I?m trying to perform a non-parametric statistical pairwise comparison of two samples "x" and "y" using the Wilcoxon test in R, but each of the pairs have a weight associated.
>
> An example of my data is the following one:
>
> set.seed(9)
> x <- sample(x = c(1:100), size = 20, replace = TRUE)
> y <- sample(x = c(1:100), size = 20, replace = TRUE)
> weight <- runif(n = 20)
> data <- data.frame(x = x, y = y, weight = weight)
>
> I?m new with statistical tests. I?ve read this other post about a similar issue:
>
> http://r.789695.n4.nabble.com/Weighted-Mann-Whitney-Wilcoxon-Test-td4695699.html <http://r.789695.n4.nabble.com/Weighted-Mann-Whitney-Wilcoxon-Test-td4695699.html>
>
> But I?m not sure if I can use the packages/works cited there.
>
> Any help/comment would be fantastic for me.
>
> Thank you!
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Jun 24 10:50:27 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 24 Jun 2017 18:50:27 +1000
Subject: [R] Execute R codes without installing R environment
In-Reply-To: <DM5PR12MB1402AA306C5E5CDA7B6BDF50D9D80@DM5PR12MB1402.namprd12.prod.outlook.com>
References: <DM5PR12MB1402AA306C5E5CDA7B6BDF50D9D80@DM5PR12MB1402.namprd12.prod.outlook.com>
Message-ID: <CA+8X3fWfbFF5DDYR1Ovp5iJZiszpG72vXANLBPUDz5=+Tp1LQw@mail.gmail.com>

Hi Daniel,
There seems to be a way to package the R interpreter and a program
into an executable file. It looks pretty complicated and would only be
worth the effort if you _must_ run your script this way and you
_can't_ install R.

https://www.r-bloggers.com/deploying-desktop-apps-with-r/

Jim


On Sat, Jun 24, 2017 at 5:26 AM, xianda deng <dengxianda2007 at hotmail.com> wrote:
> Hi,
>
>
> I have some issues with running R in our server and hope you would like to help me.
>
>
> My Target: Running R codes without installing R environment in our server. Server OS: windows
>
>
> my attempts: I tried to build the R codes into a Binary package with R studio, but I don't how to execute the binary package(*.zip file).
>
>
> My questions:  1. Is this a correct solution, which builds the R codes into a binary file, to run a R codes without installing R environment?
>
>                              2. If answer for question 1 is yes, how should I execute or call the R script?
>
>                             3. Is any another way to achieve my goal?
>
>
> Thanks!
>
>
> Sincerely
>
>
> Daniel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Sat Jun 24 14:18:20 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sat, 24 Jun 2017 13:18:20 +0100
Subject: [R] Comparing pooled proportions(complication and reoperation
 rates) of different treatment modalities
In-Reply-To: <CAGxFJbS_RVii8TARUEHEuThgQC8zSiBX6y1XKuZhKuuaEzu4xQ@mail.gmail.com>
References: <VI1PR0501MB255798662C9F78C86548AB1D8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
 <CAGxFJbS_RVii8TARUEHEuThgQC8zSiBX6y1XKuZhKuuaEzu4xQ@mail.gmail.com>
Message-ID: <e99d7f2b-a92f-2fe2-bd72-418c2fe0c898@dewey.myzen.co.uk>

Note though that this has been put on hold on stats.stackexchange.com as 
off-topic.

On 23/06/2017 19:33, Bert Gunter wrote:
> Probably the wrong list. R-help is concerned with R programming, not
> statistics methodology questions, although the intersection can be
> nonempty.
>
> I suggest you post on stats.stackexchange.com instead, which *is*
> concerned with statistics methodology questions.
>
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Jun 23, 2017 at 5:53 AM, Jay Zola <jayjay.1988 at hotmail.nl> wrote:
>> Dear sir/madame,
>>
>>
>> I am currently writing a meta-analysis on the complication and reoperation rates of 5 different treatment modalities after a distal radius fracture. I was able to pool the rates of the 5 different rates using R. Now I have to compare the pooled rates of the 4 treatment modalities with the golden standard separately. I though the chi squared test would be the best method. How do I do that using r. The R code I have used for the former calculation are added as a Word-file attachment. Your help would be highly appreciated.
>>
>>
>> Yours sincerely,
>>
>>
>> Student
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ---
> This email has been checked for viruses by AVG.
> http://www.avg.com
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil at dcn.davis.ca.us  Sat Jun 24 15:27:50 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 24 Jun 2017 06:27:50 -0700
Subject: [R] Execute R codes without installing R environment
In-Reply-To: <DM5PR12MB1402AA306C5E5CDA7B6BDF50D9D80@DM5PR12MB1402.namprd12.prod.outlook.com>
References: <DM5PR12MB1402AA306C5E5CDA7B6BDF50D9D80@DM5PR12MB1402.namprd12.prod.outlook.com>
Message-ID: <1D1B2ABB-407F-47DC-9154-31598729C701@dcn.davis.ca.us>

1) Producing a zip file most likely means you put your code in a package. This can be a useful thing to do,  but it most definitely does not create a standalone executable. 

3) You have not communicated your goal clearly. Many people want to treat R on a server as a remote compute resource... you might want to look at the OpenCPU project if that is your goal. Alternatively,  using ssh to remotely invoke R at the command line using the parallel package is well supported on Unix-ish operating systems, but that can be more tricky on a Windows server and requires that R be installed.  Other people want to log on to their server gui and run code interactively because the server has more RAM/CPU cores/disk space... for that you also need to get R installed first.  These options definitely involve the assistance of your sysadmin. If you are trying to get R running without that assistance there are portable installs of R, but you still need the approval of your sysadmin. 
-- 
Sent from my phone. Please excuse my brevity.

On June 23, 2017 12:26:49 PM PDT, xianda deng <dengxianda2007 at hotmail.com> wrote:
>Hi,
>
>
>I have some issues with running R in our server and hope you would like
>to help me.
>
>
>My Target: Running R codes without installing R environment in our
>server. Server OS: windows
>
>
>my attempts: I tried to build the R codes into a Binary package with R
>studio, but I don't how to execute the binary package(*.zip file).
>
>
>My questions:  1. Is this a correct solution, which builds the R codes
>into a binary file, to run a R codes without installing R environment?
>
>2. If answer for question 1 is yes, how should I execute or call the R
>script?
>
>                            3. Is any another way to achieve my goal?
>
>
>Thanks!
>
>
>Sincerely
>
>
>Daniel
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dengxianda2007 at hotmail.com  Sat Jun 24 14:17:16 2017
From: dengxianda2007 at hotmail.com (xianda deng)
Date: Sat, 24 Jun 2017 12:17:16 +0000
Subject: [R] Execute R codes without installing R environment
In-Reply-To: <CA+8X3fWfbFF5DDYR1Ovp5iJZiszpG72vXANLBPUDz5=+Tp1LQw@mail.gmail.com>
References: <DM5PR12MB1402AA306C5E5CDA7B6BDF50D9D80@DM5PR12MB1402.namprd12.prod.outlook.com>,
 <CA+8X3fWfbFF5DDYR1Ovp5iJZiszpG72vXANLBPUDz5=+Tp1LQw@mail.gmail.com>
Message-ID: <CY4PR12MB1399D616DFACBBA02540B939D9D90@CY4PR12MB1399.namprd12.prod.outlook.com>

Hi Jim,


Thank you for the quick responding and information.


Sincerely


Daniel


________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Saturday, June 24, 2017 4:50
To: xianda deng
Cc: r-help at r-project.org
Subject: Re: [R] Execute R codes without installing R environment

Hi Daniel,
There seems to be a way to package the R interpreter and a program
into an executable file. It looks pretty complicated and would only be
worth the effort if you _must_ run your script this way and you
_can't_ install R.

https://www.r-bloggers.com/deploying-desktop-apps-with-r/
Deploying Desktop Apps with R | R-bloggers<https://www.r-bloggers.com/deploying-desktop-apps-with-r/>
www.r-bloggers.com
Step 1: Create a deployment skeleton. Because this technique uses portable apps, you can save yourself some time by creating a skeleton desktop deployment.




Jim


On Sat, Jun 24, 2017 at 5:26 AM, xianda deng <dengxianda2007 at hotmail.com> wrote:
> Hi,
>
>
> I have some issues with running R in our server and hope you would like to help me.
>
>
> My Target: Running R codes without installing R environment in our server. Server OS: windows
>
>
> my attempts: I tried to build the R codes into a Binary package with R studio, but I don't how to execute the binary package(*.zip file).
>
>
> My questions:  1. Is this a correct solution, which builds the R codes into a binary file, to run a R codes without installing R environment?
>
>                              2. If answer for question 1 is yes, how should I execute or call the R script?
>
>                             3. Is any another way to achieve my goal?
>
>
> Thanks!
>
>
> Sincerely
>
>
> Daniel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help

thz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dengxianda2007 at hotmail.com  Sat Jun 24 15:57:31 2017
From: dengxianda2007 at hotmail.com (xianda deng)
Date: Sat, 24 Jun 2017 13:57:31 +0000
Subject: [R] Execute R codes without installing R environment
In-Reply-To: <1D1B2ABB-407F-47DC-9154-31598729C701@dcn.davis.ca.us>
References: <DM5PR12MB1402AA306C5E5CDA7B6BDF50D9D80@DM5PR12MB1402.namprd12.prod.outlook.com>,
 <1D1B2ABB-407F-47DC-9154-31598729C701@dcn.davis.ca.us>
Message-ID: <DM5PR12MB1402F9EFB477EB5D37F97277D9D90@DM5PR12MB1402.namprd12.prod.outlook.com>

Got it. Thanks. 

Daniel

Sent from my iPhone

> On Jun 24, 2017, at 9:28 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> 1) Producing a zip file most likely means you put your code in a package. This can be a useful thing to do,  but it most definitely does not create a standalone executable. 
> 
> 3) You have not communicated your goal clearly. Many people want to treat R on a server as a remote compute resource... you might want to look at the OpenCPU project if that is your goal. Alternatively,  using ssh to remotely invoke R at the command line using the parallel package is well supported on Unix-ish operating systems, but that can be more tricky on a Windows server and requires that R be installed.  Other people want to log on to their server gui and run code interactively because the server has more RAM/CPU cores/disk space... for that you also need to get R installed first.  These options definitely involve the assistance of your sysadmin. If you are trying to get R running without that assistance there are portable installs of R, but you still need the approval of your sysadmin. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
>> On June 23, 2017 12:26:49 PM PDT, xianda deng <dengxianda2007 at hotmail.com> wrote:
>> Hi,
>> 
>> 
>> I have some issues with running R in our server and hope you would like
>> to help me.
>> 
>> 
>> My Target: Running R codes without installing R environment in our
>> server. Server OS: windows
>> 
>> 
>> my attempts: I tried to build the R codes into a Binary package with R
>> studio, but I don't how to execute the binary package(*.zip file).
>> 
>> 
>> My questions:  1. Is this a correct solution, which builds the R codes
>> into a binary file, to run a R codes without installing R environment?
>> 
>> 2. If answer for question 1 is yes, how should I execute or call the R
>> script?
>> 
>>                           3. Is any another way to achieve my goal?
>> 
>> 
>> Thanks!
>> 
>> 
>> Sincerely
>> 
>> 
>> Daniel
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From john9427 at gmail.com  Sun Jun 25 00:47:12 2017
From: john9427 at gmail.com (John Murtagh)
Date: Sat, 24 Jun 2017 23:47:12 +0100
Subject: [R] Fwd: Widgets under renderUI Shiny
In-Reply-To: <mailman.2901.1498340918.47836.r-help@r-project.org>
References: <mailman.2901.1498340918.47836.r-help@r-project.org>
Message-ID: <CA+abw2VwR7E_UhAHLTPtS8A_Tp7-nOHdO_B5Kr=7LED0RQonFQ@mail.gmail.com>

Hi All,

I am not sure if this is a relevant platform to ask but I have tried other
more related platforms and haven't had any luck so i thought i would try my
luck here.

Basically I want to generate a selectInput widget with a conditional under
renderUI in Shiny.

The number of widgets generated will depend on the number of variables a
user selects. Try as I may I have not been able to get this to work and
have had no luck in getting any help on other platforms hence why i am
asking here on the odd chance someone may be able to share his knowledge
and explain what it is I am doing wrong or a workaround that I can apply.
Below is the code I have so far (please feel free to criticize the code, I
am new to R/programming with no background). Thanks

 library(shiny)


ui= fluidPage(
  sidebarLayout(
    sidebarPanel(
      selectizeInput(inputId= "invar", label= "invar",
                     choices= names(iris),
                     selected= names(iris)[1],
                     multiple=T),
      uiOutput("invarpdf")

    ),
    mainPanel(
      tableOutput("tab")
    )
  ))


server= function(input, output,session) {

  sorted <-  reactive({
    data <- iris[ ,c(input$invar)]
    #print(input$invar)
    data})

  output$invarpdf<-renderUI({
    numvar<- length(input$varnames)
     {
      selectInput(inputId=paste0("distinvar",input$invar),paste0("Please
Select Probability Distribution of ", input$invar),
                  choices = c("Normal","Uniform","Triangular"))
      conditionalPanel(condition = "input.distinvarpdf=='Normal'",
                       textInput("invarpdfmean","Please Select Input
Variable Mean:",0.25),
                       textInput("invarpdfsd","Please Select Input
Variable Standard Deviation", 0.02))
      conditionalPanel(condition = "input.distinvarpdf=='Uniform'",
                       textInput("invarpdfmin","Please Select Minimum
Input Variable Value:",0.18),
                       textInput("invarpdfmax","Please Select Maximum
Input Variable Value", 0.3))
      conditionalPanel(condition = "input.distinvarpdf=='Triangular'",
                       textInput("invarpdfmin","Please Select Minimum
Input Variable Value:",0.18),
                       textInput("invarpdfmax","Please Select Maximum
Input Variable Value:", 0.3))
      conditionalPanel(condition = "input.distinvarpdf=='Log Normal'",
                       textInput("invarpdfmeanlog","Please Select Mean
Log of Input Variable:",0.18),
                       textInput("invarpdfsdlog","Please Select
Standard Deviation Log of Input Variable:", 0.3))
    }})

  output$MonteCarlo <- renderPlot({
    set.seed(1)


    n <- input$sampleSize




    if(distinvarpdf=="Normal"){

      invarpdfVec <- rnorm(n,mean = as.numeric(input$invarpdfmean),sd=
as.numeric(input$invarpdfsd))
    }
    if(distinvarpdf=="Uniform"){

      invarpdfVec <- runif(n,min = as.numeric(input$invarpdfmin),max =
as.numeric(input$invarpdfmax))
    }
    if(distinvarpdf=="Triangular"){

      invarpdfVec <- rltriangle(n,a = as.numeric(input$invarpdfmin),b
= as.numeric(input$invarpdfmax))
    }
    if(distinvarpdf=="Log Normal"){

      invarpdfVec <- rlnorm(n,meanlog =
as.numeric(input$invarpdfmeanlog),sdlog =
as.numeric(input$invarpdfsdlog))
    }




    h<- hist(distinvarpdf,


...

[Message clipped]

	[[alternative HTML version deleted]]


From christophe.elek at gmail.com  Sat Jun 24 19:49:47 2017
From: christophe.elek at gmail.com (Christophe Elek)
Date: Sat, 24 Jun 2017 13:49:47 -0400
Subject: [R] Fill in empty cell in data.frame from previous value
Message-ID: <594ea639.0e56240a.7719d.b58e@mx.google.com>

Hello Total newbie here... I hope I read the guide properly

I have the following data.frame (I read it from a CSV file I cannot change)

  names val
1 Mandy   1
2         2
3 John    2
4         2

I want to read the row number 2, but I want the first column to be ?Mandy? and not null

print (frame[2,])
2 Mandy   2

I can manipulate the data.frame once loaded
How can I fill all cell in column ?names? with the previous value ?
Or is there a function that will get me the row and fill the ?names? column ?

NOTA BENE: I do not want the answer, I want to find it myself but I need guidance
If there is a function, tell me the library and I will search
If this is an algorithm, tell me generally how you would do and let me scratch my head first ?

Thanks Chris


	[[alternative HTML version deleted]]


From dreamscollector9 at gmail.com  Sun Jun 25 07:41:31 2017
From: dreamscollector9 at gmail.com (Dreams Collector)
Date: Sun, 25 Jun 2017 07:41:31 +0200
Subject: [R] Paired Weighted Wilcoxon test in R
In-Reply-To: <CA+8X3fV_iuuTEet7Yu4nZdbuWkcciKuWkH0BFvSOhPxMiqgQZg@mail.gmail.com>
References: <57B68802-850B-4B14-AD89-9713AC93DD67@gmail.com>
 <CA+8X3fV_iuuTEet7Yu4nZdbuWkcciKuWkH0BFvSOhPxMiqgQZg@mail.gmail.com>
Message-ID: <4359075B-B4AD-4997-8CB0-C8B10220FF4A@gmail.com>

Thank you very much for your suggestions, Jim!

> El 24 jun 2017, a las 9:57, Jim Lemon <drjimlemon at gmail.com> escribi?:
> 
> Hi DC9,
> As no one has answered, I would say that as both the survey package
> and Professor Lumley are widely respected, that is as good as it gets.
> 
> Jim
> 
> On Fri, Jun 23, 2017 at 7:26 PM, Dreams Collector
> <dreamscollector9 at gmail.com> wrote:
>> Dear R-users,
>> 
>> I?m trying to perform a non-parametric statistical pairwise comparison of two samples "x" and "y" using the Wilcoxon test in R, but each of the pairs have a weight associated.
>> 
>> An example of my data is the following one:
>> 
>> set.seed(9)
>> x <- sample(x = c(1:100), size = 20, replace = TRUE)
>> y <- sample(x = c(1:100), size = 20, replace = TRUE)
>> weight <- runif(n = 20)
>> data <- data.frame(x = x, y = y, weight = weight)
>> 
>> I?m new with statistical tests. I?ve read this other post about a similar issue:
>> 
>> http://r.789695.n4.nabble.com/Weighted-Mann-Whitney-Wilcoxon-Test-td4695699.html <http://r.789695.n4.nabble.com/Weighted-Mann-Whitney-Wilcoxon-Test-td4695699.html>
>> 
>> But I?m not sure if I can use the packages/works cited there.
>> 
>> Any help/comment would be fantastic for me.
>> 
>> Thank you!
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From es927716 at ohio.edu  Sat Jun 24 18:17:07 2017
From: es927716 at ohio.edu (Sarpong, Rabby)
Date: Sat, 24 Jun 2017 16:17:07 +0000
Subject: [R] Help please
Message-ID: <DM5PR01MB3306EFB20AFFAFBF73DF7522BBD90@DM5PR01MB3306.prod.exchangelabs.com>

Hello,


I need some help on a regression I am running please. I am running a multiple regression in R and I am getting weird outputs and would like your help in resolving it.

This is the code I run:


Reg = lm (Final$Y.t.-Final$Y.t.1.  ~ Final$ Y.t.1. + Final$Cor + Final$Gov+ Final$Inv+ Final$TrOp + Final$Pop+ Final$Sch  , data = Final)
summary(Reg)


And the output I get is pasted below. As shown, highlighted variable is regressed more than once which should not be the case and I am not sure why that is the case. I have checked my data and nothing seems out of the ordinary. What could be wrong please?


PS. I am still learning to use R.


Thank you,

Rabby



Residuals:
     Min       1Q   Median       3Q      Max
-1.04279 -0.06739  0.00124  0.06376  1.59115

Coefficients:
               Estimate Std. Error t value Pr(>|t|)
(Intercept)   0.1045711  0.0867584   1.205 0.228308
Final$Y.t.1. -0.0313686  0.0058536  -5.359 9.95e-08 ***
Final$Cor10   0.0009784  0.1622916   0.006 0.995191
Final$Cor11   0.1230775  0.1165864   1.056 0.291318
Final$Cor12   0.1615939  0.1086529   1.487 0.137199
Final$Cor13   0.1934974  0.1160577   1.667 0.095713 .
Final$Cor14   0.2341660  0.1286909   1.820 0.069057 .
Final$Cor15   0.0744373  0.1036776   0.718 0.472909
Final$Cor16   0.1964904  0.0932540   2.107 0.035311 *
Final$Cor17   0.1989502  0.0908614   2.190 0.028736 *
Final$Cor18   0.1993614  0.0886491   2.249 0.024692 *
Final$Cor19   0.2062234  0.0878018   2.349 0.018991 *
Final$Cor20   0.1889846  0.0868192   2.177 0.029683 *
Final$Cor21   0.1717589  0.0855883   2.007 0.044984 *
Final$Cor22   0.1453460  0.0856982   1.696 0.090129 .
Final$Cor23   0.1976086  0.0871142   2.268 0.023474 *
Final$Cor24   0.1471384  0.0859318   1.712 0.087093 .
Final$Cor25   0.1447194  0.0851309   1.700 0.089384 .
Final$Cor26   0.1553640  0.0855425   1.816 0.069574 .
Final$Cor27   0.1220044  0.0854661   1.428 0.153678
Final$Cor28   0.1406044  0.0854213   1.646 0.100011
Final$Cor29   0.1594371  0.0860525   1.853 0.064146 .
Final$Cor30   0.1792005  0.0863734   2.075 0.038215 *
Final$Cor31   0.1376306  0.0871176   1.580 0.114398
Final$Cor32   0.1521694  0.0865125   1.759 0.078832 .
Final$Cor33   0.1535856  0.0863890   1.778 0.075671 .
Final$Cor34   0.1327356  0.0865482   1.534 0.125364
Final$Cor35   0.1501163  0.0864312   1.737 0.082661 .
Final$Cor36   0.1114404  0.0866389   1.286 0.198587
Final$Cor37   0.1326494  0.0873405   1.519 0.129073
Final$Cor38   0.0993100  0.0869474   1.142 0.253594
Final$Cor39   0.1346916  0.0885424   1.521 0.128458
Final$Cor4    0.0306186  0.1625561   0.188 0.850627
Final$Cor40   0.1596858  0.0906725   1.761 0.078459 .
Final$Cor41   0.1330054  0.0881280   1.509 0.131491
Final$Cor42   0.1355948  0.0911754   1.487 0.137216
Final$Cor43   0.1106947  0.0921995   1.201 0.230132
Final$Cor44   0.1525535  0.0923625   1.652 0.098848 .
Final$Cor45   0.0885523  0.0918222   0.964 0.335036
Final$Cor46   0.1594086  0.0911042   1.750 0.080406 .
Final$Cor47   0.1874162  0.0909010   2.062 0.039435 *
Final$Cor48   0.1746566  0.0901044   1.938 0.052800 .
Final$Cor49   0.1248750  0.0915038   1.365 0.172592
Final$Cor50   0.1270500  0.0900791   1.410 0.158660
Final$Cor51   0.0798476  0.0906523   0.881 0.378587
Final$Cor52   0.0697894  0.0918425   0.760 0.447468
Final$Cor53   0.1632391  0.0930509   1.754 0.079622 .
Final$Cor54   0.1143655  0.0933946   1.225 0.220977
Final$Cor55   0.0991357  0.0928684   1.067 0.285957
Final$Cor56   0.1191313  0.0975565   1.221 0.222257
Final$Cor57   0.1288024  0.0939890   1.370 0.170807
Final$Cor58   0.1249315  0.0951040   1.314 0.189209
Final$Cor59   0.2100375  0.1020216   2.059 0.039723 *
Final$Cor60   0.1303076  0.0944493   1.380 0.167937
Final$Cor61   0.0928124  0.1056764   0.878 0.379964
Final$Cor62   0.0767684  0.1296343   0.592 0.553828
Final$Cor63   0.1133221  0.1174685   0.965 0.334879
Final$Cor64   0.1412303  0.0978915   1.443 0.149347
Final$Cor65   0.1382271  0.1098535   1.258 0.208522
Final$Cor66   0.0982404  0.1057428   0.929 0.353041
Final$Cor67   0.1893438  0.1022572   1.852 0.064311 .
Final$Cor68   0.1578940  0.1634072   0.966 0.334099
Final$Cor69   0.2166677  0.1021570   2.121 0.034123 *
Final$Cor70   0.1143033  0.1054570   1.084 0.278623
Final$Cor71   0.1469311  0.1637571   0.897 0.369757
Final$Cor72   0.2268878  0.1103408   2.056 0.039964 *
Final$Cor73   0.1925218  0.1055544   1.824 0.068402 .
Final$Cor74   0.1574432  0.1020634   1.543 0.123178
Final$Cor75   0.0571227  0.1166594   0.490 0.624464
Final$Cor76   0.1096049  0.1634571   0.671 0.502635
Final$Cor78   0.0949307  0.1305748   0.727 0.467347
Final$Cor8    0.1082102  0.1289245   0.839 0.401443
Final$Gov    -0.0016397  0.0008084  -2.028 0.042736 *
Final$Inv     0.0016819  0.0004667   3.604 0.000326 ***
Final$TrOp    0.0002904  0.0001209   2.402 0.016445 *
Final$Pop    -0.0130554  0.0038839  -3.361 0.000799 ***
Final$Sch     0.0005785  0.0002696   2.146 0.032064 *
---



	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Jun 25 09:11:28 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 25 Jun 2017 17:11:28 +1000
Subject: [R] Fill in empty cell in data.frame from previous value
In-Reply-To: <594ea639.0e56240a.7719d.b58e@mx.google.com>
References: <594ea639.0e56240a.7719d.b58e@mx.google.com>
Message-ID: <CA+8X3fXzrTd6j7sFD=r=3NXwcDEQ1a6jbS30ShgLDFZYskzbMA@mail.gmail.com>

Hi Chris,
You may know about the *apply family of functions. These slice various
data structures and "apply" a specified function to each slice,
usually returning a list of return values. As far as I am aware, you
can't access adjacent rows unless you reformat the data structure.

There is a way to do this particular job. It requires the sequence
operator (:), the ifelse function and indexing. What you do is to
create a sequence of all the values in the element "names", then
subtract 1 for all the NA (or any other specified value) values and
use the resulting vector to index the original element "names". It
won't work if the first value is NA, nor will it work for more than
one NA in a row. I realize that this is pretty obscure, but you said
that you didn't just want the solution. It's a one-liner.

Jim

On Sun, Jun 25, 2017 at 3:49 AM, Christophe Elek
<christophe.elek at gmail.com> wrote:
> Hello Total newbie here... I hope I read the guide properly
>
> I have the following data.frame (I read it from a CSV file I cannot change)
>
>   names val
> 1 Mandy   1
> 2         2
> 3 John    2
> 4         2
>
> I want to read the row number 2, but I want the first column to be ?Mandy? and not null
>
> print (frame[2,])
> 2 Mandy   2
>
> I can manipulate the data.frame once loaded
> How can I fill all cell in column ?names? with the previous value ?
> Or is there a function that will get me the row and fill the ?names? column ?
>
> NOTA BENE: I do not want the answer, I want to find it myself but I need guidance
> If there is a function, tell me the library and I will search
> If this is an algorithm, tell me generally how you would do and let me scratch my head first ?
>
> Thanks Chris
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Jun 25 09:22:54 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 25 Jun 2017 17:22:54 +1000
Subject: [R] Help please
In-Reply-To: <DM5PR01MB3306EFB20AFFAFBF73DF7522BBD90@DM5PR01MB3306.prod.exchangelabs.com>
References: <DM5PR01MB3306EFB20AFFAFBF73DF7522BBD90@DM5PR01MB3306.prod.exchangelabs.com>
Message-ID: <CA+8X3fU7=Uf8rnBCw2fPcTd9YXj7r-Zvjza1=eJt8p0RAW81Pw@mail.gmail.com>

Hi Rabby,
It looks to me as though your variable Final$Cor is being treated as a
factor rather than a numeric value. This may be due to one or more
non-numeric values occurring in the data that is read in. Also you do
not have to use the Final$* notation in the formula as you have
specified the data frame "Final".

Jim


On Sun, Jun 25, 2017 at 2:17 AM, Sarpong, Rabby <es927716 at ohio.edu> wrote:
> Hello,
>
>
> I need some help on a regression I am running please. I am running a multiple regression in R and I am getting weird outputs and would like your help in resolving it.
>
> This is the code I run:
>
>
> Reg = lm (Final$Y.t.-Final$Y.t.1.  ~ Final$ Y.t.1. + Final$Cor + Final$Gov+ Final$Inv+ Final$TrOp + Final$Pop+ Final$Sch  , data = Final)
> summary(Reg)
>
>
> And the output I get is pasted below. As shown, highlighted variable is regressed more than once which should not be the case and I am not sure why that is the case. I have checked my data and nothing seems out of the ordinary. What could be wrong please?
>
>
> PS. I am still learning to use R.
>
>
> Thank you,
>
> Rabby
>
>
>
> Residuals:
>      Min       1Q   Median       3Q      Max
> -1.04279 -0.06739  0.00124  0.06376  1.59115
>
> Coefficients:
>                Estimate Std. Error t value Pr(>|t|)
> (Intercept)   0.1045711  0.0867584   1.205 0.228308
> Final$Y.t.1. -0.0313686  0.0058536  -5.359 9.95e-08 ***
> Final$Cor10   0.0009784  0.1622916   0.006 0.995191
> Final$Cor11   0.1230775  0.1165864   1.056 0.291318
> Final$Cor12   0.1615939  0.1086529   1.487 0.137199
> Final$Cor13   0.1934974  0.1160577   1.667 0.095713 .
> Final$Cor14   0.2341660  0.1286909   1.820 0.069057 .
> Final$Cor15   0.0744373  0.1036776   0.718 0.472909
> Final$Cor16   0.1964904  0.0932540   2.107 0.035311 *
> Final$Cor17   0.1989502  0.0908614   2.190 0.028736 *
> Final$Cor18   0.1993614  0.0886491   2.249 0.024692 *
> Final$Cor19   0.2062234  0.0878018   2.349 0.018991 *
> Final$Cor20   0.1889846  0.0868192   2.177 0.029683 *
> Final$Cor21   0.1717589  0.0855883   2.007 0.044984 *
> Final$Cor22   0.1453460  0.0856982   1.696 0.090129 .
> Final$Cor23   0.1976086  0.0871142   2.268 0.023474 *
> Final$Cor24   0.1471384  0.0859318   1.712 0.087093 .
> Final$Cor25   0.1447194  0.0851309   1.700 0.089384 .
> Final$Cor26   0.1553640  0.0855425   1.816 0.069574 .
> Final$Cor27   0.1220044  0.0854661   1.428 0.153678
> Final$Cor28   0.1406044  0.0854213   1.646 0.100011
> Final$Cor29   0.1594371  0.0860525   1.853 0.064146 .
> Final$Cor30   0.1792005  0.0863734   2.075 0.038215 *
> Final$Cor31   0.1376306  0.0871176   1.580 0.114398
> Final$Cor32   0.1521694  0.0865125   1.759 0.078832 .
> Final$Cor33   0.1535856  0.0863890   1.778 0.075671 .
> Final$Cor34   0.1327356  0.0865482   1.534 0.125364
> Final$Cor35   0.1501163  0.0864312   1.737 0.082661 .
> Final$Cor36   0.1114404  0.0866389   1.286 0.198587
> Final$Cor37   0.1326494  0.0873405   1.519 0.129073
> Final$Cor38   0.0993100  0.0869474   1.142 0.253594
> Final$Cor39   0.1346916  0.0885424   1.521 0.128458
> Final$Cor4    0.0306186  0.1625561   0.188 0.850627
> Final$Cor40   0.1596858  0.0906725   1.761 0.078459 .
> Final$Cor41   0.1330054  0.0881280   1.509 0.131491
> Final$Cor42   0.1355948  0.0911754   1.487 0.137216
> Final$Cor43   0.1106947  0.0921995   1.201 0.230132
> Final$Cor44   0.1525535  0.0923625   1.652 0.098848 .
> Final$Cor45   0.0885523  0.0918222   0.964 0.335036
> Final$Cor46   0.1594086  0.0911042   1.750 0.080406 .
> Final$Cor47   0.1874162  0.0909010   2.062 0.039435 *
> Final$Cor48   0.1746566  0.0901044   1.938 0.052800 .
> Final$Cor49   0.1248750  0.0915038   1.365 0.172592
> Final$Cor50   0.1270500  0.0900791   1.410 0.158660
> Final$Cor51   0.0798476  0.0906523   0.881 0.378587
> Final$Cor52   0.0697894  0.0918425   0.760 0.447468
> Final$Cor53   0.1632391  0.0930509   1.754 0.079622 .
> Final$Cor54   0.1143655  0.0933946   1.225 0.220977
> Final$Cor55   0.0991357  0.0928684   1.067 0.285957
> Final$Cor56   0.1191313  0.0975565   1.221 0.222257
> Final$Cor57   0.1288024  0.0939890   1.370 0.170807
> Final$Cor58   0.1249315  0.0951040   1.314 0.189209
> Final$Cor59   0.2100375  0.1020216   2.059 0.039723 *
> Final$Cor60   0.1303076  0.0944493   1.380 0.167937
> Final$Cor61   0.0928124  0.1056764   0.878 0.379964
> Final$Cor62   0.0767684  0.1296343   0.592 0.553828
> Final$Cor63   0.1133221  0.1174685   0.965 0.334879
> Final$Cor64   0.1412303  0.0978915   1.443 0.149347
> Final$Cor65   0.1382271  0.1098535   1.258 0.208522
> Final$Cor66   0.0982404  0.1057428   0.929 0.353041
> Final$Cor67   0.1893438  0.1022572   1.852 0.064311 .
> Final$Cor68   0.1578940  0.1634072   0.966 0.334099
> Final$Cor69   0.2166677  0.1021570   2.121 0.034123 *
> Final$Cor70   0.1143033  0.1054570   1.084 0.278623
> Final$Cor71   0.1469311  0.1637571   0.897 0.369757
> Final$Cor72   0.2268878  0.1103408   2.056 0.039964 *
> Final$Cor73   0.1925218  0.1055544   1.824 0.068402 .
> Final$Cor74   0.1574432  0.1020634   1.543 0.123178
> Final$Cor75   0.0571227  0.1166594   0.490 0.624464
> Final$Cor76   0.1096049  0.1634571   0.671 0.502635
> Final$Cor78   0.0949307  0.1305748   0.727 0.467347
> Final$Cor8    0.1082102  0.1289245   0.839 0.401443
> Final$Gov    -0.0016397  0.0008084  -2.028 0.042736 *
> Final$Inv     0.0016819  0.0004667   3.604 0.000326 ***
> Final$TrOp    0.0002904  0.0001209   2.402 0.016445 *
> Final$Pop    -0.0130554  0.0038839  -3.361 0.000799 ***
> Final$Sch     0.0005785  0.0002696   2.146 0.032064 *
> ---
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Jun 25 16:59:26 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Jun 2017 07:59:26 -0700
Subject: [R] Fill in empty cell in data.frame from previous value
In-Reply-To: <CA+8X3fXzrTd6j7sFD=r=3NXwcDEQ1a6jbS30ShgLDFZYskzbMA@mail.gmail.com>
References: <594ea639.0e56240a.7719d.b58e@mx.google.com>
 <CA+8X3fXzrTd6j7sFD=r=3NXwcDEQ1a6jbS30ShgLDFZYskzbMA@mail.gmail.com>
Message-ID: <CAGxFJbQQdYdCvYzGowgsP+9wSg9oTSrLoqttKQrS=SNv1-m=sQ@mail.gmail.com>

You need to go through some tutorials, not expect us to tutor you
here. That is not the purpose of this list (although we do some of
this indirectly of course). There are many good online tutorials --
search or see here:  https://www.rstudio.com/online-learning/#R  . Or
start by going through the Intro to R tutorial that ships with R.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 25, 2017 at 12:11 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Chris,
> You may know about the *apply family of functions. These slice various
> data structures and "apply" a specified function to each slice,
> usually returning a list of return values. As far as I am aware, you
> can't access adjacent rows unless you reformat the data structure.
>
> There is a way to do this particular job. It requires the sequence
> operator (:), the ifelse function and indexing. What you do is to
> create a sequence of all the values in the element "names", then
> subtract 1 for all the NA (or any other specified value) values and
> use the resulting vector to index the original element "names". It
> won't work if the first value is NA, nor will it work for more than
> one NA in a row. I realize that this is pretty obscure, but you said
> that you didn't just want the solution. It's a one-liner.
>
> Jim
>
> On Sun, Jun 25, 2017 at 3:49 AM, Christophe Elek
> <christophe.elek at gmail.com> wrote:
>> Hello Total newbie here... I hope I read the guide properly
>>
>> I have the following data.frame (I read it from a CSV file I cannot change)
>>
>>   names val
>> 1 Mandy   1
>> 2         2
>> 3 John    2
>> 4         2
>>
>> I want to read the row number 2, but I want the first column to be ?Mandy? and not null
>>
>> print (frame[2,])
>> 2 Mandy   2
>>
>> I can manipulate the data.frame once loaded
>> How can I fill all cell in column ?names? with the previous value ?
>> Or is there a function that will get me the row and fill the ?names? column ?
>>
>> NOTA BENE: I do not want the answer, I want to find it myself but I need guidance
>> If there is a function, tell me the library and I will search
>> If this is an algorithm, tell me generally how you would do and let me scratch my head first ?
>>
>> Thanks Chris
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Sun Jun 25 17:23:51 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 25 Jun 2017 11:23:51 -0400
Subject: [R] Fill in empty cell in data.frame from previous value
In-Reply-To: <594ea639.0e56240a.7719d.b58e@mx.google.com>
References: <594ea639.0e56240a.7719d.b58e@mx.google.com>
Message-ID: <71855C3F-5618-4DB7-996B-BC26E254C3D6@utoronto.ca>

Run it through a loop. I assume the cell contents is NA (Not Available). Test for it with is.na(). Whenever that returns TRUE, replace the NA value with the value from the previous row.

Cheers,
B.



> On Jun 24, 2017, at 1:49 PM, Christophe Elek <christophe.elek at gmail.com> wrote:
> 
> Hello Total newbie here... I hope I read the guide properly
> 
> I have the following data.frame (I read it from a CSV file I cannot change)
> 
>  names val
> 1 Mandy   1
> 2         2
> 3 John    2
> 4         2
> 
> I want to read the row number 2, but I want the first column to be ?Mandy? and not null
> 
> print (frame[2,])
> 2 Mandy   2
> 
> I can manipulate the data.frame once loaded
> How can I fill all cell in column ?names? with the previous value ?
> Or is there a function that will get me the row and fill the ?names? column ?
> 
> NOTA BENE: I do not want the answer, I want to find it myself but I need guidance
> If there is a function, tell me the library and I will search
> If this is an algorithm, tell me generally how you would do and let me scratch my head first ?
> 
> Thanks Chris
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From goran.brostrom at umu.se  Sun Jun 25 18:44:21 2017
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Sun, 25 Jun 2017 18:44:21 +0200
Subject: [R] Fill in empty cell in data.frame from previous value
In-Reply-To: <594ea639.0e56240a.7719d.b58e@mx.google.com>
References: <594ea639.0e56240a.7719d.b58e@mx.google.com>
Message-ID: <5d06feb0-d485-eae3-a48d-8520e2083073@umu.se>

 > library(tidyr)
 > ?fill

G?ran

On 2017-06-24 19:49, Christophe Elek wrote:
> Hello Total newbie here... I hope I read the guide properly
> 
> I have the following data.frame (I read it from a CSV file I cannot change)
> 
>    names val
> 1 Mandy   1
> 2         2
> 3 John    2
> 4         2
> 
> I want to read the row number 2, but I want the first column to be ?Mandy? and not null
> 
> print (frame[2,])
> 2 Mandy   2
> 
> I can manipulate the data.frame once loaded
> How can I fill all cell in column ?names? with the previous value ?
> Or is there a function that will get me the row and fill the ?names? column ?
> 
> NOTA BENE: I do not want the answer, I want to find it myself but I need guidance
> If there is a function, tell me the library and I will search
> If this is an algorithm, tell me generally how you would do and let me scratch my head first ?
> 
> Thanks Chris
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From eliza_botto1 at outlook.com  Sun Jun 25 13:34:26 2017
From: eliza_botto1 at outlook.com (Eliza B)
Date: Sun, 25 Jun 2017 11:34:26 +0000
Subject: [R] vertical semi-circles in R
Message-ID: <DB4PR08MB0111790FB7706E74744491FDABDE0@DB4PR08MB0111.eurprd08.prod.outlook.com>

Dear useRs,


I am to teach my students some drawing techniques in R. I started shape of an handle by using the following codes;

>plot(0,0,col="white")

>segments(0,0,0.3,0.3)

>segments(0.3,0.4,0.3,0.3)

>segments(0.3,0.4,0,0.7)

>segments(0,0.7,0,0.6)

>segments(0,0.0,0,0.1)

The coding will draw a section of a handle. Now I want to draw semi circles of radius 0.05 between (0,0.6) and (0,0.1), oriented vertically and outward with mouth facing against the y-axis.

I tried every help available online but to no use.

Thanks in advance,

EB


	[[alternative HTML version deleted]]


From christophe.elek at gmail.com  Sun Jun 25 17:25:52 2017
From: christophe.elek at gmail.com (Christophe Elek)
Date: Sun, 25 Jun 2017 11:25:52 -0400
Subject: [R] Fill in empty cell in data.frame from previous value
In-Reply-To: <CA+8X3fXzrTd6j7sFD=r=3NXwcDEQ1a6jbS30ShgLDFZYskzbMA@mail.gmail.com>
References: <594ea639.0e56240a.7719d.b58e@mx.google.com>
 <CA+8X3fXzrTd6j7sFD=r=3NXwcDEQ1a6jbS30ShgLDFZYskzbMA@mail.gmail.com>
Message-ID: <594fd5fd.d269240a.e2fd6.2eec@mx.google.com>

Perfect Jim, that Is exactly what I needed ? let me check that ... 
Cheers

From: Jim Lemon
Sent: June 25, 2017 3:11 AM
To: Christophe Elek
Cc: r-help at r-project.org
Subject: Re: [R] Fill in empty cell in data.frame from previous value

Hi Chris,
You may know about the *apply family of functions. These slice various
data structures and "apply" a specified function to each slice,
usually returning a list of return values. As far as I am aware, you
can't access adjacent rows unless you reformat the data structure.

There is a way to do this particular job. It requires the sequence
operator (:), the ifelse function and indexing. What you do is to
create a sequence of all the values in the element "names", then
subtract 1 for all the NA (or any other specified value) values and
use the resulting vector to index the original element "names". It
won't work if the first value is NA, nor will it work for more than
one NA in a row. I realize that this is pretty obscure, but you said
that you didn't just want the solution. It's a one-liner.

Jim

On Sun, Jun 25, 2017 at 3:49 AM, Christophe Elek
<christophe.elek at gmail.com> wrote:
> Hello Total newbie here... I hope I read the guide properly
>
> I have the following data.frame (I read it from a CSV file I cannot change)
>
>   names val
> 1 Mandy   1
> 2         2
> 3 John    2
> 4         2
>
> I want to read the row number 2, but I want the first column to be ?Mandy? and not null
>
> print (frame[2,])
> 2 Mandy   2
>
> I can manipulate the data.frame once loaded
> How can I fill all cell in column ?names? with the previous value ?
> Or is there a function that will get me the row and fill the ?names? column ?
>
> NOTA BENE: I do not want the answer, I want to find it myself but I need guidance
> If there is a function, tell me the library and I will search
> If this is an algorithm, tell me generally how you would do and let me scratch my head first ?
>
> Thanks Chris
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From christophe.elek at gmail.com  Sun Jun 25 17:26:07 2017
From: christophe.elek at gmail.com (Christophe Elek)
Date: Sun, 25 Jun 2017 11:26:07 -0400
Subject: [R] Fill in empty cell in data.frame from previous value
In-Reply-To: <71855C3F-5618-4DB7-996B-BC26E254C3D6@utoronto.ca>
References: <594ea639.0e56240a.7719d.b58e@mx.google.com>
 <71855C3F-5618-4DB7-996B-BC26E254C3D6@utoronto.ca>
Message-ID: <594fd60d.c8986b0a.93693.2014@mx.google.com>

Excellent Boris, thx ? this helps

From: Boris Steipe
Sent: June 25, 2017 11:23 AM
To: Christophe Elek
Cc: r-help at r-project.org
Subject: Re: [R] Fill in empty cell in data.frame from previous value

Run it through a loop. I assume the cell contents is NA (Not Available). Test for it with is.na(). Whenever that returns TRUE, replace the NA value with the value from the previous row.

Cheers,
B.



> On Jun 24, 2017, at 1:49 PM, Christophe Elek <christophe.elek at gmail.com> wrote:
> 
> Hello Total newbie here... I hope I read the guide properly
> 
> I have the following data.frame (I read it from a CSV file I cannot change)
> 
>  names val
> 1 Mandy   1
> 2         2
> 3 John    2
> 4         2
> 
> I want to read the row number 2, but I want the first column to be ?Mandy? and not null
> 
> print (frame[2,])
> 2 Mandy   2
> 
> I can manipulate the data.frame once loaded
> How can I fill all cell in column ?names? with the previous value ?
> Or is there a function that will get me the row and fill the ?names? column ?
> 
> NOTA BENE: I do not want the answer, I want to find it myself but I need guidance
> If there is a function, tell me the library and I will search
> If this is an algorithm, tell me generally how you would do and let me scratch my head first ?
> 
> Thanks Chris
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun Jun 25 20:45:33 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 25 Jun 2017 19:45:33 +0100
Subject: [R] vertical semi-circles in R
In-Reply-To: <DB4PR08MB0111790FB7706E74744491FDABDE0@DB4PR08MB0111.eurprd08.prod.outlook.com>
References: <DB4PR08MB0111790FB7706E74744491FDABDE0@DB4PR08MB0111.eurprd08.prod.outlook.com>
Message-ID: <595004CD.2070604@sapo.pt>

Hello,

I'm not the greatest graphics programmer but is this it?

#install.packages("shape")

library(shape)  # for function plotcircle

plot(0,0,col="white")
segments(0,0,0.3,0.3)
segments(0.3,0.4,0.3,0.3)
segments(0.3,0.4,0,0.7)
segments(0,0.7,0,0.6)
segments(0,0.0,0,0.1)

plotcircle(r = 0.25, mid = c(0,0.35), from = pi/2, to = -pi/2)


Note: you say you've tried every online help with no success. I had 
never used package shape, at an R prompt I typed

 > ?circle
No documentation for ?circle? in specified packages and libraries:
you could try ???circle?

so I tried ??circle and found the package. The rest took me less than 10 
minutes. (Less than 5?)

Hope this helps,

Rui Barradas

Em 25-06-2017 12:34, Eliza B escreveu:
> Dear useRs,
>
>
> I am to teach my students some drawing techniques in R. I started shape of an handle by using the following codes;
>
>> plot(0,0,col="white")
>
>> segments(0,0,0.3,0.3)
>
>> segments(0.3,0.4,0.3,0.3)
>
>> segments(0.3,0.4,0,0.7)
>
>> segments(0,0.7,0,0.6)
>
>> segments(0,0.0,0,0.1)
>
> The coding will draw a section of a handle. Now I want to draw semi circles of radius 0.05 between (0,0.6) and (0,0.1), oriented vertically and outward with mouth facing against the y-axis.
>
> I tried every help available online but to no use.
>
> Thanks in advance,
>
> EB
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Sun Jun 25 20:50:24 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 25 Jun 2017 19:50:24 +0100
Subject: [R] vertical semi-circles in R
In-Reply-To: <595004CD.2070604@sapo.pt>
References: <DB4PR08MB0111790FB7706E74744491FDABDE0@DB4PR08MB0111.eurprd08.prod.outlook.com>
 <595004CD.2070604@sapo.pt>
Message-ID: <595005F0.1040208@sapo.pt>

I forgot to mention that a circle with radius 0.05 cannot go from 
(0,0.6) to (0,0.1), that's why I've changed the radius to 0.25, half the 
distance between those points. I also chose the center point.

Rui Barradas

Em 25-06-2017 19:45, Rui Barradas escreveu:
> Hello,
>
> I'm not the greatest graphics programmer but is this it?
>
> #install.packages("shape")
>
> library(shape)  # for function plotcircle
>
> plot(0,0,col="white")
> segments(0,0,0.3,0.3)
> segments(0.3,0.4,0.3,0.3)
> segments(0.3,0.4,0,0.7)
> segments(0,0.7,0,0.6)
> segments(0,0.0,0,0.1)
>
> plotcircle(r = 0.25, mid = c(0,0.35), from = pi/2, to = -pi/2)
>
>
> Note: you say you've tried every online help with no success. I had
> never used package shape, at an R prompt I typed
>
>  > ?circle
> No documentation for ?circle? in specified packages and libraries:
> you could try ???circle?
>
> so I tried ??circle and found the package. The rest took me less than 10
> minutes. (Less than 5?)
>
> Hope this helps,
>
> Rui Barradas
>
> Em 25-06-2017 12:34, Eliza B escreveu:
>> Dear useRs,
>>
>>
>> I am to teach my students some drawing techniques in R. I started
>> shape of an handle by using the following codes;
>>
>>> plot(0,0,col="white")
>>
>>> segments(0,0,0.3,0.3)
>>
>>> segments(0.3,0.4,0.3,0.3)
>>
>>> segments(0.3,0.4,0,0.7)
>>
>>> segments(0,0.7,0,0.6)
>>
>>> segments(0,0.0,0,0.1)
>>
>> The coding will draw a section of a handle. Now I want to draw semi
>> circles of radius 0.05 between (0,0.6) and (0,0.1), oriented
>> vertically and outward with mouth facing against the y-axis.
>>
>> I tried every help available online but to no use.
>>
>> Thanks in advance,
>>
>> EB
>>
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Sun Jun 25 20:42:26 2017
From: alaios at yahoo.com (Alaios)
Date: Sun, 25 Jun 2017 18:42:26 +0000 (UTC)
Subject: [R] Writing my 3D plot function
References: <1627652181.2097203.1498416146575.ref@mail.yahoo.com>
Message-ID: <1627652181.2097203.1498416146575@mail.yahoo.com>

Hi all,I had a question last week on asking for a function that will help me draw three different circles on x,y,z axis based on polar coordinates (Each X,Y,Z circle are coming from three independent measurements of 1-360 polar coordinates). It turned out that there ?is no such function in R and thus I am trying to write my own piece of code that hopefully I will be able to share. I have spent some time to write some code based on the rgl library (Still not 100% sure that this was the best option).
My input are three polar circles X,Y,Z with a good example being the image belowhttps://www.mathworks.com/help/examples/antenna/win64/xxpolarpattern_helix.png

So for X axis my input is a 2D matrix [360,2] including a single measurement per each polar coordinate. The first thing I tried was to turn my polar coordinates to cartesian ones by writing two simple functions. This works so far and I was able to print three simple circles on 3d spaceb but the problem now are the legends I need to put that remain on cartesian coordinates. As you can see from the code below all circles should have radius 1 (in terms of simplicity) but unfortunately I have the cartesian coordinates legends that do not help on reading my Figure. You can help me by executing the code below?

require("rgls")
degreeToRadian<-function(degree){? return ? (0.01745329252*degree)}
turnPolarToX<-function(Amplitude,Coordinate){? return (Amplitude*cos(degreeToRadian(Coordinate)))}
turnPolarToY<-function(Amplitude,Coordinate){? return (Amplitude*sin(degreeToRadian(Coordinate)))}
# Putting the first circle on 3d space. Circle of radius 1X1<-turnPolarToX(1,1:360)Y1<-turnPolarToY(1,1:360)Z1<-rep(0,360)
# Putting the second circle on 3d space. Circle of radius 1X2<-turnPolarToX(1,1:360)Y2<-rep(0,360)Z2<-turnPolarToY(1,1:360)
# Putting the third circle on 3d space. Circle of radius 1X3<-rep(0,360)Y3<-turnPolarToX(1,1:360)Z3<-turnPolarToY(1,1:360)
Min<-min(X1,Y1,Z1,X2,Y2,Z2,X3,Y3,Z3)Max<-max(X1,Y1,Z1,X2,Y2,Z2,X3,Y3,Z3)plot3d(X1,Y1,Z1,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=FALSE,add=TRUE,col="red",type="l")plot3d(X2,Y2,Z2,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=FALSE,add=TRUE,col="green",type="l")plot3d(X3,Y3,Z3,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=TRUE,add=FALSE,col="blue",type="l")
Would it be also possible to include an jpeg image file on a rgls plot?
Thanks a lotRegardsAlex
	[[alternative HTML version deleted]]


From jacksonmrodrigues at gmail.com  Sun Jun 25 23:27:44 2017
From: jacksonmrodrigues at gmail.com (Jackson Rodrigues)
Date: Sun, 25 Jun 2017 18:27:44 -0300
Subject: [R] Help to organize data
Message-ID: <CAPL76w9ivMmEL6n1vZ6eM797V=JkXbkRKn=974Wmie53FhTpLA@mail.gmail.com>

Hi everybody,

My name is Jackson and come here ask for a help to organize data.
I really need help from you. I have several data sets to organize.

I have to summarize precipitation data collected in different days and
months in only one table.
However, those data are disperse in days and times. Those rainy days have a
more observations than drought ones.

Below you can find a hypothetical example of what I have and I what I need
comes in sequence.

The following table is what I have for a single year.
Notice that number of observations varies from day to day entire year.



*Day*

*Time*

*Prec*

Jan



1

7:00

20mm

1

7:20

15mm

1

7:30

5mm

2

6:00

10mm

2

15:00

16mm

...

...

...mm

31

7:00

2mm

Feb

1

9:00

6mm

1

9:45

30mm

2

6:45

12mm

2

16:00

20mm

2

22:00

60mm

*...*

*...*

*...mm*

28

11:30

25mm

*...*

*...*

*...*

*...mm*

Dec

31

*...*

*...mm*

That way is hard to develop analysis comparing to another year.
Thus, I would like summarize all information in a new (reasonable) table.

I need a command that says: Sum all January 1st, Sum all January 2nd  until
December 31st resulting in something as follows.

*Month       Day->*

*1*

*2*

*3*

*4*

*...*

*31*

*Jan*

40mm

16mm

50mm

66mm

...mm

90mm

*Feb*

60mm

120mm

25mm

45mm

...mm


*...*

...mm

...mm

...mm

...mm

...mm

...mm

*Dec*

120mm

30mm

26mm

90mm

...mm

5mm

The question is: How to manage it?

Does anybody could help me?

Thank you very much in advance

With the best wishes

Jackson M. Rodrigues

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sun Jun 25 23:47:38 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 25 Jun 2017 17:47:38 -0400
Subject: [R] Help to organize data
In-Reply-To: <CAPL76w9ivMmEL6n1vZ6eM797V=JkXbkRKn=974Wmie53FhTpLA@mail.gmail.com>
References: <CAPL76w9ivMmEL6n1vZ6eM797V=JkXbkRKn=974Wmie53FhTpLA@mail.gmail.com>
Message-ID: <CAM_vju=MzWJYQPS4wZsteTRyi-R-dDO+yttK7gUxP=vh50yVrA@mail.gmail.com>

This is pretty badly mangled (please don't post in html), but
?aggregate
is probably what you want.

Sarah

On Sun, Jun 25, 2017 at 5:27 PM, Jackson Rodrigues
<jacksonmrodrigues at gmail.com> wrote:
> Hi everybody,
>
> My name is Jackson and come here ask for a help to organize data.
> I really need help from you. I have several data sets to organize.
>
> I have to summarize precipitation data collected in different days and
> months in only one table.
> However, those data are disperse in days and times. Those rainy days have a
> more observations than drought ones.
>
> Below you can find a hypothetical example of what I have and I what I need
> comes in sequence.
>
> The following table is what I have for a single year.
> Notice that number of observations varies from day to day entire year.
>
>
>
> *Day*
>
> *Time*
>
> *Prec*
>
> Jan
>
>
>
> 1
>
> 7:00
>
> 20mm
>
> 1
>
> 7:20
>
> 15mm
>
> 1
>
> 7:30
>
> 5mm
>
> 2
>
> 6:00
>
> 10mm
>
> 2
>
> 15:00
>
> 16mm
>
> ...
>
> ...
>
> ...mm
>
> 31
>
> 7:00
>
> 2mm
>
> Feb
>
> 1
>
> 9:00
>
> 6mm
>
> 1
>
> 9:45
>
> 30mm
>
> 2
>
> 6:45
>
> 12mm
>
> 2
>
> 16:00
>
> 20mm
>
> 2
>
> 22:00
>
> 60mm
>
> *...*
>
> *...*
>
> *...mm*
>
> 28
>
> 11:30
>
> 25mm
>
> *...*
>
> *...*
>
> *...*
>
> *...mm*
>
> Dec
>
> 31
>
> *...*
>
> *...mm*
>
> That way is hard to develop analysis comparing to another year.
> Thus, I would like summarize all information in a new (reasonable) table.
>
> I need a command that says: Sum all January 1st, Sum all January 2nd  until
> December 31st resulting in something as follows.
>
> *Month       Day->*
>
> *1*
>
> *2*
>
> *3*
>
> *4*
>
> *...*
>
> *31*
>
> *Jan*
>
> 40mm
>
> 16mm
>
> 50mm
>
> 66mm
>
> ...mm
>
> 90mm
>
> *Feb*
>
> 60mm
>
> 120mm
>
> 25mm
>
> 45mm
>
> ...mm
>
>
> *...*
>
> ...mm
>
> ...mm
>
> ...mm
>
> ...mm
>
> ...mm
>
> ...mm
>
> *Dec*
>
> 120mm
>
> 30mm
>
> 26mm
>
> 90mm
>
> ...mm
>
> 5mm
>
> The question is: How to manage it?
>
> Does anybody could help me?
>
> Thank you very much in advance
>
> With the best wishes
>
> Jackson M. Rodrigues
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From mmalten at gmail.com  Sun Jun 25 23:55:24 2017
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Sun, 25 Jun 2017 21:55:24 +0000
Subject: [R] Help to organize data
In-Reply-To: <CAM_vju=MzWJYQPS4wZsteTRyi-R-dDO+yttK7gUxP=vh50yVrA@mail.gmail.com>
References: <CAPL76w9ivMmEL6n1vZ6eM797V=JkXbkRKn=974Wmie53FhTpLA@mail.gmail.com>
 <CAM_vju=MzWJYQPS4wZsteTRyi-R-dDO+yttK7gUxP=vh50yVrA@mail.gmail.com>
Message-ID: <CANOgrHYa7fFa8YQwXhRvqZ1OJxTeAubfqc2i6ehRQu0t-ha8=w@mail.gmail.com>

The tidyverse also has nice functions

On Sun, Jun 25, 2017 at 5:48 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:

> This is pretty badly mangled (please don't post in html), but
> ?aggregate
> is probably what you want.
>
> Sarah
>
> On Sun, Jun 25, 2017 at 5:27 PM, Jackson Rodrigues
> <jacksonmrodrigues at gmail.com> wrote:
> > Hi everybody,
> >
> > My name is Jackson and come here ask for a help to organize data.
> > I really need help from you. I have several data sets to organize.
> >
> > I have to summarize precipitation data collected in different days and
> > months in only one table.
> > However, those data are disperse in days and times. Those rainy days
> have a
> > more observations than drought ones.
> >
> > Below you can find a hypothetical example of what I have and I what I
> need
> > comes in sequence.
> >
> > The following table is what I have for a single year.
> > Notice that number of observations varies from day to day entire year.
> >
> >
> >
> > *Day*
> >
> > *Time*
> >
> > *Prec*
> >
> > Jan
> >
> >
> >
> > 1
> >
> > 7:00
> >
> > 20mm
> >
> > 1
> >
> > 7:20
> >
> > 15mm
> >
> > 1
> >
> > 7:30
> >
> > 5mm
> >
> > 2
> >
> > 6:00
> >
> > 10mm
> >
> > 2
> >
> > 15:00
> >
> > 16mm
> >
> > ...
> >
> > ...
> >
> > ...mm
> >
> > 31
> >
> > 7:00
> >
> > 2mm
> >
> > Feb
> >
> > 1
> >
> > 9:00
> >
> > 6mm
> >
> > 1
> >
> > 9:45
> >
> > 30mm
> >
> > 2
> >
> > 6:45
> >
> > 12mm
> >
> > 2
> >
> > 16:00
> >
> > 20mm
> >
> > 2
> >
> > 22:00
> >
> > 60mm
> >
> > *...*
> >
> > *...*
> >
> > *...mm*
> >
> > 28
> >
> > 11:30
> >
> > 25mm
> >
> > *...*
> >
> > *...*
> >
> > *...*
> >
> > *...mm*
> >
> > Dec
> >
> > 31
> >
> > *...*
> >
> > *...mm*
> >
> > That way is hard to develop analysis comparing to another year.
> > Thus, I would like summarize all information in a new (reasonable) table.
> >
> > I need a command that says: Sum all January 1st, Sum all January 2nd
> until
> > December 31st resulting in something as follows.
> >
> > *Month       Day->*
> >
> > *1*
> >
> > *2*
> >
> > *3*
> >
> > *4*
> >
> > *...*
> >
> > *31*
> >
> > *Jan*
> >
> > 40mm
> >
> > 16mm
> >
> > 50mm
> >
> > 66mm
> >
> > ...mm
> >
> > 90mm
> >
> > *Feb*
> >
> > 60mm
> >
> > 120mm
> >
> > 25mm
> >
> > 45mm
> >
> > ...mm
> >
> >
> > *...*
> >
> > ...mm
> >
> > ...mm
> >
> > ...mm
> >
> > ...mm
> >
> > ...mm
> >
> > ...mm
> >
> > *Dec*
> >
> > 120mm
> >
> > 30mm
> >
> > 26mm
> >
> > 90mm
> >
> > ...mm
> >
> > 5mm
> >
> > The question is: How to manage it?
> >
> > Does anybody could help me?
> >
> > Thank you very much in advance
> >
> > With the best wishes
> >
> > Jackson M. Rodrigues
> >
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Jun 25 23:59:02 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 26 Jun 2017 07:59:02 +1000
Subject: [R] Fill in empty cell in data.frame from previous value
In-Reply-To: <594fd5fd.d269240a.e2fd6.2eec@mx.google.com>
References: <594ea639.0e56240a.7719d.b58e@mx.google.com>
 <CA+8X3fXzrTd6j7sFD=r=3NXwcDEQ1a6jbS30ShgLDFZYskzbMA@mail.gmail.com>
 <594fd5fd.d269240a.e2fd6.2eec@mx.google.com>
Message-ID: <CA+8X3fVdNSfD6RgL0zi1BUwAmvFSbfdcHQcWedqHUBewy5w20g@mail.gmail.com>

That's the kind of help that we like to provide. And for extra marks, you
can write a small function that will deal with consecutive NA values.

Jim

On Mon, Jun 26, 2017 at 1:25 AM, Christophe Elek <christophe.elek at gmail.com>
wrote:

> Perfect Jim, that Is exactly what I needed ? let me check that ...
>
> Cheers
>
>
>
> *From: *Jim Lemon <drjimlemon at gmail.com>
> *Sent: *June 25, 2017 3:11 AM
> *To: *Christophe Elek <christophe.elek at gmail.com>
> *Cc: *r-help at r-project.org
> *Subject: *Re: [R] Fill in empty cell in data.frame from previous value
>
>
>
> Hi Chris,
>
> You may know about the *apply family of functions. These slice various
>
> data structures and "apply" a specified function to each slice,
>
> usually returning a list of return values. As far as I am aware, you
>
> can't access adjacent rows unless you reformat the data structure.
>
>
>
> There is a way to do this particular job. It requires the sequence
>
> operator (:), the ifelse function and indexing. What you do is to
>
> create a sequence of all the values in the element "names", then
>
> subtract 1 for all the NA (or any other specified value) values and
>
> use the resulting vector to index the original element "names". It
>
> won't work if the first value is NA, nor will it work for more than
>
> one NA in a row. I realize that this is pretty obscure, but you said
>
> that you didn't just want the solution. It's a one-liner.
>
>
>
> Jim
>
>
>
> On Sun, Jun 25, 2017 at 3:49 AM, Christophe Elek
>
> <christophe.elek at gmail.com> wrote:
>
> > Hello Total newbie here... I hope I read the guide properly
>
> >
>
> > I have the following data.frame (I read it from a CSV file I cannot
> change)
>
> >
>
> >   names val
>
> > 1 Mandy   1
>
> > 2         2
>
> > 3 John    2
>
> > 4         2
>
> >
>
> > I want to read the row number 2, but I want the first column to be
> ?Mandy? and not null
>
> >
>
> > print (frame[2,])
>
> > 2 Mandy   2
>
> >
>
> > I can manipulate the data.frame once loaded
>
> > How can I fill all cell in column ?names? with the previous value ?
>
> > Or is there a function that will get me the row and fill the ?names?
> column ?
>
> >
>
> > NOTA BENE: I do not want the answer, I want to find it myself but I need
> guidance
>
> > If there is a function, tell me the library and I will search
>
> > If this is an algorithm, tell me generally how you would do and let me
> scratch my head first ?
>
> >
>
> > Thanks Chris
>
> >
>
> >
>
> >         [[alternative HTML version deleted]]
>
> >
>
> > ______________________________________________
>
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> > https://stat.ethz.ch/mailman/listinfo/r-help
>
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Jun 26 00:16:53 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 26 Jun 2017 08:16:53 +1000
Subject: [R] vertical semi-circles in R
In-Reply-To: <DB4PR08MB0111790FB7706E74744491FDABDE0@DB4PR08MB0111.eurprd08.prod.outlook.com>
References: <DB4PR08MB0111790FB7706E74744491FDABDE0@DB4PR08MB0111.eurprd08.prod.outlook.com>
Message-ID: <CA+8X3fXKGQ-5RfjyrBL=E=QWF4OZwDxjagfPE+iZAcavXb-NSA@mail.gmail.com>

Hi Eliza,
How about this:

library(plotrix)
plot(0,type="n")
draw.arc(rep(0,6),seq(0.1,0.6,by=0.1),radius=0.05,
 angle1=3*pi/2,angle2=5*pi/2)

Jim

On Sun, Jun 25, 2017 at 9:34 PM, Eliza B <eliza_botto1 at outlook.com> wrote:
> Dear useRs,
>
>
> I am to teach my students some drawing techniques in R. I started shape of an handle by using the following codes;
>
>>plot(0,0,col="white")
>
>>segments(0,0,0.3,0.3)
>
>>segments(0.3,0.4,0.3,0.3)
>
>>segments(0.3,0.4,0,0.7)
>
>>segments(0,0.7,0,0.6)
>
>>segments(0,0.0,0,0.1)
>
> The coding will draw a section of a handle. Now I want to draw semi circles of radius 0.05 between (0,0.6) and (0,0.1), oriented vertically and outward with mouth facing against the y-axis.
>
> I tried every help available online but to no use.
>
> Thanks in advance,
>
> EB
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Mon Jun 26 00:47:10 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Mon, 26 Jun 2017 00:47:10 +0200
Subject: [R] rJava Broken on Linux + R 3.4
Message-ID: <20170625224710.vgdb7rbfxshdjgjm@chicca>

Dear All,
I think there is something wrong with rJava on any Debian based
distribution.
I may be wrong, but I experiencing exactly the problems mentioned at

https://github.com/amattioc/SDMX/issues/130

and at

https://github.com/s-u/rJava/issues/110

A couple of packages (RJSDMX and xlsx) are now impossible to install
on my debian stretch platform running R 3.4.

It seems I am not the only one experiencing this and it may be due to
some security patches just released.
However, if I run on my machine

> library(rJava)
> .jinit()

I get a segmentation fault, though I was able to install rJava, it
does not seem to work properly.
Does anyone have a fix for that?
Many thanks

Lorenzo


From wangnaike1989 at gmail.com  Mon Jun 26 00:26:58 2017
From: wangnaike1989 at gmail.com (Naike Wang)
Date: Sun, 25 Jun 2017 18:26:58 -0400
Subject: [R] Classic fail-safe N
Message-ID: <CAEMVQekNcpLZ5XgeEhrmTEJXdTf82tpOa2DO41eBRh2WZTY=Tg@mail.gmail.com>

Hi all,
I was conducting a meta-analysis of single proportions(i.e. without a
control group) using the metafor package. When I performed a classic
fail-safe N, I noticed that the result (the number of missing studies that
would bring p-value to the alpha, to be exact)was different than that I got
in Comprehensive Meta-Analysis Version 2.0. I wonder why R and CMA got
different results.

*Below is the R code:*
dat=read.table("Your working directory\\Example.csv",header=T,sep=",")
transf.ies=escalc(xi=cases,ni=total,measure="PLO",data=dat) #I transform
the data using the logit transformation first. In CMA, it also uses the
logit transformation.
transf.pes=rma(yi,vi,data=transf.ies,method="DL",weighted=TRUE) #Pooling
individual effect sizes in the logit scale.
ranktest(transf.pes) #Performing the fail-safe N.

*Below are the results from R:*
Fail-safe N Calculation Using the Rosenthal Approach
Observed Significance Level: <.0001
Target Significance Level:   0.05
Fail-safe N: 8446

*Below are the Classic fail-safe N results from CMA:*
Z-value for observed studies 19.91594
P-value for observed studies 0.00000
Alpha 0.05000
Tails 2.00000
Z for alpha 1.95996
Number of observed studies 58.00000
Number of missing studies that would bring p-value to > alpha 5931.00000

Notice that I got 8446 in R and 5931 in CMA.

Can anyone shed some light on this discrepancy? Thank you!

You can find my data set here:
https://drive.google.com/open?id=0B41wTxciaMqtTEJWZE9sX20wOXM

Best,
Naike

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Jun 26 01:46:22 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 25 Jun 2017 19:46:22 -0400
Subject: [R] Writing my 3D plot function
In-Reply-To: <1627652181.2097203.1498416146575@mail.yahoo.com>
References: <1627652181.2097203.1498416146575.ref@mail.yahoo.com>
 <1627652181.2097203.1498416146575@mail.yahoo.com>
Message-ID: <23AA0668-17B7-4F6B-BBDB-45806C7E99C0@dcn.davis.ca.us>

Please look at what I see in your code below (run-on code mush) to understand part of why it is important for you to send your email as plain text as the Posting Guide indicates.  You might find [1] helpful. 

[1] https://wiki.openstack.org/wiki/MailingListEtiquette
-- 
Sent from my phone. Please excuse my brevity.

On June 25, 2017 2:42:26 PM EDT, Alaios via R-help <r-help at r-project.org> wrote:
>Hi all,I had a question last week on asking for a function that will
>help me draw three different circles on x,y,z axis based on polar
>coordinates (Each X,Y,Z circle are coming from three independent
>measurements of 1-360 polar coordinates). It turned out that there ?is
>no such function in R and thus I am trying to write my own piece of
>code that hopefully I will be able to share. I have spent some time to
>write some code based on the rgl library (Still not 100% sure that this
>was the best option).
>My input are three polar circles X,Y,Z with a good example being the
>image
>belowhttps://www.mathworks.com/help/examples/antenna/win64/xxpolarpattern_helix.png
>
>So for X axis my input is a 2D matrix [360,2] including a single
>measurement per each polar coordinate. The first thing I tried was to
>turn my polar coordinates to cartesian ones by writing two simple
>functions. This works so far and I was able to print three simple
>circles on 3d spaceb but the problem now are the legends I need to put
>that remain on cartesian coordinates. As you can see from the code
>below all circles should have radius 1 (in terms of simplicity) but
>unfortunately I have the cartesian coordinates legends that do not help
>on reading my Figure. You can help me by executing the code below?
>
>require("rgls")
>degreeToRadian<-function(degree){? return ? (0.01745329252*degree)}
>turnPolarToX<-function(Amplitude,Coordinate){? return
>(Amplitude*cos(degreeToRadian(Coordinate)))}
>turnPolarToY<-function(Amplitude,Coordinate){? return
>(Amplitude*sin(degreeToRadian(Coordinate)))}
># Putting the first circle on 3d space. Circle of radius
>1X1<-turnPolarToX(1,1:360)Y1<-turnPolarToY(1,1:360)Z1<-rep(0,360)
># Putting the second circle on 3d space. Circle of radius
>1X2<-turnPolarToX(1,1:360)Y2<-rep(0,360)Z2<-turnPolarToY(1,1:360)
># Putting the third circle on 3d space. Circle of radius
>1X3<-rep(0,360)Y3<-turnPolarToX(1,1:360)Z3<-turnPolarToY(1,1:360)
>Min<-min(X1,Y1,Z1,X2,Y2,Z2,X3,Y3,Z3)Max<-max(X1,Y1,Z1,X2,Y2,Z2,X3,Y3,Z3)plot3d(X1,Y1,Z1,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=FALSE,add=TRUE,col="red",type="l")plot3d(X2,Y2,Z2,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=FALSE,add=TRUE,col="green",type="l")plot3d(X3,Y3,Z3,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=TRUE,add=FALSE,col="blue",type="l")
>Would it be also possible to include an jpeg image file on a rgls plot?
>Thanks a lotRegardsAlex
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Jun 26 02:18:37 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 25 Jun 2017 20:18:37 -0400
Subject: [R] rJava Broken on Linux + R 3.4
In-Reply-To: <20170625224710.vgdb7rbfxshdjgjm@chicca>
References: <20170625224710.vgdb7rbfxshdjgjm@chicca>
Message-ID: <DE711C6F-7603-41D4-866B-45057D347472@dcn.davis.ca.us>

I can't think of a more appropriate time to point out that there is an r-sig-debian mailing list that focuses on operating-system-related issues like this.
-- 
Sent from my phone. Please excuse my brevity.

On June 25, 2017 6:47:10 PM EDT, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
>Dear All,
>I think there is something wrong with rJava on any Debian based
>distribution.
>I may be wrong, but I experiencing exactly the problems mentioned at
>
>https://github.com/amattioc/SDMX/issues/130
>
>and at
>
>https://github.com/s-u/rJava/issues/110
>
>A couple of packages (RJSDMX and xlsx) are now impossible to install
>on my debian stretch platform running R 3.4.
>
>It seems I am not the only one experiencing this and it may be due to
>some security patches just released.
>However, if I run on my machine
>
>> library(rJava)
>> .jinit()
>
>I get a segmentation fault, though I was able to install rJava, it
>does not seem to work properly.
>Does anyone have a fix for that?
>Many thanks
>
>Lorenzo
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Jun 26 02:29:59 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 26 Jun 2017 10:29:59 +1000
Subject: [R] Help please
In-Reply-To: <DM5PR01MB3306D8C5D1D69EB4B4AE5F19BBDE0@DM5PR01MB3306.prod.exchangelabs.com>
References: <DM5PR01MB3306EFB20AFFAFBF73DF7522BBD90@DM5PR01MB3306.prod.exchangelabs.com>
 <CA+8X3fU7=Uf8rnBCw2fPcTd9YXj7r-Zvjza1=eJt8p0RAW81Pw@mail.gmail.com>
 <DM5PR01MB3306D8C5D1D69EB4B4AE5F19BBDE0@DM5PR01MB3306.prod.exchangelabs.com>
Message-ID: <CA+8X3fUKN9_C0uGuc3==moaNmkK4AzpAX67-zF6jaFJ_OJ3PMg@mail.gmail.com>

Hi Rabby,
Before you run your regression, try this:

is.factor(Final$Cor)

If this returns TRUE, then this variable is a factor and it will be
treated as a number of levels rather than a set of numeric values.
This usually happens when a text file is read in and there is at least
one value that cannot be converted to numeric. So if you are doing
something like this:

Final<-read.csv("Final.csv")

Try this:

Final<-read.csv("Final.csv",stringsAsFactors=FALSE)
Final$Cor<-as.numeric(Final$Cor)

If there is at least one NA value in Final$Cor, that is probably what
is causing your problem.

Jim

On Mon, Jun 26, 2017 at 9:38 AM, Sarpong, Rabby <es927716 at ohio.edu> wrote:
> Hello Jim,
>
> Thanks for the response I really appreciate it. I have edited the data over
> and over to correct that. But I am still getting the same results. Is that
> the only way to resolve it please?
>
> -Rabby Sarpong
>
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Sunday, June 25, 2017 3:22:54 AM
> To: Sarpong, Rabby
> Cc: r-help at R-project.org
> Subject: Re: [R] Help please
>
> Hi Rabby,
> It looks to me as though your variable Final$Cor is being treated as a
> factor rather than a numeric value. This may be due to one or more
> non-numeric values occurring in the data that is read in. Also you do
> not have to use the Final$* notation in the formula as you have
> specified the data frame "Final".
>
> Jim
>
>
> On Sun, Jun 25, 2017 at 2:17 AM, Sarpong, Rabby <es927716 at ohio.edu> wrote:
>> Hello,
>>
>>
>> I need some help on a regression I am running please. I am running a
>> multiple regression in R and I am getting weird outputs and would like your
>> help in resolving it.
>>
>> This is the code I run:
>>
>>
>> Reg = lm (Final$Y.t.-Final$Y.t.1.  ~ Final$ Y.t.1. + Final$Cor +
>> Final$Gov+ Final$Inv+ Final$TrOp + Final$Pop+ Final$Sch  , data = Final)
>> summary(Reg)
>>
>>
>> And the output I get is pasted below. As shown, highlighted variable is
>> regressed more than once which should not be the case and I am not sure why
>> that is the case. I have checked my data and nothing seems out of the
>> ordinary. What could be wrong please?
>>
>>
>> PS. I am still learning to use R.
>>
>>
>> Thank you,
>>
>> Rabby
>>
>>
>>
>> Residuals:
>>      Min       1Q   Median       3Q      Max
>> -1.04279 -0.06739  0.00124  0.06376  1.59115
>>
>> Coefficients:
>>                Estimate Std. Error t value Pr(>|t|)
>> (Intercept)   0.1045711  0.0867584   1.205 0.228308
>> Final$Y.t.1. -0.0313686  0.0058536  -5.359 9.95e-08 ***
>> Final$Cor10   0.0009784  0.1622916   0.006 0.995191
>> Final$Cor11   0.1230775  0.1165864   1.056 0.291318
>> Final$Cor12   0.1615939  0.1086529   1.487 0.137199
>> Final$Cor13   0.1934974  0.1160577   1.667 0.095713 .
>> Final$Cor14   0.2341660  0.1286909   1.820 0.069057 .
>> Final$Cor15   0.0744373  0.1036776   0.718 0.472909
>> Final$Cor16   0.1964904  0.0932540   2.107 0.035311 *
>> Final$Cor17   0.1989502  0.0908614   2.190 0.028736 *
>> Final$Cor18   0.1993614  0.0886491   2.249 0.024692 *
>> Final$Cor19   0.2062234  0.0878018   2.349 0.018991 *
>> Final$Cor20   0.1889846  0.0868192   2.177 0.029683 *
>> Final$Cor21   0.1717589  0.0855883   2.007 0.044984 *
>> Final$Cor22   0.1453460  0.0856982   1.696 0.090129 .
>> Final$Cor23   0.1976086  0.0871142   2.268 0.023474 *
>> Final$Cor24   0.1471384  0.0859318   1.712 0.087093 .
>> Final$Cor25   0.1447194  0.0851309   1.700 0.089384 .
>> Final$Cor26   0.1553640  0.0855425   1.816 0.069574 .
>> Final$Cor27   0.1220044  0.0854661   1.428 0.153678
>> Final$Cor28   0.1406044  0.0854213   1.646 0.100011
>> Final$Cor29   0.1594371  0.0860525   1.853 0.064146 .
>> Final$Cor30   0.1792005  0.0863734   2.075 0.038215 *
>> Final$Cor31   0.1376306  0.0871176   1.580 0.114398
>> Final$Cor32   0.1521694  0.0865125   1.759 0.078832 .
>> Final$Cor33   0.1535856  0.0863890   1.778 0.075671 .
>> Final$Cor34   0.1327356  0.0865482   1.534 0.125364
>> Final$Cor35   0.1501163  0.0864312   1.737 0.082661 .
>> Final$Cor36   0.1114404  0.0866389   1.286 0.198587
>> Final$Cor37   0.1326494  0.0873405   1.519 0.129073
>> Final$Cor38   0.0993100  0.0869474   1.142 0.253594
>> Final$Cor39   0.1346916  0.0885424   1.521 0.128458
>> Final$Cor4    0.0306186  0.1625561   0.188 0.850627
>> Final$Cor40   0.1596858  0.0906725   1.761 0.078459 .
>> Final$Cor41   0.1330054  0.0881280   1.509 0.131491
>> Final$Cor42   0.1355948  0.0911754   1.487 0.137216
>> Final$Cor43   0.1106947  0.0921995   1.201 0.230132
>> Final$Cor44   0.1525535  0.0923625   1.652 0.098848 .
>> Final$Cor45   0.0885523  0.0918222   0.964 0.335036
>> Final$Cor46   0.1594086  0.0911042   1.750 0.080406 .
>> Final$Cor47   0.1874162  0.0909010   2.062 0.039435 *
>> Final$Cor48   0.1746566  0.0901044   1.938 0.052800 .
>> Final$Cor49   0.1248750  0.0915038   1.365 0.172592
>> Final$Cor50   0.1270500  0.0900791   1.410 0.158660
>> Final$Cor51   0.0798476  0.0906523   0.881 0.378587
>> Final$Cor52   0.0697894  0.0918425   0.760 0.447468
>> Final$Cor53   0.1632391  0.0930509   1.754 0.079622 .
>> Final$Cor54   0.1143655  0.0933946   1.225 0.220977
>> Final$Cor55   0.0991357  0.0928684   1.067 0.285957
>> Final$Cor56   0.1191313  0.0975565   1.221 0.222257
>> Final$Cor57   0.1288024  0.0939890   1.370 0.170807
>> Final$Cor58   0.1249315  0.0951040   1.314 0.189209
>> Final$Cor59   0.2100375  0.1020216   2.059 0.039723 *
>> Final$Cor60   0.1303076  0.0944493   1.380 0.167937
>> Final$Cor61   0.0928124  0.1056764   0.878 0.379964
>> Final$Cor62   0.0767684  0.1296343   0.592 0.553828
>> Final$Cor63   0.1133221  0.1174685   0.965 0.334879
>> Final$Cor64   0.1412303  0.0978915   1.443 0.149347
>> Final$Cor65   0.1382271  0.1098535   1.258 0.208522
>> Final$Cor66   0.0982404  0.1057428   0.929 0.353041
>> Final$Cor67   0.1893438  0.1022572   1.852 0.064311 .
>> Final$Cor68   0.1578940  0.1634072   0.966 0.334099
>> Final$Cor69   0.2166677  0.1021570   2.121 0.034123 *
>> Final$Cor70   0.1143033  0.1054570   1.084 0.278623
>> Final$Cor71   0.1469311  0.1637571   0.897 0.369757
>> Final$Cor72   0.2268878  0.1103408   2.056 0.039964 *
>> Final$Cor73   0.1925218  0.1055544   1.824 0.068402 .
>> Final$Cor74   0.1574432  0.1020634   1.543 0.123178
>> Final$Cor75   0.0571227  0.1166594   0.490 0.624464
>> Final$Cor76   0.1096049  0.1634571   0.671 0.502635
>> Final$Cor78   0.0949307  0.1305748   0.727 0.467347
>> Final$Cor8    0.1082102  0.1289245   0.839 0.401443
>> Final$Gov    -0.0016397  0.0008084  -2.028 0.042736 *
>> Final$Inv     0.0016819  0.0004667   3.604 0.000326 ***
>> Final$TrOp    0.0002904  0.0001209   2.402 0.016445 *
>> Final$Pop    -0.0130554  0.0038839  -3.361 0.000799 ***
>> Final$Sch     0.0005785  0.0002696   2.146 0.032064 *
>> ---
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bhaskar.kolkata at gmail.com  Mon Jun 26 04:35:42 2017
From: bhaskar.kolkata at gmail.com (Bhaskar Mitra)
Date: Sun, 25 Jun 2017 22:35:42 -0400
Subject: [R] Request for help - adding text files to a data frame
Message-ID: <CAEGXkYVp3Hm2r0aOFszz-TZ6EePVUEAxndCUa4=698ErmYeUNw@mail.gmail.com>

Hello Everyone,

I have a data frame which looks something like this:

    V1 <-c(1,2,3)
    V2 <-c(5,6,7)
    V3 <-c(9,10,11)

     df <- data.frame(V1,V2,V3)

I want to add couple of text files at the beginning of df and save
the df as a csv file.


The csv file should look something like this:

"AAAAAAAA"
"BBBBBBBBB"
"CCCCCCCCC"
V1  V2 V3
1    5  9
2    6   10
3    7   11


Any suggestions/advice in this regard.

Thanks for your help,
Bhaskar

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Mon Jun 26 07:05:17 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 26 Jun 2017 13:05:17 +0800
Subject: [R] How to code the factor for ANOVA
Message-ID: <7de6f14a-a682-6373-7f2b-91e8ee6f6253@yeah.net>

Hi there,

I have a experimental design related question. I have done a experiment 
with 3 factors. The design matrix is similar to:

> data.frame(Factor.1 = rep(rep(0:2, each = 3),3), Factor.2 = 
rep(c("U","S","N"), 9), Factor.3 = rep(0:2, each = 9))
    Factor.1 Factor.2 Factor.3
1         0        U        0
2         0        S        0
3         0        N        0
4         1        U        0
5         1        S        0
6         1        N        0
7         2        U        0
8         2        S        0
9         2        N        0
10        0        U        1
11        0        S        1
12        0        N        1
13        1        U        1
14        1        S        1
15        1        N        1
16        2        U        1
17        2        S        1
18        2        N        1
19        0        U        2
20        0        S        2
21        0        N        2
22        1        U        2
23        1        S        2
24        1        N        2
25        2        U        2
26        2        S        2
27        2        N        2

The Factor.2 indicates the type of a fertilizer, such as urea, and the 
Factor.3 indicates the weight of the fertilizer. So the treatments with 
Factor.3 == 0 at each levels of Factor.1 are same. That means No.1, No.2 
and No.3 are same, No.4, No.5 and No.6 are same, and No.7, No.8 and No.9 
are same. Thus, in the real experiment, those treatments were not 
performed as stated in the design matrix. For instance, only No.1, No.5 
and No.9 are performed.

In the case, how to code the factor for ANOVA? I really appreciate any 
comments and suggestions. Thanks in advance.

Best regards,
Jinsong


From bgunter.4567 at gmail.com  Mon Jun 26 07:42:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Jun 2017 22:42:52 -0700
Subject: [R] Help please
In-Reply-To: <CA+8X3fUKN9_C0uGuc3==moaNmkK4AzpAX67-zF6jaFJ_OJ3PMg@mail.gmail.com>
References: <DM5PR01MB3306EFB20AFFAFBF73DF7522BBD90@DM5PR01MB3306.prod.exchangelabs.com>
 <CA+8X3fU7=Uf8rnBCw2fPcTd9YXj7r-Zvjza1=eJt8p0RAW81Pw@mail.gmail.com>
 <DM5PR01MB3306D8C5D1D69EB4B4AE5F19BBDE0@DM5PR01MB3306.prod.exchangelabs.com>
 <CA+8X3fUKN9_C0uGuc3==moaNmkK4AzpAX67-zF6jaFJ_OJ3PMg@mail.gmail.com>
Message-ID: <CAGxFJbQTfbt7967aFvsBUr8GHCHy18V-6Q2ZWPUvuHR6wXNfvA@mail.gmail.com>

On Sun, Jun 25, 2017 at 5:29 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Rabby,
> Before you run your regression, try this:
>
> is.factor(Final$Cor)
>
> If this returns TRUE, then this variable is a factor and it will be
> treated as a number of levels rather than a set of numeric values.
> This usually happens when a text file is read in and there is at least
> one value that cannot be converted to numeric. So if you are doing
> something like this:
>
> Final<-read.csv("Final.csv")
>
> Try this:
>
> Final<-read.csv("Final.csv",stringsAsFactors=FALSE)
> Final$Cor<-as.numeric(Final$Cor)
>
> If there is at least one NA value in Final$Cor, that is probably what
> is causing your problem.

I don't think so. If Final$Cor is numeric to begin with, there should
be no problem with NA's. Commas or other stray characters might be the
problem, however. As always, consulting ?read.csv should be the first
stop.

The OP would probably benefit by spending some time with an R tutorial
or two(there are many good ones on teh web), I think, where such
issues are often discussed.

Cheers,
Bert


>
> Jim
>
> On Mon, Jun 26, 2017 at 9:38 AM, Sarpong, Rabby <es927716 at ohio.edu> wrote:
>> Hello Jim,
>>
>> Thanks for the response I really appreciate it. I have edited the data over
>> and over to correct that. But I am still getting the same results. Is that
>> the only way to resolve it please?
>>
>> -Rabby Sarpong
>>
>> ________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Sunday, June 25, 2017 3:22:54 AM
>> To: Sarpong, Rabby
>> Cc: r-help at R-project.org
>> Subject: Re: [R] Help please
>>
>> Hi Rabby,
>> It looks to me as though your variable Final$Cor is being treated as a
>> factor rather than a numeric value. This may be due to one or more
>> non-numeric values occurring in the data that is read in. Also you do
>> not have to use the Final$* notation in the formula as you have
>> specified the data frame "Final".
>>
>> Jim
>>
>>
>> On Sun, Jun 25, 2017 at 2:17 AM, Sarpong, Rabby <es927716 at ohio.edu> wrote:
>>> Hello,
>>>
>>>
>>> I need some help on a regression I am running please. I am running a
>>> multiple regression in R and I am getting weird outputs and would like your
>>> help in resolving it.
>>>
>>> This is the code I run:
>>>
>>>
>>> Reg = lm (Final$Y.t.-Final$Y.t.1.  ~ Final$ Y.t.1. + Final$Cor +
>>> Final$Gov+ Final$Inv+ Final$TrOp + Final$Pop+ Final$Sch  , data = Final)
>>> summary(Reg)
>>>
>>>
>>> And the output I get is pasted below. As shown, highlighted variable is
>>> regressed more than once which should not be the case and I am not sure why
>>> that is the case. I have checked my data and nothing seems out of the
>>> ordinary. What could be wrong please?
>>>
>>>
>>> PS. I am still learning to use R.
>>>
>>>
>>> Thank you,
>>>
>>> Rabby
>>>
>>>
>>>
>>> Residuals:
>>>      Min       1Q   Median       3Q      Max
>>> -1.04279 -0.06739  0.00124  0.06376  1.59115
>>>
>>> Coefficients:
>>>                Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)   0.1045711  0.0867584   1.205 0.228308
>>> Final$Y.t.1. -0.0313686  0.0058536  -5.359 9.95e-08 ***
>>> Final$Cor10   0.0009784  0.1622916   0.006 0.995191
>>> Final$Cor11   0.1230775  0.1165864   1.056 0.291318
>>> Final$Cor12   0.1615939  0.1086529   1.487 0.137199
>>> Final$Cor13   0.1934974  0.1160577   1.667 0.095713 .
>>> Final$Cor14   0.2341660  0.1286909   1.820 0.069057 .
>>> Final$Cor15   0.0744373  0.1036776   0.718 0.472909
>>> Final$Cor16   0.1964904  0.0932540   2.107 0.035311 *
>>> Final$Cor17   0.1989502  0.0908614   2.190 0.028736 *
>>> Final$Cor18   0.1993614  0.0886491   2.249 0.024692 *
>>> Final$Cor19   0.2062234  0.0878018   2.349 0.018991 *
>>> Final$Cor20   0.1889846  0.0868192   2.177 0.029683 *
>>> Final$Cor21   0.1717589  0.0855883   2.007 0.044984 *
>>> Final$Cor22   0.1453460  0.0856982   1.696 0.090129 .
>>> Final$Cor23   0.1976086  0.0871142   2.268 0.023474 *
>>> Final$Cor24   0.1471384  0.0859318   1.712 0.087093 .
>>> Final$Cor25   0.1447194  0.0851309   1.700 0.089384 .
>>> Final$Cor26   0.1553640  0.0855425   1.816 0.069574 .
>>> Final$Cor27   0.1220044  0.0854661   1.428 0.153678
>>> Final$Cor28   0.1406044  0.0854213   1.646 0.100011
>>> Final$Cor29   0.1594371  0.0860525   1.853 0.064146 .
>>> Final$Cor30   0.1792005  0.0863734   2.075 0.038215 *
>>> Final$Cor31   0.1376306  0.0871176   1.580 0.114398
>>> Final$Cor32   0.1521694  0.0865125   1.759 0.078832 .
>>> Final$Cor33   0.1535856  0.0863890   1.778 0.075671 .
>>> Final$Cor34   0.1327356  0.0865482   1.534 0.125364
>>> Final$Cor35   0.1501163  0.0864312   1.737 0.082661 .
>>> Final$Cor36   0.1114404  0.0866389   1.286 0.198587
>>> Final$Cor37   0.1326494  0.0873405   1.519 0.129073
>>> Final$Cor38   0.0993100  0.0869474   1.142 0.253594
>>> Final$Cor39   0.1346916  0.0885424   1.521 0.128458
>>> Final$Cor4    0.0306186  0.1625561   0.188 0.850627
>>> Final$Cor40   0.1596858  0.0906725   1.761 0.078459 .
>>> Final$Cor41   0.1330054  0.0881280   1.509 0.131491
>>> Final$Cor42   0.1355948  0.0911754   1.487 0.137216
>>> Final$Cor43   0.1106947  0.0921995   1.201 0.230132
>>> Final$Cor44   0.1525535  0.0923625   1.652 0.098848 .
>>> Final$Cor45   0.0885523  0.0918222   0.964 0.335036
>>> Final$Cor46   0.1594086  0.0911042   1.750 0.080406 .
>>> Final$Cor47   0.1874162  0.0909010   2.062 0.039435 *
>>> Final$Cor48   0.1746566  0.0901044   1.938 0.052800 .
>>> Final$Cor49   0.1248750  0.0915038   1.365 0.172592
>>> Final$Cor50   0.1270500  0.0900791   1.410 0.158660
>>> Final$Cor51   0.0798476  0.0906523   0.881 0.378587
>>> Final$Cor52   0.0697894  0.0918425   0.760 0.447468
>>> Final$Cor53   0.1632391  0.0930509   1.754 0.079622 .
>>> Final$Cor54   0.1143655  0.0933946   1.225 0.220977
>>> Final$Cor55   0.0991357  0.0928684   1.067 0.285957
>>> Final$Cor56   0.1191313  0.0975565   1.221 0.222257
>>> Final$Cor57   0.1288024  0.0939890   1.370 0.170807
>>> Final$Cor58   0.1249315  0.0951040   1.314 0.189209
>>> Final$Cor59   0.2100375  0.1020216   2.059 0.039723 *
>>> Final$Cor60   0.1303076  0.0944493   1.380 0.167937
>>> Final$Cor61   0.0928124  0.1056764   0.878 0.379964
>>> Final$Cor62   0.0767684  0.1296343   0.592 0.553828
>>> Final$Cor63   0.1133221  0.1174685   0.965 0.334879
>>> Final$Cor64   0.1412303  0.0978915   1.443 0.149347
>>> Final$Cor65   0.1382271  0.1098535   1.258 0.208522
>>> Final$Cor66   0.0982404  0.1057428   0.929 0.353041
>>> Final$Cor67   0.1893438  0.1022572   1.852 0.064311 .
>>> Final$Cor68   0.1578940  0.1634072   0.966 0.334099
>>> Final$Cor69   0.2166677  0.1021570   2.121 0.034123 *
>>> Final$Cor70   0.1143033  0.1054570   1.084 0.278623
>>> Final$Cor71   0.1469311  0.1637571   0.897 0.369757
>>> Final$Cor72   0.2268878  0.1103408   2.056 0.039964 *
>>> Final$Cor73   0.1925218  0.1055544   1.824 0.068402 .
>>> Final$Cor74   0.1574432  0.1020634   1.543 0.123178
>>> Final$Cor75   0.0571227  0.1166594   0.490 0.624464
>>> Final$Cor76   0.1096049  0.1634571   0.671 0.502635
>>> Final$Cor78   0.0949307  0.1305748   0.727 0.467347
>>> Final$Cor8    0.1082102  0.1289245   0.839 0.401443
>>> Final$Gov    -0.0016397  0.0008084  -2.028 0.042736 *
>>> Final$Inv     0.0016819  0.0004667   3.604 0.000326 ***
>>> Final$TrOp    0.0002904  0.0001209   2.402 0.016445 *
>>> Final$Pop    -0.0130554  0.0038839  -3.361 0.000799 ***
>>> Final$Sch     0.0005785  0.0002696   2.146 0.032064 *
>>> ---
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Jun 26 07:47:18 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Jun 2017 22:47:18 -0700
Subject: [R] How to code the factor for ANOVA
In-Reply-To: <7de6f14a-a682-6373-7f2b-91e8ee6f6253@yeah.net>
References: <7de6f14a-a682-6373-7f2b-91e8ee6f6253@yeah.net>
Message-ID: <CAGxFJbQ__ExpSgJ8SDo4snqu=wPyvzP0o-NNDqR-sgSfW2bn2g@mail.gmail.com>

You really really need to go through one of the many R (web) tutorials
where this is discussed in detail. Or see the Intro to R tutorial that
ships with R. This is not the proper venue for learning how R handles
linear models and how its formula interface works. A terse treatment
can be found in ?lm, ?aov, and ?formula and links therein, but a
suitable tutorial would probably be a better alternative.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 25, 2017 at 10:05 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
> Hi there,
>
> I have a experimental design related question. I have done a experiment with
> 3 factors. The design matrix is similar to:
>
>> data.frame(Factor.1 = rep(rep(0:2, each = 3),3), Factor.2 =
>
> rep(c("U","S","N"), 9), Factor.3 = rep(0:2, each = 9))
>    Factor.1 Factor.2 Factor.3
> 1         0        U        0
> 2         0        S        0
> 3         0        N        0
> 4         1        U        0
> 5         1        S        0
> 6         1        N        0
> 7         2        U        0
> 8         2        S        0
> 9         2        N        0
> 10        0        U        1
> 11        0        S        1
> 12        0        N        1
> 13        1        U        1
> 14        1        S        1
> 15        1        N        1
> 16        2        U        1
> 17        2        S        1
> 18        2        N        1
> 19        0        U        2
> 20        0        S        2
> 21        0        N        2
> 22        1        U        2
> 23        1        S        2
> 24        1        N        2
> 25        2        U        2
> 26        2        S        2
> 27        2        N        2
>
> The Factor.2 indicates the type of a fertilizer, such as urea, and the
> Factor.3 indicates the weight of the fertilizer. So the treatments with
> Factor.3 == 0 at each levels of Factor.1 are same. That means No.1, No.2 and
> No.3 are same, No.4, No.5 and No.6 are same, and No.7, No.8 and No.9 are
> same. Thus, in the real experiment, those treatments were not performed as
> stated in the design matrix. For instance, only No.1, No.5 and No.9 are
> performed.
>
> In the case, how to code the factor for ANOVA? I really appreciate any
> comments and suggestions. Thanks in advance.
>
> Best regards,
> Jinsong
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Jun 26 07:50:43 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Jun 2017 22:50:43 -0700
Subject: [R] Request for help - adding text files to a data frame
In-Reply-To: <CAEGXkYVp3Hm2r0aOFszz-TZ6EePVUEAxndCUa4=698ErmYeUNw@mail.gmail.com>
References: <CAEGXkYVp3Hm2r0aOFszz-TZ6EePVUEAxndCUa4=698ErmYeUNw@mail.gmail.com>
Message-ID: <CAGxFJbRgJdxaKCYJyUkiaOxtySJr5c_Ach83R3MuJEgiR-o9bQ@mail.gmail.com>

You appear to either be ignorant of the structure pf data frames or
have not expressed yourself clearly enough (for me, anyway). Please go
through a tutorial to learn about the fixed structure of data frames,
for which your request does not appear to reflect an understanding.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 25, 2017 at 7:35 PM, Bhaskar Mitra
<bhaskar.kolkata at gmail.com> wrote:
> Hello Everyone,
>
> I have a data frame which looks something like this:
>
>     V1 <-c(1,2,3)
>     V2 <-c(5,6,7)
>     V3 <-c(9,10,11)
>
>      df <- data.frame(V1,V2,V3)
>
> I want to add couple of text files at the beginning of df and save
> the df as a csv file.
>
>
> The csv file should look something like this:
>
> "AAAAAAAA"
> "BBBBBBBBB"
> "CCCCCCCCC"
> V1  V2 V3
> 1    5  9
> 2    6   10
> 3    7   11
>
>
> Any suggestions/advice in this regard.
>
> Thanks for your help,
> Bhaskar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Jun 26 08:24:39 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 25 Jun 2017 23:24:39 -0700
Subject: [R] Request for help - adding text files to a data frame
In-Reply-To: <CAEGXkYVp3Hm2r0aOFszz-TZ6EePVUEAxndCUa4=698ErmYeUNw@mail.gmail.com>
References: <CAEGXkYVp3Hm2r0aOFszz-TZ6EePVUEAxndCUa4=698ErmYeUNw@mail.gmail.com>
Message-ID: <7DCE9CE5-A4F9-4C74-9CC4-73FF748FACD8@comcast.net>


> On Jun 25, 2017, at 7:35 PM, Bhaskar Mitra <bhaskar.kolkata at gmail.com> wrote:
> 
> Hello Everyone,
> 
> I have a data frame which looks something like this:
> 
>    V1 <-c(1,2,3)
>    V2 <-c(5,6,7)
>    V3 <-c(9,10,11)
> 
>     df <- data.frame(V1,V2,V3)
> 
> I want to add couple of text files at the beginning of df and save
> the df as a csv file.
> 
> 
> The csv file should look something like this:
> 
> "AAAAAAAA"
> "BBBBBBBBB"
> "CCCCCCCCC"
> V1  V2 V3
> 1    5  9
> 2    6   10
> 3    7   11

Why exactly would that be called a csv file? (It has no commas.)

At any rate discrepancies like that get resolved in favor of the example and my suggestion would be:

First look carefully at:

?write.table   # and read all the Arguments and Details sections

... as well as following all of the links from that help page that appear just above the Examples.

write(c("AAAAAAAA",
"BBBBBBBBB",
"CCCCCCCCC"), file="test.txt")
write.table(df, file="test.txt", append=TRUE,quote=FALSE,row.names=FALSE)
rning message:


> 
> 
> Any suggestions/advice in this regard.
> 
> Thanks for your help,
> Bhaskar
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From petr.pikal at precheza.cz  Mon Jun 26 08:26:19 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 26 Jun 2017 06:26:19 +0000
Subject: [R] Fill in empty cell in data.frame from previous value
In-Reply-To: <594fd60d.c8986b0a.93693.2014@mx.google.com>
References: <594ea639.0e56240a.7719d.b58e@mx.google.com>
 <71855C3F-5618-4DB7-996B-BC26E254C3D6@utoronto.ca>
 <594fd60d.c8986b0a.93693.2014@mx.google.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A939B@SRVEXCHCM301.precheza.cz>

Hi

Maybe I am missing something but in package "zoo" is function "na.locf", which fills empty cells with previous value.

So when you read your file

dat<-read.table("....", na="")

you can use

library(zoo)
sapply(dat, na.locf)

the only problem is that it changes factors to numeric representation. It is solved here

https://stackoverflow.com/questions/22771260/na-locf-converts-data-from-numeric-to-character

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Christophe
> Elek
> Sent: Sunday, June 25, 2017 5:26 PM
> To: Boris Steipe <boris.steipe at utoronto.ca>
> Cc: r-help at r-project.org
> Subject: Re: [R] Fill in empty cell in data.frame from previous value
>
> Excellent Boris, thx ? this helps
>
> From: Boris Steipe
> Sent: June 25, 2017 11:23 AM
> To: Christophe Elek
> Cc: r-help at r-project.org
> Subject: Re: [R] Fill in empty cell in data.frame from previous value
>
> Run it through a loop. I assume the cell contents is NA (Not Available). Test for
> it with is.na(). Whenever that returns TRUE, replace the NA value with the
> value from the previous row.
>
> Cheers,
> B.
>
>
>
> > On Jun 24, 2017, at 1:49 PM, Christophe Elek <christophe.elek at gmail.com>
> wrote:
> >
> > Hello Total newbie here... I hope I read the guide properly
> >
> > I have the following data.frame (I read it from a CSV file I cannot
> > change)
> >
> >  names val
> > 1 Mandy   1
> > 2         2
> > 3 John    2
> > 4         2
> >
> > I want to read the row number 2, but I want the first column to be
> > ?Mandy? and not null
> >
> > print (frame[2,])
> > 2 Mandy   2
> >
> > I can manipulate the data.frame once loaded How can I fill all cell in
> > column ?names? with the previous value ?
> > Or is there a function that will get me the row and fill the ?names? column ?
> >
> > NOTA BENE: I do not want the answer, I want to find it myself but I
> > need guidance If there is a function, tell me the library and I will
> > search If this is an algorithm, tell me generally how you would do and
> > let me scratch my head first ?
> >
> > Thanks Chris
> >
> >
> >     [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From wangnaike1989 at gmail.com  Mon Jun 26 08:31:45 2017
From: wangnaike1989 at gmail.com (Naike Wang)
Date: Mon, 26 Jun 2017 06:31:45 +0000
Subject: [R] Classic fail-safe N
Message-ID: <CAEMVQe=prGRri9uPYO6t8nikz+m_KjGkisKnPSjfaT7gqtr4RA@mail.gmail.com>

Hi all,
I was conducting a meta-analysis of single proportions(i.e. without a
control group) using the metafor package. When I performed a classic
fail-safe N, I noticed that the result (the number of missing studies that
would bring p-value to the alpha, to be exact)was different than that I got
in Comprehensive Meta-Analysis Version 2.0. I wonder why R and CMA got
different results.

*Below is the R code:*
dat=read.table("Your working directory\\Example.csv",header=T,sep=",")
transf.ies=escalc(xi=cases,ni=total,measure="PLO",data=dat) #I transform
the data using the logit transformation first. In CMA, it also uses the
logit transformation.
transf.pes=rma(yi,vi,data=transf.ies,method="DL",weighted=TRUE) #Pooling
individual effect sizes in the logit scale.
ranktest(transf.pes) #Performing the fail-safe N.

*Below are the results from R:*
Fail-safe N Calculation Using the Rosenthal Approach
Observed Significance Level: <.0001
Target Significance Level:   0.05
Fail-safe N: 8446

*Below are the Classic fail-safe N results from CMA:*
Z-value for observed studies 19.91594
P-value for observed studies 0.00000
Alpha 0.05000
Tails 2.00000
Z for alpha 1.95996
Number of observed studies 58.00000
Number of missing studies that would bring p-value to > alpha 5931.00000

Notice that I got 8446 in R and 5931 in CMA.

Can anyone shed some light on this discrepancy? Thank you!

You can find my data set here:
https://drive.google.com/open?id=0B41wTxciaMqtTEJWZE9sX20wOXM

Best,
Naike

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Jun 26 09:39:37 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Mon, 26 Jun 2017 07:39:37 +0000
Subject: [R] Classic fail-safe N
In-Reply-To: <CAEMVQe=prGRri9uPYO6t8nikz+m_KjGkisKnPSjfaT7gqtr4RA@mail.gmail.com>
References: <CAEMVQe=prGRri9uPYO6t8nikz+m_KjGkisKnPSjfaT7gqtr4RA@mail.gmail.com>
Message-ID: <c6f8cb3bb3314644b57f1867fae03d29@UM-MAIL3216.unimaas.nl>

I would suggest to post this to the (recently created) R-sig-meta-analysis mailing list. See:

https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis

Best,
Wolfgang

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Naike Wang
>Sent: Monday, June 26, 2017 08:32
>To: R-help at r-project.org
>Subject: [R] Classic fail-safe N
>
>Hi all,
>I was conducting a meta-analysis of single proportions(i.e. without a
>control group) using the metafor package. When I performed a classic
>fail-safe N, I noticed that the result (the number of missing studies that
>would bring p-value to the alpha, to be exact)was different than that I
>got
>in Comprehensive Meta-Analysis Version 2.0. I wonder why R and CMA got
>different results.
>
>*Below is the R code:*
>dat=read.table("Your working directory\\Example.csv",header=T,sep=",")
>transf.ies=escalc(xi=cases,ni=total,measure="PLO",data=dat) #I transform
>the data using the logit transformation first. In CMA, it also uses the
>logit transformation.
>transf.pes=rma(yi,vi,data=transf.ies,method="DL",weighted=TRUE) #Pooling
>individual effect sizes in the logit scale.
>ranktest(transf.pes) #Performing the fail-safe N.
>
>*Below are the results from R:*
>Fail-safe N Calculation Using the Rosenthal Approach
>Observed Significance Level: <.0001
>Target Significance Level:   0.05
>Fail-safe N: 8446
>
>*Below are the Classic fail-safe N results from CMA:*
>Z-value for observed studies 19.91594
>P-value for observed studies 0.00000
>Alpha 0.05000
>Tails 2.00000
>Z for alpha 1.95996
>Number of observed studies 58.00000
>Number of missing studies that would bring p-value to > alpha 5931.00000
>
>Notice that I got 8446 in R and 5931 in CMA.
>
>Can anyone shed some light on this discrepancy? Thank you!
>
>You can find my data set here:
>https://drive.google.com/open?id=0B41wTxciaMqtTEJWZE9sX20wOXM
>
>Best,
>Naike


From drjimlemon at gmail.com  Mon Jun 26 12:14:36 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 26 Jun 2017 20:14:36 +1000
Subject: [R] Request for help - adding text files to a data frame
In-Reply-To: <CAEGXkYVp3Hm2r0aOFszz-TZ6EePVUEAxndCUa4=698ErmYeUNw@mail.gmail.com>
References: <CAEGXkYVp3Hm2r0aOFszz-TZ6EePVUEAxndCUa4=698ErmYeUNw@mail.gmail.com>
Message-ID: <CA+8X3fXTP8txA_na870G_WeBm082v_Kwo55FGuJM3yOD7sQNnA@mail.gmail.com>

Hi Bhaskar,
You can put all sorts of stuff into a text file simply by using the
"sink" command:

sink("bm.txt")
cat("AAAAAAAA\n")
B9<-"BBBBBBBBB"
cat(B9,"\n",sep="")
for(i in 1:9) cat("C")
cat("\n")
print(df)
sink()

What you intend to do with a file like this is beyond me.

Jim

On Mon, Jun 26, 2017 at 12:35 PM, Bhaskar Mitra
<bhaskar.kolkata at gmail.com> wrote:
> Hello Everyone,
>
> I have a data frame which looks something like this:
>
>     V1 <-c(1,2,3)
>     V2 <-c(5,6,7)
>     V3 <-c(9,10,11)
>
>      df <- data.frame(V1,V2,V3)
>
> I want to add couple of text files at the beginning of df and save
> the df as a csv file.
>
>
> The csv file should look something like this:
>
> "AAAAAAAA"
> "BBBBBBBBB"
> "CCCCCCCCC"
> V1  V2 V3
> 1    5  9
> 2    6   10
> 3    7   11
>
>
> Any suggestions/advice in this regard.
>
> Thanks for your help,
> Bhaskar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wangnaike1989 at gmail.com  Mon Jun 26 13:29:00 2017
From: wangnaike1989 at gmail.com (Naike Wang)
Date: Mon, 26 Jun 2017 11:29:00 +0000
Subject: [R] Classic fail-safe N
In-Reply-To: <c6f8cb3bb3314644b57f1867fae03d29@UM-MAIL3216.unimaas.nl>
References: <CAEMVQe=prGRri9uPYO6t8nikz+m_KjGkisKnPSjfaT7gqtr4RA@mail.gmail.com>
 <c6f8cb3bb3314644b57f1867fae03d29@UM-MAIL3216.unimaas.nl>
Message-ID: <CAEMVQekaPBnYF6-Utc7+uvGCfshDnWdoS6YjDewWFmVcvLdVJA@mail.gmail.com>

Will do, thanks!

Viechtbauer Wolfgang (SP)
<wolfgang.viechtbauer at maastrichtuniversity.nl>?2017?6?26?
??03:39???

> I would suggest to post this to the (recently created) R-sig-meta-analysis
> mailing list. See:
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Naike
> Wang
> >Sent: Monday, June 26, 2017 08:32
> >To: R-help at r-project.org
> >Subject: [R] Classic fail-safe N
> >
> >Hi all,
> >I was conducting a meta-analysis of single proportions(i.e. without a
> >control group) using the metafor package. When I performed a classic
> >fail-safe N, I noticed that the result (the number of missing studies that
> >would bring p-value to the alpha, to be exact)was different than that I
> >got
> >in Comprehensive Meta-Analysis Version 2.0. I wonder why R and CMA got
> >different results.
> >
> >*Below is the R code:*
> >dat=read.table("Your working directory\\Example.csv",header=T,sep=",")
> >transf.ies=escalc(xi=cases,ni=total,measure="PLO",data=dat) #I transform
> >the data using the logit transformation first. In CMA, it also uses the
> >logit transformation.
> >transf.pes=rma(yi,vi,data=transf.ies,method="DL",weighted=TRUE) #Pooling
> >individual effect sizes in the logit scale.
> >ranktest(transf.pes) #Performing the fail-safe N.
> >
> >*Below are the results from R:*
> >Fail-safe N Calculation Using the Rosenthal Approach
> >Observed Significance Level: <.0001
> >Target Significance Level:   0.05
> >Fail-safe N: 8446
> >
> >*Below are the Classic fail-safe N results from CMA:*
> >Z-value for observed studies 19.91594
> >P-value for observed studies 0.00000
> >Alpha 0.05000
> >Tails 2.00000
> >Z for alpha 1.95996
> >Number of observed studies 58.00000
> >Number of missing studies that would bring p-value to > alpha 5931.00000
> >
> >Notice that I got 8446 in R and 5931 in CMA.
> >
> >Can anyone shed some light on this discrepancy? Thank you!
> >
> >You can find my data set here:
> >https://drive.google.com/open?id=0B41wTxciaMqtTEJWZE9sX20wOXM
> >
> >Best,
> >Naike
>

	[[alternative HTML version deleted]]


From eva.maria.wanek at gmail.com  Mon Jun 26 14:52:20 2017
From: eva.maria.wanek at gmail.com (Eva Wanek)
Date: Mon, 26 Jun 2017 14:52:20 +0200
Subject: [R] Changing the order of the factors in a cumulative logit model
Message-ID: <CAAthvffpPfAHvvhJvaiwquSX3Abu=jrXFM5BQaQYO5X22H2aJQ@mail.gmail.com>

Hi all,

I am using the clm function from the ordinal package to fit a cumulative
logit model. If I run the regression without formatting my dependent
variable (which is a factor), it works fine, however I need to change the
order of the factors to be able to interpret the estimates. I have tried
doing this using the relevel function and the factors are now in the
correct order, but when running the regression now, I get this:

Warning message:(1) Hessian is numerically singular: parameters are
not uniquely determined
In addition: Absolute convergence criterion was met, but relative
criterion was not met

Why is this and what can I do about it?

	[[alternative HTML version deleted]]


From jayjay.1988 at hotmail.nl  Mon Jun 26 07:53:43 2017
From: jayjay.1988 at hotmail.nl (Jay Zola)
Date: Mon, 26 Jun 2017 05:53:43 +0000
Subject: [R] Comparing pooled proportions(complication and reoperation
 rates) of different treatment modalities
In-Reply-To: <e99d7f2b-a92f-2fe2-bd72-418c2fe0c898@dewey.myzen.co.uk>
References: <VI1PR0501MB255798662C9F78C86548AB1D8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
 <CAGxFJbS_RVii8TARUEHEuThgQC8zSiBX6y1XKuZhKuuaEzu4xQ@mail.gmail.com>,
 <e99d7f2b-a92f-2fe2-bd72-418c2fe0c898@dewey.myzen.co.uk>
Message-ID: <VI1PR0501MB25578094825961E0995A1FA78ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>

What is the best way to change my R code to be able to compare the pooled proportions(complication and reoperation rates) with the Chi square method?

Verstuurd vanaf mijn iPhone

> Op 24 jun. 2017 om 14:18 heeft Michael Dewey <lists at dewey.myzen.co.uk> het volgende geschreven:
> 
> Note though that this has been put on hold on stats.stackexchange.com as off-topic.
> 
>> On 23/06/2017 19:33, Bert Gunter wrote:
>> Probably the wrong list. R-help is concerned with R programming, not
>> statistics methodology questions, although the intersection can be
>> nonempty.
>> 
>> I suggest you post on stats.stackexchange.com instead, which *is*
>> concerned with statistics methodology questions.
>> 
>> 
>> Cheers,
>> Bert
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>>> On Fri, Jun 23, 2017 at 5:53 AM, Jay Zola <jayjay.1988 at hotmail.nl> wrote:
>>> Dear sir/madame,
>>> 
>>> 
>>> I am currently writing a meta-analysis on the complication and reoperation rates of 5 different treatment modalities after a distal radius fracture. I was able to pool the rates of the 5 different rates using R. Now I have to compare the pooled rates of the 4 treatment modalities with the golden standard separately. I though the chi squared test would be the best method. How do I do that using r. The R code I have used for the former calculation are added as a Word-file attachment. Your help would be highly appreciated.
>>> 
>>> 
>>> Yours sincerely,
>>> 
>>> 
>>> Student
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ---
>> This email has been checked for viruses by AVG.
>> http://www.avg.com
>> 
>> 
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html


From alaios at yahoo.com  Mon Jun 26 08:07:49 2017
From: alaios at yahoo.com (Alaios)
Date: Mon, 26 Jun 2017 06:07:49 +0000 (UTC)
Subject: [R] Writing my 3D plot function
In-Reply-To: <23AA0668-17B7-4F6B-BBDB-45806C7E99C0@dcn.davis.ca.us>
References: <1627652181.2097203.1498416146575.ref@mail.yahoo.com>
 <1627652181.2097203.1498416146575@mail.yahoo.com>
 <23AA0668-17B7-4F6B-BBDB-45806C7E99C0@dcn.davis.ca.us>
Message-ID: <745900819.2384250.1498457269390@mail.yahoo.com>

Thanks a lot for this. I never realized that my yahoo mail does not send plain text. So this is the code I have 

require("rgls") 

degreeToRadian<-function(degree){ 
return   (0.01745329252*degree) 
} 

turnPolarToX<-function(Amplitude,Coordinate){ 
return (Amplitude*cos(degreeToRadian(Coordinate))) 
} 

turnPolarToY<-function(Amplitude,Coordinate){ 
return (Amplitude*sin(degreeToRadian(Coordinate))) 
} 

X1<-turnPolarToX(1,1:360) 
Y1<-turnPolarToY(1,1:360) 
Z1<-rep(0,360) 


X2<-turnPolarToX(1,1:360) 
Y2<-rep(0,360) 
Z2<-turnPolarToY(1,1:360) 

test3<-runif(360) 
X3<-rep(0,360) 
Y3<-turnPolarToX(1,1:360) 
Z3<-turnPolarToY(1,1:360) 

Min<-min(X1,Y1,Z1,X2,Y2,Z2,X3,Y3,Z3) 
Max<-max(X1,Y1,Z1,X2,Y2,Z2,X3,Y3,Z3) 
plot3d(X1,Y1,Z1,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=FALSE,add=TRUE,col="red",type="l") 
plot3d(X2,Y2,Z2,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=FALSE,add=TRUE,col="green",type="l") 
plot3d(X3,Y3,Z3,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=TRUE,add=FALSE,col="blue",type="l")



I hope this helps
Regards
Alex
On Monday, June 26, 2017 1:46 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:



Please look at what I see in your code below (run-on code mush) to understand part of why it is important for you to send your email as plain text as the Posting Guide indicates.  You might find [1] helpful. 

[1] https://wiki.openstack.org/wiki/MailingListEtiquette
-- 
Sent from my phone. Please excuse my brevity.


On June 25, 2017 2:42:26 PM EDT, Alaios via R-help <r-help at r-project.org> wrote:
>Hi all,I had a question last week on asking for a function that will
>help me draw three different circles on x,y,z axis based on polar
>coordinates (Each X,Y,Z circle are coming from three independent
>measurements of 1-360 polar coordinates). It turned out that there  is
>no such function in R and thus I am trying to write my own piece of
>code that hopefully I will be able to share. I have spent some time to
>write some code based on the rgl library (Still not 100% sure that this
>was the best option).
>My input are three polar circles X,Y,Z with a good example being the
>image
>belowhttps://www.mathworks.com/help/examples/antenna/win64/xxpolarpattern_helix.png
>
>So for X axis my input is a 2D matrix [360,2] including a single
>measurement per each polar coordinate. The first thing I tried was to
>turn my polar coordinates to cartesian ones by writing two simple
>functions. This works so far and I was able to print three simple
>circles on 3d spaceb but the problem now are the legends I need to put
>that remain on cartesian coordinates. As you can see from the code
>below all circles should have radius 1 (in terms of simplicity) but
>unfortunately I have the cartesian coordinates legends that do not help
>on reading my Figure. You can help me by executing the code below 
>
>require("rgls")
>degreeToRadian<-function(degree){  return   (0.01745329252*degree)}
>turnPolarToX<-function(Amplitude,Coordinate){  return
>(Amplitude*cos(degreeToRadian(Coordinate)))}
>turnPolarToY<-function(Amplitude,Coordinate){  return
>(Amplitude*sin(degreeToRadian(Coordinate)))}
># Putting the first circle on 3d space. Circle of radius
>1X1<-turnPolarToX(1,1:360)Y1<-turnPolarToY(1,1:360)Z1<-rep(0,360)
># Putting the second circle on 3d space. Circle of radius
>1X2<-turnPolarToX(1,1:360)Y2<-rep(0,360)Z2<-turnPolarToY(1,1:360)
># Putting the third circle on 3d space. Circle of radius
>1X3<-rep(0,360)Y3<-turnPolarToX(1,1:360)Z3<-turnPolarToY(1,1:360)
>Min<-min(X1,Y1,Z1,X2,Y2,Z2,X3,Y3,Z3)Max<-max(X1,Y1,Z1,X2,Y2,Z2,X3,Y3,Z3)plot3d(X1,Y1,Z1,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=FALSE,add=TRUE,col="red",type="l")plot3d(X2,Y2,Z2,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=FALSE,add=TRUE,col="green",type="l")plot3d(X3,Y3,Z3,xlim=c(Min,Max),ylim=c(Min,Max),zlim=c(Min,Max),box=TRUE,axe=TRUE,add=FALSE,col="blue",type="l")
>Would it be also possible to include an jpeg image file on a rgls plot?
>Thanks a lotRegardsAlex
>    [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mariankraus at gmx.de  Mon Jun 26 08:44:17 2017
From: mariankraus at gmx.de (Marian Kraus)
Date: Mon, 26 Jun 2017 08:44:17 +0200
Subject: [R] How to export a classification model from R to a Field
 Programmable Gate Array (FPGA)
Message-ID: <trinity-b91d8bf3-2741-407b-9ca7-595a970c4593-1498459457366@3capp-gmx-bs50>

Dear R users,

my search for a possibility to convert a generated model into VHDL to program an FPGA has still no solution.

The problem:
caret -> training -> model -> model.rds -> model.xml (PMML) --?--> VHDL-Code --?--> FPGA

The (simplified) task:
A photo detector with 16 channels is measuring the intensity of 16 different wavelength ranges. These data are classified with the possible results ?sunny?, ?cloudy? and ?rainy?. The model is trained, tested and finalized with ?caret? and saved as an .rds-file.

The solution with R:
Import new data and classify them with that model.

The problem without R:
How can the model be converted to other languages? (e.g. PMML, but this only supports a couple of models)
How is PMML (*.xml) converted to VHDL to program a FPGA or a MC which can execute the classification?
Do I first have to compile it to Python/Matlab/?? And how?

My question:
Does anybody have experiences with this and/or a solution without uploading the model somewhere to translate it?

Thank you all in advance.
?
Marian


From marc_schwartz at me.com  Mon Jun 26 15:55:00 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 26 Jun 2017 08:55:00 -0500
Subject: [R] Changing the order of the factors in a cumulative logit
	model
In-Reply-To: <CAAthvffpPfAHvvhJvaiwquSX3Abu=jrXFM5BQaQYO5X22H2aJQ@mail.gmail.com>
References: <CAAthvffpPfAHvvhJvaiwquSX3Abu=jrXFM5BQaQYO5X22H2aJQ@mail.gmail.com>
Message-ID: <BBA454BC-3433-4F1F-88E8-2A9171018753@me.com>


> On Jun 26, 2017, at 7:52 AM, Eva Wanek <eva.maria.wanek at gmail.com> wrote:
> 
> Hi all,
> 
> I am using the clm function from the ordinal package to fit a cumulative
> logit model. If I run the regression without formatting my dependent
> variable (which is a factor), it works fine, however I need to change the
> order of the factors to be able to interpret the estimates. I have tried
> doing this using the relevel function and the factors are now in the
> correct order, but when running the regression now, I get this:
> 
> Warning message:(1) Hessian is numerically singular: parameters are
> not uniquely determined
> In addition: Absolute convergence criterion was met, but relative
> criterion was not met
> 
> Why is this and what can I do about it?


Without seeing your data or a small data sample that replicates the problem:

I would check for:

1. Structural zeros in the cross tabulation of your dependent variable (DV) and your independent variable[s] (IVs).

2. Perfect prediction between your DV and IVs.

3. "Small" sample size in one or more of your DV levels.


If changing the ordering of your DV levels results in the error, you may have one or more of the above going on in one or more of your DV levels, especially if you shift one or more levels to the extremes (e.g first or last level).

How you handle this may depend upon domain subject matter knowledge and how to deal with possibly collapsing zero or low sample size categories and how that affects the relevance/applicability of the model.

Regards,

Marc Schwartz


From p.straka at unsw.edu.au  Mon Jun 26 11:02:40 2017
From: p.straka at unsw.edu.au (Peter Straka)
Date: Mon, 26 Jun 2017 19:02:40 +1000
Subject: [R] [R-pkgs] New R package MittagLeffleR
Message-ID: <CAEPY8Cb_fcBu3eHD0DqctKag96KOs-_RPzGtaiSofv2m41zorQ@mail.gmail.com>

Dear all,

apologies for interrupting your important work.

The new R package MittagLeffleR is now available on CRAN. It computes the
two types of Mittag-Leffler distributions, i.e. provides probability
density, distribution function, quantile function and random variate
generation for the Mittag-Leffler distributions, and the Mittag-Leffler
function itself. It is based on the Laplace-inversion algorithm by
Garrappa, R. (2015).

The first type of Mittag-Leffler distribution is geometric stable, (very)
heavy-tailed and typically models event durations (e.g. for earthquakes and
solar flares).

The second type is "inverse" to the sum-stable distribution, and typically
models the number of events when the waiting times between events are
heavy-tailed (a heavy-tailed renewal process).

For two examples, see https://strakaps.github.io/2017/06/26/mittagleffler/

Please report issues and bugs at
https://github.com/strakaps/MittagLeffleR/issues

Vignettes:
- plots of CDF and PDF:
https://cran.r-project.org/web/packages/MittagLeffleR/vignettes/MLdist.html
- random variable generation:
https://cran.r-project.org/web/packages/MittagLeffleR/vignettes/parametrisation.html
- calculation of quantiles:
https://cran.r-project.org/web/packages/MittagLeffleR/vignettes/probsNquantiles.html

Thanks!
-- 
* Dr Peter Straka*
*Research Fellow (DECRA), School of Physical Engineering and Mathematical
Sciences*

UNSW Canberra
Campbell ACT 2600 Australia

H: strakaps.github.io
E: p.straka at unsw.edu.au
ORCID: orcid.org/0000-0003-1735-4676
Skype + Google Hangouts: straka.ps
CRICOS Provider Code 00098G

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jayjay.1988 at hotmail.nl  Mon Jun 26 16:23:39 2017
From: jayjay.1988 at hotmail.nl (Jay Zola)
Date: Mon, 26 Jun 2017 14:23:39 +0000
Subject: [R] Comparing pooled proportions(complication and reoperation
 rates) of different treatment modalities
In-Reply-To: <VI1PR0501MB25578094825961E0995A1FA78ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>
References: <VI1PR0501MB255798662C9F78C86548AB1D8AD80@VI1PR0501MB2557.eurprd05.prod.outlook.com>
 <CAGxFJbS_RVii8TARUEHEuThgQC8zSiBX6y1XKuZhKuuaEzu4xQ@mail.gmail.com>,
 <e99d7f2b-a92f-2fe2-bd72-418c2fe0c898@dewey.myzen.co.uk>,
 <VI1PR0501MB25578094825961E0995A1FA78ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>
Message-ID: <VI1PR0501MB2557730099F2953DC8F9DED18ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>

Op 26 jun. 2017 om 15:22 heeft Jay Zola <jayjay.1988 at hotmail.nl<mailto:jayjay.1988 at hotmail.nl>> het volgende geschreven:

What is the best way to change my R code to be able to compare the pooled proportions(complication and reoperation rates) with the Chi square method?

Just adding an adjustment to the links because they were not working correctly.


Dataset on my dropbox: https://www.dropbox.com/s/j1urqzr99bt76ip/Basics%20excel%20file%20complication%20and%20reoperation%20rate.xlsx?dl=0


R code on my dropbox: https://wwwdropbox.com/s/67pnfpi10qu110v/R%20code%20voor%20forrest%20en%20funnel%20plots.rtf?dl=0


Verstuurd vanaf mijn iPhone

Op 24 jun. 2017 om 14:18 heeft Michael Dewey <lists at dewey.myzen.co.uk<mailto:lists at dewey.myzen.co.uk>> het volgende geschreven:

Note though that this has been put on hold on stats.stackexchange.com<http://stats.stackexchange.com> as off-topic.

On 23/06/2017 19:33, Bert Gunter wrote:
Probably the wrong list. R-help is concerned with R programming, not
statistics methodology questions, although the intersection can be
nonempty.

I suggest you post on stats.stackexchange.com<http://stats.stackexchange.com> instead, which *is*
concerned with statistics methodology questions.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 23, 2017 at 5:53 AM, Jay Zola <jayjay.1988 at hotmail.nl<mailto:jayjay.1988 at hotmail.nl>> wrote:
Dear sir/madame,


I am currently writing a meta-analysis on the complication and reoperation rates of 5 different treatment modalities after a distal radius fracture. I was able to pool the rates of the 5 different rates using R. Now I have to compare the pooled rates of the 4 treatment modalities with the golden standard separately. I though the chi squared test would be the best method. How do I do that using r. The R code I have used for the former calculation are added as a Word-file attachment. Your help would be highly appreciated.


Yours sincerely,


Student
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

---
This email has been checked for viruses by AVG.
http://www.avg.com



--
Michael
http://www.dewey.myzen.co.uk/home.html

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bsmith030465 at gmail.com  Mon Jun 26 18:40:10 2017
From: bsmith030465 at gmail.com (Brian Smith)
Date: Mon, 26 Jun 2017 12:40:10 -0400
Subject: [R] Jagged ROC curves?
Message-ID: <CAEQKoCHmoUv7wCWi7uQ6_452JqhC8313ag2ijdJOdzUBbU4i4Q@mail.gmail.com>

Hi,

I was trying to draw some ROC curves (prediction of case/control status),
but seem to be getting a somewhat jagged plot. Can I do something that
would 'smooth' it somewhat? Most roc curves seem to have many incremental
changes (in x and y directions), but my plot only has 4 or 5 steps even
though there are 22 data points. Should I be doing something differently?

How can I provide a URL/attachment for my plot? Not sure if I can provide
reproducible code, but here is some pseudocode, let me know if you'd like
more details:

#####
## generate roc and auc values
#####
library(pROC)
library(AUCRF)

getROC <- function(d1train,d1test){
my_model <- AUCRF(formula= status ~ ., data=d1train,
ranking='MDA',ntree=1000,pdel=0.05)
  my_opt_model <- my_model$RFopt

  my_probs <- predict(my_opt_model, d1test, type = 'prob')
  my_roc <- roc(d1test[,resp_col] ~ my_probs[,2])
  aucval <- round(as.numeric(my_roc$auc),4)
return(my_roc)
}


roc_1 <- getROC(dat1,dat1test)
plot.roc(roc_1,col="brown3")


> roc_1

Call:
roc.formula(formula = d1test[, resp_col] ~ ibd_probs[, 2])

Data: ibd_probs[, 2] in 3 controls (d1test[, resp_col] 0) < 19 cases
(d1test[, resp_col] 1).
Area under the curve: 0.8596


> roc_1$sensitivities
 [1] 1.00000000 0.94736842 0.94736842 0.94736842 0.89473684 0.84210526
0.78947368 0.73684211 0.68421053 0.68421053
[11] 0.63157895 0.57894737 0.52631579 0.47368421 0.42105263 0.36842105
0.31578947 0.26315789 0.21052632 0.15789474
[21] 0.10526316 0.05263158 0.00000000


> roc_1$specificities
 [1] 0.0000000 0.0000000 0.3333333 0.6666667 0.6666667 0.6666667 0.6666667
0.6666667 0.6666667 1.0000000 1.0000000
[12] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
1.0000000 1.0000000 1.0000000 1.0000000
[23] 1.0000000


many thanks!

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Mon Jun 26 18:59:59 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 26 Jun 2017 11:59:59 -0500
Subject: [R] Jagged ROC curves?
In-Reply-To: <CAEQKoCHmoUv7wCWi7uQ6_452JqhC8313ag2ijdJOdzUBbU4i4Q@mail.gmail.com>
References: <CAEQKoCHmoUv7wCWi7uQ6_452JqhC8313ag2ijdJOdzUBbU4i4Q@mail.gmail.com>
Message-ID: <D85F793E-5405-4380-B308-C8D8BE2DEBB8@me.com>


> On Jun 26, 2017, at 11:40 AM, Brian Smith <bsmith030465 at gmail.com> wrote:
> 
> Hi,
> 
> I was trying to draw some ROC curves (prediction of case/control status),
> but seem to be getting a somewhat jagged plot. Can I do something that
> would 'smooth' it somewhat? Most roc curves seem to have many incremental
> changes (in x and y directions), but my plot only has 4 or 5 steps even
> though there are 22 data points. Should I be doing something differently?
> 
> How can I provide a URL/attachment for my plot? Not sure if I can provide
> reproducible code, but here is some pseudocode, let me know if you'd like
> more details:
> 
> #####
> ## generate roc and auc values
> #####
> library(pROC)
> library(AUCRF)
> 
> getROC <- function(d1train,d1test){
> my_model <- AUCRF(formula= status ~ ., data=d1train,
> ranking='MDA',ntree=1000,pdel=0.05)
>  my_opt_model <- my_model$RFopt
> 
>  my_probs <- predict(my_opt_model, d1test, type = 'prob')
>  my_roc <- roc(d1test[,resp_col] ~ my_probs[,2])
>  aucval <- round(as.numeric(my_roc$auc),4)
> return(my_roc)
> }
> 
> 
> roc_1 <- getROC(dat1,dat1test)
> plot.roc(roc_1,col="brown3")
> 
> 
>> roc_1
> 
> Call:
> roc.formula(formula = d1test[, resp_col] ~ ibd_probs[, 2])
> 
> Data: ibd_probs[, 2] in 3 controls (d1test[, resp_col] 0) < 19 cases
> (d1test[, resp_col] 1).
> Area under the curve: 0.8596
> 
> 
>> roc_1$sensitivities
> [1] 1.00000000 0.94736842 0.94736842 0.94736842 0.89473684 0.84210526
> 0.78947368 0.73684211 0.68421053 0.68421053
> [11] 0.63157895 0.57894737 0.52631579 0.47368421 0.42105263 0.36842105
> 0.31578947 0.26315789 0.21052632 0.15789474
> [21] 0.10526316 0.05263158 0.00000000
> 
> 
>> roc_1$specificities
> [1] 0.0000000 0.0000000 0.3333333 0.6666667 0.6666667 0.6666667 0.6666667
> 0.6666667 0.6666667 1.0000000 1.0000000
> [12] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> 1.0000000 1.0000000 1.0000000 1.0000000
> [23] 1.0000000
> 
> 
> many thanks!


ROC curves are typically step functions of some nature, depending upon your thresholds, so the default behavior is not going to be smoothed.

I am not sure how they (AUCRF and pROC) may interact, but look at the ?smooth function in the latter package to see if it might help.

To your second point, if your plot is a png/jpg file, you could attach it to your post here, if that was your desire. Otherwise, you could post it to a cloud based repository, like Dropbox, and provide the URL for public sharing here. The R lists support limited binary attachment types and png/jpg/pdf/ps are supported.

Regards,

Marc Schwartz


From bsmith030465 at gmail.com  Mon Jun 26 20:10:01 2017
From: bsmith030465 at gmail.com (Brian Smith)
Date: Mon, 26 Jun 2017 14:10:01 -0400
Subject: [R] Jagged ROC curves?
In-Reply-To: <D85F793E-5405-4380-B308-C8D8BE2DEBB8@me.com>
References: <CAEQKoCHmoUv7wCWi7uQ6_452JqhC8313ag2ijdJOdzUBbU4i4Q@mail.gmail.com>
 <D85F793E-5405-4380-B308-C8D8BE2DEBB8@me.com>
Message-ID: <CAEQKoCEj4rgjG4NRwO7u5_GEfxUTOH8u3gNoKt9Y6rSSN0RPng@mail.gmail.com>

Hi Marc,

I tried to attache the png file of the plot, but the mailing list blocked
it!


"For the attached two png files (test_roc.png & test_roc_smooth.png)

1. Using 'plot' function:

plot(c(1,0),c(0,1), type='l', lty=3, xlim=c(1.01,-0.01),
ylim=c(-0.01,1.01), xaxs='i', yaxs='i', ylab='', xlab='')
plot(roc_1,col="brown3", lwd=2, add=T, lty=1)

2. Using the 'smooth' function:

plot(c(1,0),c(0,1), type='l', lty=3, xlim=c(1.01,-0.01),
ylim=c(-0.01,1.01), xaxs='i', yaxs='i', ylab='', xlab='')
plot(smooth(roc_1),col="brown3", lwd=2, add=T, lty=1)


I guess most ROCs that I've seen are somewhere in between, i.e. they have a
little jaggedness, but not as much as in plot #1 above"


thanks!

On Mon, Jun 26, 2017 at 12:59 PM, Marc Schwartz <marc_schwartz at me.com>
wrote:

>
> > On Jun 26, 2017, at 11:40 AM, Brian Smith <bsmith030465 at gmail.com>
> wrote:
> >
> > Hi,
> >
> > I was trying to draw some ROC curves (prediction of case/control status),
> > but seem to be getting a somewhat jagged plot. Can I do something that
> > would 'smooth' it somewhat? Most roc curves seem to have many incremental
> > changes (in x and y directions), but my plot only has 4 or 5 steps even
> > though there are 22 data points. Should I be doing something differently?
> >
> > How can I provide a URL/attachment for my plot? Not sure if I can provide
> > reproducible code, but here is some pseudocode, let me know if you'd like
> > more details:
> >
> > #####
> > ## generate roc and auc values
> > #####
> > library(pROC)
> > library(AUCRF)
> >
> > getROC <- function(d1train,d1test){
> > my_model <- AUCRF(formula= status ~ ., data=d1train,
> > ranking='MDA',ntree=1000,pdel=0.05)
> >  my_opt_model <- my_model$RFopt
> >
> >  my_probs <- predict(my_opt_model, d1test, type = 'prob')
> >  my_roc <- roc(d1test[,resp_col] ~ my_probs[,2])
> >  aucval <- round(as.numeric(my_roc$auc),4)
> > return(my_roc)
> > }
> >
> >
> > roc_1 <- getROC(dat1,dat1test)
> > plot.roc(roc_1,col="brown3")
> >
> >
> >> roc_1
> >
> > Call:
> > roc.formula(formula = d1test[, resp_col] ~ ibd_probs[, 2])
> >
> > Data: ibd_probs[, 2] in 3 controls (d1test[, resp_col] 0) < 19 cases
> > (d1test[, resp_col] 1).
> > Area under the curve: 0.8596
> >
> >
> >> roc_1$sensitivities
> > [1] 1.00000000 0.94736842 0.94736842 0.94736842 0.89473684 0.84210526
> > 0.78947368 0.73684211 0.68421053 0.68421053
> > [11] 0.63157895 0.57894737 0.52631579 0.47368421 0.42105263 0.36842105
> > 0.31578947 0.26315789 0.21052632 0.15789474
> > [21] 0.10526316 0.05263158 0.00000000
> >
> >
> >> roc_1$specificities
> > [1] 0.0000000 0.0000000 0.3333333 0.6666667 0.6666667 0.6666667 0.6666667
> > 0.6666667 0.6666667 1.0000000 1.0000000
> > [12] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> 1.0000000
> > 1.0000000 1.0000000 1.0000000 1.0000000
> > [23] 1.0000000
> >
> >
> > many thanks!
>
>
> ROC curves are typically step functions of some nature, depending upon
> your thresholds, so the default behavior is not going to be smoothed.
>
> I am not sure how they (AUCRF and pROC) may interact, but look at the
> ?smooth function in the latter package to see if it might help.
>
> To your second point, if your plot is a png/jpg file, you could attach it
> to your post here, if that was your desire. Otherwise, you could post it to
> a cloud based repository, like Dropbox, and provide the URL for public
> sharing here. The R lists support limited binary attachment types and
> png/jpg/pdf/ps are supported.
>
> Regards,
>
> Marc Schwartz
>
>

	[[alternative HTML version deleted]]


From jayjay.1988 at hotmail.nl  Mon Jun 26 20:19:17 2017
From: jayjay.1988 at hotmail.nl (Jay Zola)
Date: Mon, 26 Jun 2017 18:19:17 +0000
Subject: [R] Model studies in one analysis using treatment as a five level
 moderator in a meta-regression
Message-ID: <VI1PR0501MB2557403844FC94AE4787AF8E8ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>

Hello,


I am medical student, writing a meta-analysis on complication and reoperation rates after the five most common treatments of distal radius fractures. I have been busy with the statistics for months by my self, but find it quite hard since our classes were very basic. Now I want to compare the treatment modalities to see if there are significant differences. Using R I was able to synthesize the complication rates and reoperation rates for each treatment method. But I never had any R course and managed by trial and error, so the code probably doesn't look that great. Someone told me I could best model the data in one analysis using treatment as a five level moderator in a meta-regression. Can some help me with the R code to do this? Your help would be very much appreciated.


Thank you,


Jay


Study| Event Type| Treatment| Number of Events (n)| N| n/N|

Kumaravel| Complications| EF| 3| 23| 0,1304348|

Franck| Complications| EF| 2| 20| 0,1|

Schonnemann| Complications| EF| 8| 30| 0,2666667|

Aita| Complications| EF| 1| 16| 0,0625|

Hove| Complications| EF| 31| 39| 0,7948718|

Andersen| Complications| EF| 26| 75| 0,3466667|

Krughaug| Complications| EF| 22| 75| 0,2933333|

Moroni| Complications| EF| 0| 20| 0|

Plate| Complications| IMN| 3| 30| 0,1|

Chappuis| Complications| IMN| 4| 16| 0,25|

Gradl| Complications| IMN| 12| 66| 0,1818182|

Schonnemann| Complications| IMN| 6| 31| 0,1935484|

Aita| Complications| IMN| 1| 16| 0,0625|

Dremstrop| Complications| IMN| 17| 44| 0,3863636|

Wong| Complications| PC| 1| 30| 0,0333333|

Kumaravel| Complications| PC| 4| 25| 0,16|


Dataset on my dropbox: https://www.dropbox.com/s/j1urqzr99bt76ip/Basics%20excel%20file%20complication%20and%20reoperation%20rate.xlsx?dl=0

Basics excel file complication and reoperation rate.xlsx<https://www.dropbox.com/s/j1urqzr99bt76ip/Basics%20excel%20file%20complication%20and%20reoperation%20rate.xlsx?dl=0>
www.dropbox.com
Shared with Dropbox




library(meta)
library(stargazer)
library(foreign)

All <-read.spss("C:\\Users\\313635aa.STUDENT\\Desktop\\Meta-Analyse Complications and Reoperations.sav",to.data.frame = T, use.value.labels = T)
All <- na.omit(All)

Complications <- All[which(All[,"Event_Type"] == "Complications"),]
Re_operation <- All[which(All[,"Event_Type"] == "Reoperations"),]

EF <- All[which(All[,"Treatment"] == "EF"),]
IMN <- All[which(All[,"Treatment"] == "IMN"),]
pc <- All[which(All[,"Treatment"] == "PC"),]
KW <- All[which(All[,"Treatment"] == "KW"),]
VPO <- All[which(All[,"Treatment"] == "VPO"),]

EF_C <- EF[which(EF[,"Event_Type"] == "Complications"),]
EF_R <- EF[which(EF[,"Event_Type"] == "Reoperations"),]

IMN_C <- IMN[which(IMN[,"Event_Type"] == "Complications"),]
IMN_R <- IMN[which(IMN[,"Event_Type"] == "Reoperations"),]

pc_C <- pc[which(pc[,"Event_Type"] == "Complications"),]
pc_R <- pc[which(pc[,"Event_Type"] == "Reoperations"),]

KW_C <- KW[which(KW[,"Event_Type"] == "Complications"),]
KW_R <- KW[which(KW[,"Event_Type"] == "Reoperations"),]

VPO_C <- VPO[which(VPO[,"Event_Type"] == "Complications"),]
VPO_R <- VPO[which(VPO[,"Event_Type"] == "Reoperations"),]

Output <- function(x, y, k.min=10){
file <- metaprop(Events_n, N, Study_ID, data = x)

forest.meta(file, studlab = T, pooled.totals = T, bysort = F)

dev.copy2pdf(file=y, width = 11.69, height = 8.27)
print(file)
}

R code on my dropbox: https://www.dropbox.com/s/67pnfpi10qu110v/R%20code%20voor%20forrest%20en%20funnel%20plots.rtf?dl=0

[https://cfl.dropboxstatic.com/static/images/icons128/page_white_word.png]<https://www.dropbox.com/s/67pnfpi10qu110v/R%20code%20voor%20forrest%20en%20funnel%20plots.rtf?dl=0>

R code voor forrest en funnel plots.rtf<https://www.dropbox.com/s/67pnfpi10qu110v/R%20code%20voor%20forrest%20en%20funnel%20plots.rtf?dl=0>
www.dropbox.com
Shared with Dropbox






	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Mon Jun 26 20:34:12 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 26 Jun 2017 13:34:12 -0500
Subject: [R] Jagged ROC curves?
In-Reply-To: <CAEQKoCHuqMTWmpYfor6YwJkkcuBSbrxxRP0L_b=2_bAXH++mTg@mail.gmail.com>
References: <CAEQKoCHmoUv7wCWi7uQ6_452JqhC8313ag2ijdJOdzUBbU4i4Q@mail.gmail.com>
 <D85F793E-5405-4380-B308-C8D8BE2DEBB8@me.com>
 <CAEQKoCHuqMTWmpYfor6YwJkkcuBSbrxxRP0L_b=2_bAXH++mTg@mail.gmail.com>
Message-ID: <9EE3263F-F854-41C1-B3B8-1828F6A9A59E@me.com>

Hi Brian,

Your underlying dataset for the ROC curve only has 4 unique values for specificity, even though there are 23 elements in the vector, hence the step function nature of the first plot.

The default smoothing in the smooth() function is "binormal". You might try one of the other smoothing options to see the result and whether they make visual sense.

In the absence of smoothing, there will always be a step function, but some will look "more smooth" than others depending upon your data and how the thresholds are defined for the underlying metrics. The more unique thresholds there are over the range, the smoother the step function will look.

Regards,

Marc


> On Jun 26, 2017, at 1:07 PM, Brian Smith <bsmith030465 at gmail.com> wrote:
> 
> Hi Mark,
> 
> Thanks for the reply.
> 
> For the attached two png files (test_roc.png & test_roc_smooth.png)
> 
> 1. Using 'plot' function:
> 
> plot(c(1,0),c(0,1), type='l', lty=3, xlim=c(1.01,-0.01), ylim=c(-0.01,1.01), xaxs='i', yaxs='i', ylab='', xlab='')
> plot(roc_1,col="brown3", lwd=2, add=T, lty=1)
> 
> 2. Using the 'smooth' function:
> 
> plot(c(1,0),c(0,1), type='l', lty=3, xlim=c(1.01,-0.01), ylim=c(-0.01,1.01), xaxs='i', yaxs='i', ylab='', xlab='')
> plot(smooth(roc_1),col="brown3", lwd=2, add=T, lty=1)
> 
> 
> I guess most ROCs that I've seen are somewhere in between, i.e. they have a little jaggedness, but not as much as in plot #1 above.<test_roc.png><test_roc_smooth.png>
> 
> thanks!
> 
> Pankaj
> 
> On Mon, Jun 26, 2017 at 12:59 PM, Marc Schwartz <marc_schwartz at me.com <mailto:marc_schwartz at me.com>> wrote:
> 
> > On Jun 26, 2017, at 11:40 AM, Brian Smith <bsmith030465 at gmail.com <mailto:bsmith030465 at gmail.com>> wrote:
> >
> > Hi,
> >
> > I was trying to draw some ROC curves (prediction of case/control status),
> > but seem to be getting a somewhat jagged plot. Can I do something that
> > would 'smooth' it somewhat? Most roc curves seem to have many incremental
> > changes (in x and y directions), but my plot only has 4 or 5 steps even
> > though there are 22 data points. Should I be doing something differently?
> >
> > How can I provide a URL/attachment for my plot? Not sure if I can provide
> > reproducible code, but here is some pseudocode, let me know if you'd like
> > more details:
> >
> > #####
> > ## generate roc and auc values
> > #####
> > library(pROC)
> > library(AUCRF)
> >
> > getROC <- function(d1train,d1test){
> > my_model <- AUCRF(formula= status ~ ., data=d1train,
> > ranking='MDA',ntree=1000,pdel=0.05)
> >  my_opt_model <- my_model$RFopt
> >
> >  my_probs <- predict(my_opt_model, d1test, type = 'prob')
> >  my_roc <- roc(d1test[,resp_col] ~ my_probs[,2])
> >  aucval <- round(as.numeric(my_roc$auc),4)
> > return(my_roc)
> > }
> >
> >
> > roc_1 <- getROC(dat1,dat1test)
> > plot.roc(roc_1,col="brown3")
> >
> >
> >> roc_1
> >
> > Call:
> > roc.formula(formula = d1test[, resp_col] ~ ibd_probs[, 2])
> >
> > Data: ibd_probs[, 2] in 3 controls (d1test[, resp_col] 0) < 19 cases
> > (d1test[, resp_col] 1).
> > Area under the curve: 0.8596
> >
> >
> >> roc_1$sensitivities
> > [1] 1.00000000 0.94736842 0.94736842 0.94736842 0.89473684 0.84210526
> > 0.78947368 0.73684211 0.68421053 0.68421053
> > [11] 0.63157895 0.57894737 0.52631579 0.47368421 0.42105263 0.36842105
> > 0.31578947 0.26315789 0.21052632 0.15789474
> > [21] 0.10526316 0.05263158 0.00000000
> >
> >
> >> roc_1$specificities
> > [1] 0.0000000 0.0000000 0.3333333 0.6666667 0.6666667 0.6666667 0.6666667
> > 0.6666667 0.6666667 1.0000000 1.0000000
> > [12] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> > 1.0000000 1.0000000 1.0000000 1.0000000
> > [23] 1.0000000
> >
> >
> > many thanks!
> 
> 
> ROC curves are typically step functions of some nature, depending upon your thresholds, so the default behavior is not going to be smoothed.
> 
> I am not sure how they (AUCRF and pROC) may interact, but look at the ?smooth function in the latter package to see if it might help.
> 
> To your second point, if your plot is a png/jpg file, you could attach it to your post here, if that was your desire. Otherwise, you could post it to a cloud based repository, like Dropbox, and provide the URL for public sharing here. The R lists support limited binary attachment types and png/jpg/pdf/ps are supported.
> 
> Regards,
> 
> Marc Schwartz
> 
> 


	[[alternative HTML version deleted]]


From vito.muggeo at unipa.it  Mon Jun 26 22:05:25 2017
From: vito.muggeo at unipa.it (Vito Michele Rosario Muggeo)
Date: Mon, 26 Jun 2017 20:05:25 +0000
Subject: [R] Model studies in one analysis using treatment as a five
 level moderator in a meta-regression
In-Reply-To: <VI1PR0501MB2557403844FC94AE4787AF8E8ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>
Message-ID: <20170626200525.Horde.yEpy93zDtzVTx-i-2R0OHhU@webmail.unipa.it>

hi Jay,
Consult a local statistician. Statistics is not you think is (namely  
simple computations, R and probably plotting..).

regards,
vito



Jay Zola <jayjay.1988 at hotmail.nl> ha scritto:

> Hello,
>
>
> I am medical student, writing a meta-analysis on complication and  
> reoperation rates after the five most common treatments of distal  
> radius fractures. I have been busy with the statistics for months by  
> my self, but find it quite hard since our classes were very basic.  
> Now I want to compare the treatment modalities to see if there are  
> significant differences. Using R I was able to synthesize the  
> complication rates and reoperation rates for each treatment method.  
> But I never had any R course and managed by trial and error, so the  
> code probably doesn't look that great. Someone told me I could best  
> model the data in one analysis using treatment as a five level  
> moderator in a meta-regression. Can some help me with the R code to  
> do this? Your help would be very much appreciated.
>
>
> Thank you,
>
>
> Jay
>
>
> Study| Event Type| Treatment| Number of Events (n)| N| n/N|
>
> Kumaravel| Complications| EF| 3| 23| 0,1304348|
>
> Franck| Complications| EF| 2| 20| 0,1|
>
> Schonnemann| Complications| EF| 8| 30| 0,2666667|
>
> Aita| Complications| EF| 1| 16| 0,0625|
>
> Hove| Complications| EF| 31| 39| 0,7948718|
>
> Andersen| Complications| EF| 26| 75| 0,3466667|
>
> Krughaug| Complications| EF| 22| 75| 0,2933333|
>
> Moroni| Complications| EF| 0| 20| 0|
>
> Plate| Complications| IMN| 3| 30| 0,1|
>
> Chappuis| Complications| IMN| 4| 16| 0,25|
>
> Gradl| Complications| IMN| 12| 66| 0,1818182|
>
> Schonnemann| Complications| IMN| 6| 31| 0,1935484|
>
> Aita| Complications| IMN| 1| 16| 0,0625|
>
> Dremstrop| Complications| IMN| 17| 44| 0,3863636|
>
> Wong| Complications| PC| 1| 30| 0,0333333|
>
> Kumaravel| Complications| PC| 4| 25| 0,16|
>
>
> Dataset on my dropbox:  
> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2Fj1urqzr99bt76ip%2FBasics%2520excel%2520file%2520complication%2520and%2520reoperation%2520rate.xlsx%3Fdl%3D0&e=541e9c83&h=065e9ef9&f=y
>
> Basics excel file complication and reoperation  
> rate.xlsx<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2Fj1urqzr99bt76ip%2FBasics%2520excel%2520file%2520complication%2520and%2520reoperation%2520rate.xlsx%3Fdl%3D0&e=541e9c83&h=065e9ef9&f=y>
> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.dropbox.com&e=541e9c83&h=4bc36151&f=y
> Shared with Dropbox
>
>
>
>
> library(meta)
> library(stargazer)
> library(foreign)
>
> All <-read.spss("C:\\Users\\313635aa.STUDENT\\Desktop\\Meta-Analyse  
> Complications and Reoperations.sav",to.data.frame = T,  
> use.value.labels = T)
> All <- na.omit(All)
>
> Complications <- All[which(All[,"Event_Type"] == "Complications"),]
> Re_operation <- All[which(All[,"Event_Type"] == "Reoperations"),]
>
> EF <- All[which(All[,"Treatment"] == "EF"),]
> IMN <- All[which(All[,"Treatment"] == "IMN"),]
> pc <- All[which(All[,"Treatment"] == "PC"),]
> KW <- All[which(All[,"Treatment"] == "KW"),]
> VPO <- All[which(All[,"Treatment"] == "VPO"),]
>
> EF_C <- EF[which(EF[,"Event_Type"] == "Complications"),]
> EF_R <- EF[which(EF[,"Event_Type"] == "Reoperations"),]
>
> IMN_C <- IMN[which(IMN[,"Event_Type"] == "Complications"),]
> IMN_R <- IMN[which(IMN[,"Event_Type"] == "Reoperations"),]
>
> pc_C <- pc[which(pc[,"Event_Type"] == "Complications"),]
> pc_R <- pc[which(pc[,"Event_Type"] == "Reoperations"),]
>
> KW_C <- KW[which(KW[,"Event_Type"] == "Complications"),]
> KW_R <- KW[which(KW[,"Event_Type"] == "Reoperations"),]
>
> VPO_C <- VPO[which(VPO[,"Event_Type"] == "Complications"),]
> VPO_R <- VPO[which(VPO[,"Event_Type"] == "Reoperations"),]
>
> Output <- function(x, y, k.min=10){
> file <- metaprop(Events_n, N, Study_ID, data = x)
>
> forest.meta(file, studlab = T, pooled.totals = T, bysort = F)
>
> dev.copy2pdf(file=y, width = 11.69, height = 8.27)
> print(file)
> }
>
> R code on my dropbox:  
> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2F67pnfpi10qu110v%2FR%2520code%2520voor%2520forrest%2520en%2520funnel%2520plots.rtf%3Fdl%3D0&e=541e9c83&h=1df77562&f=y
>
> [https://urlsand.esvalabs.com/?u=https%3A%2F%2Fcfl.dropboxstatic.com%2Fstatic%2Fimages%2Ficons128%2Fpage_white_word.png&e=541e9c83&h=b0ed7c54&f=y]<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2F67pnfpi10qu110v%2FR%2520code%2520voor%2520forrest%2520en%2520funnel%2520plots.rtf%3Fdl%3D0&e=541e9c83&h=1df77562&f=y>
>
> R code voor forrest en funnel  
> plots.rtf<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2F67pnfpi10qu110v%2FR%2520code%2520voor%2520forrest%2520en%2520funnel%2520plots.rtf%3Fdl%3D0&e=541e9c83&h=1df77562&f=y>
> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.dropbox.com&e=541e9c83&h=4bc36151&f=y
> Shared with Dropbox
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=541e9c83&h=16efca0d&f=y
> PLEASE do read the posting guide  
> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=541e9c83&h=0c678195&f=y
> and provide commented, minimal, self-contained, reproducible code.


From jayjay.1988 at hotmail.nl  Mon Jun 26 23:43:54 2017
From: jayjay.1988 at hotmail.nl (Jay Zola)
Date: Mon, 26 Jun 2017 21:43:54 +0000
Subject: [R] Model studies in one analysis using treatment as a five
 level moderator in a meta-regression
In-Reply-To: <20170626200525.Horde.yEpy93zDtzVTx-i-2R0OHhU@webmail.unipa.it>
References: <VI1PR0501MB2557403844FC94AE4787AF8E8ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>,
 <20170626200525.Horde.yEpy93zDtzVTx-i-2R0OHhU@webmail.unipa.it>
Message-ID: <VI1PR0501MB2557107D26947CC6D2D6EC6A8ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>

Dear Vito,

Thank you for your reply. I tried to contact the statistics departement numerous times, but did not receive any reply. That is why I started to look on the internet for help.

Yours sincerely,

Jay

Verstuurd vanaf mijn iPhone

> Op 26 jun. 2017 om 22:05 heeft Vito Michele Rosario Muggeo <vito.muggeo at unipa.it> het volgende geschreven:
> 
> hi Jay,
> Consult a local statistician. Statistics is not you think is (namely simple computations, R and probably plotting..).
> 
> regards,
> vito
> 
> 
> 
> Jay Zola <jayjay.1988 at hotmail.nl> ha scritto:
> 
>> Hello,
>> 
>> 
>> I am medical student, writing a meta-analysis on complication and reoperation rates after the five most common treatments of distal radius fractures. I have been busy with the statistics for months by my self, but find it quite hard since our classes were very basic. Now I want to compare the treatment modalities to see if there are significant differences. Using R I was able to synthesize the complication rates and reoperation rates for each treatment method. But I never had any R course and managed by trial and error, so the code probably doesn't look that great. Someone told me I could best model the data in one analysis using treatment as a five level moderator in a meta-regression. Can some help me with the R code to do this? Your help would be very much appreciated.
>> 
>> 
>> Thank you,
>> 
>> 
>> Jay
>> 
>> 
>> Study| Event Type| Treatment| Number of Events (n)| N| n/N|
>> 
>> Kumaravel| Complications| EF| 3| 23| 0,1304348|
>> 
>> Franck| Complications| EF| 2| 20| 0,1|
>> 
>> Schonnemann| Complications| EF| 8| 30| 0,2666667|
>> 
>> Aita| Complications| EF| 1| 16| 0,0625|
>> 
>> Hove| Complications| EF| 31| 39| 0,7948718|
>> 
>> Andersen| Complications| EF| 26| 75| 0,3466667|
>> 
>> Krughaug| Complications| EF| 22| 75| 0,2933333|
>> 
>> Moroni| Complications| EF| 0| 20| 0|
>> 
>> Plate| Complications| IMN| 3| 30| 0,1|
>> 
>> Chappuis| Complications| IMN| 4| 16| 0,25|
>> 
>> Gradl| Complications| IMN| 12| 66| 0,1818182|
>> 
>> Schonnemann| Complications| IMN| 6| 31| 0,1935484|
>> 
>> Aita| Complications| IMN| 1| 16| 0,0625|
>> 
>> Dremstrop| Complications| IMN| 17| 44| 0,3863636|
>> 
>> Wong| Complications| PC| 1| 30| 0,0333333|
>> 
>> Kumaravel| Complications| PC| 4| 25| 0,16|
>> 
>> 
>> Dataset on my dropbox: https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2Fj1urqzr99bt76ip%2FBasics%2520excel%2520file%2520complication%2520and%2520reoperation%2520rate.xlsx%3Fdl%3D0&e=541e9c83&h=065e9ef9&f=y
>> 
>> Basics excel file complication and reoperation rate.xlsx<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2Fj1urqzr99bt76ip%2FBasics%2520excel%2520file%2520complication%2520and%2520reoperation%2520rate.xlsx%3Fdl%3D0&e=541e9c83&h=065e9ef9&f=y>
>> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.dropbox.com&e=541e9c83&h=4bc36151&f=y
>> Shared with Dropbox
>> 
>> 
>> 
>> 
>> library(meta)
>> library(stargazer)
>> library(foreign)
>> 
>> All <-read.spss("C:\\Users\\313635aa.STUDENT\\Desktop\\Meta-Analyse Complications and Reoperations.sav",to.data.frame = T, use.value.labels = T)
>> All <- na.omit(All)
>> 
>> Complications <- All[which(All[,"Event_Type"] == "Complications"),]
>> Re_operation <- All[which(All[,"Event_Type"] == "Reoperations"),]
>> 
>> EF <- All[which(All[,"Treatment"] == "EF"),]
>> IMN <- All[which(All[,"Treatment"] == "IMN"),]
>> pc <- All[which(All[,"Treatment"] == "PC"),]
>> KW <- All[which(All[,"Treatment"] == "KW"),]
>> VPO <- All[which(All[,"Treatment"] == "VPO"),]
>> 
>> EF_C <- EF[which(EF[,"Event_Type"] == "Complications"),]
>> EF_R <- EF[which(EF[,"Event_Type"] == "Reoperations"),]
>> 
>> IMN_C <- IMN[which(IMN[,"Event_Type"] == "Complications"),]
>> IMN_R <- IMN[which(IMN[,"Event_Type"] == "Reoperations"),]
>> 
>> pc_C <- pc[which(pc[,"Event_Type"] == "Complications"),]
>> pc_R <- pc[which(pc[,"Event_Type"] == "Reoperations"),]
>> 
>> KW_C <- KW[which(KW[,"Event_Type"] == "Complications"),]
>> KW_R <- KW[which(KW[,"Event_Type"] == "Reoperations"),]
>> 
>> VPO_C <- VPO[which(VPO[,"Event_Type"] == "Complications"),]
>> VPO_R <- VPO[which(VPO[,"Event_Type"] == "Reoperations"),]
>> 
>> Output <- function(x, y, k.min=10){
>> file <- metaprop(Events_n, N, Study_ID, data = x)
>> 
>> forest.meta(file, studlab = T, pooled.totals = T, bysort = F)
>> 
>> dev.copy2pdf(file=y, width = 11.69, height = 8.27)
>> print(file)
>> }
>> 
>> R code on my dropbox: https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2F67pnfpi10qu110v%2FR%2520code%2520voor%2520forrest%2520en%2520funnel%2520plots.rtf%3Fdl%3D0&e=541e9c83&h=1df77562&f=y
>> 
>> [https://urlsand.esvalabs.com/?u=https%3A%2F%2Fcfl.dropboxstatic.com%2Fstatic%2Fimages%2Ficons128%2Fpage_white_word.png&e=541e9c83&h=b0ed7c54&f=y]<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2F67pnfpi10qu110v%2FR%2520code%2520voor%2520forrest%2520en%2520funnel%2520plots.rtf%3Fdl%3D0&e=541e9c83&h=1df77562&f=y>
>> 
>> R code voor forrest en funnel plots.rtf<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2F67pnfpi10qu110v%2FR%2520code%2520voor%2520forrest%2520en%2520funnel%2520plots.rtf%3Fdl%3D0&e=541e9c83&h=1df77562&f=y>
>> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.dropbox.com&e=541e9c83&h=4bc36151&f=y
>> Shared with Dropbox
>> 
>> 
>> 
>> 
>> 
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=541e9c83&h=16efca0d&f=y
>> PLEASE do read the posting guide https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=541e9c83&h=0c678195&f=y
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


From petr.pikal at precheza.cz  Tue Jun 27 08:37:28 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 27 Jun 2017 06:37:28 +0000
Subject: [R] Model studies in one analysis using treatment as a five
 level moderator in a meta-regression
In-Reply-To: <VI1PR0501MB2557107D26947CC6D2D6EC6A8ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>
References: <VI1PR0501MB2557403844FC94AE4787AF8E8ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>,
 <20170626200525.Horde.yEpy93zDtzVTx-i-2R0OHhU@webmail.unipa.it>
 <VI1PR0501MB2557107D26947CC6D2D6EC6A8ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A9656@SRVEXCHCM301.precheza.cz>

Hi

You could try to ask your question on Stackexchange, maybe somebody will answer it. This list is dedicated to helping with R code not to teaching statistics (and you did not express any direct question about the code).

Anyway, you should complain about your statistics department.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jay Zola
> Sent: Monday, June 26, 2017 11:44 PM
> To: Vito Michele Rosario Muggeo <vito.muggeo at unipa.it>
> Cc: r-help at r-project.org
> Subject: Re: [R] Model studies in one analysis using treatment as a five level
> moderator in a meta-regression
>
> Dear Vito,
>
> Thank you for your reply. I tried to contact the statistics departement
> numerous times, but did not receive any reply. That is why I started to look on
> the internet for help.
>
> Yours sincerely,
>
> Jay
>
> Verstuurd vanaf mijn iPhone
>
> > Op 26 jun. 2017 om 22:05 heeft Vito Michele Rosario Muggeo
> <vito.muggeo at unipa.it> het volgende geschreven:
> >
> > hi Jay,
> > Consult a local statistician. Statistics is not you think is (namely simple
> computations, R and probably plotting..).
> >
> > regards,
> > vito
> >
> >
> >
> > Jay Zola <jayjay.1988 at hotmail.nl> ha scritto:
> >
> >> Hello,
> >>
> >>
> >> I am medical student, writing a meta-analysis on complication and
> reoperation rates after the five most common treatments of distal radius
> fractures. I have been busy with the statistics for months by my self, but find it
> quite hard since our classes were very basic. Now I want to compare the
> treatment modalities to see if there are significant differences. Using R I was
> able to synthesize the complication rates and reoperation rates for each
> treatment method. But I never had any R course and managed by trial and
> error, so the code probably doesn't look that great. Someone told me I could
> best model the data in one analysis using treatment as a five level moderator in
> a meta-regression. Can some help me with the R code to do this? Your help
> would be very much appreciated.
> >>
> >>
> >> Thank you,
> >>
> >>
> >> Jay
> >>
> >>
> >> Study| Event Type| Treatment| Number of Events (n)| N| n/N|
> >>
> >> Kumaravel| Complications| EF| 3| 23| 0,1304348|
> >>
> >> Franck| Complications| EF| 2| 20| 0,1|
> >>
> >> Schonnemann| Complications| EF| 8| 30| 0,2666667|
> >>
> >> Aita| Complications| EF| 1| 16| 0,0625|
> >>
> >> Hove| Complications| EF| 31| 39| 0,7948718|
> >>
> >> Andersen| Complications| EF| 26| 75| 0,3466667|
> >>
> >> Krughaug| Complications| EF| 22| 75| 0,2933333|
> >>
> >> Moroni| Complications| EF| 0| 20| 0|
> >>
> >> Plate| Complications| IMN| 3| 30| 0,1|
> >>
> >> Chappuis| Complications| IMN| 4| 16| 0,25|
> >>
> >> Gradl| Complications| IMN| 12| 66| 0,1818182|
> >>
> >> Schonnemann| Complications| IMN| 6| 31| 0,1935484|
> >>
> >> Aita| Complications| IMN| 1| 16| 0,0625|
> >>
> >> Dremstrop| Complications| IMN| 17| 44| 0,3863636|
> >>
> >> Wong| Complications| PC| 1| 30| 0,0333333|
> >>
> >> Kumaravel| Complications| PC| 4| 25| 0,16|
> >>
> >>
> >> Dataset on my dropbox:
> >>
> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2F
> j
> >>
> 1urqzr99bt76ip%2FBasics%2520excel%2520file%2520complication%2520and
> %2
> >> 520reoperation%2520rate.xlsx%3Fdl%3D0&e=541e9c83&h=065e9ef9&f=y
> >>
> >> Basics excel file complication and reoperation
> >>
> rate.xlsx<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.c
> >>
> om%2Fs%2Fj1urqzr99bt76ip%2FBasics%2520excel%2520file%2520complicatio
> n
> >>
> %2520and%2520reoperation%2520rate.xlsx%3Fdl%3D0&e=541e9c83&h=065e
> 9ef9
> >> &f=y>
> >>
> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.dropbox.com&e=541e
> 9c
> >> 83&h=4bc36151&f=y
> >> Shared with Dropbox
> >>
> >>
> >>
> >>
> >> library(meta)
> >> library(stargazer)
> >> library(foreign)
> >>
> >> All <-read.spss("C:\\Users\\313635aa.STUDENT\\Desktop\\Meta-Analyse
> >> Complications and Reoperations.sav",to.data.frame = T,
> >> use.value.labels = T) All <- na.omit(All)
> >>
> >> Complications <- All[which(All[,"Event_Type"] == "Complications"),]
> >> Re_operation <- All[which(All[,"Event_Type"] == "Reoperations"),]
> >>
> >> EF <- All[which(All[,"Treatment"] == "EF"),] IMN <-
> >> All[which(All[,"Treatment"] == "IMN"),] pc <-
> >> All[which(All[,"Treatment"] == "PC"),] KW <-
> >> All[which(All[,"Treatment"] == "KW"),] VPO <-
> >> All[which(All[,"Treatment"] == "VPO"),]
> >>
> >> EF_C <- EF[which(EF[,"Event_Type"] == "Complications"),] EF_R <-
> >> EF[which(EF[,"Event_Type"] == "Reoperations"),]
> >>
> >> IMN_C <- IMN[which(IMN[,"Event_Type"] == "Complications"),] IMN_R <-
> >> IMN[which(IMN[,"Event_Type"] == "Reoperations"),]
> >>
> >> pc_C <- pc[which(pc[,"Event_Type"] == "Complications"),] pc_R <-
> >> pc[which(pc[,"Event_Type"] == "Reoperations"),]
> >>
> >> KW_C <- KW[which(KW[,"Event_Type"] == "Complications"),] KW_R <-
> >> KW[which(KW[,"Event_Type"] == "Reoperations"),]
> >>
> >> VPO_C <- VPO[which(VPO[,"Event_Type"] == "Complications"),] VPO_R <-
> >> VPO[which(VPO[,"Event_Type"] == "Reoperations"),]
> >>
> >> Output <- function(x, y, k.min=10){
> >> file <- metaprop(Events_n, N, Study_ID, data = x)
> >>
> >> forest.meta(file, studlab = T, pooled.totals = T, bysort = F)
> >>
> >> dev.copy2pdf(file=y, width = 11.69, height = 8.27)
> >> print(file)
> >> }
> >>
> >> R code on my dropbox:
> >>
> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.com%2Fs%2F
> 6
> >>
> 7pnfpi10qu110v%2FR%2520code%2520voor%2520forrest%2520en%2520funn
> el%25
> >> 20plots.rtf%3Fdl%3D0&e=541e9c83&h=1df77562&f=y
> >>
> >> [https://urlsand.esvalabs.com/?u=https%3A%2F%2Fcfl.dropboxstatic.com%
> >>
> 2Fstatic%2Fimages%2Ficons128%2Fpage_white_word.png&e=541e9c83&h=b0
> ed7
> >>
> c54&f=y]<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.co
> >>
> m%2Fs%2F67pnfpi10qu110v%2FR%2520code%2520voor%2520forrest%2520e
> n%2520
> >> funnel%2520plots.rtf%3Fdl%3D0&e=541e9c83&h=1df77562&f=y>
> >>
> >> R code voor forrest en funnel
> >> plots.rtf<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fwww.dropbox.c
> >>
> om%2Fs%2F67pnfpi10qu110v%2FR%2520code%2520voor%2520forrest%2520
> en%252
> >> 0funnel%2520plots.rtf%3Fdl%3D0&e=541e9c83&h=1df77562&f=y>
> >>
> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.dropbox.com&e=541e
> 9c
> >> 83&h=4bc36151&f=y
> >> Shared with Dropbox
> >>
> >>
> >>
> >>
> >>
> >>
> >>    [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>
> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%
> >> 2Flistinfo%2Fr-help&e=541e9c83&h=16efca0d&f=y
> >> PLEASE do read the posting guide
> >> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-
> project.org%2Fpost
> >> ing-guide.html&e=541e9c83&h=0c678195&f=y
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From maechler at stat.math.ethz.ch  Tue Jun 27 10:27:52 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 27 Jun 2017 10:27:52 +0200
Subject: [R] [Rd] setReplaceMethod creates 'object' in the userworkspace
In-Reply-To: <7674cb22-2b04-f3c1-63fe-f046e7761074@uni-duesseldorf.de>
References: <7674cb22-2b04-f3c1-63fe-f046e7761074@uni-duesseldorf.de>
Message-ID: <22866.5896.130784.758880@stat.math.ethz.ch>

>>>>> Jonathan Fritzemeier <clausjonathan.fritzemeier at uni-duesseldorf.de>
>>>>>     on Fri, 23 Jun 2017 16:15:30 +0200 writes:

    > Hi,
    > I recognized that the function 'setReplaceMethod' is creating a
    > character vector in the user workspace having the name (e.g. "newClass")
    > of the class used as value. If you can sort out a mistake by myself, I
    > would like you to file a bug report.

Yes, a mistake by yourself (and really not fit for R-devel,
but rather for R-help to which I follow up now)

    > BBFN,
    > Jonathan

> setClass("newClass", representation(value="numeric"))
> 
> setMethod(f = "initialize", signature = "newClass",
>     definition = function(.Object){
>         .Object at value <- 1
>     return(.Object)
> })
> 
> setGeneric(name = "myValue",
>         def  = function(object) { standardGeneric("myValue") }
> )
> setGeneric(name = "myValue<-",
>         def  = function(object, value) { standardGeneric("myValue<-") }
> )
> 
> setMethod("myValue", signature(object = "newClass"),
>     function(object) {
>         return(object at value)
>     }
> )

> setReplaceMethod("myValue", signature = (object = "newClass"),
>     function(object, value) {
>         object at value <- value
>         return(object)
>     }
> )

Q: what do you think happens with the above [last setReplaceMethod() call] ?
A: it creates an R object named 'object' in the globalenv
   (or the package if this would go into a package)

If just replace  '(object = "newClass")'   by   '"newClass"'
things should be fine.

{{ Removing all the completely redundant return(.), i.e. return
   implicitly rather than via an extra function call would also
   make the code "cleaner" and more R-like  }} 

Best,
Martin


> myNewObject <- new("newClass")
> print(object)
> 
> 
> > print(object)
> [1] "newClass"
>


From jcubic at jcubic.pl  Tue Jun 27 10:06:16 2017
From: jcubic at jcubic.pl (Jakub Jankiewicz)
Date: Tue, 27 Jun 2017 10:06:16 +0200
Subject: [R] Wrong function when import from module using get
Message-ID: <20170627100616.61a1817e@old-laptop>

Hi,

I found this issue:

when I have 3 modules:

* AnalysisA
* AnalysisB
* AnalysisC

I load all modules at the beginning from list of modules:

analyses <- list('AnalysisA', 'AnalysisB', 'AnalysisC')

for (module in analyses) {
   library(module, character.only = TRUE)
}

and I want to add a function isValid to each module, but I've added it only
for AnalysisB. When I run this code:

# value <- <selected by user>

flags <- sapply(analyses, function(module) {
    namespace <- getNamespace(module)
    tryCatch({
        isValid <- get("isValid", namespace)
        isValid(value)
    }, error = function(e) {
        TRUE
    })
})

# show analyses

analyses[flags]

then when R call get for AnalysisA it throw error, for AnalysisB it
return function but for AnalysisC it return function from AnalysisB and don't
throw error.

As a workaround instead of tryCatch I've used:

if ("isValid" %in% ls(namespace)) {
    isValid <- get("isValid", namespace)
    isValid(value)
} else {
    TRUE
}

Is this a bug? Should this be reported?

I'm using R 3.4.0 on windows.

--
Jakub Jankiewicz, Web Developer
http://jcubic.pl/me


From jcubic at onet.pl  Tue Jun 27 10:15:26 2017
From: jcubic at onet.pl (Jakub Jankiewicz)
Date: Tue, 27 Jun 2017 10:15:26 +0200
Subject: [R] Wrong function when import from module using get
In-Reply-To: <20170627100616.61a1817e@old-laptop>
References: <20170627100616.61a1817e@old-laptop>
Message-ID: <20170627101526.4a22cc4a@old-laptop>

By module I mean a package instaled using:

R CMD INSTAL /path/

On Tue, 27 Jun 2017 10:06:16 +0200
Jakub Jankiewicz <jcubic at jcubic.pl> wrote:

> Hi,
> 
> I found this issue:
> 
> when I have 3 modules:
> 
> * AnalysisA
> * AnalysisB
> * AnalysisC
> 
> I load all modules at the beginning from list of modules:
> 
> analyses <- list('AnalysisA', 'AnalysisB', 'AnalysisC')
> 
> for (module in analyses) {
>    library(module, character.only = TRUE)
> }
> 
> and I want to add a function isValid to each module, but I've added it only
> for AnalysisB. When I run this code:
> 
> # value <- <selected by user>
> 
> flags <- sapply(analyses, function(module) {
>     namespace <- getNamespace(module)
>     tryCatch({
>         isValid <- get("isValid", namespace)
>         isValid(value)
>     }, error = function(e) {
>         TRUE
>     })
> })
> 
> # show analyses
> 
> analyses[flags]
> 
> then when R call get for AnalysisA it throw error, for AnalysisB it
> return function but for AnalysisC it return function from AnalysisB and
> don't throw error.
> 
> As a workaround instead of tryCatch I've used:
> 
> if ("isValid" %in% ls(namespace)) {
>     isValid <- get("isValid", namespace)
>     isValid(value)
> } else {
>     TRUE
> }
> 
> Is this a bug? Should this be reported?
> 
> I'm using R 3.4.0 on windows.
> 
> --
> Jakub Jankiewicz, Web Developer
> http://jcubic.pl/me
--
Jakub Jankiewicz, Web Developer
http://jcubic.pl/me


From sandykido at gmail.com  Tue Jun 27 16:58:26 2017
From: sandykido at gmail.com (sandeep Rana)
Date: Tue, 27 Jun 2017 20:28:26 +0530
Subject: [R] Please help(urgent) - How to simulate transactional data for
	reliability/survival analysis
Message-ID: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>

Hi friends, 
I haven't done such a simulation before and any help would be greatly appreciated. I need your guidance.

I need to simulate end to end data for Reliability/survival analysis of a Pump ,with correlation in place, that is at 'Transactional level' or at the granularity of time-minutes, where each observation is a reading captured via Pump's sensors each minute.
Once transactional data is prepared I Then need to summarise above data for reliability/ survival analysis. 

To begin with below is the transactional data format that i want prepare: 
Pump-id| Timestamp | temp | vibration | suction pressure| discharge pressure | Flow 

Above transactional data has to be prepared with below failure modes
Defects :
(1)    Cavitation ? very high in frequency but low impact
(2)    Bearing Damage ? very low in frequency but high impact
(3)    Worn Shaft ? medium frequency but medium impact

I have used survsim package but that's not what I need here. 
Please help and guide. 

Regards,
Sandeep 


From bgunter.4567 at gmail.com  Tue Jun 27 17:24:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 27 Jun 2017 08:24:58 -0700
Subject: [R] Please help(urgent) - How to simulate transactional data
 for reliability/survival analysis
In-Reply-To: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>
References: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>
Message-ID: <CAGxFJbRGw_vSajVyjd3zp_65m68_-o9--AVrO3QYzo_vhy1aCA@mail.gmail.com>

I think you need to find a local consultant. Someone here might have a
suggestion or two where to look (as I do below), but this list only
provides help on R programming code, not statistical issues (see
programming guide below for details).

You might wish to have a look at the CRAN survival analysis task view
to see if any packages might address your needs (but warning: it's
mostly about medical applications):

https://cran.r-project.org/web/views/Survival.html

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 27, 2017 at 7:58 AM, sandeep Rana <sandykido at gmail.com> wrote:
> Hi friends,
> I haven't done such a simulation before and any help would be greatly appreciated. I need your guidance.
>
> I need to simulate end to end data for Reliability/survival analysis of a Pump ,with correlation in place, that is at 'Transactional level' or at the granularity of time-minutes, where each observation is a reading captured via Pump's sensors each minute.
> Once transactional data is prepared I Then need to summarise above data for reliability/ survival analysis.
>
> To begin with below is the transactional data format that i want prepare:
> Pump-id| Timestamp | temp | vibration | suction pressure| discharge pressure | Flow
>
> Above transactional data has to be prepared with below failure modes
> Defects :
> (1)    Cavitation ? very high in frequency but low impact
> (2)    Bearing Damage ? very low in frequency but high impact
> (3)    Worn Shaft ? medium frequency but medium impact
>
> I have used survsim package but that's not what I need here.
> Please help and guide.
>
> Regards,
> Sandeep
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Jun 27 17:24:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 27 Jun 2017 08:24:58 -0700
Subject: [R] Please help(urgent) - How to simulate transactional data
 for reliability/survival analysis
In-Reply-To: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>
References: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>
Message-ID: <CAGxFJbRGw_vSajVyjd3zp_65m68_-o9--AVrO3QYzo_vhy1aCA@mail.gmail.com>

I think you need to find a local consultant. Someone here might have a
suggestion or two where to look (as I do below), but this list only
provides help on R programming code, not statistical issues (see
programming guide below for details).

You might wish to have a look at the CRAN survival analysis task view
to see if any packages might address your needs (but warning: it's
mostly about medical applications):

https://cran.r-project.org/web/views/Survival.html

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 27, 2017 at 7:58 AM, sandeep Rana <sandykido at gmail.com> wrote:
> Hi friends,
> I haven't done such a simulation before and any help would be greatly appreciated. I need your guidance.
>
> I need to simulate end to end data for Reliability/survival analysis of a Pump ,with correlation in place, that is at 'Transactional level' or at the granularity of time-minutes, where each observation is a reading captured via Pump's sensors each minute.
> Once transactional data is prepared I Then need to summarise above data for reliability/ survival analysis.
>
> To begin with below is the transactional data format that i want prepare:
> Pump-id| Timestamp | temp | vibration | suction pressure| discharge pressure | Flow
>
> Above transactional data has to be prepared with below failure modes
> Defects :
> (1)    Cavitation ? very high in frequency but low impact
> (2)    Bearing Damage ? very low in frequency but high impact
> (3)    Worn Shaft ? medium frequency but medium impact
>
> I have used survsim package but that's not what I need here.
> Please help and guide.
>
> Regards,
> Sandeep
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cbuddenhagen at gmail.com  Tue Jun 27 17:45:45 2017
From: cbuddenhagen at gmail.com (Chris Buddenhagen)
Date: Tue, 27 Jun 2017 11:45:45 -0400
Subject: [R] Nash equilibrium and other game theory tools implemented in
 networks using igraph or similar
Message-ID: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>

Does anyone know of some code, and examples that implement game theory/Nash
equilibrium hypothesis testing using existing packages like igraph/statnet
or similar?

Perhaps along the lines of this article:

Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014). Local Nash
Equilibrium in Social Networks, *4*, 6224.

Best,
Chris Buddenhagen
cbuddenhagen at gmail.com

	[[alternative HTML version deleted]]


From bsmith030465 at gmail.com  Tue Jun 27 20:43:34 2017
From: bsmith030465 at gmail.com (Brian Smith)
Date: Tue, 27 Jun 2017 14:43:34 -0400
Subject: [R] ggplot2 geom_bar arrangement
Message-ID: <CAEQKoCGPvU3ZDdW2WqvsJM185vK5tj1u+MDmpec1AO8pbStMtw@mail.gmail.com>

Hi,

I was trying to draw a geom_bar plot. However, by default, the bars are
arranged according to the label, which I don't want. I want the bars to
appear exactly as they appear in the data frame. For example in the code:

 Lab=c(letters[4:6],letters[1:3])
 valuex = c(3.1,2.3,0.4,-0.4,-1.2,-4.4)
 df <- data.frame(Lab,valuex)
 px <- ggplot(df,aes(Lab,valuex,label=Lab)) + geom_text(aes(y=0)) +
geom_bar(stat = "identity")
 px


The default arranges the bars in order 'a' through 'f', but I want them
arranged as per df.

How can I do this?

thanks!

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Tue Jun 27 21:58:00 2017
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 27 Jun 2017 14:58:00 -0500
Subject: [R] ggplot2 geom_bar arrangement
In-Reply-To: <CAEQKoCGPvU3ZDdW2WqvsJM185vK5tj1u+MDmpec1AO8pbStMtw@mail.gmail.com>
References: <CAEQKoCGPvU3ZDdW2WqvsJM185vK5tj1u+MDmpec1AO8pbStMtw@mail.gmail.com>
Message-ID: <CAN5YmCGzCC=SyHqwkMQ7Lw1V9QiyWFCZCVenm6BpyanKtFQ-Fg@mail.gmail.com>

You just have to change the levels of the factor ...

library(ggplot2)

Lab = c(letters[4:6], letters[1:3])
valuex = c(3.1,2.3,0.4,-0.4,-1.2,-4.4)
df <- data.frame(Lab,valuex)

# set the factor levels to the same order as observed in the data frame
df$Lab <- factor(df$Lab, levels=unique(df$Lab))

px <- ggplot(df,aes(Lab,valuex,label=Lab)) +
  geom_text(aes(y=0)) +
  geom_bar(stat = "identity")
px

Jean

On Tue, Jun 27, 2017 at 1:43 PM, Brian Smith <bsmith030465 at gmail.com> wrote:

> Hi,
>
> I was trying to draw a geom_bar plot. However, by default, the bars are
> arranged according to the label, which I don't want. I want the bars to
> appear exactly as they appear in the data frame. For example in the code:
>
>  Lab=c(letters[4:6],letters[1:3])
>  valuex = c(3.1,2.3,0.4,-0.4,-1.2,-4.4)
>  df <- data.frame(Lab,valuex)
>  px <- ggplot(df,aes(Lab,valuex,label=Lab)) + geom_text(aes(y=0)) +
> geom_bar(stat = "identity")
>  px
>
>
> The default arranges the bars in order 'a' through 'f', but I want them
> arranged as per df.
>
> How can I do this?
>
> thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From bsmith030465 at gmail.com  Wed Jun 28 00:03:38 2017
From: bsmith030465 at gmail.com (Brian Smith)
Date: Tue, 27 Jun 2017 18:03:38 -0400
Subject: [R] ggplot2 geom_bar label justification
Message-ID: <CAEQKoCFz_VJH5Jj8fNFDy9xtUCQjriDUN6cJn61Q0P8tV0Nt+Q@mail.gmail.com>

Hi,

I was trying to make a horizontal bar plot. The barplot works when the text
labels are of reasonable length, but not if some of them are slightly long.
I think the long ones get 'squeezed' by default before the plot is flipped
and keep the skew after the flip. Is there a way I can get around this?

In the code below, plot px looks just fine, but the labels get staggered in
plot py.

#########

      Lab1 = c("Tom","Harry","Brad","Helen","Julie","Steve")

Lab2=c('abracadabra','rumplestiltskin','adadf','asddsdfsdsfsds','sdfsdfsfsfs','sddf')
      valuex = c(3.1,2.3,0.4,-0.4,-1.2,-4.4)
      df1 <- data.frame(Lab1,Lab2,valuex)
      df1$hjust <- ifelse(df1$valuex > 0, 1.3, -0.3)
      df1$Lab1 <- factor(df1$Lab1, levels = unique(df1$Lab1))
      df1$Lab2 <- factor(df1$Lab2, levels = unique(df1$Lab2))

      ## plot 1
      px <- ggplot(df1,aes(Lab,valuex,label=Lab1,hjust = hjust)) +
geom_text(aes(y=0,size=5)) +
        geom_bar(stat = "identity")
      px <- px + coord_flip()

      ## plot 2
      py <- ggplot(df1,aes(Lab,valuex,label=Lab2,hjust = hjust)) +
geom_text(aes(y=0,size=5)) +
        geom_bar(stat = "identity")
      py <- py + coord_flip()

#########

many thanks for your help!

	[[alternative HTML version deleted]]


From bsmith030465 at gmail.com  Wed Jun 28 00:20:39 2017
From: bsmith030465 at gmail.com (Brian Smith)
Date: Tue, 27 Jun 2017 18:20:39 -0400
Subject: [R] ggplot2 geom_bar arrangement
In-Reply-To: <CAN5YmCGzCC=SyHqwkMQ7Lw1V9QiyWFCZCVenm6BpyanKtFQ-Fg@mail.gmail.com>
References: <CAEQKoCGPvU3ZDdW2WqvsJM185vK5tj1u+MDmpec1AO8pbStMtw@mail.gmail.com>
 <CAN5YmCGzCC=SyHqwkMQ7Lw1V9QiyWFCZCVenm6BpyanKtFQ-Fg@mail.gmail.com>
Message-ID: <CAEQKoCHU8chq=7iUp3dJet=zLt-B_OCpuB7Tpa-uYBm4pV2K6w@mail.gmail.com>

Thanks Jean, that worked!

On Tue, Jun 27, 2017 at 3:58 PM, Adams, Jean <jvadams at usgs.gov> wrote:

> You just have to change the levels of the factor ...
>
> library(ggplot2)
>
> Lab = c(letters[4:6], letters[1:3])
> valuex = c(3.1,2.3,0.4,-0.4,-1.2,-4.4)
> df <- data.frame(Lab,valuex)
>
> # set the factor levels to the same order as observed in the data frame
> df$Lab <- factor(df$Lab, levels=unique(df$Lab))
>
> px <- ggplot(df,aes(Lab,valuex,label=Lab)) +
>   geom_text(aes(y=0)) +
>   geom_bar(stat = "identity")
> px
>
> Jean
>
> On Tue, Jun 27, 2017 at 1:43 PM, Brian Smith <bsmith030465 at gmail.com>
> wrote:
>
>> Hi,
>>
>> I was trying to draw a geom_bar plot. However, by default, the bars are
>> arranged according to the label, which I don't want. I want the bars to
>> appear exactly as they appear in the data frame. For example in the code:
>>
>>  Lab=c(letters[4:6],letters[1:3])
>>  valuex = c(3.1,2.3,0.4,-0.4,-1.2,-4.4)
>>  df <- data.frame(Lab,valuex)
>>  px <- ggplot(df,aes(Lab,valuex,label=Lab)) + geom_text(aes(y=0)) +
>> geom_bar(stat = "identity")
>>  px
>>
>>
>> The default arranges the bars in order 'a' through 'f', but I want them
>> arranged as per df.
>>
>> How can I do this?
>>
>> thanks!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From sunnysingha.analytics at gmail.com  Wed Jun 28 05:20:58 2017
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Wed, 28 Jun 2017 08:50:58 +0530
Subject: [R] Fwd: Please help(immediate) - How to simulate transactional
	data for reliability/survival analysis
References: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>
Message-ID: <175D3E83-459D-4989-856B-D750D39C1834@gmail.com>

I apologise as I had mistakenly posted this message via non- member mail. So I'm reposting it with member id. I need help in this case. 

> Hi friends, 
> I haven't done such a simulation before and any help would be greatly appreciated. I need your guidance.
> 
> I need to simulate end to end data for Reliability/survival analysis of a Pump ,with correlation in place, that is at 'Transactional level' or at the granularity of time-minutes, where each observation is a reading captured via Pump's sensors each minute.
> Once transactional data is prepared I Then need to summarise above data for reliability/ survival analysis. 
> 
> To begin with below is the transactional data format that i want prepare: 
> Pump-id| Timestamp | temp | vibration | suction pressure| discharge pressure | Flow 
> 
> Above transactional data has to be prepared with below failure modes
> Defects :
> (1)    Cavitation ? very high in frequency but low impact
> (2)    Bearing Damage ? very low in frequency but high impact
> (3)    Worn Shaft ? medium frequency but medium impact
> 
> I have used survsim package but that's not what I need here. 
> Please help and guide. 
> 
> Regards,
> Sandeep 
> 


From sunnysingha.analytics at gmail.com  Wed Jun 28 05:20:58 2017
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Wed, 28 Jun 2017 08:50:58 +0530
Subject: [R] Fwd: Please help(immediate) - How to simulate transactional
	data for reliability/survival analysis
References: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>
Message-ID: <175D3E83-459D-4989-856B-D750D39C1834@gmail.com>

I apologise as I had mistakenly posted this message via non- member mail. So I'm reposting it with member id. I need help in this case. 

> Hi friends, 
> I haven't done such a simulation before and any help would be greatly appreciated. I need your guidance.
> 
> I need to simulate end to end data for Reliability/survival analysis of a Pump ,with correlation in place, that is at 'Transactional level' or at the granularity of time-minutes, where each observation is a reading captured via Pump's sensors each minute.
> Once transactional data is prepared I Then need to summarise above data for reliability/ survival analysis. 
> 
> To begin with below is the transactional data format that i want prepare: 
> Pump-id| Timestamp | temp | vibration | suction pressure| discharge pressure | Flow 
> 
> Above transactional data has to be prepared with below failure modes
> Defects :
> (1)    Cavitation ? very high in frequency but low impact
> (2)    Bearing Damage ? very low in frequency but high impact
> (3)    Worn Shaft ? medium frequency but medium impact
> 
> I have used survsim package but that's not what I need here. 
> Please help and guide. 
> 
> Regards,
> Sandeep 
> 


From bgunter.4567 at gmail.com  Wed Jun 28 05:53:05 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 27 Jun 2017 20:53:05 -0700
Subject: [R] Fwd: Please help(immediate) - How to simulate transactional
 data for reliability/survival analysis
In-Reply-To: <175D3E83-459D-4989-856B-D750D39C1834@gmail.com>
References: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>
 <175D3E83-459D-4989-856B-D750D39C1834@gmail.com>
Message-ID: <CAGxFJbTOQB32r0oQLCpyVw5Srj9Ooywuas_PL=Gc5UqDzbX8hg@mail.gmail.com>

There is no member id. Anyone can sign up to post on this list. I
already responded to your prior post.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 27, 2017 at 8:20 PM, Sunny Singha
<sunnysingha.analytics at gmail.com> wrote:
> I apologise as I had mistakenly posted this message via non- member mail. So I'm reposting it with member id. I need help in this case.
>
>> Hi friends,
>> I haven't done such a simulation before and any help would be greatly appreciated. I need your guidance.
>>
>> I need to simulate end to end data for Reliability/survival analysis of a Pump ,with correlation in place, that is at 'Transactional level' or at the granularity of time-minutes, where each observation is a reading captured via Pump's sensors each minute.
>> Once transactional data is prepared I Then need to summarise above data for reliability/ survival analysis.
>>
>> To begin with below is the transactional data format that i want prepare:
>> Pump-id| Timestamp | temp | vibration | suction pressure| discharge pressure | Flow
>>
>> Above transactional data has to be prepared with below failure modes
>> Defects :
>> (1)    Cavitation ? very high in frequency but low impact
>> (2)    Bearing Damage ? very low in frequency but high impact
>> (3)    Worn Shaft ? medium frequency but medium impact
>>
>> I have used survsim package but that's not what I need here.
>> Please help and guide.
>>
>> Regards,
>> Sandeep
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Jun 28 05:53:05 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 27 Jun 2017 20:53:05 -0700
Subject: [R] Fwd: Please help(immediate) - How to simulate transactional
 data for reliability/survival analysis
In-Reply-To: <175D3E83-459D-4989-856B-D750D39C1834@gmail.com>
References: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>
 <175D3E83-459D-4989-856B-D750D39C1834@gmail.com>
Message-ID: <CAGxFJbTOQB32r0oQLCpyVw5Srj9Ooywuas_PL=Gc5UqDzbX8hg@mail.gmail.com>

There is no member id. Anyone can sign up to post on this list. I
already responded to your prior post.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 27, 2017 at 8:20 PM, Sunny Singha
<sunnysingha.analytics at gmail.com> wrote:
> I apologise as I had mistakenly posted this message via non- member mail. So I'm reposting it with member id. I need help in this case.
>
>> Hi friends,
>> I haven't done such a simulation before and any help would be greatly appreciated. I need your guidance.
>>
>> I need to simulate end to end data for Reliability/survival analysis of a Pump ,with correlation in place, that is at 'Transactional level' or at the granularity of time-minutes, where each observation is a reading captured via Pump's sensors each minute.
>> Once transactional data is prepared I Then need to summarise above data for reliability/ survival analysis.
>>
>> To begin with below is the transactional data format that i want prepare:
>> Pump-id| Timestamp | temp | vibration | suction pressure| discharge pressure | Flow
>>
>> Above transactional data has to be prepared with below failure modes
>> Defects :
>> (1)    Cavitation ? very high in frequency but low impact
>> (2)    Bearing Damage ? very low in frequency but high impact
>> (3)    Worn Shaft ? medium frequency but medium impact
>>
>> I have used survsim package but that's not what I need here.
>> Please help and guide.
>>
>> Regards,
>> Sandeep
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From antonio.jordan at dean.com  Tue Jun 27 11:46:19 2017
From: antonio.jordan at dean.com (Antonio Jordan)
Date: Tue, 27 Jun 2017 09:46:19 +0000
Subject: [R] Seg Fault memory violation
Message-ID: <20170627094618.GA66775@dean.com>

Greetings all,

Recently ran into a seg fault the keeps reoccurring whenever R-java is used (I believe). Not sure if this is an R issue or an openjdk issue so I'm trying to cover all bases with this report. I tried downgrading R version from 3.4.0 to 3.3.3 with the same results. Also tried downgrading java version from 1.8 to 1.7 with no luck. Running on a fully updated CentOS 7 x86_64, openjdk1.8, R 3.4.0(latest). Seems behavior is related to stack clash fix, as it seems to have exposed some memory mismanagement. Behavior wasn't noticed until after patches were applied although we can't seem to find a current workaround. Attached are backtraces ran for the same script under java 1.7 and 1.8 respectively on the same system. We have multiple installations and they all exhibit the same behavior. Any help would be greatly appreciated. Thanks for your time all.
-------------- next part --------------
Program received signal SIGBUS, Bus error.
bcEval (body=body at entry=0x857990, rho=rho at entry=0x17f3d798, useCache=useCache at entry=TRUE) at eval.c:5873
5873    {
(gdb) bt
#0  bcEval (body=body at entry=0x857990, rho=rho at entry=0x17f3d798, useCache=useCache at entry=TRUE) at eval.c:5873
#1  0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x17f3d798) at eval.c:624
#2  0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f3d450, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#3  0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x17f3d450, suppliedvars=<optimized out>) at eval.c:1549
#4  0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x17f3d450, useCache=useCache at entry=TRUE)
    at eval.c:6400
#5  0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x17f3d450) at eval.c:624
#6  0x00007ffff78d4a7e in forcePromise (e=e at entry=0x17f3d488) at eval.c:520
#7  0x00007ffff78d41ec in Rf_eval (e=0x17f3d488, rho=0x607a68) at eval.c:661
#8  0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#9  0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#10 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x17f3d5a0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#11 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x17f3d5a0) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#12 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f3d450, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#13 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x17f3d450, suppliedvars=<optimized out>) at eval.c:1549
#14 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x17f3d450, useCache=useCache at entry=TRUE)
    at eval.c:6400
#15 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x17f3d450) at eval.c:624
#16 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f3dd60, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#17 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x17f3dd60, suppliedvars=<optimized out>) at eval.c:1549
#18 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x17f3dd60, useCache=useCache at entry=TRUE)
    at eval.c:6400
#19 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x17f3dd60) at eval.c:624
#20 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f3e0c0, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#21 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x17f3da88, op=op at entry=0x3ae4eb8,
---Type <return> to continue, or q <return> to quit---
    arglist=arglist at entry=0x17f3db30, rho=rho at entry=0x17f3e0c0, suppliedvars=<optimized out>) at eval.c:1549
#22 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x17f3da88, n=n at entry=1, rho=rho at entry=0x17f3e0c0) at eval.c:1676
#23 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x17f3e0c0)
    at apply.c:70
#24 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x17f3e0c0)
    at names.c:1360
#25 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x17f3e0c0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#26 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x17f3e0c0) at eval.c:624
#27 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f3e928, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#28 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x17f3e928, suppliedvars=<optimized out>) at eval.c:1549
#29 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x17f3e928, useCache=useCache at entry=TRUE)
    at eval.c:6400
#30 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x17f3e928) at eval.c:624
#31 0x00007ffff78d4a7e in forcePromise (e=0x17f3eb90) at eval.c:520
---Type <return> to continue, or q <return> to quit---
#32 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x17f3eca8, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#33 getvar (sidx=<optimized out>, vcache=0x7fffea7312a0, keepmiss=FALSE, dd=FALSE, rho=0x17f3eca8, symbol=<optimized out>)
    at eval.c:4756
#34 bcEval (body=body at entry=0x857990, rho=rho at entry=0x17f3eca8, useCache=useCache at entry=TRUE) at eval.c:6189
#35 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x17f3eca8) at eval.c:624
#36 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f3e928, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#37 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x17f3e928, suppliedvars=<optimized out>) at eval.c:1549
#38 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x17f3e928, useCache=useCache at entry=TRUE)
    at eval.c:6400
#39 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x17f3e928) at eval.c:624
#40 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x17f3e960) at eval.c:520
#41 0x00007ffff78d41ec in Rf_eval (e=0x17f3e960, rho=0x607a68) at eval.c:661
#42 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#43 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
---Type <return> to continue, or q <return> to quit---
    at objects.c:449
#44 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x17f3eab0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#45 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x17f3eab0) at eval.c:624
#46 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f3e928, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#47 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x17f3e928, suppliedvars=<optimized out>) at eval.c:1549
#48 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x17f3e928, useCache=useCache at entry=TRUE)
    at eval.c:6400
#49 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x17f3e928) at eval.c:624
#50 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f3f8e0, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#51 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae4050, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x17f3f8e0, suppliedvars=<optimized out>) at eval.c:1549
#52 0x00007ffff78cd101 in bcEval (body=body at entry=0x39ecde0, rho=rho at entry=0x17f3f8e0, useCache=useCache at entry=TRUE)
    at eval.c:6400
---Type <return> to continue, or q <return> to quit---
#53 0x00007ffff78d4138 in Rf_eval (e=0x39ecde0, rho=0x17f3f8e0) at eval.c:624
#54 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x17f3fd40) at eval.c:520
#55 0x00007ffff78d41ec in Rf_eval (e=0x17f3fd40, rho=0x607a68) at eval.c:661
#56 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#57 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#58 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x17f3fe58, useCache=useCache at entry=TRUE)
    at eval.c:6449
#59 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x17f3fe58) at eval.c:624
#60 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f3f8e0, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#61 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae3e90, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x17f3f8e0, suppliedvars=<optimized out>) at eval.c:1549
#62 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x17f3f8e0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#63 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x17f3f8e0) at eval.c:624
#64 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0x17f40ba8, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#65 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x17f40570, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x17f40618, rho=rho at entry=0x17f40ba8, suppliedvars=<optimized out>) at eval.c:1549
#66 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x17f40570, n=n at entry=1, rho=rho at entry=0x17f40ba8) at eval.c:1676
#67 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x17f40ba8)
    at apply.c:70
#68 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x17f40ba8)
    at names.c:1360
#69 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x17f40ba8, useCache=useCache at entry=TRUE)
    at eval.c:6449
#70 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x17f40ba8) at eval.c:624
#71 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f41448, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#72 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x17f41448, suppliedvars=<optimized out>) at eval.c:1549
#73 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x17f41448, useCache=useCache at entry=TRUE)
    at eval.c:6400
---Type <return> to continue, or q <return> to quit---
#74 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x17f41448) at eval.c:624
#75 0x00007ffff78d4a7e in forcePromise (e=0x17f41678) at eval.c:520
#76 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x17f40828, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#77 getvar (sidx=<optimized out>, vcache=0x7fffea7306c0, keepmiss=FALSE, dd=FALSE, rho=0x17f40828, symbol=<optimized out>)
    at eval.c:4756
#78 bcEval (body=body at entry=0x857990, rho=rho at entry=0x17f40828, useCache=useCache at entry=TRUE) at eval.c:6189
#79 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x17f40828) at eval.c:624
#80 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f41448, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#81 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x17f41448, suppliedvars=<optimized out>) at eval.c:1549
#82 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x17f41448, useCache=useCache at entry=TRUE)
    at eval.c:6400
#83 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x17f41448) at eval.c:624
#84 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x17f41480) at eval.c:520
#85 0x00007ffff78d41ec in Rf_eval (e=0x17f41480, rho=0x607a68) at eval.c:661
---Type <return> to continue, or q <return> to quit---
#86 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#87 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#88 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x17f41598, useCache=useCache at entry=TRUE)
    at eval.c:6449
#89 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x17f41598) at eval.c:624
#90 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f41448, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#91 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x17f41448, suppliedvars=<optimized out>) at eval.c:1549
#92 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x17f41448, useCache=useCache at entry=TRUE)
    at eval.c:6400
#93 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x17f41448) at eval.c:624
#94 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f41d58, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#95 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x17f41d58, suppliedvars=<optimized out>) at eval.c:1549
---Type <return> to continue, or q <return> to quit---
#96 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x17f41d58, useCache=useCache at entry=TRUE)
    at eval.c:6400
#97 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x17f41d58) at eval.c:624
#98 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f44f70, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#99 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x17f44970, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x17f41b28, rho=rho at entry=0x17f44f70, suppliedvars=<optimized out>) at eval.c:1549
#100 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x17f44970, n=n at entry=1, rho=rho at entry=0x17f44f70) at eval.c:1676
#101 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x17f44f70)
    at apply.c:70
#102 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x17f44f70)
    at names.c:1360
#103 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x17f44f70, useCache=useCache at entry=TRUE)
    at eval.c:6449
#104 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x17f44f70) at eval.c:624
#105 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f45810, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
---Type <return> to continue, or q <return> to quit---
#106 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x17f45810, suppliedvars=<optimized out>) at eval.c:1549
#107 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x17f45810, useCache=useCache at entry=TRUE)
    at eval.c:6400
#108 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x17f45810) at eval.c:624
#109 0x00007ffff78d4a7e in forcePromise (e=0x17f45a40) at eval.c:520
#110 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x17f45b58, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#111 getvar (sidx=<optimized out>, vcache=0x7fffea72fc20, keepmiss=FALSE, dd=FALSE, rho=0x17f45b58, symbol=<optimized out>)
    at eval.c:4756
#112 bcEval (body=body at entry=0x857990, rho=rho at entry=0x17f45b58, useCache=useCache at entry=TRUE) at eval.c:6189
#113 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x17f45b58) at eval.c:624
#114 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f45810, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#115 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x17f45810, suppliedvars=<optimized out>) at eval.c:1549
#116 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x17f45810, useCache=useCache at entry=TRUE)
---Type <return> to continue, or q <return> to quit---
    at eval.c:6400
#117 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x17f45810) at eval.c:624
#118 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x17f45848) at eval.c:520
#119 0x00007ffff78d41ec in Rf_eval (e=0x17f45848, rho=0x607a68) at eval.c:661
#120 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#121 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#122 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x17f45960, useCache=useCache at entry=TRUE)
    at eval.c:6449
#123 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x17f45960) at eval.c:624
#124 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f45810, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#125 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x17f45810, suppliedvars=<optimized out>) at eval.c:1549
#126 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x17f45810, useCache=useCache at entry=TRUE)
    at eval.c:6400
#127 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x17f45810) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#128 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f45f98, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#129 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x17f45f98, suppliedvars=<optimized out>) at eval.c:1549
#130 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x17f45f98, useCache=useCache at entry=TRUE)
    at eval.c:6400
#131 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x17f45f98) at eval.c:624
#132 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f7f640, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#133 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x17f7c168, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x17f45d68, rho=rho at entry=0x17f7f640, suppliedvars=<optimized out>) at eval.c:1549
#134 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x17f7c168, n=n at entry=1, rho=rho at entry=0x17f7f640) at eval.c:1676
#135 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x17f7f640)
    at apply.c:70
#136 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x17f7f640)
    at names.c:1360
#137 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x17f7f640, useCache=useCache at entry=TRUE)
---Type <return> to continue, or q <return> to quit---
    at eval.c:6449
#138 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x17f7f640) at eval.c:624
#139 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f805f8, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#140 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x17f805f8, suppliedvars=<optimized out>) at eval.c:1549
#141 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x17f805f8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#142 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x17f805f8) at eval.c:624
#143 0x00007ffff78d4a7e in forcePromise (e=0x17f7fc08) at eval.c:520
#144 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x17f7fe00, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#145 getvar (sidx=<optimized out>, vcache=0x7fffea72f180, keepmiss=FALSE, dd=FALSE, rho=0x17f7fe00, symbol=<optimized out>)
    at eval.c:4756
#146 bcEval (body=body at entry=0x857990, rho=rho at entry=0x17f7fe00, useCache=useCache at entry=TRUE) at eval.c:6189
#147 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x17f7fe00) at eval.c:624
#148 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0x17f805f8, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#149 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x17f805f8, suppliedvars=<optimized out>) at eval.c:1549
#150 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x17f805f8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#151 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x17f805f8) at eval.c:624
#152 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x17f7f700) at eval.c:520
#153 0x00007ffff78d41ec in Rf_eval (e=0x17f7f700, rho=0x607a68) at eval.c:661
#154 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#155 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#156 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x17f7fa10, useCache=useCache at entry=TRUE)
    at eval.c:6449
#157 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x17f7fa10) at eval.c:624
#158 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f805f8, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#159 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0x17f805f8, suppliedvars=<optimized out>) at eval.c:1549
#160 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x17f805f8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#161 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x17f805f8) at eval.c:624
#162 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17f80728, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#163 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x17f80728, suppliedvars=<optimized out>) at eval.c:1549
#164 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x17f80728, useCache=useCache at entry=TRUE)
    at eval.c:6400
#165 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x17f80728) at eval.c:624
#166 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17fc1f60, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#167 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x17fc0bd8, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x17f81230, rho=rho at entry=0x17fc1f60, suppliedvars=<optimized out>) at eval.c:1549
#168 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x17fc0bd8, n=n at entry=1, rho=rho at entry=0x17fc1f60) at eval.c:1676
#169 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x17fc1f60)
---Type <return> to continue, or q <return> to quit---
    at apply.c:70
#170 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x17fc1f60)
    at names.c:1360
#171 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x17fc1f60, useCache=useCache at entry=TRUE)
    at eval.c:6449
#172 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x17fc1f60) at eval.c:624
#173 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17fc3940, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#174 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x17fc3940, suppliedvars=<optimized out>) at eval.c:1549
#175 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x17fc3940, useCache=useCache at entry=TRUE)
    at eval.c:6400
#176 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x17fc3940) at eval.c:624
#177 0x00007ffff78d4a7e in forcePromise (e=0x17fc2fc0) at eval.c:520
#178 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x17fc2448, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#179 getvar (sidx=<optimized out>, vcache=0x7fffea72e6e0, keepmiss=FALSE, dd=FALSE, rho=0x17fc2448, symbol=<optimized out>)
---Type <return> to continue, or q <return> to quit---
    at eval.c:4756
#180 bcEval (body=body at entry=0x857990, rho=rho at entry=0x17fc2448, useCache=useCache at entry=TRUE) at eval.c:6189
#181 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x17fc2448) at eval.c:624
#182 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17fc3940, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#183 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x17fc3940, suppliedvars=<optimized out>) at eval.c:1549
#184 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x17fc3940, useCache=useCache at entry=TRUE)
    at eval.c:6400
#185 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x17fc3940) at eval.c:624
#186 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x17fc39b0) at eval.c:520
#187 0x00007ffff78d41ec in Rf_eval (e=0x17fc39b0, rho=0x607a68) at eval.c:661
#188 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#189 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#190 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x17fc2d90, useCache=useCache at entry=TRUE)
    at eval.c:6449
---Type <return> to continue, or q <return> to quit---
#191 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x17fc2d90) at eval.c:624
#192 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17fc3940, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#193 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x17fc3940, suppliedvars=<optimized out>) at eval.c:1549
#194 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x17fc3940, useCache=useCache at entry=TRUE)
    at eval.c:6400
#195 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x17fc3940) at eval.c:624
#196 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17fc5208, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#197 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x17fc5208, suppliedvars=<optimized out>) at eval.c:1549
#198 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x17fc5208, useCache=useCache at entry=TRUE)
    at eval.c:6400
#199 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x17fc5208) at eval.c:624
#200 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x17ffdfb8, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
---Type <return> to continue, or q <return> to quit---
#201 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x17ffbfa0, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x17fc4d70, rho=rho at entry=0x17ffdfb8, suppliedvars=<optimized out>) at eval.c:1549
#202 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x17ffbfa0, n=n at entry=1, rho=rho at entry=0x17ffdfb8) at eval.c:1676
#203 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x17ffdfb8)
    at apply.c:70
#204 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x17ffdfb8)
    at names.c:1360
#205 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x17ffdfb8, useCache=useCache at entry=TRUE)
    at eval.c:6449
#206 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x17ffdfb8) at eval.c:624
#207 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x180009f8, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#208 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x180009f8, suppliedvars=<optimized out>) at eval.c:1549
#209 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x180009f8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#210 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x180009f8) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#211 0x00007ffff78d4a7e in forcePromise (e=0x17fff210) at eval.c:520
#212 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x17ffe7b0, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#213 getvar (sidx=<optimized out>, vcache=0x7fffea72dc40, keepmiss=FALSE, dd=FALSE, rho=0x17ffe7b0, symbol=<optimized out>)
    at eval.c:4756
#214 bcEval (body=body at entry=0x857990, rho=rho at entry=0x17ffe7b0, useCache=useCache at entry=TRUE) at eval.c:6189
#215 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x17ffe7b0) at eval.c:624
#216 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x180009f8, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#217 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x180009f8, suppliedvars=<optimized out>) at eval.c:1549
#218 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x180009f8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#219 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x180009f8) at eval.c:624
#220 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x18000a30) at eval.c:520
#221 0x00007ffff78d41ec in Rf_eval (e=0x18000a30, rho=0x607a68) at eval.c:661
#222 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
---Type <return> to continue, or q <return> to quit---
#223 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#224 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x17fffcc0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#225 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x17fffcc0) at eval.c:624
#226 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x180009f8, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#227 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x180009f8, suppliedvars=<optimized out>) at eval.c:1549
#228 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x180009f8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#229 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x180009f8) at eval.c:624
#230 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18001b38, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#231 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x18001b38, suppliedvars=<optimized out>) at eval.c:1549
#232 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x18001b38, useCache=useCache at entry=TRUE)
---Type <return> to continue, or q <return> to quit---
    at eval.c:6400
#233 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x18001b38) at eval.c:624
#234 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xee03e88, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#235 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0xecbaa90, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x18001bc0, rho=rho at entry=0xee03e88, suppliedvars=<optimized out>) at eval.c:1549
#236 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0xecbaa90, n=n at entry=1, rho=rho at entry=0xee03e88) at eval.c:1676
#237 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0xee03e88)
    at apply.c:70
#238 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0xee03e88)
    at names.c:1360
#239 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0xee03e88, useCache=useCache at entry=TRUE)
    at eval.c:6449
#240 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0xee03e88) at eval.c:624
#241 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xee14220, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#242 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0xee14220, suppliedvars=<optimized out>) at eval.c:1549
#243 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0xee14220, useCache=useCache at entry=TRUE)
    at eval.c:6400
#244 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0xee14220) at eval.c:624
#245 0x00007ffff78d4a7e in forcePromise (e=0xee14450) at eval.c:520
#246 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0xee038a0, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#247 getvar (sidx=<optimized out>, vcache=0x7fffea72d1a0, keepmiss=FALSE, dd=FALSE, rho=0xee038a0, symbol=<optimized out>)
    at eval.c:4756
#248 bcEval (body=body at entry=0x857990, rho=rho at entry=0xee038a0, useCache=useCache at entry=TRUE) at eval.c:6189
#249 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0xee038a0) at eval.c:624
#250 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xee14220, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#251 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0xee14220, suppliedvars=<optimized out>) at eval.c:1549
#252 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0xee14220, useCache=useCache at entry=TRUE)
    at eval.c:6400
---Type <return> to continue, or q <return> to quit---
#253 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0xee14220) at eval.c:624
#254 0x00007ffff78d4a7e in forcePromise (e=e at entry=0xee14258) at eval.c:520
#255 0x00007ffff78d41ec in Rf_eval (e=0xee14258, rho=0x607a68) at eval.c:661
#256 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#257 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#258 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0xee14370, useCache=useCache at entry=TRUE)
    at eval.c:6449
#259 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0xee14370) at eval.c:624
#260 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xee14220, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#261 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0xee14220, suppliedvars=<optimized out>) at eval.c:1549
#262 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0xee14220, useCache=useCache at entry=TRUE)
    at eval.c:6400
#263 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0xee14220) at eval.c:624
#264 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0xee15280, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#265 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0xee15280, suppliedvars=<optimized out>) at eval.c:1549
#266 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0xee15280, useCache=useCache at entry=TRUE)
    at eval.c:6400
#267 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0xee15280) at eval.c:624
#268 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18658918, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#269 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x18658f18, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0xee15050, rho=rho at entry=0x18658918, suppliedvars=<optimized out>) at eval.c:1549
#270 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x18658f18, n=n at entry=1, rho=rho at entry=0x18658918) at eval.c:1676
#271 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x18658918)
    at apply.c:70
#272 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x18658918)
    at names.c:1360
#273 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x18658918, useCache=useCache at entry=TRUE)
    at eval.c:6449
---Type <return> to continue, or q <return> to quit---
#274 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x18658918) at eval.c:624
#275 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18658078, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#276 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x18658078, suppliedvars=<optimized out>) at eval.c:1549
#277 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x18658078, useCache=useCache at entry=TRUE)
    at eval.c:6400
#278 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x18658078) at eval.c:624
#279 0x00007ffff78d4a7e in forcePromise (e=0x18658db0) at eval.c:520
#280 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x18658c98, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#281 getvar (sidx=<optimized out>, vcache=0x7fffea72c700, keepmiss=FALSE, dd=FALSE, rho=0x18658c98, symbol=<optimized out>)
    at eval.c:4756
#282 bcEval (body=body at entry=0x857990, rho=rho at entry=0x18658c98, useCache=useCache at entry=TRUE) at eval.c:6189
#283 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x18658c98) at eval.c:624
#284 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18658078, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
---Type <return> to continue, or q <return> to quit---
#285 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x18658078, suppliedvars=<optimized out>) at eval.c:1549
#286 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x18658078, useCache=useCache at entry=TRUE)
    at eval.c:6400
#287 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x18658078) at eval.c:624
#288 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x18658040) at eval.c:520
#289 0x00007ffff78d41ec in Rf_eval (e=0x18658040, rho=0x607a68) at eval.c:661
#290 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#291 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#292 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x18657f28, useCache=useCache at entry=TRUE)
    at eval.c:6449
#293 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x18657f28) at eval.c:624
#294 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18658078, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#295 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x18658078, suppliedvars=<optimized out>) at eval.c:1549
---Type <return> to continue, or q <return> to quit---
#296 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x18658078, useCache=useCache at entry=TRUE)
    at eval.c:6400
#297 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x18658078) at eval.c:624
#298 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18657768, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#299 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x18657768, suppliedvars=<optimized out>) at eval.c:1549
#300 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x18657768, useCache=useCache at entry=TRUE)
    at eval.c:6400
#301 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x18657768) at eval.c:624
#302 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xed5ebf8, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#303 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0xed5f1f8, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x18657998, rho=rho at entry=0xed5ebf8, suppliedvars=<optimized out>) at eval.c:1549
#304 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0xed5f1f8, n=n at entry=1, rho=rho at entry=0xed5ebf8) at eval.c:1676
#305 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0xed5ebf8)
    at apply.c:70
---Type <return> to continue, or q <return> to quit---
#306 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0xed5ebf8)
    at names.c:1360
#307 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0xed5ebf8, useCache=useCache at entry=TRUE)
    at eval.c:6449
#308 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0xed5ebf8) at eval.c:624
#309 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xed5e358, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#310 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0xed5e358, suppliedvars=<optimized out>) at eval.c:1549
#311 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0xed5e358, useCache=useCache at entry=TRUE)
    at eval.c:6400
#312 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0xed5e358) at eval.c:624
#313 0x00007ffff78d4a7e in forcePromise (e=0xed5e128) at eval.c:520
#314 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0xed5e010, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#315 getvar (sidx=<optimized out>, vcache=0x7fffea72bc60, keepmiss=FALSE, dd=FALSE, rho=0xed5e010, symbol=<optimized out>)
    at eval.c:4756
---Type <return> to continue, or q <return> to quit---
#316 bcEval (body=body at entry=0x857990, rho=rho at entry=0xed5e010, useCache=useCache at entry=TRUE) at eval.c:6189
#317 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0xed5e010) at eval.c:624
#318 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xed5e358, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#319 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0xed5e358, suppliedvars=<optimized out>) at eval.c:1549
#320 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0xed5e358, useCache=useCache at entry=TRUE)
    at eval.c:6400
#321 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0xed5e358) at eval.c:624
#322 0x00007ffff78d4a7e in forcePromise (e=e at entry=0xed5e320) at eval.c:520
#323 0x00007ffff78d41ec in Rf_eval (e=0xed5e320, rho=0x607a68) at eval.c:661
#324 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#325 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#326 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0xed5e208, useCache=useCache at entry=TRUE)
    at eval.c:6449
#327 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0xed5e208) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#328 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xed5e358, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#329 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0xed5e358, suppliedvars=<optimized out>) at eval.c:1549
#330 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0xed5e358, useCache=useCache at entry=TRUE)
    at eval.c:6400
#331 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0xed5e358) at eval.c:624
#332 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xed5da48, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#333 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0xed5da48, suppliedvars=<optimized out>) at eval.c:1549
#334 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0xed5da48, useCache=useCache at entry=TRUE)
    at eval.c:6400
#335 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0xed5da48) at eval.c:624
#336 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18269c90, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#337 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x1826a290, op=op at entry=0x3ae4eb8,
---Type <return> to continue, or q <return> to quit---
    arglist=arglist at entry=0xed5dc78, rho=rho at entry=0x18269c90, suppliedvars=<optimized out>) at eval.c:1549
#338 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x1826a290, n=n at entry=1, rho=rho at entry=0x18269c90) at eval.c:1676
#339 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x18269c90)
    at apply.c:70
#340 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x18269c90)
    at names.c:1360
#341 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x18269c90, useCache=useCache at entry=TRUE)
    at eval.c:6449
#342 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x18269c90) at eval.c:624
#343 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x182693f0, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#344 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x182693f0, suppliedvars=<optimized out>) at eval.c:1549
#345 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x182693f0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#346 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x182693f0) at eval.c:624
#347 0x00007ffff78d4a7e in forcePromise (e=0x182691c0) at eval.c:520
---Type <return> to continue, or q <return> to quit---
#348 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x182690a8, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#349 getvar (sidx=<optimized out>, vcache=0x7fffea72b1c0, keepmiss=FALSE, dd=FALSE, rho=0x182690a8, symbol=<optimized out>)
    at eval.c:4756
#350 bcEval (body=body at entry=0x857990, rho=rho at entry=0x182690a8, useCache=useCache at entry=TRUE) at eval.c:6189
#351 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x182690a8) at eval.c:624
#352 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x182693f0, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#353 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x182693f0, suppliedvars=<optimized out>) at eval.c:1549
#354 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x182693f0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#355 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x182693f0) at eval.c:624
#356 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x182693b8) at eval.c:520
#357 0x00007ffff78d41ec in Rf_eval (e=0x182693b8, rho=0x607a68) at eval.c:661
#358 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#359 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
---Type <return> to continue, or q <return> to quit---
    at objects.c:449
#360 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x182692a0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#361 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x182692a0) at eval.c:624
#362 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x182693f0, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#363 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x182693f0, suppliedvars=<optimized out>) at eval.c:1549
#364 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x182693f0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#365 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x182693f0) at eval.c:624
#366 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18268ae0, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#367 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x18268ae0, suppliedvars=<optimized out>) at eval.c:1549
#368 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x18268ae0, useCache=useCache at entry=TRUE)
    at eval.c:6400
---Type <return> to continue, or q <return> to quit---
#369 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x18268ae0) at eval.c:624
#370 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x182b2030, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#371 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x182b2630, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x18268d10, rho=rho at entry=0x182b2030, suppliedvars=<optimized out>) at eval.c:1549
#372 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x182b2630, n=n at entry=1, rho=rho at entry=0x182b2030) at eval.c:1676
#373 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x182b2030)
    at apply.c:70
#374 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x182b2030)
    at names.c:1360
#375 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x182b2030, useCache=useCache at entry=TRUE)
    at eval.c:6449
#376 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x182b2030) at eval.c:624
#377 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x182b1790, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#378 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x182b1790, suppliedvars=<optimized out>) at eval.c:1549
---Type <return> to continue, or q <return> to quit---
#379 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x182b1790, useCache=useCache at entry=TRUE)
    at eval.c:6400
#380 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x182b1790) at eval.c:624
#381 0x00007ffff78d4a7e in forcePromise (e=0x182b1560) at eval.c:520
#382 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x182b1448, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#383 getvar (sidx=<optimized out>, vcache=0x7fffea72a720, keepmiss=FALSE, dd=FALSE, rho=0x182b1448, symbol=<optimized out>)
    at eval.c:4756
#384 bcEval (body=body at entry=0x857990, rho=rho at entry=0x182b1448, useCache=useCache at entry=TRUE) at eval.c:6189
#385 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x182b1448) at eval.c:624
#386 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x182b1790, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#387 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x182b1790, suppliedvars=<optimized out>) at eval.c:1549
#388 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x182b1790, useCache=useCache at entry=TRUE)
    at eval.c:6400
#389 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x182b1790) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#390 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x182b1758) at eval.c:520
#391 0x00007ffff78d41ec in Rf_eval (e=0x182b1758, rho=0x607a68) at eval.c:661
#392 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#393 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#394 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x182b1640, useCache=useCache at entry=TRUE)
    at eval.c:6449
#395 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x182b1640) at eval.c:624
#396 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x182b1790, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#397 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x182b1790, suppliedvars=<optimized out>) at eval.c:1549
#398 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x182b1790, useCache=useCache at entry=TRUE)
    at eval.c:6400
#399 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x182b1790) at eval.c:624
#400 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x182b0e80, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
---Type <return> to continue, or q <return> to quit---
#401 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x182b0e80, suppliedvars=<optimized out>) at eval.c:1549
#402 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x182b0e80, useCache=useCache at entry=TRUE)
    at eval.c:6400
#403 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x182b0e80) at eval.c:624
#404 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x184fc660, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#405 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x184fcc60, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x182b10b0, rho=rho at entry=0x184fc660, suppliedvars=<optimized out>) at eval.c:1549
#406 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x184fcc60, n=n at entry=1, rho=rho at entry=0x184fc660) at eval.c:1676
#407 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x184fc660)
    at apply.c:70
#408 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x184fc660)
    at names.c:1360
#409 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x184fc660, useCache=useCache at entry=TRUE)
    at eval.c:6449
#410 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x184fc660) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#411 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x184fbdc0, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#412 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x184fbdc0, suppliedvars=<optimized out>) at eval.c:1549
#413 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x184fbdc0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#414 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x184fbdc0) at eval.c:624
#415 0x00007ffff78d4a7e in forcePromise (e=0x184fbb90) at eval.c:520
#416 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x184fba78, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#417 getvar (sidx=<optimized out>, vcache=0x7fffea729c80, keepmiss=FALSE, dd=FALSE, rho=0x184fba78, symbol=<optimized out>)
    at eval.c:4756
#418 bcEval (body=body at entry=0x857990, rho=rho at entry=0x184fba78, useCache=useCache at entry=TRUE) at eval.c:6189
#419 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x184fba78) at eval.c:624
#420 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x184fbdc0, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#421 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0x184fbdc0, suppliedvars=<optimized out>) at eval.c:1549
#422 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x184fbdc0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#423 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x184fbdc0) at eval.c:624
#424 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x184fbd88) at eval.c:520
#425 0x00007ffff78d41ec in Rf_eval (e=0x184fbd88, rho=0x607a68) at eval.c:661
#426 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#427 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#428 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x184fbc70, useCache=useCache at entry=TRUE)
    at eval.c:6449
#429 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x184fbc70) at eval.c:624
#430 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x184fbdc0, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#431 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x184fbdc0, suppliedvars=<optimized out>) at eval.c:1549
#432 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x184fbdc0, useCache=useCache at entry=TRUE)
---Type <return> to continue, or q <return> to quit---
    at eval.c:6400
#433 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x184fbdc0) at eval.c:624
#434 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x184fb4b0, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#435 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x184fb4b0, suppliedvars=<optimized out>) at eval.c:1549
#436 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x184fb4b0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#437 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x184fb4b0) at eval.c:624
#438 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18558fb8, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#439 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x185595b8, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x184fb6e0, rho=rho at entry=0x18558fb8, suppliedvars=<optimized out>) at eval.c:1549
#440 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x185595b8, n=n at entry=1, rho=rho at entry=0x18558fb8) at eval.c:1676
#441 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x18558fb8)
    at apply.c:70
#442 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x18558fb8)
---Type <return> to continue, or q <return> to quit---
    at names.c:1360
#443 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x18558fb8, useCache=useCache at entry=TRUE)
    at eval.c:6449
#444 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x18558fb8) at eval.c:624
#445 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18558718, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#446 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x18558718, suppliedvars=<optimized out>) at eval.c:1549
#447 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x18558718, useCache=useCache at entry=TRUE)
    at eval.c:6400
#448 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x18558718) at eval.c:624
#449 0x00007ffff78d4a7e in forcePromise (e=0x185584e8) at eval.c:520
#450 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x185583d0, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#451 getvar (sidx=<optimized out>, vcache=0x7fffea7291e0, keepmiss=FALSE, dd=FALSE, rho=0x185583d0, symbol=<optimized out>)
    at eval.c:4756
#452 bcEval (body=body at entry=0x857990, rho=rho at entry=0x185583d0, useCache=useCache at entry=TRUE) at eval.c:6189
---Type <return> to continue, or q <return> to quit---
#453 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x185583d0) at eval.c:624
#454 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18558718, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#455 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x18558718, suppliedvars=<optimized out>) at eval.c:1549
#456 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x18558718, useCache=useCache at entry=TRUE)
    at eval.c:6400
#457 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x18558718) at eval.c:624
#458 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x185586e0) at eval.c:520
#459 0x00007ffff78d41ec in Rf_eval (e=0x185586e0, rho=0x607a68) at eval.c:661
#460 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#461 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#462 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x185585c8, useCache=useCache at entry=TRUE)
    at eval.c:6449
#463 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x185585c8) at eval.c:624
#464 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0x18558718, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#465 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x18558718, suppliedvars=<optimized out>) at eval.c:1549
#466 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x18558718, useCache=useCache at entry=TRUE)
    at eval.c:6400
#467 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x18558718) at eval.c:624
#468 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18557e08, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#469 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x18557e08, suppliedvars=<optimized out>) at eval.c:1549
#470 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x18557e08, useCache=useCache at entry=TRUE)
    at eval.c:6400
#471 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x18557e08) at eval.c:624
#472 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18638670, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#473 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x18638c70, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x18558038, rho=rho at entry=0x18638670, suppliedvars=<optimized out>) at eval.c:1549
---Type <return> to continue, or q <return> to quit---
#474 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x18638c70, n=n at entry=1, rho=rho at entry=0x18638670) at eval.c:1676
#475 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x18638670)
    at apply.c:70
#476 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x18638670)
    at names.c:1360
#477 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x18638670, useCache=useCache at entry=TRUE)
    at eval.c:6449
#478 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x18638670) at eval.c:624
#479 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18637dd0, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#480 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x18637dd0, suppliedvars=<optimized out>) at eval.c:1549
#481 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x18637dd0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#482 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x18637dd0) at eval.c:624
#483 0x00007ffff78d4a7e in forcePromise (e=0x18637ba0) at eval.c:520
#484 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x18637a88, symbol=<optimized out>, value=<optimized out>)
---Type <return> to continue, or q <return> to quit---
    at eval.c:4714
#485 getvar (sidx=<optimized out>, vcache=0x7fffea728740, keepmiss=FALSE, dd=FALSE, rho=0x18637a88, symbol=<optimized out>)
    at eval.c:4756
#486 bcEval (body=body at entry=0x857990, rho=rho at entry=0x18637a88, useCache=useCache at entry=TRUE) at eval.c:6189
#487 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x18637a88) at eval.c:624
#488 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18637dd0, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#489 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x18637dd0, suppliedvars=<optimized out>) at eval.c:1549
#490 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x18637dd0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#491 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x18637dd0) at eval.c:624
#492 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x18637d98) at eval.c:520
#493 0x00007ffff78d41ec in Rf_eval (e=0x18637d98, rho=0x607a68) at eval.c:661
#494 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#495 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
---Type <return> to continue, or q <return> to quit---
#496 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x18637c80, useCache=useCache at entry=TRUE)
    at eval.c:6449
#497 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x18637c80) at eval.c:624
#498 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18637dd0, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#499 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x18637dd0, suppliedvars=<optimized out>) at eval.c:1549
#500 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x18637dd0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#501 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x18637dd0) at eval.c:624
#502 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18636d00, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#503 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x18636d00, suppliedvars=<optimized out>) at eval.c:1549
#504 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x18636d00, useCache=useCache at entry=TRUE)
    at eval.c:6400
#505 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x18636d00) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#506 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18822a78, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#507 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x18823008, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x18636f30, rho=rho at entry=0x18822a78, suppliedvars=<optimized out>) at eval.c:1549
#508 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x18823008, n=n at entry=1, rho=rho at entry=0x18822a78) at eval.c:1676
#509 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x18822a78)
    at apply.c:70
#510 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x18822a78)
    at names.c:1360
#511 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x18822a78, useCache=useCache at entry=TRUE)
    at eval.c:6449
#512 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x18822a78) at eval.c:624
#513 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x188221d8, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#514 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x188221d8, suppliedvars=<optimized out>) at eval.c:1549
#515 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x188221d8, useCache=useCache at entry=TRUE)
---Type <return> to continue, or q <return> to quit---
    at eval.c:6400
#516 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x188221d8) at eval.c:624
#517 0x00007ffff78d4a7e in forcePromise (e=0x18821fa8) at eval.c:520
#518 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x18821e90, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#519 getvar (sidx=<optimized out>, vcache=0x7fffea727ca0, keepmiss=FALSE, dd=FALSE, rho=0x18821e90, symbol=<optimized out>)
    at eval.c:4756
#520 bcEval (body=body at entry=0x857990, rho=rho at entry=0x18821e90, useCache=useCache at entry=TRUE) at eval.c:6189
#521 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x18821e90) at eval.c:624
#522 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x188221d8, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#523 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x188221d8, suppliedvars=<optimized out>) at eval.c:1549
#524 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x188221d8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#525 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x188221d8) at eval.c:624
#526 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x188221a0) at eval.c:520
---Type <return> to continue, or q <return> to quit---
#527 0x00007ffff78d41ec in Rf_eval (e=0x188221a0, rho=0x607a68) at eval.c:661
#528 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#529 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#530 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x18822088, useCache=useCache at entry=TRUE)
    at eval.c:6449
#531 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x18822088) at eval.c:624
#532 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x188221d8, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#533 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x188221d8, suppliedvars=<optimized out>) at eval.c:1549
#534 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x188221d8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#535 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x188221d8) at eval.c:624
#536 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18821938, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#537 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0x18821938, suppliedvars=<optimized out>) at eval.c:1549
#538 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x18821938, useCache=useCache at entry=TRUE)
    at eval.c:6400
#539 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x18821938) at eval.c:624
#540 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x188d47d0, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#541 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x188d4dd0, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x18821b68, rho=rho at entry=0x188d47d0, suppliedvars=<optimized out>) at eval.c:1549
#542 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x188d4dd0, n=n at entry=1, rho=rho at entry=0x188d47d0) at eval.c:1676
#543 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x188d47d0)
    at apply.c:70
#544 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x188d47d0)
    at names.c:1360
#545 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x188d47d0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#546 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x188d47d0) at eval.c:624
#547 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0x188d3f30, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#548 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x188d3f30, suppliedvars=<optimized out>) at eval.c:1549
#549 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x188d3f30, useCache=useCache at entry=TRUE)
    at eval.c:6400
#550 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x188d3f30) at eval.c:624
#551 0x00007ffff78d4a7e in forcePromise (e=0x188d3d00) at eval.c:520
#552 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x188d3be8, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#553 getvar (sidx=<optimized out>, vcache=0x7fffea727200, keepmiss=FALSE, dd=FALSE, rho=0x188d3be8, symbol=<optimized out>)
    at eval.c:4756
#554 bcEval (body=body at entry=0x857990, rho=rho at entry=0x188d3be8, useCache=useCache at entry=TRUE) at eval.c:6189
#555 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x188d3be8) at eval.c:624
#556 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x188d3f30, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#557 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x188d3f30, suppliedvars=<optimized out>) at eval.c:1549
---Type <return> to continue, or q <return> to quit---
#558 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x188d3f30, useCache=useCache at entry=TRUE)
    at eval.c:6400
#559 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x188d3f30) at eval.c:624
#560 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x188d3ef8) at eval.c:520
#561 0x00007ffff78d41ec in Rf_eval (e=0x188d3ef8, rho=0x607a68) at eval.c:661
#562 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#563 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#564 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x188d3de0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#565 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x188d3de0) at eval.c:624
#566 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x188d3f30, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#567 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x188d3f30, suppliedvars=<optimized out>) at eval.c:1549
#568 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x188d3f30, useCache=useCache at entry=TRUE)
    at eval.c:6400
---Type <return> to continue, or q <return> to quit---
#569 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x188d3f30) at eval.c:624
#570 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x188d3620, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#571 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x188d3620, suppliedvars=<optimized out>) at eval.c:1549
#572 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x188d3620, useCache=useCache at entry=TRUE)
    at eval.c:6400
#573 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x188d3620) at eval.c:624
#574 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xea30a18, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#575 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x188e93f8, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x188d3850, rho=rho at entry=0xea30a18, suppliedvars=<optimized out>) at eval.c:1549
#576 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x188e93f8, n=n at entry=1, rho=rho at entry=0xea30a18) at eval.c:1676
#577 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0xea30a18)
    at apply.c:70
#578 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0xea30a18)
    at names.c:1360
---Type <return> to continue, or q <return> to quit---
#579 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0xea30a18, useCache=useCache at entry=TRUE)
    at eval.c:6449
#580 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0xea30a18) at eval.c:624
#581 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xea30178, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#582 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0xea30178, suppliedvars=<optimized out>) at eval.c:1549
#583 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0xea30178, useCache=useCache at entry=TRUE)
    at eval.c:6400
#584 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0xea30178) at eval.c:624
#585 0x00007ffff78d4a7e in forcePromise (e=0xea2ff48) at eval.c:520
#586 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0xea2fe30, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#587 getvar (sidx=<optimized out>, vcache=0x7fffea726760, keepmiss=FALSE, dd=FALSE, rho=0xea2fe30, symbol=<optimized out>)
    at eval.c:4756
#588 bcEval (body=body at entry=0x857990, rho=rho at entry=0xea2fe30, useCache=useCache at entry=TRUE) at eval.c:6189
#589 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0xea2fe30) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#590 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xea30178, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#591 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0xea30178, suppliedvars=<optimized out>) at eval.c:1549
#592 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0xea30178, useCache=useCache at entry=TRUE)
    at eval.c:6400
#593 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0xea30178) at eval.c:624
#594 0x00007ffff78d4a7e in forcePromise (e=e at entry=0xea30140) at eval.c:520
#595 0x00007ffff78d41ec in Rf_eval (e=0xea30140, rho=0x607a68) at eval.c:661
#596 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#597 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#598 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0xea30028, useCache=useCache at entry=TRUE)
    at eval.c:6449
#599 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0xea30028) at eval.c:624
#600 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xea30178, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
---Type <return> to continue, or q <return> to quit---
#601 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0xea30178, suppliedvars=<optimized out>) at eval.c:1549
#602 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0xea30178, useCache=useCache at entry=TRUE)
    at eval.c:6400
#603 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0xea30178) at eval.c:624
#604 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xea2f868, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#605 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0xea2f868, suppliedvars=<optimized out>) at eval.c:1549
#606 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0xea2f868, useCache=useCache at entry=TRUE)
    at eval.c:6400
#607 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0xea2f868) at eval.c:624
#608 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb06328, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#609 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0xeb08050, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0xea2fa98, rho=rho at entry=0xeb06328, suppliedvars=<optimized out>) at eval.c:1549
#610 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0xeb08050, n=n at entry=1, rho=rho at entry=0xeb06328) at eval.c:1676
---Type <return> to continue, or q <return> to quit---
#611 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0xeb06328)
    at apply.c:70
#612 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0xeb06328)
    at names.c:1360
#613 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0xeb06328, useCache=useCache at entry=TRUE)
    at eval.c:6449
#614 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0xeb06328) at eval.c:624
#615 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb069f0, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#616 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0xeb069f0, suppliedvars=<optimized out>) at eval.c:1549
#617 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0xeb069f0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#618 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0xeb069f0) at eval.c:624
#619 0x00007ffff78d4a7e in forcePromise (e=0xeb067c0) at eval.c:520
#620 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0xeb066a8, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
---Type <return> to continue, or q <return> to quit---
#621 getvar (sidx=<optimized out>, vcache=0x7fffea725cc0, keepmiss=FALSE, dd=FALSE, rho=0xeb066a8, symbol=<optimized out>)
    at eval.c:4756
#622 bcEval (body=body at entry=0x857990, rho=rho at entry=0xeb066a8, useCache=useCache at entry=TRUE) at eval.c:6189
#623 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0xeb066a8) at eval.c:624
#624 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb069f0, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#625 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0xeb069f0, suppliedvars=<optimized out>) at eval.c:1549
#626 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0xeb069f0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#627 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0xeb069f0) at eval.c:624
#628 0x00007ffff78d4a7e in forcePromise (e=e at entry=0xeb069b8) at eval.c:520
#629 0x00007ffff78d41ec in Rf_eval (e=0xeb069b8, rho=0x607a68) at eval.c:661
#630 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#631 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#632 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0xeb068a0, useCache=useCache at entry=TRUE)
---Type <return> to continue, or q <return> to quit---
    at eval.c:6449
#633 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0xeb068a0) at eval.c:624
#634 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb069f0, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#635 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0xeb069f0, suppliedvars=<optimized out>) at eval.c:1549
#636 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0xeb069f0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#637 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0xeb069f0) at eval.c:624
#638 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb060e0, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#639 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0xeb060e0, suppliedvars=<optimized out>) at eval.c:1549
#640 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0xeb060e0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#641 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0xeb060e0) at eval.c:624
#642 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0xeb2b1b0, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#643 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0xeb2bf70, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0xeb053a8, rho=rho at entry=0xeb2b1b0, suppliedvars=<optimized out>) at eval.c:1549
#644 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0xeb2bf70, n=n at entry=1, rho=rho at entry=0xeb2b1b0) at eval.c:1676
#645 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0xeb2b1b0)
    at apply.c:70
#646 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0xeb2b1b0)
    at names.c:1360
#647 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0xeb2b1b0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#648 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0xeb2b1b0) at eval.c:624
#649 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb2a948, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#650 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0xeb2a948, suppliedvars=<optimized out>) at eval.c:1549
#651 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0xeb2a948, useCache=useCache at entry=TRUE)
    at eval.c:6400
---Type <return> to continue, or q <return> to quit---
#652 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0xeb2a948) at eval.c:624
#653 0x00007ffff78d4a7e in forcePromise (e=0xeb2b680) at eval.c:520
#654 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0xeb2b530, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#655 getvar (sidx=<optimized out>, vcache=0x7fffea725220, keepmiss=FALSE, dd=FALSE, rho=0xeb2b530, symbol=<optimized out>)
    at eval.c:4756
#656 bcEval (body=body at entry=0x857990, rho=rho at entry=0xeb2b530, useCache=useCache at entry=TRUE) at eval.c:6189
#657 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0xeb2b530) at eval.c:624
#658 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb2a948, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#659 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0xeb2a948, suppliedvars=<optimized out>) at eval.c:1549
#660 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0xeb2a948, useCache=useCache at entry=TRUE)
    at eval.c:6400
#661 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0xeb2a948) at eval.c:624
#662 0x00007ffff78d4a7e in forcePromise (e=e at entry=0xeb2a910) at eval.c:520
#663 0x00007ffff78d41ec in Rf_eval (e=0xeb2a910, rho=0x607a68) at eval.c:661
---Type <return> to continue, or q <return> to quit---
#664 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#665 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#666 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0xeb2a7f8, useCache=useCache at entry=TRUE)
    at eval.c:6449
#667 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0xeb2a7f8) at eval.c:624
#668 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb2a948, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#669 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0xeb2a948, suppliedvars=<optimized out>) at eval.c:1549
#670 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0xeb2a948, useCache=useCache at entry=TRUE)
    at eval.c:6400
#671 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0xeb2a948) at eval.c:624
#672 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb2a070, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#673 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0xeb2a070, suppliedvars=<optimized out>) at eval.c:1549
---Type <return> to continue, or q <return> to quit---
#674 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0xeb2a070, useCache=useCache at entry=TRUE)
    at eval.c:6400
#675 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0xeb2a070) at eval.c:624
#676 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xec49ac0, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#677 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0xec4a0c0, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0xeb2a2a0, rho=rho at entry=0xec49ac0, suppliedvars=<optimized out>) at eval.c:1549
#678 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0xec4a0c0, n=n at entry=1, rho=rho at entry=0xec49ac0) at eval.c:1676
#679 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0xec49ac0)
    at apply.c:70
#680 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0xec49ac0)
    at names.c:1360
#681 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0xec49ac0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#682 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0xec49ac0) at eval.c:624
#683 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xec49220, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
---Type <return> to continue, or q <return> to quit---
#684 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0xec49220, suppliedvars=<optimized out>) at eval.c:1549
#685 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0xec49220, useCache=useCache at entry=TRUE)
    at eval.c:6400
#686 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0xec49220) at eval.c:624
#687 0x00007ffff78d4a7e in forcePromise (e=0xec48ff0) at eval.c:520
#688 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0xec48ed8, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#689 getvar (sidx=<optimized out>, vcache=0x7fffea724780, keepmiss=FALSE, dd=FALSE, rho=0xec48ed8, symbol=<optimized out>)
    at eval.c:4756
#690 bcEval (body=body at entry=0x857990, rho=rho at entry=0xec48ed8, useCache=useCache at entry=TRUE) at eval.c:6189
#691 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0xec48ed8) at eval.c:624
#692 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xec49220, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#693 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0xec49220, suppliedvars=<optimized out>) at eval.c:1549
#694 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0xec49220, useCache=useCache at entry=TRUE)
---Type <return> to continue, or q <return> to quit---
    at eval.c:6400
#695 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0xec49220) at eval.c:624
#696 0x00007ffff78d4a7e in forcePromise (e=e at entry=0xec491e8) at eval.c:520
#697 0x00007ffff78d41ec in Rf_eval (e=0xec491e8, rho=0x607a68) at eval.c:661
#698 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#699 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#700 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0xec490d0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#701 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0xec490d0) at eval.c:624
#702 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xec49220, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#703 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0xec49220, suppliedvars=<optimized out>) at eval.c:1549
#704 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0xec49220, useCache=useCache at entry=TRUE)
    at eval.c:6400
#705 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0xec49220) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#706 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xec48910, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#707 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0xec48910, suppliedvars=<optimized out>) at eval.c:1549
#708 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0xec48910, useCache=useCache at entry=TRUE)
    at eval.c:6400
#709 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0xec48910) at eval.c:624
#710 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xed32460, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#711 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0xed339c8, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0xec48b40, rho=rho at entry=0xed32460, suppliedvars=<optimized out>) at eval.c:1549
#712 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0xed339c8, n=n at entry=1, rho=rho at entry=0xed32460) at eval.c:1676
#713 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0xed32460)
    at apply.c:70
#714 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0xed32460)
    at names.c:1360
#715 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0xed32460, useCache=useCache at entry=TRUE)
---Type <return> to continue, or q <return> to quit---
    at eval.c:6449
#716 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0xed32460) at eval.c:624
#717 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xed32b28, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#718 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0xed32b28, suppliedvars=<optimized out>) at eval.c:1549
#719 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0xed32b28, useCache=useCache at entry=TRUE)
    at eval.c:6400
#720 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0xed32b28) at eval.c:624
#721 0x00007ffff78d4a7e in forcePromise (e=0xed328f8) at eval.c:520
#722 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0xed327e0, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#723 getvar (sidx=<optimized out>, vcache=0x7fffea723ce0, keepmiss=FALSE, dd=FALSE, rho=0xed327e0, symbol=<optimized out>)
    at eval.c:4756
#724 bcEval (body=body at entry=0x857990, rho=rho at entry=0xed327e0, useCache=useCache at entry=TRUE) at eval.c:6189
#725 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0xed327e0) at eval.c:624
#726 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0xed32b28, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#727 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0xed32b28, suppliedvars=<optimized out>) at eval.c:1549
#728 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0xed32b28, useCache=useCache at entry=TRUE)
    at eval.c:6400
#729 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0xed32b28) at eval.c:624
#730 0x00007ffff78d4a7e in forcePromise (e=e at entry=0xed32af0) at eval.c:520
#731 0x00007ffff78d41ec in Rf_eval (e=0xed32af0, rho=0x607a68) at eval.c:661
#732 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#733 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#734 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0xed329d8, useCache=useCache at entry=TRUE)
    at eval.c:6449
#735 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0xed329d8) at eval.c:624
#736 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xed32b28, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#737 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0xed32b28, suppliedvars=<optimized out>) at eval.c:1549
#738 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0xed32b28, useCache=useCache at entry=TRUE)
    at eval.c:6400
#739 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0xed32b28) at eval.c:624
#740 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xed32218, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#741 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0xed32218, suppliedvars=<optimized out>) at eval.c:1549
#742 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0xed32218, useCache=useCache at entry=TRUE)
    at eval.c:6400
#743 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0xed32218) at eval.c:624
#744 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xecc47c0, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#745 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0xecc4dc0, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0xed314e0, rho=rho at entry=0xecc47c0, suppliedvars=<optimized out>) at eval.c:1549
#746 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0xecc4dc0, n=n at entry=1, rho=rho at entry=0xecc47c0) at eval.c:1676
#747 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0xecc47c0)
---Type <return> to continue, or q <return> to quit---
    at apply.c:70
#748 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0xecc47c0)
    at names.c:1360
#749 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0xecc47c0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#750 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0xecc47c0) at eval.c:624
#751 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x186e3160, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#752 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x186e3160, suppliedvars=<optimized out>) at eval.c:1549
#753 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x186e3160, useCache=useCache at entry=TRUE)
    at eval.c:6400
#754 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x186e3160) at eval.c:624
#755 0x00007ffff78d4a7e in forcePromise (e=0x186e2f30) at eval.c:520
#756 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0xecc4b40, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#757 getvar (sidx=<optimized out>, vcache=0x7fffea723240, keepmiss=FALSE, dd=FALSE, rho=0xecc4b40, symbol=<optimized out>)
---Type <return> to continue, or q <return> to quit---
    at eval.c:4756
#758 bcEval (body=body at entry=0x857990, rho=rho at entry=0xecc4b40, useCache=useCache at entry=TRUE) at eval.c:6189
#759 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0xecc4b40) at eval.c:624
#760 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x186e3160, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#761 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x186e3160, suppliedvars=<optimized out>) at eval.c:1549
#762 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x186e3160, useCache=useCache at entry=TRUE)
    at eval.c:6400
#763 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x186e3160) at eval.c:624
#764 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x186e3128) at eval.c:520
#765 0x00007ffff78d41ec in Rf_eval (e=0x186e3128, rho=0x607a68) at eval.c:661
#766 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#767 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#768 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x186e3010, useCache=useCache at entry=TRUE)
    at eval.c:6449
---Type <return> to continue, or q <return> to quit---
#769 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x186e3010) at eval.c:624
#770 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x186e3160, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#771 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x186e3160, suppliedvars=<optimized out>) at eval.c:1549
#772 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x186e3160, useCache=useCache at entry=TRUE)
    at eval.c:6400
#773 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x186e3160) at eval.c:624
#774 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x186e2850, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#775 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x186e2850, suppliedvars=<optimized out>) at eval.c:1549
#776 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x186e2850, useCache=useCache at entry=TRUE)
    at eval.c:6400
#777 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x186e2850) at eval.c:624
#778 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x186f3c60, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
---Type <return> to continue, or q <return> to quit---
#779 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x186f4260, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x186e2a80, rho=rho at entry=0x186f3c60, suppliedvars=<optimized out>) at eval.c:1549
#780 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x186f4260, n=n at entry=1, rho=rho at entry=0x186f3c60) at eval.c:1676
#781 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x186f3c60)
    at apply.c:70
#782 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x186f3c60)
    at names.c:1360
#783 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x186f3c60, useCache=useCache at entry=TRUE)
    at eval.c:6449
#784 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x186f3c60) at eval.c:624
#785 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x186f33c0, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#786 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x186f33c0, suppliedvars=<optimized out>) at eval.c:1549
#787 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x186f33c0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#788 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x186f33c0) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#789 0x00007ffff78d4a7e in forcePromise (e=0x186f3190) at eval.c:520
#790 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x186f3078, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#791 getvar (sidx=<optimized out>, vcache=0x7fffea7227a0, keepmiss=FALSE, dd=FALSE, rho=0x186f3078, symbol=<optimized out>)
    at eval.c:4756
#792 bcEval (body=body at entry=0x857990, rho=rho at entry=0x186f3078, useCache=useCache at entry=TRUE) at eval.c:6189
#793 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x186f3078) at eval.c:624
#794 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x186f33c0, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#795 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x186f33c0, suppliedvars=<optimized out>) at eval.c:1549
#796 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x186f33c0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#797 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x186f33c0) at eval.c:624
#798 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x186f3388) at eval.c:520
#799 0x00007ffff78d41ec in Rf_eval (e=0x186f3388, rho=0x607a68) at eval.c:661
#800 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
---Type <return> to continue, or q <return> to quit---
#801 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#802 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x186f3270, useCache=useCache at entry=TRUE)
    at eval.c:6449
#803 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x186f3270) at eval.c:624
#804 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x186f33c0, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#805 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x186f33c0, suppliedvars=<optimized out>) at eval.c:1549
#806 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x186f33c0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#807 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x186f33c0) at eval.c:624
#808 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x186f2ab0, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#809 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x186f2ab0, suppliedvars=<optimized out>) at eval.c:1549
#810 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x186f2ab0, useCache=useCache at entry=TRUE)
---Type <return> to continue, or q <return> to quit---
    at eval.c:6400
#811 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x186f2ab0) at eval.c:624
#812 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb99588, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#813 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0xeb99b88, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x186f2ce0, rho=rho at entry=0xeb99588, suppliedvars=<optimized out>) at eval.c:1549
#814 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0xeb99b88, n=n at entry=1, rho=rho at entry=0xeb99588) at eval.c:1676
#815 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0xeb99588)
    at apply.c:70
#816 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0xeb99588)
    at names.c:1360
#817 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0xeb99588, useCache=useCache at entry=TRUE)
    at eval.c:6449
#818 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0xeb99588) at eval.c:624
#819 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb98ce8, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#820 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0xeb98ce8, suppliedvars=<optimized out>) at eval.c:1549
#821 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0xeb98ce8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#822 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0xeb98ce8) at eval.c:624
#823 0x00007ffff78d4a7e in forcePromise (e=0xeb98ab8) at eval.c:520
#824 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0xeb989a0, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#825 getvar (sidx=<optimized out>, vcache=0x7fffea721d00, keepmiss=FALSE, dd=FALSE, rho=0xeb989a0, symbol=<optimized out>)
    at eval.c:4756
#826 bcEval (body=body at entry=0x857990, rho=rho at entry=0xeb989a0, useCache=useCache at entry=TRUE) at eval.c:6189
#827 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0xeb989a0) at eval.c:624
#828 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb98ce8, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#829 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0xeb98ce8, suppliedvars=<optimized out>) at eval.c:1549
#830 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0xeb98ce8, useCache=useCache at entry=TRUE)
    at eval.c:6400
---Type <return> to continue, or q <return> to quit---
#831 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0xeb98ce8) at eval.c:624
#832 0x00007ffff78d4a7e in forcePromise (e=e at entry=0xeb98cb0) at eval.c:520
#833 0x00007ffff78d41ec in Rf_eval (e=0xeb98cb0, rho=0x607a68) at eval.c:661
#834 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#835 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#836 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0xeb98b98, useCache=useCache at entry=TRUE)
    at eval.c:6449
#837 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0xeb98b98) at eval.c:624
#838 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xeb98ce8, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#839 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0xeb98ce8, suppliedvars=<optimized out>) at eval.c:1549
#840 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0xeb98ce8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#841 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0xeb98ce8) at eval.c:624
#842 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0xeb983d8, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#843 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0xeb983d8, suppliedvars=<optimized out>) at eval.c:1549
#844 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0xeb983d8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#845 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0xeb983d8) at eval.c:624
#846 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18570e68, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#847 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x18572b90, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0xeb98608, rho=rho at entry=0x18570e68, suppliedvars=<optimized out>) at eval.c:1549
#848 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x18572b90, n=n at entry=1, rho=rho at entry=0x18570e68) at eval.c:1676
#849 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x18570e68)
    at apply.c:70
#850 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x18570e68)
    at names.c:1360
#851 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x18570e68, useCache=useCache at entry=TRUE)
    at eval.c:6449
---Type <return> to continue, or q <return> to quit---
#852 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x18570e68) at eval.c:624
#853 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18571530, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#854 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x18571530, suppliedvars=<optimized out>) at eval.c:1549
#855 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x18571530, useCache=useCache at entry=TRUE)
    at eval.c:6400
#856 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x18571530) at eval.c:624
#857 0x00007ffff78d4a7e in forcePromise (e=0x18571300) at eval.c:520
#858 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x185711e8, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#859 getvar (sidx=<optimized out>, vcache=0x7fffea721260, keepmiss=FALSE, dd=FALSE, rho=0x185711e8, symbol=<optimized out>)
    at eval.c:4756
#860 bcEval (body=body at entry=0x857990, rho=rho at entry=0x185711e8, useCache=useCache at entry=TRUE) at eval.c:6189
#861 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x185711e8) at eval.c:624
#862 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18571530, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
---Type <return> to continue, or q <return> to quit---
#863 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x18571530, suppliedvars=<optimized out>) at eval.c:1549
#864 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x18571530, useCache=useCache at entry=TRUE)
    at eval.c:6400
#865 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x18571530) at eval.c:624
#866 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x185714f8) at eval.c:520
#867 0x00007ffff78d41ec in Rf_eval (e=0x185714f8, rho=0x607a68) at eval.c:661
#868 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#869 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#870 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x185713e0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#871 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x185713e0) at eval.c:624
#872 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18571530, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#873 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x18571530, suppliedvars=<optimized out>) at eval.c:1549
---Type <return> to continue, or q <return> to quit---
#874 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x18571530, useCache=useCache at entry=TRUE)
    at eval.c:6400
#875 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x18571530) at eval.c:624
#876 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18570460, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#877 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x18570460, suppliedvars=<optimized out>) at eval.c:1549
#878 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x18570460, useCache=useCache at entry=TRUE)
    at eval.c:6400
#879 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x18570460) at eval.c:624
#880 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x1856eb28, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#881 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x1856f7d0, op=op at entry=0x3ae4eb8,
    arglist=arglist at entry=0x1856f728, rho=rho at entry=0x1856eb28, suppliedvars=<optimized out>) at eval.c:1549
#882 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x1856f7d0, n=n at entry=1, rho=rho at entry=0x1856eb28) at eval.c:1676
#883 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0x1856eb28)
    at apply.c:70
---Type <return> to continue, or q <return> to quit---
#884 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0x1856eb28)
    at names.c:1360
#885 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0x1856eb28, useCache=useCache at entry=TRUE)
    at eval.c:6449
#886 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0x1856eb28) at eval.c:624
#887 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x1856e288, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#888 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0x1856e288, suppliedvars=<optimized out>) at eval.c:1549
#889 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0x1856e288, useCache=useCache at entry=TRUE)
    at eval.c:6400
#890 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0x1856e288) at eval.c:624
#891 0x00007ffff78d4a7e in forcePromise (e=0x1856e058) at eval.c:520
#892 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x1856eea8, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#893 getvar (sidx=<optimized out>, vcache=0x7fffea7207c0, keepmiss=FALSE, dd=FALSE, rho=0x1856eea8, symbol=<optimized out>)
    at eval.c:4756
---Type <return> to continue, or q <return> to quit---
#894 bcEval (body=body at entry=0x857990, rho=rho at entry=0x1856eea8, useCache=useCache at entry=TRUE) at eval.c:6189
#895 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0x1856eea8) at eval.c:624
#896 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x1856e288, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#897 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0x1856e288, suppliedvars=<optimized out>) at eval.c:1549
#898 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0x1856e288, useCache=useCache at entry=TRUE)
    at eval.c:6400
#899 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0x1856e288) at eval.c:624
#900 0x00007ffff78d4a7e in forcePromise (e=e at entry=0x1856e250) at eval.c:520
#901 0x00007ffff78d41ec in Rf_eval (e=0x1856e250, rho=0x607a68) at eval.c:661
#902 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#903 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
    at objects.c:449
#904 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0x1856e138, useCache=useCache at entry=TRUE)
    at eval.c:6449
#905 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0x1856e138) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#906 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x1856e288, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#907 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0x1856e288, suppliedvars=<optimized out>) at eval.c:1549
#908 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0x1856e288, useCache=useCache at entry=TRUE)
    at eval.c:6400
#909 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0x1856e288) at eval.c:624
#910 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x1856d978, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#911 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x39edf58, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x1856d978, suppliedvars=<optimized out>) at eval.c:1549
#912 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae4458, rho=rho at entry=0x1856d978, useCache=useCache at entry=TRUE)
    at eval.c:6400
#913 0x00007ffff78d4138 in Rf_eval (e=0x3ae4458, rho=rho at entry=0x1856d978) at eval.c:624
#914 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xe9779d0, arglist=arglist at entry=0x0, op=op at entry=0x3ae4eb8) at eval.c:1614
#915 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x1856b8f0, op=op at entry=0x3ae4eb8,
---Type <return> to continue, or q <return> to quit---
    arglist=arglist at entry=0x1856dba8, rho=rho at entry=0xe9779d0, suppliedvars=<optimized out>) at eval.c:1549
#916 0x00007ffff78d84bc in R_forceAndCall (e=e at entry=0x1856b8f0, n=n at entry=1, rho=rho at entry=0xe9779d0) at eval.c:1676
#917 0x00007ffff782cd92 in do_lapply (call=<optimized out>, op=<optimized out>, args=<optimized out>, rho=0xe9779d0)
    at apply.c:70
#918 0x00007ffff79092e9 in do_internal (call=<optimized out>, op=<optimized out>, args=<optimized out>, env=0xe9779d0)
    at names.c:1360
#919 0x00007ffff78c462a in bcEval (body=body at entry=0x74abd8, rho=rho at entry=0xe9779d0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#920 0x00007ffff78d4138 in Rf_eval (e=0x74abd8, rho=rho at entry=0xe9779d0) at eval.c:624
#921 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xe977130, arglist=arglist at entry=0x0, op=op at entry=0x74acb8) at eval.c:1614
#922 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5d20, op=op at entry=0x74acb8, arglist=<optimized out>,
    rho=rho at entry=0xe977130, suppliedvars=<optimized out>) at eval.c:1549
#923 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e70, rho=rho at entry=0xe977130, useCache=useCache at entry=TRUE)
    at eval.c:6400
#924 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e70, rho=0xe977130) at eval.c:624
#925 0x00007ffff78d4a7e in forcePromise (e=0xe976f00) at eval.c:520
---Type <return> to continue, or q <return> to quit---
#926 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0xe976de8, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#927 getvar (sidx=<optimized out>, vcache=0x7fffea71fd20, keepmiss=FALSE, dd=FALSE, rho=0xe976de8, symbol=<optimized out>)
    at eval.c:4756
#928 bcEval (body=body at entry=0x857990, rho=rho at entry=0xe976de8, useCache=useCache at entry=TRUE) at eval.c:6189
#929 0x00007ffff78d4138 in Rf_eval (e=0x857990, rho=rho at entry=0xe976de8) at eval.c:624
#930 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xe977130, arglist=arglist at entry=0x0, op=op at entry=0x857a70) at eval.c:1614
#931 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5cb0, op=op at entry=0x857a70, arglist=<optimized out>,
    rho=rho at entry=0xe977130, suppliedvars=<optimized out>) at eval.c:1549
#932 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5e38, rho=rho at entry=0xe977130, useCache=useCache at entry=TRUE)
    at eval.c:6400
#933 0x00007ffff78d4138 in Rf_eval (e=0x3ae5e38, rho=0xe977130) at eval.c:624
#934 0x00007ffff78d4a7e in forcePromise (e=e at entry=0xe9770f8) at eval.c:520
#935 0x00007ffff78d41ec in Rf_eval (e=0xe9770f8, rho=0x607a68) at eval.c:661
#936 0x00007ffff790a940 in GetObject (cptr=<optimized out>, cptr=<optimized out>) at objects.c:82
#937 0x00007ffff790b8e2 in do_usemethod (call=0x887498, op=<optimized out>, args=0x887460, env=<optimized out>)
---Type <return> to continue, or q <return> to quit---
    at objects.c:449
#938 0x00007ffff78c462a in bcEval (body=body at entry=0x8874d0, rho=rho at entry=0xe976fe0, useCache=useCache at entry=TRUE)
    at eval.c:6449
#939 0x00007ffff78d4138 in Rf_eval (e=0x8874d0, rho=rho at entry=0xe976fe0) at eval.c:624
#940 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0xe977130, arglist=arglist at entry=0x0, op=op at entry=0x887620) at eval.c:1614
#941 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3ae5c40, op=op at entry=0x887620, arglist=<optimized out>,
    rho=rho at entry=0xe977130, suppliedvars=<optimized out>) at eval.c:1549
#942 0x00007ffff78cd101 in bcEval (body=body at entry=0x3ae5c08, rho=rho at entry=0xe977130, useCache=useCache at entry=TRUE)
    at eval.c:6400
#943 0x00007ffff78d4138 in Rf_eval (e=0x3ae5c08, rho=rho at entry=0xe977130) at eval.c:624
#944 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x181d3540, arglist=arglist at entry=0x0, op=op at entry=0x3ae6780) at eval.c:1614
#945 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3c81750, op=op at entry=0x3ae6780, arglist=<optimized out>,
    rho=rho at entry=0x181d3540, suppliedvars=<optimized out>) at eval.c:1549
#946 0x00007ffff78cd101 in bcEval (body=body at entry=0x3c824d8, rho=rho at entry=0x181d3540, useCache=useCache at entry=TRUE)
    at eval.c:6400
---Type <return> to continue, or q <return> to quit---
#947 0x00007ffff78d4138 in Rf_eval (e=0x3c824d8, rho=rho at entry=0x181d3540) at eval.c:624
#948 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x182890d0, arglist=arglist at entry=0x0, op=op at entry=0x3c820b0) at eval.c:1614
#949 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3c8b8c0, op=op at entry=0x3c820b0, arglist=<optimized out>,
    rho=rho at entry=0x182890d0, suppliedvars=<optimized out>) at eval.c:1549
#950 0x00007ffff78cd101 in bcEval (body=body at entry=0x3c8b380, rho=rho at entry=0x182890d0, useCache=useCache at entry=TRUE)
    at eval.c:6400
#951 0x00007ffff78d4138 in Rf_eval (e=0x3c8b380, rho=rho at entry=0x182890d0) at eval.c:624
#952 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18289300, arglist=arglist at entry=0x0, op=op at entry=0x3c8d788) at eval.c:1614
#953 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3c99d18, op=op at entry=0x3c8d788, arglist=<optimized out>,
    rho=rho at entry=0x18289300, suppliedvars=<optimized out>) at eval.c:1549
#954 0x00007ffff78cd101 in bcEval (body=body at entry=0x3c99bc8, rho=rho at entry=0x18289300, useCache=useCache at entry=TRUE)
    at eval.c:6400
#955 0x00007ffff78d4138 in Rf_eval (e=0x3c99bc8, rho=rho at entry=0x18289300) at eval.c:624
#956 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18356b68, arglist=arglist at entry=0x0, op=op at entry=0x3c9a6d0) at eval.c:1614
---Type <return> to continue, or q <return> to quit---
#957 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3cd4be0, op=op at entry=0x3c9a6d0, arglist=<optimized out>,
    rho=rho at entry=0x18356b68, suppliedvars=<optimized out>) at eval.c:1549
#958 0x00007ffff78cd101 in bcEval (body=body at entry=0x3cd53a0, rho=rho at entry=0x18356b68, useCache=useCache at entry=TRUE)
    at eval.c:6400
#959 0x00007ffff78d4138 in Rf_eval (e=0x3cd53a0, rho=rho at entry=0x18356b68) at eval.c:624
#960 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18355000, arglist=arglist at entry=0x0, op=op at entry=0x3cd4fb0) at eval.c:1614
#961 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3cd7638, op=op at entry=0x3cd4fb0, arglist=<optimized out>,
    rho=rho at entry=0x18355000, suppliedvars=<optimized out>) at eval.c:1549
#962 0x00007ffff78cd101 in bcEval (body=body at entry=0x3cd6eb0, rho=rho at entry=0x18355000, useCache=useCache at entry=TRUE)
    at eval.c:6400
#963 0x00007ffff78d4138 in Rf_eval (e=0x3cd6eb0, rho=0x18355000) at eval.c:624
#964 0x00007ffff78d4a7e in forcePromise (e=0x18354fc8) at eval.c:520
#965 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x18354e08, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#966 getvar (sidx=<optimized out>, vcache=0x7fffea71ee20, keepmiss=FALSE, dd=FALSE, rho=0x18354e08, symbol=<optimized out>)
    at eval.c:4756
---Type <return> to continue, or q <return> to quit---
#967 bcEval (body=body at entry=0x8cb570, rho=rho at entry=0x18354e08, useCache=useCache at entry=TRUE) at eval.c:6189
#968 0x00007ffff78d4138 in Rf_eval (e=0x8cb570, rho=0x18354e08) at eval.c:624
#969 0x00007ffff78d4a7e in forcePromise (e=0x18355948) at eval.c:520
#970 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x183556a8, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#971 getvar (sidx=<optimized out>, vcache=0x7fffea71edf0, keepmiss=FALSE, dd=FALSE, rho=0x183556a8, symbol=<optimized out>)
    at eval.c:4756
#972 bcEval (body=body at entry=0x8c7418, rho=rho at entry=0x183556a8, useCache=useCache at entry=TRUE) at eval.c:6189
#973 0x00007ffff78d4138 in Rf_eval (e=0x8c7418, rho=0x183556a8) at eval.c:624
#974 0x00007ffff78d4a7e in forcePromise (e=0x18355600) at eval.c:520
#975 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x183562c8, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#976 getvar (sidx=<optimized out>, vcache=0x7fffea71edc0, keepmiss=FALSE, dd=FALSE, rho=0x183562c8, symbol=<optimized out>)
    at eval.c:4756
#977 bcEval (body=body at entry=0x8ca830, rho=rho at entry=0x183562c8, useCache=useCache at entry=TRUE) at eval.c:6189
#978 0x00007ffff78d4138 in Rf_eval (e=0x8ca830, rho=0x183562c8) at eval.c:624
#979 0x00007ffff78d4a7e in forcePromise (e=0x18356220) at eval.c:520
---Type <return> to continue, or q <return> to quit---
#980 0x00007ffff78d2e91 in FORCE_PROMISE (keepmiss=FALSE, rho=0x18355f80, symbol=<optimized out>, value=<optimized out>)
    at eval.c:4714
#981 getvar (sidx=<optimized out>, vcache=0x7fffea71ecf0, keepmiss=FALSE, dd=FALSE, rho=0x18355f80, symbol=<optimized out>)
    at eval.c:4756
#982 bcEval (body=body at entry=0x8cabb0, rho=rho at entry=0x18355f80, useCache=useCache at entry=TRUE) at eval.c:6189
#983 0x00007ffff78d4138 in Rf_eval (e=0x8cabb0, rho=rho at entry=0x18355f80) at eval.c:624
#984 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x183562c8, arglist=arglist at entry=0x0, op=op at entry=0x18356290) at eval.c:1614
#985 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x8c98e8, op=op at entry=0x18356290, arglist=<optimized out>,
    rho=rho at entry=0x183562c8, suppliedvars=<optimized out>) at eval.c:1549
#986 0x00007ffff78cd101 in bcEval (body=body at entry=0x8c7140, rho=rho at entry=0x183562c8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#987 0x00007ffff78d4138 in Rf_eval (e=0x8c7140, rho=rho at entry=0x183562c8) at eval.c:624
#988 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x183556a8, arglist=arglist at entry=0x0, op=op at entry=0x18354d60) at eval.c:1614
#989 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x8c6a28, op=op at entry=0x18354d60, arglist=<optimized out>,
    rho=rho at entry=0x183556a8, suppliedvars=<optimized out>) at eval.c:1549
---Type <return> to continue, or q <return> to quit---
#990 0x00007ffff78cd101 in bcEval (body=body at entry=0x8c6070, rho=rho at entry=0x183556a8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#991 0x00007ffff78d4138 in Rf_eval (e=0x8c6070, rho=rho at entry=0x183556a8) at eval.c:624
#992 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18354e08, arglist=arglist at entry=0x0, op=op at entry=0x18354dd0) at eval.c:1614
#993 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x8c6268, op=op at entry=0x18354dd0, arglist=<optimized out>,
    rho=rho at entry=0x18354e08, suppliedvars=<optimized out>) at eval.c:1549
#994 0x00007ffff78cd101 in bcEval (body=body at entry=0x8ba918, rho=rho at entry=0x18354e08, useCache=useCache at entry=TRUE)
    at eval.c:6400
#995 0x00007ffff78d4138 in Rf_eval (e=0x8ba918, rho=rho at entry=0x18354e08) at eval.c:624
#996 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x18355000, arglist=arglist at entry=0x0, op=op at entry=0x8baa68) at eval.c:1614
#997 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x3cd75c8, op=op at entry=0x8baa68, arglist=<optimized out>,
    rho=rho at entry=0x18355000, suppliedvars=<optimized out>) at eval.c:1549
#998 0x00007ffff78cd101 in bcEval (body=body at entry=0x3cd7590, rho=rho at entry=0x18355000, useCache=useCache at entry=TRUE)
    at eval.c:6400
#999 0x00007ffff78d4138 in Rf_eval (e=0x3cd7590, rho=rho at entry=0x18355000) at eval.c:624
---Type <return> to continue, or q <return> to quit---
#1000 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x63f0f0, arglist=arglist at entry=0x0, op=op at entry=0x3cd8140) at eval.c:1614
#1001 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x18353e50, op=op at entry=0x3cd8140, arglist=<optimized out>,
    rho=rho at entry=0x63f0f0, suppliedvars=<optimized out>) at eval.c:1549
#1002 0x00007ffff78d42f4 in Rf_eval (e=0x18353e50, rho=0x63f0f0) at eval.c:747
#1003 0x00007ffff78d5618 in R_cmpfun1 (fun=fun at entry=0xdb76950) at eval.c:1304
#1004 0x00007ffff78d56cb in R_cmpfun (fun=fun at entry=0xdb76950) at eval.c:1359
#1005 0x00007ffff78d621e in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x80e8ea8, arglist=arglist at entry=0x0, op=op at entry=0xdb76950) at eval.c:1569
#1006 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x5142508, op=op at entry=0xdb76950, arglist=<optimized out>,
    rho=rho at entry=0x80e8ea8, suppliedvars=<optimized out>) at eval.c:1549
#1007 0x00007ffff78cd101 in bcEval (body=body at entry=0x1806f6f8, rho=rho at entry=0x80e8ea8, useCache=useCache at entry=TRUE)
    at eval.c:6400
#1008 0x00007ffff78d4138 in Rf_eval (e=0x1806f6f8, rho=rho at entry=0x80e8ea8) at eval.c:624
#1009 0x00007ffff78d61af in R_execClosure (call=call at entry=0x6079c0, newrho=<optimized out>, sysparent=<optimized out>,
    rho=rho at entry=0x63f0f0, arglist=arglist at entry=0x0, op=op at entry=0x7ea9480) at eval.c:1614
#1010 0x00007ffff78d6539 in Rf_applyClosure (call=call at entry=0x8717ca8, op=op at entry=0x7ea9480, arglist=<optimized out>,
---Type <return> to continue, or q <return> to quit---
    rho=rho at entry=0x63f0f0, suppliedvars=<optimized out>) at eval.c:1549
#1011 0x00007ffff78cd101 in bcEval (body=<optimized out>, rho=rho at entry=0x63f0f0, useCache=useCache at entry=TRUE) at eval.c:6400
#1012 0x00007ffff78da49e in R_compileAndExecute (call=call at entry=0x8715dc0, rho=rho at entry=0x63f0f0) at eval.c:1402
#1013 0x00007ffff78da9ae in do_for (call=0x8715dc0, op=0x612708, args=0x8715d88, rho=0x63f0f0) at eval.c:1981
#1014 0x00007ffff78d4529 in Rf_eval (e=<optimized out>, rho=rho at entry=0x63f0f0) at eval.c:700
#1015 0x00007ffff78d6ea0 in do_begin (call=0x871b980, op=0x614ed8, args=0x8715df8, rho=0x63f0f0) at eval.c:2191
#1016 0x00007ffff78d4529 in Rf_eval (e=<optimized out>, rho=0x63f0f0) at eval.c:700
#1017 0x00007ffff78d4529 in Rf_eval (e=<optimized out>, rho=rho at entry=0x63f0f0) at eval.c:700
#1018 0x00007ffff78d6ea0 in do_begin (call=0x87147e8, op=0x614ed8, args=0x8714820, rho=0x63f0f0) at eval.c:2191
#1019 0x00007ffff78d4529 in Rf_eval (e=e at entry=0x87147e8, rho=rho at entry=0x63f0f0) at eval.c:700
#1020 0x00007ffff78fde12 in Rf_ReplIteration (rho=rho at entry=0x63f0f0, savestack=savestack at entry=0,
    browselevel=browselevel at entry=0, state=state at entry=0x7fffffffd350) at main.c:258
#1021 0x00007ffff78fe1f1 in R_ReplConsole (rho=0x63f0f0, savestack=0, browselevel=0) at main.c:308
#1022 0x00007ffff78fe2af in run_Rmainloop () at main.c:1059
#1023 0x00007ffff78fe2f2 in Rf_mainloop () at main.c:1066
#1024 0x000000000040080b in main (ac=<optimized out>, av=<optimized out>) at Rmain.c:29
-------------- next part --------------
Program received signal SIGSEGV, Segmentation fault.
0x00007fffcd96f2b4 in ?? ()
(gdb) bt
#0  0x00007fffcd96f2b4 in ?? ()
#1  0x0000000000000246 in ?? ()
#2  0x00007fffcd96f160 in ?? ()
#3  0x00007ffffffe6c80 in ?? ()
#4  0x00007ffffffe6c30 in ?? ()
#5  0x00007fffdd9d4e5d in get_cpu_info_wrapper ()
    at /usr/src/debug/java-1.8.0-openjdk-1.8.0.131-3.b12.el7_3.x86_64/openjdk/hotspot/src/cpu/x86/vm/vm_version_x86.cpp:395
#6  VM_Version::get_processor_features ()
    at /usr/src/debug/java-1.8.0-openjdk-1.8.0.131-3.b12.el7_3.x86_64/openjdk/hotspot/src/cpu/x86/vm/vm_version_x86.cpp:415
#7  0x49656e696c65746e in ?? ()
#8  0x02200800000306e4 in ?? ()
#9  0x178bfbffffba2203 in ?? ()
#10 0x01c0003f3c004121 in ?? ()
#11 0x000000000000003f in ?? ()
#12 0x0000000000000000 in ?? ()

From ruipbarradas at sapo.pt  Tue Jun 27 18:42:36 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 27 Jun 2017 17:42:36 +0100
Subject: [R] Nash equilibrium and other game theory tools implemented in
 networks using igraph or similar
In-Reply-To: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
Message-ID: <59528AFC.3050604@sapo.pt>

Hello,

A Google search for "R package Local Nash Equilibrium"
got

https://cran.r-project.org/web/packages/GNE/GNE.pdf

as the first hit.

Hope this helps,

Rui Barradas

Em 27-06-2017 16:45, Chris Buddenhagen escreveu:
> Does anyone know of some code, and examples that implement game theory/Nash
> equilibrium hypothesis testing using existing packages like igraph/statnet
> or similar?
>
> Perhaps along the lines of this article:
>
> Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014). Local Nash
> Equilibrium in Social Networks, *4*, 6224.
>
> Best,
> Chris Buddenhagen
> cbuddenhagen at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From taur.vil at outlook.com  Tue Jun 27 18:46:44 2017
From: taur.vil at outlook.com (Tauras Vilgalys)
Date: Tue, 27 Jun 2017 16:46:44 +0000
Subject: [R] Finding optim.R function
Message-ID: <BLUPR01MB291A8E36C162CC7CEB333AC93DC0@BLUPR01MB291.prod.exchangelabs.com>

Hello, could anybody direct me where to find code for optim.R? I was able to find the C code at http://docs.rexamine.com/R-devel/optim_8c.html, but the R version would be easier for me to work with and modify.


Thank you!


	[[alternative HTML version deleted]]


From mehmet.suzen at gmail.com  Tue Jun 27 20:00:49 2017
From: mehmet.suzen at gmail.com (Suzen, Mehmet)
Date: Tue, 27 Jun 2017 20:00:49 +0200
Subject: [R] Nash equilibrium and other game theory tools implemented in
 networks using igraph or similar
In-Reply-To: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
Message-ID: <CAPtbhHzYD59jNvLAW=h2kdmF7TTfUXjKucDAZAsMftahDyQJ7A@mail.gmail.com>

Why don't you implement and uplad the package to CRAN?

On 27 Jun 2017 17:45, "Chris Buddenhagen" <cbuddenhagen at gmail.com> wrote:

Does anyone know of some code, and examples that implement game theory/Nash
equilibrium hypothesis testing using existing packages like igraph/statnet
or similar?

Perhaps along the lines of this article:

Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014). Local Nash
Equilibrium in Social Networks, *4*, 6224.

Best,
Chris Buddenhagen
cbuddenhagen at gmail.com

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From thomas.mailund at gmail.com  Wed Jun 28 05:52:45 2017
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Wed, 28 Jun 2017 05:52:45 +0200
Subject: [R] ggplot2 geom_bar arrangement
In-Reply-To: <CAEQKoCGPvU3ZDdW2WqvsJM185vK5tj1u+MDmpec1AO8pbStMtw@mail.gmail.com>
References: <CAEQKoCGPvU3ZDdW2WqvsJM185vK5tj1u+MDmpec1AO8pbStMtw@mail.gmail.com>
Message-ID: <ed2e403d-c78f-4fd8-aa35-5204164bca66@Spark>

The order the bars are plotted in is determined by the levels in a factor, and your labels are treated as a factor. You can make sure you keep the order of your labels by simply doing this:

Lab <- factor(Lab, levels = Lab)

before constructing the data frame.

Cheers

On 27 Jun 2017, 20.43 +0200, Brian Smith <bsmith030465 at gmail.com>, wrote:
> Hi,
>
> I was trying to draw a geom_bar plot. However, by default, the bars are
> arranged according to the label, which I don't want. I want the bars to
> appear exactly as they appear in the data frame. For example in the code:
>
> Lab=c(letters[4:6],letters[1:3])
> valuex = c(3.1,2.3,0.4,-0.4,-1.2,-4.4)
> df <- data.frame(Lab,valuex)
> px <- ggplot(df,aes(Lab,valuex,label=Lab)) + geom_text(aes(y=0)) +
> geom_bar(stat = "identity")
> px
>
>
> The default arranges the bars in order 'a' through 'f', but I want them
> arranged as per df.
>
> How can I do this?
>
> thanks!
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jun 28 10:40:34 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 28 Jun 2017 04:40:34 -0400
Subject: [R] ggplot2 geom_bar arrangement
In-Reply-To: <CAEQKoCGPvU3ZDdW2WqvsJM185vK5tj1u+MDmpec1AO8pbStMtw@mail.gmail.com>
References: <CAEQKoCGPvU3ZDdW2WqvsJM185vK5tj1u+MDmpec1AO8pbStMtw@mail.gmail.com>
Message-ID: <2EFD187A-3888-4AAC-88FA-EB9E172BEA9B@dcn.davis.ca.us>

In the general case it is not possible to do as you ask because "Lab" can be duplicated. However, in your specific case it is unique in your data frame, so you just have to control the order of the factor labels instead of letting them be set up in the default manner. Of course, you have to be aware that sticking character vectors into data frames without using the stringsAsFactors argument (read the help on the data.frame function) means they get converted to factors automatically so that is where you have to take control. 

df <- data.frame( Lab=factor( Lab, labels=Lab ),valuex)
-- 
Sent from my phone. Please excuse my brevity.

On June 27, 2017 2:43:34 PM EDT, Brian Smith <bsmith030465 at gmail.com> wrote:
>Hi,
>
>I was trying to draw a geom_bar plot. However, by default, the bars are
>arranged according to the label, which I don't want. I want the bars to
>appear exactly as they appear in the data frame. For example in the
>code:
>
> Lab=c(letters[4:6],letters[1:3])
> valuex = c(3.1,2.3,0.4,-0.4,-1.2,-4.4)
> df <- data.frame(Lab,valuex)
> px <- ggplot(df,aes(Lab,valuex,label=Lab)) + geom_text(aes(y=0)) +
>geom_bar(stat = "identity")
> px
>
>
>The default arranges the bars in order 'a' through 'f', but I want them
>arranged as per df.
>
>How can I do this?
>
>thanks!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Jun 28 10:47:27 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 28 Jun 2017 04:47:27 -0400
Subject: [R] Finding optim.R function
In-Reply-To: <BLUPR01MB291A8E36C162CC7CEB333AC93DC0@BLUPR01MB291.prod.exchangelabs.com>
References: <BLUPR01MB291A8E36C162CC7CEB333AC93DC0@BLUPR01MB291.prod.exchangelabs.com>
Message-ID: <64A8B806-2F64-40BA-AC22-E4AC99054CA2@dcn.davis.ca.us>

Much of R is implemented using C or Fortran. You are on a wild goose chase. There are contributed packages that you probably ought to investigate before modifying optim, though. 

https://cran.r-project.org/web/views/Optimization.html
-- 
Sent from my phone. Please excuse my brevity.

On June 27, 2017 12:46:44 PM EDT, Tauras Vilgalys <taur.vil at outlook.com> wrote:
>Hello, could anybody direct me where to find code for optim.R? I was
>able to find the C code at
>http://docs.rexamine.com/R-devel/optim_8c.html, but the R version would
>be easier for me to work with and modify.
>
>
>Thank you!
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Jun 28 11:08:16 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 28 Jun 2017 05:08:16 -0400
Subject: [R] Nash equilibrium and other game theory tools implemented in
	networks using igraph or similar
In-Reply-To: <CAPtbhHzYD59jNvLAW=h2kdmF7TTfUXjKucDAZAsMftahDyQJ7A@mail.gmail.com>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
 <CAPtbhHzYD59jNvLAW=h2kdmF7TTfUXjKucDAZAsMftahDyQJ7A@mail.gmail.com>
Message-ID: <A60132F1-E086-4EB4-BA3B-24B4BCC7CB72@utoronto.ca>

I don't think OP asked an unreasonable question at all.

Civility!




> On Jun 27, 2017, at 2:00 PM, Suzen, Mehmet <mehmet.suzen at gmail.com> wrote:
> 
> Why don't you implement and uplad the package to CRAN?
> 
> On 27 Jun 2017 17:45, "Chris Buddenhagen" <cbuddenhagen at gmail.com> wrote:
> 
> Does anyone know of some code, and examples that implement game theory/Nash
> equilibrium hypothesis testing using existing packages like igraph/statnet
> or similar?
> 
> Perhaps along the lines of this article:
> 
> Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014). Local Nash
> Equilibrium in Social Networks, *4*, 6224.
> 
> Best,
> Chris Buddenhagen
> cbuddenhagen at gmail.com
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Jun 28 11:21:15 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 28 Jun 2017 05:21:15 -0400
Subject: [R] Please help(urgent) - How to simulate transactional data
	for reliability/survival analysis
In-Reply-To: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>
References: <D2975E52-CE3D-4ECE-BDF3-8CC44C8CC444@gmail.com>
Message-ID: <8B17F5C0-6AAE-435D-92EE-A8ADBE214FE3@utoronto.ca>

In principle what you need to do is the following:

 - break down the time you wish to simulate into intervals.
 - for each interval, and each failure mode, determine the probability of an event.
   Determining the probability is the fun part, where you make your domain
   knowledge explicit and include all the factors into your model: cumulative load,
   failure history, pressure, temperature, phase of the moon ...
 - once you have a probability of failure, use the runif() function to give you
   a uniformly distributed random number in [0, 1]. If the number is smaller than
   your failure probability, accept the failure event, and record it.
 - Repeat many times.

Hope this helps.
B.




> On Jun 27, 2017, at 10:58 AM, sandeep Rana <sandykido at gmail.com> wrote:
> 
> Hi friends, 
> I haven't done such a simulation before and any help would be greatly appreciated. I need your guidance.
> 
> I need to simulate end to end data for Reliability/survival analysis of a Pump ,with correlation in place, that is at 'Transactional level' or at the granularity of time-minutes, where each observation is a reading captured via Pump's sensors each minute.
> Once transactional data is prepared I Then need to summarise above data for reliability/ survival analysis. 
> 
> To begin with below is the transactional data format that i want prepare: 
> Pump-id| Timestamp | temp | vibration | suction pressure| discharge pressure | Flow 
> 
> Above transactional data has to be prepared with below failure modes
> Defects :
> (1)    Cavitation ? very high in frequency but low impact
> (2)    Bearing Damage ? very low in frequency but high impact
> (3)    Worn Shaft ? medium frequency but medium impact
> 
> I have used survsim package but that's not what I need here. 
> Please help and guide. 
> 
> Regards,
> Sandeep 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Jun 28 11:41:08 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 28 Jun 2017 05:41:08 -0400
Subject: [R] Nash equilibrium and other game theory tools implemented
	in	networks using igraph or similar
In-Reply-To: <A60132F1-E086-4EB4-BA3B-24B4BCC7CB72@utoronto.ca>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
 <CAPtbhHzYD59jNvLAW=h2kdmF7TTfUXjKucDAZAsMftahDyQJ7A@mail.gmail.com>
 <A60132F1-E086-4EB4-BA3B-24B4BCC7CB72@utoronto.ca>
Message-ID: <9F3853C8-DBBA-480A-9144-8E21059F746C@dcn.davis.ca.us>

In what way does reminding people that packages exist because others just like them contributed something count as being uncivil? Terse, perhaps, since it bypassed the obvious suggestion to use a search engine, but not rude.
-- 
Sent from my phone. Please excuse my brevity.

On June 28, 2017 5:08:16 AM EDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>I don't think OP asked an unreasonable question at all.
>
>Civility!
>
>
>
>
>> On Jun 27, 2017, at 2:00 PM, Suzen, Mehmet <mehmet.suzen at gmail.com>
>wrote:
>> 
>> Why don't you implement and uplad the package to CRAN?
>> 
>> On 27 Jun 2017 17:45, "Chris Buddenhagen" <cbuddenhagen at gmail.com>
>wrote:
>> 
>> Does anyone know of some code, and examples that implement game
>theory/Nash
>> equilibrium hypothesis testing using existing packages like
>igraph/statnet
>> or similar?
>> 
>> Perhaps along the lines of this article:
>> 
>> Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014). Local
>Nash
>> Equilibrium in Social Networks, *4*, 6224.
>> 
>> Best,
>> Chris Buddenhagen
>> cbuddenhagen at gmail.com
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Jun 28 11:44:31 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 28 Jun 2017 05:44:31 -0400
Subject: [R] Nash equilibrium and other game theory tools implemented
	in	networks using igraph or similar
In-Reply-To: <9F3853C8-DBBA-480A-9144-8E21059F746C@dcn.davis.ca.us>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
 <CAPtbhHzYD59jNvLAW=h2kdmF7TTfUXjKucDAZAsMftahDyQJ7A@mail.gmail.com>
 <A60132F1-E086-4EB4-BA3B-24B4BCC7CB72@utoronto.ca>
 <9F3853C8-DBBA-480A-9144-8E21059F746C@dcn.davis.ca.us>
Message-ID: <37AAFBFC-3CB0-4F39-8AE2-97D388B3C184@utoronto.ca>

I responded to the unhelpful suggestion "Why don't you implement and uplad the package to CRAN?" No  mention of a search engine. Is this what you are commenting on Jeff?





> On Jun 28, 2017, at 5:41 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> In what way does reminding people that packages exist because others just like them contributed something count as being uncivil? Terse, perhaps, since it bypassed the obvious suggestion to use a search engine, but not rude.
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On June 28, 2017 5:08:16 AM EDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> I don't think OP asked an unreasonable question at all.
>> 
>> Civility!
>> 
>> 
>> 
>> 
>>> On Jun 27, 2017, at 2:00 PM, Suzen, Mehmet <mehmet.suzen at gmail.com>
>> wrote:
>>> 
>>> Why don't you implement and uplad the package to CRAN?
>>> 
>>> On 27 Jun 2017 17:45, "Chris Buddenhagen" <cbuddenhagen at gmail.com>
>> wrote:
>>> 
>>> Does anyone know of some code, and examples that implement game
>> theory/Nash
>>> equilibrium hypothesis testing using existing packages like
>> igraph/statnet
>>> or similar?
>>> 
>>> Perhaps along the lines of this article:
>>> 
>>> Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014). Local
>> Nash
>>> Equilibrium in Social Networks, *4*, 6224.
>>> 
>>> Best,
>>> Chris Buddenhagen
>>> cbuddenhagen at gmail.com
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From cbuddenhagen at gmail.com  Wed Jun 28 11:53:53 2017
From: cbuddenhagen at gmail.com (Chris Buddenhagen)
Date: Wed, 28 Jun 2017 05:53:53 -0400
Subject: [R] Nash equilibrium and other game theory tools implemented in
 networks using igraph or similar
In-Reply-To: <37AAFBFC-3CB0-4F39-8AE2-97D388B3C184@utoronto.ca>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
 <CAPtbhHzYD59jNvLAW=h2kdmF7TTfUXjKucDAZAsMftahDyQJ7A@mail.gmail.com>
 <A60132F1-E086-4EB4-BA3B-24B4BCC7CB72@utoronto.ca>
 <9F3853C8-DBBA-480A-9144-8E21059F746C@dcn.davis.ca.us>
 <37AAFBFC-3CB0-4F39-8AE2-97D388B3C184@utoronto.ca>
Message-ID: <CAD8Oqpvpm0yR=Rqm8xu0QBd_c=U_Wur5w3++azz-NVeFXNNYGQ@mail.gmail.com>

Thanks I too wondered about the tone. The first suggestion was that I
should "google it" and the second, write my own code. I think if I did I'd
be reinventing the wheel, (and it'd be a big challenge for me). Also, I
have been searching and not found such code, despite evidence that it has
been coded (just not sure if it was in R). BTW I did write to authors of
the article I cited, but no reply.

Chris Buddenhagen
cbuddenhagen at gmail.com

On Wed, Jun 28, 2017 at 5:44 AM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> I responded to the unhelpful suggestion "Why don't you implement and uplad
> the package to CRAN?" No  mention of a search engine. Is this what you are
> commenting on Jeff?
>
>
>
>
>
> > On Jun 28, 2017, at 5:41 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > In what way does reminding people that packages exist because others
> just like them contributed something count as being uncivil? Terse,
> perhaps, since it bypassed the obvious suggestion to use a search engine,
> but not rude.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On June 28, 2017 5:08:16 AM EDT, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> >> I don't think OP asked an unreasonable question at all.
> >>
> >> Civility!
> >>
> >>
> >>
> >>
> >>> On Jun 27, 2017, at 2:00 PM, Suzen, Mehmet <mehmet.suzen at gmail.com>
> >> wrote:
> >>>
> >>> Why don't you implement and uplad the package to CRAN?
> >>>
> >>> On 27 Jun 2017 17:45, "Chris Buddenhagen" <cbuddenhagen at gmail.com>
> >> wrote:
> >>>
> >>> Does anyone know of some code, and examples that implement game
> >> theory/Nash
> >>> equilibrium hypothesis testing using existing packages like
> >> igraph/statnet
> >>> or similar?
> >>>
> >>> Perhaps along the lines of this article:
> >>>
> >>> Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014). Local
> >> Nash
> >>> Equilibrium in Social Networks, *4*, 6224.
> >>>
> >>> Best,
> >>> Chris Buddenhagen
> >>> cbuddenhagen at gmail.com
> >>>
> >>>       [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>     [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jun 28 12:40:48 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 28 Jun 2017 06:40:48 -0400
Subject: [R] Nash equilibrium and other game theory tools implemented
	in	networks using igraph or similar
In-Reply-To: <37AAFBFC-3CB0-4F39-8AE2-97D388B3C184@utoronto.ca>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
 <CAPtbhHzYD59jNvLAW=h2kdmF7TTfUXjKucDAZAsMftahDyQJ7A@mail.gmail.com>
 <A60132F1-E086-4EB4-BA3B-24B4BCC7CB72@utoronto.ca>
 <9F3853C8-DBBA-480A-9144-8E21059F746C@dcn.davis.ca.us>
 <37AAFBFC-3CB0-4F39-8AE2-97D388B3C184@utoronto.ca>
Message-ID: <D9C9F5D5-668E-4A74-9FAE-907D6FC2F27D@dcn.davis.ca.us>

There are many possible responses to the question "Is there a package to do X." Some that I can imagine are:

* Yes, see package Y...
* No, I am familiar with all 10000 packages and there isn't...
* Silence (because no one who is paying attention is familiar with the one that exists)
* Use a search engine...
* You are a jerk because you did not use a search engine
* Packages exist because people like you did not find what they were looking for

My point was that response 5 would have been uncivil, but 6 was a valid reminder and Mehmet was just being brief, not rude.

The first does happen, but it is more common that if the question sounds interesting that this question triggers list members to search for themselves. If the OP tells us that they did this already and package Y (that appears as soon as we do this) is unsuitable for some specific reason, then we all nod and agree that the search engine wasn't up to the task and watch with the OP in case someone does respond with an answer. But when the OP does not do that we get frustrated that yet again we are being treated like a search engine by someone who does not do their homework, since we don't know why they regarded the first search result as unsuitable. 

Keep in mind that broadcasting to many uninterested parties when the pool of targeted individuals (in this case,  people who have the answer readily available) is very very small is an activity most people call "spam". Showing your work so that someone else can either see something you missed or share in the joy when a rare answer comes through is what elevates such a posting from spam to shared research. 
-- 
Sent from my phone. Please excuse my brevity.

On June 28, 2017 5:44:31 AM EDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>I responded to the unhelpful suggestion "Why don't you implement and
>uplad the package to CRAN?" No  mention of a search engine. Is this
>what you are commenting on Jeff?
>
>
>
>
>
>> On Jun 28, 2017, at 5:41 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> In what way does reminding people that packages exist because others
>just like them contributed something count as being uncivil? Terse,
>perhaps, since it bypassed the obvious suggestion to use a search
>engine, but not rude.
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> On June 28, 2017 5:08:16 AM EDT, Boris Steipe
><boris.steipe at utoronto.ca> wrote:
>>> I don't think OP asked an unreasonable question at all.
>>> 
>>> Civility!
>>> 
>>> 
>>> 
>>> 
>>>> On Jun 27, 2017, at 2:00 PM, Suzen, Mehmet <mehmet.suzen at gmail.com>
>>> wrote:
>>>> 
>>>> Why don't you implement and uplad the package to CRAN?
>>>> 
>>>> On 27 Jun 2017 17:45, "Chris Buddenhagen" <cbuddenhagen at gmail.com>
>>> wrote:
>>>> 
>>>> Does anyone know of some code, and examples that implement game
>>> theory/Nash
>>>> equilibrium hypothesis testing using existing packages like
>>> igraph/statnet
>>>> or similar?
>>>> 
>>>> Perhaps along the lines of this article:
>>>> 
>>>> Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014).
>Local
>>> Nash
>>>> Equilibrium in Social Networks, *4*, 6224.
>>>> 
>>>> Best,
>>>> Chris Buddenhagen
>>>> cbuddenhagen at gmail.com
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at effectivedefense.org  Wed Jun 28 12:56:51 2017
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Wed, 28 Jun 2017 05:56:51 -0500
Subject: [R] Nash equilibrium and other game theory tools implemented in
 networks using igraph or similar
In-Reply-To: <D9C9F5D5-668E-4A74-9FAE-907D6FC2F27D@dcn.davis.ca.us>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
 <CAPtbhHzYD59jNvLAW=h2kdmF7TTfUXjKucDAZAsMftahDyQJ7A@mail.gmail.com>
 <A60132F1-E086-4EB4-BA3B-24B4BCC7CB72@utoronto.ca>
 <9F3853C8-DBBA-480A-9144-8E21059F746C@dcn.davis.ca.us>
 <37AAFBFC-3CB0-4F39-8AE2-97D388B3C184@utoronto.ca>
 <D9C9F5D5-668E-4A74-9FAE-907D6FC2F27D@dcn.davis.ca.us>
Message-ID: <ec5eb2aa-1eda-ed40-b07f-4ad9a33e7104@effectivedefense.org>



On 2017-06-28 5:40 AM, Jeff Newmiller wrote:
> Showing your work so that someone else can either see something you missed or share in the joy when a rare answer comes through is what elevates such a posting from spam to shared research.

A "fortune"?


       sg


From Mike.Conklin at gfk.com  Wed Jun 28 16:15:08 2017
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Wed, 28 Jun 2017 14:15:08 +0000
Subject: [R] Missing dependencies in pkg installs SOLVED
Message-ID: <825f336a2df84ebf83a5f730b53b5b6b@IPXW-EXPCM02.gfk.com>

So apparently (being a linux novice) I didn't realize it was insufficient to simply have the file marked as executable. It turns out the default TMP directory on my machine  is mounted with a noexec flag so no files in that directory are allowed to be executed.  The solution is to set an environment variable TMPDIR=some new directory I created  (eg. /home/myusername/tmp) Then R uses that directory for the installs.  The easiest method then is to use do  

sudo R
Sys.setev(TMPDIR="/home/myusername/tmp") 
install.packages(pkglist)

the sudo R part just ensures I am installing into the global library and not a user specific library

--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK 
T +1 763 417 4545 | M +1 612 567 8287 

-----Original Message-----
From: Conklin, Mike (GfK) 
Sent: Friday, June 23, 2017 4:38 PM
To: Don Cohen; Duncan Murdoch
Cc: Martin Maechler; r-help at r-project.org
Subject: Re: [R] Missing dependencies in pkg installs

Checked all the permissions, and it appears that file_test returns a FALSE and system(ls -l) shows it is executable, so the problem seems to be in R and it's relationship to RHEL.  I tried installing R3.3.3 to see if the older version would install stringi and had the same problem so it doesn't appear to be R3.4 related.  I am now reaching out to some other sources who may have installed R on similar systems.


________________________________________
From: Conklin, Mike (GfK)
Sent: Friday, June 23, 2017 8:50 AM
To: Don Cohen; Duncan Murdoch
Cc: Martin Maechler; r-help at r-project.org
Subject: RE: [R] Missing dependencies in pkg installs

I had the same thought in the shower this morning but I was disappointed to find that SElinux was disabled on the system.  My next step will be to install a previous version of R on the system.  My problem is that I am planning a shiny server installation and at least half of the apps on the current system depend on these libraries that will not install.
--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK
T +1 763 417 4545 | M +1 612 567 8287

-----Original Message-----
From: Don Cohen [mailto:don-r-help at isis.cs3-inc.com]
Sent: Thursday, June 22, 2017 6:18 PM
To: Duncan Murdoch
Cc: Conklin, Mike (GfK); Martin Maechler; r-help at r-project.org
Subject: Re: [R] Missing dependencies in pkg installs

Duncan Murdoch writes:
 > On 22/06/2017 5:02 PM, Conklin, Mike (GfK) wrote:
 > > I am using debug on the .install_packages function...stepping through. Once the temporary folder is created and the tar file expanded I run file_test and get a FALSE back indicating that the configure file is not executable.
 >
 > I don't know what is causing this bug.  Perhaps a Linux user can  > reproduce it and fix it.
 >
 > Here's what I see:
 >
 > file_test("-x") calls file.access(filename, 1L).  That in turn calls the  > C library function access(..., X_OK).  The ... is the name of the file,  > translated into the local encoding and expanded.  As far as I can see,  > that means ... should be exactly the string below.
 > >
 > > [1] "/tmp/RtmpMM6iC1/R.INSTALLc5ca415e4310/stringi"
 >
 > The only thing I can think of is that your system is protecting you from  > executing a newly created file until some sort of virus or other check  > is done.  (This is common on Windows, but I've never heard of it before  > on Linux.)

Just a thought - are you running SELinux ?
Check the log files for refusals to run programs.


From lists at dewey.myzen.co.uk  Wed Jun 28 17:05:47 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 28 Jun 2017 16:05:47 +0100
Subject: [R] Model studies in one analysis using treatment as a five
 level moderator in a meta-regression
In-Reply-To: <VI1PR0501MB2557403844FC94AE4787AF8E8ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>
References: <VI1PR0501MB2557403844FC94AE4787AF8E8ADF0@VI1PR0501MB2557.eurprd05.prod.outlook.com>
Message-ID: <51fbf572-969c-6dfb-2c84-76a67e3ba0f6@dewey.myzen.co.uk>

Dear Jay

I am not that familiar with the meta package but it looks as though it 
does not allow you to do a meta-regression within metaprop. However 
there is a function metareg which takes the object you created with 
metaprop and allows you to add a moderator so i would try that next. By 
moderator in this case I mean your variable Treatment.

On 26/06/2017 19:19, Jay Zola wrote:
> Hello,
>
>
> I am medical student, writing a meta-analysis on complication and reoperation rates after the five most common treatments of distal radius fractures. I have been busy with the statistics for months by my self, but find it quite hard since our classes were very basic. Now I want to compare the treatment modalities to see if there are significant differences. Using R I was able to synthesize the complication rates and reoperation rates for each treatment method. But I never had any R course and managed by trial and error, so the code probably doesn't look that great. Someone told me I could best model the data in one analysis using treatment as a five level moderator in a meta-regression. Can some help me with the R code to do this? Your help would be very much appreciated.
>
>
> Thank you,
>
>
> Jay
>
>
> Study| Event Type| Treatment| Number of Events (n)| N| n/N|
>
> Kumaravel| Complications| EF| 3| 23| 0,1304348|
>
> Franck| Complications| EF| 2| 20| 0,1|
>
> Schonnemann| Complications| EF| 8| 30| 0,2666667|
>
> Aita| Complications| EF| 1| 16| 0,0625|
>
> Hove| Complications| EF| 31| 39| 0,7948718|
>
> Andersen| Complications| EF| 26| 75| 0,3466667|
>
> Krughaug| Complications| EF| 22| 75| 0,2933333|
>
> Moroni| Complications| EF| 0| 20| 0|
>
> Plate| Complications| IMN| 3| 30| 0,1|
>
> Chappuis| Complications| IMN| 4| 16| 0,25|
>
> Gradl| Complications| IMN| 12| 66| 0,1818182|
>
> Schonnemann| Complications| IMN| 6| 31| 0,1935484|
>
> Aita| Complications| IMN| 1| 16| 0,0625|
>
> Dremstrop| Complications| IMN| 17| 44| 0,3863636|
>
> Wong| Complications| PC| 1| 30| 0,0333333|
>
> Kumaravel| Complications| PC| 4| 25| 0,16|
>
>
> Dataset on my dropbox: https://www.dropbox.com/s/j1urqzr99bt76ip/Basics%20excel%20file%20complication%20and%20reoperation%20rate.xlsx?dl=0
>
> Basics excel file complication and reoperation rate.xlsx<https://www.dropbox.com/s/j1urqzr99bt76ip/Basics%20excel%20file%20complication%20and%20reoperation%20rate.xlsx?dl=0>
> www.dropbox.com
> Shared with Dropbox
>
>
>
>
> library(meta)
> library(stargazer)
> library(foreign)
>
> All <-read.spss("C:\\Users\\313635aa.STUDENT\\Desktop\\Meta-Analyse Complications and Reoperations.sav",to.data.frame = T, use.value.labels = T)
> All <- na.omit(All)
>
> Complications <- All[which(All[,"Event_Type"] == "Complications"),]
> Re_operation <- All[which(All[,"Event_Type"] == "Reoperations"),]
>
> EF <- All[which(All[,"Treatment"] == "EF"),]
> IMN <- All[which(All[,"Treatment"] == "IMN"),]
> pc <- All[which(All[,"Treatment"] == "PC"),]
> KW <- All[which(All[,"Treatment"] == "KW"),]
> VPO <- All[which(All[,"Treatment"] == "VPO"),]
>
> EF_C <- EF[which(EF[,"Event_Type"] == "Complications"),]
> EF_R <- EF[which(EF[,"Event_Type"] == "Reoperations"),]
>
> IMN_C <- IMN[which(IMN[,"Event_Type"] == "Complications"),]
> IMN_R <- IMN[which(IMN[,"Event_Type"] == "Reoperations"),]
>
> pc_C <- pc[which(pc[,"Event_Type"] == "Complications"),]
> pc_R <- pc[which(pc[,"Event_Type"] == "Reoperations"),]
>
> KW_C <- KW[which(KW[,"Event_Type"] == "Complications"),]
> KW_R <- KW[which(KW[,"Event_Type"] == "Reoperations"),]
>
> VPO_C <- VPO[which(VPO[,"Event_Type"] == "Complications"),]
> VPO_R <- VPO[which(VPO[,"Event_Type"] == "Reoperations"),]
>
> Output <- function(x, y, k.min=10){
> file <- metaprop(Events_n, N, Study_ID, data = x)
>
> forest.meta(file, studlab = T, pooled.totals = T, bysort = F)
>
> dev.copy2pdf(file=y, width = 11.69, height = 8.27)
> print(file)
> }
>
> R code on my dropbox: https://www.dropbox.com/s/67pnfpi10qu110v/R%20code%20voor%20forrest%20en%20funnel%20plots.rtf?dl=0
>
> [https://cfl.dropboxstatic.com/static/images/icons128/page_white_word.png]<https://www.dropbox.com/s/67pnfpi10qu110v/R%20code%20voor%20forrest%20en%20funnel%20plots.rtf?dl=0>
>
> R code voor forrest en funnel plots.rtf<https://www.dropbox.com/s/67pnfpi10qu110v/R%20code%20voor%20forrest%20en%20funnel%20plots.rtf?dl=0>
> www.dropbox.com
> Shared with Dropbox
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ---
> This email has been checked for viruses by AVG.
> http://www.avg.com
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From will.brannon at gmail.com  Mon Jun 26 21:18:54 2017
From: will.brannon at gmail.com (William Brannon)
Date: Mon, 26 Jun 2017 15:18:54 -0400
Subject: [R] [R-pkgs] Announcing sqlscore
Message-ID: <CAOfWXX7m5-1WPXUzLaMOw8vPMxRfh7MKKm93dysSxNpc8uU30w@mail.gmail.com>

Hi useRs,

I'm happy to announce package sqlscore, which just saw version 0.1.2
released to CRAN. (It was first released earlier this year, but I didn't
notify this list at the time.)

As the DESCRIPTION file puts it, this package "[p]rovides utilities for
generating SQL queries (particularly CREATE TABLE statements) from R model
objects. The most important use case is generating SQL to score a
generalized linear model or related model represented as an R object, in
which case the package handles parsing formula operators and including the
model's response function." It's intended to ease scoring of very large
datasets and those it would be difficult to read into memory.

Cheers
Will

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ruipbarradas at sapo.pt  Wed Jun 28 12:30:27 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 28 Jun 2017 11:30:27 +0100
Subject: [R] Nash equilibrium and other game theory tools implemented in
 networks using igraph or similar
In-Reply-To: <CAD8Oqpvpm0yR=Rqm8xu0QBd_c=U_Wur5w3++azz-NVeFXNNYGQ@mail.gmail.com>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
 <CAPtbhHzYD59jNvLAW=h2kdmF7TTfUXjKucDAZAsMftahDyQJ7A@mail.gmail.com>
 <A60132F1-E086-4EB4-BA3B-24B4BCC7CB72@utoronto.ca>
 <9F3853C8-DBBA-480A-9144-8E21059F746C@dcn.davis.ca.us>
 <37AAFBFC-3CB0-4F39-8AE2-97D388B3C184@utoronto.ca>
 <CAD8Oqpvpm0yR=Rqm8xu0QBd_c=U_Wur5w3++azz-NVeFXNNYGQ@mail.gmail.com>
Message-ID: <59538543.6080303@sapo.pt>

Hello,

So you misunderstood me. I didn't suggest that you should google it, 
what I did was to say that it's what I've done. And found a package. Bad 
luck if that package doesn't do what you want. Hope you find one.

Rui Barradas

Em 28-06-2017 10:53, Chris Buddenhagen escreveu:
> Thanks I too wondered about the tone. The first suggestion was that I
> should "google it" and the second, write my own code. I think if I did I'd
> be reinventing the wheel, (and it'd be a big challenge for me). Also, I
> have been searching and not found such code, despite evidence that it has
> been coded (just not sure if it was in R). BTW I did write to authors of
> the article I cited, but no reply.
>
> Chris Buddenhagen
> cbuddenhagen at gmail.com
>
> On Wed, Jun 28, 2017 at 5:44 AM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
>> I responded to the unhelpful suggestion "Why don't you implement and uplad
>> the package to CRAN?" No  mention of a search engine. Is this what you are
>> commenting on Jeff?
>>
>>
>>
>>
>>
>>> On Jun 28, 2017, at 5:41 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>>
>>> In what way does reminding people that packages exist because others
>> just like them contributed something count as being uncivil? Terse,
>> perhaps, since it bypassed the obvious suggestion to use a search engine,
>> but not rude.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On June 28, 2017 5:08:16 AM EDT, Boris Steipe <boris.steipe at utoronto.ca>
>> wrote:
>>>> I don't think OP asked an unreasonable question at all.
>>>>
>>>> Civility!
>>>>
>>>>
>>>>
>>>>
>>>>> On Jun 27, 2017, at 2:00 PM, Suzen, Mehmet <mehmet.suzen at gmail.com>
>>>> wrote:
>>>>>
>>>>> Why don't you implement and uplad the package to CRAN?
>>>>>
>>>>> On 27 Jun 2017 17:45, "Chris Buddenhagen" <cbuddenhagen at gmail.com>
>>>> wrote:
>>>>>
>>>>> Does anyone know of some code, and examples that implement game
>>>> theory/Nash
>>>>> equilibrium hypothesis testing using existing packages like
>>>> igraph/statnet
>>>>> or similar?
>>>>>
>>>>> Perhaps along the lines of this article:
>>>>>
>>>>> Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014). Local
>>>> Nash
>>>>> Equilibrium in Social Networks, *4*, 6224.
>>>>>
>>>>> Best,
>>>>> Chris Buddenhagen
>>>>> cbuddenhagen at gmail.com
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>      [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nikhil.abhyankar at gmail.com  Wed Jun 28 13:26:33 2017
From: nikhil.abhyankar at gmail.com (Nikhil Abhyankar)
Date: Wed, 28 Jun 2017 16:56:33 +0530
Subject: [R] R package for scorecard development
Message-ID: <CAMivb6p2bf-uEtd9k3YyTLk4H27fqywdcPUGOcXh5syFgEv4Qg@mail.gmail.com>

Hello all,

Is there any R package that can develop a scorecard model for a binary
target variable?

More details:
I want to create a scorecard based on the raw data I have.

I have a binary target variable and a few numeric and character input
variables.

I want to bin the variables and assign a score to each of the bins.

Each subject will be scored based on the bin it falls in for each variable.

All such scores from each of the variables will be added up to get the
final score.

There will be a cutoff score to decide which of the two classes of response
the subject falls into.

I fount and tested the smbinning package. However, it only gives the bins
for a single variable at a time.

How can I get a full scorecard model?

Thanks
Nikhil

	[[alternative HTML version deleted]]


From msuzen at gmail.com  Wed Jun 28 18:36:19 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Wed, 28 Jun 2017 18:36:19 +0200
Subject: [R] Nash equilibrium and other game theory tools implemented in
 networks using igraph or similar
In-Reply-To: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
Message-ID: <CAPtbhHwhTJ_bijTVKST=HhV_THyyJzFSxHa8F1Qqx2016uWONg@mail.gmail.com>

Hello Chris,

I was implying you are capable enough to implement it, while you have
already identify a research paper. If there is no package out there,
uploading to CRAN would help future user too. I am more than happy to
help if you want to implement from scratch.

Best,
Mehmet

On 27 June 2017 at 17:45, Chris Buddenhagen <cbuddenhagen at gmail.com> wrote:
> Does anyone know of some code, and examples that implement game theory/Nash
> equilibrium hypothesis testing using existing packages like igraph/statnet
> or similar?
>
> Perhaps along the lines of this article:
>
> Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014). Local Nash
> Equilibrium in Social Networks, *4*, 6224.
>
> Best,
> Chris Buddenhagen
> cbuddenhagen at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at effectivedefense.org  Wed Jun 28 19:42:29 2017
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Wed, 28 Jun 2017 12:42:29 -0500
Subject: [R] Nash equilibrium and other game theory tools implemented in
 networks using igraph or similar
In-Reply-To: <CAPtbhHwhTJ_bijTVKST=HhV_THyyJzFSxHa8F1Qqx2016uWONg@mail.gmail.com>
References: <CAD8OqpsukOHeUWbiEecAZdFaYOuJ+J29Ww80P-vYjksts=iY2g@mail.gmail.com>
 <CAPtbhHwhTJ_bijTVKST=HhV_THyyJzFSxHa8F1Qqx2016uWONg@mail.gmail.com>
Message-ID: <0be9ecf0-403b-312f-2017-d4a551ffa2fa@effectivedefense.org>



On 2017-06-28 11:36 AM, Suzen, Mehmet wrote:
> Hello Chris,
>
> I was implying you are capable enough to implement it, while you have
> already identify a research paper. If there is no package out there,
> uploading to CRAN would help future user too. I am more than happy to
> help if you want to implement from scratch.


       sos::findFn("nash equilibrium") identified 4 packages: antitrust, 
GNE, GPGame, and nopp.  I found GNE mentioned earlier in this thread but 
not the other three.  Similar searches for "nash equilibrium networ" and 
"nash equilibrium networks" returned no matches.


       By the way, one of the sessions at useR!2017 in Brussels next 
week will discuss "Navigating the R package universe".  This will 
provide a brief overview of tools currently available, followed by a 
general discussion of what people would want in tools to make it easier 
to find and use what you want in contributed packages, now well over 
10,000.  The planned discussion will briefly cover the "sos" package, 
"RDocumentation.org", METACRAN (www.r-pkg.org), "Task views", and other 
tools.


       We're hoping that this session will facilitate the development of 
one or more teams to collaborate on the following:


             * Creating common interfaces for different approaches to 
essentially the same problem, like "optimx".


             * Improving "Task views".


             * Improving search capabilities.


       If you can make it to useR!2017, we hope to see you in this 
session, Wed. July 5, from 17:00 - 18:30 in the main meeting room. If 
you might like to help with this but can't make Brussels, please stay 
tuned for further announcements or contact me after the conference for 
further information.


       Spencer Graves


p.s.  Please excuse if I highjacked this thread to promote this session, 
but I didn't see any mention of the sos package or RDocumentation.org, 
so it seemed appropriate.

> Best,
> Mehmet
>
> On 27 June 2017 at 17:45, Chris Buddenhagen <cbuddenhagen at gmail.com> wrote:
>> Does anyone know of some code, and examples that implement game theory/Nash
>> equilibrium hypothesis testing using existing packages like igraph/statnet
>> or similar?
>>
>> Perhaps along the lines of this article:
>>
>> Zhang, Y., Aziz-Alaoui, M. A., Bertelle, C., & Guan, J. (2014). Local Nash
>> Equilibrium in Social Networks, *4*, 6224.
>>
>> Best,
>> Chris Buddenhagen
>> cbuddenhagen at gmail.com
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwd at surewest.net  Thu Jun 29 01:30:16 2017
From: jwd at surewest.net (John)
Date: Wed, 28 Jun 2017 16:30:16 -0700
Subject: [R] Extraneous full stop in csv read
Message-ID: <20170628163016.0d9f2d8a@Draco.localdomain>

I ran into a puzzling minor behaviour I would like to understand.
Reading in a csv file, I find an extraneous "." after a column header,
"in" [short for "inches"] thus, "in.". Is this due to "in" being
reserved?  I initially blamed this on RStudio or to processing the data
through LibreCalc. However, the same result occurs in a console R
session.  Sending the file to the console via less reveals no strange
characters in the first line.  The data is California statewide
rainfall which was screen captured from the Western Regional Climate
Center web site.

First 15 lines including header line:

"yr","mo","Data","in"
1895,1,8243,8.243
1895,2,2265,2.265
1895,3,2340,2.34
1895,4,1014,1.014
1895,5,1281,1.281
1895,6,58,0.058
1895,7,156,0.156
1895,8,140,0.14
1895,9,1087,1.087
1895,10,322,0.322
1895,11,1331,1.331
1895,12,2428,2.428
1896,1,7156,7.156
1896,2,712,0.712
1896,3,2982,2.982

File read in as follows:

x <- read.csv('DRI-mo-prp.csv', header = T)

Structure:

 str(x)
'data.frame':   1469 obs. of  4 variables:
 $ yr  : int  1895 1895 1895 1895 1895 1895 1895 1895 1895 1895 ...
 $ mo  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ Data: int  8243 2265 2340 1014 1281 58 156 140 1087 322 ...
 $ in. : num  8.24 2.27 2.34 1.01 1.28 ...
[note "in" is now "in."]


From jholtman at gmail.com  Thu Jun 29 02:14:16 2017
From: jholtman at gmail.com (jim holtman)
Date: Wed, 28 Jun 2017 20:14:16 -0400
Subject: [R] Extraneous full stop in csv read
In-Reply-To: <20170628163016.0d9f2d8a@Draco.localdomain>
References: <20170628163016.0d9f2d8a@Draco.localdomain>
Message-ID: <CAAxdm-6BCqmZmH+FxOc-g1r4git3WQh2OOuB8nF1yz_XDYXFgw@mail.gmail.com>

try the 'read_csv' function in the 'readr' package:

> x <- readr::read_csv('"yr","mo","Data","in"
+ 1895,1,8243,8.243
+ 1895,2,2265,2.265
+ 1895,3,2340,2.34
+ 1895,4,1014,1.014
+ 1895,5,1281,1.281
+ 1895,6,58,0.058
+ 1895,7,156,0.156
+ 1895,8,140,0.14
+ 1895,9,1087,1.087
+ 1895,10,322,0.322
+ 1895,11,1331,1.331
+ 1895,12,2428,2.428
+ 1896,1,7156,7.156
+ 1896,2,712,0.712
+ 1896,3,2982,2.982
+ ')
> str(x)
Classes ?tbl_df?, ?tbl? and 'data.frame': 15 obs. of  4 variables:
 $ yr  : int  1895 1895 1895 1895 1895 1895 1895 1895 1895 1895 ...
 $ mo  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ Data: int  8243 2265 2340 1014 1281 58 156 140 1087 322 ...
 $ in  : num  8.24 2.27 2.34 1.01 1.28 ...


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Jun 28, 2017 at 7:30 PM, John <jwd at surewest.net> wrote:

> I ran into a puzzling minor behaviour I would like to understand.
> Reading in a csv file, I find an extraneous "." after a column header,
> "in" [short for "inches"] thus, "in.". Is this due to "in" being
> reserved?  I initially blamed this on RStudio or to processing the data
> through LibreCalc. However, the same result occurs in a console R
> session.  Sending the file to the console via less reveals no strange
> characters in the first line.  The data is California statewide
> rainfall which was screen captured from the Western Regional Climate
> Center web site.
>
> First 15 lines including header line:
>
> "yr","mo","Data","in"
> 1895,1,8243,8.243
> 1895,2,2265,2.265
> 1895,3,2340,2.34
> 1895,4,1014,1.014
> 1895,5,1281,1.281
> 1895,6,58,0.058
> 1895,7,156,0.156
> 1895,8,140,0.14
> 1895,9,1087,1.087
> 1895,10,322,0.322
> 1895,11,1331,1.331
> 1895,12,2428,2.428
> 1896,1,7156,7.156
> 1896,2,712,0.712
> 1896,3,2982,2.982
>
> File read in as follows:
>
> x <- read.csv('DRI-mo-prp.csv', header = T)
>
> Structure:
>
>  str(x)
> 'data.frame':   1469 obs. of  4 variables:
>  $ yr  : int  1895 1895 1895 1895 1895 1895 1895 1895 1895 1895 ...
>  $ mo  : int  1 2 3 4 5 6 7 8 9 10 ...
>  $ Data: int  8243 2265 2340 1014 1281 58 156 140 1087 322 ...
>  $ in. : num  8.24 2.27 2.34 1.01 1.28 ...
> [note "in" is now "in."]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Thu Jun 29 02:15:49 2017
From: jholtman at gmail.com (jim holtman)
Date: Wed, 28 Jun 2017 20:15:49 -0400
Subject: [R] Extraneous full stop in csv read
In-Reply-To: <20170628163016.0d9f2d8a@Draco.localdomain>
References: <20170628163016.0d9f2d8a@Draco.localdomain>
Message-ID: <CAAxdm-6ei2G_apcpRqxK5WjuNtXjM5FJs5saDT7Jsgyw5oKX4w@mail.gmail.com>

or use the 'check.names = FALSE':

> x <- read.csv(text = '"yr","mo","Data","in"
+ 1895,1,8243,8.243
+ 1895,2,2265,2.265
+ 1895,3,2340,2.34
+ 1895,4,1014,1.014
+ 1895,5,1281,1.281
+ 1895,6,58,0.058
+ 1895,7,156,0.156
+ 1895,8,140,0.14
+ 1895,9,1087,1.087
+ 1895,10,322,0.322
+ 1895,11,1331,1.331
+ 1895,12,2428,2.428
+ 1896,1,7156,7.156
+ 1896,2,712,0.712
+ 1896,3,2982,2.982
+ ', check.names = FALSE)
> str(x)
'data.frame': 15 obs. of  4 variables:
 $ yr  : int  1895 1895 1895 1895 1895 1895 1895 1895 1895 1895 ...
 $ mo  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ Data: int  8243 2265 2340 1014 1281 58 156 140 1087 322 ...
 $ in  : num  8.24 2.27 2.34 1.01 1.28 ...


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Jun 28, 2017 at 7:30 PM, John <jwd at surewest.net> wrote:

> I ran into a puzzling minor behaviour I would like to understand.
> Reading in a csv file, I find an extraneous "." after a column header,
> "in" [short for "inches"] thus, "in.". Is this due to "in" being
> reserved?  I initially blamed this on RStudio or to processing the data
> through LibreCalc. However, the same result occurs in a console R
> session.  Sending the file to the console via less reveals no strange
> characters in the first line.  The data is California statewide
> rainfall which was screen captured from the Western Regional Climate
> Center web site.
>
> First 15 lines including header line:
>
> "yr","mo","Data","in"
> 1895,1,8243,8.243
> 1895,2,2265,2.265
> 1895,3,2340,2.34
> 1895,4,1014,1.014
> 1895,5,1281,1.281
> 1895,6,58,0.058
> 1895,7,156,0.156
> 1895,8,140,0.14
> 1895,9,1087,1.087
> 1895,10,322,0.322
> 1895,11,1331,1.331
> 1895,12,2428,2.428
> 1896,1,7156,7.156
> 1896,2,712,0.712
> 1896,3,2982,2.982
>
> File read in as follows:
>
> x <- read.csv('DRI-mo-prp.csv', header = T)
>
> Structure:
>
>  str(x)
> 'data.frame':   1469 obs. of  4 variables:
>  $ yr  : int  1895 1895 1895 1895 1895 1895 1895 1895 1895 1895 ...
>  $ mo  : int  1 2 3 4 5 6 7 8 9 10 ...
>  $ Data: int  8243 2265 2340 1014 1281 58 156 140 1087 322 ...
>  $ in. : num  8.24 2.27 2.34 1.01 1.28 ...
> [note "in" is now "in."]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Jun 29 02:27:06 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 28 Jun 2017 17:27:06 -0700
Subject: [R] Extraneous full stop in csv read
In-Reply-To: <20170628163016.0d9f2d8a@Draco.localdomain>
References: <20170628163016.0d9f2d8a@Draco.localdomain>
Message-ID: <90F04294-CCA6-4F49-84D4-B0D279ADC33F@comcast.net>


> On Jun 28, 2017, at 4:30 PM, John <jwd at surewest.net> wrote:
> 
> I ran into a puzzling minor behaviour I would like to understand.
> Reading in a csv file, I find an extraneous "." after a column header,
> "in" [short for "inches"] thus, "in.". Is this due to "in" being
> reserved?  I initially blamed this on RStudio or to processing the data
> through LibreCalc. However, the same result occurs in a console R
> session.  Sending the file to the console via less reveals no strange
> characters in the first line.  The data is California statewide
> rainfall which was screen captured from the Western Regional Climate
> Center web site.
> 
> First 15 lines including header line:
> 
> "yr","mo","Data","in"
> 1895,1,8243,8.243
> 1895,2,2265,2.265
> 1895,3,2340,2.34
> 1895,4,1014,1.014
> 1895,5,1281,1.281
> 1895,6,58,0.058
> 1895,7,156,0.156
> 1895,8,140,0.14
> 1895,9,1087,1.087
> 1895,10,322,0.322
> 1895,11,1331,1.331
> 1895,12,2428,2.428
> 1896,1,7156,7.156
> 1896,2,712,0.712
> 1896,3,2982,2.982
> 
> File read in as follows:
> 
> x <- read.csv('DRI-mo-prp.csv', header = T)

If I change one of those other headers to "for", I also see the period-suffix appended, which supports your theory about reserved words being protected. If for some reason this were important to you, hten I'd suggest first looking at the code for make.names which in turn indicates that it's done with a .Internal call, so you'll need to look at the source code for the base-package.
-- 
David.
> 
> Structure:
> 
> str(x)
> 'data.frame':   1469 obs. of  4 variables:
> $ yr  : int  1895 1895 1895 1895 1895 1895 1895 1895 1895 1895 ...
> $ mo  : int  1 2 3 4 5 6 7 8 9 10 ...
> $ Data: int  8243 2265 2340 1014 1281 58 156 140 1087 322 ...
> $ in. : num  8.24 2.27 2.34 1.01 1.28 ...
> [note "in" is now "in."]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From farnoosh_81 at yahoo.com  Wed Jun 28 21:20:43 2017
From: farnoosh_81 at yahoo.com (Farnoosh Sheikhi)
Date: Wed, 28 Jun 2017 19:20:43 +0000 (UTC)
Subject: [R] Different date formats in one column
References: <1220786224.636968.1498677643237.ref@mail.yahoo.com>
Message-ID: <1220786224.636968.1498677643237@mail.yahoo.com>

Hi,?
I have a data set with various date formats in one column and not sure how to unify it.Here is a few formats:
02091702/22/170221201703/17/160015-08-239/2/1500170806May-2-201522-March-2014
I tried parse_date_time from lubridate library but it failed.Thanks so much.?Best,Farnoosh


	[[alternative HTML version deleted]]


From lsantoshksingh at gmail.com  Wed Jun 28 22:36:24 2017
From: lsantoshksingh at gmail.com (Santosh Kumar)
Date: Thu, 29 Jun 2017 02:06:24 +0530
Subject: [R] help needed for RInside with Qt
Message-ID: <CAB8DgdKXMui236e7kwWMcCF26ZU4AmxSHKL2E9txLaUPdiJSdw@mail.gmail.com>

Hello,

I am developing an application using Qt framework and C++. I want to use R
as statistics engine of my application. After doing some search on
internet; I came to the conclusion that RCPP, MPI with RInside is what I
need. The next logical task was to quickly tryout "qtdensity" project of
RInside, for understanding the build and other settings. I hit some
roadblock here and got little confused. I have following quaries:

1. I am using Qt  5.8 MSVC and would like to distribute both 64 bit as well
as 32 bit application.
2. Can I use binary distribution provided on CRAN with this version of Qt?
3. If not then; do I need to build R myself with MinGW and Qt too with the
same version of MinGW?
4. regarding make file modifications how should I set R_HOME env. variable?
Currently my R is installed in "C:\Program Files\R\R-3.4.0" If I set env
variable R_HOME = "C:\Program Files\R\R-3.4.0"....I get QMake error: The
system cannot find the path specified.

Any help will be much appreciated.

Thanks,
Santosh

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Jun 29 06:32:40 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 28 Jun 2017 21:32:40 -0700
Subject: [R] help needed for RInside with Qt
In-Reply-To: <CAB8DgdKXMui236e7kwWMcCF26ZU4AmxSHKL2E9txLaUPdiJSdw@mail.gmail.com>
References: <CAB8DgdKXMui236e7kwWMcCF26ZU4AmxSHKL2E9txLaUPdiJSdw@mail.gmail.com>
Message-ID: <CAGxFJbTviphbXc8JEeNaL0Km8=4+n5wRubdT3dCgdCvJSv6rpA@mail.gmail.com>

Is this application meant to be commercial? If so, R's open source
license probably would forbid you to use it. I defer to those with
real legal knowledge on this point, but you should check it. If it is
not meant to be commercial, then ignore -- I have nothing useful to
offer you.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 28, 2017 at 1:36 PM, Santosh Kumar <lsantoshksingh at gmail.com> wrote:
> Hello,
>
> I am developing an application using Qt framework and C++. I want to use R
> as statistics engine of my application. After doing some search on
> internet; I came to the conclusion that RCPP, MPI with RInside is what I
> need. The next logical task was to quickly tryout "qtdensity" project of
> RInside, for understanding the build and other settings. I hit some
> roadblock here and got little confused. I have following quaries:
>
> 1. I am using Qt  5.8 MSVC and would like to distribute both 64 bit as well
> as 32 bit application.
> 2. Can I use binary distribution provided on CRAN with this version of Qt?
> 3. If not then; do I need to build R myself with MinGW and Qt too with the
> same version of MinGW?
> 4. regarding make file modifications how should I set R_HOME env. variable?
> Currently my R is installed in "C:\Program Files\R\R-3.4.0" If I set env
> variable R_HOME = "C:\Program Files\R\R-3.4.0"....I get QMake error: The
> system cannot find the path specified.
>
> Any help will be much appreciated.
>
> Thanks,
> Santosh
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Jun 29 06:52:13 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 29 Jun 2017 00:52:13 -0400
Subject: [R] help needed for RInside with Qt
In-Reply-To: <CAGxFJbTviphbXc8JEeNaL0Km8=4+n5wRubdT3dCgdCvJSv6rpA@mail.gmail.com>
References: <CAB8DgdKXMui236e7kwWMcCF26ZU4AmxSHKL2E9txLaUPdiJSdw@mail.gmail.com>
 <CAGxFJbTviphbXc8JEeNaL0Km8=4+n5wRubdT3dCgdCvJSv6rpA@mail.gmail.com>
Message-ID: <DCD1C48D-10CB-466A-988B-0007B472C48B@dcn.davis.ca.us>

If you adhere to the terms of the license for R you should be okay legally. If you use contributed packages they may have additional requirements. However, these terms are often overlooked by programmers targeting Windows, hence Bert's caution. 

As to the content of the original post itself, it is off-topic for this list... it belongs in R-devel (but you may need to study the Posting Guide more thoroughly (use plain text at least) and clearly communicate your licensing intentions to elicit help there. You probably also ought to carefully read the R Installation and Administration Manual and indicate why that document did not answer your questions.
-- 
Sent from my phone. Please excuse my brevity.

On June 29, 2017 12:32:40 AM EDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Is this application meant to be commercial? If so, R's open source
>license probably would forbid you to use it. I defer to those with
>real legal knowledge on this point, but you should check it. If it is
>not meant to be commercial, then ignore -- I have nothing useful to
>offer you.
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Wed, Jun 28, 2017 at 1:36 PM, Santosh Kumar
><lsantoshksingh at gmail.com> wrote:
>> Hello,
>>
>> I am developing an application using Qt framework and C++. I want to
>use R
>> as statistics engine of my application. After doing some search on
>> internet; I came to the conclusion that RCPP, MPI with RInside is
>what I
>> need. The next logical task was to quickly tryout "qtdensity" project
>of
>> RInside, for understanding the build and other settings. I hit some
>> roadblock here and got little confused. I have following quaries:
>>
>> 1. I am using Qt  5.8 MSVC and would like to distribute both 64 bit
>as well
>> as 32 bit application.
>> 2. Can I use binary distribution provided on CRAN with this version
>of Qt?
>> 3. If not then; do I need to build R myself with MinGW and Qt too
>with the
>> same version of MinGW?
>> 4. regarding make file modifications how should I set R_HOME env.
>variable?
>> Currently my R is installed in "C:\Program Files\R\R-3.4.0" If I set
>env
>> variable R_HOME = "C:\Program Files\R\R-3.4.0"....I get QMake error:
>The
>> system cannot find the path specified.
>>
>> Any help will be much appreciated.
>>
>> Thanks,
>> Santosh
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Jun 29 07:51:18 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 28 Jun 2017 22:51:18 -0700 (PDT)
Subject: [R] Different date formats in one column
In-Reply-To: <1220786224.636968.1498677643237@mail.yahoo.com>
References: <1220786224.636968.1498677643237.ref@mail.yahoo.com>
 <1220786224.636968.1498677643237@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1706282246450.76660@pedal.dcn.davis.ca.us>

I doubt your actual file looks like the mess that made it to my email 
software (below) because you posted HTML-format email. Read the Posting 
Guide, and in particular figure out how to send plain text email.

You might try the "anytime" contributed package, though I suspect it too 
will choke on your mess. Otherwise, that will pretty much leave only a 
brute-force series of regular expression tests to recognize which date 
format patterns you have, and even that may not be able to get them all 
right unless you know something that limits the range of possible formats.

Below is an example of how this can be done. There are many tutorials on 
the internet that describe regular expressions... they are not unique to 
R.

#-----
dta <- read.table( text=
"DtStr
020917
2/22/17
May-2-2015
May-12-15
", header=TRUE, as.is=TRUE )

dta$Dt <- as.Date( NA )

idx <- grepl( 
"^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)-[0-9]+-[0-9]{4}$", 
dta$DtStr, perl=TRUE, ignore.case = TRUE )
dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%B-%d-%Y" )

idx <- grepl( 
"^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)-[0-9]+-[0-9]{2}$", 
dta$DtStr, perl=TRUE, ignore.case = TRUE )
dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%B-%d-%y" )

idx <- grepl( "^(0[1-9]|1[0-2])[0-9]{2}[0-9]{2}$", dta$DtStr, perl=TRUE )
dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%m%d%y" )

idx <- grepl( "^([1-9]|1[0-2])/[0-9]{1,2}/[0-9]{2}$", dta$DtStr, perl=TRUE 
)
dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%m/%d/%y" )


On Wed, 28 Jun 2017, Farnoosh Sheikhi via R-help wrote:

> Hi,?
> I have a data set with various date formats in one column and not sure how to unify it.Here is a few formats:
> 02091702/22/170221201703/17/160015-08-239/2/1500170806May-2-201522-March-2014
> I tried parse_date_time from lubridate library but it failed.Thanks so much.?Best,Farnoosh
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From msuzen at gmail.com  Wed Jun 28 18:40:16 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Wed, 28 Jun 2017 18:40:16 +0200
Subject: [R] R package for scorecard development
In-Reply-To: <CAMivb6p2bf-uEtd9k3YyTLk4H27fqywdcPUGOcXh5syFgEv4Qg@mail.gmail.com>
References: <CAMivb6p2bf-uEtd9k3YyTLk4H27fqywdcPUGOcXh5syFgEv4Qg@mail.gmail.com>
Message-ID: <CAPtbhHzBGJ1dcSroyQXHO6WUbWXiZ3AnexbPOgCSeVR8P3ZgKA@mail.gmail.com>

I suggest you to have a look at this R document:
https://cran.r-project.org/doc/contrib/Sharma-CreditScoring.pdf

On 28 June 2017 at 13:26, Nikhil Abhyankar <nikhil.abhyankar at gmail.com> wrote:
> Hello all,
>
> Is there any R package that can develop a scorecard model for a binary
> target variable?
>
> More details:
> I want to create a scorecard based on the raw data I have.
>
> I have a binary target variable and a few numeric and character input
> variables.
>
> I want to bin the variables and assign a score to each of the bins.
>
> Each subject will be scored based on the bin it falls in for each variable.
>
> All such scores from each of the variables will be added up to get the
> final score.
>
> There will be a cutoff score to decide which of the two classes of response
> the subject falls into.
>
> I fount and tested the smbinning package. However, it only gives the bins
> for a single variable at a time.
>
> How can I get a full scorecard model?
>
> Thanks
> Nikhil
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From profjcnash at gmail.com  Thu Jun 29 10:29:39 2017
From: profjcnash at gmail.com (ProfJCNash)
Date: Thu, 29 Jun 2017 04:29:39 -0400
Subject: [R] Finding optim.R function
In-Reply-To: <BLUPR01MB291A8E36C162CC7CEB333AC93DC0@BLUPR01MB291.prod.exchangelabs.com>
References: <BLUPR01MB291A8E36C162CC7CEB333AC93DC0@BLUPR01MB291.prod.exchangelabs.com>
Message-ID: <bbbea89b-8faf-3832-4cd3-41b7b3cebeb4@gmail.com>

The codes were taken from the 2nd edition of my book Compact Numerical
Methods for Computers, where they are in Pascal. They were converted by
p2c to c, so are pretty opaque and likely difficult to modify. Moreover,
they are based on 1970s codes I wrote for the first edition. Why not
look at optimr (CRAN) or the more extensive optimrx (R-forge) where
there are calls to pure R versions with improvements in the codes as
well as bounds constraints on parameters for some. If you have
suggestions or queries about the newer codes, contact me off-list and
we'll see what can be done.

JN (who will be at UseR! next week)


On 2017-06-27 12:46 PM, Tauras Vilgalys wrote:
> Hello, could anybody direct me where to find code for optim.R? I was able to find the C code at http://docs.rexamine.com/R-devel/optim_8c.html, but the R version would be easier for me to work with and modify.
> 
> 
> Thank you!
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From benoit.pele at acoss.fr  Thu Jun 29 11:13:48 2017
From: benoit.pele at acoss.fr (=?ISO-8859-1?Q?Beno=EEt_PELE?=)
Date: Thu, 29 Jun 2017 11:13:48 +0200
Subject: [R] Help : glm p-values for a factor predictor
Message-ID: <OF989B886C.250B1E03-ONC125814E.0032A301-C125814E.0032B428@urssaf.fr>

Hello, 

i am a newby on R and i am trying to make a backward selection on a 
binomial-logit glm on a large dataset (69000 lines for 145 predictors). 

After 3 days working, the stepAIC function did not terminate. I do not 
know if that is normal but i would like to try computing a "homemade" 
backward with a repeated glm ; at each step, the predictor with the max 
pvalue would be excluded until reaching a set of 20 predictors for 
example. 

My question is about the factor predictors with several levels. R provides 
only the pvalues for each level whereas i need an overall pvalue for 
testing the predictor. 

On internet, the only solution i found suggests to compute a Khi2 
log-likelihood test between the complete model and the model without the 
factor predictor to emphasize its relevance. 

Do you know other ways? Another R package managing this kind of issue? 

Thank you and best regards, Benoit. 
	[[alternative HTML version deleted]]


From rni.boh at gmail.com  Thu Jun 29 11:46:19 2017
From: rni.boh at gmail.com (Bob O'Hara)
Date: Thu, 29 Jun 2017 11:46:19 +0200
Subject: [R] Help : glm p-values for a factor predictor
In-Reply-To: <OF989B886C.250B1E03-ONC125814E.0032A301-C125814E.0032B428@urssaf.fr>
References: <OF989B886C.250B1E03-ONC125814E.0032A301-C125814E.0032B428@urssaf.fr>
Message-ID: <CAN-Z0xXXkecpyQm_03qc=HQRt3wmbUjSBxk7G+cmNc6ps9AFOw@mail.gmail.com>

It might help if you provided the code you used. It's possible that
you didn't use direction="backward" in stepAIC(). Or if you did, it
was still running, so whatever else you try will still be slow. The
statement "R provides only the pvalues for each level" is wrong: look
at the anova() function.

Bob

On 29 June 2017 at 11:13, Beno?t PELE <benoit.pele at acoss.fr> wrote:
> Hello,
>
> i am a newby on R and i am trying to make a backward selection on a
> binomial-logit glm on a large dataset (69000 lines for 145 predictors).
>
> After 3 days working, the stepAIC function did not terminate. I do not
> know if that is normal but i would like to try computing a "homemade"
> backward with a repeated glm ; at each step, the predictor with the max
> pvalue would be excluded until reaching a set of 20 predictors for
> example.
>
> My question is about the factor predictors with several levels. R provides
> only the pvalues for each level whereas i need an overall pvalue for
> testing the predictor.
>
> On internet, the only solution i found suggests to compute a Khi2
> log-likelihood test between the complete model and the model without the
> factor predictor to emphasize its relevance.
>
> Do you know other ways? Another R package managing this kind of issue?
>
> Thank you and best regards, Benoit.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bob O'Hara
NOTE NEW ADDRESS!!!
Institutt for matematiske fag
NTNU
7491 Trondheim
Norway

Mobile: +49 1515 888 5440
Journal of Negative Results - EEB: www.jnr-eeb.org


From Marios.BARLAS at cea.fr  Thu Jun 29 11:46:43 2017
From: Marios.BARLAS at cea.fr (BARLAS Marios 247554)
Date: Thu, 29 Jun 2017 09:46:43 +0000
Subject: [R] Changing ggplot2 legend key/title to custom text
Message-ID: <01BFC0B2B4ABFC4CB432008F852D7661025BE431@EXDAG0-A1.intra.cea.fr>

Hi all, 

ok I have this issue: 

I want to change my graphs legends to custom text, often requiring the use of superscripts/subscripts
I tried to use this instruction I found on stack overflow: 

labs(x = "R(Ohm)", y= "CDF", aesthetic= " Content (%)" )

but it wont' seem to work. 

Also tried bquote for super/ subscripts 

xlab(bquote(~x~/(~x~ + ~MO[2]~)* '(%)'))

but I get an error that the / operator is not recognized. 

Any ideas on how I can solve these issues ? 

Thanks in advance,
Marios Barlas


From petr.pikal at precheza.cz  Thu Jun 29 13:07:39 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 29 Jun 2017 11:07:39 +0000
Subject: [R] Changing ggplot2 legend key/title to custom text
In-Reply-To: <01BFC0B2B4ABFC4CB432008F852D7661025BE431@EXDAG0-A1.intra.cea.fr>
References: <01BFC0B2B4ABFC4CB432008F852D7661025BE431@EXDAG0-A1.intra.cea.fr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A9B7E@SRVEXCHCM301.precheza.cz>

Hi

There are plenty of examples
https://stackoverflow.com/questions/6202667/how-to-use-subscripts-in-ggplot2-legends-r
https://stackoverflow.com/questions/19507742/using-expressionpaste-to-insert-math-notation-into-a-ggplot-legend

which you can modify.

If you say

"but it wont' seem to work"

how can we know what does it mean?

Plotmath expressions are rather tricky, especially if you do not use them often. You need some experimenting.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BARLAS
> Marios 247554
> Sent: Thursday, June 29, 2017 11:47 AM
> To: r-help at r-project.org
> Subject: [R] Changing ggplot2 legend key/title to custom text
>
> Hi all,
>
> ok I have this issue:
>
> I want to change my graphs legends to custom text, often requiring the use of
> superscripts/subscripts I tried to use this instruction I found on stack overflow:
>
> labs(x = "R(Ohm)", y= "CDF", aesthetic= " Content (%)" )
>
> but it wont' seem to work.
>
> Also tried bquote for super/ subscripts
>
> xlab(bquote(~x~/(~x~ + ~MO[2]~)* '(%)'))
>
> but I get an error that the / operator is not recognized.
>
> Any ideas on how I can solve these issues ?
>
> Thanks in advance,
> Marios Barlas
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From murdoch.duncan at gmail.com  Thu Jun 29 13:27:38 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 29 Jun 2017 07:27:38 -0400
Subject: [R] Extraneous full stop in csv read
In-Reply-To: <20170628163016.0d9f2d8a@Draco.localdomain>
References: <20170628163016.0d9f2d8a@Draco.localdomain>
Message-ID: <4c38f2a6-0bb7-9b89-b6f6-8051ff542db2@gmail.com>

On 28/06/2017 7:30 PM, John wrote:
> I ran into a puzzling minor behaviour I would like to understand.
> Reading in a csv file, I find an extraneous "." after a column header,
> "in" [short for "inches"] thus, "in.". Is this due to "in" being
> reserved?  I initially blamed this on RStudio or to processing the data
> through LibreCalc. However, the same result occurs in a console R
> session.  Sending the file to the console via less reveals no strange
> characters in the first line.  The data is California statewide
> rainfall which was screen captured from the Western Regional Climate
> Center web site.
>
> First 15 lines including header line:
>
> "yr","mo","Data","in"
> 1895,1,8243,8.243
> 1895,2,2265,2.265
> 1895,3,2340,2.34
> 1895,4,1014,1.014
> 1895,5,1281,1.281
> 1895,6,58,0.058
> 1895,7,156,0.156
> 1895,8,140,0.14
> 1895,9,1087,1.087
> 1895,10,322,0.322
> 1895,11,1331,1.331
> 1895,12,2428,2.428
> 1896,1,7156,7.156
> 1896,2,712,0.712
> 1896,3,2982,2.982
>
> File read in as follows:
>
> x <- read.csv('DRI-mo-prp.csv', header = T)
>
> Structure:
>
>  str(x)
> 'data.frame':   1469 obs. of  4 variables:
>  $ yr  : int  1895 1895 1895 1895 1895 1895 1895 1895 1895 1895 ...
>  $ mo  : int  1 2 3 4 5 6 7 8 9 10 ...
>  $ Data: int  8243 2265 2340 1014 1281 58 156 140 1087 322 ...
>  $ in. : num  8.24 2.27 2.34 1.01 1.28 ...
> [note "in" is now "in."]

Yes, "in" is not a valid variable name, because of its syntactic use. 
You can stop this correction by setting check.names=FALSE in your call 
to read.csv.  This will make it a little tricky to deal with in some 
situations, e.g.

 > x <- data.frame(4)
 > names(x) <- "in"
 > x
   in
1  4
 > x$in
Error: unexpected 'in' in "x$in"

but you can work around this problem: x[, "in"] and x$`in` are both fine.

Duncan Murdoch


From Marios.BARLAS at cea.fr  Thu Jun 29 13:28:01 2017
From: Marios.BARLAS at cea.fr (BARLAS Marios 247554)
Date: Thu, 29 Jun 2017 11:28:01 +0000
Subject: [R] Changing ggplot2 legend key/title to custom text
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A9B7E@SRVEXCHCM301.precheza.cz>
References: <01BFC0B2B4ABFC4CB432008F852D7661025BE431@EXDAG0-A1.intra.cea.fr>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A9B7E@SRVEXCHCM301.precheza.cz>
Message-ID: <01BFC0B2B4ABFC4CB432008F852D7661025BE463@EXDAG0-A1.intra.cea.fr>

Hi Petr and thanks for your reply,

That's the problem I don't want to modify the labels of my legends but the title of the legend in itself inserting my custom text :) 

Take for example the 1st graph in this tutorial
http://www.sthda.com/english/wiki/ggpubr-r-package-ggplot2-based-publication-ready-plots
I want to change the "sex" in "sex subscript 2" or " (sex/sex[2]+Q)

Thanks again,

Marios Barlas
PhD Candidate
CMOS & Memory Integration
Advanced Memory Group

Leti, technology research institute 
Commissariat ? l??nergie atomique et aux ?nergies alternatives
T. +33 4 38 78 11 50 M. +33 6 02 61 83 49
www.leti.fr  | Leti is a member of the Carnot Institutes network
 
-----Message d'origine-----
De?: PIKAL Petr [mailto:petr.pikal at precheza.cz] 
Envoy??: jeudi 29 juin 2017 13:08
??: BARLAS Marios 247554 <Marios.BARLAS at cea.fr>; r-help at r-project.org
Objet?: RE: Changing ggplot2 legend key/title to custom text

Hi

There are plenty of examples
https://stackoverflow.com/questions/6202667/how-to-use-subscripts-in-ggplot2-legends-r
https://stackoverflow.com/questions/19507742/using-expressionpaste-to-insert-math-notation-into-a-ggplot-legend

which you can modify.

If you say

"but it wont' seem to work"

how can we know what does it mean?

Plotmath expressions are rather tricky, especially if you do not use them often. You need some experimenting.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BARLAS 
> Marios 247554
> Sent: Thursday, June 29, 2017 11:47 AM
> To: r-help at r-project.org
> Subject: [R] Changing ggplot2 legend key/title to custom text
>
> Hi all,
>
> ok I have this issue:
>
> I want to change my graphs legends to custom text, often requiring the 
> use of superscripts/subscripts I tried to use this instruction I found on stack overflow:
>
> labs(x = "R(Ohm)", y= "CDF", aesthetic= " Content (%)" )
>
> but it wont' seem to work.
>
> Also tried bquote for super/ subscripts
>
> xlab(bquote(~x~/(~x~ + ~MO[2]~)* '(%)'))
>
> but I get an error that the / operator is not recognized.
>
> Any ideas on how I can solve these issues ?
>
> Thanks in advance,
> Marios Barlas
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Jun 29 14:00:19 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 29 Jun 2017 12:00:19 +0000
Subject: [R] Changing ggplot2 legend key/title to custom text
In-Reply-To: <01BFC0B2B4ABFC4CB432008F852D7661025BE463@EXDAG0-A1.intra.cea.fr>
References: <01BFC0B2B4ABFC4CB432008F852D7661025BE431@EXDAG0-A1.intra.cea.fr>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A9B7E@SRVEXCHCM301.precheza.cz>
 <01BFC0B2B4ABFC4CB432008F852D7661025BE463@EXDAG0-A1.intra.cea.fr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF9A9C0A@SRVEXCHCM301.precheza.cz>

Hi

I usually use google. It is quite powerful.

Search
ggplot legend title

results in
http://www.cookbook-r.com/Graphs/Legends_(ggplot2)/

from which you could find a way how to modify legend.

library(ggplot2)
bp <- ggplot(data=PlantGrowth, aes(x=group, y=weight, fill=group)) + geom_boxplot()
bp
bp + scale_fill_discrete(name="Experimental\nCondition",
                          breaks=c("ctrl", "trt1", "trt2"),
                          labels=c("Control", "Treatment 1", "Treatment 2"))


For plotmath (subscripts, ...) see

?plotmath

e.g.

plot(1,1, main=expression("sex"[2]), sub=expression("sex"^"2"))
text(1,.8,expression(over("sex", "sex"[2])))

Cheers
Petr

> -----Original Message-----
> From: BARLAS Marios 247554 [mailto:Marios.BARLAS at cea.fr]
> Sent: Thursday, June 29, 2017 1:28 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: RE: Changing ggplot2 legend key/title to custom text
>
> Hi Petr and thanks for your reply,
>
> That's the problem I don't want to modify the labels of my legends but the title
> of the legend in itself inserting my custom text :)
>
> Take for example the 1st graph in this tutorial
> http://www.sthda.com/english/wiki/ggpubr-r-package-ggplot2-based-
> publication-ready-plots
> I want to change the "sex" in "sex subscript 2" or " (sex/sex[2]+Q)
>
> Thanks again,
>
> Marios Barlas
> PhD Candidate
> CMOS & Memory Integration
> Advanced Memory Group
>
> Leti, technology research institute
> Commissariat ? l??nergie atomique et aux ?nergies alternatives T. +33 4 38 78
> 11 50 M. +33 6 02 61 83 49 www.leti.fr  | Leti is a member of the Carnot
> Institutes network
>
> -----Message d'origine-----
> De : PIKAL Petr [mailto:petr.pikal at precheza.cz] Envoy? : jeudi 29 juin 2017
> 13:08 ? : BARLAS Marios 247554 <Marios.BARLAS at cea.fr>; r-help at r-
> project.org Objet : RE: Changing ggplot2 legend key/title to custom text
>
> Hi
>
> There are plenty of examples
> https://stackoverflow.com/questions/6202667/how-to-use-subscripts-in-
> ggplot2-legends-r
> https://stackoverflow.com/questions/19507742/using-expressionpaste-to-
> insert-math-notation-into-a-ggplot-legend
>
> which you can modify.
>
> If you say
>
> "but it wont' seem to work"
>
> how can we know what does it mean?
>
> Plotmath expressions are rather tricky, especially if you do not use them often.
> You need some experimenting.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BARLAS
> > Marios 247554
> > Sent: Thursday, June 29, 2017 11:47 AM
> > To: r-help at r-project.org
> > Subject: [R] Changing ggplot2 legend key/title to custom text
> >
> > Hi all,
> >
> > ok I have this issue:
> >
> > I want to change my graphs legends to custom text, often requiring the
> > use of superscripts/subscripts I tried to use this instruction I found on stack
> overflow:
> >
> > labs(x = "R(Ohm)", y= "CDF", aesthetic= " Content (%)" )
> >
> > but it wont' seem to work.
> >
> > Also tried bquote for super/ subscripts
> >
> > xlab(bquote(~x~/(~x~ + ~MO[2]~)* '(%)'))
> >
> > but I get an error that the / operator is not recognized.
> >
> > Any ideas on how I can solve these issues ?
> >
> > Thanks in advance,
> > Marios Barlas
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen?
> jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze
> sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i
> zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to
> z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s
> dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost
> ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo
> p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender.
> Delete the contents of this e-mail with all attachments and its copies from your
> system.
> If you are not the intended recipient of this e-mail, you are not authorized to
> use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by
> modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept
> such offer; The sender of this e-mail (offer) excludes any acceptance of the
> offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an
> express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into
> any contracts on behalf of the company except for cases in which he/she is
> expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of the
> person represented by the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From benoit.pele at acoss.fr  Thu Jun 29 15:00:18 2017
From: benoit.pele at acoss.fr (=?ISO-8859-1?Q?Beno=EEt_PELE?=)
Date: Thu, 29 Jun 2017 15:00:18 +0200
Subject: [R] Help : glm p-values for a factor predictor
In-Reply-To: <CAN-Z0xXXkecpyQm_03qc=HQRt3wmbUjSBxk7G+cmNc6ps9AFOw@mail.gmail.com>
References: <OF989B886C.250B1E03-ONC125814E.0032A301-C125814E.0032B428@urssaf.fr>
 <CAN-Z0xXXkecpyQm_03qc=HQRt3wmbUjSBxk7G+cmNc6ps9AFOw@mail.gmail.com>
Message-ID: <OFE8A5D7A8.BEB83148-ONC125814E.0046DF51-C125814E.004770FF@urssaf.fr>

Thank you for your answer.

The used code is the next one :

champ_model<-c("y","categ_juridique","Indic_CTRLAUTRE_RPOS","Indic_CTRLAUTRE_RNEG","Indic_CTRLCCA_RPOS",
 
"Indic_CTRLCCA_RNEG","Indic_CTRLCPAP_RPOS","Indic_CTRLCPAP_RNEG","Indic_CTRLLCTI_RPOS",
 
"Indic_Changement_NomLogiciel","Indic_Changement_NomEditeur","Changt_NomEditeurPaie",
 
"Changt_NomLogicielPaie","Infoabs_NomEditeurPaie","Infoabs_NomLogicielPaie",
 
"Indic_Decla_comple","Indic_Decla_AnnuRempl","class_ape","class_Logiciel","class_Editeur",
 
"moda_delai_soldeN_1","moda_delai_soldeN_2","moda_delai_soldeN_3","moda_delai_soldeN_4",
              "moda_delai_soldeN_5",
 
"moda_anciennete_debitN_1","moda_anciennete_debitN_2","moda_anciennete_debitN_3",
              "moda_anciennete_debitN_4","moda_anciennete_debitN_5",
              "moda_moy_anciennete_debit","moda_std_anciennete_debit",
              "moda_moy_delai_solde","moda_std_delai_solde",
 
var_cluster_Arome,var_cluster_BRC,var_cluster_Cedre,var_cluster_cntx2,var_cluster_ctrl,
 
var_cluster_DADS_assiette2,var_cluster_DADS_avantage2,var_cluster_DADS_contrat2,
              var_cluster_DADS_salarie2,var_cluster_Sequoia)

--> The predictors between quotes (excepted y) are qualitative ; others 
are groups of continuous predictors

Var_model<-paste0("y ~ ", paste(champ_model_cont[-1],collapse=" + "))
Logit_appr<-glm(formula=Var_model,family=binomial(link="logit"),data=pop_ctrl_siren_cca2017_appr)

--> The results of this glm do not provide overall pvalues for the 
qualitative predictors, only one pvalue by modality. And for selecting the 
qualitative predictors, i need that overall pvalue that SAS for example 
provides with PROC LOGISTIC.

Benoit Pel?.




De :    "Bob O'Hara" <rni.boh at gmail.com>
A :     Beno?t PELE <benoit.pele at acoss.fr>, 
Cc :    r-help <r-help at r-project.org>
Date :  29/06/2017 11:46
Objet : Re: [R] Help : glm p-values for a factor predictor



It might help if you provided the code you used. It's possible that
you didn't use direction="backward" in stepAIC(). Or if you did, it
was still running, so whatever else you try will still be slow. The
statement "R provides only the pvalues for each level" is wrong: look
at the anova() function.

Bob

On 29 June 2017 at 11:13, Beno?t PELE <benoit.pele at acoss.fr> wrote:
> Hello,
>
> i am a newby on R and i am trying to make a backward selection on a
> binomial-logit glm on a large dataset (69000 lines for 145 predictors).
>
> After 3 days working, the stepAIC function did not terminate. I do not
> know if that is normal but i would like to try computing a "homemade"
> backward with a repeated glm ; at each step, the predictor with the max
> pvalue would be excluded until reaching a set of 20 predictors for
> example.
>
> My question is about the factor predictors with several levels. R 
provides
> only the pvalues for each level whereas i need an overall pvalue for
> testing the predictor.
>
> On internet, the only solution i found suggests to compute a Khi2
> log-likelihood test between the complete model and the model without the
> factor predictor to emphasize its relevance.
>
> Do you know other ways? Another R package managing this kind of issue?
>
> Thank you and best regards, Benoit.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bob O'Hara
NOTE NEW ADDRESS!!!
Institutt for matematiske fag
NTNU
7491 Trondheim
Norway

Mobile: +49 1515 888 5440
Journal of Negative Results - EEB: www.jnr-eeb.org


	[[alternative HTML version deleted]]


From friendly at yorku.ca  Thu Jun 29 15:04:20 2017
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 29 Jun 2017 15:04:20 +0200
Subject: [R] Help : glm p-values for a factor predictor
In-Reply-To: <OF989B886C.250B1E03-ONC125814E.0032A301-C125814E.0032B428@urssaf.fr>
References: <OF989B886C.250B1E03-ONC125814E.0032A301-C125814E.0032B428@urssaf.fr>
Message-ID: <51cb8237-d28c-022f-948f-d6495ef8f944@yorku.ca>

On 6/29/17 11:13 AM, Beno?t PELE wrote:
> My question is about the factor predictors with several levels. R provides
> only the pvalues for each level whereas i need an overall pvalue for
> testing the predictor.

What you ask is provided by anova() -- type I tests, and car::Anova() -- 
Type II & III tests.

Factors in stepwise methods must be handled specially, to allow all 
levels to be included/excluded together.  I don't know of R software 
that does this.

HTH

-Michael


From jfox at mcmaster.ca  Thu Jun 29 15:14:59 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 29 Jun 2017 13:14:59 +0000
Subject: [R] Help : glm p-values for a factor predictor
In-Reply-To: <6573_1498741473_v5TD4WRi010096_51cb8237-d28c-022f-948f-d6495ef8f944@yorku.ca>
References: <OF989B886C.250B1E03-ONC125814E.0032A301-C125814E.0032B428@urssaf.fr>
 <6573_1498741473_v5TD4WRi010096_51cb8237-d28c-022f-948f-d6495ef8f944@yorku.ca>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836693591@FHSDB4H16-2.csu.mcmaster.ca>

Hi Michael,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Friendly
> Sent: Thursday, June 29, 2017 9:04 AM
> To: Beno?t PELE <benoit.pele at acoss.fr>; r-help at r-project.org
> Subject: Re: [R] Help : glm p-values for a factor predictor
> 
> On 6/29/17 11:13 AM, Beno?t PELE wrote:
> > My question is about the factor predictors with several levels. R
> > provides only the pvalues for each level whereas i need an overall
> > pvalue for testing the predictor.
> 
> What you ask is provided by anova() -- type I tests, and car::Anova() -- Type II
> & III tests.
> 
> Factors in stepwise methods must be handled specially, to allow all levels to
> be included/excluded together.  I don't know of R software that does this.

The step() function and stepAIC() in MASS both keep terms together and obey marginality.

Best,
 John

> 
> HTH
> 
> -Michael
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From friendly at yorku.ca  Thu Jun 29 15:00:07 2017
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 29 Jun 2017 15:00:07 +0200
Subject: [R] R package for scorecard development
In-Reply-To: <CAMivb6p2bf-uEtd9k3YyTLk4H27fqywdcPUGOcXh5syFgEv4Qg@mail.gmail.com>
References: <CAMivb6p2bf-uEtd9k3YyTLk4H27fqywdcPUGOcXh5syFgEv4Qg@mail.gmail.com>
Message-ID: <2441060a-06c6-9ee6-159a-54a91c9c2977@yorku.ca>

Hi

I'm sure there are valid reasons for wanting to use a scorecard model,
but a more straightforward approach would just be a logistic regression
or logistic discriminant analysis.

Compared to that, a scorecard model can be considered to be throwing 
away information by binning the predictors.  It is similar to what scale
developers often do by simply summing up item (0/1) scores on the 
assumption that they all should be equally weighted, rather than using 
something like factor or component weights.

Just a thought.  If you do come up with a scorecard model, it would at
least be useful to compare it with a logistic model.

-Michael

On 6/28/17 1:26 PM, Nikhil Abhyankar wrote:
> Hello all,
> 
> Is there any R package that can develop a scorecard model for a binary
> target variable?
> 
> More details:
> I want to create a scorecard based on the raw data I have.
> 
> I have a binary target variable and a few numeric and character input
> variables.
> 
> I want to bin the variables and assign a score to each of the bins.
> 
> Each subject will be scored based on the bin it falls in for each variable.
> 
> All such scores from each of the variables will be added up to get the
> final score.
> 
> There will be a cutoff score to decide which of the two classes of response
> the subject falls into.
> 
> I fount and tested the smbinning package. However, it only gives the bins
> for a single variable at a time.
> 
> How can I get a full scorecard model?
> 
> Thanks
> Nikhil
> 
> 	[[alternative HTML version deleted]]
>


From c.puschmann at student.unsw.edu.au  Thu Jun 29 06:05:05 2017
From: c.puschmann at student.unsw.edu.au (Christoph Puschmann)
Date: Thu, 29 Jun 2017 04:05:05 +0000
Subject: [R] Different date formats in one column
In-Reply-To: <1220786224.636968.1498677643237@mail.yahoo.com>
References: <1220786224.636968.1498677643237.ref@mail.yahoo.com>,
 <1220786224.636968.1498677643237@mail.yahoo.com>
Message-ID: <8E6292C9-1D6D-4908-A144-CFD38EDB541B@student.unsw.edu.au>

Hey,

Are all the dates connected? So no comma or space btw?

Regards,

Christoph

> On 29 Jun 2017, at 2:02 pm, Farnoosh Sheikhi via R-help <r-help at r-project.org> wrote:
> 
> Hi, 
> I have a data set with various date formats in one column and not sure how to unify it.Here is a few formats:
> 02091702/22/170221201703/17/160015-08-239/2/1500170806May-2-201522-March-2014
> I tried parse_date_time from lubridate library but it failed.Thanks so much. Best,Farnoosh
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lsantoshksingh at gmail.com  Thu Jun 29 10:11:54 2017
From: lsantoshksingh at gmail.com (Santosh Kumar)
Date: Thu, 29 Jun 2017 13:41:54 +0530
Subject: [R] help needed for RInside with Qt
In-Reply-To: <DCD1C48D-10CB-466A-988B-0007B472C48B@dcn.davis.ca.us>
References: <CAB8DgdKXMui236e7kwWMcCF26ZU4AmxSHKL2E9txLaUPdiJSdw@mail.gmail.com>
 <CAGxFJbTviphbXc8JEeNaL0Km8=4+n5wRubdT3dCgdCvJSv6rpA@mail.gmail.com>
 <DCD1C48D-10CB-466A-988B-0007B472C48B@dcn.davis.ca.us>
Message-ID: <CAB8DgdKA1tTay0hUi+fOtV=ttOSrWLHXcAGzQsb+y+MeQFk2bA@mail.gmail.com>

Hi Bert and Jeff,

Thanks a lot for pointing it out. It is a commercial application. I would
be distributing it. This makes R out of consideration.

Thanks again for saving much time and effort.

On Thu, Jun 29, 2017 at 10:22 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> If you adhere to the terms of the license for R you should be okay
> legally. If you use contributed packages they may have additional
> requirements. However, these terms are often overlooked by programmers
> targeting Windows, hence Bert's caution.
>
> As to the content of the original post itself, it is off-topic for this
> list... it belongs in R-devel (but you may need to study the Posting Guide
> more thoroughly (use plain text at least) and clearly communicate your
> licensing intentions to elicit help there. You probably also ought to
> carefully read the R Installation and Administration Manual and indicate
> why that document did not answer your questions.
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 29, 2017 12:32:40 AM EDT, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >Is this application meant to be commercial? If so, R's open source
> >license probably would forbid you to use it. I defer to those with
> >real legal knowledge on this point, but you should check it. If it is
> >not meant to be commercial, then ignore -- I have nothing useful to
> >offer you.
> >
> >Cheers,
> >Bert
> >
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Wed, Jun 28, 2017 at 1:36 PM, Santosh Kumar
> ><lsantoshksingh at gmail.com> wrote:
> >> Hello,
> >>
> >> I am developing an application using Qt framework and C++. I want to
> >use R
> >> as statistics engine of my application. After doing some search on
> >> internet; I came to the conclusion that RCPP, MPI with RInside is
> >what I
> >> need. The next logical task was to quickly tryout "qtdensity" project
> >of
> >> RInside, for understanding the build and other settings. I hit some
> >> roadblock here and got little confused. I have following quaries:
> >>
> >> 1. I am using Qt  5.8 MSVC and would like to distribute both 64 bit
> >as well
> >> as 32 bit application.
> >> 2. Can I use binary distribution provided on CRAN with this version
> >of Qt?
> >> 3. If not then; do I need to build R myself with MinGW and Qt too
> >with the
> >> same version of MinGW?
> >> 4. regarding make file modifications how should I set R_HOME env.
> >variable?
> >> Currently my R is installed in "C:\Program Files\R\R-3.4.0" If I set
> >env
> >> variable R_HOME = "C:\Program Files\R\R-3.4.0"....I get QMake error:
> >The
> >> system cannot find the path specified.
> >>
> >> Any help will be much appreciated.
> >>
> >> Thanks,
> >> Santosh
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wangnaike1989 at gmail.com  Thu Jun 29 15:37:11 2017
From: wangnaike1989 at gmail.com (Naike Wang)
Date: Thu, 29 Jun 2017 09:37:11 -0400
Subject: [R] Creating two groups of random numbers
Message-ID: <CAEMVQemfQcSTeen2WF6xi81ixB6G4KcMUwG5r6eVg8gJSh1qDQ@mail.gmail.com>

Hi all,
I want to create two groups of random numbers to calculate proportions. The
first group is to represent the number of cases in a study. The second
group is to represent the sample size of the study. Apparently, the sample
size is going to have to be bigger or equal to the number of cases, but the
sample size of a study is not necessarily greater than the number of cases
of another study. Here's an example:

study          cases            total
1 17 28
2 48 70
3 87 92
4 15 17

Notice that the sample size of the first study is 28, which is bigger than
the number of cases of this study, but is smaller than the number of cases
of the second study.

How do I create a data set like this?

Best,
Naike

	[[alternative HTML version deleted]]


From wangnaike1989 at gmail.com  Thu Jun 29 15:44:16 2017
From: wangnaike1989 at gmail.com (Naike Wang)
Date: Thu, 29 Jun 2017 09:44:16 -0400
Subject: [R] Creating two groups of random numbers
Message-ID: <CAEMVQe=SLGke0yh5JKUgEad-YoUv5vWV5qQ9iQ3FyEO+ygYGSw@mail.gmail.com>

Hi all,
I want to create two groups of random numbers to calculate proportions. The
first group is to represent the number of cases in a study. The second
group is to represent the sample size of the study. Apparently, the sample
size is going to have to be bigger or equal to the number of cases, but the
sample size of a study is not necessarily greater than the number of cases
of another study. Here's an example:

study                 cases            total
1                        17                 28
2                        48                 70
3                        87                 92
4                        15                 17



Notice that the sample size of the first study is 28, which is bigger than
the number of cases of this study, but is smaller than the number of cases
of the second study.

How do I create a data set like this?

Best,
Naike

	[[alternative HTML version deleted]]


From varevare at googlemail.com  Thu Jun 29 14:41:34 2017
From: varevare at googlemail.com (vare vare)
Date: Thu, 29 Jun 2017 14:41:34 +0200
Subject: [R] package to fit mixtures of student-t distributions
Message-ID: <11F020B9-9C17-4EBE-BD1A-EEC26589CB93@googlemail.com>

Hello!

I am new to R (before used python exclusively and would actually call the R solution for this issue inside a python notebook, hope that doesn?t disqualify me right of the batch).

Right now I am  looking for a piece of software  to fit a 1D data sample to a mixture of t-distributions.

I searched quite a while already and it seems to be that this is a somehwat obscure endeavor as most search results turn up for mixture of gaussians (what I am not interested here).

The most promising candidates so far are the "AdMit" and "MitSEM" R packages. However I do not know R and find the description of these packages rather comlple and it seems their core objective is not the fitting of mixtures of t?s but instead use this as a step to accomplish something else.

This is in a nutshell what I want the software to accomplish:

Fitting a mixture of t-distributions to some data and estimate the "location" "scale" and "degrees of freedom" for each.

I hope someone can point me to a simple package, I can?t believe that this is such an obscure use case.

Thanks!


From bgunter.4567 at gmail.com  Thu Jun 29 16:58:23 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 29 Jun 2017 07:58:23 -0700
Subject: [R] package to fit mixtures of student-t distributions
In-Reply-To: <11F020B9-9C17-4EBE-BD1A-EEC26589CB93@googlemail.com>
References: <11F020B9-9C17-4EBE-BD1A-EEC26589CB93@googlemail.com>
Message-ID: <CAGxFJbQWRAKTSADyNan1jYeH-tkp99Xu+5AXw9qN5P+x2kXrpg@mail.gmail.com>

Offlist, because this is (a) an opinion and (b) about statistics and
therefore offtopic.

I don't know whether any such package exists, but I would predict that
this is likely to be overdetermined (too many parameters) and
therefore unlikely to be a successful strategy. Fitting a mixture of
Gaussians is already difficult enough.

Feel free to ignore, of course, and no need to reply.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 29, 2017 at 5:41 AM, vare vare via R-help
<r-help at r-project.org> wrote:
> Hello!
>
> I am new to R (before used python exclusively and would actually call the R solution for this issue inside a python notebook, hope that doesn?t disqualify me right of the batch).
>
> Right now I am  looking for a piece of software  to fit a 1D data sample to a mixture of t-distributions.
>
> I searched quite a while already and it seems to be that this is a somehwat obscure endeavor as most search results turn up for mixture of gaussians (what I am not interested here).
>
> The most promising candidates so far are the "AdMit" and "MitSEM" R packages. However I do not know R and find the description of these packages rather comlple and it seems their core objective is not the fitting of mixtures of t?s but instead use this as a step to accomplish something else.
>
> This is in a nutshell what I want the software to accomplish:
>
> Fitting a mixture of t-distributions to some data and estimate the "location" "scale" and "degrees of freedom" for each.
>
> I hope someone can point me to a simple package, I can?t believe that this is such an obscure use case.
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Thu Jun 29 17:09:04 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 29 Jun 2017 11:09:04 -0400
Subject: [R] Creating two groups of random numbers
In-Reply-To: <CAEMVQe=SLGke0yh5JKUgEad-YoUv5vWV5qQ9iQ3FyEO+ygYGSw@mail.gmail.com>
References: <CAEMVQe=SLGke0yh5JKUgEad-YoUv5vWV5qQ9iQ3FyEO+ygYGSw@mail.gmail.com>
Message-ID: <6F0ECC7A-72D3-4A29-BCD4-55B8EEB5F589@utoronto.ca>

I'd do it this way ... let me know if you need explanations.

minSize <- 15
maxSize <- 100
minSample <- 0.1
maxSample <- 0.8

# setup dataframe with totals, and cases as fractions
myStudies <- data.frame(study = 1:Nstudies,
                        cases = runif(Nstudies,
                                      min = minSample,
                                      max = maxSample),
                        total = sample(minSize:maxSize,
                                       Nstudies,
                                       replace = TRUE))

# convert case fractions of totals to integers
myStudies$cases <- round(myStudies$cases * myStudies$total)


Cheers,
Boris



> On Jun 29, 2017, at 9:44 AM, Naike Wang <wangnaike1989 at gmail.com> wrote:
> 
> Hi all,
> I want to create two groups of random numbers to calculate proportions. The
> first group is to represent the number of cases in a study. The second
> group is to represent the sample size of the study. Apparently, the sample
> size is going to have to be bigger or equal to the number of cases, but the
> sample size of a study is not necessarily greater than the number of cases
> of another study. Here's an example:
> 
> study                 cases            total
> 1                        17                 28
> 2                        48                 70
> 3                        87                 92
> 4                        15                 17
> 
> 
> 
> Notice that the sample size of the first study is 28, which is bigger than
> the number of cases of this study, but is smaller than the number of cases
> of the second study.
> 
> How do I create a data set like this?
> 
> Best,
> Naike
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Thu Jun 29 17:17:44 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 29 Jun 2017 16:17:44 +0100
Subject: [R] Creating two groups of random numbers
In-Reply-To: <CAEMVQe=SLGke0yh5JKUgEad-YoUv5vWV5qQ9iQ3FyEO+ygYGSw@mail.gmail.com>
References: <CAEMVQe=SLGke0yh5JKUgEad-YoUv5vWV5qQ9iQ3FyEO+ygYGSw@mail.gmail.com>
Message-ID: <e3387e6d-bd3f-f5d4-1fa0-cb763ccd9b6a@dewey.myzen.co.uk>

Please do not cross post as people waste time replying on one forum not 
knowing you have already received excellent advice on another.

On 29/06/2017 14:44, Naike Wang wrote:
> Hi all,
> I want to create two groups of random numbers to calculate proportions. The
> first group is to represent the number of cases in a study. The second
> group is to represent the sample size of the study. Apparently, the sample
> size is going to have to be bigger or equal to the number of cases, but the
> sample size of a study is not necessarily greater than the number of cases
> of another study. Here's an example:
>
> study                 cases            total
> 1                        17                 28
> 2                        48                 70
> 3                        87                 92
> 4                        15                 17
>
>
>
> Notice that the sample size of the first study is 28, which is bigger than
> the number of cases of this study, but is smaller than the number of cases
> of the second study.
>
> How do I create a data set like this?
>
> Best,
> Naike
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ---
> This email has been checked for viruses by AVG.
> http://www.avg.com
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jayjay.1988 at hotmail.nl  Thu Jun 29 19:38:12 2017
From: jayjay.1988 at hotmail.nl (Jay Zola)
Date: Thu, 29 Jun 2017 17:38:12 +0000
Subject: [R] Change Rcode for a meta-analysis(netmeta) to use a random
 effects model instead of a mixed effects model
Message-ID: <VI1PR0501MB2557B6D4E7BBACE0584777978AD20@VI1PR0501MB2557.eurprd05.prod.outlook.com>

Hello,


I am writing a meta-analysis on the complication and reoperation rates after 5 treatment modalities of a distal radius fracture. I have a code to compare the complication and reoperation rates. Currently it is using a mixed effects model. Is it possible to change the code so a random effects model is used?


Thank you very much,


Jay



R code


library(meta) library(readxl) All <- read_excel("Basics excel file complication and reoperation rate.xlsx", sheet=1) names(All) <- c("Study_ID","Event_Type","Treatment","Events_n","N","nN") All$Treatment <- factor(All$Treatment, levels=c("PC","EF","IMN","KW","VPO")) # Outcomes Complications <- subset(All, Event_Type=="Complications") Reoperations <- subset(All, Event_Type=="Reoperations") # Comparison of treatment effects to gold standard in the Complications subset mtpr1 <- metaprop(Events_n, N, Study_ID, data = Complications) meta::metareg(mtpr1, ~Treatment) # Comparison of treatment effects to gold standard in the Reoperations subset mtpr2 <- metaprop(Events_n, N, Study_ID, data = Reoperations) meta::metareg(mtpr2, ~Treatment) # Comparison of treatment effects to gold standard in the All dataset # Interaction effects have been considered mtpr <- metaprop(Events_n, N, Study_ID, data = All) meta::metareg(mtpr, ~Treatment*Event_Type)


A part of the dataset:

Study| Event Type| Treatment| Number of Events (n)| N| n/N|
Kumaravel| Complications| EF| 3| 23| 0,1304348|
Franck| Complications| EF| 2| 20| 0,1|
Schonnemann| Complications| EF| 8| 30| 0,2666667|
Aita| Complications| EF| 1| 16| 0,0625|
Hove| Complications| EF| 31| 39| 0,7948718|
Andersen| Complications| EF| 26| 75| 0,3466667|
Krughaug| Complications| EF| 22| 75| 0,2933333|
Moroni| Complications| EF| 0| 20| 0|
Plate| Complications| IMN| 3| 30| 0,1|
Chappuis| Complications| IMN| 4| 16| 0,25|
Gradl| Complications| IMN| 12| 66| 0,1818182|
Schonnemann| Complications| IMN| 6| 31| 0,1935484|
Aita| Complications| IMN| 1| 16| 0,0625|
Dremstrop| Complications| IMN| 17| 44| 0,3863636|
Wong| Complications| PC| 1| 30| 0,0333333|
Kumaravel| Complications| PC| 4| 25| 0,16|


	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Jun 29 19:47:21 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Thu, 29 Jun 2017 17:47:21 +0000
Subject: [R] Change Rcode for a meta-analysis(netmeta) to use a random
 effects model instead of a mixed effects model
In-Reply-To: <VI1PR0501MB2557B6D4E7BBACE0584777978AD20@VI1PR0501MB2557.eurprd05.prod.outlook.com>
References: <VI1PR0501MB2557B6D4E7BBACE0584777978AD20@VI1PR0501MB2557.eurprd05.prod.outlook.com>
Message-ID: <ebd316e654fb4f188911675348d909e3@UM-MAIL3216.unimaas.nl>

The code in your mail in a mangled mess, since you posted in HTML. Please configure your email client to send emails in plain text. 

Could you explain what exactly you mean by "Currently it is using a mixed effects model. Is it possible to change the code so a random effects model is used?"

Best,
Wolfgang

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jay Zola
>Sent: Thursday, June 29, 2017 19:38
>To: r-help at r-project.org
>Subject: [R] Change Rcode for a meta-analysis(netmeta) to use a random
>effects model instead of a mixed effects model
>
>Hello,
>
>I am writing a meta-analysis on the complication and reoperation rates
>after 5 treatment modalities of a distal radius fracture. I have a code to
>compare the complication and reoperation rates. Currently it is using a
>mixed effects model. Is it possible to change the code so a random effects
>model is used?
>
>Thank you very much,
>
>Jay
>
>R code
>
>library(meta) library(readxl) All <- read_excel("Basics excel file
>complication and reoperation rate.xlsx", sheet=1) names(All) <-
>c("Study_ID","Event_Type","Treatment","Events_n","N","nN") All$Treatment
><- factor(All$Treatment, levels=c("PC","EF","IMN","KW","VPO")) # Outcomes
>Complications <- subset(All, Event_Type=="Complications") Reoperations <-
>subset(All, Event_Type=="Reoperations") # Comparison of treatment effects
>to gold standard in the Complications subset mtpr1 <- metaprop(Events_n,
>N, Study_ID, data = Complications) meta::metareg(mtpr1, ~Treatment) #
>Comparison of treatment effects to gold standard in the Reoperations
>subset mtpr2 <- metaprop(Events_n, N, Study_ID, data = Reoperations)
>meta::metareg(mtpr2, ~Treatment) # Comparison of treatment effects to gold
>standard in the All dataset # Interaction effects have been considered
>mtpr <- metaprop(Events_n, N, Study_ID, data = All) meta::metareg(mtpr,
>~Treatment*Event_Type)
>
>A part of the dataset:
>
>Study| Event Type| Treatment| Number of Events (n)| N| n/N|
>Kumaravel| Complications| EF| 3| 23| 0,1304348|
>Franck| Complications| EF| 2| 20| 0,1|
>Schonnemann| Complications| EF| 8| 30| 0,2666667|
>Aita| Complications| EF| 1| 16| 0,0625|
>Hove| Complications| EF| 31| 39| 0,7948718|
>Andersen| Complications| EF| 26| 75| 0,3466667|
>Krughaug| Complications| EF| 22| 75| 0,2933333|
>Moroni| Complications| EF| 0| 20| 0|
>Plate| Complications| IMN| 3| 30| 0,1|
>Chappuis| Complications| IMN| 4| 16| 0,25|
>Gradl| Complications| IMN| 12| 66| 0,1818182|
>Schonnemann| Complications| IMN| 6| 31| 0,1935484|
>Aita| Complications| IMN| 1| 16| 0,0625|
>Dremstrop| Complications| IMN| 17| 44| 0,3863636|
>Wong| Complications| PC| 1| 30| 0,0333333|
>Kumaravel| Complications| PC| 4| 25| 0,16|
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-
>guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jayjay.1988 at hotmail.nl  Thu Jun 29 19:54:38 2017
From: jayjay.1988 at hotmail.nl (Jay Zola)
Date: Thu, 29 Jun 2017 17:54:38 +0000
Subject: [R] Change Rcode for a meta-analysis(netmeta) to use a random
 effects model instead of a mixed effects model
In-Reply-To: <ebd316e654fb4f188911675348d909e3@UM-MAIL3216.unimaas.nl>
References: <VI1PR0501MB2557B6D4E7BBACE0584777978AD20@VI1PR0501MB2557.eurprd05.prod.outlook.com>,
 <ebd316e654fb4f188911675348d909e3@UM-MAIL3216.unimaas.nl>
Message-ID: <VI1PR0501MB2557018EEAD7E06C1AE8EAAA8AD20@VI1PR0501MB2557.eurprd05.prod.outlook.com>

Link Dropbox R code: https://www.dropbox.com/s/9u6e89t6dq39r53/Rcode%20metaregression.docx?dl=0

Rcode metaregression.docx<https://www.dropbox.com/s/9u6e89t6dq39r53/Rcode%20metaregression.docx?dl=0>
www.dropbox.com
Shared with Dropbox




Link Dropbox part of dataset: https://www.dropbox.com/s/j1urqzr99bt76ip/Basics%20excel%20file%20complication%20and%20reoperation%20rate.xlsx?dl=0



________________________________
Van: Viechtbauer Wolfgang (SP) <wolfgang.viechtbauer at maastrichtuniversity.nl>
Verzonden: donderdag 29 juni 2017 19:47
Aan: Jay Zola; r-help at r-project.org
Onderwerp: RE: Change Rcode for a meta-analysis(netmeta) to use a random effects model instead of a mixed effects model

The code in your mail in a mangled mess, since you posted in HTML. Please configure your email client to send emails in plain text.

Could you explain what exactly you mean by "Currently it is using a mixed effects model. Is it possible to change the code so a random effects model is used?"

Best,
Wolfgang

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jay Zola
>Sent: Thursday, June 29, 2017 19:38
>To: r-help at r-project.org
>Subject: [R] Change Rcode for a meta-analysis(netmeta) to use a random
>effects model instead of a mixed effects model
>
>Hello,
>
>I am writing a meta-analysis on the complication and reoperation rates
>after 5 treatment modalities of a distal radius fracture. I have a code to
>compare the complication and reoperation rates. Currently it is using a
>mixed effects model. Is it possible to change the code so a random effects
>model is used?
>
>Thank you very much,
>
>Jay
>
>R code
>
>library(meta) library(readxl) All <- read_excel("Basics excel file
>complication and reoperation rate.xlsx", sheet=1) names(All) <-
>c("Study_ID","Event_Type","Treatment","Events_n","N","nN") All$Treatment
><- factor(All$Treatment, levels=c("PC","EF","IMN","KW","VPO")) # Outcomes
>Complications <- subset(All, Event_Type=="Complications") Reoperations <-
>subset(All, Event_Type=="Reoperations") # Comparison of treatment effects
>to gold standard in the Complications subset mtpr1 <- metaprop(Events_n,
>N, Study_ID, data = Complications) meta::metareg(mtpr1, ~Treatment) #
>Comparison of treatment effects to gold standard in the Reoperations
>subset mtpr2 <- metaprop(Events_n, N, Study_ID, data = Reoperations)
>meta::metareg(mtpr2, ~Treatment) # Comparison of treatment effects to gold
>standard in the All dataset # Interaction effects have been considered
>mtpr <- metaprop(Events_n, N, Study_ID, data = All) meta::metareg(mtpr,
>~Treatment*Event_Type)
>
>A part of the dataset:
>
>Study| Event Type| Treatment| Number of Events (n)| N| n/N|
>Kumaravel| Complications| EF| 3| 23| 0,1304348|
>Franck| Complications| EF| 2| 20| 0,1|
>Schonnemann| Complications| EF| 8| 30| 0,2666667|
>Aita| Complications| EF| 1| 16| 0,0625|
>Hove| Complications| EF| 31| 39| 0,7948718|
>Andersen| Complications| EF| 26| 75| 0,3466667|
>Krughaug| Complications| EF| 22| 75| 0,2933333|
>Moroni| Complications| EF| 0| 20| 0|
>Plate| Complications| IMN| 3| 30| 0,1|
>Chappuis| Complications| IMN| 4| 16| 0,25|
>Gradl| Complications| IMN| 12| 66| 0,1818182|
>Schonnemann| Complications| IMN| 6| 31| 0,1935484|
>Aita| Complications| IMN| 1| 16| 0,0625|
>Dremstrop| Complications| IMN| 17| 44| 0,3863636|
>Wong| Complications| PC| 1| 30| 0,0333333|
>Kumaravel| Complications| PC| 4| 25| 0,16|
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-
>guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Thu Jun 29 21:04:47 2017
From: chocold12 at gmail.com (lily li)
Date: Thu, 29 Jun 2017 13:04:47 -0600
Subject: [R] about reading files in order
Message-ID: <CAN5afy9ZNOCv+gUFtpFPJMsxgQ6s=C6bWaWYRPLhf8T-QgsPvg@mail.gmail.com>

Hi R users,
I have a question about opening the txt files and putting them into a
matrix. The txt files are in the folder01, while they have the name
file.1.txt, file.2.txt, file.3.txt, etc. There are about 200 such text
files. Each txt file contains one value inside. When I tried to use the
code below, I found that the txt files are not in order, from 1, 2, 3, to
200. Rather, they are in the order 1, 10, 100, 101, etc. How to change it
so that they are in order? Thanks for your help.

temp <- list.files('folder01',pattern="*.txt"
name.list <-lapply(paste('folder01',temp,sep='/'),read.table,head=F)
library(data.table)
files.matrix <-rbindlist(name.list)

Also, when use the code below, how to complete it so that the values of the
files are stored in a matrix?
lists = list.files('folder01')
for (i in 1:length(lists)){
  file <- read.table(paste('folder01',lists[i],sep='/'),head=F)
  print(file)
}

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Thu Jun 29 21:47:45 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 29 Jun 2017 12:47:45 -0700
Subject: [R] about reading files in order
In-Reply-To: <CAN5afy9ZNOCv+gUFtpFPJMsxgQ6s=C6bWaWYRPLhf8T-QgsPvg@mail.gmail.com>
References: <CAN5afy9ZNOCv+gUFtpFPJMsxgQ6s=C6bWaWYRPLhf8T-QgsPvg@mail.gmail.com>
Message-ID: <CAFDcVCR9FcE+a81GOp9_bzyu+qp4MdUb7qbptWpooZqznSdJRw@mail.gmail.com>

You can use:

> files <- list.files(path = "folder01")
> files <- gtools::mixedsort(files)

to order the files in a "human-friendly" order rather than
lexicographic order (which sort() provides).

FYI 1; it's preferred to use file.path("folder01", list[i]) rather
than paste('folder01',lists[i],sep='/').

FYI 2; if you use list.files(path = "folder01", full.names = TRUE),
you get the full paths rather name just the file names, i.e. you don't
have to use file.path().

/Henrik

On Thu, Jun 29, 2017 at 12:04 PM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
> I have a question about opening the txt files and putting them into a
> matrix. The txt files are in the folder01, while they have the name
> file.1.txt, file.2.txt, file.3.txt, etc. There are about 200 such text
> files. Each txt file contains one value inside. When I tried to use the
> code below, I found that the txt files are not in order, from 1, 2, 3, to
> 200. Rather, they are in the order 1, 10, 100, 101, etc. How to change it
> so that they are in order? Thanks for your help.
>
> temp <- list.files('folder01',pattern="*.txt"
> name.list <-lapply(paste('folder01',temp,sep='/'),read.table,head=F)
> library(data.table)
> files.matrix <-rbindlist(name.list)
>
> Also, when use the code below, how to complete it so that the values of the
> files are stored in a matrix?
> lists = list.files('folder01')
> for (i in 1:length(lists)){
>   file <- read.table(paste('folder01',lists[i],sep='/'),head=F)
>   print(file)
> }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Thu Jun 29 22:12:22 2017
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 29 Jun 2017 15:12:22 -0500
Subject: [R] about reading files in order
In-Reply-To: <CAFDcVCR9FcE+a81GOp9_bzyu+qp4MdUb7qbptWpooZqznSdJRw@mail.gmail.com>
References: <CAN5afy9ZNOCv+gUFtpFPJMsxgQ6s=C6bWaWYRPLhf8T-QgsPvg@mail.gmail.com>
 <CAFDcVCR9FcE+a81GOp9_bzyu+qp4MdUb7qbptWpooZqznSdJRw@mail.gmail.com>
Message-ID: <CAN5YmCG_r1Y9Ayvj_w-98-gOY5VciMVQMYqfK5DoMRWFYJFuSg@mail.gmail.com>

Thanks for that answer.
I was not aware of gtools::mixedsort
<https://www.rdocumentation.org/packages/gtools/versions/3.5.0/topics/mixedsort>
function.

Jean

On Thu, Jun 29, 2017 at 2:47 PM, Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> You can use:
>
> > files <- list.files(path = "folder01")
> > files <- gtools::mixedsort(files)
>
> to order the files in a "human-friendly" order rather than
> lexicographic order (which sort() provides).
>
> FYI 1; it's preferred to use file.path("folder01", list[i]) rather
> than paste('folder01',lists[i],sep='/').
>
> FYI 2; if you use list.files(path = "folder01", full.names = TRUE),
> you get the full paths rather name just the file names, i.e. you don't
> have to use file.path().
>
> /Henrik
>
> On Thu, Jun 29, 2017 at 12:04 PM, lily li <chocold12 at gmail.com> wrote:
> > Hi R users,
> > I have a question about opening the txt files and putting them into a
> > matrix. The txt files are in the folder01, while they have the name
> > file.1.txt, file.2.txt, file.3.txt, etc. There are about 200 such text
> > files. Each txt file contains one value inside. When I tried to use the
> > code below, I found that the txt files are not in order, from 1, 2, 3, to
> > 200. Rather, they are in the order 1, 10, 100, 101, etc. How to change it
> > so that they are in order? Thanks for your help.
> >
> > temp <- list.files('folder01',pattern="*.txt"
> > name.list <-lapply(paste('folder01',temp,sep='/'),read.table,head=F)
> > library(data.table)
> > files.matrix <-rbindlist(name.list)
> >
> > Also, when use the code below, how to complete it so that the values of
> the
> > files are stored in a matrix?
> > lists = list.files('folder01')
> > for (i in 1:length(lists)){
> >   file <- read.table(paste('folder01',lists[i],sep='/'),head=F)
> >   print(file)
> > }
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Thu Jun 29 23:19:54 2017
From: chocold12 at gmail.com (lily li)
Date: Thu, 29 Jun 2017 15:19:54 -0600
Subject: [R] about reading files in order
In-Reply-To: <CAN5YmCG_r1Y9Ayvj_w-98-gOY5VciMVQMYqfK5DoMRWFYJFuSg@mail.gmail.com>
References: <CAN5afy9ZNOCv+gUFtpFPJMsxgQ6s=C6bWaWYRPLhf8T-QgsPvg@mail.gmail.com>
 <CAFDcVCR9FcE+a81GOp9_bzyu+qp4MdUb7qbptWpooZqznSdJRw@mail.gmail.com>
 <CAN5YmCG_r1Y9Ayvj_w-98-gOY5VciMVQMYqfK5DoMRWFYJFuSg@mail.gmail.com>
Message-ID: <CAN5afy9i2V1OTO7Y9JrR5+OS1mmHiged8siyBDPsymj_zzLp_g@mail.gmail.com>

Thanks also.

On Thu, Jun 29, 2017 at 2:12 PM, Adams, Jean <jvadams at usgs.gov> wrote:

> Thanks for that answer.
> I was not aware of gtools::mixedsort
> <https://www.rdocumentation.org/packages/gtools/versions/3.5.0/topics/mixedsort>
> function.
>
> Jean
>
> On Thu, Jun 29, 2017 at 2:47 PM, Henrik Bengtsson <
> henrik.bengtsson at gmail.com> wrote:
>
>> You can use:
>>
>> > files <- list.files(path = "folder01")
>> > files <- gtools::mixedsort(files)
>>
>> to order the files in a "human-friendly" order rather than
>> lexicographic order (which sort() provides).
>>
>> FYI 1; it's preferred to use file.path("folder01", list[i]) rather
>> than paste('folder01',lists[i],sep='/').
>>
>> FYI 2; if you use list.files(path = "folder01", full.names = TRUE),
>> you get the full paths rather name just the file names, i.e. you don't
>> have to use file.path().
>>
>> /Henrik
>>
>> On Thu, Jun 29, 2017 at 12:04 PM, lily li <chocold12 at gmail.com> wrote:
>> > Hi R users,
>> > I have a question about opening the txt files and putting them into a
>> > matrix. The txt files are in the folder01, while they have the name
>> > file.1.txt, file.2.txt, file.3.txt, etc. There are about 200 such text
>> > files. Each txt file contains one value inside. When I tried to use the
>> > code below, I found that the txt files are not in order, from 1, 2, 3,
>> to
>> > 200. Rather, they are in the order 1, 10, 100, 101, etc. How to change
>> it
>> > so that they are in order? Thanks for your help.
>> >
>> > temp <- list.files('folder01',pattern="*.txt"
>> > name.list <-lapply(paste('folder01',temp,sep='/'),read.table,head=F)
>> > library(data.table)
>> > files.matrix <-rbindlist(name.list)
>> >
>> > Also, when use the code below, how to complete it so that the values of
>> the
>> > files are stored in a matrix?
>> > lists = list.files('folder01')
>> > for (i in 1:length(lists)){
>> >   file <- read.table(paste('folder01',lists[i],sep='/'),head=F)
>> >   print(file)
>> > }
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From Scott.Waichler at pnnl.gov  Thu Jun 29 23:43:49 2017
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Thu, 29 Jun 2017 21:43:49 +0000
Subject: [R] plot3D color ramp not working as expected
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881BA48462@EX10MBOX03.pnnl.gov>

Hi, I want to use a discrete color ramp with plot3D, and show NA values as white (default).  I get unexpected results per the following.

# as in help(slice3D) example:
par(mfrow = c(2,2))
x <- y <- z <- seq(-1, 1, by = 0.1)
grid <- mesh(x, y, z)
colvar <- with(grid, x*exp(-x^2 - y^2 - z^2))
slice3D (x, y, z, colvar = colvar, theta = 60)
#
# use three discrete classes and colors instead of a continuous ramp
slice3D(x, y, z, colvar = colvar, theta = 60,
        col = c("blue", "green", "red"), breaks = c(-0.5, -0.1, 0.1, 0.5))
# now set a vertical slice of the cube to NA
colvar[10,,] <- NA
# displays as expected; default NAcol = "white"
slice3D (x, y, z, colvar = colvar, theta = 60) 
# does not display as expected--notice
# the colors shifted down in value, with NA and -0.5 to -0.1 now both white.
slice3D(x, y, z, colvar = colvar, theta = 60,
        col = c("blue", "green", "red"),
        breaks = c(-0.5, -0.1, 0.1, 0.5))

Please help.  Thanks,
Scott

Scott Waichler, PhD
Pacific Northwest National Laboratory
scott.waichler at pnnl.gov
Richland, Washington, USA


From jdnewmil at dcn.davis.ca.us  Fri Jun 30 02:23:23 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 29 Jun 2017 20:23:23 -0400
Subject: [R] Different date formats in one column
In-Reply-To: <640783066.1613323.1498778736527@mail.yahoo.com>
References: <1220786224.636968.1498677643237.ref@mail.yahoo.com>
 <1220786224.636968.1498677643237@mail.yahoo.com>
 <alpine.BSF.2.00.1706282246450.76660@pedal.dcn.davis.ca.us>
 <640783066.1613323.1498778736527@mail.yahoo.com>
Message-ID: <CDC0D1FE-CAE8-4420-ACDF-6C097470559A@dcn.davis.ca.us>

Left as an exercise for the student. 
-- 
Sent from my phone. Please excuse my brevity.

On June 29, 2017 7:25:36 PM EDT, Farnoosh Sheikhi <farnoosh_81 at yahoo.com> wrote:
>Thanks Jeff. This is a nice way of solving this problem. What about the
>cases with 0015-02-21?Many thanks.?Best,Farnoosh
>
> 
>
>On Wednesday, June 28, 2017 10:49 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
> 
>
> I doubt your actual file looks like the mess that made it to my email 
>software (below) because you posted HTML-format email. Read the Posting
>
>Guide, and in particular figure out how to send plain text email.
>
>You might try the "anytime" contributed package, though I suspect it
>too 
>will choke on your mess. Otherwise, that will pretty much leave only a 
>brute-force series of regular expression tests to recognize which date 
>format patterns you have, and even that may not be able to get them all
>
>right unless you know something that limits the range of possible
>formats.
>
>Below is an example of how this can be done. There are many tutorials
>on 
>the internet that describe regular expressions... they are not unique
>to 
>R.
>
>#-----
>dta <- read.table( text=
>"DtStr
>020917
>2/22/17
>May-2-2015
>May-12-15
>", header=TRUE, as.is=TRUE )
>
>dta$Dt <- as.Date( NA )
>
>idx <- grepl( 
>"^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)-[0-9]+-[0-9]{4}$", 
>dta$DtStr, perl=TRUE, ignore.case = TRUE )
>dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%B-%d-%Y" )
>
>idx <- grepl( 
>"^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)-[0-9]+-[0-9]{2}$", 
>dta$DtStr, perl=TRUE, ignore.case = TRUE )
>dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%B-%d-%y" )
>
>idx <- grepl( "^(0[1-9]|1[0-2])[0-9]{2}[0-9]{2}$", dta$DtStr, perl=TRUE
>)
>dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%m%d%y" )
>
>idx <- grepl( "^([1-9]|1[0-2])/[0-9]{1,2}/[0-9]{2}$", dta$DtStr,
>perl=TRUE 
>)
>dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%m/%d/%y" )
>
>
>On Wed, 28 Jun 2017, Farnoosh Sheikhi via R-help wrote:
>
>> Hi,?
>> I have a data set with various date formats in one column and not
>sure how to unify it.Here is a few formats:
>>
>02091702/22/170221201703/17/160015-08-239/2/1500170806May-2-201522-March-2014
>> I tried parse_date_time from lubridate library but it failed.Thanks
>so much.?Best,Farnoosh
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>---------------------------------------------------------------------------
>Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live
>Go...
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
>Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
>/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.?
>rocks...1k
>---------------------------------------------------------------------------
>
>   


From maitra at email.com  Thu Jun 29 18:15:27 2017
From: maitra at email.com (Ranjan Maitra)
Date: Thu, 29 Jun 2017 11:15:27 -0500
Subject: [R] package to fit mixtures of student-t distributions
In-Reply-To: <11F020B9-9C17-4EBE-BD1A-EEC26589CB93@googlemail.com>
References: <11F020B9-9C17-4EBE-BD1A-EEC26589CB93@googlemail.com>
Message-ID: <20170629111527.8540c03edf6088bebd621e86@email.com>

Would package "teigen" help?

Ranjan

On Thu, 29 Jun 2017 14:41:34 +0200 vare vare via R-help <r-help at r-project.org> wrote:

> Hello!
> 
> I am new to R (before used python exclusively and would actually call the R solution for this issue inside a python notebook, hope that doesn?t disqualify me right of the batch).
> 
> Right now I am  looking for a piece of software  to fit a 1D data sample to a mixture of t-distributions.
> 
> I searched quite a while already and it seems to be that this is a somehwat obscure endeavor as most search results turn up for mixture of gaussians (what I am not interested here).
> 
> The most promising candidates so far are the "AdMit" and "MitSEM" R packages. However I do not know R and find the description of these packages rather comlple and it seems their core objective is not the fitting of mixtures of t?s but instead use this as a step to accomplish something else.
> 
> This is in a nutshell what I want the software to accomplish:
> 
> Fitting a mixture of t-distributions to some data and estimate the "location" "scale" and "degrees of freedom" for each.
> 
> I hope someone can point me to a simple package, I can?t believe that this is such an obscure use case.
> 
> Thanks!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From varevare at googlemail.com  Thu Jun 29 19:02:12 2017
From: varevare at googlemail.com (vare vare)
Date: Thu, 29 Jun 2017 19:02:12 +0200
Subject: [R] package to fit mixtures of student-t distributions
In-Reply-To: <CAGxFJbQWRAKTSADyNan1jYeH-tkp99Xu+5AXw9qN5P+x2kXrpg@mail.gmail.com>
References: <11F020B9-9C17-4EBE-BD1A-EEC26589CB93@googlemail.com>
 <CAGxFJbQWRAKTSADyNan1jYeH-tkp99Xu+5AXw9qN5P+x2kXrpg@mail.gmail.com>
Message-ID: <B62F3548-BD92-4104-9FC8-6FAC75810896@googlemail.com>

I don?t see how neither a) or b) applies to this question nor the technical merit of the remark about  mixture models.

Do you have a suggestion for a more appropriate forum for this issue/question? (stackoverflow basically sent me here).

Kind regards

> On 29. Jun 2017, at 16:58, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Offlist, because this is (a) an opinion and (b) about statistics and
> therefore offtopic.
> 
> I don't know whether any such package exists, but I would predict that
> this is likely to be overdetermined (too many parameters) and
> therefore unlikely to be a successful strategy. Fitting a mixture of
> Gaussians is already difficult enough.
> 
> Feel free to ignore, of course, and no need to reply.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Jun 29, 2017 at 5:41 AM, vare vare via R-help
> <r-help at r-project.org> wrote:
>> Hello!
>> 
>> I am new to R (before used python exclusively and would actually call the R solution for this issue inside a python notebook, hope that doesn?t disqualify me right of the batch).
>> 
>> Right now I am  looking for a piece of software  to fit a 1D data sample to a mixture of t-distributions.
>> 
>> I searched quite a while already and it seems to be that this is a somehwat obscure endeavor as most search results turn up for mixture of gaussians (what I am not interested here).
>> 
>> The most promising candidates so far are the "AdMit" and "MitSEM" R packages. However I do not know R and find the description of these packages rather comlple and it seems their core objective is not the fitting of mixtures of t?s but instead use this as a step to accomplish something else.
>> 
>> This is in a nutshell what I want the software to accomplish:
>> 
>> Fitting a mixture of t-distributions to some data and estimate the "location" "scale" and "degrees of freedom" for each.
>> 
>> I hope someone can point me to a simple package, I can?t believe that this is such an obscure use case.
>> 
>> Thanks!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From anbyrley at buffalo.edu  Thu Jun 29 19:25:38 2017
From: anbyrley at buffalo.edu (Alex Byrley)
Date: Thu, 29 Jun 2017 13:25:38 -0400
Subject: [R] Packages for Learning Algorithm Independent Branch and Bound
 for Feature Selection
Message-ID: <CAJkA6kLsyuSPJaLcqhGfKPf4VpOzXgf-4UNX=WraoOCvVXmHMg@mail.gmail.com>

I am looking for packages that can run a branch-and-bound algorithm to
maximize a distance measure (such as Bhattacharyya or Mahalanobis) on a set
of features.

I would like this to be learning algorithm independent, so that the method
just looks at the features, and selects the subset of a user-defined size
that maximizes a distance criteria such as those stated above.

Can anyone give some suggestions?

Alex Byrley
Graduate Student
Department of Electrical Engineering
235 Davis Hall
(716) 341-1802

	[[alternative HTML version deleted]]


From farnoosh_81 at yahoo.com  Fri Jun 30 01:23:51 2017
From: farnoosh_81 at yahoo.com (Farnoosh Sheikhi)
Date: Thu, 29 Jun 2017 23:23:51 +0000 (UTC)
Subject: [R] Different date formats in one column
In-Reply-To: <8E6292C9-1D6D-4908-A144-CFD38EDB541B@student.unsw.edu.au>
References: <1220786224.636968.1498677643237.ref@mail.yahoo.com>
 <1220786224.636968.1498677643237@mail.yahoo.com>
 <8E6292C9-1D6D-4908-A144-CFD38EDB541B@student.unsw.edu.au>
Message-ID: <69728386.1599208.1498778631219@mail.yahoo.com>

Hi Christoph,
There is "," between dates.Many thanks.?Best,Farnoosh

 

    On Wednesday, June 28, 2017 9:05 PM, Christoph Puschmann <c.puschmann at student.unsw.edu.au> wrote:
 

 Hey,

Are all the dates connected? So no comma or space btw?

Regards,

Christoph

> On 29 Jun 2017, at 2:02 pm, Farnoosh Sheikhi via R-help <r-help at r-project.org> wrote:
> 
> Hi, 
> I have a data set with various date formats in one column and not sure how to unify it.Here is a few formats:
> 02091702/22/170221201703/17/160015-08-239/2/1500170806May-2-201522-March-2014
> I tried parse_date_time from lubridate library but it failed.Thanks so much. Best,Farnoosh
> 
> 
>? ? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From farnoosh_81 at yahoo.com  Fri Jun 30 01:25:36 2017
From: farnoosh_81 at yahoo.com (Farnoosh Sheikhi)
Date: Thu, 29 Jun 2017 23:25:36 +0000 (UTC)
Subject: [R] Different date formats in one column
In-Reply-To: <alpine.BSF.2.00.1706282246450.76660@pedal.dcn.davis.ca.us>
References: <1220786224.636968.1498677643237.ref@mail.yahoo.com>
 <1220786224.636968.1498677643237@mail.yahoo.com>
 <alpine.BSF.2.00.1706282246450.76660@pedal.dcn.davis.ca.us>
Message-ID: <640783066.1613323.1498778736527@mail.yahoo.com>

Thanks Jeff. This is a nice way of solving this problem. What about the cases with 0015-02-21?Many thanks.?Best,Farnoosh

 

    On Wednesday, June 28, 2017 10:49 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
 

 I doubt your actual file looks like the mess that made it to my email 
software (below) because you posted HTML-format email. Read the Posting 
Guide, and in particular figure out how to send plain text email.

You might try the "anytime" contributed package, though I suspect it too 
will choke on your mess. Otherwise, that will pretty much leave only a 
brute-force series of regular expression tests to recognize which date 
format patterns you have, and even that may not be able to get them all 
right unless you know something that limits the range of possible formats.

Below is an example of how this can be done. There are many tutorials on 
the internet that describe regular expressions... they are not unique to 
R.

#-----
dta <- read.table( text=
"DtStr
020917
2/22/17
May-2-2015
May-12-15
", header=TRUE, as.is=TRUE )

dta$Dt <- as.Date( NA )

idx <- grepl( 
"^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)-[0-9]+-[0-9]{4}$", 
dta$DtStr, perl=TRUE, ignore.case = TRUE )
dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%B-%d-%Y" )

idx <- grepl( 
"^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)-[0-9]+-[0-9]{2}$", 
dta$DtStr, perl=TRUE, ignore.case = TRUE )
dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%B-%d-%y" )

idx <- grepl( "^(0[1-9]|1[0-2])[0-9]{2}[0-9]{2}$", dta$DtStr, perl=TRUE )
dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%m%d%y" )

idx <- grepl( "^([1-9]|1[0-2])/[0-9]{1,2}/[0-9]{2}$", dta$DtStr, perl=TRUE 
)
dta$Dt[ idx ] <- as.Date( dta$DtStr[ idx ], format="%m/%d/%y" )


On Wed, 28 Jun 2017, Farnoosh Sheikhi via R-help wrote:

> Hi,?
> I have a data set with various date formats in one column and not sure how to unify it.Here is a few formats:
> 02091702/22/170221201703/17/160015-08-239/2/1500170806May-2-201522-March-2014
> I tried parse_date_time from lubridate library but it failed.Thanks so much.?Best,Farnoosh
>
>
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------

   
	[[alternative HTML version deleted]]


From markleeds2 at gmail.com  Fri Jun 30 03:57:50 2017
From: markleeds2 at gmail.com (Mark Leeds)
Date: Thu, 29 Jun 2017 21:57:50 -0400
Subject: [R] package to fit mixtures of student-t distributions
In-Reply-To: <20170629111527.8540c03edf6088bebd621e86@email.com>
References: <11F020B9-9C17-4EBE-BD1A-EEC26589CB93@googlemail.com>
 <20170629111527.8540c03edf6088bebd621e86@email.com>
Message-ID: <CAHz+bWaG4KS7u0+cNh2Cfaa1FFN40Cn+RMQYJBp8FQQxnq6Dag@mail.gmail.com>

Hi: The R package below may be of use to you.

https://journal.r-project.org/archive/2009-1/RJournal_2009-1_Ardia+et+al.pdf


On Thu, Jun 29, 2017 at 12:15 PM, Ranjan Maitra <maitra at email.com> wrote:

> Would package "teigen" help?
>
> Ranjan
>
> On Thu, 29 Jun 2017 14:41:34 +0200 vare vare via R-help <
> r-help at r-project.org> wrote:
>
> > Hello!
> >
> > I am new to R (before used python exclusively and would actually call
> the R solution for this issue inside a python notebook, hope that doesn?t
> disqualify me right of the batch).
> >
> > Right now I am  looking for a piece of software  to fit a 1D data sample
> to a mixture of t-distributions.
> >
> > I searched quite a while already and it seems to be that this is a
> somehwat obscure endeavor as most search results turn up for mixture of
> gaussians (what I am not interested here).
> >
> > The most promising candidates so far are the "AdMit" and "MitSEM" R
> packages. However I do not know R and find the description of these
> packages rather comlple and it seems their core objective is not the
> fitting of mixtures of t?s but instead use this as a step to accomplish
> something else.
> >
> > This is in a nutshell what I want the software to accomplish:
> >
> > Fitting a mixture of t-distributions to some data and estimate the
> "location" "scale" and "degrees of freedom" for each.
> >
> > I hope someone can point me to a simple package, I can?t believe that
> this is such an obscure use case.
> >
> > Thanks!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Important Notice: This mailbox is ignored: e-mails are set to be deleted
> on receipt. Please respond to the mailing list if appropriate. For those
> needing to send personal or professional e-mail, please use appropriate
> addresses.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Ramgad82 at gmx.net  Fri Jun 30 09:25:15 2017
From: Ramgad82 at gmx.net (Dagmar)
Date: Fri, 30 Jun 2017 09:25:15 +0200
Subject: [R] Unit of cellsize in 'ascgen' from adehabitatMR? Spatialpoints
	unit?
Message-ID: <392bd7a8-1a87-d3ba-1f9f-788ffaea7d69@gmx.net>

Hello dear all,

A simple understanding question but I cannot find the answer anywhere.

I use coordiates (longitude, latitude) in my study. I created a 
SpatialPoints class from those data and then I created a grid using the 
'ascgen' command in the package 'adehabitatMR' like:

ascgen(xy,cellsize=40).

It worked out fine and my analysis is doing great. But I don't know what 
unit the 'cellsize' is. Is it the area (squaremeter), or the length of 
the border of each rastercell (meter)? Or is it some dimension that I 
cannot grasp from a geografical sense? I can't find the information 
anywhere.

Best, Dagmar


From pd.mes at cbs.dk  Fri Jun 30 11:44:29 2017
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Fri, 30 Jun 2017 09:44:29 +0000
Subject: [R] R 3.4.1 is released
Message-ID: <28FA5251-413A-43DE-8DC2-C99398A16063@cbs.dk>

The build system rolled up R-3.4.1.tar.gz (codename "Single Candle") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.4.1.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard



These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = f12a9c3881197b20b08dd3d1f9d005e6
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 8c65d9a0af345a185d3770c9876f1d51
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 4cd5e22f3fffd3525a65acd7d3ed0e28
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 71562183d75dd2080d86c42bbf733bb7
MD5 (R-latest.tar.gz) = 3a79c01dc0527c62e80ffb1c489297ea
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = f60d286bb7294cef00cb0eed4052a66f
MD5 (VERSION-INFO.dcf) = cc04bf1371ce85ec7fb32143692ead4e
MD5 (R-3/R-3.4.1.tar.gz) = 3a79c01dc0527c62e80ffb1c489297ea


6474d9791fff6a74936296bde3fcb569477f5958e4326189bd6e5ab878e0cd4f  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
f0d18e22b9bdfe1dd91547d401b4ef5c8828b2c956a51dc54e7476196b48f87e  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
c732c6ec885f4085ba20ae837ac9bcf2ad0952e61fcf910953bdd8dd2c103d23  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
a10f84be31f897456a31d31690df2fdc3f21a197f28b4d04332cc85005dcd0d2  NEWS.2
shasum: R-2: 
shasum: R-3: Is a directory
02b1135d15ea969a3582caeb95594a05e830a6debcdb5b85ed2d5836a6a3fc78  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
52f934a4e8581945cbc1ba234932749066b5744cbd3b1cb467ba6ef164975163  THANKS
e53d0641f90183fee5b7bec130b77d398634211a111fee3ceefb1536275865be  VERSION-INFO.dcf
02b1135d15ea969a3582caeb95594a05e830a6debcdb5b85ed2d5836a6a3fc78  R-3/R-3.4.1.tar.gz



This is the relevant part of the NEWS file

CHANGES IN R 3.4.1:

 INSTALLATION on a UNIX-ALIKE:

   * The deprecated support for PCRE versions older than 8.20 has been
     removed.

 BUG FIXES:

   * getParseData() gave incorrect column information when code
     contained multi-byte characters.  (PR#17254)

   * Asking for help using expressions like ?stats::cor() did not
     work.  (PR#17250)

   * readRDS(url(....)) now works.

   * R CMD Sweave again returns status = 0 on successful completion.

   * Vignettes listed in .Rbuildignore were not being ignored
     properly.  (PR#17246)

   * file.mtime() no longer returns NA on Windows when the file or
     directory is being used by another process.  This affected
     installed.packages(), which is now protected against this.

   * R CMD INSTALL Windows .zip file obeys --lock and --pkglock flags.

   * (Windows only) The choose.files() function could return incorrect
     results when called with multi = FALSE.  (PR#17270)

   * aggregate(<data.frame>, drop = FALSE) now also works in case of
     near-equal numbers in by.  (PR#16918)

   * fourfoldplot() could encounter integer overflow when calculating
     the odds ratio. (PR#17286)

   * parse() no longer gives spurious warnings when extracting srcrefs
     from a file not encoded in the current locale.

     This was seen from R CMD check with inst/doc/*.R files, and check
     has some additional protection for such files.

   * print.noquote(x) now always returns its argument x (invisibly).

   * Non-UTF-8 multibyte character sets were not handled properly in
     source references.  (PR#16732)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From i.visser at uva.nl  Fri Jun 30 14:36:25 2017
From: i.visser at uva.nl (Ingmar Visser)
Date: Fri, 30 Jun 2017 14:36:25 +0200
Subject: [R] package to fit mixtures of student-t distributions
In-Reply-To: <11F020B9-9C17-4EBE-BD1A-EEC26589CB93@googlemail.com>
References: <11F020B9-9C17-4EBE-BD1A-EEC26589CB93@googlemail.com>
Message-ID: <CABmqZHPg=o1yoRFuzwENczQHAkhYgwyF9Qo3zrULMX4uUcq67Q@mail.gmail.com>

gamlss.mx can fit these I believe (although no experience with these myself)
flexmix may be (relatively easily) adaptable to accomplish this as well
hth, Ingmar

Ingmar Visser
Universitair Hoofddocent ontwikkelingspsychologie | Directeur College
Psychologie
Afdeling Psychologie | Faculteit Maatschappij- en Gedragswetenschappen |
Universiteit van Amsterdam
Bezoek | Nieuwe Achtergracht 129B | Kamer G 1.18
Post | Postbus 15933 | 1001 NK Amsterdam
Pakketpost | Valckenierstraat 59 | 1018 XE Amsterdam
T: +31205256723 | M: +31647260824 | e: i.visser at uva.nl

On Thu, Jun 29, 2017 at 2:41 PM, vare vare via R-help <r-help at r-project.org>
wrote:

> Hello!
>
> I am new to R (before used python exclusively and would actually call the
> R solution for this issue inside a python notebook, hope that doesn?t
> disqualify me right of the batch).
>
> Right now I am  looking for a piece of software  to fit a 1D data sample
> to a mixture of t-distributions.
>
> I searched quite a while already and it seems to be that this is a
> somehwat obscure endeavor as most search results turn up for mixture of
> gaussians (what I am not interested here).
>
> The most promising candidates so far are the "AdMit" and "MitSEM" R
> packages. However I do not know R and find the description of these
> packages rather comlple and it seems their core objective is not the
> fitting of mixtures of t?s but instead use this as a step to accomplish
> something else.
>
> This is in a nutshell what I want the software to accomplish:
>
> Fitting a mixture of t-distributions to some data and estimate the
> "location" "scale" and "degrees of freedom" for each.
>
> I hope someone can point me to a simple package, I can?t believe that this
> is such an obscure use case.
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ahmedatia80 at gmail.com  Fri Jun 30 15:27:05 2017
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Fri, 30 Jun 2017 10:27:05 -0300
Subject: [R] Predict
Message-ID: <CAG6S0O=FY67ejCTv4e_Q8OMNTncZdBHEhESYdj+h=3WPTjxFFQ@mail.gmail.com>

Hi folks,

I have 25 stand height observations over 7 years period and daily
leafbiomass data during this period. I want to use the 25 plant height
observations as inputs and predict the daily stand height during the 7
years.


SH=matrix(data=NA , nrow = 2641, ncol = 1)
for (i in 1:2641) {
  SH<- predict(lm(height~Date, data=Stand_Height));

  dl=leafbiom$Date[i-1];
  de=leafbiom$Date[i];
SH[i]=sum(SH[leafbiom$Date==de&leafbiom$Date==dl])


}
SH


The SH output is the prediction of Stand height in 25 observations
only and provides NA for the remaining 2616 iterations.

Thanks for your help.



Ahmed Attia, Ph.D.
Agronomist & Soil Scientist


From sarah.goslee at gmail.com  Fri Jun 30 15:37:42 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 30 Jun 2017 09:37:42 -0400
Subject: [R] Predict
In-Reply-To: <CAG6S0O=FY67ejCTv4e_Q8OMNTncZdBHEhESYdj+h=3WPTjxFFQ@mail.gmail.com>
References: <CAG6S0O=FY67ejCTv4e_Q8OMNTncZdBHEhESYdj+h=3WPTjxFFQ@mail.gmail.com>
Message-ID: <CAM_vjumQ8wBDfnGXiB==r5U8jc8Sk1c4aU6piNRcPBqCh-GLVA@mail.gmail.com>

There are a bunch of things wrong here, although without a
reproducible example I can't really fix most of them.

- You're overwriting SH within the loop.
- You're running the regression 2641 times, even though the result
never changes.
- You're never predicting from your linear model using the other data
not in the regression.
- Leaf biomass data is never used for anything. I would have thought
that you would use leaf biomass as the predictor variable, not Date.
- I'm not sure why you want the cumulative sum of stand height; that
doesn't make sense to me.

I'm guessing you want:

height.model <- lm(height ~ leafbiomass, data = Stand_Height)
pred.height <- predict(height.model, leafbiom)

# not sure about the reasoning behind this
SH <- cumsum(pred.height)

You don't need a loop. Overwriting SH is the biggest R problem; the
rest of my questions have to do with what your objective actually is,
like what you are modeling and what you are doing with the
predictions. But my sample code might be enough to get you headed in
the right direction regardless.

Sarah

On Fri, Jun 30, 2017 at 9:27 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> Hi folks,
>
> I have 25 stand height observations over 7 years period and daily
> leafbiomass data during this period. I want to use the 25 plant height
> observations as inputs and predict the daily stand height during the 7
> years.
>
>
> SH=matrix(data=NA , nrow = 2641, ncol = 1)
> for (i in 1:2641) {
>   SH<- predict(lm(height~Date, data=Stand_Height));
>
>   dl=leafbiom$Date[i-1];
>   de=leafbiom$Date[i];
> SH[i]=sum(SH[leafbiom$Date==de&leafbiom$Date==dl])
>
>
> }
> SH
>
>
> The SH output is the prediction of Stand height in 25 observations
> only and provides NA for the remaining 2616 iterations.
>
> Thanks for your help.
>
>
>
> Ahmed Attia, Ph.D.
> Agronomist & Soil Scientist
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From chocold12 at gmail.com  Fri Jun 30 16:50:45 2017
From: chocold12 at gmail.com (lily li)
Date: Fri, 30 Jun 2017 08:50:45 -0600
Subject: [R] about reading files in order
In-Reply-To: <CAPCDkROb8T86UxfSonnsaf-FCsZnmEZ6Mppx27YJg9zOeAvvxA@mail.gmail.com>
References: <CAN5afy9ZNOCv+gUFtpFPJMsxgQ6s=C6bWaWYRPLhf8T-QgsPvg@mail.gmail.com>
 <CAPCDkROb8T86UxfSonnsaf-FCsZnmEZ6Mppx27YJg9zOeAvvxA@mail.gmail.com>
Message-ID: <CAN5afy-_gFWjAQVXh=2TcHp5iXCVwp9StwS7je7A4r__udEYoA@mail.gmail.com>

Who is this person and what did he/she mean?

On Fri, Jun 30, 2017 at 1:48 AM, Kindell Young <kyb22 at email.vccs.edu> wrote:

>
> On Jun 29, Silly FAGGOTS DICKS [R] 4 chicks not 18-40 year old dudes with
> no life or reason too still live except wasting our worlds oxygen on
> pathetic excuses of nothings that should eat a bullet for their next meal
> instead of bull SHIT ( although I know they like the taste of shit)  (its a
> favorite of ]r[ist subscribers )
>
> Show quoted text
>
> 15:04, "lily li" <chocold12 at gmail.com> wrote:
> >
> > Hi R users,
> > I have a question about opening the txt files and putting them into a
> > matrix. The txt files are in the folder01, while they have the name
> > file.1.txt, file.2.txt, file.3.txt, etc. There are about 200 such text
> > files. Each txt file contains one value inside. When I tried to use the
> > code below, I found that the txt files are not in order, from 1, 2, 3, to
> > 200. Rather, they are in the order 1, 10, 100, 101, etc. How to change it
> > so that they are in order? Thanks for your help.
> >
> > temp <- list.files('folder01',pattern="*.txt"
> > name.list <-lapply(paste('folder01',temp,sep='/'),read.table,head=F)
> > library(data.table)
> > files.matrix <-rbindlist(name.list)
> >
> > Also, when use the code below, how to complete it so that the values of
> the
> > files are stored in a matrix?
> > lists = list.files('folder01')
> > for (i in 1:length(lists)){
> >   file <- read.table(paste('folder01',lists[i],sep='/'),head=F)
> >   print(file)
> > }
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From ahmedatia80 at gmail.com  Fri Jun 30 17:23:35 2017
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Fri, 30 Jun 2017 12:23:35 -0300
Subject: [R] Predict
In-Reply-To: <CAM_vjumQ8wBDfnGXiB==r5U8jc8Sk1c4aU6piNRcPBqCh-GLVA@mail.gmail.com>
References: <CAG6S0O=FY67ejCTv4e_Q8OMNTncZdBHEhESYdj+h=3WPTjxFFQ@mail.gmail.com>
 <CAM_vjumQ8wBDfnGXiB==r5U8jc8Sk1c4aU6piNRcPBqCh-GLVA@mail.gmail.com>
Message-ID: <CAG6S0O=h4Ckqt==J0qeT+XMuYYX5K-du-TJxS_1+kZWUSeBbJQ@mail.gmail.com>

Sorry for the confusion, here is the edited question.

The data= Stand_Height (attached) is recorded from 12/1/2009 to
12/31/2015 (25 observations) and the other dataset (leafbiom) is
recorded from 10/7/2009 to 12/29/2016 (daily observations).

I want to use the 25 observations of stand height to predict the daily
stand height from 10/7/2009 to 12/29/2016. The daily stand height will
be multiplied by leaf biomass to produce a new variable.

I agree that a loop is not needed, would the forecast library help or
should I use predict library.

Stand_Height=ts(Stand_Height$height,start=2009,end = 2016,
                frequency =365)

plot(forecast(ets(Stand_Height),10))
a=seq(as.Date("2009-12-01"),by="weeks",length=11)
axis(1, at = a, labels = format(a, "%Y %b %d"), cex.axis=0.6)


#Error :$ operator is invalid for atomic vectors

Thanks


Ahmed Attia, Ph.D.
Agronomist & Soil Scientist






On Fri, Jun 30, 2017 at 10:37 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> There are a bunch of things wrong here, although without a
> reproducible example I can't really fix most of them.
>
> - You're overwriting SH within the loop.
> - You're running the regression 2641 times, even though the result
> never changes.
> - You're never predicting from your linear model using the other data
> not in the regression.
> - Leaf biomass data is never used for anything. I would have thought
> that you would use leaf biomass as the predictor variable, not Date.
> - I'm not sure why you want the cumulative sum of stand height; that
> doesn't make sense to me.
>
> I'm guessing you want:
>
> height.model <- lm(height ~ leafbiomass, data = Stand_Height)
> pred.height <- predict(height.model, leafbiom)
>
> # not sure about the reasoning behind this
> SH <- cumsum(pred.height)
>
> You don't need a loop. Overwriting SH is the biggest R problem; the
> rest of my questions have to do with what your objective actually is,
> like what you are modeling and what you are doing with the
> predictions. But my sample code might be enough to get you headed in
> the right direction regardless.
>
> Sarah
>
> On Fri, Jun 30, 2017 at 9:27 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>> Hi folks,
>>
>> I have 25 stand height observations over 7 years period and daily
>> leafbiomass data during this period. I want to use the 25 plant height
>> observations as inputs and predict the daily stand height during the 7
>> years.
>>
>>
>> SH=matrix(data=NA , nrow = 2641, ncol = 1)
>> for (i in 1:2641) {
>>   SH<- predict(lm(height~Date, data=Stand_Height));
>>
>>   dl=leafbiom$Date[i-1];
>>   de=leafbiom$Date[i];
>> SH[i]=sum(SH[leafbiom$Date==de&leafbiom$Date==dl])
>>
>>
>> }
>> SH
>>
>>
>> The SH output is the prediction of Stand height in 25 observations
>> only and provides NA for the remaining 2616 iterations.
>>
>> Thanks for your help.
>>
>>
>>
>> Ahmed Attia, Ph.D.
>> Agronomist & Soil Scientist
>>
> --
> Sarah Goslee
> http://www.functionaldiversity.org

From bgunter.4567 at gmail.com  Fri Jun 30 17:33:41 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 30 Jun 2017 08:33:41 -0700
Subject: [R] Predict
In-Reply-To: <CAG6S0O=h4Ckqt==J0qeT+XMuYYX5K-du-TJxS_1+kZWUSeBbJQ@mail.gmail.com>
References: <CAG6S0O=FY67ejCTv4e_Q8OMNTncZdBHEhESYdj+h=3WPTjxFFQ@mail.gmail.com>
 <CAM_vjumQ8wBDfnGXiB==r5U8jc8Sk1c4aU6piNRcPBqCh-GLVA@mail.gmail.com>
 <CAG6S0O=h4Ckqt==J0qeT+XMuYYX5K-du-TJxS_1+kZWUSeBbJQ@mail.gmail.com>
Message-ID: <CAGxFJbS_A2ij1=ztSyDO0xz=M1KjLXmTWbBGJaCDdv-DhYXRsQ@mail.gmail.com>

Seems like you need to start by learning R. Lots of good online
tutorials exist -- have you spent time with any? And possibly also
spend some time with a basic statistics text or a statistical expert
to clarify your goals and methodology.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 30, 2017 at 8:23 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> Sorry for the confusion, here is the edited question.
>
> The data= Stand_Height (attached) is recorded from 12/1/2009 to
> 12/31/2015 (25 observations) and the other dataset (leafbiom) is
> recorded from 10/7/2009 to 12/29/2016 (daily observations).
>
> I want to use the 25 observations of stand height to predict the daily
> stand height from 10/7/2009 to 12/29/2016. The daily stand height will
> be multiplied by leaf biomass to produce a new variable.
>
> I agree that a loop is not needed, would the forecast library help or
> should I use predict library.
>
> Stand_Height=ts(Stand_Height$height,start=2009,end = 2016,
>                 frequency =365)
>
> plot(forecast(ets(Stand_Height),10))
> a=seq(as.Date("2009-12-01"),by="weeks",length=11)
> axis(1, at = a, labels = format(a, "%Y %b %d"), cex.axis=0.6)
>
>
> #Error :$ operator is invalid for atomic vectors
>
> Thanks
>
>
> Ahmed Attia, Ph.D.
> Agronomist & Soil Scientist
>
>
>
>
>
>
> On Fri, Jun 30, 2017 at 10:37 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> There are a bunch of things wrong here, although without a
>> reproducible example I can't really fix most of them.
>>
>> - You're overwriting SH within the loop.
>> - You're running the regression 2641 times, even though the result
>> never changes.
>> - You're never predicting from your linear model using the other data
>> not in the regression.
>> - Leaf biomass data is never used for anything. I would have thought
>> that you would use leaf biomass as the predictor variable, not Date.
>> - I'm not sure why you want the cumulative sum of stand height; that
>> doesn't make sense to me.
>>
>> I'm guessing you want:
>>
>> height.model <- lm(height ~ leafbiomass, data = Stand_Height)
>> pred.height <- predict(height.model, leafbiom)
>>
>> # not sure about the reasoning behind this
>> SH <- cumsum(pred.height)
>>
>> You don't need a loop. Overwriting SH is the biggest R problem; the
>> rest of my questions have to do with what your objective actually is,
>> like what you are modeling and what you are doing with the
>> predictions. But my sample code might be enough to get you headed in
>> the right direction regardless.
>>
>> Sarah
>>
>> On Fri, Jun 30, 2017 at 9:27 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>>> Hi folks,
>>>
>>> I have 25 stand height observations over 7 years period and daily
>>> leafbiomass data during this period. I want to use the 25 plant height
>>> observations as inputs and predict the daily stand height during the 7
>>> years.
>>>
>>>
>>> SH=matrix(data=NA , nrow = 2641, ncol = 1)
>>> for (i in 1:2641) {
>>>   SH<- predict(lm(height~Date, data=Stand_Height));
>>>
>>>   dl=leafbiom$Date[i-1];
>>>   de=leafbiom$Date[i];
>>> SH[i]=sum(SH[leafbiom$Date==de&leafbiom$Date==dl])
>>>
>>>
>>> }
>>> SH
>>>
>>>
>>> The SH output is the prediction of Stand height in 25 observations
>>> only and provides NA for the remaining 2616 iterations.
>>>
>>> Thanks for your help.
>>>
>>>
>>>
>>> Ahmed Attia, Ph.D.
>>> Agronomist & Soil Scientist
>>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri Jun 30 17:40:55 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 30 Jun 2017 11:40:55 -0400
Subject: [R] about reading files in order
In-Reply-To: <CAN5afy-_gFWjAQVXh=2TcHp5iXCVwp9StwS7je7A4r__udEYoA@mail.gmail.com>
References: <CAN5afy9ZNOCv+gUFtpFPJMsxgQ6s=C6bWaWYRPLhf8T-QgsPvg@mail.gmail.com>
 <CAPCDkROb8T86UxfSonnsaf-FCsZnmEZ6Mppx27YJg9zOeAvvxA@mail.gmail.com>
 <CAN5afy-_gFWjAQVXh=2TcHp5iXCVwp9StwS7je7A4r__udEYoA@mail.gmail.com>
Message-ID: <8E3EF4A6-EF30-412E-B8B9-7D80227A08C1@dcn.davis.ca.us>

See http://en.wikipedia.org/wiki/Internet_troll
-- 
Sent from my phone. Please excuse my brevity.

On June 30, 2017 10:50:45 AM EDT, lily li <chocold12 at gmail.com> wrote:
>Who is this person and what did he/she mean?
>
>On Fri, Jun 30, 2017 at 1:48 AM, Kindell Young <kyb22 at email.vccs.edu>
>wrote:
>
>>
>> On Jun 29, Silly FAGGOTS DICKS [R] 4 chicks not 18-40 year old dudes
>with
>> no life or reason too still live except wasting our worlds oxygen on
>> pathetic excuses of nothings that should eat a bullet for their next
>meal
>> instead of bull SHIT ( although I know they like the taste of shit) 
>(its a
>> favorite of ]r[ist subscribers )
>>
>> Show quoted text
>>
>> 15:04, "lily li" <chocold12 at gmail.com> wrote:
>> >
>> > Hi R users,
>> > I have a question about opening the txt files and putting them into
>a
>> > matrix. The txt files are in the folder01, while they have the name
>> > file.1.txt, file.2.txt, file.3.txt, etc. There are about 200 such
>text
>> > files. Each txt file contains one value inside. When I tried to use
>the
>> > code below, I found that the txt files are not in order, from 1, 2,
>3, to
>> > 200. Rather, they are in the order 1, 10, 100, 101, etc. How to
>change it
>> > so that they are in order? Thanks for your help.
>> >
>> > temp <- list.files('folder01',pattern="*.txt"
>> > name.list
><-lapply(paste('folder01',temp,sep='/'),read.table,head=F)
>> > library(data.table)
>> > files.matrix <-rbindlist(name.list)
>> >
>> > Also, when use the code below, how to complete it so that the
>values of
>> the
>> > files are stored in a matrix?
>> > lists = list.files('folder01')
>> > for (i in 1:length(lists)){
>> >   file <- read.table(paste('folder01',lists[i],sep='/'),head=F)
>> >   print(file)
>> > }
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jun.shen.ut at gmail.com  Fri Jun 30 17:47:23 2017
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Fri, 30 Jun 2017 11:47:23 -0400
Subject: [R] Multiple "scale_color_manual" statements in one plot (ggplot2,
 flexible legend challenge)
Message-ID: <CAMCXXmr=0ta1qy85-0o5BcVw_1n_c=OGEQMWovdQTUr_0EKXVQ@mail.gmail.com>

Dear list,

I am facing an unusual situation where I need to create two sets of legends
based on the color mapping. Can't get exactly what I want and really
appreciate any advice from ggplot experts.

Let's say I have the first dataset "df1" that draws some points and based
on which a "loess" line with confidence interval is added. Then the second
dataset "df2" will produce a line and ribbon.

These are all fine. The challenge is I want to color and shape code the
points and then have two sets of legends, one for the points and one for
the lines. I have tried different ways, so far I can only get the legend
for the points but not for the lines.

Attached the sample code and sample data.

I tried to add "color" arguments to the "geom_smooth" and "geom_line" and
doesn't work. I think the problem is I need to separate the color schemes
for lines and points, but I can't use multiple scale_color_manual statement
in one ggplot.

Jun Shen

####sample data#########
df1 <-  structure(list(Y2 = c(0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L), X = c(27L, 8L,
33L, 53L, 100L, 52L, 9L, 60L, 50L, 10L, 3L, 30L, 50L, 15L, 90L,
48L, 110L, 75L, 72L, 150L, 47L, 30L), GRP = structure(c(3L, 1L,
3L, 4L, 4L, 4L, 1L, 3L, 3L, 1L, 2L, 2L, 2L, 3L, 4L, 4L, 4L, 4L,
4L, 4L, 2L, 4L), .Label = c("1", "2", "3", "4"), class = "factor")), .Names
= c("Y2",
"X", "GRP"), row.names = c(NA, -22L), class = "data.frame")

df2 <-  structure(list(X = c(1L, 10L, 20L, 30L, 40L, 50L, 60L, 70L, 80L,
90L, 100L, 110L, 120L, 130L, 140L, 150L), P025 = c(0.000319,
0.00928, 0.0232, 0.0393, 0.0556, 0.0699, 0.0833, 0.0949, 0.104,
0.113, 0.119, 0.124, 0.129, 0.134, 0.138, 0.144), P50 = c(0.00352,
0.0262, 0.0479, 0.0681, 0.0855, 0.103, 0.118, 0.134, 0.149, 0.164,
0.178, 0.19, 0.202, 0.213, 0.224, 0.234), P975 = c(0.016, 0.0523,
0.0768, 0.0987, 0.119, 0.14, 0.159, 0.178, 0.199, 0.223, 0.247,
0.269, 0.291, 0.312, 0.338, 0.36)), .Names = c("X", "P025", "P50",
"P975"), class = "data.frame", row.names = c(NA, -16L))

####code####
cols.point <- c('1'="#E69F00", '2'="#56B4E9", '3'="#009E73", '4'="#CC79A7")
shape.point <- c('1'=1, '2'=4, '3'=15, '4'=19)

ggplot(data = df1, aes(x=X)) +
  geom_point(aes(y=Y2, color=GRP, shape=GRP, size=1.5)) +
  geom_smooth(aes(y=Y2),  method= 'loess', size=1.5)  +
  geom_line(data=df2, aes(y=P50), size=1.5) +
  geom_ribbon(data=df2,aes(ymin=P025, ymax=P975), alpha=0.2) +
  theme_bw() +
  scale_color_manual(name="",values=cols.point) +
  scale_shape_manual(name="",values=shape.point) +
  guides(color = guide_legend(title='Group', override.aes=list()),
         size = 'none',
         shape = guide_legend(title='Group', override.aes=list(size=2))) +
  theme(legend.position = "top")

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 30 18:11:08 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 30 Jun 2017 09:11:08 -0700
Subject: [R] package to fit mixtures of student-t distributions
In-Reply-To: <B62F3548-BD92-4104-9FC8-6FAC75810896@googlemail.com>
References: <11F020B9-9C17-4EBE-BD1A-EEC26589CB93@googlemail.com>
 <CAGxFJbQWRAKTSADyNan1jYeH-tkp99Xu+5AXw9qN5P+x2kXrpg@mail.gmail.com>
 <B62F3548-BD92-4104-9FC8-6FAC75810896@googlemail.com>
Message-ID: <EB577824-34FF-4A7C-BFDC-1D45C95359AE@comcast.net>


> On Jun 29, 2017, at 10:02 AM, vare vare via R-help <r-help at r-project.org> wrote:
> 
> I don?t see how neither a) or b) applies to this question nor the technical merit of the remark about  mixture models.
> 
> Do you have a suggestion for a more appropriate forum for this issue/question?

CrossValidated.com, although if you frame it in terms of "I need a language specific response", they often will refer questioners back to StackOverflow. There seems to be a widespread aversion to doing people's searching for them. You should read the Posting Guide and the help pages for any online forum you consider posting to. SO has a filter that prevents LMGTFY responses, but Rhelp has no such prohibition.

http://lmgtfy.com/?q=package+to+fit+mixtures+of+student-t+distributions

> (stackoverflow basically sent me here).

I question whether "stackoverflow basically sent me here" in any meaningful sense. There is a response yesterday on StackOverflow from Ben Bolker in which he constructed a working example (which should have been provided by you) and he then illustrated the use of a function from the `teigen` package that seemed to work fairly well. There were not any comments that suggested you should use the rhelp mailing list. You have not commented on, upvoted, or accepted that answer using the mechanisms given to you by the SO people to recognize the answerer's effort or guide the "helping" process.  So one suggestion would be to:

-- show what searching you have done,  (Maybe you really do need methods advice?)

-- and why the suggestions so far are not satisfactory.

-- 
David.


> 
> Kind regards
> 
>> On 29. Jun 2017, at 16:58, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 
>> Offlist, because this is (a) an opinion and (b) about statistics and
>> therefore offtopic.
>> 
>> I don't know whether any such package exists, but I would predict that
>> this is likely to be overdetermined (too many parameters) and
>> therefore unlikely to be a successful strategy. Fitting a mixture of
>> Gaussians is already difficult enough.
>> 
>> Feel free to ignore, of course, and no need to reply.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Thu, Jun 29, 2017 at 5:41 AM, vare vare via R-help
>> <r-help at r-project.org> wrote:
>>> Hello!
>>> 
>>> I am new to R (before used python exclusively and would actually call the R solution for this issue inside a python notebook, hope that doesn?t disqualify me right of the batch).
>>> 
>>> Right now I am  looking for a piece of software  to fit a 1D data sample to a mixture of t-distributions.
>>> 
>>> I searched quite a while already and it seems to be that this is a somehwat obscure endeavor as most search results turn up for mixture of gaussians (what I am not interested here).
>>> 
>>> The most promising candidates so far are the "AdMit" and "MitSEM" R packages. However I do not know R and find the description of these packages rather comlple and it seems their core objective is not the fitting of mixtures of t?s but instead use this as a step to accomplish something else.
>>> 
>>> This is in a nutshell what I want the software to accomplish:
>>> 
>>> Fitting a mixture of t-distributions to some data and estimate the "location" "scale" and "degrees of freedom" for each.
>>> 
>>> I hope someone can point me to a simple package, I can?t believe that this is such an obscure use case.
>>> 
>>> Thanks!
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sarah.goslee at gmail.com  Fri Jun 30 18:13:09 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 30 Jun 2017 12:13:09 -0400
Subject: [R] Predict
In-Reply-To: <CAG6S0O=h4Ckqt==J0qeT+XMuYYX5K-du-TJxS_1+kZWUSeBbJQ@mail.gmail.com>
References: <CAG6S0O=FY67ejCTv4e_Q8OMNTncZdBHEhESYdj+h=3WPTjxFFQ@mail.gmail.com>
 <CAM_vjumQ8wBDfnGXiB==r5U8jc8Sk1c4aU6piNRcPBqCh-GLVA@mail.gmail.com>
 <CAG6S0O=h4Ckqt==J0qeT+XMuYYX5K-du-TJxS_1+kZWUSeBbJQ@mail.gmail.com>
Message-ID: <CAM_vjukwM8wP2B8e=VOOOOnsq91zCKMvQWwB83jH0_sa+Tx0oQ@mail.gmail.com>

Once again, you are over-writing your variable. This time, you are overwriting
the entirety of Stand_Height with the timeseries of height.

Perhaps you should spend some time with one of the good introductory R
resources out there, and think a bit more about your procedure.

Sarah

On Fri, Jun 30, 2017 at 11:23 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> Sorry for the confusion, here is the edited question.
>
> The data= Stand_Height (attached) is recorded from 12/1/2009 to
> 12/31/2015 (25 observations) and the other dataset (leafbiom) is
> recorded from 10/7/2009 to 12/29/2016 (daily observations).
>
> I want to use the 25 observations of stand height to predict the daily
> stand height from 10/7/2009 to 12/29/2016. The daily stand height will
> be multiplied by leaf biomass to produce a new variable.
>
> I agree that a loop is not needed, would the forecast library help or
> should I use predict library.
>
> Stand_Height=ts(Stand_Height$height,start=2009,end = 2016,
>                 frequency =365)
>
> plot(forecast(ets(Stand_Height),10))
> a=seq(as.Date("2009-12-01"),by="weeks",length=11)
> axis(1, at = a, labels = format(a, "%Y %b %d"), cex.axis=0.6)
>
>
> #Error :$ operator is invalid for atomic vectors
>
> Thanks
>
>
> Ahmed Attia, Ph.D.
> Agronomist & Soil Scientist
>
>
>
>
>
>
> On Fri, Jun 30, 2017 at 10:37 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> There are a bunch of things wrong here, although without a
>> reproducible example I can't really fix most of them.
>>
>> - You're overwriting SH within the loop.
>> - You're running the regression 2641 times, even though the result
>> never changes.
>> - You're never predicting from your linear model using the other data
>> not in the regression.
>> - Leaf biomass data is never used for anything. I would have thought
>> that you would use leaf biomass as the predictor variable, not Date.
>> - I'm not sure why you want the cumulative sum of stand height; that
>> doesn't make sense to me.
>>
>> I'm guessing you want:
>>
>> height.model <- lm(height ~ leafbiomass, data = Stand_Height)
>> pred.height <- predict(height.model, leafbiom)
>>
>> # not sure about the reasoning behind this
>> SH <- cumsum(pred.height)
>>
>> You don't need a loop. Overwriting SH is the biggest R problem; the
>> rest of my questions have to do with what your objective actually is,
>> like what you are modeling and what you are doing with the
>> predictions. But my sample code might be enough to get you headed in
>> the right direction regardless.
>>
>> Sarah
>>
>> On Fri, Jun 30, 2017 at 9:27 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>>> Hi folks,
>>>
>>> I have 25 stand height observations over 7 years period and daily
>>> leafbiomass data during this period. I want to use the 25 plant height
>>> observations as inputs and predict the daily stand height during the 7
>>> years.
>>>
>>>
>>> SH=matrix(data=NA , nrow = 2641, ncol = 1)
>>> for (i in 1:2641) {
>>>   SH<- predict(lm(height~Date, data=Stand_Height));
>>>
>>>   dl=leafbiom$Date[i-1];
>>>   de=leafbiom$Date[i];
>>> SH[i]=sum(SH[leafbiom$Date==de&leafbiom$Date==dl])
>>>
>>>
>>> }
>>> SH
>>>
>>>
>>> The SH output is the prediction of Stand height in 25 observations
>>> only and provides NA for the remaining 2616 iterations.
>>>
>>> Thanks for your help.


From dwinsemius at comcast.net  Fri Jun 30 18:27:11 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 30 Jun 2017 09:27:11 -0700
Subject: [R] Predict
In-Reply-To: <CAM_vjukwM8wP2B8e=VOOOOnsq91zCKMvQWwB83jH0_sa+Tx0oQ@mail.gmail.com>
References: <CAG6S0O=FY67ejCTv4e_Q8OMNTncZdBHEhESYdj+h=3WPTjxFFQ@mail.gmail.com>
 <CAM_vjumQ8wBDfnGXiB==r5U8jc8Sk1c4aU6piNRcPBqCh-GLVA@mail.gmail.com>
 <CAG6S0O=h4Ckqt==J0qeT+XMuYYX5K-du-TJxS_1+kZWUSeBbJQ@mail.gmail.com>
 <CAM_vjukwM8wP2B8e=VOOOOnsq91zCKMvQWwB83jH0_sa+Tx0oQ@mail.gmail.com>
Message-ID: <6A9E6617-7B3A-4113-8883-2CFF304BA4AA@comcast.net>


> On Jun 30, 2017, at 9:13 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> Once again, you are over-writing your variable. This time, you are overwriting
> the entirety of Stand_Height with the timeseries of height.
> 
> Perhaps you should spend some time with one of the good introductory R
> resources out there, and think a bit more about your procedure.
> 
> Sarah
> 
> On Fri, Jun 30, 2017 at 11:23 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>> Sorry for the confusion, here is the edited question.
>> 
>> The data= Stand_Height (attached) is recorded from 12/1/2009 to

Also.  Nothing attached made it back to the list readership, although it probably did make it to Sarah Goslee. Attachments should have the file extension `.txt` so that your mail client can give it the proper MIME-type. The only MIME-type that the server accepts for data is 'plain text".

So, .... You should also spend more time reading the Mailing list Info page and the Posting Guide.


-- 
David.

>> 12/31/2015 (25 observations) and the other dataset (leafbiom) is
>> recorded from 10/7/2009 to 12/29/2016 (daily observations).
>> 
>> I want to use the 25 observations of stand height to predict the daily
>> stand height from 10/7/2009 to 12/29/2016. The daily stand height will
>> be multiplied by leaf biomass to produce a new variable.
>> 
>> I agree that a loop is not needed, would the forecast library help or
>> should I use predict library.
>> 
>> Stand_Height=ts(Stand_Height$height,start=2009,end = 2016,
>>                frequency =365)
>> 
>> plot(forecast(ets(Stand_Height),10))
>> a=seq(as.Date("2009-12-01"),by="weeks",length=11)
>> axis(1, at = a, labels = format(a, "%Y %b %d"), cex.axis=0.6)
>> 
>> 
>> #Error :$ operator is invalid for atomic vectors
>> 
>> Thanks
>> 
>> 
>> Ahmed Attia, Ph.D.
>> Agronomist & Soil Scientist
>> 
>> 
>> 
>> 
>> 
>> 
>> On Fri, Jun 30, 2017 at 10:37 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>> There are a bunch of things wrong here, although without a
>>> reproducible example I can't really fix most of them.
>>> 
>>> - You're overwriting SH within the loop.
>>> - You're running the regression 2641 times, even though the result
>>> never changes.
>>> - You're never predicting from your linear model using the other data
>>> not in the regression.
>>> - Leaf biomass data is never used for anything. I would have thought
>>> that you would use leaf biomass as the predictor variable, not Date.
>>> - I'm not sure why you want the cumulative sum of stand height; that
>>> doesn't make sense to me.
>>> 
>>> I'm guessing you want:
>>> 
>>> height.model <- lm(height ~ leafbiomass, data = Stand_Height)
>>> pred.height <- predict(height.model, leafbiom)
>>> 
>>> # not sure about the reasoning behind this
>>> SH <- cumsum(pred.height)
>>> 
>>> You don't need a loop. Overwriting SH is the biggest R problem; the
>>> rest of my questions have to do with what your objective actually is,
>>> like what you are modeling and what you are doing with the
>>> predictions. But my sample code might be enough to get you headed in
>>> the right direction regardless.
>>> 
>>> Sarah
>>> 
>>> On Fri, Jun 30, 2017 at 9:27 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>>>> Hi folks,
>>>> 
>>>> I have 25 stand height observations over 7 years period and daily
>>>> leafbiomass data during this period. I want to use the 25 plant height
>>>> observations as inputs and predict the daily stand height during the 7
>>>> years.
>>>> 
>>>> 
>>>> SH=matrix(data=NA , nrow = 2641, ncol = 1)
>>>> for (i in 1:2641) {
>>>>  SH<- predict(lm(height~Date, data=Stand_Height));
>>>> 
>>>>  dl=leafbiom$Date[i-1];
>>>>  de=leafbiom$Date[i];
>>>> SH[i]=sum(SH[leafbiom$Date==de&leafbiom$Date==dl])
>>>> 
>>>> 
>>>> }
>>>> SH
>>>> 
>>>> 
>>>> The SH output is the prediction of Stand height in 25 observations
>>>> only and provides NA for the remaining 2616 iterations.
>>>> 
>>>> Thanks for your help.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From shineryang1 at gmail.com  Fri Jun 30 18:16:14 2017
From: shineryang1 at gmail.com (Shiner Yang)
Date: Fri, 30 Jun 2017 09:16:14 -0700
Subject: [R] Questions regarding to JohnSonFit() in the R package Johnson
	{SuppDists}
Message-ID: <CAJPWc4E+a0gk_DnEvwcr+iMFNcObbuPjgxWqyksq4UCeQUTQrA@mail.gmail.com>

Hello,

I was trying to fit a Johnson curve by first figuring out the parameter
estimates using JohosnFit of a vector by a group ID using the aggregate
function. I.E.

aggregate(x, by = list(ID), JohnsonFit)

where x is the variable I am trying to perform JohnsonFit on. It is a
continuous random variable. However, I keep getting the following error:

Error in JohnsonFit(x) :
Unbounded solution intermediate values out of range

When I run the fit individually by group ID, it works fine. However I do
not want to do that manually as there are a large number of groups that
would be too laborious to do so.

If possible, could you shed some light on this error?

Thanks!

-- 
Regards,

Shiner Yang
B. Sc Statistics & Economics, Commerce Minor | UBC
Co-President, Science Co-op Students Association

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Jun 30 19:34:58 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 30 Jun 2017 10:34:58 -0700
Subject: [R] Questions regarding to JohnSonFit() in the R package
	Johnson {SuppDists}
In-Reply-To: <CAJPWc4E+a0gk_DnEvwcr+iMFNcObbuPjgxWqyksq4UCeQUTQrA@mail.gmail.com>
References: <CAJPWc4E+a0gk_DnEvwcr+iMFNcObbuPjgxWqyksq4UCeQUTQrA@mail.gmail.com>
Message-ID: <CAF8bMcYkFkJ1JxZFi4npOV_p9VKmfU3kPpC7XS6pMNSUg4mekA@mail.gmail.com>

This happens for some inputs, e.g.,
   > JohnsonFit(c(2,3,4,5,6,7,8,30,50,300))
   Error in JohnsonFit(c(2, 3, 4, 5, 6, 7, 8, 30, 50, 300)) :
   Unbounded solution intermediate values out of range
The usual recommendation is to contact the maintainer of the package but
that isn't possible in this case
   > maintainer("SuppDists")
   [1] "ORPHANED"

You can work around the problem to some extent by replacing
   JohnsonFit
with a function that detects errrors in JohnsonFit and returns an indicator
that JohnsonFit fails and lets you move on to the next subset of data.
E.g.,
   function(x) tryCatch(JohnsonFit(x),
                                    error=function(e)
structure(conditionMessage(e), x=x))


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jun 30, 2017 at 9:16 AM, Shiner Yang <shineryang1 at gmail.com> wrote:

> Hello,
>
> I was trying to fit a Johnson curve by first figuring out the parameter
> estimates using JohosnFit of a vector by a group ID using the aggregate
> function. I.E.
>
> aggregate(x, by = list(ID), JohnsonFit)
>
> where x is the variable I am trying to perform JohnsonFit on. It is a
> continuous random variable. However, I keep getting the following error:
>
> Error in JohnsonFit(x) :
> Unbounded solution intermediate values out of range
>
> When I run the fit individually by group ID, it works fine. However I do
> not want to do that manually as there are a large number of groups that
> would be too laborious to do so.
>
> If possible, could you shed some light on this error?
>
> Thanks!
>
> --
> Regards,
>
> Shiner Yang
> B. Sc Statistics & Economics, Commerce Minor | UBC
> Co-President, Science Co-op Students Association
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Jun 30 15:25:55 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 30 Jun 2017 15:25:55 +0200
Subject: [R] The R Journal, Volume 9, Issue 1
Message-ID: <alpine.LFD.2.20.1706301522210.21338@reclus.nhh.no>

Dear all,

The latest issue of The R Journal is now available at:

https://journal.r-project.org/archive/2017-1/.

Many thanks to all contributors - especially reviewers and authors.

Regards,
Bettina

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


