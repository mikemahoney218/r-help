From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Dec  1 01:04:46 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 1 Dec 2019 13:04:46 +1300
Subject: [R] Adding a legend to a (multi-facet) plot produced by ggplot().
Message-ID: <8be97862-5230-6b7d-362f-95b0580893f5@auckland.ac.nz>


I have been struggling to add a legend as indicated in the subject line,
with no success at all.  I find the help to be completely bewildering.

I have attached the code of what I have tried in the context of a simple
reproducible example.

I have also attached a pdf file of a plot produced with base graphics to 
illustrate roughly what I am after.

I would be grateful if someone could point me in the right direction.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: reprex.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20191201/38741f81/attachment.txt>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: whatIwant.pdf
Type: application/pdf
Size: 6661 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20191201/38741f81/attachment.pdf>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Dec  1 15:03:12 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 1 Dec 2019 14:03:12 +0000
Subject: [R] 
 Adding a legend to a (multi-facet) plot produced by ggplot().
In-Reply-To: <8be97862-5230-6b7d-362f-95b0580893f5@auckland.ac.nz>
References: <8be97862-5230-6b7d-362f-95b0580893f5@auckland.ac.nz>
Message-ID: <7c191087-cab3-9291-365b-79d194065a55@sapo.pt>

Hello,

See if this is it. The standard trick is to reshape the data from wide 
to long, see the SO post [1]. Then add a scale_shape_* layer to the plot.


yyy <- cbind(xxx, y3 = y3)
long <- reshape2::melt(yyy, id.vars = c("x", "y1", "grp"))

ggplot(long, aes(x, y = value, colour = variable, shape = variable)) +
   geom_line(aes(y = y1)) +
   geom_point() +
   scale_colour_manual("Doesn't work",values=c("blue","red"),
                       labels=c("clyde","irving")) +
   scale_shape_manual("Doesn't work",values=c(16,3),
                       labels=c("clyde","irving")) +

   facet_grid(cols=vars(grp))


[1] 
https://stackoverflow.com/questions/2185252/reshaping-data-frame-from-wide-to-long-format

Hope this helps,

Rui Barradas

?s 00:04 de 01/12/19, Rolf Turner escreveu:
> 
> I have been struggling to add a legend as indicated in the subject line,
> with no success at all.? I find the help to be completely bewildering.
> 
> I have attached the code of what I have tried in the context of a simple
> reproducible example.
> 
> I have also attached a pdf file of a plot produced with base graphics to 
> illustrate roughly what I am after.
> 
> I would be grateful if someone could point me in the right direction.
> 
> cheers,
> 
> Rolf Turner
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From je||rey@pu|||n @end|ng |rom gm@||@com  Sun Dec  1 03:35:03 2019
From: je||rey@pu|||n @end|ng |rom gm@||@com (Jeffrey Pullin)
Date: Sun, 1 Dec 2019 13:35:03 +1100
Subject: [R] 
 Adding a legend to a (multi-facet) plot produced by ggplot().
Message-ID: <CADDC+2daKDAhWv1GaVRiTmGwrP3V4R0Js41nzNZT=-j=rC=6mQ@mail.gmail.com>

Hi Rolf,

Some code to produce the plot you want is here:

https://gist.github.com/jeffreypullin/be752f11a136601ffecddc73ba0519b9

Hope you find it helpful.

Personally I have found that the key to effective ggplot2 use is getting
your data into the right format (one data.frame, tidy style) before you plot
it.

Cheers
Jeffrey

	[[alternative HTML version deleted]]


From unw|n @end|ng |rom m@th@un|-@ug@burg@de  Sun Dec  1 16:48:41 2019
From: unw|n @end|ng |rom m@th@un|-@ug@burg@de (Antony Unwin)
Date: Sun, 1 Dec 2019 16:48:41 +0100
Subject: [R] 
 Adding a legend to a (multi-facet) plot produced by ggplot().
Message-ID: <75B199E1-2219-4F05-94C4-C1D4174D03C7@math.uni-augsburg.de>

How about defining your dataset differently, making the colouring property a variable?

xxx <- data.frame(x=rep(x, 4), y=c(y2, y3), grp=factor(rep(c("a","b"),each=20, times=2)), type=factor(rep(c("clyde", "irving"), each=40)))
ggplot(xxx, aes(x,y, colour=type, shape=type)) + geom_point() + geom_abline(intercept=3, slope=2) + facet_wrap(vars(grp)) + scale_colour_manual(values=c("blue", "red"))  + scale_shape_manual(values=c(20,3))

Then you could also plot the four groups separately if you wanted to:

ggplot(xxx, aes(x,y, colour=type, shape=type)) + geom_point() + geom_abline(intercept=3, slope=2) + facet_grid(rows=vars(type), cols=vars(grp)) + scale_colour_manual(values=c("blue", "red"))  + scale_shape_manual(values=c(20,3))

Antony Unwin
University of Augsburg, 
Germany




> From: Rolf Turner <r.turner at auckland.ac.nz>
> Subject: [R] Adding a legend to a (multi-facet) plot produced by ggplot().
> Date: 1 December 2019 at 01:04:46 CET
> To: R help <R-help at r-project.org>
> 
> 
> 
> I have been struggling to add a legend as indicated in the subject line,
> with no success at all.  I find the help to be completely bewildering.
> 
> I have attached the code of what I have tried in the context of a simple
> reproducible example.
> 
> I have also attached a pdf file of a plot produced with base graphics to illustrate roughly what I am after.
> 
> I would be grateful if someone could point me in the right direction.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276

From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Dec  1 12:46:15 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 2 Dec 2019 00:46:15 +1300
Subject: [R] Still struggling with facet_grid_paginate() from package
 ggforce.
Message-ID: <87c21057-b345-3764-0f74-e03682165dce@auckland.ac.nz>


I am trying to produce a ggplot2 graphic in which there is a single 
conditioning variable with a large number of levels (24).

If I use facet_grid() I get a plot with either 24 rows or 24 columns,
both of which look like hell.

I thought that facet_grid_paginate() would rescue me, but it doesn't 
seem to.  I ask for 3 rows and 4 columns, and thought that I would get 
two 3 x 4 pages  Instead I get six pages with only one row (of four 
facets) per page.

Am I misunderstanding something?  Doing something silly?  Or is this a bug?

I have attached a reproducible example, along with the data set on which 
it depends.

Grateful for any insight.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: reprex.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20191202/bd4728db/attachment.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: egDat.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20191202/bd4728db/attachment-0001.txt>

From bur@k@ym@kc| @end|ng |rom gm@||@com  Sun Dec  1 14:33:16 2019
From: bur@k@ym@kc| @end|ng |rom gm@||@com (Burak Kaymakci)
Date: Sun, 1 Dec 2019 16:33:16 +0300
Subject: [R] How to use preProcess in Caret?
Message-ID: <CAMEVu8gsekqn=m79JKCnrcCfCxM15U2wJfu640GoO9BSrsj31w@mail.gmail.com>

Hello there,

I am using caret and neuralnet to train a neural network to predict times
table. I am using 'backprop' algorithm for neuralnet to experiment and
learn.

Before using caret, I've trained a neuralnet without using caret, I've
normalized my input & outputs using preProcess with 'range' method. Then I
predicted my test set, did the multiplication and addition on predictions
to get the real values. It gave me good results.

What I want to ask is, when I try to train my network using caret, I get an
error saying algorithm did not converge. I am thinking that I might be
doing something wrong with my pre-processing,

How would I go about using preProcess in train?
Do I pass my not-normalized data set to the train function and train
function handles normalization internally?

You can find my R gist here
<https://gist.github.com/andreyuhai/f299282f5a827e2a27c586afc9eb4eb5>

Thank you,
Burak

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Dec  1 22:45:53 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 1 Dec 2019 21:45:53 +0000
Subject: [R] Still struggling with facet_grid_paginate() from package
 ggforce.
In-Reply-To: <87c21057-b345-3764-0f74-e03682165dce@auckland.ac.nz>
References: <87c21057-b345-3764-0f74-e03682165dce@auckland.ac.nz>
Message-ID: <d7b6b0f6-600d-8202-04d2-99f288c9f7c7@sapo.pt>

Hello,

Here are two ways.

The first is an adaptation from your code. It uses facet_wrap_paginate, 
not *_grid_*.


plotObj2 <- vector("list",2)
for(pg in 1:2) {
   plotObj2[[pg]] <- ggplot(egDat) +
     geom_point(aes(y = obsd, x = x),
                na.rm = TRUE, shape = 20, colour = "blue") +
     geom_line(aes(y = fit2, x = cPred)) +
     facet_wrap_paginate(facets = ~Trt,
                         ncol = 4, nrow = 3, page = pg) +
     theme_bw()
}
print(plotObj2)


The second is an adaptation of SO[1]. It needs two calls to the plot 
code and it's slower but gets the job done.


g <- ggplot(egDat) +
   geom_point(aes(y = obsd, x = x),
              na.rm = TRUE, shape = 20, colour = "blue") +
   geom_line(aes(y = fit2, x = cPred)) +
   facet_wrap_paginate(facets = ~Trt, ncol = 4, nrow = 3, page = 1) +
   theme_bw()

n <- n_pages(g)
for(i in 1:n){
   print(g + facet_wrap_paginate(~Trt, ncol = 4, nrow = 3, page = i))
}

print(g)



Hope this helps,

Rui Barradas


[1] https://stackoverflow.com/a/58373858/8245406


?s 11:46 de 01/12/19, Rolf Turner escreveu:
> 
> I am trying to produce a ggplot2 graphic in which there is a single 
> conditioning variable with a large number of levels (24).
> 
> If I use facet_grid() I get a plot with either 24 rows or 24 columns,
> both of which look like hell.
> 
> I thought that facet_grid_paginate() would rescue me, but it doesn't 
> seem to.? I ask for 3 rows and 4 columns, and thought that I would get 
> two 3 x 4 pages? Instead I get six pages with only one row (of four 
> facets) per page.
> 
> Am I misunderstanding something?? Doing something silly?? Or is this a bug?
> 
> I have attached a reproducible example, along with the data set on which 
> it depends.
> 
> Grateful for any insight.
> 
> cheers,
> 
> Rolf Turner
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Dec  2 02:07:05 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 2 Dec 2019 14:07:05 +1300
Subject: [R] 
 Adding a legend to a (multi-facet) plot produced by ggplot().
In-Reply-To: <7c191087-cab3-9291-365b-79d194065a55@sapo.pt>
References: <8be97862-5230-6b7d-362f-95b0580893f5@auckland.ac.nz>
 <7c191087-cab3-9291-365b-79d194065a55@sapo.pt>
Message-ID: <6419b5fc-0021-086c-6b28-9e79ead15c5b@auckland.ac.nz>


On 2/12/19 3:03 am, Rui Barradas wrote:

> Hello,
> 
> See if this is it. The standard trick is to reshape the data from wide 
> to long, see the SO post [1]. Then add a scale_shape_* layer to the plot.
> 
> 
> yyy <- cbind(xxx, y3 = y3)
> long <- reshape2::melt(yyy, id.vars = c("x", "y1", "grp"))
> 
> ggplot(long, aes(x, y = value, colour = variable, shape = variable)) +
>  ? geom_line(aes(y = y1)) +
>  ? geom_point() +
>  ? scale_colour_manual("Doesn't work",values=c("blue","red"),
>  ????????????????????? labels=c("clyde","irving")) +
>  ? scale_shape_manual("Doesn't work",values=c(16,3),
>  ????????????????????? labels=c("clyde","irving")) +
> 
>  ? facet_grid(cols=vars(grp))
> 
> 
> [1] 
> https://stackoverflow.com/questions/2185252/reshaping-data-frame-from-wide-to-long-format 
> 
> 
> Hope this helps,

Almost there.  However the colour of the line changes with "values" and 
lines show up in the legend.  I want the lines to be black in all 
facets, and only points to show up in the legend.

I fiddled about a bit trying to achieve this but only succeeded in 
messing things up completely.

Can you guide me a bit further, please?

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Dec  2 01:45:00 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 2 Dec 2019 13:45:00 +1300
Subject: [R] Still struggling with facet_grid_paginate() from package
 ggforce.
In-Reply-To: <d7b6b0f6-600d-8202-04d2-99f288c9f7c7@sapo.pt>
References: <87c21057-b345-3764-0f74-e03682165dce@auckland.ac.nz>
 <d7b6b0f6-600d-8202-04d2-99f288c9f7c7@sapo.pt>
Message-ID: <778ebbbe-a028-1cba-fabe-92ee33c36c32@auckland.ac.nz>


On 2/12/19 10:45 am, Rui Barradas wrote:

> Hello,
> 
> Here are two ways.
> 
> The first is an adaptation from your code. It uses facet_wrap_paginate, 
> not *_grid_*.
> 
> 
> plotObj2 <- vector("list",2)
> for(pg in 1:2) {
>  ? plotObj2[[pg]] <- ggplot(egDat) +
>  ??? geom_point(aes(y = obsd, x = x),
>  ?????????????? na.rm = TRUE, shape = 20, colour = "blue") +
>  ??? geom_line(aes(y = fit2, x = cPred)) +
>  ??? facet_wrap_paginate(facets = ~Trt,
>  ??????????????????????? ncol = 4, nrow = 3, page = pg) +
>  ??? theme_bw()
> }
> print(plotObj2)
> 
> 
> The second is an adaptation of SO[1]. It needs two calls to the plot 
> code and it's slower but gets the job done.
> 
> 
> g <- ggplot(egDat) +
>  ? geom_point(aes(y = obsd, x = x),
>  ???????????? na.rm = TRUE, shape = 20, colour = "blue") +
>  ? geom_line(aes(y = fit2, x = cPred)) +
>  ? facet_wrap_paginate(facets = ~Trt, ncol = 4, nrow = 3, page = 1) +
>  ? theme_bw()
> 
> n <- n_pages(g)
> for(i in 1:n){
>  ? print(g + facet_wrap_paginate(~Trt, ncol = 4, nrow = 3, page = i))
> }
> 
> print(g)
> 
> 
> 
> Hope this helps.

Indeed it did.  You are brilliant, Rui. Problem solved.

I note that one can, I think, calculate the number of pages a priori,
thus avoiding two calls to ggplot(), in something like the following manner:

nface <- with(Dat,prod(sapply(condVars,
                        function(x){length(levels(get(x)))})))

npgs  <- ceiling(nface/(nrow*ncol))

where Dat is the data frame of data being plotted and condVars is a 
vector of the names of the variables being conditioned on (i.e. the 
variables determining the facets).  In the example that I provided,
condVars would just be "Trt", but it all seems to work in settings in 
which there is more than one conditioning variable.

Thanks very much.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Dec  2 05:19:24 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 2 Dec 2019 17:19:24 +1300
Subject: [R] 
 Adding a legend to a (multi-facet) plot produced by ggplot().
In-Reply-To: <d10651bf-ee45-8242-62c8-252d2782d352@sapo.pt>
References: <8be97862-5230-6b7d-362f-95b0580893f5@auckland.ac.nz>
 <7c191087-cab3-9291-365b-79d194065a55@sapo.pt>
 <6419b5fc-0021-086c-6b28-9e79ead15c5b@auckland.ac.nz>
 <d10651bf-ee45-8242-62c8-252d2782d352@sapo.pt>
Message-ID: <c0611f69-8bef-d597-f551-706b8c47093b@auckland.ac.nz>

On 2/12/19 5:08 pm, Rui Barradas wrote:
> Hello,
> 
> Here are two ways of drawing the lines black and at the same time 
> removing the lines in the legend. The second way is more idiomatic.
> 
> 
> 1. Override the colour setting in the ggplot call when drawing the lines:
> 
> geom_line(aes(y = y1), colour = "black") +
> 
> 
> 2. Don't set the colour aesthetic in the initial ggplot call. It will be 
> needed only to draw the points, so set it in geom_point(). Though it 
> doesn't influence the lines' colour and the lines in the legend, the 
> same principle applies to shape = variable so I have moved it to 
> geom_point().
> 
> The complete instruction becomes:
> 
> 
> ggplot(long, aes(x, y = value)) +
>  ? geom_line(aes(y = y1)) +
>  ? geom_point(aes(colour = variable, shape = variable)) +
>  ? scale_colour_manual("Doesn't work",values=c("blue","red"),
>  ????????????????????? labels=c("clyde","irving")) +
>  ? scale_shape_manual("Doesn't work",values=c(16,3),
>  ???????????????????? labels=c("clyde","irving")) +
> 
>  ? facet_grid(cols=vars(grp))
> 
> 
> 
> Hope this helps.

Boy did it *ever*!!!  Perfect. Thank you *HUGELY*!!!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Dec  2 05:08:02 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 2 Dec 2019 04:08:02 +0000
Subject: [R] 
 Adding a legend to a (multi-facet) plot produced by ggplot().
In-Reply-To: <6419b5fc-0021-086c-6b28-9e79ead15c5b@auckland.ac.nz>
References: <8be97862-5230-6b7d-362f-95b0580893f5@auckland.ac.nz>
 <7c191087-cab3-9291-365b-79d194065a55@sapo.pt>
 <6419b5fc-0021-086c-6b28-9e79ead15c5b@auckland.ac.nz>
Message-ID: <d10651bf-ee45-8242-62c8-252d2782d352@sapo.pt>

Hello,

Here are two ways of drawing the lines black and at the same time 
removing the lines in the legend. The second way is more idiomatic.


1. Override the colour setting in the ggplot call when drawing the lines:

geom_line(aes(y = y1), colour = "black") +


2. Don't set the colour aesthetic in the initial ggplot call. It will be 
needed only to draw the points, so set it in geom_point(). Though it 
doesn't influence the lines' colour and the lines in the legend, the 
same principle applies to shape = variable so I have moved it to 
geom_point().

The complete instruction becomes:


ggplot(long, aes(x, y = value)) +
   geom_line(aes(y = y1)) +
   geom_point(aes(colour = variable, shape = variable)) +
   scale_colour_manual("Doesn't work",values=c("blue","red"),
                       labels=c("clyde","irving")) +
   scale_shape_manual("Doesn't work",values=c(16,3),
                      labels=c("clyde","irving")) +

   facet_grid(cols=vars(grp))



Hope this helps,

Rui Barradas


?s 01:07 de 02/12/19, Rolf Turner escreveu:
> 
> On 2/12/19 3:03 am, Rui Barradas wrote:
> 
>> Hello,
>>
>> See if this is it. The standard trick is to reshape the data from wide 
>> to long, see the SO post [1]. Then add a scale_shape_* layer to the plot.
>>
>>
>> yyy <- cbind(xxx, y3 = y3)
>> long <- reshape2::melt(yyy, id.vars = c("x", "y1", "grp"))
>>
>> ggplot(long, aes(x, y = value, colour = variable, shape = variable)) +
>> ?? geom_line(aes(y = y1)) +
>> ?? geom_point() +
>> ?? scale_colour_manual("Doesn't work",values=c("blue","red"),
>> ?????????????????????? labels=c("clyde","irving")) +
>> ?? scale_shape_manual("Doesn't work",values=c(16,3),
>> ?????????????????????? labels=c("clyde","irving")) +
>>
>> ?? facet_grid(cols=vars(grp))
>>
>>
>> [1] 
>> https://stackoverflow.com/questions/2185252/reshaping-data-frame-from-wide-to-long-format 
>>
>>
>> Hope this helps,
> 
> Almost there.? However the colour of the line changes with "values" and 
> lines show up in the legend.? I want the lines to be black in all 
> facets, and only points to show up in the legend.
> 
> I fiddled about a bit trying to achieve this but only succeeded in 
> messing things up completely.
> 
> Can you guide me a bit further, please?
> 
> cheers,
> 
> Rolf
>


From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Tue Dec  3 10:18:01 2019
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Tue, 3 Dec 2019 10:18:01 +0100
Subject: [R] Two geom_bar with counts to put in the same plot
Message-ID: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>

Dear Contributors,
I would like to ask help on how to create a  plot that is the overlapping
of two other plots.
It is a geom_bar structure, where I want to count the occurrences of two
variables, participation1 and participation2 that I recoded as factors as
ParticipationNOPUN and ParticipationPUN to have nice names in the legend.
The variables to "count" in the two plots are delta11_L and delta2_L
These are my data and code to create the two plots. I would like to put
them in the same plot as superimposed areas so that I see the change in the
distribution of counts in the two cases.
This is DB:

participation1 participation2 ParticipantsNOPUN ParticipantsPUN delta11_L
delta2_L
  [1,]              1              1                 2               2
    0        0
  [2,]              1              1                 2               2
  -10      -10
  [3,]              1              1                 2               2
  -10        0
  [4,]              1              1                 2               2
    0        0
  [5,]              1              1                 2               2
    0        0
  [6,]              1              1                 2               2
    0        0
  [7,]              1              0                 2               1
  -30       30
  [8,]              1              1                 2               2
    0       10
  [9,]              1              0                 2               1
   10       40
 [10,]              1              1                 2               2
    0        0
 [11,]              0              0                 1               1
   20        0
 [12,]              1              1                 2               2
   10        0
 [13,]              1              1                 2               2
    0        0
 [14,]              1              1                 2               2
    0        0
 [15,]              1              1                 2               2
   20       10
 [16,]              1              1                 2               2
    0        0
 [17,]              1              1                 2               2
    0        0
 [18,]              1              1                 2               2
  -10       30
 [19,]              0              0                 1               1
   30       10
 [20,]              1              1                 2               2
   10       10
 [21,]              1              1                 2               2
    0        0
 [22,]              1              1                 2               2
    0        0
 [23,]              1              1                 2               2
    0      -10
 [24,]              1              1                 2               2
    0      -20
 [25,]              1              1                 2               2
   10      -10
 [26,]              1              1                 2               2
    0        0
 [27,]              1              1                 2               2
    0        0

First PLOT(I need to subset the data to eliminate some NA. NB: the two
dataframes end up not having the same number of rows for this reason):

ggplot(data=subset(DB, !is.na(participation1)), aes(x = delta11_L, fill
=ParticipantsNOPUN))+
         geom_bar(position = "dodge")+ theme_bw(base_size = 12) +
labs(x="Delta Contributions (PGG w/out punishment)")+
  theme(legend.position = "top",legend.title = element_blank())
+scale_fill_brewer(palette="Set1")

Second PLOT:

 ggplot(DB, aes(x = delta2_L, fill =ParticipantsPUN)  , aes(x = delta2_L,
fill =ParticipantsPUN))+
  geom_bar(position = "dodge")+ theme_bw(base_size = 12) + labs(x="Delta
Contributions (PGG w/punishment)")+
  theme(legend.position = "top",legend.title = element_blank())
+scale_fill_brewer(palette="Set1")



is it possible to create a density plot of the two counts data on the same
plot?
Do I need to create a variable count or long data format?
Thanks

	[[alternative HTML version deleted]]


From vodvo@ @end|ng |rom zoho@com  Tue Dec  3 13:09:12 2019
From: vodvo@ @end|ng |rom zoho@com (vod vos)
Date: Tue, 03 Dec 2019 04:09:12 -0800
Subject: [R] How to find the best fit of inner cut ellipse to points in
 polar plot?
Message-ID: <16ecbaa186c.10276a62e1034.5455362847641034762@zoho.com>

hi,

1. How to find the best fit of  inner cut ellipse to points in polar plot?

2. How can we find the ellipse passing through  most of the points in polar plot?

And can we get the center x, center y, major radius, minor radius, and rotation angle of the ellipse?

The csv data is attached.

Thanks.

From vodvo@ @end|ng |rom zoho@com  Tue Dec  3 13:35:16 2019
From: vodvo@ @end|ng |rom zoho@com (vod vos)
Date: Tue, 03 Dec 2019 04:35:16 -0800
Subject: [R] =?utf-8?b?5Zue5aSNOkhvdyB0byBmaW5kIHRoZSBiZXN0IGZpdCBvZiAg?=
 =?utf-8?q?inner_cut_ellipse_to_points_in_polar_plot=3F?=
In-Reply-To: <16ecbaa186c.10276a62e1034.5455362847641034762@zoho.com>
References: <16ecbaa186c.10276a62e1034.5455362847641034762@zoho.com>
Message-ID: <16ecbc1f6dc.e3ed5bf11441.3412535460238780222@zoho.com>




 ---- ? ???, 03 ??? 2019 04:09:12 -0800 vod vos <vodvos at zoho.com> ?? ----
 > hi,
 > 
 > 1. How to find the best fit of  inner cut ellipse to points in polar plot?
 > 
 > 2. How can we find the ellipse passing through  most of the points in polar plot?
 > 
 > And can we get the center x, center y, major radius, minor radius, and rotation angle of the ellipse?
 > 
 > The csv data is attached.
 > 
 > Thanks.

We need just consider the r and theta columns in polar coordinate.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Dec  3 15:03:32 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 3 Dec 2019 14:03:32 +0000
Subject: [R] Two geom_bar with counts to put in the same plot
In-Reply-To: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>
References: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>
Message-ID: <44f89f64-08c8-617c-8de5-9425e9b57f51@sapo.pt>

Hello,

Please post the output of

dput(DB)

in a next e-mail to R-Help, like this it's difficult for us to use the 
data you posted.

And yes, I bet you will need the data in long format. It is a frequent 
first step to the problem of plotting two or more columns in the same 
graph. To say more only with data.


Hope this helps,

Rui Barradas

?s 09:18 de 03/12/19, Francesca escreveu:
> Dear Contributors,
> I would like to ask help on how to create a  plot that is the overlapping
> of two other plots.
> It is a geom_bar structure, where I want to count the occurrences of two
> variables, participation1 and participation2 that I recoded as factors as
> ParticipationNOPUN and ParticipationPUN to have nice names in the legend.
> The variables to "count" in the two plots are delta11_L and delta2_L
> These are my data and code to create the two plots. I would like to put
> them in the same plot as superimposed areas so that I see the change in the
> distribution of counts in the two cases.
> This is DB:
> 
> participation1 participation2 ParticipantsNOPUN ParticipantsPUN delta11_L
> delta2_L
>    [1,]              1              1                 2               2
>      0        0
>    [2,]              1              1                 2               2
>    -10      -10
>    [3,]              1              1                 2               2
>    -10        0
>    [4,]              1              1                 2               2
>      0        0
>    [5,]              1              1                 2               2
>      0        0
>    [6,]              1              1                 2               2
>      0        0
>    [7,]              1              0                 2               1
>    -30       30
>    [8,]              1              1                 2               2
>      0       10
>    [9,]              1              0                 2               1
>     10       40
>   [10,]              1              1                 2               2
>      0        0
>   [11,]              0              0                 1               1
>     20        0
>   [12,]              1              1                 2               2
>     10        0
>   [13,]              1              1                 2               2
>      0        0
>   [14,]              1              1                 2               2
>      0        0
>   [15,]              1              1                 2               2
>     20       10
>   [16,]              1              1                 2               2
>      0        0
>   [17,]              1              1                 2               2
>      0        0
>   [18,]              1              1                 2               2
>    -10       30
>   [19,]              0              0                 1               1
>     30       10
>   [20,]              1              1                 2               2
>     10       10
>   [21,]              1              1                 2               2
>      0        0
>   [22,]              1              1                 2               2
>      0        0
>   [23,]              1              1                 2               2
>      0      -10
>   [24,]              1              1                 2               2
>      0      -20
>   [25,]              1              1                 2               2
>     10      -10
>   [26,]              1              1                 2               2
>      0        0
>   [27,]              1              1                 2               2
>      0        0
> 
> First PLOT(I need to subset the data to eliminate some NA. NB: the two
> dataframes end up not having the same number of rows for this reason):
> 
> ggplot(data=subset(DB, !is.na(participation1)), aes(x = delta11_L, fill
> =ParticipantsNOPUN))+
>           geom_bar(position = "dodge")+ theme_bw(base_size = 12) +
> labs(x="Delta Contributions (PGG w/out punishment)")+
>    theme(legend.position = "top",legend.title = element_blank())
> +scale_fill_brewer(palette="Set1")
> 
> Second PLOT:
> 
>   ggplot(DB, aes(x = delta2_L, fill =ParticipantsPUN)  , aes(x = delta2_L,
> fill =ParticipantsPUN))+
>    geom_bar(position = "dodge")+ theme_bw(base_size = 12) + labs(x="Delta
> Contributions (PGG w/punishment)")+
>    theme(legend.position = "top",legend.title = element_blank())
> +scale_fill_brewer(palette="Set1")
> 
> 
> 
> is it possible to create a density plot of the two counts data on the same
> plot?
> Do I need to create a variable count or long data format?
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Tue Dec  3 15:10:10 2019
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Tue, 3 Dec 2019 15:10:10 +0100
Subject: [R] Two geom_bar with counts to put in the same plot
In-Reply-To: <44f89f64-08c8-617c-8de5-9425e9b57f51@sapo.pt>
References: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>
 <44f89f64-08c8-617c-8de5-9425e9b57f51@sapo.pt>
Message-ID: <7CF54C04-1DBE-40B2-9C2E-F014571810EC@gmail.com>

Hi
here it is;. THANKS!

dput(DATASET)
structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 
1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 
1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 
1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 
0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 
1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 
1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 
1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 
1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 
1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 
2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 2, 2, 2, 2, 2, 
1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 
2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 
2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 
1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 
-10, -10, 0, 0, 0, -30, 0, 10, 0, 20, 10, 0, 0, 20, 0, 0, -10, 
30, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, -10, 0, 0, 0, 
40, -10, 0, 10, 0, 10, 0, -20, 0, 0, 0, 10, -20, 10, -10, 40, 
-10, -10, 10, 20, 10, 0, 0, 0, 0, 0, 0, -10, 0, 0, 20, 0, 0, 
0, 0, 10, 0, 0, 0, 10, 0, -10, 10, 0, 0, 10, 10, 10, 0, 0, 0, 
0, 0, -10, 0, 0, 0, 20, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 10, 0, 
10, 0, 0, 0, 20, -20, 0, 0, -10, 0, 0, 0, 0, -10, 10, 0, 20, 
0, 0, 0, 0, 0, -10, 0, 0, 0, 0, 0, -10, 0, 0, -10, 0, -10, 30, 
-10, 0, 0, 10, -10, 0, -10, -10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 
0, 10, 0, 0, 10, 10, 0, 0, -20, -10, 0, 0, 0, 0, 0, 0, 10, 30, 
40, 30, 30, 30, 30, 20, 20, 40, 20, 20, 10, 20, 30, 20, 40, 20, 
30, 20, 30, 20, 20, 30, 20, 40, 10, 20, 10, 30, 30, 30, 30, 10, 
30, 30, 20, 10, 40, 30, 40, 40, 30, 20, 10, 10, 20, 20, 30, 40, 
40, 40, 40, 0, 20, 20, 40, 10, 20, 20, 10, 0, -10, 0, 0, 0, 0, 
30, 10, 40, 0, 0, 0, 0, 0, 10, 0, 0, 30, 10, 10, 0, 0, -10, -20, 
-10, 0, 0, 0, -10, 10, 0, 40, 0, 30, 0, 10, 0, 40, 0, 0, -10, 
0, 10, 40, -10, 0, 0, 0, 10, 0, 10, -10, 40, 10, 20, 10, 40, 
0, 10, -10, 0, 40, 0, 0, -10, 0, 0, 20, -10, 0, 10, 0, 30, -10, 
0, 0, 0, -10, 40, 10, 10, 0, 10, -10, 0, 10, 0, 10, 0, -20, 20, 
0, 0, -20, 20, 0, -30, 20, 0, 0, 20, 10, 0, 20, 30, 0, 0, -10, 
10, 10, 0, -10, 40, 10, 0, 10, 0, 0, 20, 10, 20, 30, 0, 40, 30, 
0, 20, 40, -10, 0, 0, 0, -10, 0, 20, -10, 0, 0, 10, 0, 0, 20, 
-20, -20, 0, 20, 0, 0, 10, 0, -10, -10, 20, -10, 0, 0, 0, 0, 
0, 0, 0, -10, 30, 10, 0, 0, 10, 20, 10, -10, 10, 0, 0, -10, 30, 
-20, 10, 0, 0, 0, 10, 10, 10, 10, -10, 0, 20, 10, 10, 10, 0, 
-10, -10, 0, 0, 10, 20, 0, -10, 10, 0, 10, 20, 10, 0, 0, 0, 0, 
10, 10, 10, 30, 10, 0, 0, -10, 40, 0, 0, 10, 10, 40, 30, -10, 
0, 0, 10, 20, 0, 0, 10, 40, 0, 0, -10, -20), .Dim = c(236L, 6L
), .Dimnames = list(NULL, c("participation1", "participation2", 
"ParticipantsNOPUN", "ParticipantsPUN", "delta11_L", "delta2_L"
)))





Francesca Pancotto
----------------------------------
Francesca Pancotto, PhD
Associate Professor of Political Economy
Universit? di Modena e Reggio Emilia
Viale A. Allegri, 9
40121 Reggio Emilia
Office: +39 0522 523264
Web: 
https://sites.google.com/view/francescapancotto/home <https://sites.google.com/view/francescapancotto/home>

----------------------------------

> Il giorno 3 dic 2019, alle ore 15:03, Rui Barradas <ruipbarradas at sapo.pt> ha scritto:
> 
> Hello,
> 
> Please post the output of
> 
> dput(DB)
> 
> in a next e-mail to R-Help, like this it's difficult for us to use the data you posted.
> 
> And yes, I bet you will need the data in long format. It is a frequent first step to the problem of plotting two or more columns in the same graph. To say more only with data.
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 09:18 de 03/12/19, Francesca escreveu:
>> Dear Contributors,
>> I would like to ask help on how to create a  plot that is the overlapping
>> of two other plots.
>> It is a geom_bar structure, where I want to count the occurrences of two
>> variables, participation1 and participation2 that I recoded as factors as
>> ParticipationNOPUN and ParticipationPUN to have nice names in the legend.
>> The variables to "count" in the two plots are delta11_L and delta2_L
>> These are my data and code to create the two plots. I would like to put
>> them in the same plot as superimposed areas so that I see the change in the
>> distribution of counts in the two cases.
>> This is DB:
>> participation1 participation2 ParticipantsNOPUN ParticipantsPUN delta11_L
>> delta2_L
>>   [1,]              1              1                 2               2
>>     0        0
>>   [2,]              1              1                 2               2
>>   -10      -10
>>   [3,]              1              1                 2               2
>>   -10        0
>>   [4,]              1              1                 2               2
>>     0        0
>>   [5,]              1              1                 2               2
>>     0        0
>>   [6,]              1              1                 2               2
>>     0        0
>>   [7,]              1              0                 2               1
>>   -30       30
>>   [8,]              1              1                 2               2
>>     0       10
>>   [9,]              1              0                 2               1
>>    10       40
>>  [10,]              1              1                 2               2
>>     0        0
>>  [11,]              0              0                 1               1
>>    20        0
>>  [12,]              1              1                 2               2
>>    10        0
>>  [13,]              1              1                 2               2
>>     0        0
>>  [14,]              1              1                 2               2
>>     0        0
>>  [15,]              1              1                 2               2
>>    20       10
>>  [16,]              1              1                 2               2
>>     0        0
>>  [17,]              1              1                 2               2
>>     0        0
>>  [18,]              1              1                 2               2
>>   -10       30
>>  [19,]              0              0                 1               1
>>    30       10
>>  [20,]              1              1                 2               2
>>    10       10
>>  [21,]              1              1                 2               2
>>     0        0
>>  [22,]              1              1                 2               2
>>     0        0
>>  [23,]              1              1                 2               2
>>     0      -10
>>  [24,]              1              1                 2               2
>>     0      -20
>>  [25,]              1              1                 2               2
>>    10      -10
>>  [26,]              1              1                 2               2
>>     0        0
>>  [27,]              1              1                 2               2
>>     0        0
>> First PLOT(I need to subset the data to eliminate some NA. NB: the two
>> dataframes end up not having the same number of rows for this reason):
>> ggplot(data=subset(DB, !is.na(participation1)), aes(x = delta11_L, fill
>> =ParticipantsNOPUN))+
>>          geom_bar(position = "dodge")+ theme_bw(base_size = 12) +
>> labs(x="Delta Contributions (PGG w/out punishment)")+
>>   theme(legend.position = "top",legend.title = element_blank())
>> +scale_fill_brewer(palette="Set1")
>> Second PLOT:
>>  ggplot(DB, aes(x = delta2_L, fill =ParticipantsPUN)  , aes(x = delta2_L,
>> fill =ParticipantsPUN))+
>>   geom_bar(position = "dodge")+ theme_bw(base_size = 12) + labs(x="Delta
>> Contributions (PGG w/punishment)")+
>>   theme(legend.position = "top",legend.title = element_blank())
>> +scale_fill_brewer(palette="Set1")
>> is it possible to create a density plot of the two counts data on the same
>> plot?
>> Do I need to create a variable count or long data format?
>> Thanks
>> 	[[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Dec  3 19:02:45 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 3 Dec 2019 12:02:45 -0600
Subject: [R] strange output with merge function
Message-ID: <CAF9-5jNwJtFPy4m_h_KTjP3AagCDcYK9tXaX4wRMW18mdJ2r0w@mail.gmail.com>

Hi,

I have two data frames like this:

> head(a)
                V1    V2     V3     V4 V5   V6      V7          V8    V9
 V10
1: ENSG00000272636 chr17 181637 181636  - 4924 -769472   rs7216126 chr17
951108
2: ENSG00000273172 chr17 191588 191587  - 4978   40553  rs62053745 chr17
151035
3: ENSG00000273172 chr17 191588 191587  - 4978   39501  rs77383171 chr17
152087
4: ENSG00000273172 chr17 191588 191587  - 4978   38817  rs34245596 chr17
152771
5: ENSG00000273172 chr17 191588 191587  - 4978   38580 rs112513622 chr17
153008
6: ENSG00000273172 chr17 191588 191587  - 4978   37794   rs8069278 chr17
153794
      V11         V12       V13 V14          V15  V16
1: 951108 4.03837e-05  0.429720   1 6.967229e-05 TRUE
2: 151035 1.42190e-08 -0.488594   0 7.139876e-05 TRUE
3: 152087 1.76913e-09 -0.664469   0 7.139876e-05 TRUE
4: 152771 2.04442e-08 -0.479176   0 7.139876e-05 TRUE
5: 153008 6.46268e-07 -0.768610   0 7.139876e-05 TRUE
6: 153794 1.95944e-08 -0.480011   0 7.139876e-05 TRUE


> head(f)
            V8
1:  rs12940868
2:   rs4383187
3:   rs4404112
4:   rs7214091
5:  rs35871790
6: rs112532541

I am trying to merge with:

m=merge(a,f,by="V8")

but I am getting this output where column on which I am merging V8 is
replaced with number 17...

> head(m)
   V8              V1    V2     V3     V4 V5   V6    V7    V9    V10    V11
1: 17 ENSG00000273172 chr17 191588 191587  - 4978  1108 chr17 190480 190480
2: 17 ENSG00000273172 chr17 191588 191587  - 4978  1108 chr17 190480 190480
3: 17 ENSG00000273172 chr17 191588 191587  - 4978  1108 chr17 190480 190480
4: 17 ENSG00000262061 chr17 331206 331205  + 5858 24653 chr17 355858 355858
5: 17 ENSG00000262061 chr17 331206 331205  + 5858 24653 chr17 355858 355858
6: 17 ENSG00000262061 chr17 331206 331205  + 5858 24653 chr17 355858 355858
           V12       V13 V14          V15  V16
1: 8.23430e-09 -0.511644   0 7.139876e-05 TRUE
2: 8.23430e-09 -0.511644   0 7.139876e-05 TRUE
3: 8.23430e-09 -0.511644   0 7.139876e-05 TRUE
4: 5.46479e-05 -0.329785   0 5.962828e-05 TRUE
5: 5.46479e-05 -0.329785   0 5.962828e-05 TRUE
6: 5.46479e-05 -0.329785   0 5.962828e-05 TRUE

Please advise,
Thanks
Ana

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Dec  3 19:46:53 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 03 Dec 2019 10:46:53 -0800
Subject: [R] strange output with merge function
In-Reply-To: <CAF9-5jNwJtFPy4m_h_KTjP3AagCDcYK9tXaX4wRMW18mdJ2r0w@mail.gmail.com>
References: <CAF9-5jNwJtFPy4m_h_KTjP3AagCDcYK9tXaX4wRMW18mdJ2r0w@mail.gmail.com>
Message-ID: <E103EE2B-D8D3-49B6-98FE-20D6CEB098CF@dcn.davis.ca.us>

My guess would be that your key columns are factors with different levels. You have to be very careful manipulating factors... I recommend using character data until you are ready to do analysis steps that need factors. You may be able to resolve this by importing your data with the as.is=TRUE or stringsAsFactors=FALSE depending what functions you are using (read the help for your input function).

On December 3, 2019 10:02:45 AM PST, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>Hi,
>
>I have two data frames like this:
>
>> head(a)
>               V1    V2     V3     V4 V5   V6      V7          V8    V9
> V10
>1: ENSG00000272636 chr17 181637 181636  - 4924 -769472   rs7216126
>chr17
>951108
>2: ENSG00000273172 chr17 191588 191587  - 4978   40553  rs62053745
>chr17
>151035
>3: ENSG00000273172 chr17 191588 191587  - 4978   39501  rs77383171
>chr17
>152087
>4: ENSG00000273172 chr17 191588 191587  - 4978   38817  rs34245596
>chr17
>152771
>5: ENSG00000273172 chr17 191588 191587  - 4978   38580 rs112513622
>chr17
>153008
>6: ENSG00000273172 chr17 191588 191587  - 4978   37794   rs8069278
>chr17
>153794
>      V11         V12       V13 V14          V15  V16
>1: 951108 4.03837e-05  0.429720   1 6.967229e-05 TRUE
>2: 151035 1.42190e-08 -0.488594   0 7.139876e-05 TRUE
>3: 152087 1.76913e-09 -0.664469   0 7.139876e-05 TRUE
>4: 152771 2.04442e-08 -0.479176   0 7.139876e-05 TRUE
>5: 153008 6.46268e-07 -0.768610   0 7.139876e-05 TRUE
>6: 153794 1.95944e-08 -0.480011   0 7.139876e-05 TRUE
>
>
>> head(f)
>            V8
>1:  rs12940868
>2:   rs4383187
>3:   rs4404112
>4:   rs7214091
>5:  rs35871790
>6: rs112532541
>
>I am trying to merge with:
>
>m=merge(a,f,by="V8")
>
>but I am getting this output where column on which I am merging V8 is
>replaced with number 17...
>
>> head(m)
>V8              V1    V2     V3     V4 V5   V6    V7    V9    V10   
>V11
>1: 17 ENSG00000273172 chr17 191588 191587  - 4978  1108 chr17 190480
>190480
>2: 17 ENSG00000273172 chr17 191588 191587  - 4978  1108 chr17 190480
>190480
>3: 17 ENSG00000273172 chr17 191588 191587  - 4978  1108 chr17 190480
>190480
>4: 17 ENSG00000262061 chr17 331206 331205  + 5858 24653 chr17 355858
>355858
>5: 17 ENSG00000262061 chr17 331206 331205  + 5858 24653 chr17 355858
>355858
>6: 17 ENSG00000262061 chr17 331206 331205  + 5858 24653 chr17 355858
>355858
>           V12       V13 V14          V15  V16
>1: 8.23430e-09 -0.511644   0 7.139876e-05 TRUE
>2: 8.23430e-09 -0.511644   0 7.139876e-05 TRUE
>3: 8.23430e-09 -0.511644   0 7.139876e-05 TRUE
>4: 5.46479e-05 -0.329785   0 5.962828e-05 TRUE
>5: 5.46479e-05 -0.329785   0 5.962828e-05 TRUE
>6: 5.46479e-05 -0.329785   0 5.962828e-05 TRUE
>
>Please advise,
>Thanks
>Ana
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Dec  3 20:13:41 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 3 Dec 2019 13:13:41 -0600
Subject: [R] strange output with merge function
In-Reply-To: <E103EE2B-D8D3-49B6-98FE-20D6CEB098CF@dcn.davis.ca.us>
References: <CAF9-5jNwJtFPy4m_h_KTjP3AagCDcYK9tXaX4wRMW18mdJ2r0w@mail.gmail.com>
 <E103EE2B-D8D3-49B6-98FE-20D6CEB098CF@dcn.davis.ca.us>
Message-ID: <CAF9-5jPSRtGH0twO_W88N7sAK06GxJvDa-RfZFShSf=JZunOrg@mail.gmail.com>

HI Jeff,

the issue got resolved after I converted data in as.data.frame.

Thank you for the useful input!

Ana

On Tue, Dec 3, 2019 at 12:46 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> My guess would be that your key columns are factors with different levels.
> You have to be very careful manipulating factors... I recommend using
> character data until you are ready to do analysis steps that need factors.
> You may be able to resolve this by importing your data with the as.is=TRUE
> or stringsAsFactors=FALSE depending what functions you are using (read the
> help for your input function).
>
> On December 3, 2019 10:02:45 AM PST, Ana Marija <
> sokovic.anamarija at gmail.com> wrote:
> >Hi,
> >
> >I have two data frames like this:
> >
> >> head(a)
> >               V1    V2     V3     V4 V5   V6      V7          V8    V9
> > V10
> >1: ENSG00000272636 chr17 181637 181636  - 4924 -769472   rs7216126
> >chr17
> >951108
> >2: ENSG00000273172 chr17 191588 191587  - 4978   40553  rs62053745
> >chr17
> >151035
> >3: ENSG00000273172 chr17 191588 191587  - 4978   39501  rs77383171
> >chr17
> >152087
> >4: ENSG00000273172 chr17 191588 191587  - 4978   38817  rs34245596
> >chr17
> >152771
> >5: ENSG00000273172 chr17 191588 191587  - 4978   38580 rs112513622
> >chr17
> >153008
> >6: ENSG00000273172 chr17 191588 191587  - 4978   37794   rs8069278
> >chr17
> >153794
> >      V11         V12       V13 V14          V15  V16
> >1: 951108 4.03837e-05  0.429720   1 6.967229e-05 TRUE
> >2: 151035 1.42190e-08 -0.488594   0 7.139876e-05 TRUE
> >3: 152087 1.76913e-09 -0.664469   0 7.139876e-05 TRUE
> >4: 152771 2.04442e-08 -0.479176   0 7.139876e-05 TRUE
> >5: 153008 6.46268e-07 -0.768610   0 7.139876e-05 TRUE
> >6: 153794 1.95944e-08 -0.480011   0 7.139876e-05 TRUE
> >
> >
> >> head(f)
> >            V8
> >1:  rs12940868
> >2:   rs4383187
> >3:   rs4404112
> >4:   rs7214091
> >5:  rs35871790
> >6: rs112532541
> >
> >I am trying to merge with:
> >
> >m=merge(a,f,by="V8")
> >
> >but I am getting this output where column on which I am merging V8 is
> >replaced with number 17...
> >
> >> head(m)
> >V8              V1    V2     V3     V4 V5   V6    V7    V9    V10
> >V11
> >1: 17 ENSG00000273172 chr17 191588 191587  - 4978  1108 chr17 190480
> >190480
> >2: 17 ENSG00000273172 chr17 191588 191587  - 4978  1108 chr17 190480
> >190480
> >3: 17 ENSG00000273172 chr17 191588 191587  - 4978  1108 chr17 190480
> >190480
> >4: 17 ENSG00000262061 chr17 331206 331205  + 5858 24653 chr17 355858
> >355858
> >5: 17 ENSG00000262061 chr17 331206 331205  + 5858 24653 chr17 355858
> >355858
> >6: 17 ENSG00000262061 chr17 331206 331205  + 5858 24653 chr17 355858
> >355858
> >           V12       V13 V14          V15  V16
> >1: 8.23430e-09 -0.511644   0 7.139876e-05 TRUE
> >2: 8.23430e-09 -0.511644   0 7.139876e-05 TRUE
> >3: 8.23430e-09 -0.511644   0 7.139876e-05 TRUE
> >4: 5.46479e-05 -0.329785   0 5.962828e-05 TRUE
> >5: 5.46479e-05 -0.329785   0 5.962828e-05 TRUE
> >6: 5.46479e-05 -0.329785   0 5.962828e-05 TRUE
> >
> >Please advise,
> >Thanks
> >Ana
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Dec  3 20:40:44 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 3 Dec 2019 13:40:44 -0600
Subject: [R] how to merge 5 data frames by one column
Message-ID: <CAF9-5jNyFmnH4+bVWAALWEYivz+=PqOTumTbUfeoBf=b+qGP_w@mail.gmail.com>

Hello,

I have 5 dataframes (s11,s22,s33,s44,s55) that look like this:

> head(s11)
               V1.1                          rs         V3.1        V4.1
1 ENSG00000154803  rs12940868 3.80175e-05 -0.519565
2 ENSG00000154803   rs4383187 8.92772e-05 -0.367303
3 ENSG00000154803   rs4404112 9.32402e-05 -0.366634
4 ENSG00000154803   rs7214091 8.38003e-05  0.337576
5 ENSG00000154803  rs35871790 9.67028e-05 -0.305755
6 ENSG00000154803 rs112532541 1.08341e-04 -0.305493

> head(s22)
               V1.2                               rs        V3.2      V4.2
602 ENSG00000264589  rs62065452 1.34475e-17 -0.695948
603 ENSG00000264589 rs377004743 1.26272e-17 -0.695627
630 ENSG00000264589   rs1724390 1.01129e-17 -0.693518
643 ENSG00000264589 rs367637729 4.05726e-17 -0.682833
653 ENSG00000264589 rs376183404 1.13177e-17 -0.697646
673 ENSG00000264589 rs112327620 1.59840e-17 -0.707904

Each one has one unique value in respective V1

I am trying to merge all at once all 5 data frames by the "rs" column.

Can you please help with this,
Ana

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Dec  3 20:48:32 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 3 Dec 2019 13:48:32 -0600
Subject: [R] how to merge 5 data frames by one column
In-Reply-To: <CAF9-5jNyFmnH4+bVWAALWEYivz+=PqOTumTbUfeoBf=b+qGP_w@mail.gmail.com>
References: <CAF9-5jNyFmnH4+bVWAALWEYivz+=PqOTumTbUfeoBf=b+qGP_w@mail.gmail.com>
Message-ID: <CAF9-5jMOwmkPwrAawJNrP17JKsHzSZACmOEOQff0tLLu4EnALw@mail.gmail.com>

the desired output would look like this (example give just for two genes,
it should include all 5 from all 5 data frames):

where the example is if say only 5 rs are shared between those two genes,
what is given after rs# is values from V4 column for each gene

GENES ENSG00000001629 ENSG00000127914
rs1208998 -0.0337989326337439  -0.00106024397995199
rs4729008 0.0630831868839983  0.00890783698397027
rs11772754 0.181375539335959  0.0012636115921931
rs10257459 0.0369962603988132  0.00509887844657462
rs17164876 0.0307882763321834  -0.00188979524322732

On Tue, Dec 3, 2019 at 1:40 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have 5 dataframes (s11,s22,s33,s44,s55) that look like this:
>
> > head(s11)
>                V1.1                          rs         V3.1        V4.1
> 1 ENSG00000154803  rs12940868 3.80175e-05 -0.519565
> 2 ENSG00000154803   rs4383187 8.92772e-05 -0.367303
> 3 ENSG00000154803   rs4404112 9.32402e-05 -0.366634
> 4 ENSG00000154803   rs7214091 8.38003e-05  0.337576
> 5 ENSG00000154803  rs35871790 9.67028e-05 -0.305755
> 6 ENSG00000154803 rs112532541 1.08341e-04 -0.305493
>
> > head(s22)
>                V1.2                               rs        V3.2      V4.2
> 602 ENSG00000264589  rs62065452 1.34475e-17 -0.695948
> 603 ENSG00000264589 rs377004743 1.26272e-17 -0.695627
> 630 ENSG00000264589   rs1724390 1.01129e-17 -0.693518
> 643 ENSG00000264589 rs367637729 4.05726e-17 -0.682833
> 653 ENSG00000264589 rs376183404 1.13177e-17 -0.697646
> 673 ENSG00000264589 rs112327620 1.59840e-17 -0.707904
>
> Each one has one unique value in respective V1
>
> I am trying to merge all at once all 5 data frames by the "rs" column.
>
> Can you please help with this,
> Ana
>
>
>
>
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Dec  3 21:09:48 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 3 Dec 2019 14:09:48 -0600
Subject: [R] how to merge 5 data frames by one column
In-Reply-To: <CAF9-5jMOwmkPwrAawJNrP17JKsHzSZACmOEOQff0tLLu4EnALw@mail.gmail.com>
References: <CAF9-5jNyFmnH4+bVWAALWEYivz+=PqOTumTbUfeoBf=b+qGP_w@mail.gmail.com>
 <CAF9-5jMOwmkPwrAawJNrP17JKsHzSZACmOEOQff0tLLu4EnALw@mail.gmail.com>
Message-ID: <CAF9-5jOK9LHE4ddReNfDP4yQVsSobA=WYQbJcWSiLb1a8a0J5w@mail.gmail.com>

I can perhaps do this:

m=Reduce(function(x, y) merge(x, y, all=TRUE), list(s11, s22, s33,s44,s55))

but than in the output of this one SNP (just for example)

> head(m)
         rs            V1.1        V3.1     V4.1 V1.2 V3.2 V4.2
 V1.3
6 rs1029829 ENSG00000154803 1.02519e-11 0.469402 <NA>   NA   NA
ENSG00000141030
         V3.3     V4.3 V1.4 V3.4 V4.4 V1.5 V3.5 V4.5
6 3.06126e-28 0.726948 <NA>   NA   NA <NA>   NA   NA
...

but how to filter out this output (m) in order to remove all rows where I
have NA in any of these columns: V1.1,V1.2,V1.3,V1.4,V1.5





On Tue, Dec 3, 2019 at 1:48 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> the desired output would look like this (example give just for two genes,
> it should include all 5 from all 5 data frames):
>
> where the example is if say only 5 rs are shared between those two genes,
> what is given after rs# is values from V4 column for each gene
>
> GENES ENSG00000001629 ENSG00000127914
> rs1208998 -0.0337989326337439  -0.00106024397995199
> rs4729008 0.0630831868839983  0.00890783698397027
> rs11772754 0.181375539335959  0.0012636115921931
> rs10257459 0.0369962603988132  0.00509887844657462
> rs17164876 0.0307882763321834  -0.00188979524322732
>
> On Tue, Dec 3, 2019 at 1:40 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
>
>> Hello,
>>
>> I have 5 dataframes (s11,s22,s33,s44,s55) that look like this:
>>
>> > head(s11)
>>                V1.1                          rs         V3.1        V4.1
>> 1 ENSG00000154803  rs12940868 3.80175e-05 -0.519565
>> 2 ENSG00000154803   rs4383187 8.92772e-05 -0.367303
>> 3 ENSG00000154803   rs4404112 9.32402e-05 -0.366634
>> 4 ENSG00000154803   rs7214091 8.38003e-05  0.337576
>> 5 ENSG00000154803  rs35871790 9.67028e-05 -0.305755
>> 6 ENSG00000154803 rs112532541 1.08341e-04 -0.305493
>>
>> > head(s22)
>>                V1.2                               rs        V3.2      V4.2
>> 602 ENSG00000264589  rs62065452 1.34475e-17 -0.695948
>> 603 ENSG00000264589 rs377004743 1.26272e-17 -0.695627
>> 630 ENSG00000264589   rs1724390 1.01129e-17 -0.693518
>> 643 ENSG00000264589 rs367637729 4.05726e-17 -0.682833
>> 653 ENSG00000264589 rs376183404 1.13177e-17 -0.697646
>> 673 ENSG00000264589 rs112327620 1.59840e-17 -0.707904
>>
>> Each one has one unique value in respective V1
>>
>> I am trying to merge all at once all 5 data frames by the "rs" column.
>>
>> Can you please help with this,
>> Ana
>>
>>
>>
>>
>>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Dec  3 21:16:08 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 3 Dec 2019 14:16:08 -0600
Subject: [R] how to merge 5 data frames by one column
In-Reply-To: <CAF9-5jOK9LHE4ddReNfDP4yQVsSobA=WYQbJcWSiLb1a8a0J5w@mail.gmail.com>
References: <CAF9-5jNyFmnH4+bVWAALWEYivz+=PqOTumTbUfeoBf=b+qGP_w@mail.gmail.com>
 <CAF9-5jMOwmkPwrAawJNrP17JKsHzSZACmOEOQff0tLLu4EnALw@mail.gmail.com>
 <CAF9-5jOK9LHE4ddReNfDP4yQVsSobA=WYQbJcWSiLb1a8a0J5w@mail.gmail.com>
Message-ID: <CAF9-5jPpit_tGbPLLAU5fpbhqmf+OKkJ6GReOH2ba+X2hKMEZQ@mail.gmail.com>

would this make sense for the previous:
mt=na.omit(m, cols = c("V1.1","V1.2","V1.3","V1.4","V1.5"))

On Tue, Dec 3, 2019 at 2:09 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> I can perhaps do this:
>
> m=Reduce(function(x, y) merge(x, y, all=TRUE), list(s11, s22, s33,s44,s55))
>
> but than in the output of this one SNP (just for example)
>
> > head(m)
>          rs            V1.1        V3.1     V4.1 V1.2 V3.2 V4.2
>  V1.3
> 6 rs1029829 ENSG00000154803 1.02519e-11 0.469402 <NA>   NA   NA
> ENSG00000141030
>          V3.3     V4.3 V1.4 V3.4 V4.4 V1.5 V3.5 V4.5
> 6 3.06126e-28 0.726948 <NA>   NA   NA <NA>   NA   NA
> ...
>
> but how to filter out this output (m) in order to remove all rows where I
> have NA in any of these columns: V1.1,V1.2,V1.3,V1.4,V1.5
>
>
>
>
>
> On Tue, Dec 3, 2019 at 1:48 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
>
>> the desired output would look like this (example give just for two genes,
>> it should include all 5 from all 5 data frames):
>>
>> where the example is if say only 5 rs are shared between those two genes,
>> what is given after rs# is values from V4 column for each gene
>>
>> GENES ENSG00000001629 ENSG00000127914
>> rs1208998 -0.0337989326337439  -0.00106024397995199
>> rs4729008 0.0630831868839983  0.00890783698397027
>> rs11772754 0.181375539335959  0.0012636115921931
>> rs10257459 0.0369962603988132  0.00509887844657462
>> rs17164876 0.0307882763321834  -0.00188979524322732
>>
>> On Tue, Dec 3, 2019 at 1:40 PM Ana Marija <sokovic.anamarija at gmail.com>
>> wrote:
>>
>>> Hello,
>>>
>>> I have 5 dataframes (s11,s22,s33,s44,s55) that look like this:
>>>
>>> > head(s11)
>>>                V1.1                          rs         V3.1        V4.1
>>> 1 ENSG00000154803  rs12940868 3.80175e-05 -0.519565
>>> 2 ENSG00000154803   rs4383187 8.92772e-05 -0.367303
>>> 3 ENSG00000154803   rs4404112 9.32402e-05 -0.366634
>>> 4 ENSG00000154803   rs7214091 8.38003e-05  0.337576
>>> 5 ENSG00000154803  rs35871790 9.67028e-05 -0.305755
>>> 6 ENSG00000154803 rs112532541 1.08341e-04 -0.305493
>>>
>>> > head(s22)
>>>                V1.2                               rs        V3.2
>>>  V4.2
>>> 602 ENSG00000264589  rs62065452 1.34475e-17 -0.695948
>>> 603 ENSG00000264589 rs377004743 1.26272e-17 -0.695627
>>> 630 ENSG00000264589   rs1724390 1.01129e-17 -0.693518
>>> 643 ENSG00000264589 rs367637729 4.05726e-17 -0.682833
>>> 653 ENSG00000264589 rs376183404 1.13177e-17 -0.697646
>>> 673 ENSG00000264589 rs112327620 1.59840e-17 -0.707904
>>>
>>> Each one has one unique value in respective V1
>>>
>>> I am trying to merge all at once all 5 data frames by the "rs" column.
>>>
>>> Can you please help with this,
>>> Ana
>>>
>>>
>>>
>>>
>>>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Tue Dec  3 21:16:50 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 4 Dec 2019 09:16:50 +1300
Subject: [R] How to find the best fit of inner cut ellipse to points in
 polar plot?
In-Reply-To: <16ecbaa186c.10276a62e1034.5455362847641034762@zoho.com>
References: <16ecbaa186c.10276a62e1034.5455362847641034762@zoho.com>
Message-ID: <CAB8pepxJervBE6b-71JcaA8XcFiG3gMFEmucRh23PvyEe-uUCQ@mail.gmail.com>

(1) There is no csv attached (may have been removed).
(2) If you have a "polar plot", then wouldn't the "center" be the
origin of the plot/coordinates?
(3) If you don't need an exact ellipse, you could transform your
coordinates into cartesian coordinates, and then use a periodic form
of regression.
(4) If you need an exact ellipse, then you would have (three?)
parameters, ignoring the center.
If you work out the R formula, then you could try nonlinear
regression, to estimate those parameters, maybe...

On Wed, Dec 4, 2019 at 1:09 AM vod vos via R-help <r-help at r-project.org> wrote:
>
> hi,
>
> 1. How to find the best fit of  inner cut ellipse to points in polar plot?
>
> 2. How can we find the ellipse passing through  most of the points in polar plot?
>
> And can we get the center x, center y, major radius, minor radius, and rotation angle of the ellipse?
>
> The csv data is attached.
>
> Thanks.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Dec  3 21:27:22 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 3 Dec 2019 14:27:22 -0600
Subject: [R] how to merge 5 data frames by one column
In-Reply-To: <CAF9-5jPpit_tGbPLLAU5fpbhqmf+OKkJ6GReOH2ba+X2hKMEZQ@mail.gmail.com>
References: <CAF9-5jNyFmnH4+bVWAALWEYivz+=PqOTumTbUfeoBf=b+qGP_w@mail.gmail.com>
 <CAF9-5jMOwmkPwrAawJNrP17JKsHzSZACmOEOQff0tLLu4EnALw@mail.gmail.com>
 <CAF9-5jOK9LHE4ddReNfDP4yQVsSobA=WYQbJcWSiLb1a8a0J5w@mail.gmail.com>
 <CAF9-5jPpit_tGbPLLAU5fpbhqmf+OKkJ6GReOH2ba+X2hKMEZQ@mail.gmail.com>
Message-ID: <CAF9-5jPXkCjJDBRP2SPD-LLn3K2160JLBsYBL=FaYeJY=6bG5g@mail.gmail.com>

I apologize I would need to reformulate this problem because there will be
much more unique genes I have to look up, 381

so all genes or in one data frame

> head(r)
               V1         V2          V3        V4
1 ENSG00000273172  rs7215271 4.33932e-17 -0.602316
2 ENSG00000273172 rs34889101 4.99518e-17 -0.596089
3 ENSG00000273172  rs4890177 4.23229e-17 -0.590085
4 ENSG00000273172  rs4890178 7.14216e-17 -0.581467
5 ENSG00000273172  rs7503363 3.16802e-17 -0.582836
6 ENSG00000273172 rs35611892 2.24399e-17 -0.583710

> tail(r)
                   V1          V2          V3        V4
18946 ENSG00000141560    rs7215271 8.53890e-17  0.572286
18947 ENSG00000141560    rs606532 9.00740e-17  0.572151
18963 ENSG00000175711 rs111566282 5.71871e-17 -0.609586
18964 ENSG00000175711  rs76319775 4.58843e-17 -0.610164
18965 ENSG00000175711  rs62074661 4.17490e-17 -0.603199
18966 ENSG00000176845  rs11433639 1.45496e-17 -0.761955

So for the adobe example I would just have in result for merging this one
row: because they gave this same rs: rs7215271
and output would contain all columns related to those two genes which have
the same:  rs7215271

it can be also possible that I can find more than 2 genes sharing the same
rs.

Can you please advise about this




On Tue, Dec 3, 2019 at 2:16 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> would this make sense for the previous:
> mt=na.omit(m, cols = c("V1.1","V1.2","V1.3","V1.4","V1.5"))
>
> On Tue, Dec 3, 2019 at 2:09 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
>
>> I can perhaps do this:
>>
>> m=Reduce(function(x, y) merge(x, y, all=TRUE), list(s11, s22,
>> s33,s44,s55))
>>
>> but than in the output of this one SNP (just for example)
>>
>> > head(m)
>>          rs            V1.1        V3.1     V4.1 V1.2 V3.2 V4.2
>>  V1.3
>> 6 rs1029829 ENSG00000154803 1.02519e-11 0.469402 <NA>   NA   NA
>> ENSG00000141030
>>          V3.3     V4.3 V1.4 V3.4 V4.4 V1.5 V3.5 V4.5
>> 6 3.06126e-28 0.726948 <NA>   NA   NA <NA>   NA   NA
>> ...
>>
>> but how to filter out this output (m) in order to remove all rows where I
>> have NA in any of these columns: V1.1,V1.2,V1.3,V1.4,V1.5
>>
>>
>>
>>
>>
>> On Tue, Dec 3, 2019 at 1:48 PM Ana Marija <sokovic.anamarija at gmail.com>
>> wrote:
>>
>>> the desired output would look like this (example give just for two
>>> genes, it should include all 5 from all 5 data frames):
>>>
>>> where the example is if say only 5 rs are shared between those two
>>> genes, what is given after rs# is values from V4 column for each gene
>>>
>>> GENES ENSG00000001629 ENSG00000127914
>>> rs1208998 -0.0337989326337439  -0.00106024397995199
>>> rs4729008 0.0630831868839983  0.00890783698397027
>>> rs11772754 0.181375539335959  0.0012636115921931
>>> rs10257459 0.0369962603988132  0.00509887844657462
>>> rs17164876 0.0307882763321834  -0.00188979524322732
>>>
>>> On Tue, Dec 3, 2019 at 1:40 PM Ana Marija <sokovic.anamarija at gmail.com>
>>> wrote:
>>>
>>>> Hello,
>>>>
>>>> I have 5 dataframes (s11,s22,s33,s44,s55) that look like this:
>>>>
>>>> > head(s11)
>>>>                V1.1                          rs         V3.1        V4.1
>>>> 1 ENSG00000154803  rs12940868 3.80175e-05 -0.519565
>>>> 2 ENSG00000154803   rs4383187 8.92772e-05 -0.367303
>>>> 3 ENSG00000154803   rs4404112 9.32402e-05 -0.366634
>>>> 4 ENSG00000154803   rs7214091 8.38003e-05  0.337576
>>>> 5 ENSG00000154803  rs35871790 9.67028e-05 -0.305755
>>>> 6 ENSG00000154803 rs112532541 1.08341e-04 -0.305493
>>>>
>>>> > head(s22)
>>>>                V1.2                               rs        V3.2
>>>>  V4.2
>>>> 602 ENSG00000264589  rs62065452 1.34475e-17 -0.695948
>>>> 603 ENSG00000264589 rs377004743 1.26272e-17 -0.695627
>>>> 630 ENSG00000264589   rs1724390 1.01129e-17 -0.693518
>>>> 643 ENSG00000264589 rs367637729 4.05726e-17 -0.682833
>>>> 653 ENSG00000264589 rs376183404 1.13177e-17 -0.697646
>>>> 673 ENSG00000264589 rs112327620 1.59840e-17 -0.707904
>>>>
>>>> Each one has one unique value in respective V1
>>>>
>>>> I am trying to merge all at once all 5 data frames by the "rs" column.
>>>>
>>>> Can you please help with this,
>>>> Ana
>>>>
>>>>
>>>>
>>>>
>>>>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Dec  3 21:42:29 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 3 Dec 2019 12:42:29 -0800
Subject: [R] how to merge 5 data frames by one column
In-Reply-To: <CAF9-5jPpit_tGbPLLAU5fpbhqmf+OKkJ6GReOH2ba+X2hKMEZQ@mail.gmail.com>
References: <CAF9-5jNyFmnH4+bVWAALWEYivz+=PqOTumTbUfeoBf=b+qGP_w@mail.gmail.com>
 <CAF9-5jMOwmkPwrAawJNrP17JKsHzSZACmOEOQff0tLLu4EnALw@mail.gmail.com>
 <CAF9-5jOK9LHE4ddReNfDP4yQVsSobA=WYQbJcWSiLb1a8a0J5w@mail.gmail.com>
 <CAF9-5jPpit_tGbPLLAU5fpbhqmf+OKkJ6GReOH2ba+X2hKMEZQ@mail.gmail.com>
Message-ID: <dba3d707-0a2f-5867-f652-055adad27a49@comcast.net>


On 12/3/19 12:16 PM, Ana Marija wrote:
> would this make sense for the previous:
> mt=na.omit(m, cols = c("V1.1","V1.2","V1.3","V1.4","V1.5"))
>
> On Tue, Dec 3, 2019 at 2:09 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
>
>> I can perhaps do this:
>>
>> m=Reduce(function(x, y) merge(x, y, all=TRUE), list(s11, s22, s33,s44,s55))
>>
>> but than in the output of this one SNP (just for example)
>>
>>> head(m)
>>           rs            V1.1        V3.1     V4.1 V1.2 V3.2 V4.2
>>   V1.3
>> 6 rs1029829 ENSG00000154803 1.02519e-11 0.469402 <NA>   NA   NA
>> ENSG00000141030
>>           V3.3     V4.3 V1.4 V3.4 V4.4 V1.5 V3.5 V4.5
>> 6 3.06126e-28 0.726948 <NA>   NA   NA <NA>   NA   NA


It's a very simple matter when using gmail to adhere to the Posting 
Guide policy of plaintext submission to rhelp. Failing to adhere to that 
rule is making your successive posting less and less readable.

>> ...
>>
>> but how to filter out this output (m) in order to remove all rows where I
>> have NA in any of these columns: V1.1,V1.2,V1.3,V1.4,V1.5

The complete.cases function returns a logical vector suitable for 
selecting a subset.


-- 

David.

>>
>>
>>
>>
>>
>> On Tue, Dec 3, 2019 at 1:48 PM Ana Marija <sokovic.anamarija at gmail.com>
>> wrote:
>>
>>> the desired output would look like this (example give just for two genes,
>>> it should include all 5 from all 5 data frames):
>>>
>>> where the example is if say only 5 rs are shared between those two genes,
>>> what is given after rs# is values from V4 column for each gene
>>>
>>> GENES ENSG00000001629 ENSG00000127914
>>> rs1208998 -0.0337989326337439  -0.00106024397995199
>>> rs4729008 0.0630831868839983  0.00890783698397027
>>> rs11772754 0.181375539335959  0.0012636115921931
>>> rs10257459 0.0369962603988132  0.00509887844657462
>>> rs17164876 0.0307882763321834  -0.00188979524322732
>>>
>>> On Tue, Dec 3, 2019 at 1:40 PM Ana Marija <sokovic.anamarija at gmail.com>
>>> wrote:
>>>
>>>> Hello,
>>>>
>>>> I have 5 dataframes (s11,s22,s33,s44,s55) that look like this:
>>>>
>>>>> head(s11)
>>>>                 V1.1                          rs         V3.1        V4.1
>>>> 1 ENSG00000154803  rs12940868 3.80175e-05 -0.519565
>>>> 2 ENSG00000154803   rs4383187 8.92772e-05 -0.367303
>>>> 3 ENSG00000154803   rs4404112 9.32402e-05 -0.366634
>>>> 4 ENSG00000154803   rs7214091 8.38003e-05  0.337576
>>>> 5 ENSG00000154803  rs35871790 9.67028e-05 -0.305755
>>>> 6 ENSG00000154803 rs112532541 1.08341e-04 -0.305493
>>>>
>>>>> head(s22)
>>>>                 V1.2                               rs        V3.2
>>>>   V4.2
>>>> 602 ENSG00000264589  rs62065452 1.34475e-17 -0.695948
>>>> 603 ENSG00000264589 rs377004743 1.26272e-17 -0.695627
>>>> 630 ENSG00000264589   rs1724390 1.01129e-17 -0.693518
>>>> 643 ENSG00000264589 rs367637729 4.05726e-17 -0.682833
>>>> 653 ENSG00000264589 rs376183404 1.13177e-17 -0.697646
>>>> 673 ENSG00000264589 rs112327620 1.59840e-17 -0.707904
>>>>
>>>> Each one has one unique value in respective V1
>>>>
>>>> I am trying to merge all at once all 5 data frames by the "rs" column.
>>>>
>>>> Can you please help with this,
>>>> Ana
>>>>
>>>>
>>>>
>>>>
>>>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Dec  3 23:38:04 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 3 Dec 2019 16:38:04 -0600
Subject: [R] undefined columns selected
Message-ID: <CAF9-5jMDrupxXAO8r2-ZOsKMe84CDzvxoUYRKivNv6mUwz-ERg@mail.gmail.com>

Hello,

I am trying to run this software:

https://github.com/eleporcu/TWMR

and I have my input files in my current directory: ENSG00000154803.matrix,
ENSG00000154803.ld

but when I try to run it:

Rscript MR.R ENSG00000154803

[1] "ENSG00000154803"
Error in `[.data.frame`(C, , 1:length(C[, 1])) :
  undefined columns selected
Calls: as.matrix -> [ -> [.data.frame
Execution halted

I should mention that I was able to run this script before with the same
command when I had input like:
https://github.com/eleporcu/TWMR/blob/master/ENSG00000000971.matrix

and I also, per suggestion changed the beginning of the code to be:
cmd_args <- commandArgs(TRUE)
if (length(cmd_args) == 0L) stop("No arguments specified.")
print(cmd_args)
gene<-cmd_args[length(cmd_args)]   ## Last argument is the 'gene'
Ngwas<-239087
N_eQTLs<-32000
out<-c("gene","alpha","SE","P","Nsnps","Ngene")

file<-paste(gene,"matrix",sep=".")
if (!file.exists(file)) stop("File not found: ", file)
filecluster<-read.table(file,header=T,sep=" ",dec=".")
beta<-as.matrix(filecluster[,2:(length(filecluster[1,])-1)])

now my input is like this:

https://github.com/eleporcu/TWMR/blob/master/ENSG00000000419.matrix

so 4 columns instead of 3 like it was before and when I run it I get that
error above.

Please advise,
Ana

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Dec  4 01:08:54 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 3 Dec 2019 16:08:54 -0800
Subject: [R] undefined columns selected
In-Reply-To: <CAF9-5jMDrupxXAO8r2-ZOsKMe84CDzvxoUYRKivNv6mUwz-ERg@mail.gmail.com>
References: <CAF9-5jMDrupxXAO8r2-ZOsKMe84CDzvxoUYRKivNv6mUwz-ERg@mail.gmail.com>
Message-ID: <CAGxFJbRanFCyPpg1Y=7efDtC6M-VMBSHPPr+_DoFpATUWmD8pA@mail.gmail.com>

Basically no clue, but note that C[, 1:length(C[ ,1])] looks suspect -- you
are selecting the number of columns equal to the number of rows in C. Is
that really what you want to do?

Bert

On Tue, Dec 3, 2019, 2:36 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:

> Hello,
>
> I am trying to run this software:
>
> https://github.com/eleporcu/TWMR
>
> and I have my input files in my current directory: ENSG00000154803.matrix,
> ENSG00000154803.ld
>
> but when I try to run it:
>
> Rscript MR.R ENSG00000154803
>
> [1] "ENSG00000154803"
> Error in `[.data.frame`(C, , 1:length(C[, 1])) :
>   undefined columns selected
> Calls: as.matrix -> [ -> [.data.frame
> Execution halted
>
> I should mention that I was able to run this script before with the same
> command when I had input like:
> https://github.com/eleporcu/TWMR/blob/master/ENSG00000000971.matrix
>
> and I also, per suggestion changed the beginning of the code to be:
> cmd_args <- commandArgs(TRUE)
> if (length(cmd_args) == 0L) stop("No arguments specified.")
> print(cmd_args)
> gene<-cmd_args[length(cmd_args)]   ## Last argument is the 'gene'
> Ngwas<-239087
> N_eQTLs<-32000
> out<-c("gene","alpha","SE","P","Nsnps","Ngene")
>
> file<-paste(gene,"matrix",sep=".")
> if (!file.exists(file)) stop("File not found: ", file)
> filecluster<-read.table(file,header=T,sep=" ",dec=".")
> beta<-as.matrix(filecluster[,2:(length(filecluster[1,])-1)])
>
> now my input is like this:
>
> https://github.com/eleporcu/TWMR/blob/master/ENSG00000000419.matrix
>
> so 4 columns instead of 3 like it was before and when I run it I get that
> error above.
>
> Please advise,
> Ana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Dec  4 03:16:33 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 4 Dec 2019 13:16:33 +1100
Subject: [R] 
	=?utf-8?b?5Zue5aSNOkhvdyB0byBmaW5kIHRoZSBiZXN0IGZpdCBvZiBp?=
	=?utf-8?q?nner_cut_ellipse_to_points_in_polar_plot=3F?=
In-Reply-To: <16ece267db6.ddcb34de10739.2803708586142920905@zoho.com>
References: <16ecbaa186c.10276a62e1034.5455362847641034762@zoho.com>
 <16ecbc1f6dc.e3ed5bf11441.3412535460238780222@zoho.com>
 <CA+8X3fXC6OPyfVEtviR8w9_KqCOhFod=9L8tCxiyAJb+GzV=sQ@mail.gmail.com>
 <16ece267db6.ddcb34de10739.2803708586142920905@zoho.com>
Message-ID: <CA+8X3fVbtaV82f3eHafWZyTm_eihQ3X+wVHY4uKC9AxztpXj9Q@mail.gmail.com>

Hi vod,
Now that I have your data I can do a bit better:

# save data as "vv.csv"
vv<-read.csv("vv.csv")
# order the points in order of theta
vv<-vv[order(vv$theta),]
oldpar<-polar.plot(vv$r,vv$theta,main="Polar plat of vv.csv",lwd=3,line.col=4,
 point.symbols=4,rp.type="p",show.centroid=TRUE,radial.lim=c(0,max(vv$r)))
draw.circle(0.3,0.15,radius=2.5,lwd=2,border="red")
draw.ellipse(0.28,0.15,a=2.6,b=2.5,angle=19,border="green")

Using a circle (red) there is not much left to explain. Adjusting the
major and minor axes and the angle gives a pretty good fit.

Jim

On Wed, Dec 4, 2019 at 10:44 AM vod vos <vodvos at zoho.com> wrote:
>
> Hi drjimlemon,
> Thank you, but it seems no working.
> The raw  csv file is here,  we need just consider the r and theta columns in polar coordinate.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: vv.png
Type: image/png
Size: 67427 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20191204/928347e8/attachment.png>

From tg@77m @end|ng |rom y@hoo@com  Wed Dec  4 06:37:34 2019
From: tg@77m @end|ng |rom y@hoo@com (Thomas Subia)
Date: Wed, 4 Dec 2019 05:37:34 +0000 (UTC)
Subject: [R] Combining text files
References: <2007642980.8545491.1575437854634.ref@mail.yahoo.com>
Message-ID: <2007642980.8545491.1575437854634@mail.yahoo.com>

Colleagues,
I've got several text files which contain data for each metric I need to report on.One text file contains the serial number data. Another has customer and work order number. Another has test data. All text files have the same number of rows but all have different numbers of columns.

I was thinking about using bind_cols() to do this. 

Am I on the right track here?
All the best,
Thomas SubiaStatistician / Sr. Quality EngineerIMG Precision Inc.

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Dec  4 06:55:08 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 03 Dec 2019 21:55:08 -0800
Subject: [R] Combining text files
In-Reply-To: <2007642980.8545491.1575437854634@mail.yahoo.com>
References: <2007642980.8545491.1575437854634.ref@mail.yahoo.com>
 <2007642980.8545491.1575437854634@mail.yahoo.com>
Message-ID: <1E5E42ED-623D-40B8-AD17-D6F54665DB82@dcn.davis.ca.us>

Do you know for certain that the rows are in the same order? then yes... cbind or bind_cols would do it. I would be surprised to find such files... but it is possible.

On December 3, 2019 9:37:34 PM PST, Thomas Subia via R-help <r-help at r-project.org> wrote:
>Colleagues,
>I've got several text files which contain data for each metric I need
>to report on.One text file contains the serial number data. Another has
>customer and work order number. Another has test data. All text files
>have the same number of rows but all have different numbers of columns.
>
>I was thinking about using bind_cols() to do this. 
>
>Am I on the right track here?
>All the best,
>Thomas SubiaStatistician / Sr. Quality EngineerIMG Precision Inc.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Dec  4 09:16:18 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 4 Dec 2019 08:16:18 +0000
Subject: [R] Two geom_bar with counts to put in the same plot
In-Reply-To: <7CF54C04-1DBE-40B2-9C2E-F014571810EC@gmail.com>
References: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>
 <44f89f64-08c8-617c-8de5-9425e9b57f51@sapo.pt>
 <7CF54C04-1DBE-40B2-9C2E-F014571810EC@gmail.com>
Message-ID: <afa9e5f9-7bb0-fb33-6cd7-341775b1dfd8@sapo.pt>

Hello,

Is it as simple as this? The code below does not separate the 
participant1 and participant2, only the 'delta' variables.


idv <- grep("part", names(DB)[-(3:4)], ignore.case = TRUE, value = TRUE)
dblong <- reshape2::melt(DB[-(3:4)], id.vars = idv)
head(dblong)

ggplot(dblong, aes(x = value, fill = variable)) +
   geom_density(aes(alpha = 0.2)) +
   scale_alpha_continuous(guide = "none")


I will also repost the data, since you have posted a matrix and this 
code needs a data.frame.


DB <-
structure(list(participation1 = c(1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), participation2 = c(1,
1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,
0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,
1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,
1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,
0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,
0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1), ParticipantsNOPUN = structure(c(2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA), .Label = c("1", "2"), class = "factor"),
     ParticipantsPUN = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 1L,
     2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L,
     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L,
     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L,
     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L,
     1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,
     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L,
     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L,
     2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,
     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L,
     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"),
     delta11_L = c(0, -10, -10, 0, 0, 0, -30, 0, 10, 0, 20, 10,
     0, 0, 20, 0, 0, -10, 30, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0,
     0, 0, 0, 0, -10, 0, 0, 0, 40, -10, 0, 10, 0, 10, 0, -20,
     0, 0, 0, 10, -20, 10, -10, 40, -10, -10, 10, 20, 10, 0, 0,
     0, 0, 0, 0, -10, 0, 0, 20, 0, 0, 0, 0, 10, 0, 0, 0, 10, 0,
     -10, 10, 0, 0, 10, 10, 10, 0, 0, 0, 0, 0, -10, 0, 0, 0, 20,
     0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 20, -20,
     0, 0, -10, 0, 0, 0, 0, -10, 10, 0, 20, 0, 0, 0, 0, 0, -10,
     0, 0, 0, 0, 0, -10, 0, 0, -10, 0, -10, 30, -10, 0, 0, 10,
     -10, 0, -10, -10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0,
     10, 10, 0, 0, -20, -10, 0, 0, 0, 0, 0, 0, 10, 30, 40, 30,
     30, 30, 30, 20, 20, 40, 20, 20, 10, 20, 30, 20, 40, 20, 30,
     20, 30, 20, 20, 30, 20, 40, 10, 20, 10, 30, 30, 30, 30, 10,
     30, 30, 20, 10, 40, 30, 40, 40, 30, 20, 10, 10, 20, 20, 30,
     40, 40, 40, 40, 0, 20, 20, 40, 10, 20, 20, 10), delta2_L = c(0,
     -10, 0, 0, 0, 0, 30, 10, 40, 0, 0, 0, 0, 0, 10, 0, 0, 30,
     10, 10, 0, 0, -10, -20, -10, 0, 0, 0, -10, 10, 0, 40, 0,
     30, 0, 10, 0, 40, 0, 0, -10, 0, 10, 40, -10, 0, 0, 0, 10,
     0, 10, -10, 40, 10, 20, 10, 40, 0, 10, -10, 0, 40, 0, 0,
     -10, 0, 0, 20, -10, 0, 10, 0, 30, -10, 0, 0, 0, -10, 40,
     10, 10, 0, 10, -10, 0, 10, 0, 10, 0, -20, 20, 0, 0, -20,
     20, 0, -30, 20, 0, 0, 20, 10, 0, 20, 30, 0, 0, -10, 10, 10,
     0, -10, 40, 10, 0, 10, 0, 0, 20, 10, 20, 30, 0, 40, 30, 0,
     20, 40, -10, 0, 0, 0, -10, 0, 20, -10, 0, 0, 10, 0, 0, 20,
     -20, -20, 0, 20, 0, 0, 10, 0, -10, -10, 20, -10, 0, 0, 0,
     0, 0, 0, 0, -10, 30, 10, 0, 0, 10, 20, 10, -10, 10, 0, 0,
     -10, 30, -20, 10, 0, 0, 0, 10, 10, 10, 10, -10, 0, 20, 10,
     10, 10, 0, -10, -10, 0, 0, 10, 20, 0, -10, 10, 0, 10, 20,
     10, 0, 0, 0, 0, 10, 10, 10, 30, 10, 0, 0, -10, 40, 0, 0,
     10, 10, 40, 30, -10, 0, 0, 10, 20, 0, 0, 10, 40, 0, 0, -10,
     -20)), row.names = c(NA, -236L), class = "data.frame")


Hope this helps,

Rui Barradas



?s 14:10 de 03/12/19, Francesca escreveu:
> Hi
> here it is;. THANKS!
> 
> dput(DATASET)
> structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,
> 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,
> 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,
> 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,
> 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,
> 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,
> 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,
> 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 2, 2, 2, 2, 2,
> 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
> 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2,
> 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,
> 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,
> -10, -10, 0, 0, 0, -30, 0, 10, 0, 20, 10, 0, 0, 20, 0, 0, -10,
> 30, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, -10, 0, 0, 0,
> 40, -10, 0, 10, 0, 10, 0, -20, 0, 0, 0, 10, -20, 10, -10, 40,
> -10, -10, 10, 20, 10, 0, 0, 0, 0, 0, 0, -10, 0, 0, 20, 0, 0,
> 0, 0, 10, 0, 0, 0, 10, 0, -10, 10, 0, 0, 10, 10, 10, 0, 0, 0,
> 0, 0, -10, 0, 0, 0, 20, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 10, 0,
> 10, 0, 0, 0, 20, -20, 0, 0, -10, 0, 0, 0, 0, -10, 10, 0, 20,
> 0, 0, 0, 0, 0, -10, 0, 0, 0, 0, 0, -10, 0, 0, -10, 0, -10, 30,
> -10, 0, 0, 10, -10, 0, -10, -10, 0, 10, 0, 0, 0, 0, 0, 0, 0,
> 0, 10, 0, 0, 10, 10, 0, 0, -20, -10, 0, 0, 0, 0, 0, 0, 10, 30,
> 40, 30, 30, 30, 30, 20, 20, 40, 20, 20, 10, 20, 30, 20, 40, 20,
> 30, 20, 30, 20, 20, 30, 20, 40, 10, 20, 10, 30, 30, 30, 30, 10,
> 30, 30, 20, 10, 40, 30, 40, 40, 30, 20, 10, 10, 20, 20, 30, 40,
> 40, 40, 40, 0, 20, 20, 40, 10, 20, 20, 10, 0, -10, 0, 0, 0, 0,
> 30, 10, 40, 0, 0, 0, 0, 0, 10, 0, 0, 30, 10, 10, 0, 0, -10, -20,
> -10, 0, 0, 0, -10, 10, 0, 40, 0, 30, 0, 10, 0, 40, 0, 0, -10,
> 0, 10, 40, -10, 0, 0, 0, 10, 0, 10, -10, 40, 10, 20, 10, 40,
> 0, 10, -10, 0, 40, 0, 0, -10, 0, 0, 20, -10, 0, 10, 0, 30, -10,
> 0, 0, 0, -10, 40, 10, 10, 0, 10, -10, 0, 10, 0, 10, 0, -20, 20,
> 0, 0, -20, 20, 0, -30, 20, 0, 0, 20, 10, 0, 20, 30, 0, 0, -10,
> 10, 10, 0, -10, 40, 10, 0, 10, 0, 0, 20, 10, 20, 30, 0, 40, 30,
> 0, 20, 40, -10, 0, 0, 0, -10, 0, 20, -10, 0, 0, 10, 0, 0, 20,
> -20, -20, 0, 20, 0, 0, 10, 0, -10, -10, 20, -10, 0, 0, 0, 0,
> 0, 0, 0, -10, 30, 10, 0, 0, 10, 20, 10, -10, 10, 0, 0, -10, 30,
> -20, 10, 0, 0, 0, 10, 10, 10, 10, -10, 0, 20, 10, 10, 10, 0,
> -10, -10, 0, 0, 10, 20, 0, -10, 10, 0, 10, 20, 10, 0, 0, 0, 0,
> 10, 10, 10, 30, 10, 0, 0, -10, 40, 0, 0, 10, 10, 40, 30, -10,
> 0, 0, 10, 20, 0, 0, 10, 40, 0, 0, -10, -20), .Dim = c(236L, 6L
> ), .Dimnames = list(NULL, c("participation1", "participation2",
> "ParticipantsNOPUN", "ParticipantsPUN", "delta11_L", "delta2_L"
> )))
> 
> 
> 
> 
> 
> Francesca Pancotto
> ----------------------------------
> Francesca Pancotto, PhD
> Associate Professor of Political Economy
> Universit? di Modena e Reggio Emilia
> Viale A. Allegri, 9
> 40121 Reggio Emilia
> Office: +39 0522 523264
> Web:
> https://sites.google.com/view/francescapancotto/home
> 
> ----------------------------------
> 
>> Il giorno 3 dic 2019, alle ore 15:03, Rui Barradas 
>> <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> ha scritto:
>>
>> Hello,
>>
>> Please post the output of
>>
>> dput(DB)
>>
>> in a next e-mail to R-Help, like this it's difficult for us to use the 
>> data you posted.
>>
>> And yes, I bet you will need the data in long format. It is a frequent 
>> first step to the problem of plotting two or more columns in the same 
>> graph. To say more only with data.
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 09:18 de 03/12/19, Francesca escreveu:
>>> Dear Contributors,
>>> I would like to ask help on how to create a ?plot that is the overlapping
>>> of two other plots.
>>> It is a geom_bar structure, where I want to count the occurrences of two
>>> variables, participation1 and participation2 that I recoded as factors as
>>> ParticipationNOPUN and ParticipationPUN to have nice names in the legend.
>>> The variables to "count" in the two plots are delta11_L and delta2_L
>>> These are my data and code to create the two plots. I would like to put
>>> them in the same plot as superimposed areas so that I see the change 
>>> in the
>>> distribution of counts in the two cases.
>>> This is DB:
>>> participation1 participation2 ParticipantsNOPUN ParticipantsPUN delta11_L
>>> delta2_L
>>> ??[1,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ??[2,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ??-10 ?????-10
>>> ??[3,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ??-10 ???????0
>>> ??[4,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ??[5,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ??[6,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ??[7,] ?????????????1 ?????????????0 ????????????????2 ??????????????1
>>> ??-30 ??????30
>>> ??[8,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ??????10
>>> ??[9,] ?????????????1 ?????????????0 ????????????????2 ??????????????1
>>> ???10 ??????40
>>> ?[10,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ?[11,] ?????????????0 ?????????????0 ????????????????1 ??????????????1
>>> ???20 ???????0
>>> ?[12,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ???10 ???????0
>>> ?[13,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ?[14,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ?[15,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ???20 ??????10
>>> ?[16,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ?[17,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ?[18,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ??-10 ??????30
>>> ?[19,] ?????????????0 ?????????????0 ????????????????1 ??????????????1
>>> ???30 ??????10
>>> ?[20,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ???10 ??????10
>>> ?[21,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ?[22,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ?[23,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ?????-10
>>> ?[24,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ?????-20
>>> ?[25,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ???10 ?????-10
>>> ?[26,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> ?[27,] ?????????????1 ?????????????1 ????????????????2 ??????????????2
>>> ????0 ???????0
>>> First PLOT(I need to subset the data to eliminate some NA. NB: the two
>>> dataframes end up not having the same number of rows for this reason):
>>> ggplot(data=subset(DB, !is.na(participation1)), aes(x = delta11_L, fill
>>> =ParticipantsNOPUN))+
>>> ?????????geom_bar(position = "dodge")+ theme_bw(base_size = 12) +
>>> labs(x="Delta Contributions (PGG w/out punishment)")+
>>> ??theme(legend.position = "top",legend.title = element_blank())
>>> +scale_fill_brewer(palette="Set1")
>>> Second PLOT:
>>> ?ggplot(DB, aes(x = delta2_L, fill =ParticipantsPUN) ?, aes(x = delta2_L,
>>> fill =ParticipantsPUN))+
>>> ??geom_bar(position = "dodge")+ theme_bw(base_size = 12) + labs(x="Delta
>>> Contributions (PGG w/punishment)")+
>>> ??theme(legend.position = "top",legend.title = element_blank())
>>> +scale_fill_brewer(palette="Set1")
>>> is it possible to create a density plot of the two counts data on the 
>>> same
>>> plot?
>>> Do I need to create a variable count or long data format?
>>> Thanks
>>> [[alternative HTML version deleted]]
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
>>> UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From er|cjberger @end|ng |rom gm@||@com  Wed Dec  4 10:23:05 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 4 Dec 2019 11:23:05 +0200
Subject: [R] Combining text files
In-Reply-To: <1E5E42ED-623D-40B8-AD17-D6F54665DB82@dcn.davis.ca.us>
References: <2007642980.8545491.1575437854634.ref@mail.yahoo.com>
 <2007642980.8545491.1575437854634@mail.yahoo.com>
 <1E5E42ED-623D-40B8-AD17-D6F54665DB82@dcn.davis.ca.us>
Message-ID: <CAGgJW76RVuw+_39OtG0ZuddTgyopWSdX_4g=sc9P2tnh=7URbQ@mail.gmail.com>

Continuing with Jeff's point: do you know for certain that the serial
number in row 5 of one file corresponds to the 'work order number' in row 5
of a different file?
Ideally this could be verified based on some sort of identifier that
appears as a column in both files and you could match up corresponding rows
in the two files by matching this identifier (or possibly multiple
identifiers.)
This type of matching is called a join and joins are supported in the dplyr
package (which also provides the bind_cols() function you referred to.)
Check out
?dplyr::join

HTH,
Eric



On Wed, Dec 4, 2019 at 7:55 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Do you know for certain that the rows are in the same order? then yes...
> cbind or bind_cols would do it. I would be surprised to find such files...
> but it is possible.
>
> On December 3, 2019 9:37:34 PM PST, Thomas Subia via R-help <
> r-help at r-project.org> wrote:
> >Colleagues,
> >I've got several text files which contain data for each metric I need
> >to report on.One text file contains the serial number data. Another has
> >customer and work order number. Another has test data. All text files
> >have the same number of rows but all have different numbers of columns.
> >
> >I was thinking about using bind_cols() to do this.
> >
> >Am I on the right track here?
> >All the best,
> >Thomas SubiaStatistician / Sr. Quality EngineerIMG Precision Inc.
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Wed Dec  4 12:36:40 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Wed, 4 Dec 2019 12:36:40 +0100
Subject: [R] Error in FUN(X[[i]], ...) : subscript out of bounds
Message-ID: <CA+nrPnvxLuh=jHkrXYOdshErm_y77W8MVGso4PvtzUGV-XA9eQ@mail.gmail.com>

Hi , I know nobody will respond to my query as I asked few in the past and
no answer received for any of my questions. However, I am asking here with
the hope it will get responded.

I am using bayesian optimization to tune the parameter of mtry for random
forest but it gives me the error: Error in FUN(X[[i]], ...) : subscript out
of bounds

I am using the following code:

fit_bayes <- function(mtry) {
  ## Use the same model code but for a single (C, sigma) pair.
  mod <- train(Effort ~ ., data = tr,
               method = "rf",
               preProc = c("center", "scale", "zv"),
               metric = "RMSE",
               trControl = ctrl,
               tuneGrid = data.frame(C = 10^(mtry)))

  list(Score = -getTrainPerf(mod)[, "TrainRMSE"], Pred = 0)
}


library(rBayesianOptimization)

bounds <- list(mtry = c(-2,  5)


set.seed(8606)
bo_search <- BayesianOptimization(fit_bayes,
                                  bounds = bounds,
                                  init_points = 10,
                                  n_iter = 100,
                                  acq = "ucb",
                                  kappa = 1,
                                  eps = 0.0)
bo_search

	[[alternative HTML version deleted]]


From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Wed Dec  4 15:27:35 2019
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Wed, 4 Dec 2019 15:27:35 +0100
Subject: [R] Two geom_bar with counts to put in the same plot
In-Reply-To: <3de1995f-a5a2-167a-10b0-229f419514ff@sapo.pt>
References: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>
 <44f89f64-08c8-617c-8de5-9425e9b57f51@sapo.pt>
 <7CF54C04-1DBE-40B2-9C2E-F014571810EC@gmail.com>
 <afa9e5f9-7bb0-fb33-6cd7-341775b1dfd8@sapo.pt>
 <CAKFaUKga_K3i9LRsUnS-V2H_Q6ZZgYVVCOny7gxQn-M3ZgpWgw@mail.gmail.com>
 <3de1995f-a5a2-167a-10b0-229f419514ff@sapo.pt>
Message-ID: <CAKFaUKg3eZKAnYjjh-zoMUeenT-Y6mDU_8kLi37LkFSUYcjHnA@mail.gmail.com>

Hi!
It is not exactly what I wanted but more than I suspected I could get.
Thanks a lot, this is awesome!
Francesca

On Wed, 4 Dec 2019 at 14:04, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Please keep R-Help in the thread.
>
> As for the question, the following divides by facets, participation1/2
> with values 0/1. See if that's what you want.
>
>
> idv <- grep("part", names(DB)[-(3:4)], ignore.case = TRUE, value = TRUE)
> dblong <- reshape2::melt(DB[-(3:4)], id.vars = idv)
> dblong <- reshape2::melt(dblong, id.vars = c("variable", "value"))
> names(dblong) <- c("deltaVar", "delta", "participationVar",
> "participation")
> dblong <- dblong[complete.cases(dblong),]
>
> ggplot(dblong, aes(x = delta, fill = deltaVar)) +
>    geom_density(aes(alpha = 0.2)) +
>    scale_alpha_continuous(guide = "none") +
>    facet_wrap(participationVar ~ participation)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 08:25 de 04/12/19, Francesca escreveu:
> > Dear  Rui
> > the code works and the final picture is aesthetical as I wanted(very
> > beautiful indeed), but I probably did not explain that the two
> > distributions that I want to overlap, must be different by participation
> > 1 and participation 2, which are to dummy variables that identify :
> > Participation 1(equivalent to PARTICIPATIONNOPUN): 1 participants, 0 non
> > participants, for the variable delta11_L
> > Participation 2(equivalent to PARTICIPATIONPUN): 1 participants, 0 non
> > participants, for the variable delta2_L
> >
> > The density plots are four in the end rather than 2: I compare delta11_L
> > for Participants1 vsnon participants and delta2_L for Participants 2 vs
> > non Participants 2,
> > I basically want to verify whether the population of Participants vs Non
> > participants, change going from delta11_L to delta2_L
> >
> >
> > Sorry for being unclear.
> > Thanks for any help.
> > Francesca
> >
> > On Wed, 4 Dec 2019 at 09:16, Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     Is it as simple as this? The code below does not separate the
> >     participant1 and participant2, only the 'delta' variables.
> >
> >
> >     idv <- grep("part", names(DB)[-(3:4)], ignore.case = TRUE, value =
> TRUE)
> >     dblong <- reshape2::melt(DB[-(3:4)], id.vars = idv)
> >     head(dblong)
> >
> >     ggplot(dblong, aes(x = value, fill = variable)) +
> >         geom_density(aes(alpha = 0.2)) +
> >         scale_alpha_continuous(guide = "none")
> >
> >
> >     I will also repost the data, since you have posted a matrix and this
> >     code needs a data.frame.
> >
> >
> >     DB <-
> >     structure(list(participation1 = c(1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> >     1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), participation2 = c(1,
> >     1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,
> >     0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,
> >     1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,
> >     1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,
> >     0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,
> >     0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1), ParticipantsNOPUN = structure(c(2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA), .Label = c("1", "2"), class =
> >     "factor"),
> >           ParticipantsPUN = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 1L,
> >           2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L,
> >           2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L,
> >           2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L,
> >           1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L,
> >           2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L,
> >           2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"),
> >           delta11_L = c(0, -10, -10, 0, 0, 0, -30, 0, 10, 0, 20, 10,
> >           0, 0, 20, 0, 0, -10, 30, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0,
> >           0, 0, 0, 0, -10, 0, 0, 0, 40, -10, 0, 10, 0, 10, 0, -20,
> >           0, 0, 0, 10, -20, 10, -10, 40, -10, -10, 10, 20, 10, 0, 0,
> >           0, 0, 0, 0, -10, 0, 0, 20, 0, 0, 0, 0, 10, 0, 0, 0, 10, 0,
> >           -10, 10, 0, 0, 10, 10, 10, 0, 0, 0, 0, 0, -10, 0, 0, 0, 20,
> >           0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 20, -20,
> >           0, 0, -10, 0, 0, 0, 0, -10, 10, 0, 20, 0, 0, 0, 0, 0, -10,
> >           0, 0, 0, 0, 0, -10, 0, 0, -10, 0, -10, 30, -10, 0, 0, 10,
> >           -10, 0, -10, -10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0,
> >           10, 10, 0, 0, -20, -10, 0, 0, 0, 0, 0, 0, 10, 30, 40, 30,
> >           30, 30, 30, 20, 20, 40, 20, 20, 10, 20, 30, 20, 40, 20, 30,
> >           20, 30, 20, 20, 30, 20, 40, 10, 20, 10, 30, 30, 30, 30, 10,
> >           30, 30, 20, 10, 40, 30, 40, 40, 30, 20, 10, 10, 20, 20, 30,
> >           40, 40, 40, 40, 0, 20, 20, 40, 10, 20, 20, 10), delta2_L = c(0,
> >           -10, 0, 0, 0, 0, 30, 10, 40, 0, 0, 0, 0, 0, 10, 0, 0, 30,
> >           10, 10, 0, 0, -10, -20, -10, 0, 0, 0, -10, 10, 0, 40, 0,
> >           30, 0, 10, 0, 40, 0, 0, -10, 0, 10, 40, -10, 0, 0, 0, 10,
> >           0, 10, -10, 40, 10, 20, 10, 40, 0, 10, -10, 0, 40, 0, 0,
> >           -10, 0, 0, 20, -10, 0, 10, 0, 30, -10, 0, 0, 0, -10, 40,
> >           10, 10, 0, 10, -10, 0, 10, 0, 10, 0, -20, 20, 0, 0, -20,
> >           20, 0, -30, 20, 0, 0, 20, 10, 0, 20, 30, 0, 0, -10, 10, 10,
> >           0, -10, 40, 10, 0, 10, 0, 0, 20, 10, 20, 30, 0, 40, 30, 0,
> >           20, 40, -10, 0, 0, 0, -10, 0, 20, -10, 0, 0, 10, 0, 0, 20,
> >           -20, -20, 0, 20, 0, 0, 10, 0, -10, -10, 20, -10, 0, 0, 0,
> >           0, 0, 0, 0, -10, 30, 10, 0, 0, 10, 20, 10, -10, 10, 0, 0,
> >           -10, 30, -20, 10, 0, 0, 0, 10, 10, 10, 10, -10, 0, 20, 10,
> >           10, 10, 0, -10, -10, 0, 0, 10, 20, 0, -10, 10, 0, 10, 20,
> >           10, 0, 0, 0, 0, 10, 10, 10, 30, 10, 0, 0, -10, 40, 0, 0,
> >           10, 10, 40, 30, -10, 0, 0, 10, 20, 0, 0, 10, 40, 0, 0, -10,
> >           -20)), row.names = c(NA, -236L), class = "data.frame")
> >
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >
> >
> >     ?s 14:10 de 03/12/19, Francesca escreveu:
> >      > Hi
> >      > here it is;. THANKS!
> >      >
> >      > dput(DATASET)
> >      > structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> >      > 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> >      > 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,
> >      > 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >      > 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,
> >      > 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >      > 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,
> >      > 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> >      > 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,
> >      > 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,
> >      > 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,
> >      > 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 2, 2, 2, 2, 2,
> >      > 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2,
> >      > 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2,
> >      > 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,
> >      > 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,
> >      > -10, -10, 0, 0, 0, -30, 0, 10, 0, 20, 10, 0, 0, 20, 0, 0, -10,
> >      > 30, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, -10, 0, 0, 0,
> >      > 40, -10, 0, 10, 0, 10, 0, -20, 0, 0, 0, 10, -20, 10, -10, 40,
> >      > -10, -10, 10, 20, 10, 0, 0, 0, 0, 0, 0, -10, 0, 0, 20, 0, 0,
> >      > 0, 0, 10, 0, 0, 0, 10, 0, -10, 10, 0, 0, 10, 10, 10, 0, 0, 0,
> >      > 0, 0, -10, 0, 0, 0, 20, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 10, 0,
> >      > 10, 0, 0, 0, 20, -20, 0, 0, -10, 0, 0, 0, 0, -10, 10, 0, 20,
> >      > 0, 0, 0, 0, 0, -10, 0, 0, 0, 0, 0, -10, 0, 0, -10, 0, -10, 30,
> >      > -10, 0, 0, 10, -10, 0, -10, -10, 0, 10, 0, 0, 0, 0, 0, 0, 0,
> >      > 0, 10, 0, 0, 10, 10, 0, 0, -20, -10, 0, 0, 0, 0, 0, 0, 10, 30,
> >      > 40, 30, 30, 30, 30, 20, 20, 40, 20, 20, 10, 20, 30, 20, 40, 20,
> >      > 30, 20, 30, 20, 20, 30, 20, 40, 10, 20, 10, 30, 30, 30, 30, 10,
> >      > 30, 30, 20, 10, 40, 30, 40, 40, 30, 20, 10, 10, 20, 20, 30, 40,
> >      > 40, 40, 40, 0, 20, 20, 40, 10, 20, 20, 10, 0, -10, 0, 0, 0, 0,
> >      > 30, 10, 40, 0, 0, 0, 0, 0, 10, 0, 0, 30, 10, 10, 0, 0, -10, -20,
> >      > -10, 0, 0, 0, -10, 10, 0, 40, 0, 30, 0, 10, 0, 40, 0, 0, -10,
> >      > 0, 10, 40, -10, 0, 0, 0, 10, 0, 10, -10, 40, 10, 20, 10, 40,
> >      > 0, 10, -10, 0, 40, 0, 0, -10, 0, 0, 20, -10, 0, 10, 0, 30, -10,
> >      > 0, 0, 0, -10, 40, 10, 10, 0, 10, -10, 0, 10, 0, 10, 0, -20, 20,
> >      > 0, 0, -20, 20, 0, -30, 20, 0, 0, 20, 10, 0, 20, 30, 0, 0, -10,
> >      > 10, 10, 0, -10, 40, 10, 0, 10, 0, 0, 20, 10, 20, 30, 0, 40, 30,
> >      > 0, 20, 40, -10, 0, 0, 0, -10, 0, 20, -10, 0, 0, 10, 0, 0, 20,
> >      > -20, -20, 0, 20, 0, 0, 10, 0, -10, -10, 20, -10, 0, 0, 0, 0,
> >      > 0, 0, 0, -10, 30, 10, 0, 0, 10, 20, 10, -10, 10, 0, 0, -10, 30,
> >      > -20, 10, 0, 0, 0, 10, 10, 10, 10, -10, 0, 20, 10, 10, 10, 0,
> >      > -10, -10, 0, 0, 10, 20, 0, -10, 10, 0, 10, 20, 10, 0, 0, 0, 0,
> >      > 10, 10, 10, 30, 10, 0, 0, -10, 40, 0, 0, 10, 10, 40, 30, -10,
> >      > 0, 0, 10, 20, 0, 0, 10, 40, 0, 0, -10, -20), .Dim = c(236L, 6L
> >      > ), .Dimnames = list(NULL, c("participation1", "participation2",
> >      > "ParticipantsNOPUN", "ParticipantsPUN", "delta11_L", "delta2_L"
> >      > )))
> >      >
> >      >
> >      >
> >      >
> >      >
> >      > Francesca Pancotto
> >      > ----------------------------------
> >      > Francesca Pancotto, PhD
> >      > Associate Professor of Political Economy
> >      > Universit? di Modena e Reggio Emilia
> >      > Viale A. Allegri, 9
> >      > 40121 Reggio Emilia
> >      > Office: +39 0522 523264
> >      > Web:
> >      > https://sites.google.com/view/francescapancotto/home
> >      >
> >      > ----------------------------------
> >      >
> >      >> Il giorno 3 dic 2019, alle ore 15:03, Rui Barradas
> >      >> <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
> >     <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>> ha
> scritto:
> >      >>
> >      >> Hello,
> >      >>
> >      >> Please post the output of
> >      >>
> >      >> dput(DB)
> >      >>
> >      >> in a next e-mail to R-Help, like this it's difficult for us to
> >     use the
> >      >> data you posted.
> >      >>
> >      >> And yes, I bet you will need the data in long format. It is a
> >     frequent
> >      >> first step to the problem of plotting two or more columns in the
> >     same
> >      >> graph. To say more only with data.
> >      >>
> >      >>
> >      >> Hope this helps,
> >      >>
> >      >> Rui Barradas
> >      >>
> >      >> ?s 09:18 de 03/12/19, Francesca escreveu:
> >      >>> Dear Contributors,
> >      >>> I would like to ask help on how to create a  plot that is the
> >     overlapping
> >      >>> of two other plots.
> >      >>> It is a geom_bar structure, where I want to count the
> >     occurrences of two
> >      >>> variables, participation1 and participation2 that I recoded as
> >     factors as
> >      >>> ParticipationNOPUN and ParticipationPUN to have nice names in
> >     the legend.
> >      >>> The variables to "count" in the two plots are delta11_L and
> >     delta2_L
> >      >>> These are my data and code to create the two plots. I would
> >     like to put
> >      >>> them in the same plot as superimposed areas so that I see the
> >     change
> >      >>> in the
> >      >>> distribution of counts in the two cases.
> >      >>> This is DB:
> >      >>> participation1 participation2 ParticipantsNOPUN ParticipantsPUN
> >     delta11_L
> >      >>> delta2_L
> >      >>>   [1,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>   [2,]              1              1                 2
> >                    2
> >      >>>   -10      -10
> >      >>>   [3,]              1              1                 2
> >                    2
> >      >>>   -10        0
> >      >>>   [4,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>   [5,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>   [6,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>   [7,]              1              0                 2
> >                    1
> >      >>>   -30       30
> >      >>>   [8,]              1              1                 2
> >                    2
> >      >>>     0       10
> >      >>>   [9,]              1              0                 2
> >                    1
> >      >>>    10       40
> >      >>>  [10,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [11,]              0              0                 1
> >                    1
> >      >>>    20        0
> >      >>>  [12,]              1              1                 2
> >                    2
> >      >>>    10        0
> >      >>>  [13,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [14,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [15,]              1              1                 2
> >                    2
> >      >>>    20       10
> >      >>>  [16,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [17,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [18,]              1              1                 2
> >                    2
> >      >>>   -10       30
> >      >>>  [19,]              0              0                 1
> >                    1
> >      >>>    30       10
> >      >>>  [20,]              1              1                 2
> >                    2
> >      >>>    10       10
> >      >>>  [21,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [22,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [23,]              1              1                 2
> >                    2
> >      >>>     0      -10
> >      >>>  [24,]              1              1                 2
> >                    2
> >      >>>     0      -20
> >      >>>  [25,]              1              1                 2
> >                    2
> >      >>>    10      -10
> >      >>>  [26,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [27,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>> First PLOT(I need to subset the data to eliminate some NA. NB:
> >     the two
> >      >>> dataframes end up not having the same number of rows for this
> >     reason):
> >      >>> ggplot(data=subset(DB, !is.na <http://is.na>(participation1)),
> >     aes(x = delta11_L, fill
> >      >>> =ParticipantsNOPUN))+
> >      >>>          geom_bar(position = "dodge")+ theme_bw(base_size = 12)
> +
> >      >>> labs(x="Delta Contributions (PGG w/out punishment)")+
> >      >>>   theme(legend.position = "top",legend.title = element_blank())
> >      >>> +scale_fill_brewer(palette="Set1")
> >      >>> Second PLOT:
> >      >>>  ggplot(DB, aes(x = delta2_L, fill =ParticipantsPUN)  , aes(x =
> >     delta2_L,
> >      >>> fill =ParticipantsPUN))+
> >      >>>   geom_bar(position = "dodge")+ theme_bw(base_size = 12) +
> >     labs(x="Delta
> >      >>> Contributions (PGG w/punishment)")+
> >      >>>   theme(legend.position = "top",legend.title = element_blank())
> >      >>> +scale_fill_brewer(palette="Set1")
> >      >>> is it possible to create a density plot of the two counts data
> >     on the
> >      >>> same
> >      >>> plot?
> >      >>> Do I need to create a variable count or long data format?
> >      >>> Thanks
> >      >>> [[alternative HTML version deleted]]
> >      >>> ______________________________________________
> >      >>> R-help at r-project.org <mailto:R-help at r-project.org>
> >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing
> >     list -- To
> >      >>> UNSUBSCRIBE and more, see
> >      >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >      >>> PLEASE do read the posting guide
> >      >>> http://www.R-project.org/posting-guide.html
> >      >>> and provide commented, minimal, self-contained, reproducible
> code.
> >      >
> >
> >
> >
> > --
> >
> > Francesca
> >
> > ----------------------------------
> > Francesca Pancotto, PhD
> > Universit? di Modena e Reggio Emilia
> > Viale A. Allegri, 9
> > 40121 Reggio Emilia
> > Office: +39 0522 523264
> > Web: https://sites.google.com/view/francescapancotto/home
> > <https://sites.google.com/site/francescapancotto/>
> > ----------------------------------
>


-- 

Francesca

----------------------------------
Francesca Pancotto, PhD
Universit? di Modena e Reggio Emilia
Viale A. Allegri, 9
40121 Reggio Emilia
Office: +39 0522 523264
Web: https://sites.google.com/view/francescapancotto/home
<https://sites.google.com/site/francescapancotto/>
----------------------------------

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Dec  4 16:03:52 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 4 Dec 2019 15:03:52 +0000
Subject: [R] Error in FUN(X[[i]], ...) : subscript out of bounds
In-Reply-To: <CA+nrPnvxLuh=jHkrXYOdshErm_y77W8MVGso4PvtzUGV-XA9eQ@mail.gmail.com>
References: <CA+nrPnvxLuh=jHkrXYOdshErm_y77W8MVGso4PvtzUGV-XA9eQ@mail.gmail.com>
Message-ID: <d82cb5444e734c9f9f2a001cc5d51e56@SRVEXCHCM1301.precheza.cz>

Hi

I am pretty sure that nobody will be able to answer your question due to
lack of information. 

Missing parentheses          here
bounds <- list(mtry = c(-2,  5)

Use ?debug if the error is from your function. 
If the code is coppied from some help page, use the data from help page and
try to find differences in your data and help data.

Provide reproducible example 

I get this
Error in train(Effort ~ ., data = tr, method = "rf", preProc = c("center",
: 
  could not find function "train"
Timing stopped at: 0 0 0.01

with your code

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha gupta
> Sent: Wednesday, December 4, 2019 12:37 PM
> To: r-help at r-project.org
> Subject: [R] Error in FUN(X[[i]], ...) : subscript out of bounds
> 
> Hi , I know nobody will respond to my query as I asked few in the past and
> no answer received for any of my questions. However, I am asking here with
> the hope it will get responded.
> 
> I am using bayesian optimization to tune the parameter of mtry for random
> forest but it gives me the error: Error in FUN(X[[i]], ...) : subscript
out of
> bounds
> 
> I am using the following code:
> 
> fit_bayes <- function(mtry) {
>   ## Use the same model code but for a single (C, sigma) pair.
>   mod <- train(Effort ~ ., data = tr,
>                method = "rf",
>                preProc = c("center", "scale", "zv"),
>                metric = "RMSE",
>                trControl = ctrl,
>                tuneGrid = data.frame(C = 10^(mtry)))
> 
>   list(Score = -getTrainPerf(mod)[, "TrainRMSE"], Pred = 0) }
> 
> 
> library(rBayesianOptimization)
> 
> bounds <- list(mtry = c(-2,  5)
> 
> 
> set.seed(8606)
> bo_search <- BayesianOptimization(fit_bayes,
>                                   bounds = bounds,
>                                   init_points = 10,
>                                   n_iter = 100,
>                                   acq = "ucb",
>                                   kappa = 1,
>                                   eps = 0.0) bo_search
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From pedro@r@|@e|@m@r|nho @end|ng |rom gm@||@com  Tue Dec  3 17:38:30 2019
From: pedro@r@|@e|@m@r|nho @end|ng |rom gm@||@com (Pedro Rafael)
Date: Tue, 3 Dec 2019 13:38:30 -0300
Subject: [R] [R-pkgs] ropenblas package
Message-ID: <CAKwavrn3m5nt-Y_LGiL-M=afdS-Ty=HEOAQtNg+QDsqVurq_4A@mail.gmail.com>

Dear colleagues,

The *ropenblas* <https://prdm0.github.io/ropenblas/> is a package designed
to facilitate the linking of the library *OpenBLAS*
<https://www.openblas.net/> with the language *R*
<https://www.r-project.org/>. The package, which works only for Linux
systems, will automatically download the latest source code from the
*OpenBLAS* <https://www.openblas.net/> library and compile the code. The
package will automatically bind the language *R*
<https://www.r-project.org/> to use the *OpenBLAS*
<https://www.openblas.net/> library. Everything will be done automatically
regardless of the Linux distribution you are using.

You can also specify older versions of the *OpenBLAS*
<https://www.openblas.net/> library. Automatically, if no version is
specified, the *ropenblas* <https://prdm0.github.io/ropenblas/> package
will consider the latest version of the library *OpenBLAS*
<https://www.openblas.net/>.

Considering using the *OpenBLAS* <https://www.openblas.net/> library rather
than the *BLAS* <http://www.netlib.org/blas/> may bring extra optimizations
for your code and improved computational performance for your simulations,
since *OpenBLAS* <https://www.openblas.net/> is an optimized implementation
of the library *BLAS* <http://www.netlib.org/blas/>.

Some of the reasons why it is convenient to link *R*
<https://www.r-project.org/> language to the use of *BLAS*
<http://www.netlib.org/blas/> optimized alternatives can be found *here*
<https://csantill.github.io/RPerformanceWBLAS/>. Several other *benchmarks*
<https://en.wikipedia.org/wiki/Benchmarking> that point to improved
computing performance by considering the library *OpenBLAS*
<https://www.openblas.net/> can be found on the internet.

Best regards,

Pedro Rafael.

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From W||||@m@Prophet @end|ng |rom koch|nd@com  Wed Dec  4 14:47:27 2019
From: W||||@m@Prophet @end|ng |rom koch|nd@com (Prophet, William)
Date: Wed, 4 Dec 2019 13:47:27 +0000
Subject: [R] package MCMCpack
Message-ID: <MW2PR1501MB2187EAB4931D9363565957F4E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>

I am running R on my work computer with the following parameters:
> sessionInfo()
R version 3.5.3 (2019-03-11)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)


I am trying to install the "MCMCpack" library. In the process however, I receive the message:

> install.packages("MCMCpack")

Warning in install.packages :

  package 'MCMCpack' is not available (for R version 3.5.3)


I have tried to install earlier versions of the "MCMCpack" library which I obtained from the following website:
https://cran.r-project.org/src/contrib/Archive/MCMCpack/

using the following code:
packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
install.packages(packageurl, type="source")

but I get an identical error message:

> packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"

> install.packages(packageurl, type="source")

Warning in install.packages :

  package 'https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz' is not available (for R version 3.5.3)



I realize that updating my R version to 3.6.1 could possibly solve the problem, but this would be impractical for me because my version needs to be consistent with others on my team. In any case, the fact that I am getting errors (detailed above) with *every* version of "MCMCpack" seems odd.

Do you have any suggestions for how I can install a working version of "MCMCpack" for my version of R?

Thank you,
Bill





	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Dec  4 16:31:33 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 4 Dec 2019 10:31:33 -0500
Subject: [R] package MCMCpack
In-Reply-To: <MW2PR1501MB2187EAB4931D9363565957F4E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
References: <MW2PR1501MB2187EAB4931D9363565957F4E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
Message-ID: <5a8d0c2a-1be1-58aa-674f-50b77def1d9f@gmail.com>

On 04/12/2019 8:47 a.m., Prophet, William wrote:
> I am running R on my work computer with the following parameters:
>> sessionInfo()
> R version 3.5.3 (2019-03-11)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> 
> I am trying to install the "MCMCpack" library. In the process however, I receive the message:
> 
>> install.packages("MCMCpack")
> 
> Warning in install.packages :
> 
>    package 'MCMCpack' is not available (for R version 3.5.3)
> 
> 
> I have tried to install earlier versions of the "MCMCpack" library which I obtained from the following website:
> https://cran.r-project.org/src/contrib/Archive/MCMCpack/
> 
> using the following code:
> packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> install.packages(packageurl, type="source")

That's not the way to install a tarball.  You should use

install.packages(packageurl, type="source", repos=NULL)

However, you may still have problems:  when I tried that, the install 
failed because of C++ errors.  I don't know if configure options (e.g. 
specifying a particular version of C++) would have fixed the problems.

Duncan Murdoch

> 
> but I get an identical error message:
> 
>> packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> 
>> install.packages(packageurl, type="source")
> 
> Warning in install.packages :
> 
>    package 'https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz' is not available (for R version 3.5.3)
> 
> 
> 
> I realize that updating my R version to 3.6.1 could possibly solve the problem, but this would be impractical for me because my version needs to be consistent with others on my team. In any case, the fact that I am getting errors (detailed above) with *every* version of "MCMCpack" seems odd.
> 
> Do you have any suggestions for how I can install a working version of "MCMCpack" for my version of R?
> 
> Thank you,
> Bill
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From W||||@m@Prophet @end|ng |rom koch|nd@com  Wed Dec  4 16:34:33 2019
From: W||||@m@Prophet @end|ng |rom koch|nd@com (Prophet, William)
Date: Wed, 4 Dec 2019 15:34:33 +0000
Subject: [R] package MCMCpack
In-Reply-To: <5a8d0c2a-1be1-58aa-674f-50b77def1d9f@gmail.com>
References: <MW2PR1501MB2187EAB4931D9363565957F4E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
 <5a8d0c2a-1be1-58aa-674f-50b77def1d9f@gmail.com>
Message-ID: <MW2PR1501MB2187DC55E997F48DEF23BC09E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>

Yes, I should have mentioned that I tried this same line of code and I still got an error. 


-----Original Message-----
From: Duncan Murdoch <murdoch.duncan at gmail.com> 
Sent: Wednesday, December 4, 2019 8:32 AM
To: Prophet, William <William.Prophet at kochind.com>; r-help at r-project.org
Subject: Re: [R] package MCMCpack

Sent by an external sender

----------------------------------------------------------------------
On 04/12/2019 8:47 a.m., Prophet, William wrote:
> I am running R on my work computer with the following parameters:
>> sessionInfo()
> R version 3.5.3 (2019-03-11)
> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8 
> x64 (build 9200)
>
>
> I am trying to install the "MCMCpack" library. In the process however, I receive the message:
>
>> install.packages("MCMCpack")
>
> Warning in install.packages :
>
>    package 'MCMCpack' is not available (for R version 3.5.3)
>
>
> I have tried to install earlier versions of the "MCMCpack" library which I obtained from the following website:
> https://cran.r-project.org/src/contrib/Archive/MCMCpack/
>
> using the following code:
> packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> install.packages(packageurl, type="source")

That's not the way to install a tarball.  You should use

install.packages(packageurl, type="source", repos=NULL)

However, you may still have problems:  when I tried that, the install failed because of C++ errors.  I don't know if configure options (e.g.
specifying a particular version of C++) would have fixed the problems.

Duncan Murdoch

>
> but I get an identical error message:
>
>> packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
>
>> install.packages(packageurl, type="source")
>
> Warning in install.packages :
>
>    package 
> 'https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-
> 4.tar.gz' is not available (for R version 3.5.3)
>
>
>
> I realize that updating my R version to 3.6.1 could possibly solve the problem, but this would be impractical for me because my version needs to be consistent with others on my team. In any case, the fact that I am getting errors (detailed above) with *every* version of "MCMCpack" seems odd.
>
> Do you have any suggestions for how I can install a working version of "MCMCpack" for my version of R?
>
> Thank you,
> Bill
>
>
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From wdun|@p @end|ng |rom t|bco@com  Wed Dec  4 16:53:30 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Wed, 4 Dec 2019 07:53:30 -0800
Subject: [R] Error in FUN(X[[i]], ...) : subscript out of bounds
In-Reply-To: <CA+nrPnvxLuh=jHkrXYOdshErm_y77W8MVGso4PvtzUGV-XA9eQ@mail.gmail.com>
References: <CA+nrPnvxLuh=jHkrXYOdshErm_y77W8MVGso4PvtzUGV-XA9eQ@mail.gmail.com>
Message-ID: <CAF8bMcaZYv0nxr6jrZUYgjwHii7aAV2+60qG5wv=d+NsXzn-rQ@mail.gmail.com>

In your fit_bayes function, you have
   getTrainPerf(mod)[, "TrainRMSE"]
What are the column name of the output of getTrainPerf(mod)?
   print(colnames(getTrainPerf(mod)))
You can home in on the problem faster if you call
   traceback()
immediately after the error.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Dec 4, 2019 at 3:38 AM Neha gupta <neha.bologna90 at gmail.com> wrote:

> Hi , I know nobody will respond to my query as I asked few in the past and
> no answer received for any of my questions. However, I am asking here with
> the hope it will get responded.
>
> I am using bayesian optimization to tune the parameter of mtry for random
> forest but it gives me the error: Error in FUN(X[[i]], ...) : subscript out
> of bounds
>
> I am using the following code:
>
> fit_bayes <- function(mtry) {
>   ## Use the same model code but for a single (C, sigma) pair.
>   mod <- train(Effort ~ ., data = tr,
>                method = "rf",
>                preProc = c("center", "scale", "zv"),
>                metric = "RMSE",
>                trControl = ctrl,
>                tuneGrid = data.frame(C = 10^(mtry)))
>
>   list(Score = -getTrainPerf(mod)[, "TrainRMSE"], Pred = 0)
> }
>
>
> library(rBayesianOptimization)
>
> bounds <- list(mtry = c(-2,  5)
>
>
> set.seed(8606)
> bo_search <- BayesianOptimization(fit_bayes,
>                                   bounds = bounds,
>                                   init_points = 10,
>                                   n_iter = 100,
>                                   acq = "ucb",
>                                   kappa = 1,
>                                   eps = 0.0)
> bo_search
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Dec  4 19:04:45 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 4 Dec 2019 12:04:45 -0600
Subject: [R] Error related to matrix system is exactly singular
Message-ID: <CAF9-5jMk-FDA64L=NnK9rzYZiW-cH1cOQ63L_dKBxX91_7_VHw@mail.gmail.com>

Hello,

I was running this software https://github.com/eleporcu/TWMR
via:

Rscript MR.R ENSG00000154803
my files are located here:
https://filebin.net/smt1kcw2d9sody67

I got this error:

[1] "ENSG00000154803"
Error in solve.default(C) :
  Lapack routine dgesv: system is exactly singular: U[15,15] = 0
Calls: solve -> solve.default
Execution halted

in the original code I changed this:

and I also in order to run it I changed the beginning of the code to be:

cmd_args <- commandArgs(TRUE)if (length(cmd_args) == 0L) stop("No
arguments specified.")
print(cmd_args)
gene<-cmd_args[length(cmd_args)]   ## Last argument is the 'gene'
Ngwas<-239087
N_eQTLs<-32000
out<-c("gene","alpha","SE","P","Nsnps","Ngene")

file<-paste(gene,"matrix",sep=".")if (!file.exists(file)) stop("File
not found: ", file)
filecluster<-read.table(file,header=T,sep=" ",dec=".")
beta<-as.matrix(filecluster[,2:(length(filecluster[1,])-1)])

when I was running it with just 3 columns in .matrix file.

Please advise, is it something wrong with the format of my files now?

Thanks

Ana

	[[alternative HTML version deleted]]


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Wed Dec  4 19:04:08 2019
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Wed, 4 Dec 2019 10:04:08 -0800
Subject: [R] How to use preProcess in Caret?
In-Reply-To: <CAMEVu8gsekqn=m79JKCnrcCfCxM15U2wJfu640GoO9BSrsj31w@mail.gmail.com>
References: <CAMEVu8gsekqn=m79JKCnrcCfCxM15U2wJfu640GoO9BSrsj31w@mail.gmail.com>
Message-ID: <CAA99HCy3nuGw1aBqQpsTyXEJch0rQJUzQRMJR4Jqf35coY9oGA@mail.gmail.com>

Hello,

Have you tried alternative methods of pre-processing your data, such
as simply calling scale()? What is the effect on convergence, for both
the caret package and and the neuralnet package? There's an example
using scale() with the neuralnet package at the link below:

https://datascienceplus.com/fitting-neural-network-in-r/

HTH, Bill.

W. Michels, Ph.D.



On Sun, Dec 1, 2019 at 10:04 AM Burak Kaymakci <burakaymakci at gmail.com> wrote:
>
> Hello there,
>
> I am using caret and neuralnet to train a neural network to predict times
> table. I am using 'backprop' algorithm for neuralnet to experiment and
> learn.
>
> Before using caret, I've trained a neuralnet without using caret, I've
> normalized my input & outputs using preProcess with 'range' method. Then I
> predicted my test set, did the multiplication and addition on predictions
> to get the real values. It gave me good results.
>
> What I want to ask is, when I try to train my network using caret, I get an
> error saying algorithm did not converge. I am thinking that I might be
> doing something wrong with my pre-processing,
>
> How would I go about using preProcess in train?
> Do I pass my not-normalized data set to the train function and train
> function handles normalization internally?
>
> You can find my R gist here
> <https://gist.github.com/andreyuhai/f299282f5a827e2a27c586afc9eb4eb5>
>
> Thank you,
> Burak
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Dec  4 21:09:08 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 04 Dec 2019 12:09:08 -0800
Subject: [R] Error related to matrix system is exactly singular
In-Reply-To: <CAF9-5jMk-FDA64L=NnK9rzYZiW-cH1cOQ63L_dKBxX91_7_VHw@mail.gmail.com>
References: <CAF9-5jMk-FDA64L=NnK9rzYZiW-cH1cOQ63L_dKBxX91_7_VHw@mail.gmail.com>
Message-ID: <A2051D44-6FE2-4540-8BC8-687F7A55C74E@dcn.davis.ca.us>

See below

On December 4, 2019 10:04:45 AM PST, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>Hello,

... removed for clarity

>
>Please advise, is it something wrong with the format of my files now?
>
>Thanks
>
>Ana
>
>	[[alternative HTML version deleted]]

... 

>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

You are sabatoging your own efforts to get help by repeatedly posting HTML- formatted email on a plain- text-only mailing list.

-- 
Sent from my phone. Please excuse my brevity.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Dec  4 23:30:50 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 4 Dec 2019 16:30:50 -0600
Subject: [R] Lapack routine dgesv: system is exactly singular
Message-ID: <CAF9-5jNBkLPkzGfg7KYeKfA51n3UhW8mJhXixg_e+-8B9=zQ7g@mail.gmail.com>

Hello,

I am sorry for posting this question related to TWMR but it seems I
can nto proceed with this. Hopefully this post now will make sense.

So I am running this code:
https://github.com/eleporcu/TWMR/blob/master/MR.R

I made this change in code so that I can run it like this:
Rscript MR.R ENSG00000154803

the change of the beginning of code is this:
cmd_args <- commandArgs(TRUE)
if (length(cmd_args) == 0L) stop("No arguments specified.")
print(cmd_args)
gene<-cmd_args[length(cmd_args)]   ## Last argument is the 'gene'
Ngwas<-239087
N_eQTLs<-32000
out<-c("gene","alpha","SE","P","Nsnps","Ngene")

file<-paste(gene,"matrix",sep=".")
if (!file.exists(file)) stop("File not found: ", file)
filecluster<-read.table(file,header=T,sep=" ",dec=".")
beta<-as.matrix(filecluster[,2:(length(filecluster[1,])-1)])

The error I am getting when I run the code with my data is:
[1] "ENSG00000154803"
Error in solve.default(C) :
  Lapack routine dgesv: system is exactly singular: U[15,15] = 0
Calls: solve -> solve.default
Execution halted


I loaded my ENSG00000154803.ld file in R as matrix (a) and:

library(matrixcalc)
is.singular.matrix(a, tol = 1e-08)
TRUE

Seems that my matrix is singular. What do you advice in this case?

Thanks
Ana


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Wed Dec  4 23:44:53 2019
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Wed, 4 Dec 2019 14:44:53 -0800
Subject: [R] package MCMCpack
In-Reply-To: <MW2PR1501MB2187DC55E997F48DEF23BC09E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
References: <MW2PR1501MB2187EAB4931D9363565957F4E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
 <5a8d0c2a-1be1-58aa-674f-50b77def1d9f@gmail.com>
 <MW2PR1501MB2187DC55E997F48DEF23BC09E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
Message-ID: <CAA99HCwmwvxit1UREnvzQ0ZV5rkK0HvQfpJE_zSkaLw5oDXVNA@mail.gmail.com>

Hi William,

It's not clear to me why you need this particular older version of
MCMCpack. From the archive I find MCMCpack_1.2-4 dates back to
2012-06-14, and MCMCpack_1.2-4.1 dates back to 2013-04-07:

MCMCpack_1.2-4.1.tar.gz 2013-04-07 00:05 481K
MCMCpack_1.2-4.tar.gz 2012-06-14 12:36 482K

Have you tried newer versions of MCMCpack? While the newest version of
MCMCpack (1.4-5) may require R (? 3.6), I have sessionInfo() logs
suggesting that MCMCpack_1.4-3 (2018-05-15 09:54 672K) ran just fine
under R version 3.3.3 (2017-03-06) -- "Another Canoe". In fact, an
archived version of the MCMCpack_1.4-3 DESCRIPTION_file indicates that
MCMCpack_1.4-3 only requires  R (>= 2.10.0).

Hope this helps,

Bill.

W. Michels, Ph.D.





On Wed, Dec 4, 2019 at 7:34 AM Prophet, William
<William.Prophet at kochind.com> wrote:
>
> Yes, I should have mentioned that I tried this same line of code and I still got an error.
>
>
> -----Original Message-----
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> Sent: Wednesday, December 4, 2019 8:32 AM
> To: Prophet, William <William.Prophet at kochind.com>; r-help at r-project.org
> Subject: Re: [R] package MCMCpack
>
> Sent by an external sender
>
> ----------------------------------------------------------------------
> On 04/12/2019 8:47 a.m., Prophet, William wrote:
> > I am running R on my work computer with the following parameters:
> >> sessionInfo()
> > R version 3.5.3 (2019-03-11)
> > Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
> > x64 (build 9200)
> >
> >
> > I am trying to install the "MCMCpack" library. In the process however, I receive the message:
> >
> >> install.packages("MCMCpack")
> >
> > Warning in install.packages :
> >
> >    package 'MCMCpack' is not available (for R version 3.5.3)
> >
> >
> > I have tried to install earlier versions of the "MCMCpack" library which I obtained from the following website:
> > https://cran.r-project.org/src/contrib/Archive/MCMCpack/
> >
> > using the following code:
> > packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> > install.packages(packageurl, type="source")
>
> That's not the way to install a tarball.  You should use
>
> install.packages(packageurl, type="source", repos=NULL)
>
> However, you may still have problems:  when I tried that, the install failed because of C++ errors.  I don't know if configure options (e.g.
> specifying a particular version of C++) would have fixed the problems.
>
> Duncan Murdoch
>
> >
> > but I get an identical error message:
> >
> >> packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> >
> >> install.packages(packageurl, type="source")
> >
> > Warning in install.packages :
> >
> >    package
> > 'https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-
> > 4.tar.gz' is not available (for R version 3.5.3)
> >
> >
> >
> > I realize that updating my R version to 3.6.1 could possibly solve the problem, but this would be impractical for me because my version needs to be consistent with others on my team. In any case, the fact that I am getting errors (detailed above) with *every* version of "MCMCpack" seems odd.
> >
> > Do you have any suggestions for how I can install a working version of "MCMCpack" for my version of R?
> >
> > Thank you,
> > Bill
> >
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From W||||@m@Prophet @end|ng |rom koch|nd@com  Wed Dec  4 23:52:30 2019
From: W||||@m@Prophet @end|ng |rom koch|nd@com (Prophet, William)
Date: Wed, 4 Dec 2019 22:52:30 +0000
Subject: [R] package MCMCpack
In-Reply-To: <CAA99HCwmwvxit1UREnvzQ0ZV5rkK0HvQfpJE_zSkaLw5oDXVNA@mail.gmail.com>
References: <MW2PR1501MB2187EAB4931D9363565957F4E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
 <5a8d0c2a-1be1-58aa-674f-50b77def1d9f@gmail.com>
 <MW2PR1501MB2187DC55E997F48DEF23BC09E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
 <CAA99HCwmwvxit1UREnvzQ0ZV5rkK0HvQfpJE_zSkaLw5oDXVNA@mail.gmail.com>
Message-ID: <MW2PR1501MB21878B1BFB26D09A1A9CCF55E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>

Thank you for your reply. I have tried various versions and I get an error in each case. In the case of MCMCpack_1.4-3 although the error may be related to something specific in my configuration. In any case, I get the following error when I try to install that version:

> packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.4-3.tar.gz"
> install.packages(packageurl, repos=NULL, type="source")
trying URL 'https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.4-3.tar.gz'
Content type 'application/x-gzip' length 688047 bytes (671 KB)
downloaded 671 KB

ERROR: dependency 'mcmc' is not available for package 'MCMCpack'
* removing 'C:/R/R-3.5.3/library/MCMCpack'
In R CMD INSTALL
Warning in install.packages :
  installation of package 'C:/Users/prophetw/AppData/Local/Temp/RtmpykZoRh/downloaded_packages/MCMCpack_1.4-3.tar.gz' had non-zero exit status





-----Original Message-----
From: William Michels <wjm1 at caa.columbia.edu> 
Sent: Wednesday, December 4, 2019 3:45 PM
To: Prophet, William <William.Prophet at kochind.com>
Cc: Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
Subject: Re: [R] package MCMCpack

Sent by an external sender

----------------------------------------------------------------------
Hi William,

It's not clear to me why you need this particular older version of MCMCpack. From the archive I find MCMCpack_1.2-4 dates back to 2012-06-14, and MCMCpack_1.2-4.1 dates back to 2013-04-07:

MCMCpack_1.2-4.1.tar.gz 2013-04-07 00:05 481K MCMCpack_1.2-4.tar.gz 2012-06-14 12:36 482K

Have you tried newer versions of MCMCpack? While the newest version of MCMCpack (1.4-5) may require R (? 3.6), I have sessionInfo() logs suggesting that MCMCpack_1.4-3 (2018-05-15 09:54 672K) ran just fine under R version 3.3.3 (2017-03-06) -- "Another Canoe". In fact, an archived version of the MCMCpack_1.4-3 DESCRIPTION_file indicates that
MCMCpack_1.4-3 only requires  R (>= 2.10.0).

Hope this helps,

Bill.

W. Michels, Ph.D.





On Wed, Dec 4, 2019 at 7:34 AM Prophet, William <William.Prophet at kochind.com> wrote:
>
> Yes, I should have mentioned that I tried this same line of code and I still got an error.
>
>
> -----Original Message-----
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> Sent: Wednesday, December 4, 2019 8:32 AM
> To: Prophet, William <William.Prophet at kochind.com>; 
> r-help at r-project.org
> Subject: Re: [R] package MCMCpack
>
> Sent by an external sender
>
> ----------------------------------------------------------------------
> On 04/12/2019 8:47 a.m., Prophet, William wrote:
> > I am running R on my work computer with the following parameters:
> >> sessionInfo()
> > R version 3.5.3 (2019-03-11)
> > Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 
> > 8
> > x64 (build 9200)
> >
> >
> > I am trying to install the "MCMCpack" library. In the process however, I receive the message:
> >
> >> install.packages("MCMCpack")
> >
> > Warning in install.packages :
> >
> >    package 'MCMCpack' is not available (for R version 3.5.3)
> >
> >
> > I have tried to install earlier versions of the "MCMCpack" library which I obtained from the following website:
> > https://cran.r-project.org/src/contrib/Archive/MCMCpack/
> >
> > using the following code:
> > packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> > install.packages(packageurl, type="source")
>
> That's not the way to install a tarball.  You should use
>
> install.packages(packageurl, type="source", repos=NULL)
>
> However, you may still have problems:  when I tried that, the install failed because of C++ errors.  I don't know if configure options (e.g.
> specifying a particular version of C++) would have fixed the problems.
>
> Duncan Murdoch
>
> >
> > but I get an identical error message:
> >
> >> packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> >
> >> install.packages(packageurl, type="source")
> >
> > Warning in install.packages :
> >
> >    package
> > 'https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.
> > 2- 4.tar.gz' is not available (for R version 3.5.3)
> >
> >
> >
> > I realize that updating my R version to 3.6.1 could possibly solve the problem, but this would be impractical for me because my version needs to be consistent with others on my team. In any case, the fact that I am getting errors (detailed above) with *every* version of "MCMCpack" seems odd.
> >
> > Do you have any suggestions for how I can install a working version of "MCMCpack" for my version of R?
> >
> > Thank you,
> > Bill
> >
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Thu Dec  5 00:14:35 2019
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Wed, 4 Dec 2019 15:14:35 -0800
Subject: [R] package MCMCpack
In-Reply-To: <MW2PR1501MB21878B1BFB26D09A1A9CCF55E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
References: <MW2PR1501MB2187EAB4931D9363565957F4E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
 <5a8d0c2a-1be1-58aa-674f-50b77def1d9f@gmail.com>
 <MW2PR1501MB2187DC55E997F48DEF23BC09E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
 <CAA99HCwmwvxit1UREnvzQ0ZV5rkK0HvQfpJE_zSkaLw5oDXVNA@mail.gmail.com>
 <MW2PR1501MB21878B1BFB26D09A1A9CCF55E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
Message-ID: <CAA99HCyqgqApJa18ifWYdVQOWr77bXxWE4r46uF06Bp471ppdA@mail.gmail.com>

You can try installing the mcmc package first:

https://cran.r-project.org/web/packages/mcmc/index.html
https://cran.r-project.org/src/contrib/Archive/mcmc/

I've used mcmc_0.9-5 with MCMCpack_1.4-3 under R version 3.3.3.

HTH, Bill.

W. Michels, Ph.D.


On Wed, Dec 4, 2019 at 2:52 PM Prophet, William
<William.Prophet at kochind.com> wrote:
>
> Thank you for your reply. I have tried various versions and I get an error in each case. In the case of MCMCpack_1.4-3 although the error may be related to something specific in my configuration. In any case, I get the following error when I try to install that version:
>
> > packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.4-3.tar.gz"
> > install.packages(packageurl, repos=NULL, type="source")
> trying URL 'https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.4-3.tar.gz'
> Content type 'application/x-gzip' length 688047 bytes (671 KB)
> downloaded 671 KB
>
> ERROR: dependency 'mcmc' is not available for package 'MCMCpack'
> * removing 'C:/R/R-3.5.3/library/MCMCpack'
> In R CMD INSTALL
> Warning in install.packages :
>   installation of package 'C:/Users/prophetw/AppData/Local/Temp/RtmpykZoRh/downloaded_packages/MCMCpack_1.4-3.tar.gz' had non-zero exit status
>
>
>
>
>
> -----Original Message-----
> From: William Michels <wjm1 at caa.columbia.edu>
> Sent: Wednesday, December 4, 2019 3:45 PM
> To: Prophet, William <William.Prophet at kochind.com>
> Cc: Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
> Subject: Re: [R] package MCMCpack
>
> Sent by an external sender
>
> ----------------------------------------------------------------------
> Hi William,
>
> It's not clear to me why you need this particular older version of MCMCpack. From the archive I find MCMCpack_1.2-4 dates back to 2012-06-14, and MCMCpack_1.2-4.1 dates back to 2013-04-07:
>
> MCMCpack_1.2-4.1.tar.gz 2013-04-07 00:05 481K MCMCpack_1.2-4.tar.gz 2012-06-14 12:36 482K
>
> Have you tried newer versions of MCMCpack? While the newest version of MCMCpack (1.4-5) may require R (? 3.6), I have sessionInfo() logs suggesting that MCMCpack_1.4-3 (2018-05-15 09:54 672K) ran just fine under R version 3.3.3 (2017-03-06) -- "Another Canoe". In fact, an archived version of the MCMCpack_1.4-3 DESCRIPTION_file indicates that
> MCMCpack_1.4-3 only requires  R (>= 2.10.0).
>
> Hope this helps,
>
> Bill.
>
> W. Michels, Ph.D.
>
>
>
>
>
> On Wed, Dec 4, 2019 at 7:34 AM Prophet, William <William.Prophet at kochind.com> wrote:
> >
> > Yes, I should have mentioned that I tried this same line of code and I still got an error.
> >
> >
> > -----Original Message-----
> > From: Duncan Murdoch <murdoch.duncan at gmail.com>
> > Sent: Wednesday, December 4, 2019 8:32 AM
> > To: Prophet, William <William.Prophet at kochind.com>;
> > r-help at r-project.org
> > Subject: Re: [R] package MCMCpack
> >
> > Sent by an external sender
> >
> > ----------------------------------------------------------------------
> > On 04/12/2019 8:47 a.m., Prophet, William wrote:
> > > I am running R on my work computer with the following parameters:
> > >> sessionInfo()
> > > R version 3.5.3 (2019-03-11)
> > > Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >=
> > > 8
> > > x64 (build 9200)
> > >
> > >
> > > I am trying to install the "MCMCpack" library. In the process however, I receive the message:
> > >
> > >> install.packages("MCMCpack")
> > >
> > > Warning in install.packages :
> > >
> > >    package 'MCMCpack' is not available (for R version 3.5.3)
> > >
> > >
> > > I have tried to install earlier versions of the "MCMCpack" library which I obtained from the following website:
> > > https://cran.r-project.org/src/contrib/Archive/MCMCpack/
> > >
> > > using the following code:
> > > packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> > > install.packages(packageurl, type="source")
> >
> > That's not the way to install a tarball.  You should use
> >
> > install.packages(packageurl, type="source", repos=NULL)
> >
> > However, you may still have problems:  when I tried that, the install failed because of C++ errors.  I don't know if configure options (e.g.
> > specifying a particular version of C++) would have fixed the problems.
> >
> > Duncan Murdoch
> >
> > >
> > > but I get an identical error message:
> > >
> > >> packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> > >
> > >> install.packages(packageurl, type="source")
> > >
> > > Warning in install.packages :
> > >
> > >    package
> > > 'https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.
> > > 2- 4.tar.gz' is not available (for R version 3.5.3)
> > >
> > >
> > >
> > > I realize that updating my R version to 3.6.1 could possibly solve the problem, but this would be impractical for me because my version needs to be consistent with others on my team. In any case, the fact that I am getting errors (detailed above) with *every* version of "MCMCpack" seems odd.
> > >
> > > Do you have any suggestions for how I can install a working version of "MCMCpack" for my version of R?
> > >
> > > Thank you,
> > > Bill
> > >
> > >
> > >
> > >
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From W||||@m@Prophet @end|ng |rom koch|nd@com  Thu Dec  5 00:25:12 2019
From: W||||@m@Prophet @end|ng |rom koch|nd@com (Prophet, William)
Date: Wed, 4 Dec 2019 23:25:12 +0000
Subject: [R] package MCMCpack
In-Reply-To: <CAA99HCyqgqApJa18ifWYdVQOWr77bXxWE4r46uF06Bp471ppdA@mail.gmail.com>
References: <MW2PR1501MB2187EAB4931D9363565957F4E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
 <5a8d0c2a-1be1-58aa-674f-50b77def1d9f@gmail.com>
 <MW2PR1501MB2187DC55E997F48DEF23BC09E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
 <CAA99HCwmwvxit1UREnvzQ0ZV5rkK0HvQfpJE_zSkaLw5oDXVNA@mail.gmail.com>
 <MW2PR1501MB21878B1BFB26D09A1A9CCF55E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>
 <CAA99HCyqgqApJa18ifWYdVQOWr77bXxWE4r46uF06Bp471ppdA@mail.gmail.com>
Message-ID: <MW2PR1501MB2187A7F0BC5DA4BA30230B43E85D0@MW2PR1501MB2187.namprd15.prod.outlook.com>

That was it!! ???
Thank you very much. 

Bill P.




-----Original Message-----
From: William Michels <wjm1 at caa.columbia.edu> 
Sent: Wednesday, December 4, 2019 4:15 PM
To: Prophet, William <William.Prophet at kochind.com>
Cc: Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
Subject: Re: [R] package MCMCpack

Sent by an external sender

----------------------------------------------------------------------
You can try installing the mcmc package first:

https://cran.r-project.org/web/packages/mcmc/index.html
https://cran.r-project.org/src/contrib/Archive/mcmc/

I've used mcmc_0.9-5 with MCMCpack_1.4-3 under R version 3.3.3.

HTH, Bill.

W. Michels, Ph.D.


On Wed, Dec 4, 2019 at 2:52 PM Prophet, William <William.Prophet at kochind.com> wrote:
>
> Thank you for your reply. I have tried various versions and I get an error in each case. In the case of MCMCpack_1.4-3 although the error may be related to something specific in my configuration. In any case, I get the following error when I try to install that version:
>
> > packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.4-3.tar.gz"
> > install.packages(packageurl, repos=NULL, type="source")
> trying URL 'https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.4-3.tar.gz'
> Content type 'application/x-gzip' length 688047 bytes (671 KB) 
> downloaded 671 KB
>
> ERROR: dependency 'mcmc' is not available for package 'MCMCpack'
> * removing 'C:/R/R-3.5.3/library/MCMCpack'
> In R CMD INSTALL
> Warning in install.packages :
>   installation of package 
> 'C:/Users/prophetw/AppData/Local/Temp/RtmpykZoRh/downloaded_packages/M
> CMCpack_1.4-3.tar.gz' had non-zero exit status
>
>
>
>
>
> -----Original Message-----
> From: William Michels <wjm1 at caa.columbia.edu>
> Sent: Wednesday, December 4, 2019 3:45 PM
> To: Prophet, William <William.Prophet at kochind.com>
> Cc: Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
> Subject: Re: [R] package MCMCpack
>
> Sent by an external sender
>
> ----------------------------------------------------------------------
> Hi William,
>
> It's not clear to me why you need this particular older version of MCMCpack. From the archive I find MCMCpack_1.2-4 dates back to 2012-06-14, and MCMCpack_1.2-4.1 dates back to 2013-04-07:
>
> MCMCpack_1.2-4.1.tar.gz 2013-04-07 00:05 481K MCMCpack_1.2-4.tar.gz 
> 2012-06-14 12:36 482K
>
> Have you tried newer versions of MCMCpack? While the newest version of 
> MCMCpack (1.4-5) may require R (? 3.6), I have sessionInfo() logs 
> suggesting that MCMCpack_1.4-3 (2018-05-15 09:54 672K) ran just fine 
> under R version 3.3.3 (2017-03-06) -- "Another Canoe". In fact, an 
> archived version of the MCMCpack_1.4-3 DESCRIPTION_file indicates that
> MCMCpack_1.4-3 only requires  R (>= 2.10.0).
>
> Hope this helps,
>
> Bill.
>
> W. Michels, Ph.D.
>
>
>
>
>
> On Wed, Dec 4, 2019 at 7:34 AM Prophet, William <William.Prophet at kochind.com> wrote:
> >
> > Yes, I should have mentioned that I tried this same line of code and I still got an error.
> >
> >
> > -----Original Message-----
> > From: Duncan Murdoch <murdoch.duncan at gmail.com>
> > Sent: Wednesday, December 4, 2019 8:32 AM
> > To: Prophet, William <William.Prophet at kochind.com>; 
> > r-help at r-project.org
> > Subject: Re: [R] package MCMCpack
> >
> > Sent by an external sender
> >
> > --------------------------------------------------------------------
> > -- On 04/12/2019 8:47 a.m., Prophet, William wrote:
> > > I am running R on my work computer with the following parameters:
> > >> sessionInfo()
> > > R version 3.5.3 (2019-03-11)
> > > Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 
> > > >=
> > > 8
> > > x64 (build 9200)
> > >
> > >
> > > I am trying to install the "MCMCpack" library. In the process however, I receive the message:
> > >
> > >> install.packages("MCMCpack")
> > >
> > > Warning in install.packages :
> > >
> > >    package 'MCMCpack' is not available (for R version 3.5.3)
> > >
> > >
> > > I have tried to install earlier versions of the "MCMCpack" library which I obtained from the following website:
> > > https://cran.r-project.org/src/contrib/Archive/MCMCpack/
> > >
> > > using the following code:
> > > packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> > > install.packages(packageurl, type="source")
> >
> > That's not the way to install a tarball.  You should use
> >
> > install.packages(packageurl, type="source", repos=NULL)
> >
> > However, you may still have problems:  when I tried that, the install failed because of C++ errors.  I don't know if configure options (e.g.
> > specifying a particular version of C++) would have fixed the problems.
> >
> > Duncan Murdoch
> >
> > >
> > > but I get an identical error message:
> > >
> > >> packageurl <- "https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.2-4.tar.gz"
> > >
> > >> install.packages(packageurl, type="source")
> > >
> > > Warning in install.packages :
> > >
> > >    package
> > > 'https://cran.r-project.org/src/contrib/Archive/MCMCpack/MCMCpack_1.
> > > 2- 4.tar.gz' is not available (for R version 3.5.3)
> > >
> > >
> > >
> > > I realize that updating my R version to 3.6.1 could possibly solve the problem, but this would be impractical for me because my version needs to be consistent with others on my team. In any case, the fact that I am getting errors (detailed above) with *every* version of "MCMCpack" seems odd.
> > >
> > > Do you have any suggestions for how I can install a working version of "MCMCpack" for my version of R?
> > >
> > > Thank you,
> > > Bill
> > >
> > >
> > >
> > >
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Thu Dec  5 08:58:12 2019
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Thu, 5 Dec 2019 08:58:12 +0100
Subject: [R] Two geom_bar with counts to put in the same plot
In-Reply-To: <CAKFaUKg3eZKAnYjjh-zoMUeenT-Y6mDU_8kLi37LkFSUYcjHnA@mail.gmail.com>
References: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>
 <44f89f64-08c8-617c-8de5-9425e9b57f51@sapo.pt>
 <7CF54C04-1DBE-40B2-9C2E-F014571810EC@gmail.com>
 <afa9e5f9-7bb0-fb33-6cd7-341775b1dfd8@sapo.pt>
 <CAKFaUKga_K3i9LRsUnS-V2H_Q6ZZgYVVCOny7gxQn-M3ZgpWgw@mail.gmail.com>
 <3de1995f-a5a2-167a-10b0-229f419514ff@sapo.pt>
 <CAKFaUKg3eZKAnYjjh-zoMUeenT-Y6mDU_8kLi37LkFSUYcjHnA@mail.gmail.com>
Message-ID: <9A232655-6419-4DFC-B4D4-3E0472A09065@gmail.com>

Hi, sorry for bothering again.
I was wondering how I can reshape the data, if in your code, 
I would like to have only two panels, where in the panel with Participation =0, I represent delta11_L of participation1==0
and delta2_L of participation2==0, and in the right panel, I want Participation=1, but representing together 
delta11_L of participation1==1, and delta2_L of participation2==1.

I get messed up with the joint melting of participation, which determines the facet, but then I cannot assign the proper fill to the density plots which depend on it, and on the other hand I would like to have in the same plot with mixed participation.

I hope it is clear. 
Nonetheless, the previous plot is useful to understand something I had not thought about.
Thanks again for your time.
F.
----------------------------------

> Il giorno 4 dic 2019, alle ore 15:27, Francesca <francesca.pancotto at gmail.com> ha scritto:
> 
> Hi!
> It is not exactly what I wanted but more than I suspected I could get. Thanks a lot, this is awesome!
> Francesca
> 
> On Wed, 4 Dec 2019 at 14:04, Rui Barradas <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> wrote:
> Hello,
> 
> Please keep R-Help in the thread.
> 
> As for the question, the following divides by facets, participation1/2 
> with values 0/1. See if that's what you want.
> 
> 
> idv <- grep("part", names(DB)[-(3:4)], ignore.case = TRUE, value = TRUE)
> dblong <- reshape2::melt(DB[-(3:4)], id.vars = idv)
> dblong <- reshape2::melt(dblong, id.vars = c("variable", "value"))
> names(dblong) <- c("deltaVar", "delta", "participationVar", "participation")
> dblong <- dblong[complete.cases(dblong),]
> 
> ggplot(dblong, aes(x = delta, fill = deltaVar)) +
>    geom_density(aes(alpha = 0.2)) +
>    scale_alpha_continuous(guide = "none") +
>    facet_wrap(participationVar ~ participation)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 08:25 de 04/12/19, Francesca escreveu:
> > Dear  Rui
> > the code works and the final picture is aesthetical as I wanted(very 
> > beautiful indeed), but I probably did not explain that the two 
> > distributions that I want to overlap, must be different by participation 
> > 1 and participation 2, which are to dummy variables that identify :
> > Participation 1(equivalent to PARTICIPATIONNOPUN): 1 participants, 0 non 
> > participants, for the variable delta11_L
> > Participation 2(equivalent to PARTICIPATIONPUN): 1 participants, 0 non
> > participants, for the variable delta2_L
> > 
> > The density plots are four in the end rather than 2: I compare delta11_L 
> > for Participants1 vsnon participants and delta2_L for Participants 2 vs
> > non Participants 2,
> > I basically want to verify whether the population of Participants vs Non 
> > participants, change going from delta11_L to delta2_L
> > 
> > 
> > Sorry for being unclear.
> > Thanks for any help.
> > Francesca
> > 
> > On Wed, 4 Dec 2019 at 09:16, Rui Barradas <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt> 
> > <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>> wrote:
> > 
> >     Hello,
> > 
> >     Is it as simple as this? The code below does not separate the
> >     participant1 and participant2, only the 'delta' variables.
> > 
> > 
> >     idv <- grep("part", names(DB)[-(3:4)], ignore.case = TRUE, value = TRUE)
> >     dblong <- reshape2::melt(DB[-(3:4)], id.vars = idv)
> >     head(dblong)
> > 
> >     ggplot(dblong, aes(x = value, fill = variable)) +
> >         geom_density(aes(alpha = 0.2)) +
> >         scale_alpha_continuous(guide = "none")
> > 
> > 
> >     I will also repost the data, since you have posted a matrix and this
> >     code needs a data.frame.
> > 
> > 
> >     DB <-
> >     structure(list(participation1 = c(1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> >     1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), participation2 = c(1,
> >     1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,
> >     0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,
> >     1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,
> >     1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,
> >     0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,
> >     1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,
> >     0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >     1, 1, 1, 1), ParticipantsNOPUN = structure(c(2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA), .Label = c("1", "2"), class =
> >     "factor"),
> >           ParticipantsPUN = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 1L,
> >           2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L,
> >           2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L,
> >           2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L,
> >           1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L,
> >           2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,
> >           1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L,
> >           2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >           2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"),
> >           delta11_L = c(0, -10, -10, 0, 0, 0, -30, 0, 10, 0, 20, 10,
> >           0, 0, 20, 0, 0, -10, 30, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0,
> >           0, 0, 0, 0, -10, 0, 0, 0, 40, -10, 0, 10, 0, 10, 0, -20,
> >           0, 0, 0, 10, -20, 10, -10, 40, -10, -10, 10, 20, 10, 0, 0,
> >           0, 0, 0, 0, -10, 0, 0, 20, 0, 0, 0, 0, 10, 0, 0, 0, 10, 0,
> >           -10, 10, 0, 0, 10, 10, 10, 0, 0, 0, 0, 0, -10, 0, 0, 0, 20,
> >           0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 20, -20,
> >           0, 0, -10, 0, 0, 0, 0, -10, 10, 0, 20, 0, 0, 0, 0, 0, -10,
> >           0, 0, 0, 0, 0, -10, 0, 0, -10, 0, -10, 30, -10, 0, 0, 10,
> >           -10, 0, -10, -10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0,
> >           10, 10, 0, 0, -20, -10, 0, 0, 0, 0, 0, 0, 10, 30, 40, 30,
> >           30, 30, 30, 20, 20, 40, 20, 20, 10, 20, 30, 20, 40, 20, 30,
> >           20, 30, 20, 20, 30, 20, 40, 10, 20, 10, 30, 30, 30, 30, 10,
> >           30, 30, 20, 10, 40, 30, 40, 40, 30, 20, 10, 10, 20, 20, 30,
> >           40, 40, 40, 40, 0, 20, 20, 40, 10, 20, 20, 10), delta2_L = c(0,
> >           -10, 0, 0, 0, 0, 30, 10, 40, 0, 0, 0, 0, 0, 10, 0, 0, 30,
> >           10, 10, 0, 0, -10, -20, -10, 0, 0, 0, -10, 10, 0, 40, 0,
> >           30, 0, 10, 0, 40, 0, 0, -10, 0, 10, 40, -10, 0, 0, 0, 10,
> >           0, 10, -10, 40, 10, 20, 10, 40, 0, 10, -10, 0, 40, 0, 0,
> >           -10, 0, 0, 20, -10, 0, 10, 0, 30, -10, 0, 0, 0, -10, 40,
> >           10, 10, 0, 10, -10, 0, 10, 0, 10, 0, -20, 20, 0, 0, -20,
> >           20, 0, -30, 20, 0, 0, 20, 10, 0, 20, 30, 0, 0, -10, 10, 10,
> >           0, -10, 40, 10, 0, 10, 0, 0, 20, 10, 20, 30, 0, 40, 30, 0,
> >           20, 40, -10, 0, 0, 0, -10, 0, 20, -10, 0, 0, 10, 0, 0, 20,
> >           -20, -20, 0, 20, 0, 0, 10, 0, -10, -10, 20, -10, 0, 0, 0,
> >           0, 0, 0, 0, -10, 30, 10, 0, 0, 10, 20, 10, -10, 10, 0, 0,
> >           -10, 30, -20, 10, 0, 0, 0, 10, 10, 10, 10, -10, 0, 20, 10,
> >           10, 10, 0, -10, -10, 0, 0, 10, 20, 0, -10, 10, 0, 10, 20,
> >           10, 0, 0, 0, 0, 10, 10, 10, 30, 10, 0, 0, -10, 40, 0, 0,
> >           10, 10, 40, 30, -10, 0, 0, 10, 20, 0, 0, 10, 40, 0, 0, -10,
> >           -20)), row.names = c(NA, -236L), class = "data.frame")
> > 
> > 
> >     Hope this helps,
> > 
> >     Rui Barradas
> > 
> > 
> > 
> >     ?s 14:10 de 03/12/19, Francesca escreveu:
> >      > Hi
> >      > here it is;. THANKS!
> >      >
> >      > dput(DATASET)
> >      > structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> >      > 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> >      > 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,
> >      > 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >      > 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,
> >      > 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >      > 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,
> >      > 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,
> >      > 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,
> >      > 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,
> >      > 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
> >      > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,
> >      > 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >      > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 2, 2, 2, 2, 2,
> >      > 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2,
> >      > 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2,
> >      > 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> >      > 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,
> >      > 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,
> >      > 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,
> >      > -10, -10, 0, 0, 0, -30, 0, 10, 0, 20, 10, 0, 0, 20, 0, 0, -10,
> >      > 30, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, -10, 0, 0, 0,
> >      > 40, -10, 0, 10, 0, 10, 0, -20, 0, 0, 0, 10, -20, 10, -10, 40,
> >      > -10, -10, 10, 20, 10, 0, 0, 0, 0, 0, 0, -10, 0, 0, 20, 0, 0,
> >      > 0, 0, 10, 0, 0, 0, 10, 0, -10, 10, 0, 0, 10, 10, 10, 0, 0, 0,
> >      > 0, 0, -10, 0, 0, 0, 20, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 10, 0,
> >      > 10, 0, 0, 0, 20, -20, 0, 0, -10, 0, 0, 0, 0, -10, 10, 0, 20,
> >      > 0, 0, 0, 0, 0, -10, 0, 0, 0, 0, 0, -10, 0, 0, -10, 0, -10, 30,
> >      > -10, 0, 0, 10, -10, 0, -10, -10, 0, 10, 0, 0, 0, 0, 0, 0, 0,
> >      > 0, 10, 0, 0, 10, 10, 0, 0, -20, -10, 0, 0, 0, 0, 0, 0, 10, 30,
> >      > 40, 30, 30, 30, 30, 20, 20, 40, 20, 20, 10, 20, 30, 20, 40, 20,
> >      > 30, 20, 30, 20, 20, 30, 20, 40, 10, 20, 10, 30, 30, 30, 30, 10,
> >      > 30, 30, 20, 10, 40, 30, 40, 40, 30, 20, 10, 10, 20, 20, 30, 40,
> >      > 40, 40, 40, 0, 20, 20, 40, 10, 20, 20, 10, 0, -10, 0, 0, 0, 0,
> >      > 30, 10, 40, 0, 0, 0, 0, 0, 10, 0, 0, 30, 10, 10, 0, 0, -10, -20,
> >      > -10, 0, 0, 0, -10, 10, 0, 40, 0, 30, 0, 10, 0, 40, 0, 0, -10,
> >      > 0, 10, 40, -10, 0, 0, 0, 10, 0, 10, -10, 40, 10, 20, 10, 40,
> >      > 0, 10, -10, 0, 40, 0, 0, -10, 0, 0, 20, -10, 0, 10, 0, 30, -10,
> >      > 0, 0, 0, -10, 40, 10, 10, 0, 10, -10, 0, 10, 0, 10, 0, -20, 20,
> >      > 0, 0, -20, 20, 0, -30, 20, 0, 0, 20, 10, 0, 20, 30, 0, 0, -10,
> >      > 10, 10, 0, -10, 40, 10, 0, 10, 0, 0, 20, 10, 20, 30, 0, 40, 30,
> >      > 0, 20, 40, -10, 0, 0, 0, -10, 0, 20, -10, 0, 0, 10, 0, 0, 20,
> >      > -20, -20, 0, 20, 0, 0, 10, 0, -10, -10, 20, -10, 0, 0, 0, 0,
> >      > 0, 0, 0, -10, 30, 10, 0, 0, 10, 20, 10, -10, 10, 0, 0, -10, 30,
> >      > -20, 10, 0, 0, 0, 10, 10, 10, 10, -10, 0, 20, 10, 10, 10, 0,
> >      > -10, -10, 0, 0, 10, 20, 0, -10, 10, 0, 10, 20, 10, 0, 0, 0, 0,
> >      > 10, 10, 10, 30, 10, 0, 0, -10, 40, 0, 0, 10, 10, 40, 30, -10,
> >      > 0, 0, 10, 20, 0, 0, 10, 40, 0, 0, -10, -20), .Dim = c(236L, 6L
> >      > ), .Dimnames = list(NULL, c("participation1", "participation2",
> >      > "ParticipantsNOPUN", "ParticipantsPUN", "delta11_L", "delta2_L"
> >      > )))
> >      >
> >      >
> >      >
> >      >
> >      >
> >      > Francesca Pancotto
> >      > ----------------------------------
> >      > Francesca Pancotto, PhD
> >      > Associate Professor of Political Economy
> >      > Universit? di Modena e Reggio Emilia
> >      > Viale A. Allegri, 9
> >      > 40121 Reggio Emilia
> >      > Office: +39 0522 523264
> >      > Web:
> >      > https://sites.google.com/view/francescapancotto/home <https://sites.google.com/view/francescapancotto/home>
> >      >
> >      > ----------------------------------
> >      >
> >      >> Il giorno 3 dic 2019, alle ore 15:03, Rui Barradas
> >      >> <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt> <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>
> >     <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt> <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>>> ha scritto:
> >      >>
> >      >> Hello,
> >      >>
> >      >> Please post the output of
> >      >>
> >      >> dput(DB)
> >      >>
> >      >> in a next e-mail to R-Help, like this it's difficult for us to
> >     use the
> >      >> data you posted.
> >      >>
> >      >> And yes, I bet you will need the data in long format. It is a
> >     frequent
> >      >> first step to the problem of plotting two or more columns in the
> >     same
> >      >> graph. To say more only with data.
> >      >>
> >      >>
> >      >> Hope this helps,
> >      >>
> >      >> Rui Barradas
> >      >>
> >      >> ?s 09:18 de 03/12/19, Francesca escreveu:
> >      >>> Dear Contributors,
> >      >>> I would like to ask help on how to create a  plot that is the
> >     overlapping
> >      >>> of two other plots.
> >      >>> It is a geom_bar structure, where I want to count the
> >     occurrences of two
> >      >>> variables, participation1 and participation2 that I recoded as
> >     factors as
> >      >>> ParticipationNOPUN and ParticipationPUN to have nice names in
> >     the legend.
> >      >>> The variables to "count" in the two plots are delta11_L and
> >     delta2_L
> >      >>> These are my data and code to create the two plots. I would
> >     like to put
> >      >>> them in the same plot as superimposed areas so that I see the
> >     change
> >      >>> in the
> >      >>> distribution of counts in the two cases.
> >      >>> This is DB:
> >      >>> participation1 participation2 ParticipantsNOPUN ParticipantsPUN
> >     delta11_L
> >      >>> delta2_L
> >      >>>   [1,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>   [2,]              1              1                 2
> >                    2
> >      >>>   -10      -10
> >      >>>   [3,]              1              1                 2
> >                    2
> >      >>>   -10        0
> >      >>>   [4,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>   [5,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>   [6,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>   [7,]              1              0                 2
> >                    1
> >      >>>   -30       30
> >      >>>   [8,]              1              1                 2
> >                    2
> >      >>>     0       10
> >      >>>   [9,]              1              0                 2
> >                    1
> >      >>>    10       40
> >      >>>  [10,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [11,]              0              0                 1
> >                    1
> >      >>>    20        0
> >      >>>  [12,]              1              1                 2
> >                    2
> >      >>>    10        0
> >      >>>  [13,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [14,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [15,]              1              1                 2
> >                    2
> >      >>>    20       10
> >      >>>  [16,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [17,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [18,]              1              1                 2
> >                    2
> >      >>>   -10       30
> >      >>>  [19,]              0              0                 1
> >                    1
> >      >>>    30       10
> >      >>>  [20,]              1              1                 2
> >                    2
> >      >>>    10       10
> >      >>>  [21,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [22,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [23,]              1              1                 2
> >                    2
> >      >>>     0      -10
> >      >>>  [24,]              1              1                 2
> >                    2
> >      >>>     0      -20
> >      >>>  [25,]              1              1                 2
> >                    2
> >      >>>    10      -10
> >      >>>  [26,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>>  [27,]              1              1                 2
> >                    2
> >      >>>     0        0
> >      >>> First PLOT(I need to subset the data to eliminate some NA. NB:
> >     the two
> >      >>> dataframes end up not having the same number of rows for this
> >     reason):
> >      >>> ggplot(data=subset(DB, !is.na <http://is.na/> <http://is.na <http://is.na/>>(participation1)),
> >     aes(x = delta11_L, fill
> >      >>> =ParticipantsNOPUN))+
> >      >>>          geom_bar(position = "dodge")+ theme_bw(base_size = 12) +
> >      >>> labs(x="Delta Contributions (PGG w/out punishment)")+
> >      >>>   theme(legend.position = "top",legend.title = element_blank())
> >      >>> +scale_fill_brewer(palette="Set1")
> >      >>> Second PLOT:
> >      >>>  ggplot(DB, aes(x = delta2_L, fill =ParticipantsPUN)  , aes(x =
> >     delta2_L,
> >      >>> fill =ParticipantsPUN))+
> >      >>>   geom_bar(position = "dodge")+ theme_bw(base_size = 12) +
> >     labs(x="Delta
> >      >>> Contributions (PGG w/punishment)")+
> >      >>>   theme(legend.position = "top",legend.title = element_blank())
> >      >>> +scale_fill_brewer(palette="Set1")
> >      >>> is it possible to create a density plot of the two counts data
> >     on the
> >      >>> same
> >      >>> plot?
> >      >>> Do I need to create a variable count or long data format?
> >      >>> Thanks
> >      >>> [[alternative HTML version deleted]]
> >      >>> ______________________________________________
> >      >>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
> >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>> mailing
> >     list -- To
> >      >>> UNSUBSCRIBE and more, see
> >      >>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> >      >>> PLEASE do read the posting guide
> >      >>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> >      >>> and provide commented, minimal, self-contained, reproducible code.
> >      >
> > 
> > 
> > 
> > -- 
> > 
> > Francesca
> > 
> > ----------------------------------
> > Francesca Pancotto, PhD
> > Universit? di Modena e Reggio Emilia
> > Viale A. Allegri, 9
> > 40121 Reggio Emilia
> > Office: +39 0522 523264
> > Web: https://sites.google.com/view/francescapancotto/home <https://sites.google.com/view/francescapancotto/home> 
> > <https://sites.google.com/site/francescapancotto/ <https://sites.google.com/site/francescapancotto/>>
> > ----------------------------------
> 
> 
> -- 
> 
> Francesca
> 
> ----------------------------------
> Francesca Pancotto, PhD
> Universit? di Modena e Reggio Emilia
> Viale A. Allegri, 9
> 40121 Reggio Emilia
> Office: +39 0522 523264
> Web: https://sites.google.com/view/francescapancotto/home <https://sites.google.com/site/francescapancotto/>
> ----------------------------------


	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Dec  5 11:11:58 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 5 Dec 2019 21:11:58 +1100
Subject: [R] Two geom_bar with counts to put in the same plot
In-Reply-To: <9A232655-6419-4DFC-B4D4-3E0472A09065@gmail.com>
References: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>
 <44f89f64-08c8-617c-8de5-9425e9b57f51@sapo.pt>
 <7CF54C04-1DBE-40B2-9C2E-F014571810EC@gmail.com>
 <afa9e5f9-7bb0-fb33-6cd7-341775b1dfd8@sapo.pt>
 <CAKFaUKga_K3i9LRsUnS-V2H_Q6ZZgYVVCOny7gxQn-M3ZgpWgw@mail.gmail.com>
 <3de1995f-a5a2-167a-10b0-229f419514ff@sapo.pt>
 <CAKFaUKg3eZKAnYjjh-zoMUeenT-Y6mDU_8kLi37LkFSUYcjHnA@mail.gmail.com>
 <9A232655-6419-4DFC-B4D4-3E0472A09065@gmail.com>
Message-ID: <CA+8X3fWcgExPcZF3skLtbfz8GdcD7ZHXr6Lz7bAXCeKdAL64+g@mail.gmail.com>

Hi Francesca,
Do you want something like this?

Jim

On Thu, Dec 5, 2019 at 6:58 PM Francesca <francesca.pancotto at gmail.com> wrote:
>
> Hi, sorry for bothering again.
> I was wondering how I can reshape the data, if in your code,
> I would like to have only two panels, where in the panel with Participation =0, I represent delta11_L of participation1==0
> and delta2_L of participation2==0, and in the right panel, I want Participation=1, but representing together
> delta11_L of participation1==1, and delta2_L of participation2==1.
>
> I get messed up with the joint melting of participation, which determines the facet, but then I cannot assign the proper fill to the density plots which depend on it, and on the other hand I would like to have in the same plot with mixed participation.
>
> I hope it is clear.
> Nonetheless, the previous plot is useful to understand something I had not thought about.
> Thanks again for your time.
> F.
> ----------------------------------
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: fp.png
Type: image/png
Size: 37171 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20191205/621e0b3a/attachment.png>

From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Thu Dec  5 11:14:33 2019
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Thu, 5 Dec 2019 11:14:33 +0100
Subject: [R] Two geom_bar with counts to put in the same plot
In-Reply-To: <CA+8X3fWcgExPcZF3skLtbfz8GdcD7ZHXr6Lz7bAXCeKdAL64+g@mail.gmail.com>
References: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>
 <44f89f64-08c8-617c-8de5-9425e9b57f51@sapo.pt>
 <7CF54C04-1DBE-40B2-9C2E-F014571810EC@gmail.com>
 <afa9e5f9-7bb0-fb33-6cd7-341775b1dfd8@sapo.pt>
 <CAKFaUKga_K3i9LRsUnS-V2H_Q6ZZgYVVCOny7gxQn-M3ZgpWgw@mail.gmail.com>
 <3de1995f-a5a2-167a-10b0-229f419514ff@sapo.pt>
 <CAKFaUKg3eZKAnYjjh-zoMUeenT-Y6mDU_8kLi37LkFSUYcjHnA@mail.gmail.com>
 <9A232655-6419-4DFC-B4D4-3E0472A09065@gmail.com>
 <CA+8X3fWcgExPcZF3skLtbfz8GdcD7ZHXr6Lz7bAXCeKdAL64+g@mail.gmail.com>
Message-ID: <6B568B3C-D4D5-4941-9E10-A5F16AB317E6@gmail.com>

Exactly. I was trying to remelt data in the right way, but I could not get there yet. Can you suggest me this code?
Thanks a lot
F.

----------------------------------

> Il giorno 5 dic 2019, alle ore 11:11, Jim Lemon <drjimlemon at gmail.com> ha scritto:
> 
> Hi Francesca,
> Do you want something like this?
> 
> Jim
> 
> On Thu, Dec 5, 2019 at 6:58 PM Francesca <francesca.pancotto at gmail.com> wrote:
>> 
>> Hi, sorry for bothering again.
>> I was wondering how I can reshape the data, if in your code,
>> I would like to have only two panels, where in the panel with Participation =0, I represent delta11_L of participation1==0
>> and delta2_L of participation2==0, and in the right panel, I want Participation=1, but representing together
>> delta11_L of participation1==1, and delta2_L of participation2==1.
>> 
>> I get messed up with the joint melting of participation, which determines the facet, but then I cannot assign the proper fill to the density plots which depend on it, and on the other hand I would like to have in the same plot with mixed participation.
>> 
>> I hope it is clear.
>> Nonetheless, the previous plot is useful to understand something I had not thought about.
>> Thanks again for your time.
>> F.
>> ----------------------------------
>> 
> <fp.png>


	[[alternative HTML version deleted]]


From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Thu Dec  5 11:19:46 2019
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Thu, 5 Dec 2019 11:19:46 +0100
Subject: [R] Two geom_bar with counts to put in the same plot
In-Reply-To: <CA+8X3fUdzo9ObLikiLVnhf6Svy7BYWq6esF4Nvic2qaeGypxTA@mail.gmail.com>
References: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>
 <44f89f64-08c8-617c-8de5-9425e9b57f51@sapo.pt>
 <7CF54C04-1DBE-40B2-9C2E-F014571810EC@gmail.com>
 <afa9e5f9-7bb0-fb33-6cd7-341775b1dfd8@sapo.pt>
 <CAKFaUKga_K3i9LRsUnS-V2H_Q6ZZgYVVCOny7gxQn-M3ZgpWgw@mail.gmail.com>
 <3de1995f-a5a2-167a-10b0-229f419514ff@sapo.pt>
 <CAKFaUKg3eZKAnYjjh-zoMUeenT-Y6mDU_8kLi37LkFSUYcjHnA@mail.gmail.com>
 <9A232655-6419-4DFC-B4D4-3E0472A09065@gmail.com>
 <CA+8X3fWcgExPcZF3skLtbfz8GdcD7ZHXr6Lz7bAXCeKdAL64+g@mail.gmail.com>
 <6B568B3C-D4D5-4941-9E10-A5F16AB317E6@gmail.com>
 <CA+8X3fUdzo9ObLikiLVnhf6Svy7BYWq6esF4Nvic2qaeGypxTA@mail.gmail.com>
Message-ID: <E1DB6DC4-5FF9-4750-9D1C-1CB7049028CB@gmail.com>

This is a consolation, because I cannot get it in ggplot either!
Thanks for the code!

F.--------------------------------

> Il giorno 5 dic 2019, alle ore 11:17, Jim Lemon <drjimlemon at gmail.com> ha scritto:
> 
> Sorry it's not ggplot, I couldn't work that one out.
> 
> # using the data frame structure that Rui kindly added
> # and perhaps Rui can work out how to do this in ggplot
> DBcomplete<-DB[complete.cases(DB),]
> library(plotrix)
> png("fp.png")
> par(mfrow=c(1,2))
> density11_0<-density(DBcomplete$delta11_L[DBcomplete$participation1==0])
> density2_0<-density(DBcomplete$delta2_L[DBcomplete$participation1==0])
> plot(0,xlim=c(-30,50),ylim=c(0,max(density11_0$y)),type="n",
> xlab="delta",ylab="density",main="participation == 0")
> plot_bg("lightgray")
> grid(col="white")
> polygon(density11_0,col="#ff773344")
> polygon(density2_0,col="#3377ff44")
> density11_1<-density(DBcomplete$delta11_L[DBcomplete$participation1==1])
> density2_1<-density(DBcomplete$delta2_L[DBcomplete$participation1==1])
> plot(0,xlim=c(-30,50),ylim=c(0,max(density11_1$y)),type="n",
> xlab="delta",ylab="density",main="participation == 1")
> plot_bg("lightgray")
> grid(col="white")
> polygon(density11_1,col="#ff773344")
> polygon(density2_1,col="#3377ff44")
> par(cex=0.9)
> legend(5,0.11,c("delta11_L","delta2_L"),fill=c("#ff773344","#3377ff44"))
> dev.off()
> 
> Jim
> 
> On Thu, Dec 5, 2019 at 9:14 PM Francesca <francesca.pancotto at gmail.com> wrote:
>> 
>> Exactly. I was trying to remelt data in the right way, but I could not get there yet. Can you suggest me this code?
>> Thanks a lot
>> F.
>> 
>> ----------------------------------
>> 
>> Il giorno 5 dic 2019, alle ore 11:11, Jim Lemon <drjimlemon at gmail.com> ha scritto:
>> 
>> Hi Francesca,
>> Do you want something like this?
>> 
>> Jim
>> 
>> On Thu, Dec 5, 2019 at 6:58 PM Francesca <francesca.pancotto at gmail.com> wrote:
>> 
>> 
>> Hi, sorry for bothering again.
>> I was wondering how I can reshape the data, if in your code,
>> I would like to have only two panels, where in the panel with Participation =0, I represent delta11_L of participation1==0
>> and delta2_L of participation2==0, and in the right panel, I want Participation=1, but representing together
>> delta11_L of participation1==1, and delta2_L of participation2==1.
>> 
>> I get messed up with the joint melting of participation, which determines the facet, but then I cannot assign the proper fill to the density plots which depend on it, and on the other hand I would like to have in the same plot with mixed participation.
>> 
>> I hope it is clear.
>> Nonetheless, the previous plot is useful to understand something I had not thought about.
>> Thanks again for your time.
>> F.
>> ----------------------------------
>> 
>> <fp.png>
>> 
>> 


	[[alternative HTML version deleted]]


From bur@k@ym@kc| @end|ng |rom gm@||@com  Thu Dec  5 11:21:45 2019
From: bur@k@ym@kc| @end|ng |rom gm@||@com (Burak Kaymakci)
Date: Thu, 5 Dec 2019 13:21:45 +0300
Subject: [R] How to use preProcess in Caret?
In-Reply-To: <CAA99HCy3nuGw1aBqQpsTyXEJch0rQJUzQRMJR4Jqf35coY9oGA@mail.gmail.com>
References: <CAMEVu8gsekqn=m79JKCnrcCfCxM15U2wJfu640GoO9BSrsj31w@mail.gmail.com>
 <CAA99HCy3nuGw1aBqQpsTyXEJch0rQJUzQRMJR4Jqf35coY9oGA@mail.gmail.com>
Message-ID: <CAMEVu8hUrh9mfBrW+wtJfWEkTHODvunPAJKFh-t2CM0YWLN=LA@mail.gmail.com>

Hello there,

Yes, I'd tried scale as well. I mean, I could do my preprocessing
separately and it was working fine.
I was just wondering how preProcess argument in train function works. As
far as I know, when preProcess argument is set, it normalizes inputs but
not outputs.

Then I've figured we could also use recipes and that normalizes both
predictors and outcomes as you wish.

Here
<https://stackoverflow.com/questions/59126400/how-does-setting-preprocess-argument-in-train-function-in-caret-work?noredirect=1#comment104528951_59126400>
you can take a look at the question I've asked on SO.
You can see the use of recipe in comments below by "missuse".

I will read the link you've shared as well.

Thank you,
Burak


William Michels <wjm1 at caa.columbia.edu>, 4 Ara 2019 ?ar, 21:04 tarihinde
?unu yazd?:

> Hello,
>
> Have you tried alternative methods of pre-processing your data, such
> as simply calling scale()? What is the effect on convergence, for both
> the caret package and and the neuralnet package? There's an example
> using scale() with the neuralnet package at the link below:
>
> https://datascienceplus.com/fitting-neural-network-in-r/
>
> HTH, Bill.
>
> W. Michels, Ph.D.
>
>
>
> On Sun, Dec 1, 2019 at 10:04 AM Burak Kaymakci <burakaymakci at gmail.com>
> wrote:
> >
> > Hello there,
> >
> > I am using caret and neuralnet to train a neural network to predict times
> > table. I am using 'backprop' algorithm for neuralnet to experiment and
> > learn.
> >
> > Before using caret, I've trained a neuralnet without using caret, I've
> > normalized my input & outputs using preProcess with 'range' method. Then
> I
> > predicted my test set, did the multiplication and addition on predictions
> > to get the real values. It gave me good results.
> >
> > What I want to ask is, when I try to train my network using caret, I get
> an
> > error saying algorithm did not converge. I am thinking that I might be
> > doing something wrong with my pre-processing,
> >
> > How would I go about using preProcess in train?
> > Do I pass my not-normalized data set to the train function and train
> > function handles normalization internally?
> >
> > You can find my R gist here
> > <https://gist.github.com/andreyuhai/f299282f5a827e2a27c586afc9eb4eb5>
> >
> > Thank you,
> > Burak
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nto|edo@b|o| @end|ng |rom gm@||@com  Wed Dec  4 20:07:36 2019
From: nto|edo@b|o| @end|ng |rom gm@||@com (Nestor Toledo)
Date: Wed, 4 Dec 2019 16:07:36 -0300
Subject: [R] how to deal with deprecated functions
Message-ID: <bd9c4a3c-e469-69c9-b3d4-563fd3ae2c01@gmail.com>

Hello everyone, even I'm not fluent in coding, R has become a 
fundamental part of my daily work as a researcher and I'm very much 
grateful for such a wonderful, open tool. However, I have faced in many 
opportunities the problems associated with updates/upgrades of packages. 
Frequently packages developers modify command syntax or directly 
deprecate entire functions. This becomes a nuisance, since I must to 
recode my scripts partially or totally, or even search for alternative 
functions in other packages. Is there any solution to this, other than 
skip updates or keeping old versions installed in a different folder? 
Could be acceptable ask developers to do not deprecate functions but 
keep them as "legacy" ones or similar?

Thanks in advance and I apologize for my deficient English grammar

-- 
Dr. N?stor Toledo
Divisi?n Paleontolog?a Vertebrados
ntoledo at fcnym.unlp.edu.ar
Unidades de Investigaci?n Anexo Museo FCNyM-UNLP
Av. 60 y 122
B1900FWA (B1906CXT)  La Plata, Argentina
Tel. 54 221 422 8451 int 115 of 115
https://www.researchgate.net/profile/Nestor_Toledo
http://sedici.unlp.edu.ar/handle/10915/55101


From u|r|ch@ke||er @end|ng |rom un|@|u  Thu Dec  5 10:37:46 2019
From: u|r|ch@ke||er @end|ng |rom un|@|u (Ulrich KELLER)
Date: Thu, 5 Dec 2019 09:37:46 +0000
Subject: [R] Method dispatch sometimes failsfor lavaan objects
Message-ID: <C72888C9-0D6B-4093-80A4-5F7AF82EDFB4@uni.lu>

Hello,

in some R sessions, method dispatch for objects of the (S4) class ?lavaan" fail. An example from such a ?bad? session:

> library(lavaan)
> HS.model <- ' visual  =~ x1 + x2 + x3
+               textual =~ x4 + x5 + x6
+               speed   =~ x7 + x8 + x9 '
> fit <- cfa(HS.model, data = HolzingerSwineford1939)
> vcov(fit)
Error in UseMethod("vcov") : 
  no applicable method for 'vcov' applied to an object of class ?lavaan"

But everything _seems_ to be fine:

> selectMethod("vcov", list("lavaan"))
[?]
<environment: namespace:lavaan>

Signatures:
        object  
target  "lavaan"
defined ?lavaan"

> pryr::method_from_call(vcov(fit))
[?]
<environment: namespace:lavaan>

Signatures:
        object  
target  "lavaan"
defined ?lavaan?

For other calls, R uses the default method instead of the one for lavaan, leading to other errors:

> coef(fit)
Error: $ operator not defined for this S4 class
> traceback()
2: coef.default(fit)
1: coef(fit)

Here too, selectMethod() seems to indicate that everything is fine.

As I mentioned, this happens in ?some? R sessions, but I haven?t been able no narrow down what distinguishes ?bad? from ?good? sessions (where the problem does not occur). I?ve tried starting with a new session with just package lavaan loaded (where it works) and then one by one loading the same packages I have loaded in a bad session, but I can?t reproduce the error in the new session.

Some time ago, somebody posted this problem to the lavaan Google group, but nothing came of it (https://groups.google.com/forum/#!topic/lavaan/LoUemqNhXBM). My hope is that somebody here will have an idea for investigating this problem further.

Thanks a lot in advance,

Uli


Session info from a bad session with almost all objects removed from the workspace and restarted with only lavaan package loaded:

> sessionInfo()
R version 3.6.1 (2019-07-05)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Mojave 10.14.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lavaan_0.6-5

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.3       rstudioapi_0.10  knitr_1.25       magrittr_1.5     tidyselect_0.2.5
 [6] mnormt_1.5-5     pbivnorm_0.6.0   R6_2.4.0         rlang_0.4.1      stringr_1.4.0   
[11] dplyr_0.8.3      globals_0.12.4   tools_3.6.1      parallel_3.6.1   xfun_0.10       
[16] htmltools_0.4.0  assertthat_0.2.1 digest_0.6.22    tibble_2.1.3     crayon_1.3.4    
[21] pryr_0.1.4       purrr_0.3.3      codetools_0.2-16 glue_1.3.1       stringi_1.4.3   
[26] compiler_3.6.1   pillar_1.4.2     stats4_3.6.1     future_1.15.0    listenv_0.7.0   
[31] pkgconfig_2.0.3 


Session info from a good session with lots of packages loaded while trying to reproduce the problem:

> sessionInfo()
R version 3.6.1 (2019-07-05)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Mojave 10.14.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] future_1.15.0         rlang_0.4.1           magrittr_1.5          TAM_3.3-10           
 [5] CDM_7.4-19            mvtnorm_1.0-11        semPlot_1.1.2         MplusAutomation_0.7-3
 [9] forcats_0.4.0         stringr_1.4.0         dplyr_0.8.3           purrr_0.3.3          
[13] readr_1.3.1           tidyr_1.0.0           tibble_2.1.3          ggplot2_3.2.1        
[17] tidyverse_1.2.1       psych_1.8.12          semTools_0.5-2        lavaan_0.6-5         

loaded via a namespace (and not attached):
  [1] minqa_1.2.4         colorspace_1.4-1    rjson_0.2.20        htmlTable_1.13.2   
  [5] corpcor_1.6.9       base64enc_0.1-3     rstudioapi_0.10     listenv_0.7.0      
  [9] lubridate_1.7.4     xml2_1.2.2          codetools_0.2-16    splines_3.6.1      
 [13] mnormt_1.5-5        knitr_1.25          glasso_1.11         texreg_1.36.23     
 [17] zeallot_0.1.0       Formula_1.2-3       jsonlite_1.6        nloptr_1.2.1       
 [21] broom_0.5.2         cluster_2.1.0       png_0.1-7           regsem_1.3.9       
 [25] compiler_3.6.1      httr_1.4.1          backports_1.1.5     assertthat_0.2.1   
 [29] Matrix_1.2-17       lazyeval_0.2.2      cli_1.1.0           acepack_1.4.1      
 [33] htmltools_0.4.0     tools_3.6.1         OpenMx_2.14.11      igraph_1.2.4.1     
 [37] coda_0.19-3         gtable_0.3.0        glue_1.3.1          reshape2_1.4.3     
 [41] Rcpp_1.0.3          carData_3.0-2       cellranger_1.1.0    vctrs_0.2.0        
 [45] nlme_3.1-142        lisrelToR_0.1.4     xfun_0.10           globals_0.12.4     
 [49] proto_1.0.0         openxlsx_4.1.3      lme4_1.1-21         rvest_0.3.5        
 [53] ggm_2.3             lifecycle_0.1.0     gtools_3.8.1        XML_3.98-1.20      
 [57] MASS_7.3-51.4       scales_1.0.0        BDgraph_2.61        hms_0.5.2          
 [61] kutils_1.69         parallel_3.6.1      huge_1.3.4          RColorBrewer_1.1-2 
 [65] pbapply_1.4-2       gridExtra_2.3       pander_0.6.3        rpart_4.1-15       
 [69] latticeExtra_0.6-28 stringi_1.4.3       sem_3.1-9           checkmate_1.9.4    
 [73] polycor_0.7-10      boot_1.3-23         zip_2.0.4           truncnorm_1.0-8    
 [77] d3Network_0.5.2.1   pkgconfig_2.0.3     Rsolnp_1.16         arm_1.10-1         
 [81] lattice_0.20-38     htmlwidgets_1.5.1   tidyselect_0.2.5    plyr_1.8.4         
 [85] R6_2.4.0            generics_0.0.2      Hmisc_4.3-0         whisker_0.4        
 [89] gsubfn_0.7          pillar_1.4.2        haven_2.2.0         foreign_0.8-72     
 [93] withr_2.1.2         rockchalk_1.8.144   survival_3.1-7      abind_1.4-5        
 [97] nnet_7.3-12         modelr_0.1.5        crayon_1.3.4        fdrtool_1.2.15     
[101] jpeg_0.1-8.1        grid_3.6.1          readxl_1.3.1        qgraph_1.6.3       
[105] data.table_1.12.6   pbivnorm_0.6.0      matrixcalc_1.0-3    digest_0.6.22      
[109] xtable_1.8-4        mi_1.0              stats4_3.6.1        munsell_0.5.0      

From dubrovv@@kkyy @end|ng |rom gm@||@com  Thu Dec  5 12:39:07 2019
From: dubrovv@@kkyy @end|ng |rom gm@||@com (=?UTF-8?B?0JDQu9C10LrRgdCw0L3QtNGAINCU0YPQsdGA0L7QstGB0LrQuNC5?=)
Date: Thu, 5 Dec 2019 14:39:07 +0300
Subject: [R] Help to write the R-code, please
Message-ID: <CAAdh95OBzPQRznL+v80GEn3M8qAGsYT9PG3_-H42Y-Yhwi8m0A@mail.gmail.com>

Task:
A family of sets of letters is given. Find K for which one can construct a
set consisting of K letters, each of them belonging to exactly K sets of a
given family.

Possible solution:
For each letter, we will have a separate 'scoop', in which we will' put '
the letter. This can be done using array A of 255 elements. In this case,
the number of the 'scoop' corresponding to a letter is determined by the
letter code (it is known that any letter is encoded by some binary number
containing 8 digits - called bits; in Pascal, its code can be determined by
using the ord function). When viewing the sets, let's count how many times
each letter met. This is done as follows. When you meet a letter, increase
the contents of the corresponding array element by 1. The initial contents
of the array elements are 0. After viewing the letters of all sets,
elements a determine the number of corresponding letters, and therefore the
number of sets that have the corresponding letter (because in one set, all
elements are different!). Using similarly array B from 255 elements (more
need not, so as the desired the number of to on condition not exceeds
number of letters) count the number of units, twos and so on in array A.
Maximum significance index K, for which K=B[K] and will solution meet the
tasks.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Dec  5 15:49:18 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 5 Dec 2019 14:49:18 +0000
Subject: [R] how to deal with deprecated functions
In-Reply-To: <bd9c4a3c-e469-69c9-b3d4-563fd3ae2c01@gmail.com>
References: <bd9c4a3c-e469-69c9-b3d4-563fd3ae2c01@gmail.com>
Message-ID: <d6f078dc-e9ac-73d4-2d0f-03c925150658@sapo.pt>

Hello,

If you are talking about CRAN packages, like it seems you are, then 
there is no general purpose solution. What is deprecated depends on each 
package's team of developers/maintainer.

Since R is open source and so must be all CRAN packages, a possible 
solution is to have your own package of deprecated functions. This 
package could be used while you don't recode your scripts, or even used 
for ever, as long as those functions, maybe with a different name,  do 
not conflict with the new behavior of the rest of the packages they came 
from. Is not that difficult to write a package, and in this case you 
would even have more examples, if needed.


Hope this helps,

Rui Barradas

?s 19:07 de 04/12/19, Nestor Toledo escreveu:
> Hello everyone, even I'm not fluent in coding, R has become a 
> fundamental part of my daily work as a researcher and I'm very much 
> grateful for such a wonderful, open tool. However, I have faced in many 
> opportunities the problems associated with updates/upgrades of packages. 
> Frequently packages developers modify command syntax or directly 
> deprecate entire functions. This becomes a nuisance, since I must to 
> recode my scripts partially or totally, or even search for alternative 
> functions in other packages. Is there any solution to this, other than 
> skip updates or keeping old versions installed in a different folder? 
> Could be acceptable ask developers to do not deprecate functions but 
> keep them as "legacy" ones or similar?
> 
> Thanks in advance and I apologize for my deficient English grammar
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Dec  5 16:08:11 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 05 Dec 2019 07:08:11 -0800
Subject: [R] Help to write the R-code, please
In-Reply-To: <CAAdh95OBzPQRznL+v80GEn3M8qAGsYT9PG3_-H42Y-Yhwi8m0A@mail.gmail.com>
References: <CAAdh95OBzPQRznL+v80GEn3M8qAGsYT9PG3_-H42Y-Yhwi8m0A@mail.gmail.com>
Message-ID: <62DE81B2-1F3C-4A93-9EEF-DFE464ED9B6C@dcn.davis.ca.us>



On December 5, 2019 3:39:07 AM PST, "????????? ??????????" <dubrovvsskkyy at gmail.com> wrote:
>Task:
>A family of sets of letters is given. Find K for which one can
>construct a
>set consisting of K letters, each of them belonging to exactly K sets
>of a
>given family.

... 
>
>	[[alternative HTML version deleted]]
>

This is a plain-text mailing list, meaning that some unspecified text version of your HTML-formatted messages will reach us which reduces our ability to understand you.

>______________________________________________

..

>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

Do this. It warns you that this list is not for homework help, nor is it a do-my-work-for-me forum.
-- 
Sent from my phone. Please excuse my brevity.


From pro|jcn@@h @end|ng |rom gm@||@com  Thu Dec  5 16:18:45 2019
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Thu, 5 Dec 2019 10:18:45 -0500
Subject: [R] how to deal with deprecated functions
In-Reply-To: <d6f078dc-e9ac-73d4-2d0f-03c925150658@sapo.pt>
References: <bd9c4a3c-e469-69c9-b3d4-563fd3ae2c01@gmail.com>
 <d6f078dc-e9ac-73d4-2d0f-03c925150658@sapo.pt>
Message-ID: <2f7dc94a-179d-e7eb-5f44-21412426be05@gmail.com>

I would second Rui's suggestion. However, as a package developer and maintainer, I think
it is important to note that users need to be encouraged to use good tools. I work with optimization
codes. My software was incorporated into the optim() function a LONG time ago. I have updated
and expanded the methods in packages, particularly optimx. But CRAN regularly imposes new
standards. Worse, there are recent changes in gfortran which may or may not be justified.
In the last couple of months, I've had several messages from CRAN to "fix" my packages,
though likely there is nothing "wrong" with the code, but it doesn't have quite the right
setup for the altered R. Within reason, I'm willing to do a bit of cleanup from time to
time. And to add new features and capabilities as I am able.

For users, there is another lurking danger. I've been merging some of my packages to reduce the
number I have to maintain. I retired from teaching in 2008, so it is not unimaginable that
there might not be a maintainer rather suddenly. I've had users send quite rude messages
"Why don't you fix this program". Well, some maintainers will gladly do so if you arrange their
resurrection.

More realistically, it has always been time for younger members of the R community to team up
with older ones so we have a succession plan. Current CRAN seems fixated on single person
maintainers, but I think CRAN and other open-source projects need to consider
group maintenance -- several people maintaining several packages. That isn't picking a
fight with the CRAN folk -- things evolved and it is difficult to change a working system.

JN


On 2019-12-05 9:49 a.m., Rui Barradas wrote:
> Hello,
> 
> If you are talking about CRAN packages, like it seems you are, then there is no general purpose solution. What is
> deprecated depends on each package's team of developers/maintainer.
> 
> Since R is open source and so must be all CRAN packages, a possible solution is to have your own package of deprecated
> functions. This package could be used while you don't recode your scripts, or even used for ever, as long as those
> functions, maybe with a different name,? do not conflict with the new behavior of the rest of the packages they came
> from. Is not that difficult to write a package, and in this case you would even have more examples, if needed.
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 19:07 de 04/12/19, Nestor Toledo escreveu:
>> Hello everyone, even I'm not fluent in coding, R has become a fundamental part of my daily work as a researcher and
>> I'm very much grateful for such a wonderful, open tool. However, I have faced in many opportunities the problems
>> associated with updates/upgrades of packages. Frequently packages developers modify command syntax or directly
>> deprecate entire functions. This becomes a nuisance, since I must to recode my scripts partially or totally, or even
>> search for alternative functions in other packages. Is there any solution to this, other than skip updates or keeping
>> old versions installed in a different folder? Could be acceptable ask developers to do not deprecate functions but
>> keep them as "legacy" ones or similar?
>>
>> Thanks in advance and I apologize for my deficient English grammar
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Dec  5 16:36:50 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 5 Dec 2019 15:36:50 +0000
Subject: [R] Two geom_bar with counts to put in the same plot
In-Reply-To: <E1DB6DC4-5FF9-4750-9D1C-1CB7049028CB@gmail.com>
References: <CAKFaUKjj=cJNNVgiSjv3suin_+5iQVohGbSGamCY5P6JfRZ+DA@mail.gmail.com>
 <44f89f64-08c8-617c-8de5-9425e9b57f51@sapo.pt>
 <7CF54C04-1DBE-40B2-9C2E-F014571810EC@gmail.com>
 <afa9e5f9-7bb0-fb33-6cd7-341775b1dfd8@sapo.pt>
 <CAKFaUKga_K3i9LRsUnS-V2H_Q6ZZgYVVCOny7gxQn-M3ZgpWgw@mail.gmail.com>
 <3de1995f-a5a2-167a-10b0-229f419514ff@sapo.pt>
 <CAKFaUKg3eZKAnYjjh-zoMUeenT-Y6mDU_8kLi37LkFSUYcjHnA@mail.gmail.com>
 <9A232655-6419-4DFC-B4D4-3E0472A09065@gmail.com>
 <CA+8X3fWcgExPcZF3skLtbfz8GdcD7ZHXr6Lz7bAXCeKdAL64+g@mail.gmail.com>
 <6B568B3C-D4D5-4941-9E10-A5F16AB317E6@gmail.com>
 <CA+8X3fUdzo9ObLikiLVnhf6Svy7BYWq6esF4Nvic2qaeGypxTA@mail.gmail.com>
 <E1DB6DC4-5FF9-4750-9D1C-1CB7049028CB@gmail.com>
Message-ID: <cfd43c64-54b9-2bb5-3a68-07a883ae95f7@sapo.pt>

Hello,

A ggplot graph follows almost exactly my previous code. The *only* 
difference is in facet_wrap(). See below.


library(ggplot2)

idv <- grep("part", names(DB)[-(3:4)], ignore.case = TRUE, value = TRUE)
dblong <- reshape2::melt(DB[-(3:4)], id.vars = idv)
dblong <- reshape2::melt(dblong, id.vars = c("variable", "value"))
names(dblong) <- c("deltaVar", "delta", "participationVar", "participation")
dblong <- dblong[complete.cases(dblong),]

ggplot(dblong, aes(x = delta, fill = deltaVar)) +
   geom_density(aes(alpha = 0.2)) +
   scale_alpha_continuous(guide = "none") +
   facet_wrap( ~ participation)


Hope this helps,

Rui Barradas

?s 10:19 de 05/12/19, Francesca escreveu:
> This is a consolation, because I cannot get it in ggplot either!
> Thanks for the code!
> 
> F.--------------------------------
> 
>> Il giorno 5 dic 2019, alle ore 11:17, Jim Lemon <drjimlemon at gmail.com> ha scritto:
>>
>> Sorry it's not ggplot, I couldn't work that one out.
>>
>> # using the data frame structure that Rui kindly added
>> # and perhaps Rui can work out how to do this in ggplot
>> DBcomplete<-DB[complete.cases(DB),]
>> library(plotrix)
>> png("fp.png")
>> par(mfrow=c(1,2))
>> density11_0<-density(DBcomplete$delta11_L[DBcomplete$participation1==0])
>> density2_0<-density(DBcomplete$delta2_L[DBcomplete$participation1==0])
>> plot(0,xlim=c(-30,50),ylim=c(0,max(density11_0$y)),type="n",
>> xlab="delta",ylab="density",main="participation == 0")
>> plot_bg("lightgray")
>> grid(col="white")
>> polygon(density11_0,col="#ff773344")
>> polygon(density2_0,col="#3377ff44")
>> density11_1<-density(DBcomplete$delta11_L[DBcomplete$participation1==1])
>> density2_1<-density(DBcomplete$delta2_L[DBcomplete$participation1==1])
>> plot(0,xlim=c(-30,50),ylim=c(0,max(density11_1$y)),type="n",
>> xlab="delta",ylab="density",main="participation == 1")
>> plot_bg("lightgray")
>> grid(col="white")
>> polygon(density11_1,col="#ff773344")
>> polygon(density2_1,col="#3377ff44")
>> par(cex=0.9)
>> legend(5,0.11,c("delta11_L","delta2_L"),fill=c("#ff773344","#3377ff44"))
>> dev.off()
>>
>> Jim
>>
>> On Thu, Dec 5, 2019 at 9:14 PM Francesca <francesca.pancotto at gmail.com> wrote:
>>>
>>> Exactly. I was trying to remelt data in the right way, but I could not get there yet. Can you suggest me this code?
>>> Thanks a lot
>>> F.
>>>
>>> ----------------------------------
>>>
>>> Il giorno 5 dic 2019, alle ore 11:11, Jim Lemon <drjimlemon at gmail.com> ha scritto:
>>>
>>> Hi Francesca,
>>> Do you want something like this?
>>>
>>> Jim
>>>
>>> On Thu, Dec 5, 2019 at 6:58 PM Francesca <francesca.pancotto at gmail.com> wrote:
>>>
>>>
>>> Hi, sorry for bothering again.
>>> I was wondering how I can reshape the data, if in your code,
>>> I would like to have only two panels, where in the panel with Participation =0, I represent delta11_L of participation1==0
>>> and delta2_L of participation2==0, and in the right panel, I want Participation=1, but representing together
>>> delta11_L of participation1==1, and delta2_L of participation2==1.
>>>
>>> I get messed up with the joint melting of participation, which determines the facet, but then I cannot assign the proper fill to the density plots which depend on it, and on the other hand I would like to have in the same plot with mixed participation.
>>>
>>> I hope it is clear.
>>> Nonetheless, the previous plot is useful to understand something I had not thought about.
>>> Thanks again for your time.
>>> F.
>>> ----------------------------------
>>>
>>> <fp.png>
>>>
>>>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From t@ub|@ @end|ng |rom |mgprec|@|on@com  Thu Dec  5 16:39:56 2019
From: t@ub|@ @end|ng |rom |mgprec|@|on@com (Thomas Subia)
Date: Thu, 5 Dec 2019 15:39:56 +0000
Subject: [R] readxl question
Message-ID: <CH2PR17MB3749076EBDBFE96E7D3ABB41B85C0@CH2PR17MB3749.namprd17.prod.outlook.com>

Colleagues,

I'm trying to extract a cell from all Excel files in a directory.

library(readxl)
files <- list.files(pattern="*.xls", full.names = FALSE)

date <- lapply(files, read_excel, sheet="Sheet1", range=("B5"))

date_df <- as.data.frame(date)
trans_date <-t(date_df)
mydates <- list(trans_date)
write.table(mydates,"mydates.txt",sep="\t")

Looking at mydates.txt shows:

""
"Saturday..June.09..2018"	
"Saturday..June.09..2018.1"	
"Saturday..June.09..2018.2"

But the original Excel contents are:

Saturday, June 09, 2018
Saturday, June 09, 2018
Saturday, June 09, 2018

I get a similar problem with my serial numbers

serial <-lapply(files, read_excel, sheet="Sheet1", range=("B9"))

serial_df <- as.data.frame(serial)
trans_serial <-t(serial_df)
myserials <- list(trans_serial)
write.table(myserials,"myserials.txt",sep="\t")

R Output

""
"X96739.0027.1"	
"X96739.0041.1"	
"X96739.0044.1"	

Original Excel Content
96739-0027/1
96739-0041/1
96739-0044/1

How can I amend my script so that the output matches the original Excel content?

Thomas Subia 
Statistician / Senior Quality Engineer
IMG Precision


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Dec  5 18:16:21 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 5 Dec 2019 12:16:21 -0500
Subject: [R] how to deal with deprecated functions
In-Reply-To: <bd9c4a3c-e469-69c9-b3d4-563fd3ae2c01@gmail.com>
References: <bd9c4a3c-e469-69c9-b3d4-563fd3ae2c01@gmail.com>
Message-ID: <c790e523-8808-5c2c-d06f-10d2ef4a8e3d@gmail.com>

On 04/12/2019 2:07 p.m., Nestor Toledo wrote:
> Hello everyone, even I'm not fluent in coding, R has become a
> fundamental part of my daily work as a researcher and I'm very much
> grateful for such a wonderful, open tool. However, I have faced in many
> opportunities the problems associated with updates/upgrades of packages.
> Frequently packages developers modify command syntax or directly
> deprecate entire functions. This becomes a nuisance, since I must to
> recode my scripts partially or totally, or even search for alternative
> functions in other packages. Is there any solution to this, other than
> skip updates or keeping old versions installed in a different folder?
> Could be acceptable ask developers to do not deprecate functions but
> keep them as "legacy" ones or similar?
> 
> Thanks in advance and I apologize for my deficient English grammar
> 

As Rui said, there's no easy way to prevent this.  In my experience, 
most maintainers are quite willing to avoid changes that cause problems, 
or help users to work around them:  but they have to know that problems 
were caused.

The easiest way to do this is to share your own code by putting it in a 
package on CRAN with sufficient tests to detect problems.  When a 
package maintainer submits a package update, CRAN checks that all 
"revdeps" (i.e. reverse dependencies, packages that depend on the 
updated one) still pass their tests.  The submitter is asked to contact 
the maintainers of the other packages to resolve any new problems.

Duncan Murdoch


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Dec  5 18:23:23 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 5 Dec 2019 20:23:23 +0300
Subject: [R] Help to write the R-code, please
In-Reply-To: <CAAdh95OBzPQRznL+v80GEn3M8qAGsYT9PG3_-H42Y-Yhwi8m0A@mail.gmail.com>
References: <CAAdh95OBzPQRznL+v80GEn3M8qAGsYT9PG3_-H42Y-Yhwi8m0A@mail.gmail.com>
Message-ID: <20191205202323.2484817a@parabola>

It might be easier to implement in R if you employ the base functions
that take arrays and operate on them as if they represented sets. See
the help() for "union", "intersect", "setdiff", "setequal" and the
operator "%in%".

-- 
Best regards,
Ivan


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Dec  5 18:43:07 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 5 Dec 2019 20:43:07 +0300
Subject: [R] readxl question
In-Reply-To: <CH2PR17MB3749076EBDBFE96E7D3ABB41B85C0@CH2PR17MB3749.namprd17.prod.outlook.com>
References: <CH2PR17MB3749076EBDBFE96E7D3ABB41B85C0@CH2PR17MB3749.namprd17.prod.outlook.com>
Message-ID: <20191205204307.5d599ab0@parabola>

On Thu, 5 Dec 2019 15:39:56 +0000
Thomas Subia <tsubia at imgprecision.com> wrote:

> date <- lapply(files, read_excel, sheet="Sheet1", range=("B5"))
> date_df <- as.data.frame(date)
> trans_date <-t(date_df)
> mydates <- list(trans_date)

This feels a bit excessive for what looks like a one-dimensional string
vector. Why is it needed? Can you get better results with sapply or
vapply (which return vectors, not lists)?

In particular, as.data.frame might be responsible for the name
mangling. Also, your data seems to end up inside the row names. Try
using str() on every step of the transformation to check if that is the
case.

Also check out the .name_repair argument of the read_excel function,
but I think that as.data.frame is part of the problem.

-- 
Best regards,
Ivan


From er|cjberger @end|ng |rom gm@||@com  Thu Dec  5 21:44:59 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 5 Dec 2019 22:44:59 +0200
Subject: [R] passing reference class method within the class as an argument
Message-ID: <CAGgJW77HvKC4_hYZtOtd8RPX4gUR8Gy=5QX5LsE80YuvVk6J=g@mail.gmail.com>

Here is the code of a reproducible example:

foo <- setRefClass("foo",
                   fields=list(x="numeric"),
                   methods=list(
                       initialize=function(a) {
                           x <<- a
                       },
                       funcA=function(f) {
                           f(x)+f(x)
                       },
                       funcB=function(y) {
                           y^2
                       },
                       funcC=function() {
                           u <- funcA(funcB)
                           u
                       }
                   ))

w <- foo(2)
z <- w$funcC()
print(z)

When I run this code it gives the following error:

Error in funcA(funcB) : object 'funcB' not found

How am I supposed to pass funcB?

Thanks,
Eric


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Dec  5 22:24:42 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 6 Dec 2019 10:24:42 +1300
Subject: [R] [FORGED]  readxl question
In-Reply-To: <CH2PR17MB3749076EBDBFE96E7D3ABB41B85C0@CH2PR17MB3749.namprd17.prod.outlook.com>
References: <CH2PR17MB3749076EBDBFE96E7D3ABB41B85C0@CH2PR17MB3749.namprd17.prod.outlook.com>
Message-ID: <79ec5ccc-89ab-5a20-8b89-f54b7cbbb311@auckland.ac.nz>


The best advice that anyone could give:

See fortunes::fortune("Friends") .

cheers,

Rolf Turner

On 6/12/19 4:39 am, Thomas Subia wrote:
> Colleagues,
> 
> I'm trying to extract a cell from all Excel files in a directory.
> 
> library(readxl)
> files <- list.files(pattern="*.xls", full.names = FALSE)
> 
> date <- lapply(files, read_excel, sheet="Sheet1", range=("B5"))
> 
> date_df <- as.data.frame(date)
> trans_date <-t(date_df)
> mydates <- list(trans_date)
> write.table(mydates,"mydates.txt",sep="\t")
> 
> Looking at mydates.txt shows:
> 
> ""
> "Saturday..June.09..2018"	
> "Saturday..June.09..2018.1"	
> "Saturday..June.09..2018.2"
> 
> But the original Excel contents are:
> 
> Saturday, June 09, 2018
> Saturday, June 09, 2018
> Saturday, June 09, 2018
> 
> I get a similar problem with my serial numbers
> 
> serial <-lapply(files, read_excel, sheet="Sheet1", range=("B9"))
> 
> serial_df <- as.data.frame(serial)
> trans_serial <-t(serial_df)
> myserials <- list(trans_serial)
> write.table(myserials,"myserials.txt",sep="\t")
> 
> R Output
> 
> ""
> "X96739.0027.1"	
> "X96739.0041.1"	
> "X96739.0044.1"	
> 
> Original Excel Content
> 96739-0027/1
> 96739-0041/1
> 96739-0044/1
> 
> How can I amend my script so that the output matches the original Excel content?


From r@oknz @end|ng |rom gm@||@com  Fri Dec  6 00:18:50 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 6 Dec 2019 12:18:50 +1300
Subject: [R] Help to write the R-code, please
In-Reply-To: <CAAdh95OBzPQRznL+v80GEn3M8qAGsYT9PG3_-H42Y-Yhwi8m0A@mail.gmail.com>
References: <CAAdh95OBzPQRznL+v80GEn3M8qAGsYT9PG3_-H42Y-Yhwi8m0A@mail.gmail.com>
Message-ID: <CABcYAdLaS-D+w-P406icBdxQv9hXinm=gcyQN1Of17Tx3huZ5w@mail.gmail.com>

This particular task is not a problem about R.
It is a problem n combinatorics.
Start with the obvious brute force algorithm
(1) Let S be the union of all the sets
(2) For each K in 0 .. |S|
(3)   Enumerate all |S| choose K subsets C of S
(4)     If C satisfies the condition, report it and stop
(5) Report that there is no solution.
There is a function 'combn' in the 'combinat' package that
is perfectly suited to step 3.

I have not examined your outlined solution.  Even if it is right,
it pays to START by writing a crude obvious brute force
algorithm like this so that you can test your test cases.

On Fri, 6 Dec 2019 at 03:14, ????????? ??????????
<dubrovvsskkyy at gmail.com> wrote:
>
> Task:
> A family of sets of letters is given. Find K for which one can construct a
> set consisting of K letters, each of them belonging to exactly K sets of a
> given family.
>
> Possible solution:
> For each letter, we will have a separate 'scoop', in which we will' put '
> the letter. This can be done using array A of 255 elements. In this case,
> the number of the 'scoop' corresponding to a letter is determined by the
> letter code (it is known that any letter is encoded by some binary number
> containing 8 digits - called bits; in Pascal, its code can be determined by
> using the ord function). When viewing the sets, let's count how many times
> each letter met. This is done as follows. When you meet a letter, increase
> the contents of the corresponding array element by 1. The initial contents
> of the array elements are 0. After viewing the letters of all sets,
> elements a determine the number of corresponding letters, and therefore the
> number of sets that have the corresponding letter (because in one set, all
> elements are different!). Using similarly array B from 255 elements (more
> need not, so as the desired the number of to on condition not exceeds
> number of letters) count the number of units, twos and so on in array A.
> Maximum significance index K, for which K=B[K] and will solution meet the
> tasks.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Fri Dec  6 08:27:03 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 6 Dec 2019 09:27:03 +0200
Subject: [R] SOLVED: passing reference class method within the class as an
 argument
Message-ID: <CAGgJW75A5+jO7uU+wavxVWeLK-e+jaVY1hUnvFDEHmXYBDzM8w@mail.gmail.com>

Here is the modified code of the reproducible example I sent previously.
Notice the .self$ prefix to funcB which is what has changed

foo <- setRefClass("foo",
                   fields=list(x="numeric"),
                   methods=list(
                       initialize=function(a) {
                           x <<- a
                       },
                       funcA=function(f) {
                           f(x)+f(x)
                       },
                       funcB=function(y) {
                           y^2
                       },
                       funcC=function() {
                           u <- funcA(.self$funcB)
                           u
                       }
                   ))

w <- foo(2)
z <- w$funcC()
print(z)

# 8

	[[alternative HTML version deleted]]


From m@rc_grt @end|ng |rom y@hoo@|r  Fri Dec  6 08:39:15 2019
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Fri, 6 Dec 2019 08:39:15 +0100
Subject: [R] How prevent update of a package
References: <026e0c2b-55f1-887a-94d2-ec44b0848c5a.ref@yahoo.fr>
Message-ID: <026e0c2b-55f1-887a-94d2-ec44b0848c5a@yahoo.fr>

I use R 3.6.1 in macOSX 10.15.1 (Catalina).

I cannot install the last version (3.0-7) of the package raster from 
source or from binary. In both cases I get

 ??*** caught segfault ***
address 0x31, cause 'memory not mapped'

when I try to load it.

Same occurs when I use the development version using:

library(devtools)
install_github("rspatial/raster")

This is the same bug as described here: 
https://github.com/rspatial/raster/issues/63

The last working version for me is the 2.5-8

require(devtools)
install_version("raster", version = "2.5-8", repos = 
"http://cran.us.r-project.org")

However, each time that I use update.packages(), raster wants to be updated.

So here my three questions:

- Does someone has a solution to have raster 3.0-7 working in MacOSX ?

- Do others have raster 3.0-7 working in R 3.6.1 and Catalina MacOSX ?

- How to prevent raster package to be updated ?

Thanks a lot

Marc


From pro|@@m|t@m|tt@| @end|ng |rom gm@||@com  Fri Dec  6 08:42:08 2019
From: pro|@@m|t@m|tt@| @end|ng |rom gm@||@com (Amit Mittal)
Date: Fri, 6 Dec 2019 07:42:08 +0000
Subject: [R] How prevent update of a package
In-Reply-To: <026e0c2b-55f1-887a-94d2-ec44b0848c5a@yahoo.fr>
References: <026e0c2b-55f1-887a-94d2-ec44b0848c5a.ref@yahoo.fr>,
 <026e0c2b-55f1-887a-94d2-ec44b0848c5a@yahoo.fr>
Message-ID: <DM6PR13MB2620DF17AD68841BAA290B13FC5F0@DM6PR13MB2620.namprd13.prod.outlook.com>

Just install Older R from the project R archives in a separate directory

Best Regards

Please excuse the brevity of the message. This message was sent from a mobile device.

________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Marc Girondot via R-help <r-help at r-project.org>
Sent: Friday, December 6, 2019 1:09 PM
To: R-help Mailing List
Subject: [R] How prevent update of a package

I use R 3.6.1 in macOSX 10.15.1 (Catalina).

I cannot install the last version (3.0-7) of the package raster from
source or from binary. In both cases I get

??*** caught segfault ***
address 0x31, cause 'memory not mapped'

when I try to load it.

Same occurs when I use the development version using:

library(devtools)
install_github("rspatial/raster")

This is the same bug as described here:
https://github.com/rspatial/raster/issues/63

The last working version for me is the 2.5-8

require(devtools)
install_version("raster", version = "2.5-8", repos =
"http://cran.us.r-project.org")

However, each time that I use update.packages(), raster wants to be updated.

So here my three questions:

- Does someone has a solution to have raster 3.0-7 working in MacOSX ?

- Do others have raster 3.0-7 working in R 3.6.1 and Catalina MacOSX ?

- How to prevent raster package to be updated ?

Thanks a lot

Marc

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Dec  6 09:44:10 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 6 Dec 2019 09:44:10 +0100
Subject: [R] Help to write the R-code, please
In-Reply-To: <CABcYAdLaS-D+w-P406icBdxQv9hXinm=gcyQN1Of17Tx3huZ5w@mail.gmail.com>
References: <CAAdh95OBzPQRznL+v80GEn3M8qAGsYT9PG3_-H42Y-Yhwi8m0A@mail.gmail.com>
 <CABcYAdLaS-D+w-P406icBdxQv9hXinm=gcyQN1Of17Tx3huZ5w@mail.gmail.com>
Message-ID: <24042.5338.896759.351783@stat.math.ethz.ch>

>>>>> Richard O'Keefe 
>>>>>     on Fri, 6 Dec 2019 12:18:50 +1300 writes:

    > This particular task is not a problem about R.
    > It is a problem n combinatorics.
    > Start with the obvious brute force algorithm
    > (1) Let S be the union of all the sets
    > (2) For each K in 0 .. |S|
    > (3)   Enumerate all |S| choose K subsets C of S
    > (4)     If C satisfies the condition, report it and stop
    > (5) Report that there is no solution.

    > There is a function 'combn' in the 'combinat' package that
    > is perfectly suited to step 3.

combn() in  "base R" (package 'utils') should probably suffice;
its  help page [ help(combn) ] also mentions

 Author(s):

     Scott Chasalow wrote the original in 1994 for S; R package
     ?combinat? and documentation by Vince Carey <email:
     stvjc at channing.harvard.edu>; small changes by the R core team,
     notably to return an array in all cases of ?simplify = TRUE?,
     e.g., for ?combn(5,5)?.

which may suggest that R's ("utils") version of combn() may even
be slightly improved

    > I have not examined your outlined solution.  Even if it is right,
    > it pays to START by writing a crude obvious brute force
    > algorithm like this so that you can test your test cases.

Definitely!   First be *right*, only then think of being fast ..

Martin

    > On Fri, 6 Dec 2019 at 03:14, ????????? ??????????
    > <dubrovvsskkyy at gmail.com> wrote:
    >> 
    >> Task:
    >> A family of sets of letters is given. Find K for which one can construct a
    >> set consisting of K letters, each of them belonging to exactly K sets of a
    >> given family.
    >> 
    >> Possible solution:
    >> For each letter, we will have a separate 'scoop', in which we will' put '
    >> the letter. This can be done using array A of 255 elements. In this case,
    >> the number of the 'scoop' corresponding to a letter is determined by the
    >> letter code (it is known that any letter is encoded by some binary number
    >> containing 8 digits - called bits; in Pascal, its code can be determined by
    >> using the ord function). When viewing the sets, let's count how many times
    >> each letter met. This is done as follows. When you meet a letter, increase
    >> the contents of the corresponding array element by 1. The initial contents
    >> of the array elements are 0. After viewing the letters of all sets,
    >> elements a determine the number of corresponding letters, and therefore the
    >> number of sets that have the corresponding letter (because in one set, all
    >> elements are different!). Using similarly array B from 255 elements (more
    >> need not, so as the desired the number of to on condition not exceeds
    >> number of letters) count the number of units, twos and so on in array A.
    >> Maximum significance index K, for which K=B[K] and will solution meet the
    >> tasks.
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From bo|ogn@regg|o @end|ng |rom gm@||@com  Thu Dec  5 19:26:23 2019
From: bo|ogn@regg|o @end|ng |rom gm@||@com (gabriele pallotti)
Date: Thu, 5 Dec 2019 19:26:23 +0100
Subject: [R] R commander (Rcmdr) won't start
Message-ID: <CAORHkxCN81Jsn=iguu3fh-666rXA+Y5VRZRTq0bbujfgUghrag@mail.gmail.com>

Hallo
I've been using R and R commander (Rcmdr) for some years, never had
problems. I'm on Xubuntu 16.04. Yesterday I updated R from 3.4.4 to 3.6.1
and all sorts of problems occurred. Firstly I completely removed R from my
system, including old directories (with some hiccups, I must admit). Then I
installed R and R-dev without issues. Had some issues installing Rcmdr, but
in the end I met all the requirements and installed all the requested
packages, including rgl and a few others that were requested upon first
launching Rcmdr. After that, no more error messages. However, whenever I
launch R commander I get these lines, which don't mention any problem, but
the GUI won't launch.


> library(Rcmdr)
Carico il pacchetto richiesto: splines
Carico il pacchetto richiesto: RcmdrMisc
Carico il pacchetto richiesto: car
Carico il pacchetto richiesto: carData
Carico il pacchetto richiesto: sandwich
Carico il pacchetto richiesto: effects
Registered S3 methods overwritten by 'lme4':
  method                          from
  cooks.distance.influence.merMod car
  influence.merMod                car
  dfbeta.influence.merMod         car
  dfbetas.influence.merMod        car
lattice theme set by effectsTheme()
See ?effectsTheme for details.


After seeing, if I type library(Rcmdr) again, nothing happens.
I  installed Hmisc, leaps and aplpack, as these were indicated as possible
solutions, but to no avail.

This is the output of sys.info and sessionInfo


> Sys.info()
                                       sysname
                                       "Linux"
                                       release
                           "4.4.0-170-generic"
                                       version
"#199-Ubuntu SMP Thu Nov 14 01:45:04 UTC 2019"
                                      nodename
                                    "me-HP430"
                                       machine
                                      "x86_64"
                                         login
                                          "me"
                                          user
                                          "me"
                                effective_user
                                          "me"

> sessionInfo()
R version 3.6.1 (2019-07-05)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.6 LTS

Matrix products: default
BLAS:   /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

Random number generation:
 RNG:     Mersenne-Twister
 Normal:  Inversion
 Sample:  Rounding

locale:
 [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=it_IT.UTF-8        LC_COLLATE=it_IT.UTF-8
 [5] LC_MONETARY=it_IT.UTF-8    LC_MESSAGES=it_IT.UTF-8
 [7] LC_PAPER=it_IT.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=it_IT.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] effects_4.1-4   RcmdrMisc_2.5-1 sandwich_2.5-1  car_3.0-5
[5] carData_3.0-3

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.3          lattice_0.20-38     tcltk2_1.2-11
 [4] class_7.3-15        zoo_1.8-6           relimp_1.0-5
 [7] zeallot_0.1.0       digest_0.6.23       R6_2.4.1
[10] cellranger_1.1.0    backports_1.1.5     acepack_1.4.1
[13] survey_3.36         e1071_1.7-3         ggplot2_3.2.1
[16] pillar_1.4.2        rlang_0.4.2         lazyeval_0.2.2
[19] curl_4.3            readxl_1.3.1        minqa_1.2.4
[22] rstudioapi_0.10     data.table_1.12.6   nloptr_1.2.1
[25] rpart_4.1-15        Matrix_1.2-18       checkmate_1.9.4
[28] lme4_1.1-21         stringr_1.4.0       foreign_0.8-72
[31] htmlwidgets_1.5.1   munsell_0.5.0       compiler_3.6.1
[34] xfun_0.11           pkgconfig_2.0.3     base64enc_0.1-3
[37] mitools_2.4         htmltools_0.4.0     tcltk_3.6.1
[40] nnet_7.3-12         tibble_2.1.3        gridExtra_2.3
[43] htmlTable_1.13.3    Hmisc_4.3-0         rio_0.5.16
[46] Rcmdr_2.6-1         crayon_1.3.4        MASS_7.3-51.4
[49] grid_3.6.1          DBI_1.0.0           nlme_3.1-142
[52] gtable_0.3.0        lifecycle_0.1.0     magrittr_1.5
[55] scales_1.1.0        zip_2.0.4           stringi_1.4.3
[58] latticeExtra_0.6-28 vctrs_0.2.0         boot_1.3-23
[61] openxlsx_4.1.3      nortest_1.0-4       Formula_1.2-3
[64] RColorBrewer_1.1-2  tools_3.6.1         forcats_0.4.0
[67] hms_0.5.2           abind_1.4-5         survival_3.1-8
[70] colorspace_1.4-1    cluster_2.1.0       knitr_1.26
[73] haven_2.2.0

This is the list of installed packages:

Package    Version
          aplpack      1.3.3
            Hmisc      4.3-0
            leaps        3.0
            Rcmdr      2.6-1
            abind      1.4-5
          acepack      1.4.1
          aplpack      1.3.3
              arm     1.10-1
       assertthat      0.2.1
        backports      1.1.5
        base64enc      0.1-3
               BH   1.69.0-1
            callr      3.3.2
              car      3.0-5
          carData      3.0-3
       cellranger      1.1.0
        checkmate      1.9.4
              cli      1.1.0
            clipr      0.7.0
             coda     0.19-3
       colorspace      1.4-1
           crayon      1.3.4
        crosstalk      1.0.0
             curl        4.3
       data.table     1.12.6
              DBI      1.0.0
           digest     0.6.23
            e1071      1.7-3
          effects      4.1-4
         ellipsis      0.3.0
     estimability        1.3
         evaluate       0.14
            fansi      0.4.0
           farver      2.0.1
          fastmap      1.0.1
          forcats      0.4.0
          Formula      1.2-3
          ggplot2      3.2.1
             glue      1.3.1
        gridExtra        2.3
           gtable      0.3.0
            haven      2.2.0
            highr        0.8
            Hmisc      4.3-0
              hms      0.5.2
        htmlTable     1.13.3
        htmltools      0.4.0
      htmlwidgets      1.5.1
           httpuv      1.5.2
         jsonlite        1.6
            knitr       1.26
         labeling        0.3
            later      1.0.0
     latticeExtra     0.6-28
         lazyeval      0.2.2
            leaps        3.0
        lifecycle      0.1.0
             lme4     1.1-21
           lmtest     0.9-37
         magrittr        1.5
 manipulateWidget     0.10.0
         maptools      0.9-9
         markdown        1.1
       matrixcalc      1.0-3
     MatrixModels      0.4-1
               mi        1.0
             mime        0.7
           miniUI    0.1.1.1
            minqa      1.2.4
          mitools        2.4
         multcomp     1.4-10
          munsell      0.5.0
          mvtnorm     1.0-11
           nloptr      1.2.1
          nortest      1.0-4
         numDeriv 2016.8-1.1
         openxlsx      4.1.3
         pbkrtest      0.4-7
           pillar      1.4.2
        pkgconfig      2.0.3
             plyr      1.8.4
      prettyunits      1.0.2
         processx      3.4.1
         progress      1.2.2
         promises      1.1.0
               ps      1.3.0
            purrr      0.3.3
         quantreg       5.52
               R6      2.4.1
            Rcmdr      2.6-1
        RcmdrMisc      2.5-1
     RColorBrewer      1.1-2
             Rcpp      1.0.3
        RcppEigen  0.3.3.7.0
            readr      1.3.1
      readstata13      0.9.2
           readxl      1.3.1
           relimp      1.0-5
          rematch      1.0.1
         reshape2      1.4.3
              rgl   0.100.30
              rio     0.5.16
            rlang      0.4.2
        rmarkdown       1.18
       rstudioapi       0.10
         sandwich      2.5-1
           scales      1.1.0
              sem      3.1-9
            shiny      1.4.0
      sourcetools      0.1.7
               sp      1.3-2
          SparseM       1.77
          stringi      1.4.3
          stringr      1.4.0
           survey       3.36
           tcltk2     1.2-11
          TH.data     1.0-10
           tibble      2.1.3
       tidyselect      0.2.5
          tinytex       0.17
             utf8      1.1.4
            vctrs      0.2.0
          viridis      0.5.1
      viridisLite      0.3.0
          webshot      0.5.2
            withr      2.1.2
             xfun       0.11
           xtable      1.8-4
             yaml      2.2.0
          zeallot      0.1.0
              zip      2.0.4
              zoo      1.8-6

	[[alternative HTML version deleted]]


From c@|um@po|w@rt @end|ng |rom nh@@net  Fri Dec  6 12:50:46 2019
From: c@|um@po|w@rt @end|ng |rom nh@@net (POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST))
Date: Fri, 6 Dec 2019 11:50:46 +0000
Subject: [R] A better scales::dollar() ?
Message-ID: <0501040583da4a55b0c37041781824f1@NH-SLPEX171.AD1.NHS.NET>

I'm writing a quite large document in Rmarkdown which has financial data in it.  I format that data using scales::dollar() currently something like this:

>
> require (scales)
> x = 100000
> cat (dollar (x, prefix ="?", big.mark=","))

?100,000

But actually, I'd quite like to get ?100k out in that instance so I'd do:

> cat (dollar (x/10^3, prefix ="?", suffix="k" ))

?100k

But x could be 100 or 10,000,000.  I want some form of 'automatic' version that might give me something like:

>
> require (scales)
> y = 0:7
> x = 1^y
> dollar(x, prefix="?")
[1] "?1"          "?10"         "?100"        "?1,000"      "?10,000"     "?100,000"    "?1,000,000"  "?10,000,000"

But what I want is more like:

?1.00  ?10.00  ?100  ?1k  ?10k  ?100k  ?1m  ?10m

I'm sure I can write something as a little function, but before I do - is there something already out there?

I have a similar need to format milligrams through to kilograms.


********************************************************************************************************************

This message may contain confidential information. If you are not the intended recipient please inform the
sender that you have received the message in error before deleting it.
Please do not disclose, copy or distribute information in this e-mail or take any action in relation to its contents. To do so is strictly prohibited and may be unlawful. Thank you for your co-operation.

NHSmail is the secure email and directory service available for all NHS staff in England and Scotland. NHSmail is approved for exchanging patient data and other sensitive information with NHSmail and other accredited email services.

For more information and to find out how you can switch, https://portal.nhs.net/help/joiningnhsmail


From m@rc_grt @end|ng |rom y@hoo@|r  Fri Dec  6 17:46:23 2019
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Fri, 6 Dec 2019 17:46:23 +0100
Subject: [R] How prevent update of a package
In-Reply-To: <DM6PR13MB2620DF17AD68841BAA290B13FC5F0@DM6PR13MB2620.namprd13.prod.outlook.com>
References: <026e0c2b-55f1-887a-94d2-ec44b0848c5a.ref@yahoo.fr>
 <026e0c2b-55f1-887a-94d2-ec44b0848c5a@yahoo.fr>
 <DM6PR13MB2620DF17AD68841BAA290B13FC5F0@DM6PR13MB2620.namprd13.prod.outlook.com>
Message-ID: <9463d770-5760-8be6-d0df-7781752784c7@yahoo.fr>

Thanks for your answer. I try this trick:

mkdir packages
sudo chmod -R a+w packages
ls -al
drwxrwxrwx??? 2 marcgirondot staff????? 64? 6 d?c 17:20 packages

Now in R

 > require(devtools)
 >
 > install_version("raster", version = "2.5-8", repos 
="http://cran.us.r-project.org",
 ??????? lib="/Users/marcgirondot/ Here the full path /packages")

And I get:
Erreur : Failed to install 'unknown package' from URL:
 ? (converti depuis l'avis) 'lib = 
"/Users/marcgirondot/Documents/Espace_de_travail_R/packages
"' is not writable

Not sure were I do something wrong.

Thanks if you have an idea.

Marc


Le 06/12/2019 ? 08:42, Amit Mittal a ?crit?:
> Just install Older R from the project R archives in a separate directory
>
> Best Regards
>
> Please excuse the brevity of the message. This message was sent from a 
> mobile device.
> ------------------------------------------------------------------------
> *From:* R-help <r-help-bounces at r-project.org> on behalf of Marc 
> Girondot via R-help <r-help at r-project.org>
> *Sent:* Friday, December 6, 2019 1:09 PM
> *To:* R-help Mailing List
> *Subject:* [R] How prevent update of a package
> I use R 3.6.1 in macOSX 10.15.1 (Catalina).
>
> I cannot install the last version (3.0-7) of the package raster from
> source or from binary. In both cases I get
>
> ??*** caught segfault ***
> address 0x31, cause 'memory not mapped'
>
> when I try to load it.
>
> Same occurs when I use the development version using:
>
> library(devtools)
> install_github("rspatial/raster")
>
> This is the same bug as described here:
> https://github.com/rspatial/raster/issues/63
>
> The last working version for me is the 2.5-8
>
> require(devtools)
> install_version("raster", version = "2.5-8", repos =
> "http://cran.us.r-project.org")
>
> However, each time that I use update.packages(), raster wants to be 
> updated.
>
> So here my three questions:
>
> - Does someone has a solution to have raster 3.0-7 working in MacOSX ?
>
> - Do others have raster 3.0-7 working in R 3.6.1 and Catalina MacOSX ?
>
> - How to prevent raster package to be updated ?
>
> Thanks a lot
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From bo|ogn@regg|o @end|ng |rom gm@||@com  Fri Dec  6 19:38:45 2019
From: bo|ogn@regg|o @end|ng |rom gm@||@com (gabriele pallotti)
Date: Fri, 6 Dec 2019 19:38:45 +0100
Subject: [R] R commander (Rcmdr) won't start [SOLVED]
Message-ID: <CAORHkxAVEf21+GK5=_3ZeMaDsMEdzDyOaJ-_D2G8oCaBxAzgSQ@mail.gmail.com>

I managed to get Rcmdr working simply by deleting the .Rdata and .Rhistory
file from the work directory. It is rather weird, as I thought they only
contained data and settings, but probably some of these belonged to the
older version of R/Rcmdr and were not compatible with the new version.
I'll keep the old data files in a separate folder and try to open them as a
workspace after launching Rcmdr, but I won't do it now as I need Rcmdr to
work in the next days and I don't want to take any risks...

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Dec  6 20:02:29 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 06 Dec 2019 11:02:29 -0800
Subject: [R] R commander (Rcmdr) won't start [SOLVED]
In-Reply-To: <CAORHkxAVEf21+GK5=_3ZeMaDsMEdzDyOaJ-_D2G8oCaBxAzgSQ@mail.gmail.com>
References: <CAORHkxAVEf21+GK5=_3ZeMaDsMEdzDyOaJ-_D2G8oCaBxAzgSQ@mail.gmail.com>
Message-ID: <2DC85CCE-0E09-494F-B3F2-E82B79D5BCE2@dcn.davis.ca.us>

Experienced R users avoid creating .Rdata files (with nothing in front of the period) because R will automatically load them and any mistakes recorded there can interfere with future uses of R when started from the directory containing that file. RData files with something in front of the period can be loaded interactively and any problems they bring can be avoided by simply not choosing to load them.

.Rhistory files have no such negative effect... it is highly unlikely that that file was causing you any problems. They are just a record of R commands that have been used and are only retrieved by R user interfaces such as Rgui or RStudio upon request.

On December 6, 2019 10:38:45 AM PST, gabriele pallotti <bolognareggio at gmail.com> wrote:
>I managed to get Rcmdr working simply by deleting the .Rdata and
>.Rhistory
>file from the work directory. It is rather weird, as I thought they
>only
>contained data and settings, but probably some of these belonged to the
>older version of R/Rcmdr and were not compatible with the new version.
>I'll keep the old data files in a separate folder and try to open them
>as a
>workspace after launching Rcmdr, but I won't do it now as I need Rcmdr
>to
>work in the next days and I don't want to take any risks...
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From j|ox @end|ng |rom mcm@@ter@c@  Fri Dec  6 22:58:42 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 6 Dec 2019 21:58:42 +0000
Subject: [R] R commander (Rcmdr) won't start [SOLVED]
In-Reply-To: <28124_1575657553_xB6IdD9x013047_CAORHkxAVEf21+GK5=_3ZeMaDsMEdzDyOaJ-_D2G8oCaBxAzgSQ@mail.gmail.com>
References: <28124_1575657553_xB6IdD9x013047_CAORHkxAVEf21+GK5=_3ZeMaDsMEdzDyOaJ-_D2G8oCaBxAzgSQ@mail.gmail.com>
Message-ID: <0B0AF79A-91E9-4FB0-838E-2F0ED553147D@mcmaster.ca>

Dear Gabriele,

I'm glad that you were able to solve your problem. I spent a bit of time today updating my R from 3.6.0 to 3.6.1 and updating all R packages on Ubuntu, and, for what is now an obvious reason, I was unable to duplicate the problem.

Saving the .Rhistory file is benign but saving the R workspace at the end of a session in .RData can be problematic, and not just for the Rcmdr. You'll notice that while R makes saving the workspace the default (presumably to avoid inadvertent data loss, and in my opinion not a good default choice), the Rcmdr doesn't offer to save the R workspace when you select "File > Exit > From Commander and R" from the Rcmdr menus.

Best,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Dec 6, 2019, at 1:38 PM, gabriele pallotti <bolognareggio at gmail.com> wrote:
> 
> I managed to get Rcmdr working simply by deleting the .Rdata and .Rhistory
> file from the work directory. It is rather weird, as I thought they only
> contained data and settings, but probably some of these belonged to the
> older version of R/Rcmdr and were not compatible with the new version.
> I'll keep the old data files in a separate folder and try to open them as a
> workspace after launching Rcmdr, but I won't do it now as I need Rcmdr to
> work in the next days and I don't want to take any risks...
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nto|edo@b|o| @end|ng |rom gm@||@com  Fri Dec  6 15:53:28 2019
From: nto|edo@b|o| @end|ng |rom gm@||@com (=?UTF-8?Q?N=C3=A9stor_Toledo?=)
Date: Fri, 6 Dec 2019 11:53:28 -0300
Subject: [R] how to deal with deprecated functions
In-Reply-To: <c790e523-8808-5c2c-d06f-10d2ef4a8e3d@gmail.com>
References: <bd9c4a3c-e469-69c9-b3d4-563fd3ae2c01@gmail.com>
 <c790e523-8808-5c2c-d06f-10d2ef4a8e3d@gmail.com>
Message-ID: <CAG=qMXLBwGogL-0ewGYmDA4gbQVw5hZEO5Jqc=icd-KjYsq73A@mail.gmail.com>

Ok I understand. I wasn't intended to look as complaining, sorry.

 It was interesting to get the pointview of a developer (thanks JC Nash).
To code a new package comprising useful but deprecated functions is a very
good advice, thanks, I will try to hone my coding skills to do so (and to
be more involved with the R community as well).

Thanks again for your feedback



Dr. N?stor Toledo
Divisi?n Paleontolog?a Vertebrados
ntoledo at fcnym.unlp.edu.ar
Unidades de Investigaci?n Anexo Museo FCNyM-UNLP
Av. 60 y 122 B1900FWA (B1906CXT) La Plata, Argentina
Tel. 54 221 422 8451 int 115 of 115
http://sedici.unlp.edu.ar/handle/10915/55101

El jue., 5 de dic. de 2019 14:16, Duncan Murdoch <murdoch.duncan at gmail.com>
escribi?:

> On 04/12/2019 2:07 p.m., Nestor Toledo wrote:
> > Hello everyone, even I'm not fluent in coding, R has become a
> > fundamental part of my daily work as a researcher and I'm very much
> > grateful for such a wonderful, open tool. However, I have faced in many
> > opportunities the problems associated with updates/upgrades of packages.
> > Frequently packages developers modify command syntax or directly
> > deprecate entire functions. This becomes a nuisance, since I must to
> > recode my scripts partially or totally, or even search for alternative
> > functions in other packages. Is there any solution to this, other than
> > skip updates or keeping old versions installed in a different folder?
> > Could be acceptable ask developers to do not deprecate functions but
> > keep them as "legacy" ones or similar?
> >
> > Thanks in advance and I apologize for my deficient English grammar
> >
>
> As Rui said, there's no easy way to prevent this.  In my experience,
> most maintainers are quite willing to avoid changes that cause problems,
> or help users to work around them:  but they have to know that problems
> were caused.
>
> The easiest way to do this is to share your own code by putting it in a
> package on CRAN with sufficient tests to detect problems.  When a
> package maintainer submits a package update, CRAN checks that all
> "revdeps" (i.e. reverse dependencies, packages that depend on the
> updated one) still pass their tests.  The submitter is asked to contact
> the maintainers of the other packages to resolve any new problems.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From btyner @end|ng |rom gm@||@com  Sat Dec  7 16:22:05 2019
From: btyner @end|ng |rom gm@||@com (Benjamin Tyner)
Date: Sat, 7 Dec 2019 10:22:05 -0500
Subject: [R] safest way to subset (and replace) a data.table
Message-ID: <a8877300-534e-db3f-098a-eea0338fd47c@gmail.com>

Hi

I would like to replace a data.table 'DT' with a subset of itself, where 
the subset is determined by an expression 'expr' which evaluates to 
logical. Thus far I've been using:

 ?? DT <- DT[expr, ]

however this frequently results in a SIGABRT from glibc of the form:

 ?? "double free or corruption (!prev): 0x00000000c08662b40"

I've tried under the latest version of R and the latest version of data 
table, but the issue still persists. So now I'm wondering if I'm doing 
it the wrong way.

Any advice?

Regards

Ben


From phii m@iii@g oii phiiipsmith@c@  Sun Dec  8 03:31:44 2019
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Sat, 07 Dec 2019 21:31:44 -0500
Subject: [R] Plotting confidence intervals
Message-ID: <a9190f9a14473f6d7eb7b05b25f54b00@philipsmith.ca>

I want to show little bell curves on my bar chart to illustrate the 
confidence ranges. The following example from Paul Teetor's "R Cookbook" 
does what I want, but shows I-beams instead of bell curves. The I-beams 
suggest uniform, rather than normal distributions. So I am looking for a 
way to plot normal distribution curves instead.

# Example from Paul Teetor, "R Cookbook", page 238.
library(gplots)
attach(airquality)
heights <- tapply(Temp,Month,mean)
lower <- tapply(Temp,Month,function(v) t.test(v)$conf.int[1])
upper <- tapply(Temp,Month,function(v) t.test(v)$conf.int[2])
barplot2(heights,plot.ci=TRUE,ci.l=lower,ci.u=upper,
          ylim=c(50,90),xpd=FALSE,
          main="Mean Temp. By Month",
          names.arg=c("May","Jun","Jul","Aug","Sep"),
          ylab="Temp (deg. F)")

Does anyone know a package that does this or, alternatively, can anyone 
suggest a direction to go in if one were to write R code to do this?

Philip


From btupper @end|ng |rom b|ge|ow@org  Sun Dec  8 04:07:59 2019
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Sat, 7 Dec 2019 22:07:59 -0500
Subject: [R] Plotting confidence intervals
In-Reply-To: <a9190f9a14473f6d7eb7b05b25f54b00@philipsmith.ca>
References: <a9190f9a14473f6d7eb7b05b25f54b00@philipsmith.ca>
Message-ID: <CALrbzg1CGEU0YJNiJhfH0wVZzFHOkciBHMo9jKJeWX_i1pNnTA@mail.gmail.com>

Hi,

Would something like yarrr do the trick?
https://ndphillips.github.io/yarrr.html

Or gghalves?  https://github.com/erocoar/gghalves


Cheers,
Ben

On Sat, Dec 7, 2019 at 9:32 PM <phil at philipsmith.ca> wrote:

> I want to show little bell curves on my bar chart to illustrate the
> confidence ranges. The following example from Paul Teetor's "R Cookbook"
> does what I want, but shows I-beams instead of bell curves. The I-beams
> suggest uniform, rather than normal distributions. So I am looking for a
> way to plot normal distribution curves instead.
>
> # Example from Paul Teetor, "R Cookbook", page 238.
> library(gplots)
> attach(airquality)
> heights <- tapply(Temp,Month,mean)
> lower <- tapply(Temp,Month,function(v) t.test(v)$conf.int[1])
> upper <- tapply(Temp,Month,function(v) t.test(v)$conf.int[2])
> barplot2(heights,plot.ci=TRUE,ci.l=lower,ci.u=upper,
>           ylim=c(50,90),xpd=FALSE,
>           main="Mean Temp. By Month",
>           names.arg=c("May","Jun","Jul","Aug","Sep"),
>           ylab="Temp (deg. F)")
>
> Does anyone know a package that does this or, alternatively, can anyone
> suggest a direction to go in if one were to write R code to do this?
>
> Philip
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
West Boothbay Harbor, Maine
http://www.bigelow.org/
https://eco.bigelow.org

	[[alternative HTML version deleted]]


From bo|ogn@regg|o @end|ng |rom gm@||@com  Sun Dec  8 09:35:34 2019
From: bo|ogn@regg|o @end|ng |rom gm@||@com (gabriele pallotti)
Date: Sun, 8 Dec 2019 09:35:34 +0100
Subject: [R] R commander (Rcmdr) won't start [SOLVED]
In-Reply-To: <0B0AF79A-91E9-4FB0-838E-2F0ED553147D@mcmaster.ca>
References: <28124_1575657553_xB6IdD9x013047_CAORHkxAVEf21+GK5=_3ZeMaDsMEdzDyOaJ-_D2G8oCaBxAzgSQ@mail.gmail.com>
 <0B0AF79A-91E9-4FB0-838E-2F0ED553147D@mcmaster.ca>
Message-ID: <CAORHkxAeTqf60MyEmY_E1sZrJ+CtUTk=fbOcufdOcHBCS5V4ew@mail.gmail.com>

Dear John,
thank you for your prompt reply. An inexperienced user like me tends to see
the .Rdata folder like the document folder for other programs, and, as one
doesn't have to delete the document folder when updating Libreoffice, tends
to think the same for R.
But let me take the opportunity to express a huge thank you for your work
on Rcmdr. For people like me, who do statistical analyses just a few times
a year, it is a very precious resource, which can also serve as an
introduction to command-line R. As an applied linguist with a background in
semiotics, I would have plenty of reasons to explain why a graphic
interface is such a good thing. As a taxpayer, I appreciate the fact that
it makes us saves money as it allows students and researchers in the
humanities, like me, to do some basic statistics without buying SPSS
licences.
I don't want to open a debate here on the pros and cons of graphical
interfaces. Let me just say you're doing an excellent service to the
community, both with your package and your replies to this forum, which
shows you're a really kind person and deserve all our appreciation.
Best wishes
Gabriele Pallotti (Italy)




Il giorno ven 6 dic 2019 alle ore 22:58 Fox, John <jfox at mcmaster.ca> ha
scritto:

> Dear Gabriele,
>
> I'm glad that you were able to solve your problem. I spent a bit of time
> today updating my R from 3.6.0 to 3.6.1 and updating all R packages on
> Ubuntu, and, for what is now an obvious reason, I was unable to duplicate
> the problem.
>
> Saving the .Rhistory file is benign but saving the R workspace at the end
> of a session in .RData can be problematic, and not just for the Rcmdr.
> You'll notice that while R makes saving the workspace the default
> (presumably to avoid inadvertent data loss, and in my opinion not a good
> default choice), the Rcmdr doesn't offer to save the R workspace when you
> select "File > Exit > From Commander and R" from the Rcmdr menus.
>
> Best,
>  John
>
>   -----------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox
>
> > On Dec 6, 2019, at 1:38 PM, gabriele pallotti <bolognareggio at gmail.com>
> wrote:
> >
> > I managed to get Rcmdr working simply by deleting the .Rdata and
> .Rhistory
> > file from the work directory. It is rather weird, as I thought they only
> > contained data and settings, but probably some of these belonged to the
> > older version of R/Rcmdr and were not compatible with the new version.
> > I'll keep the old data files in a separate folder and try to open them
> as a
> > workspace after launching Rcmdr, but I won't do it now as I need Rcmdr to
> > work in the next days and I don't want to take any risks...
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From phii m@iii@g oii phiiipsmith@c@  Sun Dec  8 10:17:54 2019
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Sun, 08 Dec 2019 04:17:54 -0500
Subject: [R] Plotting confidence intervals
In-Reply-To: <CALrbzg1CGEU0YJNiJhfH0wVZzFHOkciBHMo9jKJeWX_i1pNnTA@mail.gmail.com>
References: <a9190f9a14473f6d7eb7b05b25f54b00@philipsmith.ca>
 <CALrbzg1CGEU0YJNiJhfH0wVZzFHOkciBHMo9jKJeWX_i1pNnTA@mail.gmail.com>
Message-ID: <d57c0ec2d50dcdf6fc9b3f4865b8fedb@philipsmith.ca>

Thanks for these helpful suggestions.

These options don't work in my case because I don't know the individual 
observations (the dots). A statistical agency collects the observations 
and keeps them confidential. It provides the mean value and the standard 
deviation, plus the fact that the observations are normally distributed. 
So I have enough information to draw the distribution function.  Mean 
values and standard deviations are provided for several cases 
(geographies). I can plot the mean values for all cases in a bar chart. 
I can show the confidence intervals as I-beams, as in my example. But I 
would prefer to show the confidence intervals as truncated bell curves, 
referring to, say, 95% of the unseen observations.

Philip

On 2019-12-07 22:07, Ben Tupper wrote:
> Hi,
> 
> Would something like yarrr do the trick?
> https://ndphillips.github.io/yarrr.html
> 
> Or gghalves?  https://github.com/erocoar/gghalves
> 
> Cheers,
> Ben
> 
> On Sat, Dec 7, 2019 at 9:32 PM <phil at philipsmith.ca> wrote:
> 
>> I want to show little bell curves on my bar chart to illustrate the
>> confidence ranges. The following example from Paul Teetor's "R
>> Cookbook"
>> does what I want, but shows I-beams instead of bell curves. The
>> I-beams
>> suggest uniform, rather than normal distributions. So I am looking
>> for a
>> way to plot normal distribution curves instead.
>> 
>> # Example from Paul Teetor, "R Cookbook", page 238.
>> library(gplots)
>> attach(airquality)
>> heights <- tapply(Temp,Month,mean)
>> lower <- tapply(Temp,Month,function(v) t.test(v)$conf.int [1][1])
>> upper <- tapply(Temp,Month,function(v) t.test(v)$conf.int [1][2])
>> barplot2(heights,plot.ci [2]=TRUE,ci.l=lower,ci.u=upper,
>> ylim=c(50,90),xpd=FALSE,
>> main="Mean Temp. By Month",
>> names.arg=c("May","Jun","Jul","Aug","Sep"),
>> ylab="Temp (deg. F)")
>> 
>> Does anyone know a package that does this or, alternatively, can
>> anyone
>> suggest a direction to go in if one were to write R code to do this?
>> 
>> Philip
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Science
> West Boothbay Harbor, Maine
> http://www.bigelow.org/
> 
> https://eco.bigelow.org
> 
> 
> 
> Links:
> ------
> [1] http://conf.int
> [2] http://plot.ci


From drj|m|emon @end|ng |rom gm@||@com  Sun Dec  8 11:00:49 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 8 Dec 2019 21:00:49 +1100
Subject: [R] Plotting confidence intervals
In-Reply-To: <d57c0ec2d50dcdf6fc9b3f4865b8fedb@philipsmith.ca>
References: <a9190f9a14473f6d7eb7b05b25f54b00@philipsmith.ca>
 <CALrbzg1CGEU0YJNiJhfH0wVZzFHOkciBHMo9jKJeWX_i1pNnTA@mail.gmail.com>
 <d57c0ec2d50dcdf6fc9b3f4865b8fedb@philipsmith.ca>
Message-ID: <CA+8X3fX0v2J0FW_fNwvKYYu_M9um=Lm51GWjRj0F9N0Atih17w@mail.gmail.com>

Hi Philip,
This may be a starter:

attach(airquality)
heights <- tapply(Temp,Month,mean)
temp_sd<-tapply(Temp,Month,sd)
lower <- tapply(Temp,Month,function(v) t.test(v)$conf.int[1])
upper <- tapply(Temp,Month,function(v) t.test(v)$conf.int[2])
library(plotrix)
barp(heights,ylim=c(0,100),names.arg=month.abb[5:9],
 main="Air quality (May-Sep)",xlab="Month",ylab="Temperature")
dispersion(1:5,y=heights,ulim=upper,llim=lower,intervals=FALSE)
ci95<-seq(-1.96,1.96,length.out=40)
norm_curve<-rescale(dnorm(ci95),c(0,0.4))
for(i in 1:5)
 polygon(c(i-norm_curve,i+norm_curve),
  c(heights[i]+ci95*temp_sd[i],heights[i]+rev(ci95*temp_sd[i])))

Jim

On Sun, Dec 8, 2019 at 8:18 PM <phil at philipsmith.ca> wrote:
> >> I want to show little bell curves on my bar chart to illustrate the
> >> confidence ranges. The following example from Paul Teetor's "R
> >> Cookbook"
> >> does what I want, but shows I-beams instead of bell curves. The
> >> I-beams
> >> suggest uniform, rather than normal distributions. So I am looking
> >> for a
> >> way to plot normal distribution curves instead.


From phii m@iii@g oii phiiipsmith@c@  Sun Dec  8 14:58:40 2019
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Sun, 08 Dec 2019 08:58:40 -0500
Subject: [R] Plotting confidence intervals
In-Reply-To: <CA+8X3fX0v2J0FW_fNwvKYYu_M9um=Lm51GWjRj0F9N0Atih17w@mail.gmail.com>
References: <a9190f9a14473f6d7eb7b05b25f54b00@philipsmith.ca>
 <CALrbzg1CGEU0YJNiJhfH0wVZzFHOkciBHMo9jKJeWX_i1pNnTA@mail.gmail.com>
 <d57c0ec2d50dcdf6fc9b3f4865b8fedb@philipsmith.ca>
 <CA+8X3fX0v2J0FW_fNwvKYYu_M9um=Lm51GWjRj0F9N0Atih17w@mail.gmail.com>
Message-ID: <69135918192f014d3a0995167ea921c7@philipsmith.ca>

Thanks so much Jim. Yes, this is giving me what I want.

Philip

On 2019-12-08 05:00, Jim Lemon wrote:
> Hi Philip,
> This may be a starter:
> 
> attach(airquality)
> heights <- tapply(Temp,Month,mean)
> temp_sd<-tapply(Temp,Month,sd)
> lower <- tapply(Temp,Month,function(v) t.test(v)$conf.int[1])
> upper <- tapply(Temp,Month,function(v) t.test(v)$conf.int[2])
> library(plotrix)
> barp(heights,ylim=c(0,100),names.arg=month.abb[5:9],
>  main="Air quality (May-Sep)",xlab="Month",ylab="Temperature")
> dispersion(1:5,y=heights,ulim=upper,llim=lower,intervals=FALSE)
> ci95<-seq(-1.96,1.96,length.out=40)
> norm_curve<-rescale(dnorm(ci95),c(0,0.4))
> for(i in 1:5)
>  polygon(c(i-norm_curve,i+norm_curve),
>   c(heights[i]+ci95*temp_sd[i],heights[i]+rev(ci95*temp_sd[i])))
> 
> Jim
> 
> On Sun, Dec 8, 2019 at 8:18 PM <phil at philipsmith.ca> wrote:
>> >> I want to show little bell curves on my bar chart to illustrate the
>> >> confidence ranges. The following example from Paul Teetor's "R
>> >> Cookbook"
>> >> does what I want, but shows I-beams instead of bell curves. The
>> >> I-beams
>> >> suggest uniform, rather than normal distributions. So I am looking
>> >> for a
>> >> way to plot normal distribution curves instead.


From j|ox @end|ng |rom mcm@@ter@c@  Sun Dec  8 15:45:35 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Sun, 8 Dec 2019 14:45:35 +0000
Subject: [R] R commander (Rcmdr) won't start [SOLVED]
In-Reply-To: <CAORHkxAeTqf60MyEmY_E1sZrJ+CtUTk=fbOcufdOcHBCS5V4ew@mail.gmail.com>
References: <28124_1575657553_xB6IdD9x013047_CAORHkxAVEf21+GK5=_3ZeMaDsMEdzDyOaJ-_D2G8oCaBxAzgSQ@mail.gmail.com>
 <0B0AF79A-91E9-4FB0-838E-2F0ED553147D@mcmaster.ca>
 <CAORHkxAeTqf60MyEmY_E1sZrJ+CtUTk=fbOcufdOcHBCS5V4ew@mail.gmail.com>
Message-ID: <4BE71B02-E362-4767-B50F-FF4AFEC54AB4@mcmaster.ca>

Dear Gabriele,

> On Dec 8, 2019, at 3:35 AM, gabriele pallotti <bolognareggio at gmail.com> wrote:
> 
> Dear John, 
> thank you for your prompt reply. An inexperienced user like me tends to see the .Rdata folder like the document folder for other programs, and, as one doesn't have to delete the document folder when updating Libreoffice, tends to think the same for R. 

The potential problem with .RData is that it's not just a file that saves the contents of the R workspace at the end of a session, but that the saved workspace is then loaded at the start of a subsequent session. This can create problems (again, not just for the Rcmdr) in that subsequent session, and not only when R is updated.

> But let me take the opportunity to express a huge thank you for your work on Rcmdr. For people like me, who do statistical analyses just a few times a year, it is a very precious resource, which can also serve as an introduction to command-line R. As an applied linguist with a background in semiotics, I would have plenty of reasons to explain why a graphic interface is such a good thing. As a taxpayer, I appreciate the fact that it makes us saves money as it allows students and researchers in the humanities, like me, to do some basic statistics without buying SPSS licences. 
> I don't want to open a debate here on the pros and cons of graphical interfaces. Let me just say you're doing an excellent service to the community, both with your package and your replies to this forum, which shows you're a really kind person and deserve all our appreciation. 

Thank you for your very kind remarks.

Best,
 John

> Best wishes
> Gabriele Pallotti (Italy)
> 
> 
> 
> 
> Il giorno ven 6 dic 2019 alle ore 22:58 Fox, John <jfox at mcmaster.ca> ha scritto:
> Dear Gabriele,
> 
> I'm glad that you were able to solve your problem. I spent a bit of time today updating my R from 3.6.0 to 3.6.1 and updating all R packages on Ubuntu, and, for what is now an obvious reason, I was unable to duplicate the problem.
> 
> Saving the .Rhistory file is benign but saving the R workspace at the end of a session in .RData can be problematic, and not just for the Rcmdr. You'll notice that while R makes saving the workspace the default (presumably to avoid inadvertent data loss, and in my opinion not a good default choice), the Rcmdr doesn't offer to save the R workspace when you select "File > Exit > From Commander and R" from the Rcmdr menus.
> 
> Best,
>  John
> 
>   -----------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox
> 
> > On Dec 6, 2019, at 1:38 PM, gabriele pallotti <bolognareggio at gmail.com> wrote:
> > 
> > I managed to get Rcmdr working simply by deleting the .Rdata and .Rhistory
> > file from the work directory. It is rather weird, as I thought they only
> > contained data and settings, but probably some of these belonged to the
> > older version of R/Rcmdr and were not compatible with the new version.
> > I'll keep the old data files in a separate folder and try to open them as a
> > workspace after launching Rcmdr, but I won't do it now as I need Rcmdr to
> > work in the next days and I don't want to take any risks...
> > 
> >       [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Dec  8 23:31:50 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 9 Dec 2019 11:31:50 +1300
Subject: [R] [FORGED] Re:  R commander (Rcmdr) won't start [SOLVED]
In-Reply-To: <CAORHkxAeTqf60MyEmY_E1sZrJ+CtUTk=fbOcufdOcHBCS5V4ew@mail.gmail.com>
References: <28124_1575657553_xB6IdD9x013047_CAORHkxAVEf21+GK5=_3ZeMaDsMEdzDyOaJ-_D2G8oCaBxAzgSQ@mail.gmail.com>
 <0B0AF79A-91E9-4FB0-838E-2F0ED553147D@mcmaster.ca>
 <CAORHkxAeTqf60MyEmY_E1sZrJ+CtUTk=fbOcufdOcHBCS5V4ew@mail.gmail.com>
Message-ID: <01d363bc-8d4f-4aa5-b14a-dd69cf820377@auckland.ac.nz>


On 8/12/19 9:35 pm, gabriele pallotti wrote:

> Dear John,
> thank you for your prompt reply. An inexperienced user like me tends to see
> the .Rdata folder like the document folder for other programs, and, as one
> doesn't have to delete the document folder when updating Libreoffice, tends
> to think the same for R.

<SNIP>

You should be aware that .RData (note the upper case "D") is *not* a 
"folder" (or "directory" in the parlance of civilised, i.e. Linux, 
users).  Rather it is a single binary *file*.  It behaves like a 
directory in some sense in that it "contains" (or may contain)  one or 
may R objects which similarly are "like" individual files.  However 
there is a distinction and it can be important to keep this distinction 
in mind in order to understand subtle phenomena that may appear.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Dec  9 01:12:04 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Sun, 8 Dec 2019 18:12:04 -0600
Subject: [R] how to create a txt file with parsed columns
Message-ID: <CAF9-5jMOAL76PJ91by1XQuG8nuSwciVS_0H92MtY=FA39Fk-oQ@mail.gmail.com>

Hello,

I have two data frames:

head(a)
              GENE        rs       BETA
1  ENSG00000154803 rs2605134  0.0360182
2  ENSG00000154803 rs7405677  0.0525463
3  ENSG00000154803 rs7211573  0.0525531
4  ENSG00000154803 rs2746026  0.0466392
5  ENSG00000141030 rs2605134  0.0806140
6  ENSG00000141030 rs7405677  0.0251654
7  ENSG00000141030 rs7211573  0.0252775
8  ENSG00000141030 rs2746026  0.0976396
9  ENSG00000205309 rs2605134  0.0838975
10 ENSG00000205309 rs7405677 -0.2148500
11 ENSG00000205309 rs7211573 -0.2148170
12 ENSG00000205309 rs2746026  0.1013920
13 ENSG00000215030 rs2605134  0.1261050
14 ENSG00000215030 rs7405677  0.0165236
15 ENSG00000215030 rs7211573  0.0163509
16 ENSG00000215030 rs2746026  0.1201180
17 ENSG00000141026 rs2605134  0.0485897
18 ENSG00000141026 rs7405677 -0.0929964
19 ENSG00000141026 rs7211573 -0.0930321
20 ENSG00000141026 rs2746026  0.0623033

head(b)
          rs       GWAS
1  rs2605134  0.0315177
2  rs7405677 -0.0816389
3  rs7211573 -0.0797796
4  rs2746026  0.0199350
5 rs11658521  0.0728377
6  rs9914107  0.0720096
7 rs56964223  0.0723903

Data frame a has:
> length(unique(a$GENE))
[1] 51
> dim(a)
[1] 287   3

and the whole data frame b is shown

I would like to create a txt file which would have rs match for each
ENSG from data frame b. If a particular ENSG does not have matching rs
from data frame b the value under it would be zero. So the txt file
would have 7 rows (for all those unique rs from data frame b) and 53
columns (for 51 ENSGs and one for unique rs and one for GWAS)

So one row of that txt file would look like this.

GENES       ENSG00000154803   ENSG00000141030  ENSG00000205309
ENSG00000215030    ENSG00000141026  GWAS
rs2605134   0.0360182         0.0806140         0.0838975
0.1261050           0.0485897       0.0315177
?

Please advise,
Ana


From drj|m|emon @end|ng |rom gm@||@com  Mon Dec  9 06:03:45 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 9 Dec 2019 16:03:45 +1100
Subject: [R] how to create a txt file with parsed columns
In-Reply-To: <CAF9-5jMOAL76PJ91by1XQuG8nuSwciVS_0H92MtY=FA39Fk-oQ@mail.gmail.com>
References: <CAF9-5jMOAL76PJ91by1XQuG8nuSwciVS_0H92MtY=FA39Fk-oQ@mail.gmail.com>
Message-ID: <CA+8X3fW9x_F3MuS6NBMJynzXVnJrtR9XJTkwYowFE57G=qGT_g@mail.gmail.com>

Hi Ana,
Is this what you want?

a<-read.table(text="GENE        rs       BETA
1  ENSG00000154803 rs2605134  0.0360182
2  ENSG00000154803 rs7405677  0.0525463
3  ENSG00000154803 rs7211573  0.0525531
4  ENSG00000154803 rs2746026  0.0466392
5  ENSG00000141030 rs2605134  0.0806140
6  ENSG00000141030 rs7405677  0.0251654
7  ENSG00000141030 rs7211573  0.0252775
8  ENSG00000141030 rs2746026  0.0976396
9  ENSG00000205309 rs2605134  0.0838975
10 ENSG00000205309 rs7405677 -0.2148500
11 ENSG00000205309 rs7211573 -0.2148170
12 ENSG00000205309 rs2746026  0.1013920
13 ENSG00000215030 rs2605134  0.1261050
14 ENSG00000215030 rs7405677  0.0165236
15 ENSG00000215030 rs7211573  0.0163509
16 ENSG00000215030 rs2746026  0.1201180
17 ENSG00000141026 rs2605134  0.0485897
18 ENSG00000141026 rs7405677 -0.0929964
19 ENSG00000141026 rs7211573 -0.0930321
20 ENSG00000141026 rs2746026  0.0623033",
header=TRUE,stringsAsFactors=FALSE)
b<-read.table(text="rs       GWAS
1  rs2605134  0.0315177
2  rs7405677 -0.0816389
3  rs7211573 -0.0797796
4  rs2746026  0.0199350
5 rs11658521  0.0728377
6  rs9914107  0.0720096
7 rs56964223  0.0723903",
header=TRUE,stringsAsFactors=FALSE)
ab<-merge(a,b,by="rs")
library(prettyR)
abc<-stretch_df(ab,idvar="rs",to.stretch=c("GENE","BETA"))

Jiim

On Mon, Dec 9, 2019 at 11:10 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have two data frames:
>
> head(a)
>               GENE        rs       BETA
> 1  ENSG00000154803 rs2605134  0.0360182
> 2  ENSG00000154803 rs7405677  0.0525463
> 3  ENSG00000154803 rs7211573  0.0525531
> 4  ENSG00000154803 rs2746026  0.0466392
> 5  ENSG00000141030 rs2605134  0.0806140
> 6  ENSG00000141030 rs7405677  0.0251654
> 7  ENSG00000141030 rs7211573  0.0252775
> 8  ENSG00000141030 rs2746026  0.0976396
> 9  ENSG00000205309 rs2605134  0.0838975
> 10 ENSG00000205309 rs7405677 -0.2148500
> 11 ENSG00000205309 rs7211573 -0.2148170
> 12 ENSG00000205309 rs2746026  0.1013920
> 13 ENSG00000215030 rs2605134  0.1261050
> 14 ENSG00000215030 rs7405677  0.0165236
> 15 ENSG00000215030 rs7211573  0.0163509
> 16 ENSG00000215030 rs2746026  0.1201180
> 17 ENSG00000141026 rs2605134  0.0485897
> 18 ENSG00000141026 rs7405677 -0.0929964
> 19 ENSG00000141026 rs7211573 -0.0930321
> 20 ENSG00000141026 rs2746026  0.0623033
>
> head(b)
>           rs       GWAS
> 1  rs2605134  0.0315177
> 2  rs7405677 -0.0816389
> 3  rs7211573 -0.0797796
> 4  rs2746026  0.0199350
> 5 rs11658521  0.0728377
> 6  rs9914107  0.0720096
> 7 rs56964223  0.0723903
>
> Data frame a has:
> > length(unique(a$GENE))
> [1] 51
> > dim(a)
> [1] 287   3
>
> and the whole data frame b is shown
>
> I would like to create a txt file which would have rs match for each
> ENSG from data frame b. If a particular ENSG does not have matching rs
> from data frame b the value under it would be zero. So the txt file
> would have 7 rows (for all those unique rs from data frame b) and 53
> columns (for 51 ENSGs and one for unique rs and one for GWAS)
>
> So one row of that txt file would look like this.
>
> GENES       ENSG00000154803   ENSG00000141030  ENSG00000205309
> ENSG00000215030    ENSG00000141026  GWAS
> rs2605134   0.0360182         0.0806140         0.0838975
> 0.1261050           0.0485897       0.0315177
> ?
>
> Please advise,
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@herry8 @end|ng |rom comc@@t@net  Sun Dec  8 23:06:01 2019
From: r@herry8 @end|ng |rom comc@@t@net (rsherry8)
Date: Sun, 8 Dec 2019 17:06:01 -0500
Subject: [R] Having problems with the ifelse and negative numbers
Message-ID: <5DED73C9.2030002@comcast.net>

Please consider the following two R statements:
     A =  runif(20, min=-1,max=1)
     ifelse( A < 0, sqrt(-A), A )

The second statement produces the following error message:
     rt(-A) : NaNs produced

I understand that you cannot take the square root of a negative number 
but I thought the condition A < 0
would take care of that issue. It appears not to be.

What am I missing?

Thanks,
Bob


From z@d @end|ng |rom |e@@||ke|y@com  Sun Dec  8 05:24:34 2019
From: z@d @end|ng |rom |e@@||ke|y@com (Zad Chow)
Date: Sat, 7 Dec 2019 23:24:34 -0500
Subject: [R] [R-pkgs] concurve v 2.3.0 - Comparing Functions, Bootstrapping,
 and Exporting Tables
Message-ID: <CAD3yMvKA7k7tHBc9v4KCyR_Wmd3sBYMB+=RhnJvCyY=j-p0aGA@mail.gmail.com>

Pleased to announce that the next version (2.3.0) of our package ?concurve?
is out on CRAN (https://cran.r-project.org/package=concurve).

In addition to plotting confidence (consonance) curves, it can now plot two
functions next to one another to see the amount of overlap. It can also
plot likelihood and deviance functions along with consonance densities and
distributions.

And it can utilize bootstrapping (the BCa and t method) to approximate the
curves, distributions, and densities. And to top it off, it can export
tables of relevant statistics in various formats.

We welcome any feedback and bug reports (
https://github.com/zadchow/concurve/issues)

Best,

Zad R. Chow
Andrew D. Vigotsky

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From kev|n@thorpe @end|ng |rom utoronto@c@  Mon Dec  9 14:11:49 2019
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Mon, 9 Dec 2019 13:11:49 +0000
Subject: [R] Having problems with the ifelse and negative numbers
In-Reply-To: <5DED73C9.2030002@comcast.net>
References: <5DED73C9.2030002@comcast.net>
Message-ID: <E27270EE-23BF-4FB7-9022-1F5F0E6FCB33@utoronto.ca>

The sqrt(-A) is evaluated for all A. The result returned is conditional on the first argument but the other two arguments are evaluated on the entire vector.

Kevin

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
 

?On 2019-12-09, 7:58 AM, "R-help on behalf of rsherry8" <r-help-bounces at r-project.org on behalf of rsherry8 at comcast.net> wrote:

    Please consider the following two R statements:
         A =  runif(20, min=-1,max=1)
         ifelse( A < 0, sqrt(-A), A )
    
    The second statement produces the following error message:
         rt(-A) : NaNs produced
    
    I understand that you cannot take the square root of a negative number 
    but I thought the condition A < 0
    would take care of that issue. It appears not to be.
    
    What am I missing?
    
    Thanks,
    Bob
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From er|cjberger @end|ng |rom gm@||@com  Mon Dec  9 14:44:26 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 9 Dec 2019 15:44:26 +0200
Subject: [R] Having problems with the ifelse and negative numbers
In-Reply-To: <E27270EE-23BF-4FB7-9022-1F5F0E6FCB33@utoronto.ca>
References: <5DED73C9.2030002@comcast.net>
 <E27270EE-23BF-4FB7-9022-1F5F0E6FCB33@utoronto.ca>
Message-ID: <CAGgJW754++SDD7dLsFHO6vDa9dY11ZLJCU30KzTx7m_qm+m+Rg@mail.gmail.com>

Hi Bob,
You wrote "the following error message" -
when in fact it is a Warning and not an error message. I think your
code does what you hoped it would do, in the sense it successfully
calculates the sqrt(abs(negativeNumber)), where appropriate.

If you want to run the code without seeing this warning message you can run

ifelse( A < 0, suppressWarnings(sqrt(-A)), A )

and you should be fine.

HTH,
Eric

On Mon, Dec 9, 2019 at 3:18 PM Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>
> The sqrt(-A) is evaluated for all A. The result returned is conditional on the first argument but the other two arguments are evaluated on the entire vector.
>
> Kevin
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
>
> ?On 2019-12-09, 7:58 AM, "R-help on behalf of rsherry8" <r-help-bounces at r-project.org on behalf of rsherry8 at comcast.net> wrote:
>
>     Please consider the following two R statements:
>          A =  runif(20, min=-1,max=1)
>          ifelse( A < 0, sqrt(-A), A )
>
>     The second statement produces the following error message:
>          rt(-A) : NaNs produced
>
>     I understand that you cannot take the square root of a negative number
>     but I thought the condition A < 0
>     would take care of that issue. It appears not to be.
>
>     What am I missing?
>
>     Thanks,
>     Bob
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rc_grt @end|ng |rom y@hoo@|r  Mon Dec  9 16:16:25 2019
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Mon, 9 Dec 2019 16:16:25 +0100
Subject: [R] Where is the SD in output of glm with Gaussian distribution
References: <3cf5da71-b888-8051-9550-a9bd3daefe7e.ref@yahoo.fr>
Message-ID: <3cf5da71-b888-8051-9550-a9bd3daefe7e@yahoo.fr>

Let do a simple glm:

 > y=rnorm(100)
 > gnul <- glm(y ~ 1)
 > gnul$coefficients
(Intercept)
 ? 0.1399966

The logLik shows the fit of two parameters (DF=2) (intercept) and sd

 > logLik(gnul)
'log Lik.' -138.7902 (df=2)

But where is the sd term in the glm object?

If I do the same with optim, I can have its value

 > dnormx <- function(x, data) {1E9*-sum(dnorm(data, mean=x["mean"], 
sd=x["sd"], log = TRUE))}
 > parg <- c(mean=0, sd=1)
 > o0 <- optim(par = parg, fn=dnormx, data=y, method="BFGS")
 > o0$value/1E9
[1] 138.7902
 > o0$par
 ???? mean??????? sd

0.1399966 0.9694405

But I would like have the value in the glm.

(and in the meantime, I don't understand why gnul$df.residual returned 
99... for me it should be 98=100 - number of observations) -1 (for mean) 
- 1 (for sd); but it is statistical question... I have asked it in 
crossvalidated [no answer still] !)

Thanks

Marc


From h@w|ckh@m @end|ng |rom gm@||@com  Mon Dec  9 16:27:36 2019
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Mon, 9 Dec 2019 09:27:36 -0600
Subject: [R] A better scales::dollar() ?
In-Reply-To: <0501040583da4a55b0c37041781824f1@NH-SLPEX171.AD1.NHS.NET>
References: <0501040583da4a55b0c37041781824f1@NH-SLPEX171.AD1.NHS.NET>
Message-ID: <CABdHhvF9R3QcivGXizZd5Vo+RdQ+X7O6iF_DNEL4pas2Y5cm3w@mail.gmail.com>

You can get pretty close with label_number_si():

pounds <- scales::label_number_si(prefix = "?")
pounds(10 ^ (0:7))
#> [1] "?1"    "?10"   "?100"  "?1K"   "?10K"  "?100K" "?1M"   "?10M"

<sup>Created on 2019-12-09 by the [reprex
package](https://reprex.tidyverse.org) (v0.3.0.9001)</sup>

Hadley

On Fri, Dec 6, 2019 at 5:51 AM POLWART, Calum (COUNTY DURHAM AND
DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org>
wrote:
>
> I'm writing a quite large document in Rmarkdown which has financial data in it.  I format that data using scales::dollar() currently something like this:
>
> >
> > require (scales)
> > x = 100000
> > cat (dollar (x, prefix ="?", big.mark=","))
>
> ?100,000
>
> But actually, I'd quite like to get ?100k out in that instance so I'd do:
>
> > cat (dollar (x/10^3, prefix ="?", suffix="k" ))
>
> ?100k
>
> But x could be 100 or 10,000,000.  I want some form of 'automatic' version that might give me something like:
>
> >
> > require (scales)
> > y = 0:7
> > x = 1^y
> > dollar(x, prefix="?")
> [1] "?1"          "?10"         "?100"        "?1,000"      "?10,000"     "?100,000"    "?1,000,000"  "?10,000,000"
>
> But what I want is more like:
>
> ?1.00  ?10.00  ?100  ?1k  ?10k  ?100k  ?1m  ?10m
>
> I'm sure I can write something as a little function, but before I do - is there something already out there?
>
> I have a similar need to format milligrams through to kilograms.
>
>
> ********************************************************************************************************************
>
> This message may contain confidential information. If ...{{dropped:27}}


From j|ox @end|ng |rom mcm@@ter@c@  Mon Dec  9 16:32:29 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 9 Dec 2019 15:32:29 +0000
Subject: [R] Where is the SD in output of glm with Gaussian distribution
In-Reply-To: <2179_1575904616_xB9FGP9O032605_3cf5da71-b888-8051-9550-a9bd3daefe7e@yahoo.fr>
References: <3cf5da71-b888-8051-9550-a9bd3daefe7e.ref@yahoo.fr>
 <2179_1575904616_xB9FGP9O032605_3cf5da71-b888-8051-9550-a9bd3daefe7e@yahoo.fr>
Message-ID: <36B2FD7F-3E7C-4135-BF77-7DC038990E02@mcmaster.ca>

Dear Marc,

For your simple model, the standard deviation of y is the square-root of the estimated dispersion parameter:

> set.seed(123)
> y <- rnorm(100)
> gnul <- glm(y ~ 1)
> summary(gnul)

Call:
glm(formula = y ~ 1)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.39957  -0.58426  -0.02865   0.60141   2.09693  

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.09041    0.09128    0.99    0.324

(Dispersion parameter for gaussian family taken to be 0.8332328)

    Null deviance: 82.49  on 99  degrees of freedom
Residual deviance: 82.49  on 99  degrees of freedom
AIC: 268.54

Number of Fisher Scoring iterations: 2

> sqrt(0.8332328)
[1] 0.9128159
> mean(y)
[1] 0.09040591
> sd(y)
[1] 0.9128159

I hope this helps,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Dec 9, 2019, at 10:16 AM, Marc Girondot via R-help <r-help at r-project.org> wrote:
> 
> Let do a simple glm:
> 
> > y=rnorm(100)
> > gnul <- glm(y ~ 1)
> > gnul$coefficients
> (Intercept)
>   0.1399966
> 
> The logLik shows the fit of two parameters (DF=2) (intercept) and sd
> 
> > logLik(gnul)
> 'log Lik.' -138.7902 (df=2)
> 
> But where is the sd term in the glm object?
> 
> If I do the same with optim, I can have its value
> 
> > dnormx <- function(x, data) {1E9*-sum(dnorm(data, mean=x["mean"], sd=x["sd"], log = TRUE))}
> > parg <- c(mean=0, sd=1)
> > o0 <- optim(par = parg, fn=dnormx, data=y, method="BFGS")
> > o0$value/1E9
> [1] 138.7902
> > o0$par
>      mean        sd
> 
> 0.1399966 0.9694405
> 
> But I would like have the value in the glm.
> 
> (and in the meantime, I don't understand why gnul$df.residual returned 99... for me it should be 98=100 - number of observations) -1 (for mean) - 1 (for sd); but it is statistical question... I have asked it in crossvalidated [no answer still] !)
> 
> Thanks
> 
> Marc
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Mon Dec  9 16:34:20 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 9 Dec 2019 17:34:20 +0200
Subject: [R] Where is the SD in output of glm with Gaussian distribution
In-Reply-To: <3cf5da71-b888-8051-9550-a9bd3daefe7e@yahoo.fr>
References: <3cf5da71-b888-8051-9550-a9bd3daefe7e.ref@yahoo.fr>
 <3cf5da71-b888-8051-9550-a9bd3daefe7e@yahoo.fr>
Message-ID: <CAGgJW74CEerC_SrVwTh6uW6d8wnN_fG-STZ76sHEkLQv2z1UEw@mail.gmail.com>

summary(gnul)

shows the std error of the coefficient estimate

On Mon, Dec 9, 2019 at 5:16 PM Marc Girondot via R-help
<r-help at r-project.org> wrote:
>
> Let do a simple glm:
>
>  > y=rnorm(100)
>  > gnul <- glm(y ~ 1)
>  > gnul$coefficients
> (Intercept)
>    0.1399966
>
> The logLik shows the fit of two parameters (DF=2) (intercept) and sd
>
>  > logLik(gnul)
> 'log Lik.' -138.7902 (df=2)
>
> But where is the sd term in the glm object?
>
> If I do the same with optim, I can have its value
>
>  > dnormx <- function(x, data) {1E9*-sum(dnorm(data, mean=x["mean"],
> sd=x["sd"], log = TRUE))}
>  > parg <- c(mean=0, sd=1)
>  > o0 <- optim(par = parg, fn=dnormx, data=y, method="BFGS")
>  > o0$value/1E9
> [1] 138.7902
>  > o0$par
>       mean        sd
>
> 0.1399966 0.9694405
>
> But I would like have the value in the glm.
>
> (and in the meantime, I don't understand why gnul$df.residual returned
> 99... for me it should be 98=100 - number of observations) -1 (for mean)
> - 1 (for sd); but it is statistical question... I have asked it in
> crossvalidated [no answer still] !)
>
> Thanks
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Dec  9 16:45:36 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Dec 2019 07:45:36 -0800
Subject: [R] Where is the SD in output of glm with Gaussian distribution
In-Reply-To: <3cf5da71-b888-8051-9550-a9bd3daefe7e@yahoo.fr>
References: <3cf5da71-b888-8051-9550-a9bd3daefe7e.ref@yahoo.fr>
 <3cf5da71-b888-8051-9550-a9bd3daefe7e@yahoo.fr>
Message-ID: <CAGxFJbQXgyVyiwgL=P0Hrn_ahxtm5UjEhAkKaOcqe33C3nskPw@mail.gmail.com>

In addition, as John's included output shows, only 1 parameter, the
intercept, is fit. As he also said, the sd is estimated from the residual
deviance -- it is not a model parameter.

Suggest you spend some time with a glm tutorial/text.

Bert

On Mon, Dec 9, 2019 at 7:17 AM Marc Girondot via R-help <
r-help at r-project.org> wrote:

> Let do a simple glm:
>
>  > y=rnorm(100)
>  > gnul <- glm(y ~ 1)
>  > gnul$coefficients
> (Intercept)
>    0.1399966
>
> The logLik shows the fit of two parameters (DF=2) (intercept) and sd
>
>  > logLik(gnul)
> 'log Lik.' -138.7902 (df=2)
>
> But where is the sd term in the glm object?
>
> If I do the same with optim, I can have its value
>
>  > dnormx <- function(x, data) {1E9*-sum(dnorm(data, mean=x["mean"],
> sd=x["sd"], log = TRUE))}
>  > parg <- c(mean=0, sd=1)
>  > o0 <- optim(par = parg, fn=dnormx, data=y, method="BFGS")
>  > o0$value/1E9
> [1] 138.7902
>  > o0$par
>       mean        sd
>
> 0.1399966 0.9694405
>
> But I would like have the value in the glm.
>
> (and in the meantime, I don't understand why gnul$df.residual returned
> 99... for me it should be 98=100 - number of observations) -1 (for mean)
> - 1 (for sd); but it is statistical question... I have asked it in
> crossvalidated [no answer still] !)
>
> Thanks
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_grt @end|ng |rom y@hoo@|r  Mon Dec  9 17:25:40 2019
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Mon, 9 Dec 2019 17:25:40 +0100
Subject: [R] Where is the SD in output of glm with Gaussian distribution
In-Reply-To: <CAGxFJbQXgyVyiwgL=P0Hrn_ahxtm5UjEhAkKaOcqe33C3nskPw@mail.gmail.com>
References: <3cf5da71-b888-8051-9550-a9bd3daefe7e.ref@yahoo.fr>
 <3cf5da71-b888-8051-9550-a9bd3daefe7e@yahoo.fr>
 <CAGxFJbQXgyVyiwgL=P0Hrn_ahxtm5UjEhAkKaOcqe33C3nskPw@mail.gmail.com>
Message-ID: <2e888ac8-32b4-34a3-0f1b-38afc85319ae@yahoo.fr>

Le 09/12/2019 ? 16:45, Bert Gunter a ?crit?:
> In addition, as John's included output shows, only 1 parameter, the 
> intercept, is fit. As he also said, the sd is estimated from the 
> residual deviance -- it is not a model parameter.
>
> Suggest you spend some time with a glm tutorial/text.

I tried ! But I miss this point. I understand now this point. Thanks a? 
lot... big progress for me.

But still I don't understand why AIC calculation uses 2 parameters if 
the SD is estimated from the residual deviance.

 > y=rnorm(100)
 > gnul <- glm(y ~ 1)
 > logLik(gnul)
'log Lik.' -136.4343 (df=2)
 > AIC(gnul)
[1] 276.8687
 > -2*logLik(gnul)+2*2
'log Lik.' 276.8687 (df=2)

This is not intuitive when to count SD as a parameter (in AIC) or not in 
df.resuidual !


>
> Bert
>
> On Mon, Dec 9, 2019 at 7:17 AM Marc Girondot via R-help 
> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>
>     Let do a simple glm:
>
>     ?> y=rnorm(100)
>     ?> gnul <- glm(y ~ 1)
>     ?> gnul$coefficients
>     (Intercept)
>     ?? 0.1399966
>
>     The logLik shows the fit of two parameters (DF=2) (intercept) and sd
>
>     ?> logLik(gnul)
>     'log Lik.' -138.7902 (df=2)
>
>     But where is the sd term in the glm object?
>
>     If I do the same with optim, I can have its value
>
>     ?> dnormx <- function(x, data) {1E9*-sum(dnorm(data, mean=x["mean"],
>     sd=x["sd"], log = TRUE))}
>     ?> parg <- c(mean=0, sd=1)
>     ?> o0 <- optim(par = parg, fn=dnormx, data=y, method="BFGS")
>     ?> o0$value/1E9
>     [1] 138.7902
>     ?> o0$par
>     ????? mean??????? sd
>
>     0.1399966 0.9694405
>
>     But I would like have the value in the glm.
>
>     (and in the meantime, I don't understand why gnul$df.residual
>     returned
>     99... for me it should be 98=100 - number of observations) -1 (for
>     mean)
>     - 1 (for sd); but it is statistical question... I have asked it in
>     crossvalidated [no answer still] !)
>
>     Thanks
>
>     Marc
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From m@rc_grt @end|ng |rom y@hoo@|r  Mon Dec  9 17:25:40 2019
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Mon, 9 Dec 2019 17:25:40 +0100
Subject: [R] Where is the SD in output of glm with Gaussian distribution
In-Reply-To: <CAGxFJbQXgyVyiwgL=P0Hrn_ahxtm5UjEhAkKaOcqe33C3nskPw@mail.gmail.com>
References: <3cf5da71-b888-8051-9550-a9bd3daefe7e.ref@yahoo.fr>
 <3cf5da71-b888-8051-9550-a9bd3daefe7e@yahoo.fr>
 <CAGxFJbQXgyVyiwgL=P0Hrn_ahxtm5UjEhAkKaOcqe33C3nskPw@mail.gmail.com>
Message-ID: <2e888ac8-32b4-34a3-0f1b-38afc85319ae@yahoo.fr>

Le 09/12/2019 ? 16:45, Bert Gunter a ?crit?:
> In addition, as John's included output shows, only 1 parameter, the 
> intercept, is fit. As he also said, the sd is estimated from the 
> residual deviance -- it is not a model parameter.
>
> Suggest you spend some time with a glm tutorial/text.

I tried ! But I miss this point. I understand now this point. Thanks a? 
lot... big progress for me.

But still I don't understand why AIC calculation uses 2 parameters if 
the SD is estimated from the residual deviance.

 > y=rnorm(100)
 > gnul <- glm(y ~ 1)
 > logLik(gnul)
'log Lik.' -136.4343 (df=2)
 > AIC(gnul)
[1] 276.8687
 > -2*logLik(gnul)+2*2
'log Lik.' 276.8687 (df=2)

This is not intuitive when to count SD as a parameter (in AIC) or not in 
df.resuidual !


>
> Bert
>
> On Mon, Dec 9, 2019 at 7:17 AM Marc Girondot via R-help 
> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>
>     Let do a simple glm:
>
>     ?> y=rnorm(100)
>     ?> gnul <- glm(y ~ 1)
>     ?> gnul$coefficients
>     (Intercept)
>     ?? 0.1399966
>
>     The logLik shows the fit of two parameters (DF=2) (intercept) and sd
>
>     ?> logLik(gnul)
>     'log Lik.' -138.7902 (df=2)
>
>     But where is the sd term in the glm object?
>
>     If I do the same with optim, I can have its value
>
>     ?> dnormx <- function(x, data) {1E9*-sum(dnorm(data, mean=x["mean"],
>     sd=x["sd"], log = TRUE))}
>     ?> parg <- c(mean=0, sd=1)
>     ?> o0 <- optim(par = parg, fn=dnormx, data=y, method="BFGS")
>     ?> o0$value/1E9
>     [1] 138.7902
>     ?> o0$par
>     ????? mean??????? sd
>
>     0.1399966 0.9694405
>
>     But I would like have the value in the glm.
>
>     (and in the meantime, I don't understand why gnul$df.residual
>     returned
>     99... for me it should be 98=100 - number of observations) -1 (for
>     mean)
>     - 1 (for sd); but it is statistical question... I have asked it in
>     crossvalidated [no answer still] !)
>
>     Thanks
>
>     Marc
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Dec  9 17:38:04 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 9 Dec 2019 10:38:04 -0600
Subject: [R] how to create a txt file with parsed columns
In-Reply-To: <CA+8X3fW9x_F3MuS6NBMJynzXVnJrtR9XJTkwYowFE57G=qGT_g@mail.gmail.com>
References: <CAF9-5jMOAL76PJ91by1XQuG8nuSwciVS_0H92MtY=FA39Fk-oQ@mail.gmail.com>
 <CA+8X3fW9x_F3MuS6NBMJynzXVnJrtR9XJTkwYowFE57G=qGT_g@mail.gmail.com>
Message-ID: <CAF9-5jNQaYZyy0Gmb29phsNd3GumMeVVuz4FCPXpBQ6FSNVWNA@mail.gmail.com>

Thanks for getting back to me, I resolved my problem with this:

library(reshape2)
c=dcast(a, rs ~ GENE)
d=merge(c,b,by="rs")
d[is.na(d)] <- 0

On Sun, Dec 8, 2019 at 11:03 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> Is this what you want?
>
> a<-read.table(text="GENE        rs       BETA
> 1  ENSG00000154803 rs2605134  0.0360182
> 2  ENSG00000154803 rs7405677  0.0525463
> 3  ENSG00000154803 rs7211573  0.0525531
> 4  ENSG00000154803 rs2746026  0.0466392
> 5  ENSG00000141030 rs2605134  0.0806140
> 6  ENSG00000141030 rs7405677  0.0251654
> 7  ENSG00000141030 rs7211573  0.0252775
> 8  ENSG00000141030 rs2746026  0.0976396
> 9  ENSG00000205309 rs2605134  0.0838975
> 10 ENSG00000205309 rs7405677 -0.2148500
> 11 ENSG00000205309 rs7211573 -0.2148170
> 12 ENSG00000205309 rs2746026  0.1013920
> 13 ENSG00000215030 rs2605134  0.1261050
> 14 ENSG00000215030 rs7405677  0.0165236
> 15 ENSG00000215030 rs7211573  0.0163509
> 16 ENSG00000215030 rs2746026  0.1201180
> 17 ENSG00000141026 rs2605134  0.0485897
> 18 ENSG00000141026 rs7405677 -0.0929964
> 19 ENSG00000141026 rs7211573 -0.0930321
> 20 ENSG00000141026 rs2746026  0.0623033",
> header=TRUE,stringsAsFactors=FALSE)
> b<-read.table(text="rs       GWAS
> 1  rs2605134  0.0315177
> 2  rs7405677 -0.0816389
> 3  rs7211573 -0.0797796
> 4  rs2746026  0.0199350
> 5 rs11658521  0.0728377
> 6  rs9914107  0.0720096
> 7 rs56964223  0.0723903",
> header=TRUE,stringsAsFactors=FALSE)
> ab<-merge(a,b,by="rs")
> library(prettyR)
> abc<-stretch_df(ab,idvar="rs",to.stretch=c("GENE","BETA"))
>
> Jiim
>
> On Mon, Dec 9, 2019 at 11:10 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I have two data frames:
> >
> > head(a)
> >               GENE        rs       BETA
> > 1  ENSG00000154803 rs2605134  0.0360182
> > 2  ENSG00000154803 rs7405677  0.0525463
> > 3  ENSG00000154803 rs7211573  0.0525531
> > 4  ENSG00000154803 rs2746026  0.0466392
> > 5  ENSG00000141030 rs2605134  0.0806140
> > 6  ENSG00000141030 rs7405677  0.0251654
> > 7  ENSG00000141030 rs7211573  0.0252775
> > 8  ENSG00000141030 rs2746026  0.0976396
> > 9  ENSG00000205309 rs2605134  0.0838975
> > 10 ENSG00000205309 rs7405677 -0.2148500
> > 11 ENSG00000205309 rs7211573 -0.2148170
> > 12 ENSG00000205309 rs2746026  0.1013920
> > 13 ENSG00000215030 rs2605134  0.1261050
> > 14 ENSG00000215030 rs7405677  0.0165236
> > 15 ENSG00000215030 rs7211573  0.0163509
> > 16 ENSG00000215030 rs2746026  0.1201180
> > 17 ENSG00000141026 rs2605134  0.0485897
> > 18 ENSG00000141026 rs7405677 -0.0929964
> > 19 ENSG00000141026 rs7211573 -0.0930321
> > 20 ENSG00000141026 rs2746026  0.0623033
> >
> > head(b)
> >           rs       GWAS
> > 1  rs2605134  0.0315177
> > 2  rs7405677 -0.0816389
> > 3  rs7211573 -0.0797796
> > 4  rs2746026  0.0199350
> > 5 rs11658521  0.0728377
> > 6  rs9914107  0.0720096
> > 7 rs56964223  0.0723903
> >
> > Data frame a has:
> > > length(unique(a$GENE))
> > [1] 51
> > > dim(a)
> > [1] 287   3
> >
> > and the whole data frame b is shown
> >
> > I would like to create a txt file which would have rs match for each
> > ENSG from data frame b. If a particular ENSG does not have matching rs
> > from data frame b the value under it would be zero. So the txt file
> > would have 7 rows (for all those unique rs from data frame b) and 53
> > columns (for 51 ENSGs and one for unique rs and one for GWAS)
> >
> > So one row of that txt file would look like this.
> >
> > GENES       ENSG00000154803   ENSG00000141030  ENSG00000205309
> > ENSG00000215030    ENSG00000141026  GWAS
> > rs2605134   0.0360182         0.0806140         0.0838975
> > 0.1261050           0.0485897       0.0315177
> > ?
> >
> > Please advise,
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Mon Dec  9 17:52:48 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 9 Dec 2019 16:52:48 +0000
Subject: [R] Where is the SD in output of glm with Gaussian distribution
In-Reply-To: <2183_1575906646_xB9FoFuo003273_CAGxFJbQXgyVyiwgL=P0Hrn_ahxtm5UjEhAkKaOcqe33C3nskPw@mail.gmail.com>
References: <3cf5da71-b888-8051-9550-a9bd3daefe7e.ref@yahoo.fr>
 <3cf5da71-b888-8051-9550-a9bd3daefe7e@yahoo.fr>
 <2183_1575906646_xB9FoFuo003273_CAGxFJbQXgyVyiwgL=P0Hrn_ahxtm5UjEhAkKaOcqe33C3nskPw@mail.gmail.com>
Message-ID: <2ED4AA82-E230-4A20-A95B-6EDA4361BADF@mcmaster.ca>

Dear Bert,

It's perhaps a bit pedantic to point it out, but the dispersion is estimated from the Pearson statistic (sum of squared residuals or weighted squared residuals) not from the residual deviance. You can see this in the code for summary.glm().

Best,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Dec 9, 2019, at 10:45 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> In addition, as John's included output shows, only 1 parameter, the
> intercept, is fit. As he also said, the sd is estimated from the residual
> deviance -- it is not a model parameter.
> 
> Suggest you spend some time with a glm tutorial/text.
> 
> Bert
> 
> On Mon, Dec 9, 2019 at 7:17 AM Marc Girondot via R-help <
> r-help at r-project.org> wrote:
> 
>> Let do a simple glm:
>> 
>>> y=rnorm(100)
>>> gnul <- glm(y ~ 1)
>>> gnul$coefficients
>> (Intercept)
>>   0.1399966
>> 
>> The logLik shows the fit of two parameters (DF=2) (intercept) and sd
>> 
>>> logLik(gnul)
>> 'log Lik.' -138.7902 (df=2)
>> 
>> But where is the sd term in the glm object?
>> 
>> If I do the same with optim, I can have its value
>> 
>>> dnormx <- function(x, data) {1E9*-sum(dnorm(data, mean=x["mean"],
>> sd=x["sd"], log = TRUE))}
>>> parg <- c(mean=0, sd=1)
>>> o0 <- optim(par = parg, fn=dnormx, data=y, method="BFGS")
>>> o0$value/1E9
>> [1] 138.7902
>>> o0$par
>>      mean        sd
>> 
>> 0.1399966 0.9694405
>> 
>> But I would like have the value in the glm.
>> 
>> (and in the meantime, I don't understand why gnul$df.residual returned
>> 99... for me it should be 98=100 - number of observations) -1 (for mean)
>> - 1 (for sd); but it is statistical question... I have asked it in
>> crossvalidated [no answer still] !)
>> 
>> Thanks
>> 
>> Marc
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Mon Dec  9 19:25:54 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Mon, 9 Dec 2019 13:25:54 -0500
Subject: [R] Having problems with the ifelse and negative numbers
In-Reply-To: <CAGgJW754++SDD7dLsFHO6vDa9dY11ZLJCU30KzTx7m_qm+m+Rg@mail.gmail.com>
References: <5DED73C9.2030002@comcast.net>
 <E27270EE-23BF-4FB7-9022-1F5F0E6FCB33@utoronto.ca>
 <CAGgJW754++SDD7dLsFHO6vDa9dY11ZLJCU30KzTx7m_qm+m+Rg@mail.gmail.com>
Message-ID: <CAGx1TMCUGV4KjjK4DDKkNBxZwjeQzmWAWSUS6DhxPbQYNJ0tcA@mail.gmail.com>

or even simpler
sqrt(abs(A))

On Mon, Dec 9, 2019 at 8:45 AM Eric Berger <ericjberger at gmail.com> wrote:
>
> Hi Bob,
> You wrote "the following error message" -
> when in fact it is a Warning and not an error message. I think your
> code does what you hoped it would do, in the sense it successfully
> calculates the sqrt(abs(negativeNumber)), where appropriate.
>
> If you want to run the code without seeing this warning message you can run
>
> ifelse( A < 0, suppressWarnings(sqrt(-A)), A )
>
> and you should be fine.
>
> HTH,
> Eric
>
> On Mon, Dec 9, 2019 at 3:18 PM Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
> >
> > The sqrt(-A) is evaluated for all A. The result returned is conditional on the first argument but the other two arguments are evaluated on the entire vector.
> >
> > Kevin
> >
> > --
> > Kevin E. Thorpe
> > Head of Biostatistics,  Applied Health Research Centre (AHRC)
> > Li Ka Shing Knowledge Institute of St. Michael's
> > Assistant Professor, Dalla Lana School of Public Health
> > University of Toronto
> > email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> >
> >
> > ?On 2019-12-09, 7:58 AM, "R-help on behalf of rsherry8" <r-help-bounces at r-project.org on behalf of rsherry8 at comcast.net> wrote:
> >
> >     Please consider the following two R statements:
> >          A =  runif(20, min=-1,max=1)
> >          ifelse( A < 0, sqrt(-A), A )
> >
> >     The second statement produces the following error message:
> >          rt(-A) : NaNs produced
> >
> >     I understand that you cannot take the square root of a negative number
> >     but I thought the condition A < 0
> >     would take care of that issue. It appears not to be.
> >
> >     What am I missing?
> >
> >     Thanks,
> >     Bob
> >
> >     ______________________________________________
> >     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dom|n|k@@chne|der @end|ng |rom w@u@edu  Mon Dec  9 19:03:17 2019
From: dom|n|k@@chne|der @end|ng |rom w@u@edu (Schneider, Dominik)
Date: Mon, 9 Dec 2019 18:03:17 +0000
Subject: [R] install package av on centos 7
Message-ID: <BL0PR01MB4148A9B26480C013CF68FD7EF5580@BL0PR01MB4148.prod.exchangelabs.com>

I tried to install the av package on centos7 server with R 3.5.3 but am receiving an error. I installed ffmpeg and ffmpeg-devel on centos 7 as below and then followed the instructions of specifying LIB_DIR and INCLUDE_DIR for installing av.

any help would be appreciated. Thanks


```
> install.packages('av', configure.vars = c("LIB_DIR=/usr/lib64","INCLUDE_DIR=/usr/include/ffmpeg"))
Installing package into '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5'
(as 'lib' is unspecified)
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0 100  720k  100  720k    0     0   987k      0 --:--:-- --:--:-- --:--:--  987k
No protocol specified
* installing *source* package 'av' ...
** package 'av' successfully unpacked and MD5 sums checked
Found INCLUDE_DIR and/or LIB_DIR!
Using PKG_CFLAGS=-I/usr/include/ffmpeg
Using PKG_LIBS=-L/usr/lib64 -lavfilter
** libs
rm -f av.so formats.o info.o init.o util.o video.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c formats.c -o formats.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c info.c -o info.o
info.c: In function 'get_video_info':
info.c:33:14: error: 'AVStream' has no member named 'codecpar'
     if(stream->codecpar->codec_type != AVMEDIA_TYPE_VIDEO)
              ^
info.c:35:49: error: 'AVStream' has no member named 'codecpar'
     AVCodec *codec = avcodec_find_decoder(stream->codecpar->codec_id);
                                                 ^
info.c:40:55: error: 'AVStream' has no member named 'codecpar'
     SET_VECTOR_ELT(streamdata, 0, Rf_ScalarReal(stream->codecpar->width));
                                                       ^
info.c:41:55: error: 'AVStream' has no member named 'codecpar'
     SET_VECTOR_ELT(streamdata, 1, Rf_ScalarReal(stream->codecpar->height));
                                                       ^
info.c:45:94: error: 'AVStream' has no member named 'codecpar'
     SET_VECTOR_ELT(streamdata, 5, safe_string(av_get_pix_fmt_name((enum AVPixelFormat) stream->codecpar->format)));
                                                                                              ^
info.c: In function 'get_audio_info':
info.c:64:14: error: 'AVStream' has no member named 'codecpar'
     if(stream->codecpar->codec_type != AVMEDIA_TYPE_AUDIO)
              ^
info.c:66:49: error: 'AVStream' has no member named 'codecpar'
     AVCodec *codec = avcodec_find_decoder(stream->codecpar->codec_id);
                                                 ^
info.c:70:55: error: 'AVStream' has no member named 'codecpar'
     SET_VECTOR_ELT(streamdata, 0, Rf_ScalarReal(stream->codecpar->channels));
                                                       ^
info.c:71:55: error: 'AVStream' has no member named 'codecpar'
     SET_VECTOR_ELT(streamdata, 1, Rf_ScalarReal(stream->codecpar->sample_rate));
                                                       ^
info.c:74:55: error: 'AVStream' has no member named 'codecpar'
     SET_VECTOR_ELT(streamdata, 4, Rf_ScalarReal(stream->codecpar->bit_rate));
                                                       ^
info.c:77:54: error: 'AVStream' has no member named 'codecpar'
     av_get_channel_layout_string(layout, 1024, stream->codecpar->channels, stream->codecpar->channel_layout);
                                                      ^
info.c:77:82: error: 'AVStream' has no member named 'codecpar'
     av_get_channel_layout_string(layout, 1024, stream->codecpar->channels, stream->codecpar->channel_layout);
                                                                                  ^
make: *** [info.o] Error 1
ERROR: compilation failed for package 'av'
* removing '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av'
Warning in install.packages :
  installation of package 'av' had non-zero exit status

The downloaded source packages are in
              '/tmp/RtmpMDafXK/downloaded_packages'
```

ffmpeg was installed successfully:

```
sudo rpm --import http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro
sudo rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm
Retrieving http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm
Preparing...                          ################################# [100%]
Updating / installing...
   1:nux-dextop-release-0-5.el7.nux   ################################# [100%]
sudo yum install ffmpeg ffmpeg-devel -y
```

Result:

```
(base) [dominik at cppc-server ffmpeg]$ ffmpeg
ffmpeg version 2.8.15 Copyright (c) 2000-2018 the FFmpeg developers
  built with gcc 4.8.5 (GCC) 20150623 (Red Hat 4.8.5-36)
  configuration: --prefix=/usr --bindir=/usr/bin --datadir=/usr/share/ffmpeg --incdir=/usr/include/ffmpeg --libdir=/usr/lib64 --mandir=/usr/share/man --arch=x86_64 --optflags='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic' --extra-ldflags='-Wl,-z,relro ' --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libvo-amrwbenc --enable-version3 --enable-bzlib --disable-crystalhd --enable-gnutls --enable-ladspa --enable-libass --enable-libcdio --enable-libdc1394 --enable-libfdk-aac --enable-nonfree --disable-indev=jack --enable-libfreetype --enable-libgsm --enable-libmp3lame --enable-openal --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-libschroedinger --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libvorbis --enable-libv4l2 --enable-libx264 --enable-libx265 --enable-libxvid --enable-x11grab --enable-avfilter --enable-avresample --enable-postproc --enable-pthreads --disable-static --enable-shared --enable-gpl --disable-debug --disable-stripping --shlibdir=/usr/lib64 --enable-runtime-cpudetect
  libavutil      54. 31.100 / 54. 31.100
  libavcodec     56. 60.100 / 56. 60.100
  libavformat    56. 40.101 / 56. 40.101
  libavdevice    56.  4.100 / 56.  4.100
  libavfilter     5. 40.101 /  5. 40.101
  libavresample   2.  1.  0 /  2.  1.  0
  libswscale      3.  1.101 /  3.  1.101
  libswresample   1.  2.101 /  1.  2.101
  libpostproc    53.  3.100 / 53.  3.100
Hyper fast Audio and Video encoder
usage: ffmpeg [options] [[infile options] -i infile]... {[outfile options] outfile}...

Use -h to get full help or, even better, run 'man ffmpeg'
(base) [dominik at cppc-server ffmpeg]$
```

	[[alternative HTML version deleted]]


From m@rc_grt @end|ng |rom y@hoo@|r  Tue Dec 10 10:27:59 2019
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Tue, 10 Dec 2019 10:27:59 +0100
Subject: [R] Having problems with the ifelse and negative numbers
In-Reply-To: <CAGx1TMCUGV4KjjK4DDKkNBxZwjeQzmWAWSUS6DhxPbQYNJ0tcA@mail.gmail.com>
References: <5DED73C9.2030002@comcast.net>
 <E27270EE-23BF-4FB7-9022-1F5F0E6FCB33@utoronto.ca>
 <CAGgJW754++SDD7dLsFHO6vDa9dY11ZLJCU30KzTx7m_qm+m+Rg@mail.gmail.com>
 <CAGx1TMCUGV4KjjK4DDKkNBxZwjeQzmWAWSUS6DhxPbQYNJ0tcA@mail.gmail.com>
Message-ID: <b7d9d3b6-9f0a-e0ff-de97-8be5cae29480@yahoo.fr>

Here is a test of the different proposed solutions and a new one faster. 
In conclusion, ifelse much be used with caution:

Aini =? runif(1000000, min=-1,max=1)
library(microbenchmark)
A <- Aini
microbenchmark({B1 <- ifelse( A < 0, sqrt(-A), A )})
# mean = 77.55551
A <- Aini
microbenchmark({B2 <- ifelse( A < 0, suppressWarnings(sqrt(-A)), A )})
# mean = 76.53762
A <- Aini
microbenchmark({B3 <- ifelse( A < 0, sqrt(abs(A)), A )})
# mean = 75.26712
A <- Aini
microbenchmark({A[A < 0] <- sqrt(-A[A < 0]);B4 <- A})
# mean = 17.71883

Marc

Le 09/12/2019 ? 19:25, Richard M. Heiberger a ?crit?:
> or even simpler
> sqrt(abs(A))
>
> On Mon, Dec 9, 2019 at 8:45 AM Eric Berger <ericjberger at gmail.com> wrote:
>> Hi Bob,
>> You wrote "the following error message" -
>> when in fact it is a Warning and not an error message. I think your
>> code does what you hoped it would do, in the sense it successfully
>> calculates the sqrt(abs(negativeNumber)), where appropriate.
>>
>> If you want to run the code without seeing this warning message you can run
>>
>> ifelse( A < 0, suppressWarnings(sqrt(-A)), A )
>>
>> and you should be fine.
>>
>> HTH,
>> Eric
>>
>> On Mon, Dec 9, 2019 at 3:18 PM Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>>> The sqrt(-A) is evaluated for all A. The result returned is conditional on the first argument but the other two arguments are evaluated on the entire vector.
>>>
>>> Kevin
>>>
>>> --
>>> Kevin E. Thorpe
>>> Head of Biostatistics,  Applied Health Research Centre (AHRC)
>>> Li Ka Shing Knowledge Institute of St. Michael's
>>> Assistant Professor, Dalla Lana School of Public Health
>>> University of Toronto
>>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>>>
>>>
>>> ?On 2019-12-09, 7:58 AM, "R-help on behalf of rsherry8" <r-help-bounces at r-project.org on behalf of rsherry8 at comcast.net> wrote:
>>>
>>>      Please consider the following two R statements:
>>>           A =  runif(20, min=-1,max=1)
>>>           ifelse( A < 0, sqrt(-A), A )
>>>
>>>      The second statement produces the following error message:
>>>           rt(-A) : NaNs produced
>>>
>>>      I understand that you cannot take the square root of a negative number
>>>      but I thought the condition A < 0
>>>      would take care of that issue. It appears not to be.
>>>
>>>      What am I missing?
>>>
>>>      Thanks,
>>>      Bob
>>>
>>>      ______________________________________________
>>>      R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>      https://stat.ethz.ch/mailman/listinfo/r-help
>>>      PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>      and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @|@|n@gu|||et @end|ng |rom uc|ouv@|n@be  Tue Dec 10 09:53:29 2019
From: @|@|n@gu|||et @end|ng |rom uc|ouv@|n@be (Alain Guillet)
Date: Tue, 10 Dec 2019 08:53:29 +0000
Subject: [R] table and unique seems to behave differently
Message-ID: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>

Hi,

I have a vector (see below the dput) and I use unique on it to get unique values. If I then sort the result of the vector obtained by unique, I see some elements that look like identical. I suspect it could be a matter of rounded values but table gives a different result: unlike unique output which contains "3.4  3.4", table has only one cell for 3.4.

Can anybody know why I get results that look like incoherent between the two functions?


Best regards,
Alain Guillet

------------------------------------------
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          6.1
year           2019
month          07
day            05
svn rev        76782
language       R
version.string R version 3.6.1 (2019-07-05)
nickname       Action of the Toes
--------------------------------------------------
> dput(toto)
c(2.5, 2.6, 2.6, 2.6, 2.6, 2.7, 2.7, 2.7, 2.7, 2.7, 2.7, 2.8,
2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.9, 2.9, 2.9, 2.9, 2.9,
2.9, 2.9, 2.9, 3, 3, 3, 3, 3, 3, 3, 3, 3.1, 3.1, 3.1, 3.1, 3.1,
3.1, 3.1, 3.1, 3.1, 3.1, 3.1, 3.1, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2,
3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3,
3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4,
3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.5,
3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6, 3.6,
3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6,
3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7,
3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7,
3.7, 3.7, 3.7, 3.7, 3.7, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8,
3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8,
3.8, 3.8, 3.8, 3.8, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9,
3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9,
3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 4, 4, 4, 4, 4, 4, 4, 4, 4,
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
4, 4, 4, 4, 4, 4, 4, 4, 4, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
4.1, 4.1, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2,
4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2,
4.2, 4.2, 4.2, 4.2, 4.2, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3,
4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3,
4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.4, 4.4, 4.4, 4.4,
4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4,
4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4,
4.4, 4.4, 4.4, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.6,
4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
4.6, 4.6, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.8, 4.8, 4.8, 4.8, 4.8,
4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8,
4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8,
4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.9, 4.9, 4.9, 4.9, 4.9,
4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5.1, 5.1, 5.1,
5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2,
5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2,
5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.3, 5.3, 5.3, 5.3, 5.3,
5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
5.3, 5.3, 5.3, 5.3, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
5.5, 5.5, 5.5, 5.5, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.7, 5.7, 5.7, 5.7, 5.7,
5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7,
5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7,
5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.8, 5.8, 5.8, 5.8,
5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
5.8, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
5.9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6.1,
6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1,
6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1,
6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.2,
6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
6.2, 6.2, 6.2, 6.2, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
6.3, 6.3, 6.3, 6.3, 6.3, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.5, 6.5,
6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5,
6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5,
6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.6, 6.6, 6.6, 6.6,
6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6,
6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6,
6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.7, 6.7, 6.7, 6.7,
6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7,
6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7,
6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.8, 6.8, 6.8,
6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
6.8, 6.8, 6.8, 6.8, 6.8, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
6.9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7.1, 7.1, 7.1, 7.1,
7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1,
7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1,
7.1, 7.1, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2,
7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2,
7.2, 7.2, 7.2, 7.2, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3,
7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3,
7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.4, 7.4,
7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4,
7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.5, 7.5, 7.5, 7.5,
7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5,
7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.6,
7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6,
7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6,
7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7,
7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.8, 7.8, 7.8,
7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8,
7.8, 7.8, 7.8, 7.8, 7.8, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9,
7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9,
7.9, 7.9, 7.9, 7.9, 7.9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 8, 8, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1,
8.1, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2,
8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.3, 8.3, 8.3, 8.3,
8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.4, 8.4, 8.4, 8.4,
8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.5, 8.5,
8.5, 8.5, 8.5, 8.5, 8.5, 8.5, 8.6, 8.6, 8.6, 8.6, 8.6, 8.6, 8.6,
8.6, 8.6, 8.6, 8.6, 8.6, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7,
8.7, 8.7, 8.7, 8.7, 8.7, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8,
8.8, 8.8, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9,
8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 9, 9, 9, 9, 9, 9, 9, 9, 9.1, 9.1,
9.1, 9.1, 9.1, 9.1, 9.1, 9.1, 9.2, 9.2, 9.2, 9.2, 9.2, 9.2, 9.2,
9.2, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3,
9.3, 9.3, 9.3, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.5, 9.5,
9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5,
9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.6, 9.6, 9.6, 9.6, 9.6, 9.6, 9.6,
9.6, 9.6, 9.6, 9.6, 9.6, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7,
9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.8,
9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9,
9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 10, 10, 10,
10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10.1,
10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1,
10.1, 10.1, 10.1, 10.1, 10.1, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2,
10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.3,
10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3,
10.3, 10.3, 10.3, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4,
10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4,
10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5,
10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.6, 10.6, 10.6, 10.6, 10.6,
10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6,
10.6, 10.6, 10.6, 10.6, 10.6, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
10.7, 10.7, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8,
10.8, 10.8, 10.8, 10.8, 10.8, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9,
10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9,
10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 11, 11, 11, 11, 11,
11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,
11, 11, 11, 11, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1,
11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1,
11.1, 11.1, 11.1, 11.1, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
11.2, 11.2, 11.2, 11.2, 11.2, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
11.3, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
11.4, 11.4, 11.4, 11.4, 11.4, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
11.5, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.8, 11.8,
11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.9, 11.9,
11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
11.9, 11.9, 11.9, 11.9, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
12, 12, 12, 12, 12, 12, 12, 12, 12.1, 12.1, 12.1, 12.1, 12.1,
12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.2,
12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.3, 12.3, 12.3,
12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.4, 12.4, 12.4, 12.4, 12.4,
12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.6, 12.6, 12.6, 12.6, 12.6,
12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
12.6, 12.6, 12.6, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
12.7, 12.7, 12.7, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
12.8, 12.8, 12.8, 12.8, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
12.9, 12.9, 12.9, 12.9, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
13, 13, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
13.1, 13.1, 13.1, 13.1, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.3, 13.3, 13.3, 13.3, 13.3,
13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.4,
13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.5, 13.5, 13.5, 13.5, 13.5,
13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
13.5, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
13.6, 13.6, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
13.7, 13.7, 13.7, 13.7, 13.7, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.9, 13.9, 13.9, 13.9,
13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
13.9, 13.9, 13.9, 13.9, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
14, 14, 14, 14, 14, 14, 14, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.2, 14.2, 14.2,
14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
14.2, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
14.3, 14.3, 14.3, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
14.4, 14.4, 14.4, 14.4, 14.4, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
14.5, 14.5, 14.5, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.7, 14.7,
14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
14.7, 14.7, 14.7, 14.7, 14.7, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
14.8, 14.8, 14.8, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
14.9, 14.9, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15.1,
15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
15.1, 15.1, 15.1, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
15.3, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4,
15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4,
15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.5,
15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.6, 15.6,
15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6,
15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6,
15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.7, 15.7, 15.7,
15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
15.7, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8,
15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8,
15.8, 15.8, 15.8, 15.8, 15.8, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9,
15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9,
15.9, 15.9, 15.9, 15.9, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
16, 16, 16, 16, 16, 16, 16, 16, 16, 16.1, 16.1, 16.1, 16.1, 16.1,
16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1,
16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.2,
16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2,
16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.3, 16.3,
16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3,
16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.4,
16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4,
16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4,
16.4, 16.4, 16.4, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5,
16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.6, 16.6,
16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6,
16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.7, 16.7, 16.7, 16.7,
16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7,
16.7, 16.7, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8,
16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.9, 16.9, 16.9,
16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9,
16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 17, 17,
17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,
17, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.2,
17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2,
17.2, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3,
17.3, 17.3, 17.3, 17.4, 17.4, 17.4, 17.4, 17.4, 17.4, 17.4, 17.5,
17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5,
17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.7, 17.7, 17.7,
17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.8, 17.8, 17.8, 17.8,
17.8, 17.8, 17.8, 17.8, 17.8, 17.9, 17.9, 17.9, 17.9, 17.9, 17.9,
17.9, 17.9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,
18, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.2, 18.2,
18.2, 18.2, 18.2, 18.2, 18.2, 18.2, 18.2, 18.3, 18.3, 18.3, 18.3,
18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.4, 18.4, 18.4,
18.4, 18.4, 18.4, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5,
18.5, 18.6, 18.7, 18.7, 18.7, 18.7, 18.8, 18.8, 18.8, 18.8, 18.8,
18.8, 18.8, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9,
18.9, 19, 19, 19, 19, 19, 19.1, 19.1, 19.1, 19.1, 19.1, 19.1,
19.1, 19.2, 19.2, 19.2, 19.2, 19.2, 19.2, 19.3, 19.3, 19.3, 19.3,
19.4, 19.4, 19.4, 19.4, 19.4, 19.5, 19.5, 19.5, 19.5, 19.6, 19.7,
19.7, 19.7, 19.7, 19.7, 19.7, 19.7, 19.8, 19.8, 19.8, 19.8, 19.8,
20.1, 20.1, 20.1, 20.1, 20.1, 20.2, 20.2, 20.3, 20.4, 20.5, 20.5,
20.5, 20.6, 20.6, 20.6, 20.6, 20.7, 20.7, 20.7, 20.8, 20.8, 20.9,
20.9, 20.9, 20.9, 21, 21.1, 21.2, 21.2, 21.2, 21.3, 21.3, 21.3,
21.4, 21.5, 21.5, 21.5, 21.6, 21.6, 21.6, 21.6, 21.9, 21.9, 22,
22.1, 22.2, 22.4, 22.4, 22.5, 22.6, 22.7, 22.7, 22.7, 23.1, 23.2,
23.2, 23.5, 23.6, 23.7, 23.8, 23.8, 24.6, 25, 26.3, 26.8, 27,
27.2)
> sort(unique(toto))
  [1]  2.5  2.6  2.7  2.8  2.9  3.0  3.1  3.2  3.3  3.4  3.4  3.5  3.6  3.6  3.7  3.8  3.8  3.9  3.9
 [20]  4.0  4.1  4.1  4.2  4.2  4.3  4.3  4.4  4.5  4.6  4.6  4.7  4.7  4.8  4.8  4.9  5.0  5.0  5.1
 [39]  5.1  5.2  5.2  5.3  5.3  5.4  5.5  5.5  5.6  5.6  5.7  5.7  5.8  5.8  5.9  6.0  6.0  6.1  6.1
 [58]  6.2  6.2  6.3  6.3  6.4  6.4  6.5  6.5  6.6  6.6  6.7  6.7  6.7  6.8  6.8  6.9  6.9  7.0  7.0
 [77]  7.1  7.1  7.1  7.2  7.2  7.3  7.3  7.4  7.4  7.5  7.5  7.6  7.6  7.7  7.7  7.8  7.8  7.9  8.0
 [96]  8.1  8.1  8.2  8.2  8.3  8.4  8.5  8.6  8.6  8.7  8.7  8.8  8.8  8.9  8.9  9.0  9.1  9.1  9.2
[115]  9.2  9.3  9.3  9.4  9.4  9.5  9.5  9.6  9.6  9.7  9.7  9.8  9.9  9.9 10.0 10.0 10.1 10.1 10.2
[134] 10.2 10.3 10.3 10.4 10.4 10.5 10.5 10.6 10.6 10.7 10.7 10.8 10.8 10.9 10.9 11.0 11.0 11.1 11.1
[153] 11.2 11.2 11.3 11.3 11.4 11.4 11.5 11.5 11.6 11.6 11.7 11.7 11.8 11.8 11.8 11.9 11.9 11.9 12.0
[172] 12.0 12.1 12.1 12.2 12.2 12.3 12.3 12.4 12.4 12.4 12.5 12.5 12.6 12.6 12.7 12.7 12.8 12.8 12.9
[191] 12.9 12.9 13.0 13.0 13.1 13.1 13.2 13.2 13.3 13.3 13.3 13.4 13.4 13.4 13.5 13.5 13.6 13.6 13.6
[210] 13.7 13.7 13.8 13.8 13.8 13.9 13.9 13.9 14.0 14.0 14.1 14.1 14.2 14.2 14.3 14.3 14.3 14.4 14.4
[229] 14.4 14.5 14.5 14.6 14.6 14.7 14.7 14.8 14.8 14.8 14.9 14.9 14.9 15.0 15.0 15.1 15.1 15.2 15.2
[248] 15.2 15.3 15.3 15.3 15.4 15.4 15.4 15.5 15.5 15.6 15.6 15.7 15.7 15.8 15.8 15.8 15.9 15.9 15.9
[267] 16.0 16.1 16.1 16.2 16.2 16.3 16.3 16.4 16.4 16.5 16.6 16.6 16.7 16.7 16.8 16.8 16.9 16.9 17.0
[286] 17.1 17.1 17.2 17.2 17.3 17.3 17.4 17.5 17.6 17.6 17.7 17.7 17.8 17.8 17.9 18.0 18.1 18.1 18.2
[305] 18.2 18.3 18.3 18.4 18.5 18.6 18.7 18.8 18.8 18.9 19.0 19.1 19.2 19.2 19.3 19.3 19.4 19.4 19.5
[324] 19.6 19.7 19.7 19.8 19.8 20.1 20.1 20.2 20.3 20.4 20.5 20.6 20.6 20.7 20.8 20.9 21.0 21.1 21.2
[343] 21.2 21.3 21.3 21.4 21.5 21.6 21.6 21.9 22.0 22.1 22.2 22.4 22.5 22.6 22.7 22.7 23.1 23.2 23.5
[362] 23.6 23.7 23.8 23.8 24.6 25.0 26.3 26.8 27.0 27.2
> table(toto)
toto
 2.5  2.6  2.7  2.8  2.9    3  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9    4  4.1  4.2  4.3  4.4
   1    4    6    9    8    8   12   13   13   14   15   23   24   25   29   39   35   29   30   33
 4.5  4.6  4.7  4.8  4.9    5  5.1  5.2  5.3  5.4  5.5  5.6  5.7  5.8  5.9    6  6.1  6.2  6.3  6.4
  48   42   45   39   57   37   42   34   48   42   36   43   40   44   39   38   39   44   40   45
 6.5  6.6  6.7  6.8  6.9    7  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9    8  8.1  8.2  8.3  8.4
  37   39   40   47   35   34   32   28   33   24   29   27   23   21   26   18   10   21   13   15
 8.5  8.6  8.7  8.8  8.9    9  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9   10 10.1 10.2 10.3 10.4
   8   12   13   10   17    8    8    8   15    8   21   12   20    8   16   17   17   16   15   19
10.5 10.6 10.7 10.8 10.9   11 11.1 11.2 11.3 11.4 11.5 11.6 11.7 11.8 11.9   12 12.1 12.2 12.3 12.4
  17   21   30   14   24   25   23   34   51   48   51   54   53   55   61   50   70   64   75   60
12.5 12.6 12.7 12.8 12.9   13 13.1 13.2 13.3 13.4 13.5 13.6 13.7 13.8 13.9   14 14.1 14.2 14.3 14.4
  72   63   55   78   55   60   68   79   70   62   72   67   80   79   74   65   58   70   68   68
14.5 14.6 14.7 14.8 14.9   15 15.1 15.2 15.3 15.4 15.5 15.6 15.7 15.8 15.9   16 16.1 16.2 16.3 16.4
  53   61   62   53   54   44   48   41   45   31   43   32   37   26   21   35   26   21   23   26
16.5 16.6 16.7 16.8 16.9   17 17.1 17.2 17.3 17.4 17.5 17.6 17.7 17.8 17.9   18 18.1 18.2 18.3 18.4
  17   20   17   17   23   19    9   13   13    7   12    8   10    9    8   14    8    9   12    6
18.5 18.6 18.7 18.8 18.9   19 19.1 19.2 19.3 19.4 19.5 19.6 19.7 19.8 20.1 20.2 20.3 20.4 20.5 20.6
   9    1    4    7   10    5    7    6    4    5    4    1    7    5    5    2    1    1    3    4
20.7 20.8 20.9   21 21.1 21.2 21.3 21.4 21.5 21.6 21.9   22 22.1 22.2 22.4 22.5 22.6 22.7 23.1 23.2
   3    2    4    1    1    3    3    1    3    4    2    1    1    1    2    1    1    3    1    2
23.5 23.6 23.7 23.8 24.6   25 26.3 26.8   27 27.2
   1    1    1    2    1    1    1    1    1    1







	[[alternative HTML version deleted]]


From chr|@ho|d @end|ng |rom p@yctc@org  Tue Dec 10 15:41:00 2019
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Tue, 10 Dec 2019 14:41:00 +0000 (GMT)
Subject: [R] table and unique seems to behave differently
In-Reply-To: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
References: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
Message-ID: <1544858897.12077607.1575988860151.JavaMail.zimbra@psyctc.org>

This doesn't answer your question but I get exactly the same vector of length 210 with unique(toto) and names(table(toto)) using the same version of R that you are and I can't see any obvious reason why you wouldn't but when I hit things like that it tends to be that one version is string with initial or trailing spaces or a character set issue.  I can't see that those apply here but it's all I could imagine without racking my poor old brains much more.

Good luck finding the answer!

Chris

----- Original Message -----
> From: "Alain Guillet" <alain.guillet at uclouvain.be>
> To: r-help at r-project.org
> Sent: Tuesday, 10 December, 2019 09:53:29
> Subject: [R] table and unique seems to behave differently

> Hi,
> 
> I have a vector (see below the dput) and I use unique on it to get unique
> values. If I then sort the result of the vector obtained by unique, I see some
> elements that look like identical. I suspect it could be a matter of rounded
> values but table gives a different result: unlike unique output which contains
> "3.4  3.4", table has only one cell for 3.4.
> 
> Can anybody know why I get results that look like incoherent between the two
> functions?
> 
> 
> Best regards,
> Alain Guillet
> 
> ------------------------------------------
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          3
> minor          6.1
> year           2019
> month          07
> day            05
> svn rev        76782
> language       R
> version.string R version 3.6.1 (2019-07-05)
> nickname       Action of the Toes
> --------------------------------------------------
>> dput(toto)
> c(2.5, 2.6, 2.6, 2.6, 2.6, 2.7, 2.7, 2.7, 2.7, 2.7, 2.7, 2.8,
> 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.9, 2.9, 2.9, 2.9, 2.9,
> 2.9, 2.9, 2.9, 3, 3, 3, 3, 3, 3, 3, 3, 3.1, 3.1, 3.1, 3.1, 3.1,
> 3.1, 3.1, 3.1, 3.1, 3.1, 3.1, 3.1, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2,
> 3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3,
> 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4,
> 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.5,
> 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6, 3.6,
> 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6,
> 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7,
> 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7,
> 3.7, 3.7, 3.7, 3.7, 3.7, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8,
> 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8,
> 3.8, 3.8, 3.8, 3.8, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9,
> 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9,
> 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
> 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
> 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
> 4.1, 4.1, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2,
> 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2,
> 4.2, 4.2, 4.2, 4.2, 4.2, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3,
> 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3,
> 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.4, 4.4, 4.4, 4.4,
> 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4,
> 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4,
> 4.4, 4.4, 4.4, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
> 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
> 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
> 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.6,
> 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
> 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
> 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
> 4.6, 4.6, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
> 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
> 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
> 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.8, 4.8, 4.8, 4.8, 4.8,
> 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8,
> 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8,
> 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.9, 4.9, 4.9, 4.9, 4.9,
> 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5.1, 5.1, 5.1,
> 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
> 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
> 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
> 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2,
> 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2,
> 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.3, 5.3, 5.3, 5.3, 5.3,
> 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
> 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
> 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
> 5.3, 5.3, 5.3, 5.3, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
> 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
> 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
> 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
> 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
> 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
> 5.5, 5.5, 5.5, 5.5, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
> 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
> 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
> 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.7, 5.7, 5.7, 5.7, 5.7,
> 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7,
> 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7,
> 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.8, 5.8, 5.8, 5.8,
> 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
> 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
> 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
> 5.8, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
> 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
> 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
> 5.9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
> 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6.1,
> 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1,
> 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1,
> 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.2,
> 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
> 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
> 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
> 6.2, 6.2, 6.2, 6.2, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
> 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
> 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
> 6.3, 6.3, 6.3, 6.3, 6.3, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
> 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
> 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
> 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.5, 6.5,
> 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5,
> 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5,
> 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.6, 6.6, 6.6, 6.6,
> 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6,
> 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6,
> 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.7, 6.7, 6.7, 6.7,
> 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7,
> 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7,
> 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.8, 6.8, 6.8,
> 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
> 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
> 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
> 6.8, 6.8, 6.8, 6.8, 6.8, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
> 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
> 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
> 6.9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7.1, 7.1, 7.1, 7.1,
> 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1,
> 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1,
> 7.1, 7.1, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2,
> 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2,
> 7.2, 7.2, 7.2, 7.2, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3,
> 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3,
> 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.4, 7.4,
> 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4,
> 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.5, 7.5, 7.5, 7.5,
> 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5,
> 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.6,
> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6,
> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6,
> 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7,
> 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.8, 7.8, 7.8,
> 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8,
> 7.8, 7.8, 7.8, 7.8, 7.8, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9,
> 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9,
> 7.9, 7.9, 7.9, 7.9, 7.9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
> 8, 8, 8, 8, 8, 8, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1,
> 8.1, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2,
> 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.3, 8.3, 8.3, 8.3,
> 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.4, 8.4, 8.4, 8.4,
> 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.5, 8.5,
> 8.5, 8.5, 8.5, 8.5, 8.5, 8.5, 8.6, 8.6, 8.6, 8.6, 8.6, 8.6, 8.6,
> 8.6, 8.6, 8.6, 8.6, 8.6, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7,
> 8.7, 8.7, 8.7, 8.7, 8.7, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8,
> 8.8, 8.8, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9,
> 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 9, 9, 9, 9, 9, 9, 9, 9, 9.1, 9.1,
> 9.1, 9.1, 9.1, 9.1, 9.1, 9.1, 9.2, 9.2, 9.2, 9.2, 9.2, 9.2, 9.2,
> 9.2, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3,
> 9.3, 9.3, 9.3, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.5, 9.5,
> 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5,
> 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.6, 9.6, 9.6, 9.6, 9.6, 9.6, 9.6,
> 9.6, 9.6, 9.6, 9.6, 9.6, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7,
> 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.8,
> 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9,
> 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 10, 10, 10,
> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10.1,
> 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1,
> 10.1, 10.1, 10.1, 10.1, 10.1, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2,
> 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.3,
> 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3,
> 10.3, 10.3, 10.3, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4,
> 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4,
> 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5,
> 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.6, 10.6, 10.6, 10.6, 10.6,
> 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6,
> 10.6, 10.6, 10.6, 10.6, 10.6, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
> 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
> 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
> 10.7, 10.7, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8,
> 10.8, 10.8, 10.8, 10.8, 10.8, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9,
> 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9,
> 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 11, 11, 11, 11, 11,
> 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,
> 11, 11, 11, 11, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1,
> 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1,
> 11.1, 11.1, 11.1, 11.1, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
> 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
> 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
> 11.2, 11.2, 11.2, 11.2, 11.2, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> 11.3, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> 11.4, 11.4, 11.4, 11.4, 11.4, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> 11.5, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.8, 11.8,
> 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> 12, 12, 12, 12, 12, 12, 12, 12, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> 12.7, 12.7, 12.7, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> 12.9, 12.9, 12.9, 12.9, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> 14, 14, 14, 14, 14, 14, 14, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> 14.5, 14.5, 14.5, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> 14.8, 14.8, 14.8, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> 14.9, 14.9, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15.1,
> 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> 15.1, 15.1, 15.1, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> 15.3, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4,
> 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4,
> 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.5,
> 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
> 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
> 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
> 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.6, 15.6,
> 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6,
> 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6,
> 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.7, 15.7, 15.7,
> 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
> 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
> 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
> 15.7, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8,
> 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8,
> 15.8, 15.8, 15.8, 15.8, 15.8, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9,
> 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9,
> 15.9, 15.9, 15.9, 15.9, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
> 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
> 16, 16, 16, 16, 16, 16, 16, 16, 16, 16.1, 16.1, 16.1, 16.1, 16.1,
> 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1,
> 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.2,
> 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2,
> 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.3, 16.3,
> 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3,
> 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.4,
> 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4,
> 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4,
> 16.4, 16.4, 16.4, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5,
> 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.6, 16.6,
> 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6,
> 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.7, 16.7, 16.7, 16.7,
> 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7,
> 16.7, 16.7, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8,
> 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.9, 16.9, 16.9,
> 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9,
> 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 17, 17,
> 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,
> 17, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.2,
> 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2,
> 17.2, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3,
> 17.3, 17.3, 17.3, 17.4, 17.4, 17.4, 17.4, 17.4, 17.4, 17.4, 17.5,
> 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5,
> 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.7, 17.7, 17.7,
> 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.8, 17.8, 17.8, 17.8,
> 17.8, 17.8, 17.8, 17.8, 17.8, 17.9, 17.9, 17.9, 17.9, 17.9, 17.9,
> 17.9, 17.9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,
> 18, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.2, 18.2,
> 18.2, 18.2, 18.2, 18.2, 18.2, 18.2, 18.2, 18.3, 18.3, 18.3, 18.3,
> 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.4, 18.4, 18.4,
> 18.4, 18.4, 18.4, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5,
> 18.5, 18.6, 18.7, 18.7, 18.7, 18.7, 18.8, 18.8, 18.8, 18.8, 18.8,
> 18.8, 18.8, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9,
> 18.9, 19, 19, 19, 19, 19, 19.1, 19.1, 19.1, 19.1, 19.1, 19.1,
> 19.1, 19.2, 19.2, 19.2, 19.2, 19.2, 19.2, 19.3, 19.3, 19.3, 19.3,
> 19.4, 19.4, 19.4, 19.4, 19.4, 19.5, 19.5, 19.5, 19.5, 19.6, 19.7,
> 19.7, 19.7, 19.7, 19.7, 19.7, 19.7, 19.8, 19.8, 19.8, 19.8, 19.8,
> 20.1, 20.1, 20.1, 20.1, 20.1, 20.2, 20.2, 20.3, 20.4, 20.5, 20.5,
> 20.5, 20.6, 20.6, 20.6, 20.6, 20.7, 20.7, 20.7, 20.8, 20.8, 20.9,
> 20.9, 20.9, 20.9, 21, 21.1, 21.2, 21.2, 21.2, 21.3, 21.3, 21.3,
> 21.4, 21.5, 21.5, 21.5, 21.6, 21.6, 21.6, 21.6, 21.9, 21.9, 22,
> 22.1, 22.2, 22.4, 22.4, 22.5, 22.6, 22.7, 22.7, 22.7, 23.1, 23.2,
> 23.2, 23.5, 23.6, 23.7, 23.8, 23.8, 24.6, 25, 26.3, 26.8, 27,
> 27.2)
>> sort(unique(toto))
>  [1]  2.5  2.6  2.7  2.8  2.9  3.0  3.1  3.2  3.3  3.4  3.4  3.5  3.6  3.6  3.7
>  3.8  3.8  3.9  3.9
> [20]  4.0  4.1  4.1  4.2  4.2  4.3  4.3  4.4  4.5  4.6  4.6  4.7  4.7  4.8  4.8
> 4.9  5.0  5.0  5.1
> [39]  5.1  5.2  5.2  5.3  5.3  5.4  5.5  5.5  5.6  5.6  5.7  5.7  5.8  5.8  5.9
> 6.0  6.0  6.1  6.1
> [58]  6.2  6.2  6.3  6.3  6.4  6.4  6.5  6.5  6.6  6.6  6.7  6.7  6.7  6.8  6.8
> 6.9  6.9  7.0  7.0
> [77]  7.1  7.1  7.1  7.2  7.2  7.3  7.3  7.4  7.4  7.5  7.5  7.6  7.6  7.7  7.7
> 7.8  7.8  7.9  8.0
> [96]  8.1  8.1  8.2  8.2  8.3  8.4  8.5  8.6  8.6  8.7  8.7  8.8  8.8  8.9  8.9
> 9.0  9.1  9.1  9.2
> [115]  9.2  9.3  9.3  9.4  9.4  9.5  9.5  9.6  9.6  9.7  9.7  9.8  9.9  9.9 10.0
> 10.0 10.1 10.1 10.2
> [134] 10.2 10.3 10.3 10.4 10.4 10.5 10.5 10.6 10.6 10.7 10.7 10.8 10.8 10.9 10.9
> 11.0 11.0 11.1 11.1
> [153] 11.2 11.2 11.3 11.3 11.4 11.4 11.5 11.5 11.6 11.6 11.7 11.7 11.8 11.8 11.8
> 11.9 11.9 11.9 12.0
> [172] 12.0 12.1 12.1 12.2 12.2 12.3 12.3 12.4 12.4 12.4 12.5 12.5 12.6 12.6 12.7
> 12.7 12.8 12.8 12.9
> [191] 12.9 12.9 13.0 13.0 13.1 13.1 13.2 13.2 13.3 13.3 13.3 13.4 13.4 13.4 13.5
> 13.5 13.6 13.6 13.6
> [210] 13.7 13.7 13.8 13.8 13.8 13.9 13.9 13.9 14.0 14.0 14.1 14.1 14.2 14.2 14.3
> 14.3 14.3 14.4 14.4
> [229] 14.4 14.5 14.5 14.6 14.6 14.7 14.7 14.8 14.8 14.8 14.9 14.9 14.9 15.0 15.0
> 15.1 15.1 15.2 15.2
> [248] 15.2 15.3 15.3 15.3 15.4 15.4 15.4 15.5 15.5 15.6 15.6 15.7 15.7 15.8 15.8
> 15.8 15.9 15.9 15.9
> [267] 16.0 16.1 16.1 16.2 16.2 16.3 16.3 16.4 16.4 16.5 16.6 16.6 16.7 16.7 16.8
> 16.8 16.9 16.9 17.0
> [286] 17.1 17.1 17.2 17.2 17.3 17.3 17.4 17.5 17.6 17.6 17.7 17.7 17.8 17.8 17.9
> 18.0 18.1 18.1 18.2
> [305] 18.2 18.3 18.3 18.4 18.5 18.6 18.7 18.8 18.8 18.9 19.0 19.1 19.2 19.2 19.3
> 19.3 19.4 19.4 19.5
> [324] 19.6 19.7 19.7 19.8 19.8 20.1 20.1 20.2 20.3 20.4 20.5 20.6 20.6 20.7 20.8
> 20.9 21.0 21.1 21.2
> [343] 21.2 21.3 21.3 21.4 21.5 21.6 21.6 21.9 22.0 22.1 22.2 22.4 22.5 22.6 22.7
> 22.7 23.1 23.2 23.5
> [362] 23.6 23.7 23.8 23.8 24.6 25.0 26.3 26.8 27.0 27.2
>> table(toto)
> toto
> 2.5  2.6  2.7  2.8  2.9    3  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9    4
> 4.1  4.2  4.3  4.4
>   1    4    6    9    8    8   12   13   13   14   15   23   24   25   29   39
>   35   29   30   33
> 4.5  4.6  4.7  4.8  4.9    5  5.1  5.2  5.3  5.4  5.5  5.6  5.7  5.8  5.9    6
> 6.1  6.2  6.3  6.4
>  48   42   45   39   57   37   42   34   48   42   36   43   40   44   39   38
>  39   44   40   45
> 6.5  6.6  6.7  6.8  6.9    7  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9    8
> 8.1  8.2  8.3  8.4
>  37   39   40   47   35   34   32   28   33   24   29   27   23   21   26   18
>  10   21   13   15
> 8.5  8.6  8.7  8.8  8.9    9  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9   10
> 10.1 10.2 10.3 10.4
>   8   12   13   10   17    8    8    8   15    8   21   12   20    8   16   17
>   17   16   15   19
> 10.5 10.6 10.7 10.8 10.9   11 11.1 11.2 11.3 11.4 11.5 11.6 11.7 11.8 11.9   12
> 12.1 12.2 12.3 12.4
>  17   21   30   14   24   25   23   34   51   48   51   54   53   55   61   50
>  70   64   75   60
> 12.5 12.6 12.7 12.8 12.9   13 13.1 13.2 13.3 13.4 13.5 13.6 13.7 13.8 13.9   14
> 14.1 14.2 14.3 14.4
>  72   63   55   78   55   60   68   79   70   62   72   67   80   79   74   65
>  58   70   68   68
> 14.5 14.6 14.7 14.8 14.9   15 15.1 15.2 15.3 15.4 15.5 15.6 15.7 15.8 15.9   16
> 16.1 16.2 16.3 16.4
>  53   61   62   53   54   44   48   41   45   31   43   32   37   26   21   35
>  26   21   23   26
> 16.5 16.6 16.7 16.8 16.9   17 17.1 17.2 17.3 17.4 17.5 17.6 17.7 17.8 17.9   18
> 18.1 18.2 18.3 18.4
>  17   20   17   17   23   19    9   13   13    7   12    8   10    9    8   14
>  8    9   12    6
> 18.5 18.6 18.7 18.8 18.9   19 19.1 19.2 19.3 19.4 19.5 19.6 19.7 19.8 20.1 20.2
> 20.3 20.4 20.5 20.6
>   9    1    4    7   10    5    7    6    4    5    4    1    7    5    5    2
>   1    1    3    4
> 20.7 20.8 20.9   21 21.1 21.2 21.3 21.4 21.5 21.6 21.9   22 22.1 22.2 22.4 22.5
> 22.6 22.7 23.1 23.2
>   3    2    4    1    1    3    3    1    3    4    2    1    1    1    2    1
>   1    3    1    2
> 23.5 23.6 23.7 23.8 24.6   25 26.3 26.8   27 27.2
>   1    1    1    2    1    1    1    1    1    1
> 
> 
> 
> 
> 
> 
> 
>	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
That page will also take you to my blog which started with earlier joys in France and Spain!

If you want to book to talk, I am trying to keep that to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Dec 10 16:03:34 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 10 Dec 2019 10:03:34 -0500
Subject: [R] table and unique seems to behave differently
In-Reply-To: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
References: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
Message-ID: <17416b21-b5ab-082e-8081-148387f91837@gmail.com>

On 10/12/2019 3:53 a.m., Alain Guillet wrote:
> Hi,
> 
> I have a vector (see below the dput) and I use unique on it to get unique values. If I then sort the result of the vector obtained by unique, I see some elements that look like identical. I suspect it could be a matter of rounded values but table gives a different result: unlike unique output which contains "3.4  3.4", table has only one cell for 3.4.
> 
> Can anybody know why I get results that look like incoherent between the two functions?

dput() does some rounding, so it doesn't necessarily reproduce values 
exactly.  For example,

x <- c(3.4, 3.4 + 1e-15)
unique(x)
#> [1] 3.4 3.4
dput(x)
#> c(3.4, 3.4)
identical(x, c(3.4, 3.4))
#> [1] FALSE

If you really want to see exact values, you can use the "hexNumeric" 
option to dput():

dput(x, control = "hexNumeric")
#> c(0x1.b333333333333p+1, 0x1.b333333333335p+1)
identical(x, c(0x1.b333333333333p+1, 0x1.b333333333335p+1))
#> [1] TRUE

Duncan Murdoch


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Dec 10 16:31:05 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 10 Dec 2019 07:31:05 -0800
Subject: [R] table and unique seems to behave differently
In-Reply-To: <17416b21-b5ab-082e-8081-148387f91837@gmail.com>
References: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
 <17416b21-b5ab-082e-8081-148387f91837@gmail.com>
Message-ID: <917F59D8-DCA5-4AA5-9463-610338EFF7B5@dcn.davis.ca.us>

I think the question was about table vs unique. Table groups by character representation, unique groups by the underlying representation.

On December 10, 2019 7:03:34 AM PST, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 10/12/2019 3:53 a.m., Alain Guillet wrote:
>> Hi,
>> 
>> I have a vector (see below the dput) and I use unique on it to get
>unique values. If I then sort the result of the vector obtained by
>unique, I see some elements that look like identical. I suspect it
>could be a matter of rounded values but table gives a different result:
>unlike unique output which contains "3.4  3.4", table has only one cell
>for 3.4.
>> 
>> Can anybody know why I get results that look like incoherent between
>the two functions?
>
>dput() does some rounding, so it doesn't necessarily reproduce values 
>exactly.  For example,
>
>x <- c(3.4, 3.4 + 1e-15)
>unique(x)
>#> [1] 3.4 3.4
>dput(x)
>#> c(3.4, 3.4)
>identical(x, c(3.4, 3.4))
>#> [1] FALSE
>
>If you really want to see exact values, you can use the "hexNumeric" 
>option to dput():
>
>dput(x, control = "hexNumeric")
>#> c(0x1.b333333333333p+1, 0x1.b333333333335p+1)
>identical(x, c(0x1.b333333333333p+1, 0x1.b333333333335p+1))
>#> [1] TRUE
>
>Duncan Murdoch
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Tue Dec 10 16:32:39 2019
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Tue, 10 Dec 2019 10:32:39 -0500
Subject: [R] table and unique seems to behave differently
In-Reply-To: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
References: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
Message-ID: <CAM_vju=Htv+LdmYxTYLs2hSaXEn4+nfwd7njpiXbGwJMC_ABvA@mail.gmail.com>

Back to the table part of the question, but using Duncan's example.

> x <- c(3.4, 3.4 + 1e-15)
> unique(x)
[1] 3.4 3.4
> table(x)
x
3.4
  2

The question was, why are these different.

table() only works on factors, so it converts the numeric vector to a
factor before tabulation.
factor() tries to do something sensible, and implicitly rounds the numeric data.

> factor(x)
[1] 3.4 3.4
Levels: 3.4

Whether you think that is actually sensible or not is up to you, but
if it isn't then you shouldn't use table.

That table uses factors is documented in ?table. A quick read of
?factor didn't find any explicit discussion, other than the
acknowledgement that factor() is lossy in:

     To transform a factor ?f? to approximately its
     original numeric values, ?as.numeric(levels(f))[f]? is recommended
     and slightly more efficient than ?as.numeric(as.character(f))?.

You can't even get table() to do what you want by being explicit:

> table(factor(x, levels = unique(x)))
Error in `levels<-`(`*tmp*`, value = as.character(levels)) :
  factor level [2] is duplicated


Sarah

On Tue, Dec 10, 2019 at 9:18 AM Alain Guillet
<alain.guillet at uclouvain.be> wrote:
>
> Hi,
>
> I have a vector (see below the dput) and I use unique on it to get unique values. If I then sort the result of the vector obtained by unique, I see some elements that look like identical. I suspect it could be a matter of rounded values but table gives a different result: unlike unique output which contains "3.4  3.4", table has only one cell for 3.4.
>
> Can anybody know why I get results that look like incoherent between the two functions?
>
>
> Best regards,
> Alain Guillet
>

-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From @|@|n@gu|||et @end|ng |rom uc|ouv@|n@be  Tue Dec 10 17:37:04 2019
From: @|@|n@gu|||et @end|ng |rom uc|ouv@|n@be (Alain Guillet)
Date: Tue, 10 Dec 2019 16:37:04 +0000
Subject: [R] table and unique seems to behave differently
In-Reply-To: <1544858897.12077607.1575988860151.JavaMail.zimbra@psyctc.org>
References: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>,
 <1544858897.12077607.1575988860151.JavaMail.zimbra@psyctc.org>
Message-ID: <AM6PR03MB55918A498AB25BDE5E5303338C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>

Another finding for me today: dput doesn't write exactly the vector that creates the problem. I could use an RData file but I think it is forbidden in this mailing list...


Alain
________________________________
De : Chris Evans <chrishold at psyctc.org>
Envoy? : mardi 10 d?cembre 2019 15:41
? : Alain Guillet <alain.guillet at uclouvain.be>
Cc : r-help at r-project.org <r-help at r-project.org>
Objet : Re: [R] table and unique seems to behave differently

This doesn't answer your question but I get exactly the same vector of length 210 with unique(toto) and names(table(toto)) using the same version of R that you are and I can't see any obvious reason why you wouldn't but when I hit things like that it tends to be that one version is string with initial or trailing spaces or a character set issue.  I can't see that those apply here but it's all I could imagine without racking my poor old brains much more.

Good luck finding the answer!

Chris

----- Original Message -----
> From: "Alain Guillet" <alain.guillet at uclouvain.be>
> To: r-help at r-project.org
> Sent: Tuesday, 10 December, 2019 09:53:29
> Subject: [R] table and unique seems to behave differently

> Hi,
>
> I have a vector (see below the dput) and I use unique on it to get unique
> values. If I then sort the result of the vector obtained by unique, I see some
> elements that look like identical. I suspect it could be a matter of rounded
> values but table gives a different result: unlike unique output which contains
> "3.4  3.4", table has only one cell for 3.4.
>
> Can anybody know why I get results that look like incoherent between the two
> functions?
>
>
> Best regards,
> Alain Guillet
>
> ------------------------------------------
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          3
> minor          6.1
> year           2019
> month          07
> day            05
> svn rev        76782
> language       R
> version.string R version 3.6.1 (2019-07-05)
> nickname       Action of the Toes
> --------------------------------------------------
>> dput(toto)
> c(2.5, 2.6, 2.6, 2.6, 2.6, 2.7, 2.7, 2.7, 2.7, 2.7, 2.7, 2.8,
> 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.9, 2.9, 2.9, 2.9, 2.9,
> 2.9, 2.9, 2.9, 3, 3, 3, 3, 3, 3, 3, 3, 3.1, 3.1, 3.1, 3.1, 3.1,
> 3.1, 3.1, 3.1, 3.1, 3.1, 3.1, 3.1, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2,
> 3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3,
> 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4,
> 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.5,
> 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6, 3.6,
> 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6,
> 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7,
> 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7,
> 3.7, 3.7, 3.7, 3.7, 3.7, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8,
> 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8,
> 3.8, 3.8, 3.8, 3.8, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9,
> 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9,
> 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
> 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
> 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
> 4.1, 4.1, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2,
> 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2,
> 4.2, 4.2, 4.2, 4.2, 4.2, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3,
> 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3,
> 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.4, 4.4, 4.4, 4.4,
> 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4,
> 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4,
> 4.4, 4.4, 4.4, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
> 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
> 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
> 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.6,
> 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
> 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
> 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
> 4.6, 4.6, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
> 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
> 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
> 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.8, 4.8, 4.8, 4.8, 4.8,
> 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8,
> 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8,
> 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.9, 4.9, 4.9, 4.9, 4.9,
> 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5.1, 5.1, 5.1,
> 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
> 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
> 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
> 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2,
> 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2,
> 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.3, 5.3, 5.3, 5.3, 5.3,
> 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
> 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
> 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
> 5.3, 5.3, 5.3, 5.3, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
> 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
> 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
> 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
> 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
> 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
> 5.5, 5.5, 5.5, 5.5, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
> 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
> 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
> 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.7, 5.7, 5.7, 5.7, 5.7,
> 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7,
> 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7,
> 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.8, 5.8, 5.8, 5.8,
> 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
> 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
> 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
> 5.8, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
> 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
> 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
> 5.9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
> 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6.1,
> 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1,
> 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1,
> 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.2,
> 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
> 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
> 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
> 6.2, 6.2, 6.2, 6.2, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
> 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
> 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
> 6.3, 6.3, 6.3, 6.3, 6.3, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
> 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
> 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
> 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.5, 6.5,
> 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5,
> 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5,
> 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.6, 6.6, 6.6, 6.6,
> 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6,
> 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6,
> 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.7, 6.7, 6.7, 6.7,
> 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7,
> 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7,
> 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.8, 6.8, 6.8,
> 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
> 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
> 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
> 6.8, 6.8, 6.8, 6.8, 6.8, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
> 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
> 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
> 6.9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7.1, 7.1, 7.1, 7.1,
> 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1,
> 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1,
> 7.1, 7.1, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2,
> 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2,
> 7.2, 7.2, 7.2, 7.2, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3,
> 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3,
> 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.4, 7.4,
> 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4,
> 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.5, 7.5, 7.5, 7.5,
> 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5,
> 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.6,
> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6,
> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6,
> 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7,
> 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.8, 7.8, 7.8,
> 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8,
> 7.8, 7.8, 7.8, 7.8, 7.8, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9,
> 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9,
> 7.9, 7.9, 7.9, 7.9, 7.9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
> 8, 8, 8, 8, 8, 8, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1,
> 8.1, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2,
> 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.3, 8.3, 8.3, 8.3,
> 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.4, 8.4, 8.4, 8.4,
> 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.5, 8.5,
> 8.5, 8.5, 8.5, 8.5, 8.5, 8.5, 8.6, 8.6, 8.6, 8.6, 8.6, 8.6, 8.6,
> 8.6, 8.6, 8.6, 8.6, 8.6, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7,
> 8.7, 8.7, 8.7, 8.7, 8.7, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8,
> 8.8, 8.8, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9,
> 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 9, 9, 9, 9, 9, 9, 9, 9, 9.1, 9.1,
> 9.1, 9.1, 9.1, 9.1, 9.1, 9.1, 9.2, 9.2, 9.2, 9.2, 9.2, 9.2, 9.2,
> 9.2, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3,
> 9.3, 9.3, 9.3, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.5, 9.5,
> 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5,
> 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.6, 9.6, 9.6, 9.6, 9.6, 9.6, 9.6,
> 9.6, 9.6, 9.6, 9.6, 9.6, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7,
> 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.8,
> 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9,
> 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 10, 10, 10,
> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10.1,
> 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1,
> 10.1, 10.1, 10.1, 10.1, 10.1, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2,
> 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.3,
> 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3,
> 10.3, 10.3, 10.3, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4,
> 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4,
> 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5,
> 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.6, 10.6, 10.6, 10.6, 10.6,
> 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6,
> 10.6, 10.6, 10.6, 10.6, 10.6, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
> 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
> 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
> 10.7, 10.7, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8,
> 10.8, 10.8, 10.8, 10.8, 10.8, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9,
> 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9,
> 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 11, 11, 11, 11, 11,
> 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,
> 11, 11, 11, 11, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1,
> 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1,
> 11.1, 11.1, 11.1, 11.1, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
> 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
> 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
> 11.2, 11.2, 11.2, 11.2, 11.2, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> 11.3, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> 11.4, 11.4, 11.4, 11.4, 11.4, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> 11.5, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.8, 11.8,
> 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> 11.9, 11.9, 11.9, 11.9, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> 12, 12, 12, 12, 12, 12, 12, 12, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> 12.6, 12.6, 12.6, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> 12.7, 12.7, 12.7, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> 12.8, 12.8, 12.8, 12.8, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> 12.9, 12.9, 12.9, 12.9, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> 13.1, 13.1, 13.1, 13.1, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> 13.5, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> 13.6, 13.6, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> 13.7, 13.7, 13.7, 13.7, 13.7, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> 13.9, 13.9, 13.9, 13.9, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> 14, 14, 14, 14, 14, 14, 14, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> 14.2, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> 14.3, 14.3, 14.3, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> 14.4, 14.4, 14.4, 14.4, 14.4, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> 14.5, 14.5, 14.5, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> 14.7, 14.7, 14.7, 14.7, 14.7, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> 14.8, 14.8, 14.8, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> 14.9, 14.9, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15.1,
> 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> 15.1, 15.1, 15.1, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> 15.3, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4,
> 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4,
> 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.5,
> 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
> 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
> 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
> 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.6, 15.6,
> 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6,
> 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6,
> 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.7, 15.7, 15.7,
> 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
> 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
> 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
> 15.7, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8,
> 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8,
> 15.8, 15.8, 15.8, 15.8, 15.8, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9,
> 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9,
> 15.9, 15.9, 15.9, 15.9, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
> 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
> 16, 16, 16, 16, 16, 16, 16, 16, 16, 16.1, 16.1, 16.1, 16.1, 16.1,
> 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1,
> 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.2,
> 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2,
> 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.3, 16.3,
> 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3,
> 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.4,
> 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4,
> 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4,
> 16.4, 16.4, 16.4, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5,
> 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.6, 16.6,
> 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6,
> 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.7, 16.7, 16.7, 16.7,
> 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7,
> 16.7, 16.7, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8,
> 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.9, 16.9, 16.9,
> 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9,
> 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 17, 17,
> 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,
> 17, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.2,
> 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2,
> 17.2, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3,
> 17.3, 17.3, 17.3, 17.4, 17.4, 17.4, 17.4, 17.4, 17.4, 17.4, 17.5,
> 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5,
> 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.7, 17.7, 17.7,
> 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.8, 17.8, 17.8, 17.8,
> 17.8, 17.8, 17.8, 17.8, 17.8, 17.9, 17.9, 17.9, 17.9, 17.9, 17.9,
> 17.9, 17.9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,
> 18, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.2, 18.2,
> 18.2, 18.2, 18.2, 18.2, 18.2, 18.2, 18.2, 18.3, 18.3, 18.3, 18.3,
> 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.4, 18.4, 18.4,
> 18.4, 18.4, 18.4, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5,
> 18.5, 18.6, 18.7, 18.7, 18.7, 18.7, 18.8, 18.8, 18.8, 18.8, 18.8,
> 18.8, 18.8, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9,
> 18.9, 19, 19, 19, 19, 19, 19.1, 19.1, 19.1, 19.1, 19.1, 19.1,
> 19.1, 19.2, 19.2, 19.2, 19.2, 19.2, 19.2, 19.3, 19.3, 19.3, 19.3,
> 19.4, 19.4, 19.4, 19.4, 19.4, 19.5, 19.5, 19.5, 19.5, 19.6, 19.7,
> 19.7, 19.7, 19.7, 19.7, 19.7, 19.7, 19.8, 19.8, 19.8, 19.8, 19.8,
> 20.1, 20.1, 20.1, 20.1, 20.1, 20.2, 20.2, 20.3, 20.4, 20.5, 20.5,
> 20.5, 20.6, 20.6, 20.6, 20.6, 20.7, 20.7, 20.7, 20.8, 20.8, 20.9,
> 20.9, 20.9, 20.9, 21, 21.1, 21.2, 21.2, 21.2, 21.3, 21.3, 21.3,
> 21.4, 21.5, 21.5, 21.5, 21.6, 21.6, 21.6, 21.6, 21.9, 21.9, 22,
> 22.1, 22.2, 22.4, 22.4, 22.5, 22.6, 22.7, 22.7, 22.7, 23.1, 23.2,
> 23.2, 23.5, 23.6, 23.7, 23.8, 23.8, 24.6, 25, 26.3, 26.8, 27,
> 27.2)
>> sort(unique(toto))
>  [1]  2.5  2.6  2.7  2.8  2.9  3.0  3.1  3.2  3.3  3.4  3.4  3.5  3.6  3.6  3.7
>  3.8  3.8  3.9  3.9
> [20]  4.0  4.1  4.1  4.2  4.2  4.3  4.3  4.4  4.5  4.6  4.6  4.7  4.7  4.8  4.8
> 4.9  5.0  5.0  5.1
> [39]  5.1  5.2  5.2  5.3  5.3  5.4  5.5  5.5  5.6  5.6  5.7  5.7  5.8  5.8  5.9
> 6.0  6.0  6.1  6.1
> [58]  6.2  6.2  6.3  6.3  6.4  6.4  6.5  6.5  6.6  6.6  6.7  6.7  6.7  6.8  6.8
> 6.9  6.9  7.0  7.0
> [77]  7.1  7.1  7.1  7.2  7.2  7.3  7.3  7.4  7.4  7.5  7.5  7.6  7.6  7.7  7.7
> 7.8  7.8  7.9  8.0
> [96]  8.1  8.1  8.2  8.2  8.3  8.4  8.5  8.6  8.6  8.7  8.7  8.8  8.8  8.9  8.9
> 9.0  9.1  9.1  9.2
> [115]  9.2  9.3  9.3  9.4  9.4  9.5  9.5  9.6  9.6  9.7  9.7  9.8  9.9  9.9 10.0
> 10.0 10.1 10.1 10.2
> [134] 10.2 10.3 10.3 10.4 10.4 10.5 10.5 10.6 10.6 10.7 10.7 10.8 10.8 10.9 10.9
> 11.0 11.0 11.1 11.1
> [153] 11.2 11.2 11.3 11.3 11.4 11.4 11.5 11.5 11.6 11.6 11.7 11.7 11.8 11.8 11.8
> 11.9 11.9 11.9 12.0
> [172] 12.0 12.1 12.1 12.2 12.2 12.3 12.3 12.4 12.4 12.4 12.5 12.5 12.6 12.6 12.7
> 12.7 12.8 12.8 12.9
> [191] 12.9 12.9 13.0 13.0 13.1 13.1 13.2 13.2 13.3 13.3 13.3 13.4 13.4 13.4 13.5
> 13.5 13.6 13.6 13.6
> [210] 13.7 13.7 13.8 13.8 13.8 13.9 13.9 13.9 14.0 14.0 14.1 14.1 14.2 14.2 14.3
> 14.3 14.3 14.4 14.4
> [229] 14.4 14.5 14.5 14.6 14.6 14.7 14.7 14.8 14.8 14.8 14.9 14.9 14.9 15.0 15.0
> 15.1 15.1 15.2 15.2
> [248] 15.2 15.3 15.3 15.3 15.4 15.4 15.4 15.5 15.5 15.6 15.6 15.7 15.7 15.8 15.8
> 15.8 15.9 15.9 15.9
> [267] 16.0 16.1 16.1 16.2 16.2 16.3 16.3 16.4 16.4 16.5 16.6 16.6 16.7 16.7 16.8
> 16.8 16.9 16.9 17.0
> [286] 17.1 17.1 17.2 17.2 17.3 17.3 17.4 17.5 17.6 17.6 17.7 17.7 17.8 17.8 17.9
> 18.0 18.1 18.1 18.2
> [305] 18.2 18.3 18.3 18.4 18.5 18.6 18.7 18.8 18.8 18.9 19.0 19.1 19.2 19.2 19.3
> 19.3 19.4 19.4 19.5
> [324] 19.6 19.7 19.7 19.8 19.8 20.1 20.1 20.2 20.3 20.4 20.5 20.6 20.6 20.7 20.8
> 20.9 21.0 21.1 21.2
> [343] 21.2 21.3 21.3 21.4 21.5 21.6 21.6 21.9 22.0 22.1 22.2 22.4 22.5 22.6 22.7
> 22.7 23.1 23.2 23.5
> [362] 23.6 23.7 23.8 23.8 24.6 25.0 26.3 26.8 27.0 27.2
>> table(toto)
> toto
> 2.5  2.6  2.7  2.8  2.9    3  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9    4
> 4.1  4.2  4.3  4.4
>   1    4    6    9    8    8   12   13   13   14   15   23   24   25   29   39
>   35   29   30   33
> 4.5  4.6  4.7  4.8  4.9    5  5.1  5.2  5.3  5.4  5.5  5.6  5.7  5.8  5.9    6
> 6.1  6.2  6.3  6.4
>  48   42   45   39   57   37   42   34   48   42   36   43   40   44   39   38
>  39   44   40   45
> 6.5  6.6  6.7  6.8  6.9    7  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9    8
> 8.1  8.2  8.3  8.4
>  37   39   40   47   35   34   32   28   33   24   29   27   23   21   26   18
>  10   21   13   15
> 8.5  8.6  8.7  8.8  8.9    9  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9   10
> 10.1 10.2 10.3 10.4
>   8   12   13   10   17    8    8    8   15    8   21   12   20    8   16   17
>   17   16   15   19
> 10.5 10.6 10.7 10.8 10.9   11 11.1 11.2 11.3 11.4 11.5 11.6 11.7 11.8 11.9   12
> 12.1 12.2 12.3 12.4
>  17   21   30   14   24   25   23   34   51   48   51   54   53   55   61   50
>  70   64   75   60
> 12.5 12.6 12.7 12.8 12.9   13 13.1 13.2 13.3 13.4 13.5 13.6 13.7 13.8 13.9   14
> 14.1 14.2 14.3 14.4
>  72   63   55   78   55   60   68   79   70   62   72   67   80   79   74   65
>  58   70   68   68
> 14.5 14.6 14.7 14.8 14.9   15 15.1 15.2 15.3 15.4 15.5 15.6 15.7 15.8 15.9   16
> 16.1 16.2 16.3 16.4
>  53   61   62   53   54   44   48   41   45   31   43   32   37   26   21   35
>  26   21   23   26
> 16.5 16.6 16.7 16.8 16.9   17 17.1 17.2 17.3 17.4 17.5 17.6 17.7 17.8 17.9   18
> 18.1 18.2 18.3 18.4
>  17   20   17   17   23   19    9   13   13    7   12    8   10    9    8   14
>  8    9   12    6
> 18.5 18.6 18.7 18.8 18.9   19 19.1 19.2 19.3 19.4 19.5 19.6 19.7 19.8 20.1 20.2
> 20.3 20.4 20.5 20.6
>   9    1    4    7   10    5    7    6    4    5    4    1    7    5    5    2
>   1    1    3    4
> 20.7 20.8 20.9   21 21.1 21.2 21.3 21.4 21.5 21.6 21.9   22 22.1 22.2 22.4 22.5
> 22.6 22.7 23.1 23.2
>   3    2    4    1    1    3    3    1    3    4    2    1    1    1    2    1
>   1    3    1    2
> 23.5 23.6 23.7 23.8 24.6   25 26.3 26.8   27 27.2
>   1    1    1    2    1    1    1    1    1    1
>
>
>
>
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=YIMb5atD3i74G%2BDxPESqCc8vrymCbcvP3zqXrVPYjHE%3D&amp;reserved=0
> PLEASE do read the posting guide https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=ht2yjUUhIHsy0ll1NRhmFNbsegVIr6KiZR1CB7MWjCE%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.

--
Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.psyctc.org%2Fpsyctc%2F&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=H3N6FpuTiA2RhVlsYZ3DL8%2FaRQeJ0uJHFXMeEQQ8Myk%3D&amp;reserved=0
and a site I manage for CORE and CORE system trust at:
   https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.coresystemtrust.org.uk%2F&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=oqR8YAMqCOWaqt3%2Fph9Iw45jTQjowwPixOfgOuFYN%2Bw%3D&amp;reserved=0
I have "semigrated" to France, see:
   https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.psyctc.org%2Fpelerinage2016%2Fsemigrating-to-france%2F&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=cwexYPBMee0%2FklIejVj%2FmuEPiRcjWrwuQaEX1KzMSHY%3D&amp;reserved=0
That page will also take you to my blog which started with earlier joys in France and Spain!

If you want to book to talk, I am trying to keep that to Thursdays and my diary is at:
   https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.psyctc.org%2Fpelerinage2016%2Fceworkdiary%2F&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=lkiZNYJh6qMaSo%2B%2BfcuFrW0H4fCvANQlKmIZYsQMWoE%3D&amp;reserved=0
Beware: French time, generally an hour ahead of UK.

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Dec 10 17:39:09 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 10 Dec 2019 11:39:09 -0500
Subject: [R] table and unique seems to behave differently
In-Reply-To: <CAM_vju=Htv+LdmYxTYLs2hSaXEn4+nfwd7njpiXbGwJMC_ABvA@mail.gmail.com>
References: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
 <CAM_vju=Htv+LdmYxTYLs2hSaXEn4+nfwd7njpiXbGwJMC_ABvA@mail.gmail.com>
Message-ID: <166dfbe1-2a63-b944-6ae0-f3c3451d6597@gmail.com>

On 10/12/2019 10:32 a.m., Sarah Goslee wrote:
> Back to the table part of the question, but using Duncan's example.
> 
>> x <- c(3.4, 3.4 + 1e-15)
>> unique(x)
> [1] 3.4 3.4
>> table(x)
> x
> 3.4
>    2
> 
> The question was, why are these different.
> 
> table() only works on factors, so it converts the numeric vector to a
> factor before tabulation.
> factor() tries to do something sensible, and implicitly rounds the numeric data.
> 
>> factor(x)
> [1] 3.4 3.4
> Levels: 3.4
> 
> Whether you think that is actually sensible or not is up to you, but
> if it isn't then you shouldn't use table.
> 
> That table uses factors is documented in ?table. A quick read of
> ?factor didn't find any explicit discussion, other than the
> acknowledgement that factor() is lossy in:
> 
>       To transform a factor ?f? to approximately its
>       original numeric values, ?as.numeric(levels(f))[f]? is recommended
>       and slightly more efficient than ?as.numeric(as.character(f))?.
> 
> You can't even get table() to do what you want by being explicit:
> 
>> table(factor(x, levels = unique(x)))
> Error in `levels<-`(`*tmp*`, value = as.character(levels)) :
>    factor level [2] is duplicated

You could get it to agree with unique if you do the string conversion 
yourself.  The first result is ugly:

x <- c(3.4, 3.4 + 1e-15)
tab <- table(sprintf("%a", x))
tab
#>
#> 0x1.b333333333333p+1 0x1.b333333333335p+1
#>                    1                    1

But if you really want you can make it readable:

names(tab) <- as.numeric(names(tab))
tab
#> 3.4 3.4
#>   1   1

Duncan Murdoch


From @|@|n@gu|||et @end|ng |rom uc|ouv@|n@be  Tue Dec 10 17:52:49 2019
From: @|@|n@gu|||et @end|ng |rom uc|ouv@|n@be (Alain Guillet)
Date: Tue, 10 Dec 2019 16:52:49 +0000
Subject: [R] table and unique seems to behave differently
In-Reply-To: <917F59D8-DCA5-4AA5-9463-610338EFF7B5@dcn.davis.ca.us>
References: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
 <17416b21-b5ab-082e-8081-148387f91837@gmail.com>,
 <917F59D8-DCA5-4AA5-9463-610338EFF7B5@dcn.davis.ca.us>
Message-ID: <AM6PR03MB5591D9CFAA6EB10CEF31533C8C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>

Thanks a lot, it answers my question.


Alain
________________________________
De : Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Envoy? : mardi 10 d?cembre 2019 16:31
? : r-help at r-project.org <r-help at r-project.org>; Duncan Murdoch <murdoch.duncan at gmail.com>; Alain Guillet <alain.guillet at uclouvain.be>; r-help at r-project.org <r-help at r-project.org>
Objet : Re: [R] table and unique seems to behave differently

I think the question was about table vs unique. Table groups by character representation, unique groups by the underlying representation.

On December 10, 2019 7:03:34 AM PST, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 10/12/2019 3:53 a.m., Alain Guillet wrote:
>> Hi,
>>
>> I have a vector (see below the dput) and I use unique on it to get
>unique values. If I then sort the result of the vector obtained by
>unique, I see some elements that look like identical. I suspect it
>could be a matter of rounded values but table gives a different result:
>unlike unique output which contains "3.4  3.4", table has only one cell
>for 3.4.
>>
>> Can anybody know why I get results that look like incoherent between
>the two functions?
>
>dput() does some rounding, so it doesn't necessarily reproduce values
>exactly.  For example,
>
>x <- c(3.4, 3.4 + 1e-15)
>unique(x)
>#> [1] 3.4 3.4
>dput(x)
>#> c(3.4, 3.4)
>identical(x, c(3.4, 3.4))
>#> [1] FALSE
>
>If you really want to see exact values, you can use the "hexNumeric"
>option to dput():
>
>dput(x, control = "hexNumeric")
>#> c(0x1.b333333333333p+1, 0x1.b333333333335p+1)
>identical(x, c(0x1.b333333333333p+1, 0x1.b333333333335p+1))
>#> [1] TRUE
>
>Duncan Murdoch
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7C74bb1eeaeb444a6499e508d77d85fba3%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115886725989409&amp;sdata=mU3K2kH%2FAwxdEQ%2BOWVYBhqNLbWGkWzmtfgx92D1DNF8%3D&amp;reserved=0
>PLEASE do read the posting guide
>https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7C74bb1eeaeb444a6499e508d77d85fba3%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115886725989409&amp;sdata=hTxOssdYb%2FcvvSFQyQZ5GBWkpHzsIrbtqJbgCgW2LPw%3D&amp;reserved=0
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Tue Dec 10 18:31:01 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Tue, 10 Dec 2019 09:31:01 -0800
Subject: [R] table and unique seems to behave differently
In-Reply-To: <AM6PR03MB55918A498AB25BDE5E5303338C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
References: <AM6PR03MB5591111EC72C5BE6833E7AD98C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
 <1544858897.12077607.1575988860151.JavaMail.zimbra@psyctc.org>
 <AM6PR03MB55918A498AB25BDE5E5303338C5B0@AM6PR03MB5591.eurprd03.prod.outlook.com>
Message-ID: <CAF8bMcaJ6uV1OHv=sU3sfgXOA7hdQkNPaFZzMOYWZmaUMWh1Fg@mail.gmail.com>

You can use save(ascii=TRUE,...) to make an ascii-only RData file that you
can include in the mail message.  E.g.,

> x <- c(3.4, 3.4 + 1e-15)
> save(x, ascii=TRUE, file=stdout())
RDA3
A
3
198145
197888
5
UTF-8
1026
1
262153
1
x
14
2
3.4
3.400000000000001
254

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Dec 10, 2019 at 8:37 AM Alain Guillet <alain.guillet at uclouvain.be>
wrote:

> Another finding for me today: dput doesn't write exactly the vector that
> creates the problem. I could use an RData file but I think it is forbidden
> in this mailing list...
>
>
> Alain
> ________________________________
> De : Chris Evans <chrishold at psyctc.org>
> Envoy? : mardi 10 d?cembre 2019 15:41
> ? : Alain Guillet <alain.guillet at uclouvain.be>
> Cc : r-help at r-project.org <r-help at r-project.org>
> Objet : Re: [R] table and unique seems to behave differently
>
> This doesn't answer your question but I get exactly the same vector of
> length 210 with unique(toto) and names(table(toto)) using the same version
> of R that you are and I can't see any obvious reason why you wouldn't but
> when I hit things like that it tends to be that one version is string with
> initial or trailing spaces or a character set issue.  I can't see that
> those apply here but it's all I could imagine without racking my poor old
> brains much more.
>
> Good luck finding the answer!
>
> Chris
>
> ----- Original Message -----
> > From: "Alain Guillet" <alain.guillet at uclouvain.be>
> > To: r-help at r-project.org
> > Sent: Tuesday, 10 December, 2019 09:53:29
> > Subject: [R] table and unique seems to behave differently
>
> > Hi,
> >
> > I have a vector (see below the dput) and I use unique on it to get unique
> > values. If I then sort the result of the vector obtained by unique, I
> see some
> > elements that look like identical. I suspect it could be a matter of
> rounded
> > values but table gives a different result: unlike unique output which
> contains
> > "3.4  3.4", table has only one cell for 3.4.
> >
> > Can anybody know why I get results that look like incoherent between the
> two
> > functions?
> >
> >
> > Best regards,
> > Alain Guillet
> >
> > ------------------------------------------
> > platform       x86_64-pc-linux-gnu
> > arch           x86_64
> > os             linux-gnu
> > system         x86_64, linux-gnu
> > status
> > major          3
> > minor          6.1
> > year           2019
> > month          07
> > day            05
> > svn rev        76782
> > language       R
> > version.string R version 3.6.1 (2019-07-05)
> > nickname       Action of the Toes
> > --------------------------------------------------
> >> dput(toto)
> > c(2.5, 2.6, 2.6, 2.6, 2.6, 2.7, 2.7, 2.7, 2.7, 2.7, 2.7, 2.8,
> > 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 2.9, 2.9, 2.9, 2.9, 2.9,
> > 2.9, 2.9, 2.9, 3, 3, 3, 3, 3, 3, 3, 3, 3.1, 3.1, 3.1, 3.1, 3.1,
> > 3.1, 3.1, 3.1, 3.1, 3.1, 3.1, 3.1, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2,
> > 3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.2, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3,
> > 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.3, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4,
> > 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.5,
> > 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6, 3.6,
> > 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6,
> > 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.6, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7,
> > 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7, 3.7,
> > 3.7, 3.7, 3.7, 3.7, 3.7, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8,
> > 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8,
> > 3.8, 3.8, 3.8, 3.8, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9,
> > 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9,
> > 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 3.9, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> > 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> > 4, 4, 4, 4, 4, 4, 4, 4, 4, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
> > 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
> > 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1, 4.1,
> > 4.1, 4.1, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2,
> > 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2,
> > 4.2, 4.2, 4.2, 4.2, 4.2, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3,
> > 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3,
> > 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.3, 4.4, 4.4, 4.4, 4.4,
> > 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4,
> > 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4, 4.4,
> > 4.4, 4.4, 4.4, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
> > 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
> > 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5,
> > 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.6,
> > 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
> > 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
> > 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6, 4.6,
> > 4.6, 4.6, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
> > 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
> > 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7,
> > 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.8, 4.8, 4.8, 4.8, 4.8,
> > 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8,
> > 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8,
> > 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.8, 4.9, 4.9, 4.9, 4.9, 4.9,
> > 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> > 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> > 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> > 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9, 4.9,
> > 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
> > 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5.1, 5.1, 5.1,
> > 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
> > 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
> > 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.1,
> > 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2,
> > 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2,
> > 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.2, 5.3, 5.3, 5.3, 5.3, 5.3,
> > 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
> > 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
> > 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3, 5.3,
> > 5.3, 5.3, 5.3, 5.3, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
> > 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
> > 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4,
> > 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.4, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
> > 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
> > 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5,
> > 5.5, 5.5, 5.5, 5.5, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
> > 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
> > 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6,
> > 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.6, 5.7, 5.7, 5.7, 5.7, 5.7,
> > 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7,
> > 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7,
> > 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.8, 5.8, 5.8, 5.8,
> > 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
> > 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
> > 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8, 5.8,
> > 5.8, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
> > 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
> > 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9, 5.9,
> > 5.9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
> > 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6.1,
> > 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1,
> > 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1,
> > 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.1, 6.2,
> > 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
> > 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
> > 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2, 6.2,
> > 6.2, 6.2, 6.2, 6.2, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
> > 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
> > 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3, 6.3,
> > 6.3, 6.3, 6.3, 6.3, 6.3, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
> > 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
> > 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4,
> > 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.4, 6.5, 6.5,
> > 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5,
> > 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5,
> > 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.6, 6.6, 6.6, 6.6,
> > 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6,
> > 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6,
> > 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.6, 6.7, 6.7, 6.7, 6.7,
> > 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7,
> > 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7,
> > 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.7, 6.8, 6.8, 6.8,
> > 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
> > 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
> > 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8,
> > 6.8, 6.8, 6.8, 6.8, 6.8, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
> > 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
> > 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9, 6.9,
> > 6.9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
> > 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7.1, 7.1, 7.1, 7.1,
> > 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1,
> > 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1, 7.1,
> > 7.1, 7.1, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2,
> > 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2,
> > 7.2, 7.2, 7.2, 7.2, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3,
> > 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3,
> > 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.3, 7.4, 7.4,
> > 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4,
> > 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.5, 7.5, 7.5, 7.5,
> > 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5,
> > 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.6,
> > 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6,
> > 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6,
> > 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7,
> > 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.8, 7.8, 7.8,
> > 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8, 7.8,
> > 7.8, 7.8, 7.8, 7.8, 7.8, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9,
> > 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9, 7.9,
> > 7.9, 7.9, 7.9, 7.9, 7.9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
> > 8, 8, 8, 8, 8, 8, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1,
> > 8.1, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2,
> > 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.2, 8.3, 8.3, 8.3, 8.3,
> > 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.3, 8.4, 8.4, 8.4, 8.4,
> > 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.4, 8.5, 8.5,
> > 8.5, 8.5, 8.5, 8.5, 8.5, 8.5, 8.6, 8.6, 8.6, 8.6, 8.6, 8.6, 8.6,
> > 8.6, 8.6, 8.6, 8.6, 8.6, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7, 8.7,
> > 8.7, 8.7, 8.7, 8.7, 8.7, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8, 8.8,
> > 8.8, 8.8, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9,
> > 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 9, 9, 9, 9, 9, 9, 9, 9, 9.1, 9.1,
> > 9.1, 9.1, 9.1, 9.1, 9.1, 9.1, 9.2, 9.2, 9.2, 9.2, 9.2, 9.2, 9.2,
> > 9.2, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3, 9.3,
> > 9.3, 9.3, 9.3, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.4, 9.5, 9.5,
> > 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.5,
> > 9.5, 9.5, 9.5, 9.5, 9.5, 9.5, 9.6, 9.6, 9.6, 9.6, 9.6, 9.6, 9.6,
> > 9.6, 9.6, 9.6, 9.6, 9.6, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7,
> > 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.8,
> > 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9,
> > 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 10, 10, 10,
> > 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10.1,
> > 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1, 10.1,
> > 10.1, 10.1, 10.1, 10.1, 10.1, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2,
> > 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.3,
> > 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3, 10.3,
> > 10.3, 10.3, 10.3, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4,
> > 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4, 10.4,
> > 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5,
> > 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.6, 10.6, 10.6, 10.6, 10.6,
> > 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6, 10.6,
> > 10.6, 10.6, 10.6, 10.6, 10.6, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
> > 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
> > 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7,
> > 10.7, 10.7, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8, 10.8,
> > 10.8, 10.8, 10.8, 10.8, 10.8, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9,
> > 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9,
> > 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 10.9, 11, 11, 11, 11, 11,
> > 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,
> > 11, 11, 11, 11, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1,
> > 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1, 11.1,
> > 11.1, 11.1, 11.1, 11.1, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
> > 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
> > 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 11.2,
> > 11.2, 11.2, 11.2, 11.2, 11.2, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> > 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> > 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> > 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> > 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3, 11.3,
> > 11.3, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> > 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> > 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> > 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4, 11.4,
> > 11.4, 11.4, 11.4, 11.4, 11.4, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> > 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> > 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> > 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> > 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5,
> > 11.5, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> > 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> > 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> > 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> > 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6,
> > 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> > 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> > 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> > 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7,
> > 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.7, 11.8, 11.8,
> > 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> > 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> > 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> > 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8,
> > 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.8, 11.9, 11.9,
> > 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> > 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> > 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> > 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> > 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9, 11.9,
> > 11.9, 11.9, 11.9, 11.9, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> > 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> > 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> > 12, 12, 12, 12, 12, 12, 12, 12, 12.1, 12.1, 12.1, 12.1, 12.1,
> > 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> > 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> > 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> > 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> > 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1,
> > 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.1, 12.2,
> > 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> > 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> > 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> > 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> > 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2,
> > 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.2, 12.3, 12.3, 12.3,
> > 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> > 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> > 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> > 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> > 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> > 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.3,
> > 12.3, 12.3, 12.3, 12.3, 12.3, 12.3, 12.4, 12.4, 12.4, 12.4, 12.4,
> > 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> > 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> > 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> > 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> > 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4, 12.4,
> > 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> > 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> > 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> > 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> > 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> > 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5,
> > 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.6, 12.6, 12.6, 12.6, 12.6,
> > 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> > 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> > 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> > 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> > 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6, 12.6,
> > 12.6, 12.6, 12.6, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> > 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> > 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> > 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> > 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7, 12.7,
> > 12.7, 12.7, 12.7, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> > 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> > 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> > 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> > 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> > 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> > 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8, 12.8,
> > 12.8, 12.8, 12.8, 12.8, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> > 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> > 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> > 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> > 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9,
> > 12.9, 12.9, 12.9, 12.9, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> > 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> > 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> > 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> > 13, 13, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> > 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> > 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> > 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> > 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> > 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1, 13.1,
> > 13.1, 13.1, 13.1, 13.1, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> > 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> > 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> > 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> > 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> > 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> > 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.2,
> > 13.2, 13.2, 13.2, 13.2, 13.2, 13.2, 13.3, 13.3, 13.3, 13.3, 13.3,
> > 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> > 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> > 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> > 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> > 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3,
> > 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.3, 13.4,
> > 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> > 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> > 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> > 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> > 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.4,
> > 13.4, 13.4, 13.4, 13.4, 13.4, 13.4, 13.5, 13.5, 13.5, 13.5, 13.5,
> > 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> > 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> > 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> > 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> > 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> > 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5, 13.5,
> > 13.5, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> > 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> > 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> > 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> > 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> > 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6, 13.6,
> > 13.6, 13.6, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> > 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> > 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> > 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> > 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> > 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> > 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7, 13.7,
> > 13.7, 13.7, 13.7, 13.7, 13.7, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> > 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> > 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> > 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> > 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> > 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> > 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8,
> > 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.8, 13.9, 13.9, 13.9, 13.9,
> > 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> > 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> > 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> > 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> > 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> > 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9, 13.9,
> > 13.9, 13.9, 13.9, 13.9, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> > 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> > 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> > 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> > 14, 14, 14, 14, 14, 14, 14, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> > 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> > 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> > 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> > 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1,
> > 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.1, 14.2, 14.2, 14.2,
> > 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> > 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> > 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> > 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> > 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> > 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2, 14.2,
> > 14.2, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> > 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> > 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> > 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> > 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> > 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3, 14.3,
> > 14.3, 14.3, 14.3, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> > 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> > 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> > 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> > 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> > 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4, 14.4,
> > 14.4, 14.4, 14.4, 14.4, 14.4, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> > 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> > 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> > 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> > 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5,
> > 14.5, 14.5, 14.5, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> > 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> > 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> > 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> > 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6,
> > 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.6, 14.7, 14.7,
> > 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> > 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> > 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> > 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> > 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7, 14.7,
> > 14.7, 14.7, 14.7, 14.7, 14.7, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> > 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> > 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> > 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> > 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8, 14.8,
> > 14.8, 14.8, 14.8, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> > 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> > 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> > 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> > 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9, 14.9,
> > 14.9, 14.9, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
> > 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
> > 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15.1,
> > 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> > 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> > 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> > 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1, 15.1,
> > 15.1, 15.1, 15.1, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> > 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> > 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> > 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2, 15.2,
> > 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> > 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> > 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> > 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3, 15.3,
> > 15.3, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4,
> > 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4,
> > 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.4, 15.5,
> > 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
> > 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
> > 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5,
> > 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.5, 15.6, 15.6,
> > 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6,
> > 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6,
> > 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.6, 15.7, 15.7, 15.7,
> > 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
> > 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
> > 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7, 15.7,
> > 15.7, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8,
> > 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8, 15.8,
> > 15.8, 15.8, 15.8, 15.8, 15.8, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9,
> > 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9, 15.9,
> > 15.9, 15.9, 15.9, 15.9, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
> > 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
> > 16, 16, 16, 16, 16, 16, 16, 16, 16, 16.1, 16.1, 16.1, 16.1, 16.1,
> > 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1,
> > 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.1, 16.2,
> > 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2,
> > 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.2, 16.3, 16.3,
> > 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3,
> > 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.3, 16.4,
> > 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4,
> > 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4, 16.4,
> > 16.4, 16.4, 16.4, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5,
> > 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.6, 16.6,
> > 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6,
> > 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.7, 16.7, 16.7, 16.7,
> > 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7, 16.7,
> > 16.7, 16.7, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8,
> > 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.8, 16.9, 16.9, 16.9,
> > 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9,
> > 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 16.9, 17, 17,
> > 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,
> > 17, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.1, 17.2,
> > 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2, 17.2,
> > 17.2, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3, 17.3,
> > 17.3, 17.3, 17.3, 17.4, 17.4, 17.4, 17.4, 17.4, 17.4, 17.4, 17.5,
> > 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5, 17.5,
> > 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.6, 17.7, 17.7, 17.7,
> > 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.8, 17.8, 17.8, 17.8,
> > 17.8, 17.8, 17.8, 17.8, 17.8, 17.9, 17.9, 17.9, 17.9, 17.9, 17.9,
> > 17.9, 17.9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,
> > 18, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.1, 18.2, 18.2,
> > 18.2, 18.2, 18.2, 18.2, 18.2, 18.2, 18.2, 18.3, 18.3, 18.3, 18.3,
> > 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.3, 18.4, 18.4, 18.4,
> > 18.4, 18.4, 18.4, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5, 18.5,
> > 18.5, 18.6, 18.7, 18.7, 18.7, 18.7, 18.8, 18.8, 18.8, 18.8, 18.8,
> > 18.8, 18.8, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9, 18.9,
> > 18.9, 19, 19, 19, 19, 19, 19.1, 19.1, 19.1, 19.1, 19.1, 19.1,
> > 19.1, 19.2, 19.2, 19.2, 19.2, 19.2, 19.2, 19.3, 19.3, 19.3, 19.3,
> > 19.4, 19.4, 19.4, 19.4, 19.4, 19.5, 19.5, 19.5, 19.5, 19.6, 19.7,
> > 19.7, 19.7, 19.7, 19.7, 19.7, 19.7, 19.8, 19.8, 19.8, 19.8, 19.8,
> > 20.1, 20.1, 20.1, 20.1, 20.1, 20.2, 20.2, 20.3, 20.4, 20.5, 20.5,
> > 20.5, 20.6, 20.6, 20.6, 20.6, 20.7, 20.7, 20.7, 20.8, 20.8, 20.9,
> > 20.9, 20.9, 20.9, 21, 21.1, 21.2, 21.2, 21.2, 21.3, 21.3, 21.3,
> > 21.4, 21.5, 21.5, 21.5, 21.6, 21.6, 21.6, 21.6, 21.9, 21.9, 22,
> > 22.1, 22.2, 22.4, 22.4, 22.5, 22.6, 22.7, 22.7, 22.7, 23.1, 23.2,
> > 23.2, 23.5, 23.6, 23.7, 23.8, 23.8, 24.6, 25, 26.3, 26.8, 27,
> > 27.2)
> >> sort(unique(toto))
> >  [1]  2.5  2.6  2.7  2.8  2.9  3.0  3.1  3.2  3.3  3.4  3.4  3.5  3.6
> 3.6  3.7
> >  3.8  3.8  3.9  3.9
> > [20]  4.0  4.1  4.1  4.2  4.2  4.3  4.3  4.4  4.5  4.6  4.6  4.7  4.7
> 4.8  4.8
> > 4.9  5.0  5.0  5.1
> > [39]  5.1  5.2  5.2  5.3  5.3  5.4  5.5  5.5  5.6  5.6  5.7  5.7  5.8
> 5.8  5.9
> > 6.0  6.0  6.1  6.1
> > [58]  6.2  6.2  6.3  6.3  6.4  6.4  6.5  6.5  6.6  6.6  6.7  6.7  6.7
> 6.8  6.8
> > 6.9  6.9  7.0  7.0
> > [77]  7.1  7.1  7.1  7.2  7.2  7.3  7.3  7.4  7.4  7.5  7.5  7.6  7.6
> 7.7  7.7
> > 7.8  7.8  7.9  8.0
> > [96]  8.1  8.1  8.2  8.2  8.3  8.4  8.5  8.6  8.6  8.7  8.7  8.8  8.8
> 8.9  8.9
> > 9.0  9.1  9.1  9.2
> > [115]  9.2  9.3  9.3  9.4  9.4  9.5  9.5  9.6  9.6  9.7  9.7  9.8  9.9
> 9.9 10.0
> > 10.0 10.1 10.1 10.2
> > [134] 10.2 10.3 10.3 10.4 10.4 10.5 10.5 10.6 10.6 10.7 10.7 10.8 10.8
> 10.9 10.9
> > 11.0 11.0 11.1 11.1
> > [153] 11.2 11.2 11.3 11.3 11.4 11.4 11.5 11.5 11.6 11.6 11.7 11.7 11.8
> 11.8 11.8
> > 11.9 11.9 11.9 12.0
> > [172] 12.0 12.1 12.1 12.2 12.2 12.3 12.3 12.4 12.4 12.4 12.5 12.5 12.6
> 12.6 12.7
> > 12.7 12.8 12.8 12.9
> > [191] 12.9 12.9 13.0 13.0 13.1 13.1 13.2 13.2 13.3 13.3 13.3 13.4 13.4
> 13.4 13.5
> > 13.5 13.6 13.6 13.6
> > [210] 13.7 13.7 13.8 13.8 13.8 13.9 13.9 13.9 14.0 14.0 14.1 14.1 14.2
> 14.2 14.3
> > 14.3 14.3 14.4 14.4
> > [229] 14.4 14.5 14.5 14.6 14.6 14.7 14.7 14.8 14.8 14.8 14.9 14.9 14.9
> 15.0 15.0
> > 15.1 15.1 15.2 15.2
> > [248] 15.2 15.3 15.3 15.3 15.4 15.4 15.4 15.5 15.5 15.6 15.6 15.7 15.7
> 15.8 15.8
> > 15.8 15.9 15.9 15.9
> > [267] 16.0 16.1 16.1 16.2 16.2 16.3 16.3 16.4 16.4 16.5 16.6 16.6 16.7
> 16.7 16.8
> > 16.8 16.9 16.9 17.0
> > [286] 17.1 17.1 17.2 17.2 17.3 17.3 17.4 17.5 17.6 17.6 17.7 17.7 17.8
> 17.8 17.9
> > 18.0 18.1 18.1 18.2
> > [305] 18.2 18.3 18.3 18.4 18.5 18.6 18.7 18.8 18.8 18.9 19.0 19.1 19.2
> 19.2 19.3
> > 19.3 19.4 19.4 19.5
> > [324] 19.6 19.7 19.7 19.8 19.8 20.1 20.1 20.2 20.3 20.4 20.5 20.6 20.6
> 20.7 20.8
> > 20.9 21.0 21.1 21.2
> > [343] 21.2 21.3 21.3 21.4 21.5 21.6 21.6 21.9 22.0 22.1 22.2 22.4 22.5
> 22.6 22.7
> > 22.7 23.1 23.2 23.5
> > [362] 23.6 23.7 23.8 23.8 24.6 25.0 26.3 26.8 27.0 27.2
> >> table(toto)
> > toto
> > 2.5  2.6  2.7  2.8  2.9    3  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8
> 3.9    4
> > 4.1  4.2  4.3  4.4
> >   1    4    6    9    8    8   12   13   13   14   15   23   24   25
>  29   39
> >   35   29   30   33
> > 4.5  4.6  4.7  4.8  4.9    5  5.1  5.2  5.3  5.4  5.5  5.6  5.7  5.8
> 5.9    6
> > 6.1  6.2  6.3  6.4
> >  48   42   45   39   57   37   42   34   48   42   36   43   40   44
>  39   38
> >  39   44   40   45
> > 6.5  6.6  6.7  6.8  6.9    7  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8
> 7.9    8
> > 8.1  8.2  8.3  8.4
> >  37   39   40   47   35   34   32   28   33   24   29   27   23   21
>  26   18
> >  10   21   13   15
> > 8.5  8.6  8.7  8.8  8.9    9  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8
> 9.9   10
> > 10.1 10.2 10.3 10.4
> >   8   12   13   10   17    8    8    8   15    8   21   12   20    8
>  16   17
> >   17   16   15   19
> > 10.5 10.6 10.7 10.8 10.9   11 11.1 11.2 11.3 11.4 11.5 11.6 11.7 11.8
> 11.9   12
> > 12.1 12.2 12.3 12.4
> >  17   21   30   14   24   25   23   34   51   48   51   54   53   55
>  61   50
> >  70   64   75   60
> > 12.5 12.6 12.7 12.8 12.9   13 13.1 13.2 13.3 13.4 13.5 13.6 13.7 13.8
> 13.9   14
> > 14.1 14.2 14.3 14.4
> >  72   63   55   78   55   60   68   79   70   62   72   67   80   79
>  74   65
> >  58   70   68   68
> > 14.5 14.6 14.7 14.8 14.9   15 15.1 15.2 15.3 15.4 15.5 15.6 15.7 15.8
> 15.9   16
> > 16.1 16.2 16.3 16.4
> >  53   61   62   53   54   44   48   41   45   31   43   32   37   26
>  21   35
> >  26   21   23   26
> > 16.5 16.6 16.7 16.8 16.9   17 17.1 17.2 17.3 17.4 17.5 17.6 17.7 17.8
> 17.9   18
> > 18.1 18.2 18.3 18.4
> >  17   20   17   17   23   19    9   13   13    7   12    8   10    9
> 8   14
> >  8    9   12    6
> > 18.5 18.6 18.7 18.8 18.9   19 19.1 19.2 19.3 19.4 19.5 19.6 19.7 19.8
> 20.1 20.2
> > 20.3 20.4 20.5 20.6
> >   9    1    4    7   10    5    7    6    4    5    4    1    7    5
> 5    2
> >   1    1    3    4
> > 20.7 20.8 20.9   21 21.1 21.2 21.3 21.4 21.5 21.6 21.9   22 22.1 22.2
> 22.4 22.5
> > 22.6 22.7 23.1 23.2
> >   3    2    4    1    1    3    3    1    3    4    2    1    1    1
> 2    1
> >   1    3    1    2
> > 23.5 23.6 23.7 23.8 24.6   25 26.3 26.8   27 27.2
> >   1    1    1    2    1    1    1    1    1    1
> >
> >
> >
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=YIMb5atD3i74G%2BDxPESqCc8vrymCbcvP3zqXrVPYjHE%3D&amp;reserved=0
> > PLEASE do read the posting guide
> https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=ht2yjUUhIHsy0ll1NRhmFNbsegVIr6KiZR1CB7MWjCE%3D&amp;reserved=0
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Chris Evans <chris at psyctc.org> Visiting Professor, University of
> Sheffield <chris.evans at sheffield.ac.uk>
> I do some consultation work for the University of Roehampton <
> chris.evans at roehampton.ac.uk> and other places
> but <chris at psyctc.org> remains my main Email address.  I have a work web
> site at:
>
> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.psyctc.org%2Fpsyctc%2F&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=H3N6FpuTiA2RhVlsYZ3DL8%2FaRQeJ0uJHFXMeEQQ8Myk%3D&amp;reserved=0
> and a site I manage for CORE and CORE system trust at:
>
> https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.coresystemtrust.org.uk%2F&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=oqR8YAMqCOWaqt3%2Fph9Iw45jTQjowwPixOfgOuFYN%2Bw%3D&amp;reserved=0
> I have "semigrated" to France, see:
>
> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.psyctc.org%2Fpelerinage2016%2Fsemigrating-to-france%2F&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=cwexYPBMee0%2FklIejVj%2FmuEPiRcjWrwuQaEX1KzMSHY%3D&amp;reserved=0
> That page will also take you to my blog which started with earlier joys in
> France and Spain!
>
> If you want to book to talk, I am trying to keep that to Thursdays and my
> diary is at:
>
> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.psyctc.org%2Fpelerinage2016%2Fceworkdiary%2F&amp;data=02%7C01%7C%7Cf5cc7176e30842e1013e08d77d7efb2f%7C7ab090d4fa2e4ecfbc7c4127b4d582ec%7C0%7C0%7C637115856659242341&amp;sdata=lkiZNYJh6qMaSo%2B%2BfcuFrW0H4fCvANQlKmIZYsQMWoE%3D&amp;reserved=0
> Beware: French time, generally an hour ahead of UK.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @p@ynebu @end|ng |rom gm@||@com  Tue Dec 10 17:09:21 2019
From: @p@ynebu @end|ng |rom gm@||@com (Sarah Payne)
Date: Tue, 10 Dec 2019 11:09:21 -0500
Subject: [R] Data Structure to Unnest_tokens in tidytext package
Message-ID: <CANB4snrh5HfM97ABu0w+8VpS+VBC0=ukQ8ago-UHCtsH51XpTg@mail.gmail.com>

Hi--I'm fairly new to R and trying to do a text mining project on a novel
using the tidytext package. The novel is saved as a plain text document and
I can import it into RStudio just fine. For reference I'm trying to do
something similar to section 1.3 of this tidy text tutorial
<https://www.tidytextmining.com/tidytext.html>, except I'm working with one
novel instead of many. So I import the novel and then run:

"tidy_novel <- quicksandr %>%
unnest_tokens (word, text)"

I get the following error:

Error in check_input(x) :
  Input must be a character vector of any length or a list of character
  vectors, each of which has a length of 1.

typeof(novel) returns "list" and str(novel) returns

Classes ?spec_tbl_df?, ?tbl_df?, ?tbl? and 'data.frame': 955 obs. of  1
variable:
 $ FOR E. S. I.: chr  "FOR E. S. I." "My old man died in a fine big house.
My ma died in a shack. I wonder where I'm gonna die, Being neither white
nor black?'" "LANGSTON HUGHES" "ONE" ...
 - attr(*, "problems")=Classes ?tbl_df?, ?tbl? and 'data.frame': 8 obs. of
 5 variables:
  ..$ row     : int  530 726 733 836 853 886 889 942
  ..$ col     : chr  NA NA NA NA ...
  ..$ expected: chr  "1 columns" "1 columns" "1 columns" "1 columns" ...
  ..$ actual  : chr  "2 columns" "2 columns" "2 columns" "2 columns" ...
  ..$ file    : chr  "'quicksandr.txt'" "'quicksandr.txt'"
"'quicksandr.txt'" "'quicksandr.txt'" ...
 - attr(*, "spec")=
  .. cols(
  ..   `FOR E. S. I.` = col_character()
  .. )
>

I'm just importing the text file and then trying to run the unnest_tokens
function, so maybe I'm missing a step in between? I seem to need my text
file in a different format, so would appreciate answers on how to do that.
Thanks, and let me know if I need to provide more info!

	[[alternative HTML version deleted]]


From j@vedbtk111 @end|ng |rom gm@||@com  Wed Dec 11 10:51:07 2019
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Wed, 11 Dec 2019 10:51:07 +0100
Subject: [R] tuning values of SVM
Message-ID: <CAJhui+vAM+6=pKcUz9tobjFS3svce1YYvNK9usB_+r+dDx31Kw@mail.gmail.com>

I want to optimize the cost and sigma parameters of SVM using Caret and
PSO. The following code I am using after imported the data.

svm_obj <- function(param, maximize = FALSE) {
  mod <- train(log10(Effort) ~ ., data = tr,
               method = "svmRadial",
               preProc = c("center", "scale", "zv"),
               metric = "MAE",
               trControl = ctrl,
               tuneGrid = data.frame(C = 10^(param[1]), sigma =
10^(param[2])))
  if(maximize)
    -getTrainPerf(mod)[, "TrainRMSE"] else
      getTrainPerf(mod)[, "TrainRMSE"]
}
  num_mods <- 10

And for the PSO, the following code

library(pso)
  set.seed(45642)
  pso_res <- psoptim(par = c(0, 0), fn = svm_obj,
                     lower = c(0.2, 4), upper = c(0.1, 0.9),
                     control = list(maxit = ceiling(num_mods)))
  pso_res

Now, it gives me the result but when I try to get the optimal values of C
and sigma using pso_res$par, it gives me the values:

0.1 and 0.9

The minimum value I provided for C is 0.2 (and maximum value is 4 as shown
above), but how can it give me the optimal value 0.1, which is even lower
than the minimum provided value.

Where I am doing mistake?

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Dec 11 11:22:38 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 11 Dec 2019 02:22:38 -0800
Subject: [R] tuning values of SVM
In-Reply-To: <CAJhui+vAM+6=pKcUz9tobjFS3svce1YYvNK9usB_+r+dDx31Kw@mail.gmail.com>
References: <CAJhui+vAM+6=pKcUz9tobjFS3svce1YYvNK9usB_+r+dDx31Kw@mail.gmail.com>
Message-ID: <CAGxFJbQSUyg7NSBPW2+VsSro7-hCuqvHdnnAL9Z7vVT9tfpCMg@mail.gmail.com>

You have:

lower = c(0.2, 4), upper = c(0.1, 0.9)

Isn't this backwards? -- you need to switch lower and upper


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Dec 11, 2019 at 1:53 AM javed khan <javedbtk111 at gmail.com> wrote:

> I want to optimize the cost and sigma parameters of SVM using Caret and
> PSO. The following code I am using after imported the data.
>
> svm_obj <- function(param, maximize = FALSE) {
>   mod <- train(log10(Effort) ~ ., data = tr,
>                method = "svmRadial",
>                preProc = c("center", "scale", "zv"),
>                metric = "MAE",
>                trControl = ctrl,
>                tuneGrid = data.frame(C = 10^(param[1]), sigma =
> 10^(param[2])))
>   if(maximize)
>     -getTrainPerf(mod)[, "TrainRMSE"] else
>       getTrainPerf(mod)[, "TrainRMSE"]
> }
>   num_mods <- 10
>
> And for the PSO, the following code
>
> library(pso)
>   set.seed(45642)
>   pso_res <- psoptim(par = c(0, 0), fn = svm_obj,
>                      lower = c(0.2, 4), upper = c(0.1, 0.9),
>                      control = list(maxit = ceiling(num_mods)))
>   pso_res
>
> Now, it gives me the result but when I try to get the optimal values of C
> and sigma using pso_res$par, it gives me the values:
>
> 0.1 and 0.9
>
> The minimum value I provided for C is 0.2 (and maximum value is 4 as shown
> above), but how can it give me the optimal value 0.1, which is even lower
> than the minimum provided value.
>
> Where I am doing mistake?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@h|mk@poor @end|ng |rom gm@||@com  Wed Dec 11 12:37:53 2019
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Wed, 11 Dec 2019 17:07:53 +0530
Subject: [R] Tables from Rmarkdown to Word Document - using huxtables
Message-ID: <CAC8=1er0F+VHTR7PGpwE2Wd1J8d6TTq7pzypbP3Hdk8xdOw8AQ@mail.gmail.com>

Dear All,

I am reading this :-

https://hughjonesd.github.io/huxtable/huxtable.html

I quote from the above:

If you want to create Word or Powerpoint documents, install the flextable
package <https://cran.r-project.org/package=flextable> from CRAN. Huxtables
can then be automatically printed in Word documents. Or you can convert
them to flextable objects and include them in Word or Powerpoint documents.

My query is how do I do the former ? How do I do this --->  Huxtables can
then be automatically printed in Word documents.

I do understand how to do this ---> Or you can convert them to flextable
objects and include them in Word or Powerpoint documents.

Thank you,
Ashim

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Dec 11 16:22:56 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 11 Dec 2019 17:22:56 +0200
Subject: [R] Data Structure to Unnest_tokens in tidytext package
In-Reply-To: <CANB4snrh5HfM97ABu0w+8VpS+VBC0=ukQ8ago-UHCtsH51XpTg@mail.gmail.com>
References: <CANB4snrh5HfM97ABu0w+8VpS+VBC0=ukQ8ago-UHCtsH51XpTg@mail.gmail.com>
Message-ID: <CAGgJW75Oq2oE_ExYnJVfp-q+whR03Mr+yy0pAPqCYuYgqdUVBA@mail.gmail.com>

Hi Sarah,
I looked at the documentation that you linked to. It contains the step

text_df <- tibble(line = 1:4, text = text)

before it does the step

text_df %>%
  unnest_tokens(word, text)

So you may be missing a step.

Best,
Eric

On Tue, Dec 10, 2019 at 9:05 PM Sarah Payne <spaynebu at gmail.com> wrote:
>
> Hi--I'm fairly new to R and trying to do a text mining project on a novel
> using the tidytext package. The novel is saved as a plain text document and
> I can import it into RStudio just fine. For reference I'm trying to do
> something similar to section 1.3 of this tidy text tutorial
> <https://www.tidytextmining.com/tidytext.html>, except I'm working with one
> novel instead of many. So I import the novel and then run:
>
> "tidy_novel <- quicksandr %>%
> unnest_tokens (word, text)"
>
> I get the following error:
>
> Error in check_input(x) :
>   Input must be a character vector of any length or a list of character
>   vectors, each of which has a length of 1.
>
> typeof(novel) returns "list" and str(novel) returns
>
> Classes ?spec_tbl_df?, ?tbl_df?, ?tbl? and 'data.frame': 955 obs. of  1
> variable:
>  $ FOR E. S. I.: chr  "FOR E. S. I." "My old man died in a fine big house.
> My ma died in a shack. I wonder where I'm gonna die, Being neither white
> nor black?'" "LANGSTON HUGHES" "ONE" ...
>  - attr(*, "problems")=Classes ?tbl_df?, ?tbl? and 'data.frame': 8 obs. of
>  5 variables:
>   ..$ row     : int  530 726 733 836 853 886 889 942
>   ..$ col     : chr  NA NA NA NA ...
>   ..$ expected: chr  "1 columns" "1 columns" "1 columns" "1 columns" ...
>   ..$ actual  : chr  "2 columns" "2 columns" "2 columns" "2 columns" ...
>   ..$ file    : chr  "'quicksandr.txt'" "'quicksandr.txt'"
> "'quicksandr.txt'" "'quicksandr.txt'" ...
>  - attr(*, "spec")=
>   .. cols(
>   ..   `FOR E. S. I.` = col_character()
>   .. )
> >
>
> I'm just importing the text file and then trying to run the unnest_tokens
> function, so maybe I'm missing a step in between? I seem to need my text
> file in a different format, so would appreciate answers on how to do that.
> Thanks, and let me know if I need to provide more info!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Dec 11 16:41:30 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 11 Dec 2019 15:41:30 +0000
Subject: [R] Tables from Rmarkdown to Word Document - using huxtables
In-Reply-To: <CAC8=1er0F+VHTR7PGpwE2Wd1J8d6TTq7pzypbP3Hdk8xdOw8AQ@mail.gmail.com>
References: <CAC8=1er0F+VHTR7PGpwE2Wd1J8d6TTq7pzypbP3Hdk8xdOw8AQ@mail.gmail.com>
Message-ID: <be551887-4479-07e9-49b9-727b278327c9@sapo.pt>

Hello,

This works for me:


library(dplyr)
library(huxtable)
library(flextable)
library(officer)

hx <- iris %>%
   group_by(Species) %>%
   summarise_if(is.numeric, mean) %>%
   as_hux() %>%
   add_colnames() %>%
   set_bold(1, , TRUE) %>%
   set_bottom_border(1, , 1) %>%
   set_width(0.99) %>%
   set_col_width(1:5, 0.99) %>%
   set_number_format(2)

hx

quick_docx(hx, file = "test.docx")


There are ways of doing the same without pipes, those functions don't 
have the prefix 'set_'. But I believe that what's important is function 
?quick_docx.

Hope this helps,

Rui Barradas

?s 11:37 de 11/12/19, Ashim Kapoor escreveu:
> Dear All,
> 
> I am reading this :-
> 
> https://hughjonesd.github.io/huxtable/huxtable.html
> 
> I quote from the above:
> 
> If you want to create Word or Powerpoint documents, install the flextable
> package <https://cran.r-project.org/package=flextable> from CRAN. Huxtables
> can then be automatically printed in Word documents. Or you can convert
> them to flextable objects and include them in Word or Powerpoint documents.
> 
> My query is how do I do the former ? How do I do this --->  Huxtables can
> then be automatically printed in Word documents.
> 
> I do understand how to do this ---> Or you can convert them to flextable
> objects and include them in Word or Powerpoint documents.
> 
> Thank you,
> Ashim
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Dec 12 08:27:40 2019
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 12 Dec 2019 12:57:40 +0530
Subject: [R] Tables from Rmarkdown to Word Document - using huxtables
In-Reply-To: <be551887-4479-07e9-49b9-727b278327c9@sapo.pt>
References: <CAC8=1er0F+VHTR7PGpwE2Wd1J8d6TTq7pzypbP3Hdk8xdOw8AQ@mail.gmail.com>
 <be551887-4479-07e9-49b9-727b278327c9@sapo.pt>
Message-ID: <CAC8=1epj-0m2oJ5ouj02qUsCVuW=TNMOvTAZyQmY4D0fwXvsJQ@mail.gmail.com>

On Wed, Dec 11, 2019 at 9:11 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> This works for me:
>
>
> library(dplyr)
> library(huxtable)
> library(flextable)
> library(officer)
>
> hx <- iris %>%
>    group_by(Species) %>%
>    summarise_if(is.numeric, mean) %>%
>    as_hux() %>%
>    add_colnames() %>%
>    set_bold(1, , TRUE) %>%
>    set_bottom_border(1, , 1) %>%
>    set_width(0.99) %>%
>    set_col_width(1:5, 0.99) %>%
>    set_number_format(2)
>
> hx
>
> quick_docx(hx, file = "test.docx")
>
>
Does set_width work for you ? For me modifying the argument to set_width is
NOT working.


> There are ways of doing the same without pipes, those functions don't
> have the prefix 'set_'. But I believe that what's important is function
> ?quick_docx.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 11:37 de 11/12/19, Ashim Kapoor escreveu:
> > Dear All,
> >
> > I am reading this :-
> >
> > https://hughjonesd.github.io/huxtable/huxtable.html
> >
> > I quote from the above:
> >
> > If you want to create Word or Powerpoint documents, install the flextable
> > package <https://cran.r-project.org/package=flextable> from CRAN.
> Huxtables
> > can then be automatically printed in Word documents. Or you can convert
> > them to flextable objects and include them in Word or Powerpoint
> documents.
> >
> > My query is how do I do the former ? How do I do this --->  Huxtables can
> > then be automatically printed in Word documents.
> >
> > I do understand how to do this ---> Or you can convert them to flextable
> > objects and include them in Word or Powerpoint documents.
> >
> > Thank you,
> > Ashim
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Thu Dec 12 10:56:30 2019
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Thu, 12 Dec 2019 09:56:30 +0000
Subject: [R] R 3.6.2 is released
Message-ID: <7F4152E4-727E-46C0-85D9-7318EB980FAB@cbs.dk>

The build system rolled up R-3.6.2.tar.gz (codename "Dark and Stormy Night") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.6.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 28a3942a7129877e9af1d5ea16202052
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 45437b38c75e0248b527c00e6d42ee6a
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 591dcf615162127f904e4e461f330ce9
MD5 (R-latest.tar.gz) = 90d23d138cee26d275da14b58296e521
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = bb45f89c01d509721c47fd41f147da60
MD5 (VERSION-INFO.dcf) = 9c33701e25092aefc1d16beb5858f20f
MD5 (R-3/R-3.6.2.tar.gz) = 90d23d138cee26d275da14b58296e521


2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
38219d9c6221ccfbf075ef03711b420a1aa8731f890c8f2337148b602a217c2d  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
0ceb6fbab3e0e29bc374683fd5c2ccd0c9c62ce8eca2a394a4603775b3ef129c  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
ca04f78ffe54afa326fe3ed40e7e1411aca0000ed2fa5ead97ddf51c6aa5b7bc  NEWS.2
bd65a45cddfb88f37370fbcee4ac8dd3f1aebeebe47c2f968fd9770ba2bbc954  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
2a8dca916cd92229ef9e328f3610ca204809c262823b860252b42072dac2473a  THANKS
40cc7cea5f0e67cf8f2f7b25a534ae6bc53f38eae2ab2c2649a952ed37f0654a  VERSION-INFO.dcf
bd65a45cddfb88f37370fbcee4ac8dd3f1aebeebe47c2f968fd9770ba2bbc954  R-3/R-3.6.2.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 3.6.2:

  NEW FEATURES:

    * runmed(x, *) gains a new option na.action determining _how_ to
      handle NaN or NA in x.

    * dotchart() gains new options ann, xaxt, frame.plot and log.

  INSTALLATION on a UNIX-ALIKE:

    * Detection of the C stack direction has been moved from run-time
      to configure: this is safer with LTO builds and allows the
      detection to be overridden - see file config.site.

    * Source-code changes enable installation on platforms using gcc
      -fno-common (the expected default for gcc 10.x).

  C-LEVEL FACILITIES:

    * installTrChar (which is nowadays is wrapped by installChar) is
      defined in Rinternals.h.  (Neither are part of the API.)

  PACKAGE INSTALLATION:

    * Header Rconfig.h contains the value of FC_LEN_T deduced at
      installation which is used by the prototypes in headers
      R_ext/BLAS.h and R_ext/Lapack.h but to avoid extensive breakage
      this is only exposed when USE_FC_LEN_T is defined.

      If a package's C/C++ calls to BLAS/LAPACK allow for the 'hidden'
      arguments used by most Fortran compilers to pass the lengths of
      Fortran character arguments, define USE_FC_LEN_T and include
      Rconfig.h (possibly _via_ R.h) before including R_ext/BLAS.h or
      R_ext/Lapack.h.

    * A package with Fortran source code and perhaps C (but not C++)
      sources can request for its shared object/DLL to be linked by the
      Fortran compiler by including a line USE_FC_TO_LINK= in
      src/Makevars[.win] and using $(SHLIB_OPENMP_FFLAGS) as part of
      PKG_LIBS.

      The known reason for doing so is a package which uses Fortran
      (only) OpenMP on a platform where the Fortran OpenMP runtime is
      incompatible with the C one (e.g. gfortran 9.x with clang).

  UTILITIES:

    * R CMD check has a new option to mitigate checks leaving
      files/directories in /tmp.  See the 'R Internals' manual - this
      is part of --as-cran.

  Windows:

    * The default standard for C++ in package installation is C++11 (as
      it has been on other platforms where available since R 3.6.0: the
      default toolchain on Windows was defaulting to C++98).

  DEPRECATED AND DEFUNCT:

    * Support for specifying C++98 in package installation is
      deprecated.

    * Support in R CMD config for F77, FCPIFCPLAGS, CPP, CXXCPP and
      CXX98 and similar is deprecated.  (CPP is found from the system
      make and may well not be set.)

      Use $CC -E and $CXX -E instead of CPP and CXXCPP.

  BUG FIXES:

    * runmed(x, *) when x contains missing values now works
      consistently for both algorithm="Stuetzle" and "Turlach", and no
      longer segfaults for "Turlach", as reported by Hilmar Berger.

    * apply(diag(3), 2:3, mean) now gives a helpful error message.

    * dgamma(x, shape, log=TRUE) now longer overflows to Inf for shape
      < 1 and very small x, fixing PR#17577, reported by Jonathan
      Rougier.

    * Buffer overflow in building error messages fixed. Reported by
      Benjamin Tremblay.

    * options(str = .) is correctly initialized at package utils load
      time, now.  A consequence is that str() in scripts now is more
      consistent to interactive use, e.g., when displaying function(**)
      argument lists.

    * as.numeric(<call>) now gives correct error message.

    * Printing ls.str() no longer wrongly shows "<missing>" in rare
      cases.

    * Auto-printing S4 objects no longer duplicates the object, for
      faster speed and reduced memory consumption. Reported by Aaron
      Lun.

    * pchisq(<LRG>, <LRG>, ncp=100) no longer takes practically forever
      in some cases.  Hence ditto for corresponding qchisq() calls.

    * x %% L for finite x no longer returns NaN when L is infinite, nor
      suffers from cancellation for large finite L, thanks to Long Qu's
      PR#17611.

      Analogously, x %/% L and L %/% x suffer less from cancellation
      and return values corresponding to limits for large L.

    * grepl(NA, *) now returns logical as documented.

    * options(warn=1e11) is an error now, instead of later leading to C
      stack overflow because of infinite recursion.

    * R_tryCatch no longer transfers control for all conditions.
      Reported and patch provided by Lionel Henry in PR#17617.

    * format(object.size(.), digits=NULL) now works, fixing PR#17628
      reported by Jonathan Carroll.

    * get_all_vars(f, d) now also works for cases, e.g. where d
      contains a matrix.  Reported by Simon Wood in 2009 and patch
      provided by Ben Bolker in PR#13624.

      Additionally, it now also works when some variables are data
      frames, fixing PR#14905, reported by Patrick Breheny.

    * barplot() could get spacings wrong if there were exactly two bars
      PR#15522.  Patch by Michael Chirico.

    * power.t.test() works in more cases when returning values of n
      smaller than 2.

    * dotchart(*, pch=., groups=.) now works better.  Reported by
      Robert and confirmed by Nic Rochette in PR#16953.

    * canCoerce(obj, cl) no longer assumes length(class(obj)) == 1.

    * plot.formula(*, subset = *) now also works in a boundary case
      reported by Robert Schlicht (TU Dresden).

    * readBin() and writeBin() of a rawConnection() now also work in
      large cases, thanks to a report and proposal by Taeke Harkema in
      PR#17665.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Dec 12 11:51:07 2019
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 12 Dec 2019 16:21:07 +0530
Subject: [R] Tables from Rmarkdown to Word Document - using huxtables
In-Reply-To: <CAC8=1epj-0m2oJ5ouj02qUsCVuW=TNMOvTAZyQmY4D0fwXvsJQ@mail.gmail.com>
References: <CAC8=1er0F+VHTR7PGpwE2Wd1J8d6TTq7pzypbP3Hdk8xdOw8AQ@mail.gmail.com>
 <be551887-4479-07e9-49b9-727b278327c9@sapo.pt>
 <CAC8=1epj-0m2oJ5ouj02qUsCVuW=TNMOvTAZyQmY4D0fwXvsJQ@mail.gmail.com>
Message-ID: <CAC8=1epyP4fCyyRa95MikZy5hV0WxaQ=6yKBvc_30ovVwuKcig@mail.gmail.com>

Hello once again,

for me,set_caption is not working as well. Here is my Rmd file :-

---
title: Testing Huxtables
author: Ashim Kapoor
output: word_document
---

```{r}
library(dplyr)
library(huxtable)

hx <- iris %>%
   group_by(Species) %>%
   summarise_if(is.numeric, mean) %>%
   as_hux() %>%
   add_colnames() %>%
   set_bold(1, , TRUE) %>%
   set_bottom_border(1, , 1) %>%
   set_width(0.3) %>%
   set_col_width(1:5, 1.5) %>%
   set_number_format(2) %>%
   set_caption("Table 1:")

hx
```

Thank you,
Ashim

On Thu, Dec 12, 2019 at 12:57 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

>
>
> On Wed, Dec 11, 2019 at 9:11 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> This works for me:
>>
>>
>> library(dplyr)
>> library(huxtable)
>> library(flextable)
>> library(officer)
>>
>> hx <- iris %>%
>>    group_by(Species) %>%
>>    summarise_if(is.numeric, mean) %>%
>>    as_hux() %>%
>>    add_colnames() %>%
>>    set_bold(1, , TRUE) %>%
>>    set_bottom_border(1, , 1) %>%
>>    set_width(0.99) %>%
>>    set_col_width(1:5, 0.99) %>%
>>    set_number_format(2)
>>
>> hx
>>
>> quick_docx(hx, file = "test.docx")
>>
>>
> Does set_width work for you ? For me modifying the argument to set_width
> is NOT working.
>
>
>> There are ways of doing the same without pipes, those functions don't
>> have the prefix 'set_'. But I believe that what's important is function
>> ?quick_docx.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 11:37 de 11/12/19, Ashim Kapoor escreveu:
>> > Dear All,
>> >
>> > I am reading this :-
>> >
>> > https://hughjonesd.github.io/huxtable/huxtable.html
>> >
>> > I quote from the above:
>> >
>> > If you want to create Word or Powerpoint documents, install the
>> flextable
>> > package <https://cran.r-project.org/package=flextable> from CRAN.
>> Huxtables
>> > can then be automatically printed in Word documents. Or you can convert
>> > them to flextable objects and include them in Word or Powerpoint
>> documents.
>> >
>> > My query is how do I do the former ? How do I do this --->  Huxtables
>> can
>> > then be automatically printed in Word documents.
>> >
>> > I do understand how to do this ---> Or you can convert them to flextable
>> > objects and include them in Word or Powerpoint documents.
>> >
>> > Thank you,
>> > Ashim
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Dec 12 14:54:21 2019
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 12 Dec 2019 05:54:21 -0800 (PST)
Subject: [R] R 3.6.2 is released
In-Reply-To: <7F4152E4-727E-46C0-85D9-7318EB980FAB@cbs.dk>
References: <7F4152E4-727E-46C0-85D9-7318EB980FAB@cbs.dk>
Message-ID: <alpine.LNX.2.20.1912120553110.8975@salmo.appl-ecosys.com>

On Thu, 12 Dec 2019, Peter Dalgaard via R-help wrote:

> The build system rolled up R-3.6.2.tar.gz (codename "Dark and Stormy
> Night") this morning.

Peter,

My thanks to all of you on the R core team.

Regards,

Rich


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Thu Dec 12 15:19:37 2019
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Thu, 12 Dec 2019 08:19:37 -0600
Subject: [R] R 3.6.2 is released
In-Reply-To: <alpine.LNX.2.20.1912120553110.8975@salmo.appl-ecosys.com>
References: <7F4152E4-727E-46C0-85D9-7318EB980FAB@cbs.dk>
 <alpine.LNX.2.20.1912120553110.8975@salmo.appl-ecosys.com>
Message-ID: <154e2058-bbdd-5c58-8bb2-eb38dc7a7fe4@effectivedefense.org>

Ditto.? Spencer Graves


On 2019-12-12 07:54, Rich Shepard wrote:
> On Thu, 12 Dec 2019, Peter Dalgaard via R-help wrote:
>
>> The build system rolled up R-3.6.2.tar.gz (codename "Dark and Stormy
>> Night") this morning.
>
> Peter,
>
> My thanks to all of you on the R core team.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h@@@n@d|w@n @end|ng |rom gm@||@com  Thu Dec 12 15:23:40 2019
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Thu, 12 Dec 2019 06:23:40 -0800
Subject: [R] R 3.6.2 is released
In-Reply-To: <154e2058-bbdd-5c58-8bb2-eb38dc7a7fe4@effectivedefense.org>
References: <7F4152E4-727E-46C0-85D9-7318EB980FAB@cbs.dk>
 <alpine.LNX.2.20.1912120553110.8975@salmo.appl-ecosys.com>
 <154e2058-bbdd-5c58-8bb2-eb38dc7a7fe4@effectivedefense.org>
Message-ID: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>

Congrats on the release! -- H

On Thu, 12 Dec 2019 at 06:20, Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

> Ditto.  Spencer Graves
>
>
> On 2019-12-12 07:54, Rich Shepard wrote:
> > On Thu, 12 Dec 2019, Peter Dalgaard via R-help wrote:
> >
> >> The build system rolled up R-3.6.2.tar.gz (codename "Dark and Stormy
> >> Night") this morning.
> >
> > Peter,
> >
> > My thanks to all of you on the R core team.
> >
> > Regards,
> >
> > Rich
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
OpenPGP:
https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using
*bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.
Si vous voudrais faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From d@v|d@@teven@ @end|ng |rom u@u@edu  Thu Dec 12 16:48:13 2019
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David Stevens)
Date: Thu, 12 Dec 2019 15:48:13 +0000
Subject: [R] Errors in R package installation
In-Reply-To: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
Message-ID: <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>

Certain R packages will not install properly on my Windows 10 computer. For example, if I

install.packages('callr')

The result is

trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
Content type 'application/x-gzip' length 100129 bytes (97 KB)
downloaded 97 KB

Warning: invalid package 'C:\Users\David'
Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
Error: ERROR: no packages specified
Warning in install.packages :
  installation of package ?callr? had non-zero exit status

The downloaded source packages are in
        ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?

both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).

Best regards

David Stevens



	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Dec 12 16:56:57 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 12 Dec 2019 17:56:57 +0200
Subject: [R] Errors in R package installation
In-Reply-To: <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
Message-ID: <CAGgJW76hrU_TvkPynYu20OdbMV5GGDFMxiV=N9a+b0dSRJBChQ@mail.gmail.com>

Apparently it does not like that the fact that your user 'David
Stevens' has a blank.
Looking at the documentation ?install.packages
it seems that if you modify your call to something like

install.packages('callr',destdir='C:\tmp')

you might be ok. (caveat: I did not try this)

You should make the directory C:\tmp (or whatever you use instead)
before you issue this call.

HTH,
Eric

On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu> wrote:
>
> Certain R packages will not install properly on my Windows 10 computer. For example, if I
>
> install.packages('callr')
>
> The result is
>
> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
> Content type 'application/x-gzip' length 100129 bytes (97 KB)
> downloaded 97 KB
>
> Warning: invalid package 'C:\Users\David'
> Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
> Error: ERROR: no packages specified
> Warning in install.packages :
>   installation of package ?callr? had non-zero exit status
>
> The downloaded source packages are in
>         ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?
>
> both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).
>
> Best regards
>
> David Stevens
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From d@v|d@@teven@ @end|ng |rom u@u@edu  Thu Dec 12 17:07:49 2019
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David Stevens)
Date: Thu, 12 Dec 2019 16:07:49 +0000
Subject: [R] Errors in R package installation
In-Reply-To: <CAGgJW76hrU_TvkPynYu20OdbMV5GGDFMxiV=N9a+b0dSRJBChQ@mail.gmail.com>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
 <CAGgJW76hrU_TvkPynYu20OdbMV5GGDFMxiV=N9a+b0dSRJBChQ@mail.gmail.com>
Message-ID: <81ee8319-f35a-37ee-e5f0-60c1d6f7a32b@usu.edu>

Thanks Eric - I had tried this and failed with

install.packages('callr',destdir='c:/myRLib')
Installing package into ?C:/myRLib?
(as ?lib? is unspecified)

  There is a binary version available but the source version is
  later:
      binary source needs_compilation
callr  3.3.2  3.4.0             FALSE

installing the source package ?callr?

trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
Content type 'application/x-gzip' length 100129 bytes (97 KB)
downloaded 97 KB

* installing *source* package 'callr' ...
** package 'callr' successfully unpacked and MD5 sums checked
** using staged installation
** R
** inst
** byte-compile and prepare package for lazy loading
Fatal error: cannot open file 'C:\Users\David': No such file or directory

ERROR: lazy loading failed for package 'callr'
* removing 'C:/myRLib/callr'
Warning in install.packages :
  installation of package ?callr? had non-zero exit status

I also tried

install.packages('callr',lib='c:/myRLib',destdir='c:/myRLib')

with the same result. There's something more here that I'm unable to discover.

Best
David
On 12/12/2019 8:56 AM, Eric Berger wrote:

Apparently it does not like that the fact that your user 'David
Stevens' has a blank.
Looking at the documentation ?install.packages
it seems that if you modify your call to something like

install.packages('callr',destdir='C:\tmp')

you might be ok. (caveat: I did not try this)

You should make the directory C:\tmp (or whatever you use instead)
before you issue this call.

HTH,
Eric

On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:


Certain R packages will not install properly on my Windows 10 computer. For example, if I

install.packages('callr')

The result is

trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
Content type 'application/x-gzip' length 100129 bytes (97 KB)
downloaded 97 KB

Warning: invalid package 'C:\Users\David'
Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
Error: ERROR: no packages specified
Warning in install.packages :
  installation of package ?callr? had non-zero exit status

The downloaded source packages are in
        ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?

both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).

Best regards

David Stevens



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


On 12/12/2019 8:56 AM, Eric Berger wrote:

Apparently it does not like that the fact that your user 'David
Stevens' has a blank.
Looking at the documentation ?install.packages
it seems that if you modify your call to something like

install.packages('callr',destdir='C:\tmp')

you might be ok. (caveat: I did not try this)

You should make the directory C:\tmp (or whatever you use instead)
before you issue this call.

HTH,
Eric

On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:



Certain R packages will not install properly on my Windows 10 computer. For example, if I

install.packages('callr')

The result is

trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
Content type 'application/x-gzip' length 100129 bytes (97 KB)
downloaded 97 KB

Warning: invalid package 'C:\Users\David'
Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
Error: ERROR: no packages specified
Warning in install.packages :
  installation of package ?callr? had non-zero exit status

The downloaded source packages are in
        ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?

both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).

Best regards

David Stevens



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


--
David K Stevens, PhD, PE
Environmental Engineering Division
Civil and Environmental Engineering
Utah State University
8200 Old Main Hill
Logan, UT 83200-8200
(435) 797-3229
david.stevens at usu.edu<mailto:david.stevens at usu.edu>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Dec 12 17:52:33 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 12 Dec 2019 18:52:33 +0200
Subject: [R] Errors in R package installation
In-Reply-To: <81ee8319-f35a-37ee-e5f0-60c1d6f7a32b@usu.edu>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
 <CAGgJW76hrU_TvkPynYu20OdbMV5GGDFMxiV=N9a+b0dSRJBChQ@mail.gmail.com>
 <81ee8319-f35a-37ee-e5f0-60c1d6f7a32b@usu.edu>
Message-ID: <CAGgJW77L9nZXpPh=Apfx5-Ydp51mQc_Xg8p30k9n4a7=+zNXQg@mail.gmail.com>

Actually there was progress as after it failed it removed the folder
c:/myRlib/callr, which means it had used it. Seems good.
I think you might find the discussion here to be relevant

https://community.rstudio.com/t/cant-install-package-remotes-when-trying-to-install-devtools/34121

Good luck,
Eric

On Thu, Dec 12, 2019 at 6:08 PM David Stevens <david.stevens at usu.edu> wrote:
>
> Thanks Eric - I had tried this and failed with
>
> install.packages('callr',destdir='c:/myRLib')
> Installing package into ?C:/myRLib?
> (as ?lib? is unspecified)
>
>   There is a binary version available but the source version is
>   later:
>       binary source needs_compilation
> callr  3.3.2  3.4.0             FALSE
>
> installing the source package ?callr?
>
> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
> Content type 'application/x-gzip' length 100129 bytes (97 KB)
> downloaded 97 KB
>
> * installing *source* package 'callr' ...
> ** package 'callr' successfully unpacked and MD5 sums checked
> ** using staged installation
> ** R
> ** inst
> ** byte-compile and prepare package for lazy loading
> Fatal error: cannot open file 'C:\Users\David': No such file or directory
>
> ERROR: lazy loading failed for package 'callr'
> * removing 'C:/myRLib/callr'
> Warning in install.packages :
>   installation of package ?callr? had non-zero exit status
>
> I also tried
>
> install.packages('callr',lib='c:/myRLib',destdir='c:/myRLib')
>
> with the same result. There's something more here that I'm unable to discover.
>
> Best
> David
> On 12/12/2019 8:56 AM, Eric Berger wrote:
>
> Apparently it does not like that the fact that your user 'David
> Stevens' has a blank.
> Looking at the documentation ?install.packages
> it seems that if you modify your call to something like
>
> install.packages('callr',destdir='C:\tmp')
>
> you might be ok. (caveat: I did not try this)
>
> You should make the directory C:\tmp (or whatever you use instead)
> before you issue this call.
>
> HTH,
> Eric
>
> On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:
>
>
> Certain R packages will not install properly on my Windows 10 computer. For example, if I
>
> install.packages('callr')
>
> The result is
>
> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
> Content type 'application/x-gzip' length 100129 bytes (97 KB)
> downloaded 97 KB
>
> Warning: invalid package 'C:\Users\David'
> Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
> Error: ERROR: no packages specified
> Warning in install.packages :
>   installation of package ?callr? had non-zero exit status
>
> The downloaded source packages are in
>         ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?
>
> both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).
>
> Best regards
>
> David Stevens
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> On 12/12/2019 8:56 AM, Eric Berger wrote:
>
> Apparently it does not like that the fact that your user 'David
> Stevens' has a blank.
> Looking at the documentation ?install.packages
> it seems that if you modify your call to something like
>
> install.packages('callr',destdir='C:\tmp')
>
> you might be ok. (caveat: I did not try this)
>
> You should make the directory C:\tmp (or whatever you use instead)
> before you issue this call.
>
> HTH,
> Eric
>
> On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:
>
>
>
> Certain R packages will not install properly on my Windows 10 computer. For example, if I
>
> install.packages('callr')
>
> The result is
>
> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
> Content type 'application/x-gzip' length 100129 bytes (97 KB)
> downloaded 97 KB
>
> Warning: invalid package 'C:\Users\David'
> Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
> Error: ERROR: no packages specified
> Warning in install.packages :
>   installation of package ?callr? had non-zero exit status
>
> The downloaded source packages are in
>         ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?
>
> both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).
>
> Best regards
>
> David Stevens
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
> David K Stevens, PhD, PE
> Environmental Engineering Division
> Civil and Environmental Engineering
> Utah State University
> 8200 Old Main Hill
> Logan, UT 83200-8200
> (435) 797-3229
> david.stevens at usu.edu<mailto:david.stevens at usu.edu>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hubertbe@umont @end|ng |rom hotm@||@com  Wed Dec 11 19:09:31 2019
From: hubertbe@umont @end|ng |rom hotm@||@com (hubert beaumont)
Date: Wed, 11 Dec 2019 18:09:31 +0000
Subject: [R] IO issues with tiff image using imager package
Message-ID: <VI1PR04MB58543C48C7A7CDCC0866080CD85A0@VI1PR04MB5854.eurprd04.prod.outlook.com>

Hi everyone,

I am trying to use: library(imager)
in loading a 2D tiff image as:

im <- load.image(NameFile)

then I can plot it as:
R(im) %>% plot(main="my test")

but when saving this image elsewhere:
save.image(im, OutNameFile), the output image has apparently the right format (tiff) but this image is blank.

Thank you for your help on this,





	[[alternative HTML version deleted]]


From d@v|d@@teven@ @end|ng |rom u@u@edu  Thu Dec 12 17:59:20 2019
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David Stevens)
Date: Thu, 12 Dec 2019 16:59:20 +0000
Subject: [R] Errors in R package installation
In-Reply-To: <CAGgJW77L9nZXpPh=Apfx5-Ydp51mQc_Xg8p30k9n4a7=+zNXQg@mail.gmail.com>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
 <CAGgJW76hrU_TvkPynYu20OdbMV5GGDFMxiV=N9a+b0dSRJBChQ@mail.gmail.com>
 <81ee8319-f35a-37ee-e5f0-60c1d6f7a32b@usu.edu>
 <CAGgJW77L9nZXpPh=Apfx5-Ydp51mQc_Xg8p30k9n4a7=+zNXQg@mail.gmail.com>
Message-ID: <97fb29f3-c419-d80a-3e5a-1a62b4d28707@usu.edu>

Thanks Eric - I'll follow up with this link. I'd tried some of these 
things before but I'll keep after it.

Best

David

On 12/12/2019 9:52 AM, Eric Berger wrote:
> Actually there was progress as after it failed it removed the folder
> c:/myRlib/callr, which means it had used it. Seems good.
> I think you might find the discussion here to be relevant
>
> https://community.rstudio.com/t/cant-install-package-remotes-when-trying-to-install-devtools/34121
>
> Good luck,
> Eric
>
> On Thu, Dec 12, 2019 at 6:08 PM David Stevens <david.stevens at usu.edu> wrote:
>> Thanks Eric - I had tried this and failed with
>>
>> install.packages('callr',destdir='c:/myRLib')
>> Installing package into ?C:/myRLib?
>> (as ?lib? is unspecified)
>>
>>    There is a binary version available but the source version is
>>    later:
>>        binary source needs_compilation
>> callr  3.3.2  3.4.0             FALSE
>>
>> installing the source package ?callr?
>>
>> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
>> Content type 'application/x-gzip' length 100129 bytes (97 KB)
>> downloaded 97 KB
>>
>> * installing *source* package 'callr' ...
>> ** package 'callr' successfully unpacked and MD5 sums checked
>> ** using staged installation
>> ** R
>> ** inst
>> ** byte-compile and prepare package for lazy loading
>> Fatal error: cannot open file 'C:\Users\David': No such file or directory
>>
>> ERROR: lazy loading failed for package 'callr'
>> * removing 'C:/myRLib/callr'
>> Warning in install.packages :
>>    installation of package ?callr? had non-zero exit status
>>
>> I also tried
>>
>> install.packages('callr',lib='c:/myRLib',destdir='c:/myRLib')
>>
>> with the same result. There's something more here that I'm unable to discover.
>>
>> Best
>> David
>> On 12/12/2019 8:56 AM, Eric Berger wrote:
>>
>> Apparently it does not like that the fact that your user 'David
>> Stevens' has a blank.
>> Looking at the documentation ?install.packages
>> it seems that if you modify your call to something like
>>
>> install.packages('callr',destdir='C:\tmp')
>>
>> you might be ok. (caveat: I did not try this)
>>
>> You should make the directory C:\tmp (or whatever you use instead)
>> before you issue this call.
>>
>> HTH,
>> Eric
>>
>> On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:
>>
>>
>> Certain R packages will not install properly on my Windows 10 computer. For example, if I
>>
>> install.packages('callr')
>>
>> The result is
>>
>> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
>> Content type 'application/x-gzip' length 100129 bytes (97 KB)
>> downloaded 97 KB
>>
>> Warning: invalid package 'C:\Users\David'
>> Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
>> Error: ERROR: no packages specified
>> Warning in install.packages :
>>    installation of package ?callr? had non-zero exit status
>>
>> The downloaded source packages are in
>>          ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?
>>
>> both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).
>>
>> Best regards
>>
>> David Stevens
>>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> On 12/12/2019 8:56 AM, Eric Berger wrote:
>>
>> Apparently it does not like that the fact that your user 'David
>> Stevens' has a blank.
>> Looking at the documentation ?install.packages
>> it seems that if you modify your call to something like
>>
>> install.packages('callr',destdir='C:\tmp')
>>
>> you might be ok. (caveat: I did not try this)
>>
>> You should make the directory C:\tmp (or whatever you use instead)
>> before you issue this call.
>>
>> HTH,
>> Eric
>>
>> On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:
>>
>>
>>
>> Certain R packages will not install properly on my Windows 10 computer. For example, if I
>>
>> install.packages('callr')
>>
>> The result is
>>
>> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
>> Content type 'application/x-gzip' length 100129 bytes (97 KB)
>> downloaded 97 KB
>>
>> Warning: invalid package 'C:\Users\David'
>> Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
>> Error: ERROR: no packages specified
>> Warning in install.packages :
>>    installation of package ?callr? had non-zero exit status
>>
>> The downloaded source packages are in
>>          ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?
>>
>> both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).
>>
>> Best regards
>>
>> David Stevens
>>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> --
>> David K Stevens, PhD, PE
>> Environmental Engineering Division
>> Civil and Environmental Engineering
>> Utah State University
>> 8200 Old Main Hill
>> Logan, UT 83200-8200
>> (435) 797-3229
>> david.stevens at usu.edu<mailto:david.stevens at usu.edu>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
David K Stevens, PhD, PE
Environmental Engineering Division
Civil and Environmental Engineering
Utah State University
8200 Old Main Hill
Logan, UT 83200-8200
(435) 797-3229
david.stevens at usu.edu


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Dec 12 19:39:41 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 12 Dec 2019 18:39:41 +0000
Subject: [R] Tables from Rmarkdown to Word Document - using huxtables
In-Reply-To: <CAC8=1epyP4fCyyRa95MikZy5hV0WxaQ=6yKBvc_30ovVwuKcig@mail.gmail.com>
References: <CAC8=1er0F+VHTR7PGpwE2Wd1J8d6TTq7pzypbP3Hdk8xdOw8AQ@mail.gmail.com>
 <be551887-4479-07e9-49b9-727b278327c9@sapo.pt>
 <CAC8=1epj-0m2oJ5ouj02qUsCVuW=TNMOvTAZyQmY4D0fwXvsJQ@mail.gmail.com>
 <CAC8=1epyP4fCyyRa95MikZy5hV0WxaQ=6yKBvc_30ovVwuKcig@mail.gmail.com>
Message-ID: <92897068-502d-4bd6-4e44-148fdf74a795@sapo.pt>

Hello,

You're right, none of the two seems to be working.

set_width gives me tables of the same width no matter what value I pass 
as argument.

And set_caption is asking for a flextable object, doesn't work with 
huxtable.

I don't know how to solve it right now, I will try later.

Rui Barradas

?s 10:51 de 12/12/19, Ashim Kapoor escreveu:
> Hello once again,
> 
> for me,set_caption is not working as well. Here is my Rmd file :-
> 
> ---
> title: Testing Huxtables
> author: Ashim Kapoor
> output: word_document
> ---
> 
> ```{r}
> library(dplyr)
> library(huxtable)
> 
> hx <- iris %>%
>  ? ?group_by(Species) %>%
>  ? ?summarise_if(is.numeric, mean) %>%
>  ? ?as_hux() %>%
>  ? ?add_colnames() %>%
>  ? ?set_bold(1, , TRUE) %>%
>  ? ?set_bottom_border(1, , 1) %>%
>  ? ?set_width(0.3) %>%
>  ? ?set_col_width(1:5, 1.5) %>%
>  ? ?set_number_format(2) %>%
>  ? ?set_caption("Table 1:")
> 
> hx
> ```
> 
> Thank you,
> Ashim
> 
> On Thu, Dec 12, 2019 at 12:57 PM Ashim Kapoor <ashimkapoor at gmail.com 
> <mailto:ashimkapoor at gmail.com>> wrote:
> 
> 
> 
>     On Wed, Dec 11, 2019 at 9:11 PM Rui Barradas <ruipbarradas at sapo.pt
>     <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>         Hello,
> 
>         This works for me:
> 
> 
>         library(dplyr)
>         library(huxtable)
>         library(flextable)
>         library(officer)
> 
>         hx <- iris %>%
>          ? ?group_by(Species) %>%
>          ? ?summarise_if(is.numeric, mean) %>%
>          ? ?as_hux() %>%
>          ? ?add_colnames() %>%
>          ? ?set_bold(1, , TRUE) %>%
>          ? ?set_bottom_border(1, , 1) %>%
>          ? ?set_width(0.99) %>%
>          ? ?set_col_width(1:5, 0.99) %>%
>          ? ?set_number_format(2)
> 
>         hx
> 
>         quick_docx(hx, file = "test.docx")
> 
>     Does set_width work for you ? For me modifying the argument to
>     set_width is NOT working.
> 
>         There are ways of doing the same without pipes, those functions
>         don't
>         have the prefix 'set_'. But I believe that what's important is
>         function
>         ?quick_docx.
> 
>         Hope this helps,
> 
>         Rui Barradas
> 
>         ?s 11:37 de 11/12/19, Ashim Kapoor escreveu:
>          > Dear All,
>          >
>          > I am reading this :-
>          >
>          > https://hughjonesd.github.io/huxtable/huxtable.html
>          >
>          > I quote from the above:
>          >
>          > If you want to create Word or Powerpoint documents, install
>         the flextable
>          > package <https://cran.r-project.org/package=flextable> from
>         CRAN. Huxtables
>          > can then be automatically printed in Word documents. Or you
>         can convert
>          > them to flextable objects and include them in Word or
>         Powerpoint documents.
>          >
>          > My query is how do I do the former ? How do I do this ---> 
>         Huxtables can
>          > then be automatically printed in Word documents.
>          >
>          > I do understand how to do this ---> Or you can convert them
>         to flextable
>          > objects and include them in Word or Powerpoint documents.
>          >
>          > Thank you,
>          > Ashim
>          >
>          >? ? ? ?[[alternative HTML version deleted]]
>          >
>          > ______________________________________________
>          > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>          > https://stat.ethz.ch/mailman/listinfo/r-help
>          > PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>          > and provide commented, minimal, self-contained, reproducible
>         code.
>          >
>


From rmh @end|ng |rom temp|e@edu  Thu Dec 12 20:05:26 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Thu, 12 Dec 2019 14:05:26 -0500
Subject: [R] Errors in R package installation
In-Reply-To: <97fb29f3-c419-d80a-3e5a-1a62b4d28707@usu.edu>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
 <CAGgJW76hrU_TvkPynYu20OdbMV5GGDFMxiV=N9a+b0dSRJBChQ@mail.gmail.com>
 <81ee8319-f35a-37ee-e5f0-60c1d6f7a32b@usu.edu>
 <CAGgJW77L9nZXpPh=Apfx5-Ydp51mQc_Xg8p30k9n4a7=+zNXQg@mail.gmail.com>
 <97fb29f3-c419-d80a-3e5a-1a62b4d28707@usu.edu>
Message-ID: <CAGx1TMBsPtN4CefqeUj7Rt=kJ3NOLOdkHuC8KB2k9LvSdZoYMw@mail.gmail.com>

Directory and file names with embedded blanks frequently don't work on
WIndows.  Use the 8.3 version of the name.
Since you were able to get the package onto your machine, you can
install it from there.

The downloaded source packages are in
        ?C:\Users\David
Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?

In the windows shell

cd c:\Users
dir /x David*

It will tell you something like
DavidS~1

Then in R you can write

install.packages("c:/Users/DavidS~1/AppData/Local/Temp/Rtmpk5NqrI/downloaded_packages/callr_3.4-0.tar.gz")

Make sure you use the correct full name of the downloaded source package.

Rich

On Thu, Dec 12, 2019 at 12:03 PM David Stevens <david.stevens at usu.edu> wrote:
>
> Thanks Eric - I'll follow up with this link. I'd tried some of these
> things before but I'll keep after it.
>
> Best
>
> David
>
> On 12/12/2019 9:52 AM, Eric Berger wrote:
> > Actually there was progress as after it failed it removed the folder
> > c:/myRlib/callr, which means it had used it. Seems good.
> > I think you might find the discussion here to be relevant
> >
> > https://community.rstudio.com/t/cant-install-package-remotes-when-trying-to-install-devtools/34121
> >
> > Good luck,
> > Eric
> >
> > On Thu, Dec 12, 2019 at 6:08 PM David Stevens <david.stevens at usu.edu> wrote:
> >> Thanks Eric - I had tried this and failed with
> >>
> >> install.packages('callr',destdir='c:/myRLib')
> >> Installing package into ?C:/myRLib?
> >> (as ?lib? is unspecified)
> >>
> >>    There is a binary version available but the source version is
> >>    later:
> >>        binary source needs_compilation
> >> callr  3.3.2  3.4.0             FALSE
> >>
> >> installing the source package ?callr?
> >>
> >> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
> >> Content type 'application/x-gzip' length 100129 bytes (97 KB)
> >> downloaded 97 KB
> >>
> >> * installing *source* package 'callr' ...
> >> ** package 'callr' successfully unpacked and MD5 sums checked
> >> ** using staged installation
> >> ** R
> >> ** inst
> >> ** byte-compile and prepare package for lazy loading
> >> Fatal error: cannot open file 'C:\Users\David': No such file or directory
> >>
> >> ERROR: lazy loading failed for package 'callr'
> >> * removing 'C:/myRLib/callr'
> >> Warning in install.packages :
> >>    installation of package ?callr? had non-zero exit status
> >>
> >> I also tried
> >>
> >> install.packages('callr',lib='c:/myRLib',destdir='c:/myRLib')
> >>
> >> with the same result. There's something more here that I'm unable to discover.
> >>
> >> Best
> >> David
> >> On 12/12/2019 8:56 AM, Eric Berger wrote:
> >>
> >> Apparently it does not like that the fact that your user 'David
> >> Stevens' has a blank.
> >> Looking at the documentation ?install.packages
> >> it seems that if you modify your call to something like
> >>
> >> install.packages('callr',destdir='C:\tmp')
> >>
> >> you might be ok. (caveat: I did not try this)
> >>
> >> You should make the directory C:\tmp (or whatever you use instead)
> >> before you issue this call.
> >>
> >> HTH,
> >> Eric
> >>
> >> On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:
> >>
> >>
> >> Certain R packages will not install properly on my Windows 10 computer. For example, if I
> >>
> >> install.packages('callr')
> >>
> >> The result is
> >>
> >> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
> >> Content type 'application/x-gzip' length 100129 bytes (97 KB)
> >> downloaded 97 KB
> >>
> >> Warning: invalid package 'C:\Users\David'
> >> Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
> >> Error: ERROR: no packages specified
> >> Warning in install.packages :
> >>    installation of package ?callr? had non-zero exit status
> >>
> >> The downloaded source packages are in
> >>          ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?
> >>
> >> both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).
> >>
> >> Best regards
> >>
> >> David Stevens
> >>
> >>
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >> On 12/12/2019 8:56 AM, Eric Berger wrote:
> >>
> >> Apparently it does not like that the fact that your user 'David
> >> Stevens' has a blank.
> >> Looking at the documentation ?install.packages
> >> it seems that if you modify your call to something like
> >>
> >> install.packages('callr',destdir='C:\tmp')
> >>
> >> you might be ok. (caveat: I did not try this)
> >>
> >> You should make the directory C:\tmp (or whatever you use instead)
> >> before you issue this call.
> >>
> >> HTH,
> >> Eric
> >>
> >> On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:
> >>
> >>
> >>
> >> Certain R packages will not install properly on my Windows 10 computer. For example, if I
> >>
> >> install.packages('callr')
> >>
> >> The result is
> >>
> >> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
> >> Content type 'application/x-gzip' length 100129 bytes (97 KB)
> >> downloaded 97 KB
> >>
> >> Warning: invalid package 'C:\Users\David'
> >> Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
> >> Error: ERROR: no packages specified
> >> Warning in install.packages :
> >>    installation of package ?callr? had non-zero exit status
> >>
> >> The downloaded source packages are in
> >>          ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?
> >>
> >> both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).
> >>
> >> Best regards
> >>
> >> David Stevens
> >>
> >>
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >> --
> >> David K Stevens, PhD, PE
> >> Environmental Engineering Division
> >> Civil and Environmental Engineering
> >> Utah State University
> >> 8200 Old Main Hill
> >> Logan, UT 83200-8200
> >> (435) 797-3229
> >> david.stevens at usu.edu<mailto:david.stevens at usu.edu>
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> --
> David K Stevens, PhD, PE
> Environmental Engineering Division
> Civil and Environmental Engineering
> Utah State University
> 8200 Old Main Hill
> Logan, UT 83200-8200
> (435) 797-3229
> david.stevens at usu.edu
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @@h|mk@poor @end|ng |rom gm@||@com  Fri Dec 13 05:25:29 2019
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Fri, 13 Dec 2019 09:55:29 +0530
Subject: [R] Tables from Rmarkdown to Word Document - using huxtables
In-Reply-To: <92897068-502d-4bd6-4e44-148fdf74a795@sapo.pt>
References: <CAC8=1er0F+VHTR7PGpwE2Wd1J8d6TTq7pzypbP3Hdk8xdOw8AQ@mail.gmail.com>
 <be551887-4479-07e9-49b9-727b278327c9@sapo.pt>
 <CAC8=1epj-0m2oJ5ouj02qUsCVuW=TNMOvTAZyQmY4D0fwXvsJQ@mail.gmail.com>
 <CAC8=1epyP4fCyyRa95MikZy5hV0WxaQ=6yKBvc_30ovVwuKcig@mail.gmail.com>
 <92897068-502d-4bd6-4e44-148fdf74a795@sapo.pt>
Message-ID: <CAC8=1eq9SCrqz3yJ-1Kq__pAqXxqP6MxT5u_pbdFfAHMDUdgAw@mail.gmail.com>

Dear Rui,

No problem and Many thanks.

Best Regards,
Ashim

On Fri, Dec 13, 2019 at 12:09 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> You're right, none of the two seems to be working.
>
> set_width gives me tables of the same width no matter what value I pass
> as argument.
>
> And set_caption is asking for a flextable object, doesn't work with
> huxtable.
>
> I don't know how to solve it right now, I will try later.
>
> Rui Barradas
>
> ?s 10:51 de 12/12/19, Ashim Kapoor escreveu:
> > Hello once again,
> >
> > for me,set_caption is not working as well. Here is my Rmd file :-
> >
> > ---
> > title: Testing Huxtables
> > author: Ashim Kapoor
> > output: word_document
> > ---
> >
> > ```{r}
> > library(dplyr)
> > library(huxtable)
> >
> > hx <- iris %>%
> >     group_by(Species) %>%
> >     summarise_if(is.numeric, mean) %>%
> >     as_hux() %>%
> >     add_colnames() %>%
> >     set_bold(1, , TRUE) %>%
> >     set_bottom_border(1, , 1) %>%
> >     set_width(0.3) %>%
> >     set_col_width(1:5, 1.5) %>%
> >     set_number_format(2) %>%
> >     set_caption("Table 1:")
> >
> > hx
> > ```
> >
> > Thank you,
> > Ashim
> >
> > On Thu, Dec 12, 2019 at 12:57 PM Ashim Kapoor <ashimkapoor at gmail.com
> > <mailto:ashimkapoor at gmail.com>> wrote:
> >
> >
> >
> >     On Wed, Dec 11, 2019 at 9:11 PM Rui Barradas <ruipbarradas at sapo.pt
> >     <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >         Hello,
> >
> >         This works for me:
> >
> >
> >         library(dplyr)
> >         library(huxtable)
> >         library(flextable)
> >         library(officer)
> >
> >         hx <- iris %>%
> >             group_by(Species) %>%
> >             summarise_if(is.numeric, mean) %>%
> >             as_hux() %>%
> >             add_colnames() %>%
> >             set_bold(1, , TRUE) %>%
> >             set_bottom_border(1, , 1) %>%
> >             set_width(0.99) %>%
> >             set_col_width(1:5, 0.99) %>%
> >             set_number_format(2)
> >
> >         hx
> >
> >         quick_docx(hx, file = "test.docx")
> >
> >     Does set_width work for you ? For me modifying the argument to
> >     set_width is NOT working.
> >
> >         There are ways of doing the same without pipes, those functions
> >         don't
> >         have the prefix 'set_'. But I believe that what's important is
> >         function
> >         ?quick_docx.
> >
> >         Hope this helps,
> >
> >         Rui Barradas
> >
> >         ?s 11:37 de 11/12/19, Ashim Kapoor escreveu:
> >          > Dear All,
> >          >
> >          > I am reading this :-
> >          >
> >          > https://hughjonesd.github.io/huxtable/huxtable.html
> >          >
> >          > I quote from the above:
> >          >
> >          > If you want to create Word or Powerpoint documents, install
> >         the flextable
> >          > package <https://cran.r-project.org/package=flextable> from
> >         CRAN. Huxtables
> >          > can then be automatically printed in Word documents. Or you
> >         can convert
> >          > them to flextable objects and include them in Word or
> >         Powerpoint documents.
> >          >
> >          > My query is how do I do the former ? How do I do this --->
> >         Huxtables can
> >          > then be automatically printed in Word documents.
> >          >
> >          > I do understand how to do this ---> Or you can convert them
> >         to flextable
> >          > objects and include them in Word or Powerpoint documents.
> >          >
> >          > Thank you,
> >          > Ashim
> >          >
> >          >       [[alternative HTML version deleted]]
> >          >
> >          > ______________________________________________
> >          > R-help at r-project.org <mailto:R-help at r-project.org> mailing
> >         list -- To UNSUBSCRIBE and more, see
> >          > https://stat.ethz.ch/mailman/listinfo/r-help
> >          > PLEASE do read the posting guide
> >         http://www.R-project.org/posting-guide.html
> >          > and provide commented, minimal, self-contained, reproducible
> >         code.
> >          >
> >
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Fri Dec 13 07:12:21 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 13 Dec 2019 08:12:21 +0200
Subject: [R] Errors in R package installation
In-Reply-To: <CAGx1TMBsPtN4CefqeUj7Rt=kJ3NOLOdkHuC8KB2k9LvSdZoYMw@mail.gmail.com>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
 <CAGgJW76hrU_TvkPynYu20OdbMV5GGDFMxiV=N9a+b0dSRJBChQ@mail.gmail.com>
 <81ee8319-f35a-37ee-e5f0-60c1d6f7a32b@usu.edu>
 <CAGgJW77L9nZXpPh=Apfx5-Ydp51mQc_Xg8p30k9n4a7=+zNXQg@mail.gmail.com>
 <97fb29f3-c419-d80a-3e5a-1a62b4d28707@usu.edu>
 <CAGx1TMBsPtN4CefqeUj7Rt=kJ3NOLOdkHuC8KB2k9LvSdZoYMw@mail.gmail.com>
Message-ID: <CAGgJW76Btx9LDK8PSOBQk-VyMnwqzi-tW7O3q1L3UoxJJxABNA@mail.gmail.com>

And a low-tech approach: how about renaming "C:\Users\David Stevens"
to "C:\Users\DavidStevens" (i.e. remove the blank in the name).
A few years ago I did the equivalent "C:\Program Files" -->
"C:\ProgramFiles" to avoid similar installation problems.

On Thu, Dec 12, 2019 at 9:06 PM Richard M. Heiberger <rmh at temple.edu> wrote:
>
> Directory and file names with embedded blanks frequently don't work on
> WIndows.  Use the 8.3 version of the name.
> Since you were able to get the package onto your machine, you can
> install it from there.
>
> The downloaded source packages are in
>         ?C:\Users\David
> Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?
>
> In the windows shell
>
> cd c:\Users
> dir /x David*
>
> It will tell you something like
> DavidS~1
>
> Then in R you can write
>
> install.packages("c:/Users/DavidS~1/AppData/Local/Temp/Rtmpk5NqrI/downloaded_packages/callr_3.4-0.tar.gz")
>
> Make sure you use the correct full name of the downloaded source package.
>
> Rich
>
> On Thu, Dec 12, 2019 at 12:03 PM David Stevens <david.stevens at usu.edu> wrote:
> >
> > Thanks Eric - I'll follow up with this link. I'd tried some of these
> > things before but I'll keep after it.
> >
> > Best
> >
> > David
> >
> > On 12/12/2019 9:52 AM, Eric Berger wrote:
> > > Actually there was progress as after it failed it removed the folder
> > > c:/myRlib/callr, which means it had used it. Seems good.
> > > I think you might find the discussion here to be relevant
> > >
> > > https://community.rstudio.com/t/cant-install-package-remotes-when-trying-to-install-devtools/34121
> > >
> > > Good luck,
> > > Eric
> > >
> > > On Thu, Dec 12, 2019 at 6:08 PM David Stevens <david.stevens at usu.edu> wrote:
> > >> Thanks Eric - I had tried this and failed with
> > >>
> > >> install.packages('callr',destdir='c:/myRLib')
> > >> Installing package into ?C:/myRLib?
> > >> (as ?lib? is unspecified)
> > >>
> > >>    There is a binary version available but the source version is
> > >>    later:
> > >>        binary source needs_compilation
> > >> callr  3.3.2  3.4.0             FALSE
> > >>
> > >> installing the source package ?callr?
> > >>
> > >> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
> > >> Content type 'application/x-gzip' length 100129 bytes (97 KB)
> > >> downloaded 97 KB
> > >>
> > >> * installing *source* package 'callr' ...
> > >> ** package 'callr' successfully unpacked and MD5 sums checked
> > >> ** using staged installation
> > >> ** R
> > >> ** inst
> > >> ** byte-compile and prepare package for lazy loading
> > >> Fatal error: cannot open file 'C:\Users\David': No such file or directory
> > >>
> > >> ERROR: lazy loading failed for package 'callr'
> > >> * removing 'C:/myRLib/callr'
> > >> Warning in install.packages :
> > >>    installation of package ?callr? had non-zero exit status
> > >>
> > >> I also tried
> > >>
> > >> install.packages('callr',lib='c:/myRLib',destdir='c:/myRLib')
> > >>
> > >> with the same result. There's something more here that I'm unable to discover.
> > >>
> > >> Best
> > >> David
> > >> On 12/12/2019 8:56 AM, Eric Berger wrote:
> > >>
> > >> Apparently it does not like that the fact that your user 'David
> > >> Stevens' has a blank.
> > >> Looking at the documentation ?install.packages
> > >> it seems that if you modify your call to something like
> > >>
> > >> install.packages('callr',destdir='C:\tmp')
> > >>
> > >> you might be ok. (caveat: I did not try this)
> > >>
> > >> You should make the directory C:\tmp (or whatever you use instead)
> > >> before you issue this call.
> > >>
> > >> HTH,
> > >> Eric
> > >>
> > >> On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:
> > >>
> > >>
> > >> Certain R packages will not install properly on my Windows 10 computer. For example, if I
> > >>
> > >> install.packages('callr')
> > >>
> > >> The result is
> > >>
> > >> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
> > >> Content type 'application/x-gzip' length 100129 bytes (97 KB)
> > >> downloaded 97 KB
> > >>
> > >> Warning: invalid package 'C:\Users\David'
> > >> Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
> > >> Error: ERROR: no packages specified
> > >> Warning in install.packages :
> > >>    installation of package ?callr? had non-zero exit status
> > >>
> > >> The downloaded source packages are in
> > >>          ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?
> > >>
> > >> both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).
> > >>
> > >> Best regards
> > >>
> > >> David Stevens
> > >>
> > >>
> > >>
> > >>          [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >> On 12/12/2019 8:56 AM, Eric Berger wrote:
> > >>
> > >> Apparently it does not like that the fact that your user 'David
> > >> Stevens' has a blank.
> > >> Looking at the documentation ?install.packages
> > >> it seems that if you modify your call to something like
> > >>
> > >> install.packages('callr',destdir='C:\tmp')
> > >>
> > >> you might be ok. (caveat: I did not try this)
> > >>
> > >> You should make the directory C:\tmp (or whatever you use instead)
> > >> before you issue this call.
> > >>
> > >> HTH,
> > >> Eric
> > >>
> > >> On Thu, Dec 12, 2019 at 5:48 PM David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:
> > >>
> > >>
> > >>
> > >> Certain R packages will not install properly on my Windows 10 computer. For example, if I
> > >>
> > >> install.packages('callr')
> > >>
> > >> The result is
> > >>
> > >> trying URL 'https://cloud.r-project.org/src/contrib/callr_3.4.0.tar.gz'
> > >> Content type 'application/x-gzip' length 100129 bytes (97 KB)
> > >> downloaded 97 KB
> > >>
> > >> Warning: invalid package 'C:\Users\David'
> > >> Warning: invalid package 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'
> > >> Error: ERROR: no packages specified
> > >> Warning in install.packages :
> > >>    installation of package ?callr? had non-zero exit status
> > >>
> > >> The downloaded source packages are in
> > >>          ?C:\Users\David Stevens\AppData\Local\Temp\Rtmpk5NqrI\downloaded_packages?
> > >>
> > >> both using RStudio 1.2.5019 and the Rgui.exe 3.6.2. I look in the download folder and the callr_3.4.0.tar.gz is there but the installer can't find it. This happens on only a subset of packages I install or update. I assume the cause is the space in my name in the c:\users folder. I've been unable to locate the environment variable or registry value that routes the tar.gz files to this location. Any ideas on how to fix this? This is a relatively recent issue (i.e. I never saw it before November - I've used R for ~15 years).
> > >>
> > >> Best regards
> > >>
> > >> David Stevens
> > >>
> > >>
> > >>
> > >>          [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >> --
> > >> David K Stevens, PhD, PE
> > >> Environmental Engineering Division
> > >> Civil and Environmental Engineering
> > >> Utah State University
> > >> 8200 Old Main Hill
> > >> Logan, UT 83200-8200
> > >> (435) 797-3229
> > >> david.stevens at usu.edu<mailto:david.stevens at usu.edu>
> > >>
> > >>          [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > David K Stevens, PhD, PE
> > Environmental Engineering Division
> > Civil and Environmental Engineering
> > Utah State University
> > 8200 Old Main Hill
> > Logan, UT 83200-8200
> > (435) 797-3229
> > david.stevens at usu.edu
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Dec 13 09:46:04 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 13 Dec 2019 11:46:04 +0300
Subject: [R] Errors in R package installation
In-Reply-To: <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
Message-ID: <20191213114604.0a60e65f@Tarkus>

On Thu, 12 Dec 2019 15:48:13 +0000
David Stevens <david.stevens at usu.edu> wrote:

> Certain R packages will not install properly on my Windows 10
> computer.

Certain, but not all? Which packages are you able to install on that
computer?

> Warning: invalid package 'C:\Users\David'
> Warning: invalid package
> 'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'

This looks like a command line argument quoting issue.

I wonder why doesn't install.packages use shQuote to quote the file
name when calling system2(c("R", "CMD", "INSTALL", file)) to install a
downloaded source package:

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/packages2.R#L833

Maybe there should be shQuote(fil) instead, especially since R does
quote the file name when installing from local source tarballs:

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/packages2.R#L676

> This happens on only a subset of packages I install or update.

I have a hypothesis: perhaps this only happens for packages with no
pre-built Windows binary available yet, since "win.binary" packages may
be installed by unpacking a zip file, without calling a command line
with potential space quoting issues:

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/packages2.R#L491
->
https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/windows/install.packages.R#L263

Calling install.packages(..., verbose = TRUE) for both a succeeding and
a failing package might help to verify whether this is the case.

> This is a relatively recent issue (i.e. I never saw it before
> November - I've used R for ~15 years).

Just to confirm it: you had no problems on the same Windows 10 computer
with the same user name and %USERPROFILE% path as before? Apparently,
tempdir() used to return a 8.3 directory path on your computer, but now
doesn't - but that should not happen, since R_reInitTempDir()
explicitly asks for a 8.3 path:

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/main/sysutils.c#L1810

Microsoft Docs page for GetShortPathName() says:

>> If you call GetShortPathName on a path that doesn't have any short
>> names on-disk, the call will succeed, but will return the long-name
>> path instead. This outcome is also possible with NTFS volumes
>> because there's no guarantee that a short name will exist for a
>> given long name.

Some newer Windows 10 installations may have
NtfsDisable8dot3NameCreation enabled, thus preventing R from getting a
8.3 path to the temp directory.

I am taking the liberty of Cc-ing R-devel because this might warrant
adding a shQuote() call to install.packages().

-- 
Best regards,
Ivan


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Dec 13 11:06:29 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 13 Dec 2019 13:06:29 +0300
Subject: [R] install package av on centos 7
In-Reply-To: <BL0PR01MB4148A9B26480C013CF68FD7EF5580@BL0PR01MB4148.prod.exchangelabs.com>
References: <BL0PR01MB4148A9B26480C013CF68FD7EF5580@BL0PR01MB4148.prod.exchangelabs.com>
Message-ID: <20191213130629.3aaa4870@trisector>

On Mon, 9 Dec 2019 18:03:17 +0000
"Schneider, Dominik" <dominik.schneider at wsu.edu> wrote:

> (base) [dominik at cppc-server ffmpeg]$ ffmpeg
> ffmpeg version 2.8.15 Copyright (c) 2000-2018 the FFmpeg developers

According to SystemRequirements of av [*], it needs ffmpeg >= 3.2.
There is FFmpeg 3.4.7 for RHEL 7 in the RPM Fusion repo [**], which
should be possible on CentOS 7. Try this version instead of 2.8.15 from
Nux Dextop.

-- 
Best regards,
Ivan

[*] https://cran.r-project.org/package=av
[**]
https://download1.rpmfusion.org/free/el/updates/7/x86_64/repoview/ffmpeg.html


From d@v|d@@teven@ @end|ng |rom u@u@edu  Fri Dec 13 14:14:28 2019
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David Stevens)
Date: Fri, 13 Dec 2019 13:14:28 +0000
Subject: [R] Errors in R package installation
In-Reply-To: <20191213114604.0a60e65f@Tarkus>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
 <20191213114604.0a60e65f@Tarkus>
Message-ID: <f975d813-3c81-7a93-ad33-777e48e674f9@usu.edu>

Ivan - thanks for looking into this. My answers to your comments are below.

Cheers

David

On 12/13/2019 1:46 AM, Ivan Krylov wrote:

On Thu, 12 Dec 2019 15:48:13 +0000
David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:



Certain R packages will not install properly on my Windows 10
computer.



Certain, but not all? Which packages are you able to install on that
computer?


Too many to name - one is nlstools. Another is tinytex.  I updated many package after bookdown wouldn't install for the same reasons. Out of a list of ~20 packages to install, ~5 failed with a similar error message.  That sent me down the rabbit hole that brought me here.




Warning: invalid package 'C:\Users\David'
Warning: invalid package
'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'



This looks like a command line argument quoting issue.

I wonder why doesn't install.packages use shQuote to quote the file
name when calling system2(c("R", "CMD", "INSTALL", file)) to install a
downloaded source package:

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/packages2.R#L833

Maybe there should be shQuote(fil) instead, especially since R does
quote the file name when installing from local source tarballs:

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/packages2.R#L676



This happens on only a subset of packages I install or update.



I have a hypothesis: perhaps this only happens for packages with no
pre-built Windows binary available yet, since "win.binary" packages may
be installed by unpacking a zip file, without calling a command line
with potential space quoting issues:

I read a thread elsewhere that said a work around is to run options(pkgType='binary') before installation and the problem went away. Does this help.



https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/packages2.R#L491
->
https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/windows/install.packages.R#L263

Calling install.packages(..., verbose = TRUE) for both a succeeding and
a failing package might help to verify whether this is the case.



This is a relatively recent issue (i.e. I never saw it before
November - I've used R for ~15 years).



Just to confirm it: you had no problems on the same Windows 10 computer
with the same user name and %USERPROFILE% path as before?

Yes, this is the case. I do the regular Windows 10 updates and update R and RStudio as soon as I am aware there's a new version out. I haven't explicitly change %USERPROFILE%.

Apparently,
tempdir() used to return a 8.3 directory path on your computer, but now
doesn't - but that should not happen, since R_reInitTempDir()
explicitly asks for a 8.3 path:

tempdir() gives

tempdir()
[1] "C:\\Users\\David Stevens\\AppData\\Local\\Temp\\RtmpQpqh0t"


>

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/main/sysutils.c#L1810

Microsoft Docs page for GetShortPathName() says:



If you call GetShortPathName on a path that doesn't have any short
names on-disk, the call will succeed, but will return the long-name
path instead. This outcome is also possible with NTFS volumes
because there's no guarantee that a short name will exist for a
given long name.



Some newer Windows 10 installations may have
NtfsDisable8dot3NameCreation enabled, thus preventing R from getting a
8.3 path to the temp directory.

I am taking the liberty of Cc-ing R-devel because this might warrant
adding a shQuote() call to install.packages().


Thanks for looking into this.




--
David K Stevens, PhD, PE
Environmental Engineering Division
Civil and Environmental Engineering
Utah State University
8200 Old Main Hill
Logan, UT 83200-8200
(435) 797-3229
david.stevens at usu.edu<mailto:david.stevens at usu.edu>

	[[alternative HTML version deleted]]


From d@v|d@@teven@ @end|ng |rom u@u@edu  Fri Dec 13 14:19:54 2019
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David Stevens)
Date: Fri, 13 Dec 2019 13:19:54 +0000
Subject: [R] Errors in R package installation
In-Reply-To: <20191213114604.0a60e65f@Tarkus>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
 <20191213114604.0a60e65f@Tarkus>
Message-ID: <72d0996f-67ed-fc68-c1a9-d829b8719cd7@usu.edu>

Ivan

Here's a longer list. RStudio checked for what needs updating, I select all of them, and enter. The following is the console output (FYI - I tried this in plain Rgui.exe and got the same result - I don't think it's an RStudio issue). The failed installs are toward the bottom.

Best

David

> install.packages(c("callr", "cli", "data.table", "english", "exactRankTests", "glmnet", "leafpop", "lmerTest", "multcomp", "plyr", "quantreg", "R.utils", "renv", "RgoogleMaps", "rmarkdown", "satellite", "SparseM", "tinytex"), lib = "C:/Users/David Stevens/Documents/R/win-library/3.6")

  There are binary versions available but the source versions are
  later:
          binary source needs_compilation
lmerTest   3.1-0  3.1-1             FALSE
quantreg    5.52   5.54              TRUE
rmarkdown   1.18    2.0             FALSE
SparseM     1.77   1.78              TRUE

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/callr_3.4.0.zip'
Content type 'application/zip' length 356928 bytes (348 KB)
downloaded 348 KB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/cli_2.0.0.zip'
Content type 'application/zip' length 392358 bytes (383 KB)
downloaded 383 KB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/data.table_1.12.8.zip'
Content type 'application/zip' length 2277502 bytes (2.2 MB)
downloaded 2.2 MB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/english_1.2-4.zip'
Content type 'application/zip' length 134736 bytes (131 KB)
downloaded 131 KB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/exactRankTests_0.8-31.zip'
Content type 'application/zip' length 168031 bytes (164 KB)
downloaded 164 KB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/glmnet_3.0-2.zip'
Content type 'application/zip' length 1823093 bytes (1.7 MB)
downloaded 1.7 MB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/leafpop_0.0.5.zip'
Content type 'application/zip' length 1910754 bytes (1.8 MB)
downloaded 1.8 MB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/multcomp_1.4-11.zip'
Content type 'application/zip' length 730724 bytes (713 KB)
downloaded 713 KB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/plyr_1.8.5.zip'
Content type 'application/zip' length 1306165 bytes (1.2 MB)
downloaded 1.2 MB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/R.utils_2.9.2.zip'
Content type 'application/zip' length 1411713 bytes (1.3 MB)
downloaded 1.3 MB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/renv_0.9.2.zip'
Content type 'application/zip' length 820084 bytes (800 KB)
downloaded 800 KB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/RgoogleMaps_1.4.5.zip'
Content type 'application/zip' length 479429 bytes (468 KB)
downloaded 468 KB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/satellite_1.0.2.zip'
Content type 'application/zip' length 3227758 bytes (3.1 MB)
downloaded 3.1 MB

trying URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/tinytex_0.18.zip'
Content type 'application/zip' length 101040 bytes (98 KB)
downloaded 98 KB

package ?callr? successfully unpacked and MD5 sums checked
package ?cli? successfully unpacked and MD5 sums checked
package ?data.table? successfully unpacked and MD5 sums checked
Warning in install.packages :
  cannot remove prior installation of package ?data.table?
Warning in install.packages :
  problem copying C:\Users\David Stevens\Documents\R\win-library\3.6\00LOCK\data.table\libs\x64\datatable.dll to C:\Users\David Stevens\Documents\R\win-library\3.6\data.table\libs\x64\datatable.dll: Permission denied
Warning in install.packages :
  restored ?data.table?
package ?english? successfully unpacked and MD5 sums checked
package ?exactRankTests? successfully unpacked and MD5 sums checked
package ?glmnet? successfully unpacked and MD5 sums checked
package ?leafpop? successfully unpacked and MD5 sums checked
package ?multcomp? successfully unpacked and MD5 sums checked
package ?plyr? successfully unpacked and MD5 sums checked
package ?R.utils? successfully unpacked and MD5 sums checked
package ?renv? successfully unpacked and MD5 sums checked
package ?RgoogleMaps? successfully unpacked and MD5 sums checked
package ?satellite? successfully unpacked and MD5 sums checked
package ?tinytex? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\David Stevens\AppData\Local\Temp\RtmpkLEdno\downloaded_packages
installing the source packages ?lmerTest?, ?quantreg?, ?rmarkdown?, ?SparseM?

trying URL 'https://cloud.r-project.org/src/contrib/lmerTest_3.1-1.tar.gz'
Content type 'application/x-gzip' length 194447 bytes (189 KB)
downloaded 189 KB

trying URL 'https://cloud.r-project.org/src/contrib/quantreg_5.54.tar.gz'
Content type 'application/x-gzip' length 995368 bytes (972 KB)
downloaded 972 KB

trying URL 'https://cloud.r-project.org/src/contrib/rmarkdown_2.0.tar.gz'
Content type 'application/x-gzip' length 3186667 bytes (3.0 MB)
downloaded 3.0 MB

trying URL 'https://cloud.r-project.org/src/contrib/SparseM_1.78.tar.gz'
Content type 'application/x-gzip' length 735024 bytes (717 KB)
downloaded 717 KB

Warning: invalid package 'C:\Users\David'
Warning: invalid package 'Stevens\AppData\Local\Temp\RtmpkLEdno/downloaded_packages/lmerTest_3.1-1.tar.gz'
Error: ERROR: no packages specified
Warning in install.packages :
  installation of package ?lmerTest? had non-zero exit status
Warning: invalid package 'C:\Users\David'
Warning: invalid package 'Stevens\AppData\Local\Temp\RtmpkLEdno/downloaded_packages/rmarkdown_2.0.tar.gz'
Error: ERROR: no packages specified
Warning in install.packages :
  installation of package ?rmarkdown? had non-zero exit status
Warning: invalid package 'C:\Users\David'
Warning: invalid package 'Stevens\AppData\Local\Temp\RtmpkLEdno/downloaded_packages/SparseM_1.78.tar.gz'
Error: ERROR: no packages specified
Warning in install.packages :
  installation of package ?SparseM? had non-zero exit status
Warning: invalid package 'C:\Users\David'
Warning: invalid package 'Stevens\AppData\Local\Temp\RtmpkLEdno/downloaded_packages/quantreg_5.54.tar.gz'
Error: ERROR: no packages specified
Warning in install.packages :
  installation of package ?quantreg? had non-zero exit status

The downloaded source packages are in
        ?C:\Users\David Stevens\AppData\Local\Temp\RtmpkLEdno\downloaded_packages?


>
On 12/13/2019 1:46 AM, Ivan Krylov wrote:

On Thu, 12 Dec 2019 15:48:13 +0000
David Stevens <david.stevens at usu.edu><mailto:david.stevens at usu.edu> wrote:



Certain R packages will not install properly on my Windows 10
computer.



Certain, but not all? Which packages are you able to install on that
computer?



Warning: invalid package 'C:\Users\David'
Warning: invalid package
'Stevens\AppData\Local\Temp\Rtmpk5NqrI/downloaded_packages/callr_3.4.0.tar.gz'



This looks like a command line argument quoting issue.

I wonder why doesn't install.packages use shQuote to quote the file
name when calling system2(c("R", "CMD", "INSTALL", file)) to install a
downloaded source package:

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/packages2.R#L833

Maybe there should be shQuote(fil) instead, especially since R does
quote the file name when installing from local source tarballs:

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/packages2.R#L676



This happens on only a subset of packages I install or update.



I have a hypothesis: perhaps this only happens for packages with no
pre-built Windows binary available yet, since "win.binary" packages may
be installed by unpacking a zip file, without calling a command line
with potential space quoting issues:

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/packages2.R#L491
->
https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/windows/install.packages.R#L263

Calling install.packages(..., verbose = TRUE) for both a succeeding and
a failing package might help to verify whether this is the case.



This is a relatively recent issue (i.e. I never saw it before
November - I've used R for ~15 years).



Just to confirm it: you had no problems on the same Windows 10 computer
with the same user name and %USERPROFILE% path as before? Apparently,
tempdir() used to return a 8.3 directory path on your computer, but now
doesn't - but that should not happen, since R_reInitTempDir()
explicitly asks for a 8.3 path:

https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/main/sysutils.c#L1810

Microsoft Docs page for GetShortPathName() says:



If you call GetShortPathName on a path that doesn't have any short
names on-disk, the call will succeed, but will return the long-name
path instead. This outcome is also possible with NTFS volumes
because there's no guarantee that a short name will exist for a
given long name.



Some newer Windows 10 installations may have
NtfsDisable8dot3NameCreation enabled, thus preventing R from getting a
8.3 path to the temp directory.

I am taking the liberty of Cc-ing R-devel because this might warrant
adding a shQuote() call to install.packages().



--
David K Stevens, PhD, PE
Environmental Engineering Division
Civil and Environmental Engineering
Utah State University
8200 Old Main Hill
Logan, UT 83200-8200
(435) 797-3229
david.stevens at usu.edu<mailto:david.stevens at usu.edu>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Dec 13 15:12:56 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 13 Dec 2019 17:12:56 +0300
Subject: [R] Errors in R package installation
In-Reply-To: <f975d813-3c81-7a93-ad33-777e48e674f9@usu.edu>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
 <20191213114604.0a60e65f@Tarkus>
 <f975d813-3c81-7a93-ad33-777e48e674f9@usu.edu>
Message-ID: <20191213171256.3be0aad7@trisector>

On Fri, 13 Dec 2019 13:19:54 +0000
David Stevens <david.stevens at usu.edu> wrote:

>   There are binary versions available but the source versions are
>   later:

Okay, that would be the reason why would R on Windows try to install a
source package instead of a binary package. One can also see that callr
has just been successfully installed from a binary package (that took
time to be built from a freshly updated source package and was
unavailable yesterday) -- but now there are other updated packages that
cannot be installed.

On Fri, 13 Dec 2019 13:14:28 +0000
David Stevens <david.stevens at usu.edu> wrote:

> I read a thread elsewhere that said a work around is to run
> options(pkgType='binary') before installation and the problem went
> away. Does this help.

Yes, this again points us at the differences between installing source
packages and "win.binary" packages.

> Yes, this is the case. I do the regular Windows 10 updates and update
> R and RStudio as soon as I am aware there's a new version out. I
> haven't explicitly change %USERPROFILE%.

Since new packages are published all the time, it is likely that your R
installation was able to install source packages successfully, until
recently.

> tempdir() gives
> 
> tempdir()
> [1] "C:\\Users\\David Stevens\\AppData\\Local\\Temp\\RtmpQpqh0t"

Yes, this is a problem.

file.path(tempdir(), "downloaded_packages") is passed to
download.packages() and used to store the downloaded files. Eventually,
download.packages() returns destination file paths (which now contain
spaces), which are then passed to what amounts to:

system2(
 command = file.path(R.home("bin"), "R"),
 args = c("CMD", "INSTALL", path), ...
)

system2() uses paste(c(env, shQuote(command), args), collapse = " ") to
form a command line and eventually passes that command line to
CreateProcess(). The path value is left unquoted, causing the error
observed above.

I believe that this is a bug in install.packages() and that the
`fil` argument in [*] should be quoted using shQuote() just like it is
quoted in all other invocations of R CMD INSTALL in the same file.

A workaround that should have worked but didn't was to pass a writeable
path without spaces as a destdir = ... argument to install.packages().
I am not sure why did install.packages() decide to use C:/myRLib as the
library instead of a temp directory to download files in (we just need
a temp directory, not a separate library). Try the following again in a
clean session?

install.packages(
 c('lmerTest', 'quantreg', 'rmarkdown', 'SparseM'),
 lib = .libPaths()[1L],
 destdir = 'c:/myRLib'
)

-- 
Best regards,
Ivan

[*]
https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/utils/R/packages2.R#L839


From d@v|d@@teven@ @end|ng |rom u@u@edu  Fri Dec 13 15:21:06 2019
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David Stevens)
Date: Fri, 13 Dec 2019 14:21:06 +0000
Subject: [R] Errors in R package installation
In-Reply-To: <20191213171256.3be0aad7@trisector>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
 <20191213114604.0a60e65f@Tarkus>
 <f975d813-3c81-7a93-ad33-777e48e674f9@usu.edu>
 <20191213171256.3be0aad7@trisector>
Message-ID: <d8fde46d-8bb1-ade0-c421-a15db85f8ccd@usu.edu>

I started a new session and entered

> rm(list=ls())
> install.packages(
+  c('lmerTest', 'quantreg', 'rmarkdown', 'SparseM'),
+  lib = .libPaths()[1L],
+  destdir = 'c:/myRLib'
+ )

And this is the result:

  There are binary versions available but the
  source versions are later:
          binary source needs_compilation
lmerTest   3.1-0  3.1-1             FALSE
quantreg    5.52   5.54              TRUE
rmarkdown   1.18    2.0             FALSE
SparseM     1.77   1.78              TRUE

installing the source packages ?lmerTest?, ?quantreg?, ?rmarkdown?, ?SparseM?

trying URL 'https://cloud.r-project.org/src/contrib/lmerTest_3.1-1.tar.gz'
Content type 'application/x-gzip' length 194447 bytes (189 KB)
downloaded 189 KB

trying URL 'https://cloud.r-project.org/src/contrib/quantreg_5.54.tar.gz'
Content type 'application/x-gzip' length 995368 bytes (972 KB)
downloaded 972 KB

trying URL 'https://cloud.r-project.org/src/contrib/rmarkdown_2.0.tar.gz'
Content type 'application/x-gzip' length 3186667 bytes (3.0 MB)
downloaded 3.0 MB

trying URL 'https://cloud.r-project.org/src/contrib/SparseM_1.78.tar.gz'
Content type 'application/x-gzip' length 735024 bytes (717 KB)
downloaded 717 KB

* installing *source* package 'lmerTest' ...
** package 'lmerTest' successfully unpacked and MD5 sums checked
** using staged installation
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
Fatal error: cannot open file 'C:\Users\David': No such file or directory

ERROR: lazy loading failed for package 'lmerTest'
* removing 'C:/myRLib/lmerTest'
Warning in install.packages :
  installation of package ?lmerTest? had non-zero exit status
* installing *source* package 'rmarkdown' ...
** package 'rmarkdown' successfully unpacked and MD5 sums checked
** using staged installation
** R
** inst
** byte-compile and prepare package for lazy loading
Fatal error: cannot open file 'C:\Users\David': No such file or directory

ERROR: lazy loading failed for package 'rmarkdown'
* removing 'C:/myRLib/rmarkdown'
Warning in install.packages :
  installation of package ?rmarkdown? had non-zero exit status
* installing *source* package 'SparseM' ...
** package 'SparseM' successfully unpacked and MD5 sums checked
** using staged installation
** libs

*** arch - i386
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c bckslv.f -o bckslv.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c chol.f -o chol.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c chol2csr.f -o chol2csr.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c cholesky.f -o cholesky.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c csr.f -o csr.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c extract.f -o extract.o
C:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-3.6.2/include" -DNDEBUG          -O3 -Wall  -std=gnu99 -mtune=generic -c init.c -o init.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c sparskit.f -o sparskit.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c subscr.f -o subscr.o
C:/Rtools/mingw_32/bin/gcc -shared -s -static-libgcc -o SparseM.dll tmp.def bckslv.o chol.o chol2csr.o cholesky.o csr.o extract.o init.o sparskit.o subscr.o -lgfortran -lm -lquadmath -LC:/PROGRA~1/R/R-3.6.2/bin/i386 -lR
installing to C:/myRLib/00LOCK-SparseM/00new/SparseM/libs/i386

*** arch - x64
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c bckslv.f -o bckslv.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c chol.f -o chol.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c chol2csr.f -o chol2csr.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c cholesky.f -o cholesky.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c csr.f -o csr.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c extract.f -o extract.o
C:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-3.6.2/include" -DNDEBUG          -O2 -Wall  -std=gnu99 -mtune=generic -c init.c -o init.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c sparskit.f -o sparskit.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c subscr.f -o subscr.o
C:/Rtools/mingw_64/bin/gcc -shared -s -static-libgcc -o SparseM.dll tmp.def bckslv.o chol.o chol2csr.o cholesky.o csr.o extract.o init.o sparskit.o subscr.o -lgfortran -lm -lquadmath -LC:/PROGRA~1/R/R-3.6.2/bin/x64 -lR
installing to C:/myRLib/00LOCK-SparseM/00new/SparseM/libs/x64
** R
** data
** demo
** inst
** byte-compile and prepare package for lazy loading
Fatal error: cannot open file 'C:\Users\David': No such file or directory

ERROR: lazy loading failed for package 'SparseM'
* removing 'C:/myRLib/SparseM'
Warning in install.packages :
  installation of package ?SparseM? had non-zero exit status
* installing *source* package 'quantreg' ...
** package 'quantreg' successfully unpacked and MD5 sums checked
** using staged installation
** libs

*** arch - i386
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c boot.f -o boot.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c bound.f -o bound.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c boundc.f -o boundc.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c brute.f -o brute.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c chlfct.f -o chlfct.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c cholesky.f -o cholesky.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c combos.f -o combos.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c crqf.f -o crqf.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c crqfnb.f -o crqfnb.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c dsel05.f -o dsel05.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c etime.f -o etime.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c extract.f -o extract.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c idmin.f -o idmin.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c iswap.f -o iswap.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c kuantiles.f -o kuantiles.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c linpack.f -o linpack.o
C:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-3.6.2/include" -DNDEBUG          -O3 -Wall  -std=gnu99 -mtune=generic -c mcmb.c -o mcmb.o
mcmb.c: In function 'func':
mcmb.c:176:32: warning: variable 'large' set but not used [-Wunused-but-set-variable]
   double taustar, pwtsum, ans, large;
                                ^
mcmb.c:175:16: warning: variable 'mm' set but not used [-Wunused-but-set-variable]
   unsigned int mm;
                ^
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c penalty.f -o penalty.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c powell.f -o powell.o
C:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-3.6.2/include" -DNDEBUG          -O3 -Wall  -std=gnu99 -mtune=generic -c quantreg_init.c -o quantreg_init.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c rls.f -o rls.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c rq0.f -o rq0.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c rq1.f -o rq1.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c rqbr.f -o rqbr.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c rqfn.f -o rqfn.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c rqfnb.f -o rqfnb.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c rqfnc.f -o rqfnc.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c rqs.f -o rqs.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c sakj.f -o sakj.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c sparskit2.f -o sparskit2.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c srqfn.f -o srqfn.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c srqfnc.f -o srqfnc.o
C:/Rtools/mingw_32/bin/gfortran      -O3  -mtune=generic -c srtpai.f -o srtpai.o
C:/Rtools/mingw_32/bin/gcc -shared -s -static-libgcc -o quantreg.dll tmp.def boot.o bound.o boundc.o brute.o chlfct.o cholesky.o combos.o crqf.o crqfnb.o dsel05.o etime.o extract.o idmin.o iswap.o kuantiles.o linpack.o mcmb.o penalty.o powell.o quantreg_init.o rls.o rq0.o rq1.o rqbr.o rqfn.o rqfnb.o rqfnc.o rqs.o sakj.o sparskit2.o srqfn.o srqfnc.o srtpai.o -LC:/PROGRA~1/R/R-3.6.2/bin/i386 -lRlapack -LC:/PROGRA~1/R/R-3.6.2/bin/i386 -lRblas -lgfortran -lm -lquadmath -lgfortran -lm -lquadmath -LC:/PROGRA~1/R/R-3.6.2/bin/i386 -lR
installing to C:/myRLib/00LOCK-quantreg/00new/quantreg/libs/i386

*** arch - x64
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c boot.f -o boot.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c bound.f -o bound.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c boundc.f -o boundc.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c brute.f -o brute.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c chlfct.f -o chlfct.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c cholesky.f -o cholesky.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c combos.f -o combos.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c crqf.f -o crqf.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c crqfnb.f -o crqfnb.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c dsel05.f -o dsel05.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c etime.f -o etime.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c extract.f -o extract.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c idmin.f -o idmin.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c iswap.f -o iswap.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c kuantiles.f -o kuantiles.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c linpack.f -o linpack.o
C:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-3.6.2/include" -DNDEBUG          -O2 -Wall  -std=gnu99 -mtune=generic -c mcmb.c -o mcmb.o
mcmb.c: In function 'func':
mcmb.c:176:32: warning: variable 'large' set but not used [-Wunused-but-set-variable]
   double taustar, pwtsum, ans, large;
                                ^
mcmb.c:175:16: warning: variable 'mm' set but not used [-Wunused-but-set-variable]
   unsigned int mm;
                ^
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c penalty.f -o penalty.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c powell.f -o powell.o
C:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-3.6.2/include" -DNDEBUG          -O2 -Wall  -std=gnu99 -mtune=generic -c quantreg_init.c -o quantreg_init.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c rls.f -o rls.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c rq0.f -o rq0.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c rq1.f -o rq1.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c rqbr.f -o rqbr.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c rqfn.f -o rqfn.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c rqfnb.f -o rqfnb.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c rqfnc.f -o rqfnc.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c rqs.f -o rqs.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c sakj.f -o sakj.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c sparskit2.f -o sparskit2.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c srqfn.f -o srqfn.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c srqfnc.f -o srqfnc.o
C:/Rtools/mingw_64/bin/gfortran      -O2  -mtune=generic -c srtpai.f -o srtpai.o
C:/Rtools/mingw_64/bin/gcc -shared -s -static-libgcc -o quantreg.dll tmp.def boot.o bound.o boundc.o brute.o chlfct.o cholesky.o combos.o crqf.o crqfnb.o dsel05.o etime.o extract.o idmin.o iswap.o kuantiles.o linpack.o mcmb.o penalty.o powell.o quantreg_init.o rls.o rq0.o rq1.o rqbr.o rqfn.o rqfnb.o rqfnc.o rqs.o sakj.o sparskit2.o srqfn.o srqfnc.o srtpai.o -LC:/PROGRA~1/R/R-3.6.2/bin/x64 -lRlapack -LC:/PROGRA~1/R/R-3.6.2/bin/x64 -lRblas -lgfortran -lm -lquadmath -lgfortran -lm -lquadmath -LC:/PROGRA~1/R/R-3.6.2/bin/x64 -lR
installing to C:/myRLib/00LOCK-quantreg/00new/quantreg/libs/x64
** R
** data
** demo
** inst
** byte-compile and prepare package for lazy loading
Fatal error: cannot open file 'C:\Users\David': No such file or directory

ERROR: lazy loading failed for package 'quantreg'
* removing 'C:/myRLib/quantreg'
Warning in install.packages :
  installation of package ?quantreg? had non-zero exit status

On 12/13/2019 7:12 AM, Ivan Krylov wrote:

install.packages(
 c('lmerTest', 'quantreg', 'rmarkdown', 'SparseM'),
 lib = .libPaths()[1L],
 destdir = 'c:/myRLib'
)

--
David K Stevens, PhD, PE
Environmental Engineering Division
Civil and Environmental Engineering
Utah State University
8200 Old Main Hill
Logan, UT 83200-8200
(435) 797-3229
david.stevens at usu.edu<mailto:david.stevens at usu.edu>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Dec 13 15:43:29 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 13 Dec 2019 17:43:29 +0300
Subject: [R] Errors in R package installation
In-Reply-To: <d8fde46d-8bb1-ade0-c421-a15db85f8ccd@usu.edu>
References: <CAP+bYWBtAJcBZChRNhq-=mptoyKeX=aGO4w+4Vaux7KZizgK+A@mail.gmail.com>
 <0ca7633b-0eba-aefc-c48b-8c0f00bab9f6@usu.edu>
 <20191213114604.0a60e65f@Tarkus>
 <f975d813-3c81-7a93-ad33-777e48e674f9@usu.edu>
 <20191213171256.3be0aad7@trisector>
 <d8fde46d-8bb1-ade0-c421-a15db85f8ccd@usu.edu>
Message-ID: <20191213174329.5bbb1a2c@trisector>

On Fri, 13 Dec 2019 14:21:06 +0000
David Stevens <david.stevens at usu.edu> wrote:

> ** byte-compile and prepare package for lazy loading
> Fatal error: cannot open file 'C:\Users\David': No such file or
> directory
> 
> ERROR: lazy loading failed for package 'rmarkdown'

Oh. Sorry, that seems to be yet another place where R is not able to
handle temporary files with spaces in their paths.

What happens is:

1. R CMD INSTALL wants to run tools:::makeLazyLoading(...) in a
   sub-process.
2. An internal function creates a temporary file (using tempfile()),
   writes all the required commands inside it and tries to run Rterm.exe
   -f <path to the temporary file>.
3. That path is also unquoted and it also contains spaces because
   that's what GetShortPathName() returned to R.
4. C:\Users\David
   Stevens\AppData\Local\Temp\Rtmpblablabla/Rinblablablabla becomes two
   separate arguments to Rterm.exe -f.

Solution: use shQuote(Rin) in [*] instead of just Rin. I will try to
report this and the previous problem as a bug.

Workaround: try setting the TMPDIR environment variable to something
without spaces (for example, the same c:/myRLib) before launching R.
(Use Sys.getenv('TMPDIR') and tempdir() to verify that it's
working.) This should help us sidestep any remaining bugs related to
temp paths containing spaces.

-- 
Best regards,
Ivan

[*]
https://github.com/wch/r-source/blob/e554f7f12b22868bdae51aadaeea4d56c9f87a32/src/library/tools/R/check.R#L125


From dom|n|k@@chne|der @end|ng |rom w@u@edu  Fri Dec 13 20:00:52 2019
From: dom|n|k@@chne|der @end|ng |rom w@u@edu (Schneider, Dominik)
Date: Fri, 13 Dec 2019 19:00:52 +0000
Subject: [R] install package av on centos 7
In-Reply-To: <20191213130629.3aaa4870@trisector>
References: <BL0PR01MB4148A9B26480C013CF68FD7EF5580@BL0PR01MB4148.prod.exchangelabs.com>
 <20191213130629.3aaa4870@trisector>
Message-ID: <CY4PR0101MB315702CDF575A9F4AD0B4F2EF5540@CY4PR0101MB3157.prod.exchangelabs.com>

Hi Ivan - Thank you for the suggestion. Unfortunately after updating both ffmpeg and ffmpeg-devel from 
https://centos.pkgs.org/7/okey-x86_64/ffmpeg-3.2.4-1.el7.centos.x86_64.rpm.html
it still will not install av in R.

any further suggestions?

(base) [dominik at cppc-server GoldStandard2]$ ffmpeg
ffmpeg version 3.2.4 Copyright (c) 2000-2017 the FFmpeg developers
  built with gcc 4.8.5 (GCC) 20150623 (Red Hat 4.8.5-11)
  configuration: --prefix=/usr --bindir=/usr/bin --datadir=/usr/share/ffmpeg --incdir=/usr/include --libdir=/usr/lib64 --shlibdir=/usr/lib64 --mandir=/usr/share/man --extra-cflags='-fPIC -I/usr/include/samba-4.0' --extra-ldflags='-lstdc++ -lsmbclient' --enable-shared --enable-gpl --enable-version3 --enable-nonfree --enable-avresample --enable-videotoolbox --enable-bzlib --enable-fontconfig --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libdc1394 --enable-libgsm --enable-libmp3lame --enable-libnut --enable-libopenh264 --enable-libopenjpeg --enable-librtmp --enable-libvorbis --enable-libx264 --enable-libxvid --enable-memalign-hack --extra-ldflags=-fPIC --extra-cflags=-fPIC --enable-pthreads --enable-postproc --enable-avfilter --enable-x11grab --enable-libopencv --enable-libcdio --enable-libfreetype --enable-libvo-amrwbenc --enable-libfdk-aac --enable-libfribidi --enable-libtheora --enable-libass --enable-libbluray --enable-libv4l2 --enable-openal --enable-libschroedinger --enable-libpulse --enable-gnutls --enable-openssl --enable-libspeex --enable-libgme --enable-libzmq --enable-libshine --enable-libsmbclient --enable-libgsm --enable-libtwolame --enable-libopus --enable-ladspa --enable-libcaca --enable-libiec61883 --enable-libssh --enable-libvidstab --enable-libwavpack --enable-libzvbi --enable-pic --enable-thumb --enable-libbs2b --enable-libx265 --enable-opengl --enable-libsnappy
  libavutil      55. 34.101 / 55. 34.101
  libavcodec     57. 64.101 / 57. 64.101
  libavformat    57. 56.101 / 57. 56.101
  libavdevice    57.  1.100 / 57.  1.100
  libavfilter     6. 65.100 /  6. 65.100
  libavresample   3.  1.  0 /  3.  1.  0
  libswscale      4.  2.100 /  4.  2.100
  libswresample   2.  3.100 /  2.  3.100
  libpostproc    54.  1.100 / 54.  1.100
Hyper fast Audio and Video encoder
usage: ffmpeg [options] [[infile options] -i infile]... {[outfile options] outfile}...

Use -h to get full help or, even better, run 'man ffmpeg'

> install.packages('av', configure.vars = c("LIB_DIR=/usr/lib64","INCLUDE_DIR=/usr/include/"))
Installing package into '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5'
(as 'lib' is unspecified)
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  720k  100  720k    0     0  1028k      0 --:--:-- --:--:-- --:--:-- 1028k
* installing *source* package 'av' ...
** package 'av' successfully unpacked and MD5 sums checked
Found INCLUDE_DIR and/or LIB_DIR!
Using PKG_CFLAGS=-I/usr/include/
Using PKG_LIBS=-L/usr/lib64 -lavfilter
** libs
rm -f av.so formats.o info.o init.o util.o video.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c formats.c -o formats.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c info.c -o info.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c init.c -o init.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c util.c -o util.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c video.c -o video.o
g++ -std=gnu++11 -shared -L/opt/microsoft/ropen/3.5.3/lib64/R/lib -o av.so formats.o info.o init.o util.o video.o -L/usr/lib64 -lavfilter -L/opt/microsoft/ropen/3.5.3/lib64/R/lib -lR
installing to /home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av/libs
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
Error: package or namespace load failed for 'av' in dyn.load(file, DLLpath = DLLpath, ...):
 unable to load shared object '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av/libs/av.so':
  /lib64/libavcodec.so.57: undefined symbol: opus_multistream_surround_encoder_create
Error: loading failed
Execution halted
ERROR: loading failed
* removing '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av'

The downloaded source packages are in
        '/tmp/RtmpVS3V8E/downloaded_packages'
Warning message:
In install.packages("av", configure.vars = c("LIB_DIR=/usr/lib64",  :
  installation of package 'av' had non-zero exit status




> install.packages('av', configure.vars = c("LIB_DIR=/usr/lib64","INCLUDE_DIR=/usr/include/ffmpeg"))
Installing package into '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5'
(as 'lib' is unspecified)
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  720k  100  720k    0     0   399k      0  0:00:01  0:00:01 --:--:--  400k
* installing *source* package 'av' ...
** package 'av' successfully unpacked and MD5 sums checked
Found INCLUDE_DIR and/or LIB_DIR!
Using PKG_CFLAGS=-I/usr/include/ffmpeg
Using PKG_LIBS=-L/usr/lib64 -lavfilter
** libs
rm -f av.so formats.o info.o init.o util.o video.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c formats.c -o formats.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c info.c -o info.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c init.c -o init.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c util.c -o util.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c video.c -o video.o
g++ -std=gnu++11 -shared -L/opt/microsoft/ropen/3.5.3/lib64/R/lib -o av.so formats.o info.o init.o util.o video.o -L/usr/lib64 -lavfilter -L/opt/microsoft/ropen/3.5.3/lib64/R/lib -lR
installing to /home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av/libs
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
Error: package or namespace load failed for 'av' in dyn.load(file, DLLpath = DLLpath, ...):
 unable to load shared object '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av/libs/av.so':
  /lib64/libavcodec.so.57: undefined symbol: opus_multistream_surround_encoder_create
Error: loading failed
Execution halted
ERROR: loading failed
* removing '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av'

The downloaded source packages are in
        '/tmp/RtmpVS3V8E/downloaded_packages'
Warning message:
In install.packages("av", configure.vars = c("LIB_DIR=/usr/lib64",  :
  installation of package 'av' had non-zero exit status
>


-----Original Message-----
From: Ivan Krylov <krylov.r00t at gmail.com> 
Sent: Friday, December 13, 2019 02:06
To: Schneider, Dominik <dominik.schneider at wsu.edu>
Cc: r-help at r-project.org
Subject: Re: [R] install package av on centos 7

On Mon, 9 Dec 2019 18:03:17 +0000
"Schneider, Dominik" <dominik.schneider at wsu.edu> wrote:

> (base) [dominik at cppc-server ffmpeg]$ ffmpeg ffmpeg version 2.8.15 
> Copyright (c) 2000-2018 the FFmpeg developers

According to SystemRequirements of av [*], it needs ffmpeg >= 3.2.
There is FFmpeg 3.4.7 for RHEL 7 in the RPM Fusion repo [**], which should be possible on CentOS 7. Try this version instead of 2.8.15 from Nux Dextop.

--
Best regards,
Ivan

[*] https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_package-3Dav&d=DwICAg&c=C3yme8gMkxg_ihJNXS06ZyWk4EJm8LdrrvxQb-Je7sw&r=mfF42lNlc_eXjwWhfTYoU_T7y-aauTyI1-BCcVTO9VI&m=BeHA4IOom-6-VTtfrGh08ztY42Wiy_Qrielm4l3YfdU&s=3yeHj1gLh2dp8tEsItyw9QqsrecnlTSg9FEpe94dKcQ&e=
[**]
https://urldefense.proofpoint.com/v2/url?u=https-3A__download1.rpmfusion.org_free_el_updates_7_x86-5F64_repoview_ffmpeg.html&d=DwICAg&c=C3yme8gMkxg_ihJNXS06ZyWk4EJm8LdrrvxQb-Je7sw&r=mfF42lNlc_eXjwWhfTYoU_T7y-aauTyI1-BCcVTO9VI&m=BeHA4IOom-6-VTtfrGh08ztY42Wiy_Qrielm4l3YfdU&s=Vtsrx5Rbu2uyWS6EMBJtLx5-czVCxRPOkrUNXRDdEIw&e= 


From dom|n|k@@chne|der @end|ng |rom w@u@edu  Fri Dec 13 22:55:44 2019
From: dom|n|k@@chne|der @end|ng |rom w@u@edu (Schneider, Dominik)
Date: Fri, 13 Dec 2019 21:55:44 +0000
Subject: [R] install package av on centos 7
In-Reply-To: <CY4PR0101MB315702CDF575A9F4AD0B4F2EF5540@CY4PR0101MB3157.prod.exchangelabs.com>
References: <BL0PR01MB4148A9B26480C013CF68FD7EF5580@BL0PR01MB4148.prod.exchangelabs.com>
 <20191213130629.3aaa4870@trisector>
 <CY4PR0101MB315702CDF575A9F4AD0B4F2EF5540@CY4PR0101MB3157.prod.exchangelabs.com>
Message-ID: <CY4PR0101MB31576B9D465838953FF60266F5540@CY4PR0101MB3157.prod.exchangelabs.com>

It worked. Thank you for your help!
I found a v2.* of ffmpeg-libs installed evn though I had v3.* of the other ffmpeg packages so I removed this and then reinstalled ffmpeg ffmpeg-devel and ffmpeg-libs. I also removed the 'okay' repo I had installed and added rpmfusion repo as suggested although I am assuming this did not solve the problem in itself.

Thanks again!

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Schneider, Dominik
Sent: Friday, December 13, 2019 11:01
To: Ivan Krylov <krylov.r00t at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] install package av on centos 7

Hi Ivan - Thank you for the suggestion. Unfortunately after updating both ffmpeg and ffmpeg-devel from https://urldefense.proofpoint.com/v2/url?u=https-3A__centos.pkgs.org_7_okey-2Dx86-5F64_ffmpeg-2D3.2.4-2D1.el7.centos.x86-5F64.rpm.html&d=DwIFAg&c=C3yme8gMkxg_ihJNXS06ZyWk4EJm8LdrrvxQb-Je7sw&r=mfF42lNlc_eXjwWhfTYoU_T7y-aauTyI1-BCcVTO9VI&m=ALpbJngXym56rhboohPLRr4u5ssQzfjBbIY3prWRREA&s=oyGHLSUv4uBxQVPxwXQiyxoqoy1nzNuxLSZYWOIa_Y4&e=
it still will not install av in R.

any further suggestions?

(base) [dominik at cppc-server GoldStandard2]$ ffmpeg ffmpeg version 3.2.4 Copyright (c) 2000-2017 the FFmpeg developers
  built with gcc 4.8.5 (GCC) 20150623 (Red Hat 4.8.5-11)
  configuration: --prefix=/usr --bindir=/usr/bin --datadir=/usr/share/ffmpeg --incdir=/usr/include --libdir=/usr/lib64 --shlibdir=/usr/lib64 --mandir=/usr/share/man --extra-cflags='-fPIC -I/usr/include/samba-4.0' --extra-ldflags='-lstdc++ -lsmbclient' --enable-shared --enable-gpl --enable-version3 --enable-nonfree --enable-avresample --enable-videotoolbox --enable-bzlib --enable-fontconfig --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libdc1394 --enable-libgsm --enable-libmp3lame --enable-libnut --enable-libopenh264 --enable-libopenjpeg --enable-librtmp --enable-libvorbis --enable-libx264 --enable-libxvid --enable-memalign-hack --extra-ldflags=-fPIC --extra-cflags=-fPIC --enable-pthreads --enable-postproc --enable-avfilter --enable-x11grab --enable-libopencv --enable-libcdio --enable-libfreetype --enable-libvo-amrwbenc --enable-libfdk-aac --enable-libfribidi --enable-libtheora --enable-libass --enable-libbluray --enable-libv4l2 --enable-openal --enable-libschroedinger --enable-libpulse --enable-gnutls --enable-openssl --enable-libspeex --enable-libgme --enable-libzmq --enable-libshine --enable-libsmbclient --enable-libgsm --enable-libtwolame --enable-libopus --enable-ladspa --enable-libcaca --enable-libiec61883 --enable-libssh --enable-libvidstab --enable-libwavpack --enable-libzvbi --enable-pic --enable-thumb --enable-libbs2b --enable-libx265 --enable-opengl --enable-libsnappy
  libavutil      55. 34.101 / 55. 34.101
  libavcodec     57. 64.101 / 57. 64.101
  libavformat    57. 56.101 / 57. 56.101
  libavdevice    57.  1.100 / 57.  1.100
  libavfilter     6. 65.100 /  6. 65.100
  libavresample   3.  1.  0 /  3.  1.  0
  libswscale      4.  2.100 /  4.  2.100
  libswresample   2.  3.100 /  2.  3.100
  libpostproc    54.  1.100 / 54.  1.100
Hyper fast Audio and Video encoder
usage: ffmpeg [options] [[infile options] -i infile]... {[outfile options] outfile}...

Use -h to get full help or, even better, run 'man ffmpeg'

> install.packages('av', configure.vars = 
> c("LIB_DIR=/usr/lib64","INCLUDE_DIR=/usr/include/"))
Installing package into '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5'
(as 'lib' is unspecified)
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  720k  100  720k    0     0  1028k      0 --:--:-- --:--:-- --:--:-- 1028k
* installing *source* package 'av' ...
** package 'av' successfully unpacked and MD5 sums checked Found INCLUDE_DIR and/or LIB_DIR!
Using PKG_CFLAGS=-I/usr/include/
Using PKG_LIBS=-L/usr/lib64 -lavfilter
** libs
rm -f av.so formats.o info.o init.o util.o video.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c formats.c -o formats.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c info.c -o info.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c init.c -o init.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c util.c -o util.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c video.c -o video.o
g++ -std=gnu++11 -shared -L/opt/microsoft/ropen/3.5.3/lib64/R/lib -o 
g++ av.so formats.o info.o init.o util.o video.o -L/usr/lib64 -lavfilter 
g++ -L/opt/microsoft/ropen/3.5.3/lib64/R/lib -lR
installing to /home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av/libs
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
Error: package or namespace load failed for 'av' in dyn.load(file, DLLpath = DLLpath, ...):
 unable to load shared object '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av/libs/av.so':
  /lib64/libavcodec.so.57: undefined symbol: opus_multistream_surround_encoder_create
Error: loading failed
Execution halted
ERROR: loading failed
* removing '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av'

The downloaded source packages are in
        '/tmp/RtmpVS3V8E/downloaded_packages'
Warning message:
In install.packages("av", configure.vars = c("LIB_DIR=/usr/lib64",  :
  installation of package 'av' had non-zero exit status




> install.packages('av', configure.vars = 
> c("LIB_DIR=/usr/lib64","INCLUDE_DIR=/usr/include/ffmpeg"))
Installing package into '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5'
(as 'lib' is unspecified)
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  720k  100  720k    0     0   399k      0  0:00:01  0:00:01 --:--:--  400k
* installing *source* package 'av' ...
** package 'av' successfully unpacked and MD5 sums checked Found INCLUDE_DIR and/or LIB_DIR!
Using PKG_CFLAGS=-I/usr/include/ffmpeg
Using PKG_LIBS=-L/usr/lib64 -lavfilter
** libs
rm -f av.so formats.o info.o init.o util.o video.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c formats.c -o formats.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c info.c -o info.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c init.c -o init.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c util.c -o util.o
gcc -std=gnu99 -I/opt/microsoft/ropen/3.5.3/lib64/R/include -DNDEBUG -I/usr/include/ffmpeg   -DU_STATIC_IMPLEMENTATION  -fvisibility=hidden -fpic  -DU_STATIC_IMPLEMENTATION -O2 -g  -c video.c -o video.o
g++ -std=gnu++11 -shared -L/opt/microsoft/ropen/3.5.3/lib64/R/lib -o 
g++ av.so formats.o info.o init.o util.o video.o -L/usr/lib64 -lavfilter 
g++ -L/opt/microsoft/ropen/3.5.3/lib64/R/lib -lR
installing to /home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av/libs
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
Error: package or namespace load failed for 'av' in dyn.load(file, DLLpath = DLLpath, ...):
 unable to load shared object '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av/libs/av.so':
  /lib64/libavcodec.so.57: undefined symbol: opus_multistream_surround_encoder_create
Error: loading failed
Execution halted
ERROR: loading failed
* removing '/home/dominik/R/x86_64-pc-linux-gnu-library/3.5/av'

The downloaded source packages are in
        '/tmp/RtmpVS3V8E/downloaded_packages'
Warning message:
In install.packages("av", configure.vars = c("LIB_DIR=/usr/lib64",  :
  installation of package 'av' had non-zero exit status
>


-----Original Message-----
From: Ivan Krylov <krylov.r00t at gmail.com>
Sent: Friday, December 13, 2019 02:06
To: Schneider, Dominik <dominik.schneider at wsu.edu>
Cc: r-help at r-project.org
Subject: Re: [R] install package av on centos 7

On Mon, 9 Dec 2019 18:03:17 +0000
"Schneider, Dominik" <dominik.schneider at wsu.edu> wrote:

> (base) [dominik at cppc-server ffmpeg]$ ffmpeg ffmpeg version 2.8.15 
> Copyright (c) 2000-2018 the FFmpeg developers

According to SystemRequirements of av [*], it needs ffmpeg >= 3.2.
There is FFmpeg 3.4.7 for RHEL 7 in the RPM Fusion repo [**], which should be possible on CentOS 7. Try this version instead of 2.8.15 from Nux Dextop.

--
Best regards,
Ivan

[*] https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_package-3Dav&d=DwICAg&c=C3yme8gMkxg_ihJNXS06ZyWk4EJm8LdrrvxQb-Je7sw&r=mfF42lNlc_eXjwWhfTYoU_T7y-aauTyI1-BCcVTO9VI&m=BeHA4IOom-6-VTtfrGh08ztY42Wiy_Qrielm4l3YfdU&s=3yeHj1gLh2dp8tEsItyw9QqsrecnlTSg9FEpe94dKcQ&e=
[**]
https://urldefense.proofpoint.com/v2/url?u=https-3A__download1.rpmfusion.org_free_el_updates_7_x86-5F64_repoview_ffmpeg.html&d=DwICAg&c=C3yme8gMkxg_ihJNXS06ZyWk4EJm8LdrrvxQb-Je7sw&r=mfF42lNlc_eXjwWhfTYoU_T7y-aauTyI1-BCcVTO9VI&m=BeHA4IOom-6-VTtfrGh08ztY42Wiy_Qrielm4l3YfdU&s=Vtsrx5Rbu2uyWS6EMBJtLx5-czVCxRPOkrUNXRDdEIw&e= 

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFAg&c=C3yme8gMkxg_ihJNXS06ZyWk4EJm8LdrrvxQb-Je7sw&r=mfF42lNlc_eXjwWhfTYoU_T7y-aauTyI1-BCcVTO9VI&m=ALpbJngXym56rhboohPLRr4u5ssQzfjBbIY3prWRREA&s=ojHuCBl-ucION0HgKAPjVRJSf4_Tc_gMhdWlgCo1xBk&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIFAg&c=C3yme8gMkxg_ihJNXS06ZyWk4EJm8LdrrvxQb-Je7sw&r=mfF42lNlc_eXjwWhfTYoU_T7y-aauTyI1-BCcVTO9VI&m=ALpbJngXym56rhboohPLRr4u5ssQzfjBbIY3prWRREA&s=Li66eYbxfucUVjfHZjU3c8lKSNcS1C4UsjfS5qEN3UA&e=
and provide commented, minimal, self-contained, reproducible code.


From dubrovv@@kkyy @end|ng |rom gm@||@com  Sat Dec 14 21:35:38 2019
From: dubrovv@@kkyy @end|ng |rom gm@||@com (=?UTF-8?B?0JDQu9C10LrRgdCw0L3QtNGAINCU0YPQsdGA0L7QstGB0LrQuNC5?=)
Date: Sat, 14 Dec 2019 23:35:38 +0300
Subject: [R] Please help translate this program in python to R.
Message-ID: <CAAdh95MYg6Fag+SMCXbHp0_arLqGZXZwPKY_Obb-SV0UB-ZdRA@mail.gmail.com>

# Iterative Merge sort (Bottom Up)

# Iterative mergesort function to
# sort arr[0...n-1]
def mergeSort(a):

    current_size = 1

    # Outer loop for traversing Each
    # sub array of current_size
    while current_size < len(a) - 1:

        left = 0
        # Inner loop for merge call
        # in a sub array
        # Each complete Iteration sorts
        # the iterating sub array
        while left < len(a)-1:

            # mid index = left index of
            # sub array + current sub
            # array size - 1
            mid = left + current_size - 1

            # (False result,True result)
            # [Condition] Can use current_size
            # if 2 * current_size < len(a)-1
            # else len(a)-1
            right = ((2 * current_size + left - 1,
                    len(a) - 1)[2 * current_size
                          + left - 1 > len(a)-1])

            # Merge call for each sub array
            merge(a, left, mid, right)
            left = left + current_size*2

        # Increasing sub array size by
        # multiple of 2
        current_size = 2 * current_size

# Merge Function
def merge(a, l, m, r):
    n1 = m - l + 1
    n2 = r - m
    L = [0] * n1
    R = [0] * n2
    for i in range(0, n1):
        L[i] = a[l + i]
    for i in range(0, n2):
        R[i] = a[m + i + 1]

    i, j, k = 0, 0, l
    while i < n1 and j < n2:
        if L[i] > R[j]:
            a[k] = R[j]
            j += 1
        else:
            a[k] = L[i]
            i += 1
        k += 1

    while i < n1:
        a[k] = L[i]
        i += 1
        k += 1

    while j < n2:
        a[k] = R[j]
        j += 1
        k += 1


# Driver code
a = [12, 11, 13, 5, 6, 7]
print("Given array is ")
print(a)

mergeSort(a)

print("Sorted array is ")
print(a)

# Contributed by Madhur Chhangani [RCOEM]

	[[alternative HTML version deleted]]


From dubrovv@@kkyy @end|ng |rom gm@||@com  Sat Dec 14 21:37:59 2019
From: dubrovv@@kkyy @end|ng |rom gm@||@com (=?UTF-8?B?0JDQu9C10LrRgdCw0L3QtNGAINCU0YPQsdGA0L7QstGB0LrQuNC5?=)
Date: Sat, 14 Dec 2019 23:37:59 +0300
Subject: [R] Please help translate this program in C++ to R
Message-ID: <CAAdh95OnxvZAGm8SOwec2GqYTYnsE4T67s3hm8jrOQU_DDMe4w@mail.gmail.com>

/* Iterative C program for merge sort */
#include<stdlib.h>
#include<stdio.h>

/* Function to merge the two haves arr[l..m] and arr[m+1..r] of array arr[]
*/
void merge(int arr[], int l, int m, int r);

// Utility function to find minimum of two integers
int min(int x, int y) { return (x<y)? x :y; }


/* Iterative mergesort function to sort arr[0...n-1] */
void mergeSort(int arr[], int n)
{
   int curr_size;  // For current size of subarrays to be merged
                   // curr_size varies from 1 to n/2
   int left_start; // For picking starting index of left subarray
                   // to be merged

   // Merge subarrays in bottom up manner.  First merge subarrays of
   // size 1 to create sorted subarrays of size 2, then merge subarrays
   // of size 2 to create sorted subarrays of size 4, and so on.
   for (curr_size=1; curr_size<=n-1; curr_size = 2*curr_size)
   {
       // Pick starting point of different subarrays of current size
       for (left_start=0; left_start<n-1; left_start += 2*curr_size)
       {
           // Find ending point of left subarray. mid+1 is starting
           // point of right
           int mid = min(left_start + curr_size - 1, n-1);

           int right_end = min(left_start + 2*curr_size - 1, n-1);

           // Merge Subarrays arr[left_start...mid] &
arr[mid+1...right_end]
           merge(arr, left_start, mid, right_end);
       }
   }
}

/* Function to merge the two haves arr[l..m] and arr[m+1..r] of array arr[]
*/
void merge(int arr[], int l, int m, int r)
{
    int i, j, k;
    int n1 = m - l + 1;
    int n2 =  r - m;

    /* create temp arrays */
    int L[n1], R[n2];

    /* Copy data to temp arrays L[] and R[] */
    for (i = 0; i < n1; i++)
        L[i] = arr[l + i];
    for (j = 0; j < n2; j++)
        R[j] = arr[m + 1+ j];

    /* Merge the temp arrays back into arr[l..r]*/
    i = 0;
    j = 0;
    k = l;
    while (i < n1 && j < n2)
    {
        if (L[i] <= R[j])
        {
            arr[k] = L[i];
            i++;
        }
        else
        {
            arr[k] = R[j];
            j++;
        }
        k++;
    }

    /* Copy the remaining elements of L[], if there are any */
    while (i < n1)
    {
        arr[k] = L[i];
        i++;
        k++;
    }

    /* Copy the remaining elements of R[], if there are any */
    while (j < n2)
    {
        arr[k] = R[j];
        j++;
        k++;
    }
}

/* Function to print an array */
void printArray(int A[], int size)
{
    int i;
    for (i=0; i < size; i++)
        printf("%d ", A[i]);
    printf("\n");
}

/* Driver program to test above functions */
int main()
{
    int arr[] = {12, 11, 13, 5, 6, 7};
    int n = sizeof(arr)/sizeof(arr[0]);

    printf("Given array is \n");
    printArray(arr, n);

    mergeSort(arr, n);

    printf("\nSorted array is \n");
    printArray(arr, n);
    return 0;
}

	[[alternative HTML version deleted]]


From bor|@@@te|pe @end|ng |rom utoronto@c@  Sun Dec 15 04:47:28 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Sun, 15 Dec 2019 03:47:28 +0000
Subject: [R] Please help translate this program in C++ to R
In-Reply-To: <CAAdh95OnxvZAGm8SOwec2GqYTYnsE4T67s3hm8jrOQU_DDMe4w@mail.gmail.com>
References: <CAAdh95OnxvZAGm8SOwec2GqYTYnsE4T67s3hm8jrOQU_DDMe4w@mail.gmail.com>
Message-ID: <69B41A88-DAE6-4C80-859A-B4713ED240F7@utoronto.ca>

See this thread why that's a bad idea ...
 https://stackoverflow.com/questions/26080716/merge-sort-in-r

... and use the code given there, or give us some context why a literal translation would be important to you.

Cheers,
Boris




> On 2019-12-15, at 05:37, ????????? ?????????? <dubrovvsskkyy at gmail.com> wrote:
> 
> /* Iterative C program for merge sort */
> #include<stdlib.h>
> #include<stdio.h>
> 
> /* Function to merge the two haves arr[l..m] and arr[m+1..r] of array arr[]
> */
> void merge(int arr[], int l, int m, int r);
> 
> // Utility function to find minimum of two integers
> int min(int x, int y) { return (x<y)? x :y; }
> 
> 
> /* Iterative mergesort function to sort arr[0...n-1] */
> void mergeSort(int arr[], int n)
> {
>   int curr_size;  // For current size of subarrays to be merged
>                   // curr_size varies from 1 to n/2
>   int left_start; // For picking starting index of left subarray
>                   // to be merged
> 
>   // Merge subarrays in bottom up manner.  First merge subarrays of
>   // size 1 to create sorted subarrays of size 2, then merge subarrays
>   // of size 2 to create sorted subarrays of size 4, and so on.
>   for (curr_size=1; curr_size<=n-1; curr_size = 2*curr_size)
>   {
>       // Pick starting point of different subarrays of current size
>       for (left_start=0; left_start<n-1; left_start += 2*curr_size)
>       {
>           // Find ending point of left subarray. mid+1 is starting
>           // point of right
>           int mid = min(left_start + curr_size - 1, n-1);
> 
>           int right_end = min(left_start + 2*curr_size - 1, n-1);
> 
>           // Merge Subarrays arr[left_start...mid] &
> arr[mid+1...right_end]
>           merge(arr, left_start, mid, right_end);
>       }
>   }
> }
> 
> /* Function to merge the two haves arr[l..m] and arr[m+1..r] of array arr[]
> */
> void merge(int arr[], int l, int m, int r)
> {
>    int i, j, k;
>    int n1 = m - l + 1;
>    int n2 =  r - m;
> 
>    /* create temp arrays */
>    int L[n1], R[n2];
> 
>    /* Copy data to temp arrays L[] and R[] */
>    for (i = 0; i < n1; i++)
>        L[i] = arr[l + i];
>    for (j = 0; j < n2; j++)
>        R[j] = arr[m + 1+ j];
> 
>    /* Merge the temp arrays back into arr[l..r]*/
>    i = 0;
>    j = 0;
>    k = l;
>    while (i < n1 && j < n2)
>    {
>        if (L[i] <= R[j])
>        {
>            arr[k] = L[i];
>            i++;
>        }
>        else
>        {
>            arr[k] = R[j];
>            j++;
>        }
>        k++;
>    }
> 
>    /* Copy the remaining elements of L[], if there are any */
>    while (i < n1)
>    {
>        arr[k] = L[i];
>        i++;
>        k++;
>    }
> 
>    /* Copy the remaining elements of R[], if there are any */
>    while (j < n2)
>    {
>        arr[k] = R[j];
>        j++;
>        k++;
>    }
> }
> 
> /* Function to print an array */
> void printArray(int A[], int size)
> {
>    int i;
>    for (i=0; i < size; i++)
>        printf("%d ", A[i]);
>    printf("\n");
> }
> 
> /* Driver program to test above functions */
> int main()
> {
>    int arr[] = {12, 11, 13, 5, 6, 7};
>    int n = sizeof(arr)/sizeof(arr[0]);
> 
>    printf("Given array is \n");
>    printArray(arr, n);
> 
>    mergeSort(arr, n);
> 
>    printf("\nSorted array is \n");
>    printArray(arr, n);
>    return 0;
> }
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bor|@@@te|pe @end|ng |rom utoronto@c@  Sun Dec 15 04:48:12 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Sun, 15 Dec 2019 03:48:12 +0000
Subject: [R] Please help translate this program in python to R.
In-Reply-To: <CAAdh95MYg6Fag+SMCXbHp0_arLqGZXZwPKY_Obb-SV0UB-ZdRA@mail.gmail.com>
References: <CAAdh95MYg6Fag+SMCXbHp0_arLqGZXZwPKY_Obb-SV0UB-ZdRA@mail.gmail.com>
Message-ID: <8AF539D7-88E8-4D5B-8661-1F02A5D27A21@utoronto.ca>

See my response to the C++ question you posted a minute later.

B.




> On 2019-12-15, at 05:35, ????????? ?????????? <dubrovvsskkyy at gmail.com> wrote:
> 
> # Iterative Merge sort (Bottom Up)
> 
> # Iterative mergesort function to
> # sort arr[0...n-1]
> def mergeSort(a):
> 
>    current_size = 1
> 
>    # Outer loop for traversing Each
>    # sub array of current_size
>    while current_size < len(a) - 1:
> 
>        left = 0
>        # Inner loop for merge call
>        # in a sub array
>        # Each complete Iteration sorts
>        # the iterating sub array
>        while left < len(a)-1:
> 
>            # mid index = left index of
>            # sub array + current sub
>            # array size - 1
>            mid = left + current_size - 1
> 
>            # (False result,True result)
>            # [Condition] Can use current_size
>            # if 2 * current_size < len(a)-1
>            # else len(a)-1
>            right = ((2 * current_size + left - 1,
>                    len(a) - 1)[2 * current_size
>                          + left - 1 > len(a)-1])
> 
>            # Merge call for each sub array
>            merge(a, left, mid, right)
>            left = left + current_size*2
> 
>        # Increasing sub array size by
>        # multiple of 2
>        current_size = 2 * current_size
> 
> # Merge Function
> def merge(a, l, m, r):
>    n1 = m - l + 1
>    n2 = r - m
>    L = [0] * n1
>    R = [0] * n2
>    for i in range(0, n1):
>        L[i] = a[l + i]
>    for i in range(0, n2):
>        R[i] = a[m + i + 1]
> 
>    i, j, k = 0, 0, l
>    while i < n1 and j < n2:
>        if L[i] > R[j]:
>            a[k] = R[j]
>            j += 1
>        else:
>            a[k] = L[i]
>            i += 1
>        k += 1
> 
>    while i < n1:
>        a[k] = L[i]
>        i += 1
>        k += 1
> 
>    while j < n2:
>        a[k] = R[j]
>        j += 1
>        k += 1
> 
> 
> # Driver code
> a = [12, 11, 13, 5, 6, 7]
> print("Given array is ")
> print(a)
> 
> mergeSort(a)
> 
> print("Sorted array is ")
> print(a)
> 
> # Contributed by Madhur Chhangani [RCOEM]
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Sun Dec 15 05:41:47 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 15 Dec 2019 06:41:47 +0200
Subject: [R] Please help translate this program in C++ to R
In-Reply-To: <69B41A88-DAE6-4C80-859A-B4713ED240F7@utoronto.ca>
References: <CAAdh95OnxvZAGm8SOwec2GqYTYnsE4T67s3hm8jrOQU_DDMe4w@mail.gmail.com>
 <69B41A88-DAE6-4C80-859A-B4713ED240F7@utoronto.ca>
Message-ID: <CAGgJW74MoBwXY_4_NLysLnsjFwO6kE7UKD3p8L_gxnOm9BQV+w@mail.gmail.com>

It is fairly easy to incorporate C++ code into R programs using the
Rcpp package.
Definitely worth the effort to learn how to do this.

On Sun, Dec 15, 2019 at 5:48 AM Boris Steipe <boris.steipe at utoronto.ca> wrote:
>
> See this thread why that's a bad idea ...
>  https://stackoverflow.com/questions/26080716/merge-sort-in-r
>
> ... and use the code given there, or give us some context why a literal translation would be important to you.
>
> Cheers,
> Boris
>
>
>
>
> > On 2019-12-15, at 05:37, ????????? ?????????? <dubrovvsskkyy at gmail.com> wrote:
> >
> > /* Iterative C program for merge sort */
> > #include<stdlib.h>
> > #include<stdio.h>
> >
> > /* Function to merge the two haves arr[l..m] and arr[m+1..r] of array arr[]
> > */
> > void merge(int arr[], int l, int m, int r);
> >
> > // Utility function to find minimum of two integers
> > int min(int x, int y) { return (x<y)? x :y; }
> >
> >
> > /* Iterative mergesort function to sort arr[0...n-1] */
> > void mergeSort(int arr[], int n)
> > {
> >   int curr_size;  // For current size of subarrays to be merged
> >                   // curr_size varies from 1 to n/2
> >   int left_start; // For picking starting index of left subarray
> >                   // to be merged
> >
> >   // Merge subarrays in bottom up manner.  First merge subarrays of
> >   // size 1 to create sorted subarrays of size 2, then merge subarrays
> >   // of size 2 to create sorted subarrays of size 4, and so on.
> >   for (curr_size=1; curr_size<=n-1; curr_size = 2*curr_size)
> >   {
> >       // Pick starting point of different subarrays of current size
> >       for (left_start=0; left_start<n-1; left_start += 2*curr_size)
> >       {
> >           // Find ending point of left subarray. mid+1 is starting
> >           // point of right
> >           int mid = min(left_start + curr_size - 1, n-1);
> >
> >           int right_end = min(left_start + 2*curr_size - 1, n-1);
> >
> >           // Merge Subarrays arr[left_start...mid] &
> > arr[mid+1...right_end]
> >           merge(arr, left_start, mid, right_end);
> >       }
> >   }
> > }
> >
> > /* Function to merge the two haves arr[l..m] and arr[m+1..r] of array arr[]
> > */
> > void merge(int arr[], int l, int m, int r)
> > {
> >    int i, j, k;
> >    int n1 = m - l + 1;
> >    int n2 =  r - m;
> >
> >    /* create temp arrays */
> >    int L[n1], R[n2];
> >
> >    /* Copy data to temp arrays L[] and R[] */
> >    for (i = 0; i < n1; i++)
> >        L[i] = arr[l + i];
> >    for (j = 0; j < n2; j++)
> >        R[j] = arr[m + 1+ j];
> >
> >    /* Merge the temp arrays back into arr[l..r]*/
> >    i = 0;
> >    j = 0;
> >    k = l;
> >    while (i < n1 && j < n2)
> >    {
> >        if (L[i] <= R[j])
> >        {
> >            arr[k] = L[i];
> >            i++;
> >        }
> >        else
> >        {
> >            arr[k] = R[j];
> >            j++;
> >        }
> >        k++;
> >    }
> >
> >    /* Copy the remaining elements of L[], if there are any */
> >    while (i < n1)
> >    {
> >        arr[k] = L[i];
> >        i++;
> >        k++;
> >    }
> >
> >    /* Copy the remaining elements of R[], if there are any */
> >    while (j < n2)
> >    {
> >        arr[k] = R[j];
> >        j++;
> >        k++;
> >    }
> > }
> >
> > /* Function to print an array */
> > void printArray(int A[], int size)
> > {
> >    int i;
> >    for (i=0; i < size; i++)
> >        printf("%d ", A[i]);
> >    printf("\n");
> > }
> >
> > /* Driver program to test above functions */
> > int main()
> > {
> >    int arr[] = {12, 11, 13, 5, 6, 7};
> >    int n = sizeof(arr)/sizeof(arr[0]);
> >
> >    printf("Given array is \n");
> >    printArray(arr, n);
> >
> >    mergeSort(arr, n);
> >
> >    printf("\nSorted array is \n");
> >    printArray(arr, n);
> >    return 0;
> > }
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Sun Dec 15 05:43:52 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 15 Dec 2019 06:43:52 +0200
Subject: [R] Please help translate this program in python to R.
In-Reply-To: <8AF539D7-88E8-4D5B-8661-1F02A5D27A21@utoronto.ca>
References: <CAAdh95MYg6Fag+SMCXbHp0_arLqGZXZwPKY_Obb-SV0UB-ZdRA@mail.gmail.com>
 <8AF539D7-88E8-4D5B-8661-1F02A5D27A21@utoronto.ca>
Message-ID: <CAGgJW772ge1NxVjMtiGcedE3qT64rGX8EsXP_fUnNFej11Lwmg@mail.gmail.com>

And similar to my response to the C++ question you posted, it is
possible to incorporate Python code into R programs using the
reticulate package.

On Sun, Dec 15, 2019 at 5:58 AM Boris Steipe <boris.steipe at utoronto.ca> wrote:
>
> See my response to the C++ question you posted a minute later.
>
> B.
>
>
>
>
> > On 2019-12-15, at 05:35, ????????? ?????????? <dubrovvsskkyy at gmail.com> wrote:
> >
> > # Iterative Merge sort (Bottom Up)
> >
> > # Iterative mergesort function to
> > # sort arr[0...n-1]
> > def mergeSort(a):
> >
> >    current_size = 1
> >
> >    # Outer loop for traversing Each
> >    # sub array of current_size
> >    while current_size < len(a) - 1:
> >
> >        left = 0
> >        # Inner loop for merge call
> >        # in a sub array
> >        # Each complete Iteration sorts
> >        # the iterating sub array
> >        while left < len(a)-1:
> >
> >            # mid index = left index of
> >            # sub array + current sub
> >            # array size - 1
> >            mid = left + current_size - 1
> >
> >            # (False result,True result)
> >            # [Condition] Can use current_size
> >            # if 2 * current_size < len(a)-1
> >            # else len(a)-1
> >            right = ((2 * current_size + left - 1,
> >                    len(a) - 1)[2 * current_size
> >                          + left - 1 > len(a)-1])
> >
> >            # Merge call for each sub array
> >            merge(a, left, mid, right)
> >            left = left + current_size*2
> >
> >        # Increasing sub array size by
> >        # multiple of 2
> >        current_size = 2 * current_size
> >
> > # Merge Function
> > def merge(a, l, m, r):
> >    n1 = m - l + 1
> >    n2 = r - m
> >    L = [0] * n1
> >    R = [0] * n2
> >    for i in range(0, n1):
> >        L[i] = a[l + i]
> >    for i in range(0, n2):
> >        R[i] = a[m + i + 1]
> >
> >    i, j, k = 0, 0, l
> >    while i < n1 and j < n2:
> >        if L[i] > R[j]:
> >            a[k] = R[j]
> >            j += 1
> >        else:
> >            a[k] = L[i]
> >            i += 1
> >        k += 1
> >
> >    while i < n1:
> >        a[k] = L[i]
> >        i += 1
> >        k += 1
> >
> >    while j < n2:
> >        a[k] = R[j]
> >        j += 1
> >        k += 1
> >
> >
> > # Driver code
> > a = [12, 11, 13, 5, 6, 7]
> > print("Given array is ")
> > print(a)
> >
> > mergeSort(a)
> >
> > print("Sorted array is ")
> > print(a)
> >
> > # Contributed by Madhur Chhangani [RCOEM]
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hwborcher@ @end|ng |rom gm@||@com  Sun Dec 15 15:20:41 2019
From: hwborcher@ @end|ng |rom gm@||@com (Hans W Borchers)
Date: Sun, 15 Dec 2019 15:20:41 +0100
Subject: [R] class of 'try' if error is raised
Message-ID: <CAML4n3OhqoT-HpNyNx5q6mERDB=1Cop=XQw6N79vUpcmFM-6Sw@mail.gmail.com>

I have been informed by CRAN administrators that the development
version of R issues warnings for my package(s). Some are easy to mend
(such as Internet links not working anymore), but this one I don't
know how to avoid:

    Error in if (class(e) == "try-error") { : the condition has length > 1

I understand that `class` can return more than one value. But what
would be the appropriate way to catch an error in a construct like
this:

    e <- try(b <- solve(a), silent=TRUE)
    if (class(e) == "try-error") {
        # ... do something
    }

Should I instead compare the class with "matrix" or "array" (or
both)?. That is, in each case check with a correct result class
instead of an error?

Thanks, HW


From e@ @end|ng |rom enr|co@chum@nn@net  Sun Dec 15 15:30:22 2019
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Sun, 15 Dec 2019 15:30:22 +0100
Subject: [R] class of 'try' if error is raised
In-Reply-To: <CAML4n3OhqoT-HpNyNx5q6mERDB=1Cop=XQw6N79vUpcmFM-6Sw@mail.gmail.com>
 (Hans W. Borchers's message of "Sun, 15 Dec 2019 15:20:41 +0100")
References: <CAML4n3OhqoT-HpNyNx5q6mERDB=1Cop=XQw6N79vUpcmFM-6Sw@mail.gmail.com>
Message-ID: <87r215wtj5.fsf@enricoschumann.net>

>>>>> "HW" == Hans W Borchers <hwborchers at gmail.com> writes:

  HW> I have been informed by CRAN administrators that the development
  HW> version of R issues warnings for my package(s). Some are easy to mend
  HW> (such as Internet links not working anymore), but this one I don't
  HW> know how to avoid:

  HW>     Error in if (class(e) == "try-error") { : the condition has length > 1

  HW> I understand that `class` can return more than one value. But what
  HW> would be the appropriate way to catch an error in a construct like
  HW> this:

  HW>     e <- try(b <- solve(a), silent=TRUE)
  HW>     if (class(e) == "try-error") {
  HW>         # ... do something
  HW>     }

  HW> Should I instead compare the class with "matrix" or "array" (or
  HW> both)?. That is, in each case check with a correct result class
  HW> instead of an error?

  HW> Thanks, HW


You should probably use

   if (inherits(e, "try-error")) {
       # ... do something
   }

kind regards
    ENrico

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From bgunter@4567 @end|ng |rom gm@||@com  Sun Dec 15 16:03:30 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 15 Dec 2019 07:03:30 -0800
Subject: [R] class of 'try' if error is raised
In-Reply-To: <CAML4n3OhqoT-HpNyNx5q6mERDB=1Cop=XQw6N79vUpcmFM-6Sw@mail.gmail.com>
References: <CAML4n3OhqoT-HpNyNx5q6mERDB=1Cop=XQw6N79vUpcmFM-6Sw@mail.gmail.com>
Message-ID: <CAGxFJbTd=3urnhFSoZpNqgygFSF1VeEHyTuP18gHQG+nm=NATw@mail.gmail.com>

See ?try which links you to ?tryCatch for the preferred approach.

Alternatively:  if(inherits(e, "try-error")) ....  ## should work and
satisfy CRAN

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Dec 15, 2019 at 6:21 AM Hans W Borchers <hwborchers at gmail.com>
wrote:

> I have been informed by CRAN administrators that the development
> version of R issues warnings for my package(s). Some are easy to mend
> (such as Internet links not working anymore), but this one I don't
> know how to avoid:
>
>     Error in if (class(e) == "try-error") { : the condition has length > 1
>
> I understand that `class` can return more than one value. But what
> would be the appropriate way to catch an error in a construct like
> this:
>
>     e <- try(b <- solve(a), silent=TRUE)
>     if (class(e) == "try-error") {
>         # ... do something
>     }
>
> Should I instead compare the class with "matrix" or "array" (or
> both)?. That is, in each case check with a correct result class
> instead of an error?
>
> Thanks, HW
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Dec 16 05:06:12 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 16 Dec 2019 17:06:12 +1300
Subject: [R] Please help translate this program in python to R.
In-Reply-To: <CAAdh95MYg6Fag+SMCXbHp0_arLqGZXZwPKY_Obb-SV0UB-ZdRA@mail.gmail.com>
References: <CAAdh95MYg6Fag+SMCXbHp0_arLqGZXZwPKY_Obb-SV0UB-ZdRA@mail.gmail.com>
Message-ID: <CABcYAdKcx0spVL3H8GQLhKhVWqNZ4oKj_+YwaiqSN0jhjbETOQ@mail.gmail.com>

The obvious question is "why?"
If you just want to sort stuff, ?sort and ?order tell you about the
sorting methods available in R.
If you want to translate this specific algorithm into R for some reason,
(a) if you don't know enough about array processing in R to do this yourself,
     how are you going to know enough to *use* it?
(b) There is a fundamental difference between arrays in Python and R which
     means that the algorithm as presented cannot possibly work in R.

Here's the difference.
>>> def f(x): x[1] = 5
...
>>> a = [1,2,3]
>>> f(a)
>>> a
[1, 5, 3]

Arrays in Python are collections of *variables* and if you pass one to
a function,
the function can *change* the very same array that you passed in.

> f <- function (x) x[2] <- 5
> a <- c(1,2,3)
> f(a)
> a
[1] 1 2 3

This is a completely different result.
Arrays in R are collections of *values*.  R acts *as if*
  x[i] <- e
really meant
  x <- get("[<-")(x, i, e)
computing a whole new array and assigning it to x.
There is in fact an actual function that does this update,
and get("[<-") returns it.
I said "as if", because there are things you can do to make the actual
implementation much more efficient, but the *observable behaviour*
is as if the entire array were replaced.
Note that this has nothing to do with how the two languages pass
arguments to functions,
it's about what an array *is* and how you work with them.

The bottom line is that if you *could* translate this algorithm from
Python to R,
you *shouldn't*.

















321

On Sun, 15 Dec 2019 at 14:56, ????????? ??????????
<dubrovvsskkyy at gmail.com> wrote:
>
> # Iterative Merge sort (Bottom Up)
>
> # Iterative mergesort function to
> # sort arr[0...n-1]
> def mergeSort(a):
>
>     current_size = 1
>
>     # Outer loop for traversing Each
>     # sub array of current_size
>     while current_size < len(a) - 1:
>
>         left = 0
>         # Inner loop for merge call
>         # in a sub array
>         # Each complete Iteration sorts
>         # the iterating sub array
>         while left < len(a)-1:
>
>             # mid index = left index of
>             # sub array + current sub
>             # array size - 1
>             mid = left + current_size - 1
>
>             # (False result,True result)
>             # [Condition] Can use current_size
>             # if 2 * current_size < len(a)-1
>             # else len(a)-1
>             right = ((2 * current_size + left - 1,
>                     len(a) - 1)[2 * current_size
>                           + left - 1 > len(a)-1])
>
>             # Merge call for each sub array
>             merge(a, left, mid, right)
>             left = left + current_size*2
>
>         # Increasing sub array size by
>         # multiple of 2
>         current_size = 2 * current_size
>
> # Merge Function
> def merge(a, l, m, r):
>     n1 = m - l + 1
>     n2 = r - m
>     L = [0] * n1
>     R = [0] * n2
>     for i in range(0, n1):
>         L[i] = a[l + i]
>     for i in range(0, n2):
>         R[i] = a[m + i + 1]
>
>     i, j, k = 0, 0, l
>     while i < n1 and j < n2:
>         if L[i] > R[j]:
>             a[k] = R[j]
>             j += 1
>         else:
>             a[k] = L[i]
>             i += 1
>         k += 1
>
>     while i < n1:
>         a[k] = L[i]
>         i += 1
>         k += 1
>
>     while j < n2:
>         a[k] = R[j]
>         j += 1
>         k += 1
>
>
> # Driver code
> a = [12, 11, 13, 5, 6, 7]
> print("Given array is ")
> print(a)
>
> mergeSort(a)
>
> print("Sorted array is ")
> print(a)
>
> # Contributed by Madhur Chhangani [RCOEM]
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Mon Dec 16 05:13:53 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 16 Dec 2019 17:13:53 +1300
Subject: [R] Please help translate this program in C++ to R
In-Reply-To: <CAAdh95OnxvZAGm8SOwec2GqYTYnsE4T67s3hm8jrOQU_DDMe4w@mail.gmail.com>
References: <CAAdh95OnxvZAGm8SOwec2GqYTYnsE4T67s3hm8jrOQU_DDMe4w@mail.gmail.com>
Message-ID: <CABcYAdLAzErszdAJ-_AkpT+atA-ivZ-N6uz7QsZLi_Y_X7gS1Q@mail.gmail.com>

As a C implementation of merge sort, that is the very reverse of impressive.
I would not translate *that* code into anything.
There is a fundamental difference between between arrays in C and arrays in R,
and it is the same as the difference between Python and R.

You are MUCH better to start from high level pseudocode and express that in R
than to start from code tangled up with the presuppositions and peculiarities of
another language with quite different presuppositions and peculiarities.


On Sun, 15 Dec 2019 at 14:57, ????????? ??????????
<dubrovvsskkyy at gmail.com> wrote:
>
> /* Iterative C program for merge sort */
> #include<stdlib.h>
> #include<stdio.h>
>
> /* Function to merge the two haves arr[l..m] and arr[m+1..r] of array arr[]
> */
> void merge(int arr[], int l, int m, int r);
>
> // Utility function to find minimum of two integers
> int min(int x, int y) { return (x<y)? x :y; }
>
>
> /* Iterative mergesort function to sort arr[0...n-1] */
> void mergeSort(int arr[], int n)
> {
>    int curr_size;  // For current size of subarrays to be merged
>                    // curr_size varies from 1 to n/2
>    int left_start; // For picking starting index of left subarray
>                    // to be merged
>
>    // Merge subarrays in bottom up manner.  First merge subarrays of
>    // size 1 to create sorted subarrays of size 2, then merge subarrays
>    // of size 2 to create sorted subarrays of size 4, and so on.
>    for (curr_size=1; curr_size<=n-1; curr_size = 2*curr_size)
>    {
>        // Pick starting point of different subarrays of current size
>        for (left_start=0; left_start<n-1; left_start += 2*curr_size)
>        {
>            // Find ending point of left subarray. mid+1 is starting
>            // point of right
>            int mid = min(left_start + curr_size - 1, n-1);
>
>            int right_end = min(left_start + 2*curr_size - 1, n-1);
>
>            // Merge Subarrays arr[left_start...mid] &
> arr[mid+1...right_end]
>            merge(arr, left_start, mid, right_end);
>        }
>    }
> }
>
> /* Function to merge the two haves arr[l..m] and arr[m+1..r] of array arr[]
> */
> void merge(int arr[], int l, int m, int r)
> {
>     int i, j, k;
>     int n1 = m - l + 1;
>     int n2 =  r - m;
>
>     /* create temp arrays */
>     int L[n1], R[n2];
>
>     /* Copy data to temp arrays L[] and R[] */
>     for (i = 0; i < n1; i++)
>         L[i] = arr[l + i];
>     for (j = 0; j < n2; j++)
>         R[j] = arr[m + 1+ j];
>
>     /* Merge the temp arrays back into arr[l..r]*/
>     i = 0;
>     j = 0;
>     k = l;
>     while (i < n1 && j < n2)
>     {
>         if (L[i] <= R[j])
>         {
>             arr[k] = L[i];
>             i++;
>         }
>         else
>         {
>             arr[k] = R[j];
>             j++;
>         }
>         k++;
>     }
>
>     /* Copy the remaining elements of L[], if there are any */
>     while (i < n1)
>     {
>         arr[k] = L[i];
>         i++;
>         k++;
>     }
>
>     /* Copy the remaining elements of R[], if there are any */
>     while (j < n2)
>     {
>         arr[k] = R[j];
>         j++;
>         k++;
>     }
> }
>
> /* Function to print an array */
> void printArray(int A[], int size)
> {
>     int i;
>     for (i=0; i < size; i++)
>         printf("%d ", A[i]);
>     printf("\n");
> }
>
> /* Driver program to test above functions */
> int main()
> {
>     int arr[] = {12, 11, 13, 5, 6, 7};
>     int n = sizeof(arr)/sizeof(arr[0]);
>
>     printf("Given array is \n");
>     printArray(arr, n);
>
>     mergeSort(arr, n);
>
>     printf("\nSorted array is \n");
>     printArray(arr, n);
>     return 0;
> }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hwborcher@ @end|ng |rom gm@||@com  Mon Dec 16 07:31:58 2019
From: hwborcher@ @end|ng |rom gm@||@com (Hans W Borchers)
Date: Mon, 16 Dec 2019 07:31:58 +0100
Subject: [R] class of 'try' if error is raised
In-Reply-To: <CAGxFJbTd=3urnhFSoZpNqgygFSF1VeEHyTuP18gHQG+nm=NATw@mail.gmail.com>
References: <CAML4n3OhqoT-HpNyNx5q6mERDB=1Cop=XQw6N79vUpcmFM-6Sw@mail.gmail.com>
 <CAGxFJbTd=3urnhFSoZpNqgygFSF1VeEHyTuP18gHQG+nm=NATw@mail.gmail.com>
Message-ID: <CAML4n3NJnqb=omqqYNgAckq+K-kcbaBC0PN+4XFPRAMPXRf3_w@mail.gmail.com>

Yes, CRAN did accept 'if(inherits(e, "try-error"))'.

I remember now, when I used the try-construct the first time, I also
saw tryCatch and found it a bit too extensive for my purposes. Will
look at it again when needed.

Thanks to you and Enrico

On Sun, 15 Dec 2019 at 16:03, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> See ?try which links you to ?tryCatch for the preferred approach.
>
> Alternatively:  if(inherits(e, "try-error")) ....  ## should work and satisfy CRAN
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Dec 15, 2019 at 6:21 AM Hans W Borchers <hwborchers at gmail.com> wrote:
>>
>> I have been informed by CRAN administrators that the development
>> version of R issues warnings for my package(s). Some are easy to mend
>> (such as Internet links not working anymore), but this one I don't
>> know how to avoid:
>>
>>     Error in if (class(e) == "try-error") { : the condition has length > 1
>>
>> I understand that `class` can return more than one value. But what
>> would be the appropriate way to catch an error in a construct like
>> this:
>>
>>     e <- try(b <- solve(a), silent=TRUE)
>>     if (class(e) == "try-error") {
>>         # ... do something
>>     }
>>
>> Should I instead compare the class with "matrix" or "array" (or
>> both)?. That is, in each case check with a correct result class
>> instead of an error?
>>
>> Thanks, HW
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From B|||@Po||ng @end|ng |rom ze||@@com  Mon Dec 16 14:24:36 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Mon, 16 Dec 2019 13:24:36 +0000
Subject: [R] Help with Identify the number (Count) of values that are less
 than 5 char and replace with 99999
Message-ID: <SN6PR02MB54377F9411702B35E1B00C33EA510@SN6PR02MB5437.namprd02.prod.outlook.com>

#RStudio Version 1.2.5019
sessionInfo()
# R version 3.6.1 (2019-07-05)
# Platform: x86_64-w64-mingw32/x64 (64-bit)
# Running under: Windows 10 x64 (build 17134)

Good morning. I have a factor that contains 1,418,303 Clinical Procedure Code (CPT).

A CPT Code is 5 char. However, among my data there are many values that are less, 2, 3, 4, as well as NA's
I get the count of NA's from the str() function = 58,481

Using the nchar function (I converted the Factor to a character column first) I get the first 1K values.
(Perhaps this is not necessary with an alternative function?)
# edt1a$ProcedureCode1 <- levels(edt1a$ProcedureCode)[edt1a$ProcedureCode]
#https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/nchar

[989] 5 5 5 5 5 5 5 5 5 5 5 5
 [ reached getOption("max.print") -- omitted 1417303 entries ]

What I would like to do is:

1. Identify the number (Count) of values that are less than 5 char (i.e. 2 char = 150, 3 char = 925, 4 char = 1002)
Probably look something like this:
|Var1   |  Freq|
|:------|-----:|
|2   |     150 |
|3   |     925 |
|4   |    1002|
2. Replace with 99999 as well as replace the NA's with 99999

head(edt1a$ProcedureCode1, n= 50) #Not apparent in top 50 but they are there
 [1] "44207" "99478" "99478" "99479" "98927" "01610" "99396" "81025" "64645" "99478" "99479" "99479" "99479" "99479" "99479" "97110" "J1885" "19081" "99479"
[20] "99478" "99479" "99479" "99479" "99213" "99213" "98927" "96372" "92507" "99479" "99478" "99478" "99478" "99479" "77065" "19083" "95874" "99244" "A7034"
[39] "A7046" "71275" "J1170" "90471" "87591" "80053" "98926" "A4649" "A7033" "43644" "85025" "73080"

str(edt1a$ProcedureCode) #Factor w/ 6244
 Factor w/ 6244 levels "0003M","00100",..: 1775 4732 4732 4733 4586 147 4708 3108 2400 4732 ...
str(edt1a$ProcedureCode1)
 chr [1:1418303] "44207" "99478" "99478" "99479" "98927" "01610" "99396" "81025" "64645" "99478" "99479" "99479" "99479" "99479" "99479" "97110" "J1885" ...

#Some examples from using sink and knitr

sink("ProcCodeV2.txt")
knitr::kable(table(edt1a$ProcedureCode1))
closeAllConnections()

|Var1   |  Freq|
|:------|-----:|
|0003M  |     1|
|0110   |     4|<--
|0111   |     5|<--
|01112  |    11|
|0112   |    14|<--
|01120  |     3|
|0113   |     2|<--
|01130  |     1|
|0114   |     1|<--
|01160  |     3|
|01170  |     4|
|0120   |     7|<--
|01200  |     8|
|01202  |    26|
|0121   |     7|<--
|01210  |    19|
|01214  |   125|
|01215  |     5|
|0122   |     2|<--
|01220  |     2|
|01230  |    11|
|0124   |     5|<--
|171    |     1|<--
|17106  |     6|

Thank you for any help.

WHP

Confidentiality Notice\ \ This email and the attachments...{{dropped:11}}


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Dec 16 14:55:53 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 16 Dec 2019 16:55:53 +0300
Subject: [R] 
 Help with Identify the number (Count) of values that are less
 than 5 char and replace with 99999
In-Reply-To: <SN6PR02MB54377F9411702B35E1B00C33EA510@SN6PR02MB5437.namprd02.prod.outlook.com>
References: <SN6PR02MB54377F9411702B35E1B00C33EA510@SN6PR02MB5437.namprd02.prod.outlook.com>
Message-ID: <20191216165553.26c02e73@trisector>

On Mon, 16 Dec 2019 13:24:36 +0000
Bill Poling <Bill.Poling at zelis.com> wrote:

> Using the nchar function (I converted the Factor to a character
> column first) I get the first 1K values.

<...>

> 1. Identify the number (Count) of values that are less than 5 char
> (i.e. 2 char = 150, 3 char = 925, 4 char = 1002)

Use the table() function to get frequency counts for discrete-valued
data (like nchar()).

> 2. Replace with 99999 as well as replace the NA's with 99999

An expression like `nchar(x) < 5` returns a boolean vector with TRUE
where the condition is, well, true, and FALSE otherwise. Use this vector
together with the subset operator (square brackets []) and assignment
operator (<-) to perform a subassignment of "99999" to the elements
of your dataset where the condition is true:

https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Index-vectors

See also: ?`[` and ?table

-- 
Best regards,
Ivan


From tr|ng @end|ng |rom gvdnet@dk  Mon Dec 16 15:55:29 2019
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Mon, 16 Dec 2019 15:55:29 +0100
Subject: [R] variable in annotation, ggplot2
Message-ID: <447a801d5b420$de34e7e0$9a9eb7a0$@gvdnet.dk>

Hi friends - I have a simple problem of inserting values in label of a
ggplot2. I have a vector V with two values and want to show them in the
plot.

Here is what I tried -  at most get the first entry "28".

R version 3.6.1 (2019-07-05)

Windows 10

 

BW
Troels

 

library(ggplot2)

x <- 1:5

y <- x^2

V <- c(28,14)

df <- data.frame(x=x,y=y)

ggplot(df,aes(x=x,y=y))+geom_line()+

    annotate("text",x=3,y=20,label=bquote(V ==.(as.vector(V))))

 

 

 

ggplot(df,aes(x=x,y=y))+geom_line()+

    annotate("text",x=3,y=20,label=expression(paste("V is ",V)))

 

 

ggplot(df,aes(x=x,y=y))+geom_line()+

    annotate("text",x=3,y=20,label=bquote(V ==.(V)))


This email has been scanned by BullGuard antivirus protection.
For more info visit www.bullguard.com
<http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt
p&url=/> 

	[[alternative HTML version deleted]]


From dubrovv@@kkyy @end|ng |rom gm@||@com  Sun Dec 15 16:18:09 2019
From: dubrovv@@kkyy @end|ng |rom gm@||@com (=?UTF-8?B?0JDQu9C10LrRgdCw0L3QtNGAINCU0YPQsdGA0L7QstGB0LrQuNC5?=)
Date: Sun, 15 Dec 2019 18:18:09 +0300
Subject: [R] Please correct my iterative merge sort code. The lack of
 recursion in the code is the main condition.
Message-ID: <CAAdh95OQsQQ7EQVn59gFDDvUvGL1qgA3C=67NbE9iphsdBkC5A@mail.gmail.com>

mrg <- function(A,B){
  R <- c()
  while(length(A)>0  length(B)>0){
    if(A[1]<B[1]){
      R <- c(R,A[1])
      A <- A[-1]
    } else{
      R <- c(R,B[1])
      B <- B[-1]
    }
  }
  return(c(R,A,B))
}
msort <- function(A){
  if(length(A)<2){
    return(A)
  } else{
    R <- c()
    W <- c()
    x <- 8
      for(i in 1:length(A)){
        if(i%%2==0){
      R <- c(R,mrg(A[(i-1)],A[i]))
        }
      }
     }
  if((length(A)%%2)==1){
    R <- c(R,A[length(A)])
  }
  for(i in 1:length(R)){
    if(i%%4==0){
      j <- i
      W <- c(W,mrg(R[(j-3):(j-2)],R[(j-1):j]))
    }
  }
  if((length(R)%%4)==3){
    W <- c(W,mrg(R[(j+1):(j+2)],R[(j+3)]))
  }
  if((length(R)%%4)<3 && (length(R)%%4)!=0){
    W <- c(W,R[(j+1):length(R)])
  }
  R <- W
  W <- c()
  while(x<length(R)){
    for(i in 1:length(R)){
      if(i%%x==0){
        j <- i
        W <- c(W,mrg(R[(j-(x-1)):(j-(x%/%2))],R[(j-(x%/%2)+1):j]))
      }
    }
    if((length(R)%%x)>(x%/%2)){
      W <- c(W,mrg(R[(j+1):(j+(x%/%2))],R[(j+(x%/%2)+1):length(R)]))
    }
    if((length(R)%%x)<=(x%/%2) && (length(R)%%x)!=0){
      W <- c(W,R[(j+1):length(R)])
    }
    x <- x*2
    R <- W
    W <- c()
  }
    R <- mrg(R[1:j],R[(j+1):length(R)])
  return(R)
}

	[[alternative HTML version deleted]]


From henr|k@bengt@@on @end|ng |rom gm@||@com  Mon Dec 16 17:23:46 2019
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Mon, 16 Dec 2019 08:23:46 -0800
Subject: [R] Please correct my iterative merge sort code. The lack of
 recursion in the code is the main condition.
In-Reply-To: <CAAdh95OQsQQ7EQVn59gFDDvUvGL1qgA3C=67NbE9iphsdBkC5A@mail.gmail.com>
References: <CAAdh95OQsQQ7EQVn59gFDDvUvGL1qgA3C=67NbE9iphsdBkC5A@mail.gmail.com>
Message-ID: <CAFDcVCSeJnxOyiwKy3uZWPtegW8sTB3dB44wu8Wu5xQ=VHXO9w@mail.gmail.com>

Folks on this list, this is my personal opinion, but please refrain from
answering this person's requests. It's pretty clear by now that they are
misusing your good intentions of trying to help people interested in R to
get their homework-like "questions" answered. There are no indications that
this person has even attempted to solve the "problems" themselves. This
smells bad intent to me.

/Henrik

On Mon, Dec 16, 2019, 07:40 ????????? ?????????? <dubrovvsskkyy at gmail.com>
wrote:

> mrg <- function(A,B){
>   R <- c()
>   while(length(A)>0  length(B)>0){
>     if(A[1]<B[1]){
>       R <- c(R,A[1])
>       A <- A[-1]
>     } else{
>       R <- c(R,B[1])
>       B <- B[-1]
>     }
>   }
>   return(c(R,A,B))
> }
> msort <- function(A){
>   if(length(A)<2){
>     return(A)
>   } else{
>     R <- c()
>     W <- c()
>     x <- 8
>       for(i in 1:length(A)){
>         if(i%%2==0){
>       R <- c(R,mrg(A[(i-1)],A[i]))
>         }
>       }
>      }
>   if((length(A)%%2)==1){
>     R <- c(R,A[length(A)])
>   }
>   for(i in 1:length(R)){
>     if(i%%4==0){
>       j <- i
>       W <- c(W,mrg(R[(j-3):(j-2)],R[(j-1):j]))
>     }
>   }
>   if((length(R)%%4)==3){
>     W <- c(W,mrg(R[(j+1):(j+2)],R[(j+3)]))
>   }
>   if((length(R)%%4)<3 && (length(R)%%4)!=0){
>     W <- c(W,R[(j+1):length(R)])
>   }
>   R <- W
>   W <- c()
>   while(x<length(R)){
>     for(i in 1:length(R)){
>       if(i%%x==0){
>         j <- i
>         W <- c(W,mrg(R[(j-(x-1)):(j-(x%/%2))],R[(j-(x%/%2)+1):j]))
>       }
>     }
>     if((length(R)%%x)>(x%/%2)){
>       W <- c(W,mrg(R[(j+1):(j+(x%/%2))],R[(j+(x%/%2)+1):length(R)]))
>     }
>     if((length(R)%%x)<=(x%/%2) && (length(R)%%x)!=0){
>       W <- c(W,R[(j+1):length(R)])
>     }
>     x <- x*2
>     R <- W
>     W <- c()
>   }
>     R <- mrg(R[1:j],R[(j+1):length(R)])
>   return(R)
> }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Dec 16 18:04:42 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Dec 2019 17:04:42 +0000
Subject: [R] 
 Help with Identify the number (Count) of values that are less
 than 5 char and replace with 99999
In-Reply-To: <SN6PR02MB54377F9411702B35E1B00C33EA510@SN6PR02MB5437.namprd02.prod.outlook.com>
References: <SN6PR02MB54377F9411702B35E1B00C33EA510@SN6PR02MB5437.namprd02.prod.outlook.com>
Message-ID: <de9267bb-2ce8-39c3-6bce-1d1a2c75fabc@sapo.pt>

Hello,

To count the number of variables with less than 5 characters, use nchar 
and table or aggregate.
Since nchar needs a character vector and you have a factor, first 
convert with as.character.


edt1a$ProcedureCode <- as.character(edt1a$ProcedureCode)


1.
Now any of the next 3 instructions will table the vector by number of 
characters.

table(nchar(edt1a$ProcedureCode))
aggregate(ProcedureCode ~ nchar(ProcedureCode), edt1a, length)
tapply(edt1a$ProcedureCode, nchar(edt1a$ProcedureCode), length)


2.
If you want to change the values with less than 5 chars or all NA's to 
"99999", a vectorized logical operation is a good way of doing it.

n <- nchar(edt1a$ProcedureCode) < 5
na <- is.na(edt1a$ProcedureCode)
edt1a$ProcedureCode[n | na] <- "99999"


Now back to factor, with the new level "99999".


edt1a$ProcedureCode <- factor(edt1a$ProcedureCode)



Hope this helps,

Rui Barradas


?s 13:24 de 16/12/19, Bill Poling escreveu:
> #RStudio Version 1.2.5019
> sessionInfo()
> # R version 3.6.1 (2019-07-05)
> # Platform: x86_64-w64-mingw32/x64 (64-bit)
> # Running under: Windows 10 x64 (build 17134)
> 
> Good morning. I have a factor that contains 1,418,303 Clinical Procedure Code (CPT).
> 
> A CPT Code is 5 char. However, among my data there are many values that are less, 2, 3, 4, as well as NA's
> I get the count of NA's from the str() function = 58,481
> 
> Using the nchar function (I converted the Factor to a character column first) I get the first 1K values.
> (Perhaps this is not necessary with an alternative function?)
> # edt1a$ProcedureCode1 <- levels(edt1a$ProcedureCode)[edt1a$ProcedureCode]
> #https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/nchar
> 
> [989] 5 5 5 5 5 5 5 5 5 5 5 5
>   [ reached getOption("max.print") -- omitted 1417303 entries ]
> 
> What I would like to do is:
> 
> 1. Identify the number (Count) of values that are less than 5 char (i.e. 2 char = 150, 3 char = 925, 4 char = 1002)
> Probably look something like this:
> |Var1   |  Freq|
> |:------|-----:|
> |2   |     150 |
> |3   |     925 |
> |4   |    1002|
> 2. Replace with 99999 as well as replace the NA's with 99999
> 
> head(edt1a$ProcedureCode1, n= 50) #Not apparent in top 50 but they are there
>   [1] "44207" "99478" "99478" "99479" "98927" "01610" "99396" "81025" "64645" "99478" "99479" "99479" "99479" "99479" "99479" "97110" "J1885" "19081" "99479"
> [20] "99478" "99479" "99479" "99479" "99213" "99213" "98927" "96372" "92507" "99479" "99478" "99478" "99478" "99479" "77065" "19083" "95874" "99244" "A7034"
> [39] "A7046" "71275" "J1170" "90471" "87591" "80053" "98926" "A4649" "A7033" "43644" "85025" "73080"
> 
> str(edt1a$ProcedureCode) #Factor w/ 6244
>   Factor w/ 6244 levels "0003M","00100",..: 1775 4732 4732 4733 4586 147 4708 3108 2400 4732 ...
> str(edt1a$ProcedureCode1)
>   chr [1:1418303] "44207" "99478" "99478" "99479" "98927" "01610" "99396" "81025" "64645" "99478" "99479" "99479" "99479" "99479" "99479" "97110" "J1885" ...
> 
> #Some examples from using sink and knitr
> 
> sink("ProcCodeV2.txt")
> knitr::kable(table(edt1a$ProcedureCode1))
> closeAllConnections()
> 
> |Var1   |  Freq|
> |:------|-----:|
> |0003M  |     1|
> |0110   |     4|<--
> |0111   |     5|<--
> |01112  |    11|
> |0112   |    14|<--
> |01120  |     3|
> |0113   |     2|<--
> |01130  |     1|
> |0114   |     1|<--
> |01160  |     3|
> |01170  |     4|
> |0120   |     7|<--
> |01200  |     8|
> |01202  |    26|
> |0121   |     7|<--
> |01210  |    19|
> |01214  |   125|
> |01215  |     5|
> |0122   |     2|<--
> |01220  |     2|
> |01230  |    11|
> |0124   |     5|<--
> |171    |     1|<--
> |17106  |     6|
> 
> Thank you for any help.
> 
> WHP
> 
> Confidentiality Notice\ \ This email and the attachments...{{dropped:11}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Dec 16 18:27:13 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Dec 2019 17:27:13 +0000
Subject: [R] variable in annotation, ggplot2
In-Reply-To: <447a801d5b420$de34e7e0$9a9eb7a0$@gvdnet.dk>
References: <447a801d5b420$de34e7e0$9a9eb7a0$@gvdnet.dk>
Message-ID: <ea5b77ce-b394-c5fd-3bc1-92832839b788@sapo.pt>

Hello,

If you form the label with paste before the plot, it can display both 
values. Something like


lab <- paste("V = ", paste(V, collapse = ","))

ggplot(df,aes(x=x,y=y)) + geom_line() +
   annotate("text", x = 3, y = 20, label = lab)


Hope this helps,

Rui Barradas

?s 14:55 de 16/12/19, Troels Ring escreveu:
> Hi friends - I have a simple problem of inserting values in label of a
> ggplot2. I have a vector V with two values and want to show them in the
> plot.
> 
> Here is what I tried -  at most get the first entry "28".
> 
> R version 3.6.1 (2019-07-05)
> 
> Windows 10
> 
>   
> 
> BW
> Troels
> 
>   
> 
> library(ggplot2)
> 
> x <- 1:5
> 
> y <- x^2
> 
> V <- c(28,14)
> 
> df <- data.frame(x=x,y=y)
> 
> ggplot(df,aes(x=x,y=y))+geom_line()+
> 
>      annotate("text",x=3,y=20,label=bquote(V ==.(as.vector(V))))
> 
>   
> 
>   
> 
>   
> 
> ggplot(df,aes(x=x,y=y))+geom_line()+
> 
>      annotate("text",x=3,y=20,label=expression(paste("V is ",V)))
> 
>   
> 
>   
> 
> ggplot(df,aes(x=x,y=y))+geom_line()+
> 
>      annotate("text",x=3,y=20,label=bquote(V ==.(V)))
> 
> 
> This email has been scanned by BullGuard antivirus protection.
> For more info visit www.bullguard.com
> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt
> p&url=/>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Mon Dec 16 19:12:15 2019
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Mon, 16 Dec 2019 18:12:15 +0000
Subject: [R] How does one pass arguments to a function, such as coxph,
 that itself is inside a function?
Message-ID: <BN7PR03MB3730AAEB1C301BC6209EC6AEE2510@BN7PR03MB3730.namprd03.prod.outlook.com>

Question summary: How does one pass arguments to a function, such as coxph, that itself is inside a function.

I am trying to write a function that will allow me to call coxph using different outcome and time variables. The coxph works when the coxph is NOT contained in a larger function (which passes the outcome and time variable to? use), but does not work when coxph is contained in a? larger funciton.

My code:

fit0 <- coxph(Surv(FUtime,Death)~Age_in_years_at_A1_max+factor(Diabetes)+factor(CKD_stage)+
                                                       factor(Phase1_first),data=mydata)
summary(fit0)

this works:?

Call:
coxph(formula = Surv(FUtime, Death) ~ Age_in_years_at_A1_max + 
? ?                         factor(Diabetes) + factor(CKD_stage) + factor(Phase1_first), 
? ? data = mydata)

? n= 350, number of events= 56 

? ? ? ? ? ? ? ? ? ? ? ? ? ?coef exp(coef) se(coef) ? ? ?z Pr(>|z|) ? ?
Age_in_years_at_A1_max ?0.04618 ? 1.04727 ?0.01384 ?3.338 0.000845 ***
factor(Diabetes)1 ? ? ? 0.12247 ? 1.13029 ?0.28282 ?0.433 0.664991 ? ?
factor(CKD_stage)3 ? ? -0.28418 ? 0.75263 ?0.38744 -0.733 0.463261 ? ?
factor(CKD_stage)4 ? ? ?0.33938 ? 1.40407 ?0.36583 ?0.928 0.353572 ? ?
factor(CKD_stage)5 ? ? ?0.97121 ? 2.64115 ?0.40171 ?2.418 0.015618 * ?
factor(Phase1_first)1 ? 0.02204 ? 1.02229 ?0.29713 ?0.074 0.940868 

other output deleted.

But this code does not work:

doit <- function(time,outcome,data){
? fit0 <-
coxph(Surv(time,outcome)~Age_in_years_at_A1_max+factor(Diabetes)+factor(CKD_stage)+factor(Phase1_first),data=data)
? print(summary(fit0))
}
doit(FUtime,Death,mydata)

 Error in Surv(time, outcome) : object 'FUtime' not found 

I am certain I have a scoping problem, but I don't know how to solve it. 

John David Sorkin M.D., Ph.D.

Professor of Medicine

Chief, Biostatistics and Informatics

University of Maryland School of Medicine Division of?Gerontology and Geriatric Medicine

Baltimore VA Medical Center

10 North Greene Street

GRECC (BT/18/GR)

Baltimore, MD 21201-1524

(Phone) 410-605-7119

(Fax) 410-605-7913 (Please call phone number above prior to faxing) 




From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Dec 16 19:31:02 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Dec 2019 18:31:02 +0000
Subject: [R] variable in annotation, ggplot2
In-Reply-To: <ea5b77ce-b394-c5fd-3bc1-92832839b788@sapo.pt>
References: <447a801d5b420$de34e7e0$9a9eb7a0$@gvdnet.dk>
 <ea5b77ce-b394-c5fd-3bc1-92832839b788@sapo.pt>
Message-ID: <e275f065-6497-4c85-e157-ae663a6b6452@sapo.pt>

Another way:


expr <- substitute(V == x, list(x = as.list(V)))
ggplot(df, aes(x, y)) + geom_line() +
   annotate("text", x = 3, y = 20,
            label = deparse(expr), parse = TRUE)

Or this one (nothing to do with your use case, it's an example of plotmath):

v <- paste("atop(", paste0("'V ='*alpha[", V, "]", collapse = ","), ")")
ggplot(df, aes(x, y)) + geom_line() +
   annotate("text", x = 3, y = 20,
            label = v, parse = TRUE)



More idiomatic? At least it allows for the use of plotmath.


Hope this helps,

Rui Barradas

?s 17:27 de 16/12/19, Rui Barradas escreveu:
> Hello,
> 
> If you form the label with paste before the plot, it can display both 
> values. Something like
> 
> 
> lab <- paste("V = ", paste(V, collapse = ","))
> 
> ggplot(df,aes(x=x,y=y)) + geom_line() +
>  ? annotate("text", x = 3, y = 20, label = lab)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 14:55 de 16/12/19, Troels Ring escreveu:
>> Hi friends - I have a simple problem of inserting values in label of a
>> ggplot2. I have a vector V with two values and want to show them in the
>> plot.
>>
>> Here is what I tried -? at most get the first entry "28".
>>
>> R version 3.6.1 (2019-07-05)
>>
>> Windows 10
>>
>>
>> BW
>> Troels
>>
>>
>> library(ggplot2)
>>
>> x <- 1:5
>>
>> y <- x^2
>>
>> V <- c(28,14)
>>
>> df <- data.frame(x=x,y=y)
>>
>> ggplot(df,aes(x=x,y=y))+geom_line()+
>>
>> ???? annotate("text",x=3,y=20,label=bquote(V ==.(as.vector(V))))
>>
>>
>>
>>
>> ggplot(df,aes(x=x,y=y))+geom_line()+
>>
>> ???? annotate("text",x=3,y=20,label=expression(paste("V is ",V)))
>>
>>
>>
>> ggplot(df,aes(x=x,y=y))+geom_line()+
>>
>> ???? annotate("text",x=3,y=20,label=bquote(V ==.(V)))
>>
>>
>> This email has been scanned by BullGuard antivirus protection.
>> For more info visit www.bullguard.com
>> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt 
>>
>> p&url=/>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Dec 16 19:45:34 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Dec 2019 18:45:34 +0000
Subject: [R] How does one pass arguments to a function, such as coxph,
 that itself is inside a function?
In-Reply-To: <BN7PR03MB3730AAEB1C301BC6209EC6AEE2510@BN7PR03MB3730.namprd03.prod.outlook.com>
References: <BN7PR03MB3730AAEB1C301BC6209EC6AEE2510@BN7PR03MB3730.namprd03.prod.outlook.com>
Message-ID: <dbb61cef-6d63-80b6-8b3f-91840d3b8e8e@sapo.pt>

Hello,

You can assemble the formula with deparse/substitute and paste.
This is the example 2 from ?coxph. I have changed list(...) to 
data.frame(...)


doit <- function(s1, s2, data){
   s1 <- deparse(substitute(s1))
   s2 <- deparse(substitute(s2))
   fmla <- paste("Surv(", s1, ",", s2, ", event)")
   fmla <- paste(fmla, "x", sep = "~")

   coxph(as.formula(fmla), data = data)
}

doit(start, stop, test2)


It works.

Hope this helps,

Rui Barradas

?s 18:12 de 16/12/19, Sorkin, John escreveu:
> Question summary: How does one pass arguments to a function, such as coxph, that itself is inside a function.
> 
> I am trying to write a function that will allow me to call coxph using different outcome and time variables. The coxph works when the coxph is NOT contained in a larger function (which passes the outcome and time variable to? use), but does not work when coxph is contained in a? larger funciton.
> 
> My code:
> 
> fit0 <- coxph(Surv(FUtime,Death)~Age_in_years_at_A1_max+factor(Diabetes)+factor(CKD_stage)+
>                                                         factor(Phase1_first),data=mydata)
> summary(fit0)
> 
> this works:
> 
> Call:
> coxph(formula = Surv(FUtime, Death) ~ Age_in_years_at_A1_max +
>  ? ?                         factor(Diabetes) + factor(CKD_stage) + factor(Phase1_first),
>  ? ? data = mydata)
> 
>  ? n= 350, number of events= 56
> 
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ?coef exp(coef) se(coef) ? ? ?z Pr(>|z|)
> Age_in_years_at_A1_max ?0.04618 ? 1.04727 ?0.01384 ?3.338 0.000845 ***
> factor(Diabetes)1 ? ? ? 0.12247 ? 1.13029 ?0.28282 ?0.433 0.664991
> factor(CKD_stage)3 ? ? -0.28418 ? 0.75263 ?0.38744 -0.733 0.463261
> factor(CKD_stage)4 ? ? ?0.33938 ? 1.40407 ?0.36583 ?0.928 0.353572
> factor(CKD_stage)5 ? ? ?0.97121 ? 2.64115 ?0.40171 ?2.418 0.015618 *
> factor(Phase1_first)1 ? 0.02204 ? 1.02229 ?0.29713 ?0.074 0.940868
> 
> other output deleted.
> 
> But this code does not work:
> 
> doit <- function(time,outcome,data){
>  ? fit0 <-
> coxph(Surv(time,outcome)~Age_in_years_at_A1_max+factor(Diabetes)+factor(CKD_stage)+factor(Phase1_first),data=data)
>  ? print(summary(fit0))
> }
> doit(FUtime,Death,mydata)
> 
>   Error in Surv(time, outcome) : object 'FUtime' not found
> 
> I am certain I have a scoping problem, but I don't know how to solve it.
> 
> John David Sorkin M.D., Ph.D.
> 
> Professor of Medicine
> 
> Chief, Biostatistics and Informatics
> 
> University of Maryland School of Medicine Division of?Gerontology and Geriatric Medicine
> 
> Baltimore VA Medical Center
> 
> 10 North Greene Street
> 
> GRECC (BT/18/GR)
> 
> Baltimore, MD 21201-1524
> 
> (Phone) 410-605-7119
> 
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdun|@p @end|ng |rom t|bco@com  Mon Dec 16 19:58:07 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 16 Dec 2019 10:58:07 -0800
Subject: [R] How does one pass arguments to a function, such as coxph,
 that itself is inside a function?
In-Reply-To: <BN7PR03MB3730AAEB1C301BC6209EC6AEE2510@BN7PR03MB3730.namprd03.prod.outlook.com>
References: <BN7PR03MB3730AAEB1C301BC6209EC6AEE2510@BN7PR03MB3730.namprd03.prod.outlook.com>
Message-ID: <CAF8bMcZ5tP+TNvjAddpEQa_KTbuKvQgENiXGTkVMz_T4gsiopQ@mail.gmail.com>

You can use substitute() to fiddle with the formula.  The following shows
how to do it using lm() instead of coxph(), but the manipulations are the
same.  It also has an 'envir' argument in case the formula depends on
anything in the callers enviroment.  The 'substitute(data)' is make the
printouts prettier.

f <- function (response, data, envir = parent.frame())
{
    formula <- eval(substitute(response ~ X), envir = envir)
    eval(as.call(list(quote(lm), formula, data = substitute(data))),
        envir = envir)
}

> d <- data.frame(check.names=FALSE, "Y-one"=1:10, "Y-two"=sqrt(1:10),
X=log(1:10))
> lm(`Y-one` ~ X, data=d)

Call:
lm(formula = `Y-one` ~ X, data = d)

Coefficients:
(Intercept)            X
    -0.4371       3.9307

> f(`Y-one`, data=d)

Call:
lm(formula = `Y-one` ~ X, data = d)

Coefficients:
(Intercept)            X
    -0.4371       3.9307
> g <- function() {
+     Y3 <- 1/(1:10)
+     f(Y3, data=d)
+ }
> g()

Call:
lm(formula = Y3 ~ X, data = d)

Coefficients:
(Intercept)            X
     0.8338      -0.3581



E.g.,
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Dec 16, 2019 at 10:12 AM Sorkin, John <jsorkin at som.umaryland.edu>
wrote:

> Question summary: How does one pass arguments to a function, such as
> coxph, that itself is inside a function.
>
> I am trying to write a function that will allow me to call coxph using
> different outcome and time variables. The coxph works when the coxph is NOT
> contained in a larger function (which passes the outcome and time variable
> to  use), but does not work when coxph is contained in a  larger funciton.
>
> My code:
>
> fit0 <-
> coxph(Surv(FUtime,Death)~Age_in_years_at_A1_max+factor(Diabetes)+factor(CKD_stage)+
>
>  factor(Phase1_first),data=mydata)
> summary(fit0)
>
> this works:
>
> Call:
> coxph(formula = Surv(FUtime, Death) ~ Age_in_years_at_A1_max +
>                             factor(Diabetes) + factor(CKD_stage) +
> factor(Phase1_first),
>     data = mydata)
>
>   n= 350, number of events= 56
>
>                            coef exp(coef) se(coef)      z Pr(>|z|)
> Age_in_years_at_A1_max  0.04618   1.04727  0.01384  3.338 0.000845 ***
> factor(Diabetes)1       0.12247   1.13029  0.28282  0.433 0.664991
> factor(CKD_stage)3     -0.28418   0.75263  0.38744 -0.733 0.463261
> factor(CKD_stage)4      0.33938   1.40407  0.36583  0.928 0.353572
> factor(CKD_stage)5      0.97121   2.64115  0.40171  2.418 0.015618 *
> factor(Phase1_first)1   0.02204   1.02229  0.29713  0.074 0.940868
>
> other output deleted.
>
> But this code does not work:
>
> doit <- function(time,outcome,data){
>   fit0 <-
>
> coxph(Surv(time,outcome)~Age_in_years_at_A1_max+factor(Diabetes)+factor(CKD_stage)+factor(Phase1_first),data=data)
>   print(summary(fit0))
> }
> doit(FUtime,Death,mydata)
>
>  Error in Surv(time, outcome) : object 'FUtime' not found
>
> I am certain I have a scoping problem, but I don't know how to solve it.
>
> John David Sorkin M.D., Ph.D.
>
> Professor of Medicine
>
> Chief, Biostatistics and Informatics
>
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
>
> Baltimore VA Medical Center
>
> 10 North Greene Street
>
> GRECC (BT/18/GR)
>
> Baltimore, MD 21201-1524
>
> (Phone) 410-605-7119
>
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Mon Dec 16 20:13:18 2019
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Mon, 16 Dec 2019 13:13:18 -0600
Subject: [R] Pattern Analysis Libraries
References: <000401d5b444$e0d88640$a28992c0$.ref@sbcglobal.net>
Message-ID: <000401d5b444$e0d88640$a28992c0$@sbcglobal.net>

R-Help

I have a need to find aggregated patterns within a data.frame of some 80
million records and wanted to know if there are any packages which could be
used to find patterns by row. For example

Col 1	Col 2 	Col3
A	1	aa
A	2	bb
A	1	aa

In this example pattern A - 1 - aa occurs twice, and A - 2 - bb occurs once.
Presently I'm simply concatenating the columns and performing a group by,
and count. Which works but wonder if there were any packages that would
perform such (and maybe other) analytics.

Sincerely

Jeff Reichman
(314) 457-1966


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Dec 16 23:19:39 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 16 Dec 2019 14:19:39 -0800
Subject: [R] Please correct my iterative merge sort code. The lack of
 recursion in the code is the main condition.
In-Reply-To: <CAFDcVCSeJnxOyiwKy3uZWPtegW8sTB3dB44wu8Wu5xQ=VHXO9w@mail.gmail.com>
References: <CAAdh95OQsQQ7EQVn59gFDDvUvGL1qgA3C=67NbE9iphsdBkC5A@mail.gmail.com>
 <CAFDcVCSeJnxOyiwKy3uZWPtegW8sTB3dB44wu8Wu5xQ=VHXO9w@mail.gmail.com>
Message-ID: <E8A15B12-D373-49F4-8C18-9B6A1C40B5A6@dcn.davis.ca.us>

The Posting Guide is pretty clear about "no homework" (it is also clear that this is a plain text mailing list). I think the recent replies to the OP have been clear on how this should be approached. I don't know what the OP "intends", but isolated (not replies to the original message) emails that have only code and no question in them are certainly not appropriate in this list.

"dubrovvsskkyy", please adhere to the Posting Guide in future posts. If you are_not_ asking for homework help then please explain why you are ignoring the advice given in previous posts.

On December 16, 2019 8:23:46 AM PST, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>Folks on this list, this is my personal opinion, but please refrain
>from
>answering this person's requests. It's pretty clear by now that they
>are
>misusing your good intentions of trying to help people interested in R
>to
>get their homework-like "questions" answered. There are no indications
>that
>this person has even attempted to solve the "problems" themselves. This
>smells bad intent to me.
>
>/Henrik
>
>On Mon, Dec 16, 2019, 07:40 ????????? ??????????
><dubrovvsskkyy at gmail.com>
>wrote:
>
>> mrg <- function(A,B){
>>   R <- c()
>>   while(length(A)>0  length(B)>0){
>>     if(A[1]<B[1]){
>>       R <- c(R,A[1])
>>       A <- A[-1]
>>     } else{
>>       R <- c(R,B[1])
>>       B <- B[-1]
>>     }
>>   }
>>   return(c(R,A,B))
>> }
>> msort <- function(A){
>>   if(length(A)<2){
>>     return(A)
>>   } else{
>>     R <- c()
>>     W <- c()
>>     x <- 8
>>       for(i in 1:length(A)){
>>         if(i%%2==0){
>>       R <- c(R,mrg(A[(i-1)],A[i]))
>>         }
>>       }
>>      }
>>   if((length(A)%%2)==1){
>>     R <- c(R,A[length(A)])
>>   }
>>   for(i in 1:length(R)){
>>     if(i%%4==0){
>>       j <- i
>>       W <- c(W,mrg(R[(j-3):(j-2)],R[(j-1):j]))
>>     }
>>   }
>>   if((length(R)%%4)==3){
>>     W <- c(W,mrg(R[(j+1):(j+2)],R[(j+3)]))
>>   }
>>   if((length(R)%%4)<3 && (length(R)%%4)!=0){
>>     W <- c(W,R[(j+1):length(R)])
>>   }
>>   R <- W
>>   W <- c()
>>   while(x<length(R)){
>>     for(i in 1:length(R)){
>>       if(i%%x==0){
>>         j <- i
>>         W <- c(W,mrg(R[(j-(x-1)):(j-(x%/%2))],R[(j-(x%/%2)+1):j]))
>>       }
>>     }
>>     if((length(R)%%x)>(x%/%2)){
>>       W <- c(W,mrg(R[(j+1):(j+(x%/%2))],R[(j+(x%/%2)+1):length(R)]))
>>     }
>>     if((length(R)%%x)<=(x%/%2) && (length(R)%%x)!=0){
>>       W <- c(W,R[(j+1):length(R)])
>>     }
>>     x <- x*2
>>     R <- W
>>     W <- c()
>>   }
>>     R <- mrg(R[1:j],R[(j+1):length(R)])
>>   return(R)
>> }
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Dec 17 02:17:53 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 16 Dec 2019 17:17:53 -0800
Subject: [R] Pattern Analysis Libraries
In-Reply-To: <000401d5b444$e0d88640$a28992c0$@sbcglobal.net>
References: <000401d5b444$e0d88640$a28992c0$.ref@sbcglobal.net>
 <000401d5b444$e0d88640$a28992c0$@sbcglobal.net>
Message-ID: <CAGxFJbQ6qkTNibM1JO2EnKEQTJE0r1+VE+ubW9JBSC9x=7c2mw@mail.gmail.com>

Your specification seems too vague to me. What sort of "patterns" are of
interest?

See also ?table on your "concatenated" columns, e.g. something like:

table(do.call(paste0, yourdata.frame))

or even

do.call(table,yourdata.frame)

for a contingency table.

There are books written on the "analytics" (both statistical and graphical)
of multidimensional contingency tables and categorical data that you may
wish to consult some to get some more specific ideas.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 16, 2019 at 11:13 AM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> R-Help
>
> I have a need to find aggregated patterns within a data.frame of some 80
> million records and wanted to know if there are any packages which could be
> used to find patterns by row. For example
>
> Col 1   Col 2   Col3
> A       1       aa
> A       2       bb
> A       1       aa
>
> In this example pattern A - 1 - aa occurs twice, and A - 2 - bb occurs
> once.
> Presently I'm simply concatenating the columns and performing a group by,
> and count. Which works but wonder if there were any packages that would
> perform such (and maybe other) analytics.
>
> Sincerely
>
> Jeff Reichman
> (314) 457-1966
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tr|ng @end|ng |rom gvdnet@dk  Tue Dec 17 08:51:20 2019
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Tue, 17 Dec 2019 08:51:20 +0100
Subject: [R] variable in annotation, ggplot2
In-Reply-To: gv97iU9LXbiKFgv98i8VV2
References: <447a801d5b420$de34e7e0$9a9eb7a0$@gvdnet.dk>
 <ea5b77ce-b394-c5fd-3bc1-92832839b788@sapo.pt> gv97iU9LXbiKFgv98i8VV2
Message-ID: <1670901d5b4ae$c6b445f0$541cd1d0$@gvdnet.dk>

Thanks a lot for the interesting possibilities - R is wonderful!
BW
Troels

-----Oprindelig meddelelse-----
Fra: Rui Barradas <ruipbarradas at sapo.pt> 
Sendt: 16. december 2019 19:31
Til: Troels Ring <tring at gvdnet.dk>; r-help mailing list <r-help at r-project.org>
Emne: Re: [R] variable in annotation, ggplot2

Another way:


expr <- substitute(V == x, list(x = as.list(V))) ggplot(df, aes(x, y)) + geom_line() +
   annotate("text", x = 3, y = 20,
            label = deparse(expr), parse = TRUE)

Or this one (nothing to do with your use case, it's an example of plotmath):

v <- paste("atop(", paste0("'V ='*alpha[", V, "]", collapse = ","), ")") ggplot(df, aes(x, y)) + geom_line() +
   annotate("text", x = 3, y = 20,
            label = v, parse = TRUE)



More idiomatic? At least it allows for the use of plotmath.


Hope this helps,

Rui Barradas

?s 17:27 de 16/12/19, Rui Barradas escreveu:
> Hello,
> 
> If you form the label with paste before the plot, it can display both 
> values. Something like
> 
> 
> lab <- paste("V = ", paste(V, collapse = ","))
> 
> ggplot(df,aes(x=x,y=y)) + geom_line() +
>    annotate("text", x = 3, y = 20, label = lab)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 14:55 de 16/12/19, Troels Ring escreveu:
>> Hi friends - I have a simple problem of inserting values in label of 
>> a ggplot2. I have a vector V with two values and want to show them in 
>> the plot.
>>
>> Here is what I tried -  at most get the first entry "28".
>>
>> R version 3.6.1 (2019-07-05)
>>
>> Windows 10
>>
>>
>> BW
>> Troels
>>
>>
>> library(ggplot2)
>>
>> x <- 1:5
>>
>> y <- x^2
>>
>> V <- c(28,14)
>>
>> df <- data.frame(x=x,y=y)
>>
>> ggplot(df,aes(x=x,y=y))+geom_line()+
>>
>>      annotate("text",x=3,y=20,label=bquote(V ==.(as.vector(V))))
>>
>>
>>
>>
>> ggplot(df,aes(x=x,y=y))+geom_line()+
>>
>>      annotate("text",x=3,y=20,label=expression(paste("V is ",V)))
>>
>>
>>
>> ggplot(df,aes(x=x,y=y))+geom_line()+
>>
>>      annotate("text",x=3,y=20,label=bquote(V ==.(V)))
>>
>>
>> This email has been scanned by BullGuard antivirus protection.
>> For more info visit www.bullguard.com 
>> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffili
>> ate=smt
>>
>> p&url=/>
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


This email has been scanned by BullGuard antivirus protection.
For more info visit www.bullguard.com


From jo@e@b@rrer@ @end|ng |rom |@g|ob@|@org  Sun Dec 15 20:02:59 2019
From: jo@e@b@rrer@ @end|ng |rom |@g|ob@|@org (Jose Barrera)
Date: Sun, 15 Dec 2019 20:02:59 +0100
Subject: [R] [R-pkgs] christmas package
Message-ID: <CACr7k5J5brk29wofrWYyKqqqNphbCLL5QLKScOrkAmx0Lj+aUg@mail.gmail.com>

Generation of a number of Christmas cards, most of them being animated. The
name of each card includes the year in which it was created.

Some examples are:

- The christmas card that was writen in 2009 shows a ?caganer? (
https://en.wikipedia.org/wiki/Caganer):

> library(christmas)
> xmas2009caganer()

- The 2019 design is about CRM (Christmas regression model)  ;-)

> xmas2019regression()

Have a nice 2020!


Jose Barrera
Statistician, Associate Lecturer

*IS**Global*
Barcelona Institute for Global Health - Campus MAR
Barcelona Biomedical Research Park (PRBB) (Room Hypatia)

Doctor Aiguader, 88
08003 Barcelona, Spain
Tel. +34 93 2147383
jose.barrera at isglobal.org
<https://www.linkedin.com/in/josebarrera>
Personal website: sites.google.com/view/josebarrera
www.isglobal.org

This message is intended exclusively for its addressee and may contain
information that is CONFIDENTIAL and protected by professional privilege.
If you are not the intended recipient you are hereby notified that any
dissemination, copy or disclosure of this communication is strictly
prohibited by law. If this message has been received in error, please
immediately notify us via e-mail and delete it.

DATA PROTECTION. We inform you that your personal data, including your
e-mail address and data included in your email correspondence, are included
in the ISGlobal Foundation filing system. Your personal data will be used
for the purpose of contacting you and sending information on the activities
of the above foundations. You can exercise your rights to  access to
personal data, rectification, erasure, restriction of processing, data
portability and object by contacting the following address: *lopd at isglobal.org
<lopd at isglobal.org>*. ISGlobal Privacy Policy at *www.isglobal.org
<http://www.isglobal.org/>*.


-----------------------------------------------------------------------------------------------------------------------------

CONFIDENCIALIDAD. Este mensaje y sus anexos se dirigen exclusivamente a su
destinatario y puede contener informaci?n confidencial, por lo que la
utilizaci?n, divulgaci?n y/o copia sin autorizaci?n est? prohibida por la
legislaci?n vigente. Si ha recibido este mensaje por error, le rogamos lo
comunique inmediatamente por esta misma v?a y proceda a su destrucci?n.

PROTECCI?N DE DATOS. Sus datos de car?cter personal utilizados en este
env?o, incluida su direcci?n de e-mail, forman parte de ficheros de
titularidad de la Fundaci?n ISGlobal  para cualquier finalidades de
contacto, relaci?n institucional y/o env?o de informaci?n sobre sus
actividades. Los datos que usted nos pueda facilitar contestando este
correo quedar?n incorporados en los correspondientes ficheros, autorizando
el uso de su direcci?n de e-mail para las finalidades citadas. Puede
ejercer los derechos de acceso, rectificaci?n, supresi?n, limitaci?n del
tratamiento, portabilidad y oposici?n dirigi?ndose a *lopd at isglobal.org
<lopd at isglobal.org>* . Pol?tica de privacidad en *www.isglobal.org
<http://www.isglobal.org/>*.

-- 


This message is intended exclusively for its addressee and may contain

information that is CONFIDENTIAL and protected by professional privilege. 
If
you are not the intended recipient you are hereby notified that any

dissemination, copy or disclosure of this communication is strictly 
prohibited
by law. If this message has been received in error, please 
immediately notify
us via e-mail and delete it.



DATA PROTECTION. We 
inform you that your personal data, including your
e-mail address and data 
included in your email correspondence, are included in
the ISGlobal 
Foundation files. Your personal data will be used for the purpose
of 
contacting you and sending information on the activities of the above

foundations. You can exercise your rights of access, rectification,

cancellation and opposition by contacting the following address: 
lopd at isglobal.org <mailto:lopd at isglobal.org>. ISGlobal
Privacy Policy at 
www.isglobal.org <http://www.isglobal.org/>.




-----------------------------------------------------------------------------------------------------------------------------


CONFIDENCIALIDAD. Este mensaje y sus anexos se dirigen exclusivamente a
su 
destinatario y puede contener informaci?n confidencial, por lo que la
utilizaci?n,
divulgaci?n y/o copia sin autorizaci?n est? prohibida por la
legislaci?n
vigente. Si ha recibido este mensaje por error, le rogamos lo 
comunique
inmediatamente por esta misma v?a y proceda a su destrucci?n.










PROTECCI?N DE DATOS. Sus datos de car?cter personal utilizados en este

env?o, incluida su direcci?n de e-mail, forman parte de ficheros de 
titularidad
de la Fundaci?n ISGlobal? para cualquier
finalidades de 
contacto, relaci?n institucional y/o env?o de informaci?n sobre
sus 
actividades. Los datos que usted nos pueda facilitar contestando este

correo quedar?n incorporados en los correspondientes ficheros, autorizando 
el
uso de su direcci?n de e-mail para las finalidades citadas. Puede 
ejercer los
derechos de acceso, rectificaci?n, cancelaci?n y oposici?n 
dirigi?ndose a lopd at isglobal.org <mailto:lopd at isglobal.org>* *. Pol?tica de 
privacidad
en www.isglobal.org <http://www.isglobal.org/>.

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ||54250 @end|ng |rom m@n@com  Tue Dec 17 20:38:02 2019
From: ||54250 @end|ng |rom m@n@com (Ioanna Ioannou)
Date: Tue, 17 Dec 2019 19:38:02 +0000
Subject: [R] How to create a new data.frame based on calculation of subsets
 of an existing data.frame
Message-ID: <DBBPR05MB6570E16C50D51322095D4A73F3500@DBBPR05MB6570.eurprd05.prod.outlook.com>

Hello everyone,


I have the following problem: I have a data.frame with multiple fields.

If I had to do my calculations for a given combination of IM.type and Taxonomy is the following:

D <- read.csv('Test_v2.csv')

names(D)

VC <- 0.01*( subset(D, IM.type == 'PGA' & Damage.state == 'DS1' & Taxonomy == 'ER+ETR_H1')[10:13] -

              subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy == 'ER+ETR_H1')[10:13])  +

  0.02*(     subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy == 'ER+ETR_H1')[10:13] -

              subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy == 'ER+ETR_H1')[10:13])  +

  0.43*( subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy == 'ER+ETR_H1')[10:13] -

           subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy == 'ER+ETR_H1')[10:13])  +

  1.0*( subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy == 'ER+ETR_H1')[10:13])

So the question is how can I do that in an automated way for all possible combinations and store the results in new data.frame  which would look like this:

Ref.No. Region  IM.type Taxonomy        IM_1   IM_2   IM_3   IM_4   VC_1   VC_2   VC_3   VC_4
1622   South America   PGA     ER+ETR_H1       1.00E-06       0.08   0.16   0.24     3.49e-294               3.449819e-05  0.002748889     0.01122911

Thanks in advance,

Best, ,

ioanna


From ||54250 @end|ng |rom m@n@com  Tue Dec 17 20:43:04 2019
From: ||54250 @end|ng |rom m@n@com (Ioanna Ioannou)
Date: Tue, 17 Dec 2019 19:43:04 +0000
Subject: [R] FW: How to create a new data.frame based on calculation of
 subsets of an existing data.frame
In-Reply-To: <DBBPR05MB6570E16C50D51322095D4A73F3500@DBBPR05MB6570.eurprd05.prod.outlook.com>
References: <DBBPR05MB6570E16C50D51322095D4A73F3500@DBBPR05MB6570.eurprd05.prod.outlook.com>
Message-ID: <DBBPR05MB65704F2FE85F9BD5AF2ABF8AF3500@DBBPR05MB6570.eurprd05.prod.outlook.com>


Hello everyone,


I have the following problem: I have a data.frame with multiple fields.

If I had to do my calculations for a given combination of IM.type and Taxonomy is the following:

D <- read.csv('Test_v2.csv')

names(D)

VC <- 0.01*( subset(D, IM.type == 'PGA' & Damage.state == 'DS1' & Taxonomy == 'ER+ETR_H1')[10:13] -

              subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy == 'ER+ETR_H1')[10:13])  +

  0.02*(     subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy == 'ER+ETR_H1')[10:13] -

              subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy == 'ER+ETR_H1')[10:13])  +

  0.43*( subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy == 'ER+ETR_H1')[10:13] -

           subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy == 'ER+ETR_H1')[10:13])  +

  1.0*( subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy == 'ER+ETR_H1')[10:13])

So the question is how can I do that in an automated way for all possible combinations and store the results in new data.frame  which would look like this:

Ref.No. Region  IM.type Taxonomy        IM_1   IM_2   IM_3   IM_4   VC_1   VC_2   VC_3   VC_4
1622   South America   PGA     ER+ETR_H1       1.00E-06       0.08   0.16   0.24     3.49e-294               3.449819e-05  0.002748889     0.01122911

Thanks in advance,

Best, ,

ioanna

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From ||54250 @end|ng |rom m@n@com  Tue Dec 17 21:11:31 2019
From: ||54250 @end|ng |rom m@n@com (Ioanna Ioannou)
Date: Tue, 17 Dec 2019 20:11:31 +0000
Subject: [R] 
 How to create a new data.frame based on calculation of subsets
 of an existing data.frame
In-Reply-To: <DBBPR05MB65704F2FE85F9BD5AF2ABF8AF3500@DBBPR05MB6570.eurprd05.prod.outlook.com>
References: <DBBPR05MB6570E16C50D51322095D4A73F3500@DBBPR05MB6570.eurprd05.prod.outlook.com>,
 <DBBPR05MB65704F2FE85F9BD5AF2ABF8AF3500@DBBPR05MB6570.eurprd05.prod.outlook.com>
Message-ID: <DBBPR05MB6570179807B0FADFF29ADE61F3500@DBBPR05MB6570.eurprd05.prod.outlook.com>

Just i case you cant see the data:

Test.v2 <- data.frame(Ref.No = c(1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629),
                      IM.type = c('PGA', 'PGA', 'PGA', 'PGA', 'Sa', 'Sa', 'Sa', 'Sa'),
                      Damage.state = c('DS1', 'DS2', 'DS3', 'DS4','DS1', 'DS2', 'DS3', 'DS4'),
                      Taxonomy = c('ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H2','ER+ETR_H2','ER+ETR_H2','ER+ETR_H2'),
                      IM_1 = c(0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00),
                      IM_2 = c(0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08),
                      IM_3 = c(0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16),
                      IM_1 = c(0.24, 0.24, 0.24, 0.24, 0.24, 0.24, 0.24, 0.24),
                      Prob.of.exceedance_1 = c(0,0,0,0,0,0,0,0),
                      Prob.of.exceedance_2 = c(0,0,0,0,0,0,0,0),
                      Prob.of.exceedance_3 = c(0.26,0.001,0.00019,0.000000573,0.04,0.00017,0.000215,0.000472),
                      Prob.of.exceedance_4 = c(0.72,0.03,0.008,0.000061,0.475,0.0007,0.00435,0.000405)
                      )
________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Ioanna Ioannou <ii54250 at msn.com>
Sent: 17 December 2019 19:43
To: r-help at r-project.org <r-help at r-project.org>
Subject: [R] FW: How to create a new data.frame based on calculation of subsets of an existing data.frame


Hello everyone,


I have the following problem: I have a data.frame with multiple fields.

If I had to do my calculations for a given combination of IM.type and Taxonomy is the following:

D <- read.csv('Test_v2.csv')

names(D)

VC <- 0.01*( subset(D, IM.type == 'PGA' & Damage.state == 'DS1' & Taxonomy == 'ER+ETR_H1')[10:13] -

              subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy == 'ER+ETR_H1')[10:13])  +

  0.02*(     subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy == 'ER+ETR_H1')[10:13] -

              subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy == 'ER+ETR_H1')[10:13])  +

  0.43*( subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy == 'ER+ETR_H1')[10:13] -

           subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy == 'ER+ETR_H1')[10:13])  +

  1.0*( subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy == 'ER+ETR_H1')[10:13])

So the question is how can I do that in an automated way for all possible combinations and store the results in new data.frame  which would look like this:

Ref.No. Region  IM.type Taxonomy        IM_1   IM_2   IM_3   IM_4   VC_1   VC_2   VC_3   VC_4
1622   South America   PGA     ER+ETR_H1       1.00E-06       0.08   0.16   0.24     3.49e-294               3.449819e-05  0.002748889     0.01122911

Thanks in advance,

Best, ,

ioanna

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ||54250 @end|ng |rom gm@||@com  Tue Dec 17 20:22:09 2019
From: ||54250 @end|ng |rom gm@||@com (ioanna ioannou)
Date: Tue, 17 Dec 2019 19:22:09 -0000
Subject: [R] FW: How to create a new data.frame based on calculation of
 subsets of an existing data.frame
In-Reply-To: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
References: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
Message-ID: <01b801d5b50f$472cc170$d5864450$@gmail.com>

Hello everyone, 
 
I have the following problem: I have a data.frame with multiple fields. 

If I had to do my calculations for a given combination of IM.type and
Taxonomy is the following:
D <- read.csv('Test_v2.csv')
names(D)

VC <- 0.01*( subset(D, IM.type == 'PGA' & Damage.state == 'DS1' & Taxonomy
== 'ER+ETR_H1')[10:13] -
              subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy
== 'ER+ETR_H1')[10:13])  +
  0.02*(     subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy
== 'ER+ETR_H1')[10:13] -
              subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy
== 'ER+ETR_H1')[10:13])  +
  0.43*( subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy ==
'ER+ETR_H1')[10:13] -
           subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy ==
'ER+ETR_H1')[10:13])  +
  1.0*( subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy ==
'ER+ETR_H1')[10:13])

So the question is how can I do that in an automated way for all possible
combinations and store the results in new data.frame  which would look like
this:

Ref.No.	Region	IM.type	Taxonomy	IM_1	IM_2	IM_3	IM_4	VC_1
VC_2	VC_3	VC_4	
1622	South America	PGA	ER+ETR_H1	1.00E-06	0.08	0.16
0.24	  3.49e-294        	  3.449819e-05 	0.002748889	0.01122911


Best, ,
ioanna

From |o@nn@@|o@nnou @end|ng |rom uc|@@c@uk  Tue Dec 17 18:59:55 2019
From: |o@nn@@|o@nnou @end|ng |rom uc|@@c@uk (Ioannou, Ioanna)
Date: Tue, 17 Dec 2019 17:59:55 +0000
Subject: [R] How to create a new data.frame based on calculation of subsets
 of an existing data.frame
Message-ID: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>

Hello everyone,

I have the following problem: I have a data.frame with multiple fields.

If I had to do my calculations for a given combination of IM.type and Taxonomy is the following:
D <- read.csv('Test_v2.csv')
names(D)

VC <- 0.01*( subset(D, IM.type == 'PGA' & Damage.state == 'DS1' & Taxonomy == 'ER+ETR_H1')[10:13] -
              subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy == 'ER+ETR_H1')[10:13])  +
  0.02*(     subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy == 'ER+ETR_H1')[10:13] -
              subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy == 'ER+ETR_H1')[10:13])  +
  0.43*( subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy == 'ER+ETR_H1')[10:13] -
           subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy == 'ER+ETR_H1')[10:13])  +
  1.0*( subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy == 'ER+ETR_H1')[10:13])

So the question is how can I do that in an automated way for all possible combinations and store the results in new data.frame  which would look like this:

Ref.No. Region  IM.type Taxonomy        IM_1    IM_2    IM_3    IM_4    VC_1    VC_2    VC_3    VC_4
1622    South America   PGA     ER+ETR_H1       1.00E-06        0.08    0.16    0.24      3.49e-294               3.449819e-05  0.002748889     0.01122911

Best, ,
ioanna


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Dec 17 22:00:02 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 18 Dec 2019 00:00:02 +0300
Subject: [R] 
 How to create a new data.frame based on calculation of subsets
 of an existing data.frame
In-Reply-To: <DBBPR05MB6570E16C50D51322095D4A73F3500@DBBPR05MB6570.eurprd05.prod.outlook.com>
References: <DBBPR05MB6570E16C50D51322095D4A73F3500@DBBPR05MB6570.eurprd05.prod.outlook.com>
Message-ID: <20191218000002.5bbb3911@Tarkus>

Hello Ioanna!

Please don't post the same question 4 times in a row. One is just
enough; you can see it posted successfully in the R-help archives:

https://stat.ethz.ch/pipermail/r-help/2019-December/465108.html

On Tue, 17 Dec 2019 19:38:02 +0000
Ioanna Ioannou <ii54250 at msn.com> wrote:

> VC <- 0.01*( subset(D, IM.type == 'PGA' & Damage.state == 'DS1' &
> Taxonomy == 'ER+ETR_H1')[10:13] -
> 
>               subset(D, IM.type == 'PGA' & Damage.state == 'DS2' &
> Taxonomy == 'ER+ETR_H1')[10:13])  +
> 
>   0.02*(     subset(D, IM.type == 'PGA' & Damage.state == 'DS2' &
> Taxonomy == 'ER+ETR_H1')[10:13] -
> 
>               subset(D, IM.type == 'PGA' & Damage.state == 'DS3' &
> Taxonomy == 'ER+ETR_H1')[10:13])  +
> 
>   0.43*( subset(D, IM.type == 'PGA' & Damage.state == 'DS3' &
> Taxonomy == 'ER+ETR_H1')[10:13] -
> 
>            subset(D, IM.type == 'PGA' & Damage.state == 'DS4' &
> Taxonomy == 'ER+ETR_H1')[10:13])  +
> 
>   1.0*( subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy
> == 'ER+ETR_H1')[10:13])

If this is supposed to be VC_1 ... VC_4, one way to make a data.frame
of it is: as.data.frame(as.list(setNames(VC, paste0('VC_', 1:4))))
(Though it's not the most elegant way, I'll have to admit.) Use cbind()
to add more columns to the resulting data.frame. Note that this
representation of the data might be not very effective to work with.

> So the question is how can I do that in an automated way for all
> possible combinations

What are "all possible combinations" here?

-- 
Best regards,
Ivan


From drj|m|emon @end|ng |rom gm@||@com  Tue Dec 17 23:40:13 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 18 Dec 2019 09:40:13 +1100
Subject: [R] 
 How to create a new data.frame based on calculation of subsets
 of an existing data.frame
In-Reply-To: <DB8PR01MB56752F156F6C4DBEC2AB0C02C9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
References: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fUbFmch8gORE9huB+1Ts50uNU1T14obR4e7V401eaNVfg@mail.gmail.com>
 <DB8PR01MB56752F156F6C4DBEC2AB0C02C9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fWnLBOPNxc1_AJVndjd0x3NrGD6UTKiK9JugZawHjwdbg@mail.gmail.com>

Okay, I'm away for most of the day and might not be able to look at it
until tomorrow.

Jim

On Wed, Dec 18, 2019 at 9:27 AM Ioannou, Ioanna
<ioanna.ioannou at ucl.ac.uk> wrote:
>
> Hello Jim ,
>
> I am very sorry.  Here is the corrected sample data to play with:
>
> Test.v2 <- data.frame(Ref.No = c(1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629),
>                       Region = rep(c('South America'), times = 8),
>                       IM.type = c('PGA', 'PGA', 'PGA', 'PGA', 'Sa', 'Sa', 'Sa', 'Sa'),
>                       Damage.state = c('DS1', 'DS2', 'DS3', 'DS4','DS1', 'DS2', 'DS3', 'DS4'),
>                       Taxonomy = c('ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H2','ER+ETR_H2','ER+ETR_H2','ER+ETR_H2'),
>                       IM_1 = c(0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00),
>                       IM_2 = c(0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08),
>                       IM_3 = c(0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16),
>                       IM_4 = c(0.24, 0.24, 0.24, 0.24, 0.24, 0.24, 0.24, 0.24),
>                       Prob.of.exceedance_1 = c(0,0,0,0,0,0,0,0),
>                       Prob.of.exceedance_2 = c(0,0,0,0,0,0,0,0),
>                       Prob.of.exceedance_3 = c(0.26,0.001,0.00019,0.000000573,0.04,0.00017,0.000215,0.000472),
>                       Prob.of.exceedance_4 = c(0.72,0.03,0.008,0.000061,0.475,0.0007,0.00435,0.000405)
>                       )
>
> Basically I am using the total probability theorem to calculate a best estimate. I am stuck how to do it for many cases. Many thanks for your patience.
>
> -----Original Message-----
> From: Jim Lemon [mailto:drjimlemon at gmail.com]
> Sent: Tuesday, December 17, 2019 10:22 PM
> To: Ioannou, Ioanna <ioanna.ioannou at ucl.ac.uk>
> Subject: Re: [R] How to create a new data.frame based on calculation of subsets of an existing data.frame
>
> Hi Ioanna,
> After looking at your post for a while, I think that you are combining columns IM_1 to IM_4 to generate VC_1 to VC_4. First, you seem to have omitted the "Region" column from Test_v2, which means that your indices (10:13) run out of range. It seems to me that you would find it easier to write down what arithmetic operations you want and translate these into logical expressions to extract the rows.
>
> Jim
>
> On Wed, Dec 18, 2019 at 7:47 AM Ioannou, Ioanna <ioanna.ioannou at ucl.ac.uk> wrote:
> >
> > Hello everyone,
> >
> > I have the following problem: I have a data.frame with multiple fields.
> >
> > If I had to do my calculations for a given combination of IM.type and Taxonomy is the following:
> > D <- read.csv('Test_v2.csv')
> > names(D)
> >
> > VC <- 0.01*( subset(D, IM.type == 'PGA' & Damage.state == 'DS1' & Taxonomy == 'ER+ETR_H1')[10:13] -
> >               subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy == 'ER+ETR_H1')[10:13])  +
> >   0.02*(     subset(D, IM.type == 'PGA' & Damage.state == 'DS2' & Taxonomy == 'ER+ETR_H1')[10:13] -
> >               subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy == 'ER+ETR_H1')[10:13])  +
> >   0.43*( subset(D, IM.type == 'PGA' & Damage.state == 'DS3' & Taxonomy == 'ER+ETR_H1')[10:13] -
> >            subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy == 'ER+ETR_H1')[10:13])  +
> >   1.0*( subset(D, IM.type == 'PGA' & Damage.state == 'DS4' & Taxonomy
> > == 'ER+ETR_H1')[10:13])
> >
> > So the question is how can I do that in an automated way for all possible combinations and store the results in new data.frame  which would look like this:
> >
> > Ref.No. Region  IM.type Taxonomy        IM_1    IM_2    IM_3    IM_4    VC_1    VC_2    VC_3    VC_4
> > 1622    South America   PGA     ER+ETR_H1       1.00E-06        0.08    0.16    0.24      3.49e-294               3.449819e-05  0.002748889     0.01122911
> >
> > Best, ,
> > ioanna
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
> > .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7C2808d89de
> > 79441309c4808d7833f7f81%7C1faf88fea9984c5b93c9210a11d9a5c2%7C0%7C0%7C6
> > 37122181061837860&amp;sdata=B%2FmCVpyLnCghj3KxgP7fYu3aOxy7uRjAVZ8fgdhc
> > u4w%3D&amp;reserved=0 PLEASE do read the posting guide
> > https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R
> > -project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7C2808d89de79441
> > 309c4808d7833f7f81%7C1faf88fea9984c5b93c9210a11d9a5c2%7C0%7C0%7C637122
> > 181061837860&amp;sdata=e4YB5rlwfSLO%2B01i92q4%2F8otuyjv%2FoZnuIwfDWPGi
> > EE%3D&amp;reserved=0 and provide commented, minimal, self-contained,
> > reproducible code.


From v@|kremk @end|ng |rom gm@||@com  Tue Dec 17 23:51:37 2019
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Tue, 17 Dec 2019 16:51:37 -0600
Subject: [R] date
Message-ID: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>

Hi All,

I wanted to to convert character date  mm/dd/yy  to YYYY-mm-dd
The sample data and my attempt is shown below

gs <-read.table(text="ID date
A1   09/27/03
A2   05/27/16
A3   01/25/13
A4   09/27/19",header=TRUE,stringsAsFactors=F)

Desired output
  ID     date      d1
 A1 09/27/03 2003-09-27
 A2 05/27/16 2016-05-27
 A3 01/25/13 2012-04-25
 A4 09/27/19 2019-09-27

I used this
gs$d1 = as.Date(as.character(gs$date), format = "%Y-%m-%d")

but I got NA's.

How do I get my desired result?
Thank you.


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Tue Dec 17 23:57:32 2019
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Tue, 17 Dec 2019 17:57:32 -0500
Subject: [R] date
In-Reply-To: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
Message-ID: <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>

Try putting / instead of - in your format, to match the data.

On Tue, Dec 17, 2019 at 5:52 PM Val <valkremk at gmail.com> wrote:
>
> Hi All,
>
> I wanted to to convert character date  mm/dd/yy  to YYYY-mm-dd
> The sample data and my attempt is shown below
>
> gs <-read.table(text="ID date
> A1   09/27/03
> A2   05/27/16
> A3   01/25/13
> A4   09/27/19",header=TRUE,stringsAsFactors=F)
>
> Desired output
>   ID     date      d1
>  A1 09/27/03 2003-09-27
>  A2 05/27/16 2016-05-27
>  A3 01/25/13 2012-04-25
>  A4 09/27/19 2019-09-27
>
> I used this
> gs$d1 = as.Date(as.character(gs$date), format = "%Y-%m-%d")
>
> but I got NA's.
>
> How do I get my desired result?
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Wed Dec 18 00:37:57 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 18 Dec 2019 00:37:57 +0100
Subject: [R] date
In-Reply-To: <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
 <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>
Message-ID: <E0F0810E-4808-47EE-B455-A00A7C3641E5@gmail.com>

...and switch the order, and use %y for 2-digit years.

> On 17 Dec 2019, at 23:57 , Patrick (Malone Quantitative) <malone at malonequantitative.com> wrote:
> 
> Try putting / instead of - in your format, to match the data.
> 
> On Tue, Dec 17, 2019 at 5:52 PM Val <valkremk at gmail.com> wrote:
>> 
>> Hi All,
>> 
>> I wanted to to convert character date  mm/dd/yy  to YYYY-mm-dd
>> The sample data and my attempt is shown below
>> 
>> gs <-read.table(text="ID date
>> A1   09/27/03
>> A2   05/27/16
>> A3   01/25/13
>> A4   09/27/19",header=TRUE,stringsAsFactors=F)
>> 
>> Desired output
>>  ID     date      d1
>> A1 09/27/03 2003-09-27
>> A2 05/27/16 2016-05-27
>> A3 01/25/13 2012-04-25
>> A4 09/27/19 2019-09-27
>> 
>> I used this
>> gs$d1 = as.Date(as.character(gs$date), format = "%Y-%m-%d")
>> 
>> but I got NA's.
>> 
>> How do I get my desired result?
>> Thank you.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jrkr|de@u @end|ng |rom gm@||@com  Wed Dec 18 02:28:17 2019
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Tue, 17 Dec 2019 20:28:17 -0500
Subject: [R] date
In-Reply-To: <E0F0810E-4808-47EE-B455-A00A7C3641E5@gmail.com>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
 <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>
 <E0F0810E-4808-47EE-B455-A00A7C3641E5@gmail.com>
Message-ID: <CAKZQJMBN+cEZbTcD-70dFEj4u=tpOER=Cux6BS_W9Wk1corX8A@mail.gmail.com>

library(lubridate)
gs$dat1  <-  mdy(gs$date)

On Tue, 17 Dec 2019 at 18:38, peter dalgaard <pdalgd at gmail.com> wrote:
>
> ...and switch the order, and use %y for 2-digit years.
>
> > On 17 Dec 2019, at 23:57 , Patrick (Malone Quantitative) <malone at malonequantitative.com> wrote:
> >
> > Try putting / instead of - in your format, to match the data.
> >
> > On Tue, Dec 17, 2019 at 5:52 PM Val <valkremk at gmail.com> wrote:
> >>
> >> Hi All,
> >>
> >> I wanted to to convert character date  mm/dd/yy  to YYYY-mm-dd
> >> The sample data and my attempt is shown below
> >>
> >> gs <-read.table(text="ID date
> >> A1   09/27/03
> >> A2   05/27/16
> >> A3   01/25/13
> >> A4   09/27/19",header=TRUE,stringsAsFactors=F)
> >>
> >> Desired output
> >>  ID     date      d1
> >> A1 09/27/03 2003-09-27
> >> A2 05/27/16 2016-05-27
> >> A3 01/25/13 2012-04-25
> >> A4 09/27/19 2019-09-27
> >>
> >> I used this
> >> gs$d1 = as.Date(as.character(gs$date), format = "%Y-%m-%d")
> >>
> >> but I got NA's.
> >>
> >> How do I get my desired result?
> >> Thank you.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
John Kane
Kingston ON Canada


From j@vedbtk111 @end|ng |rom gm@||@com  Wed Dec 18 10:06:56 2019
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Wed, 18 Dec 2019 10:06:56 +0100
Subject: [R] How to find absolute residuals
Message-ID: <CAJhui+tymFiH6V3+7ARuZkOnb+a1q7zt2hQnw_vbm1ib4WPi_Q@mail.gmail.com>

I need the absolute residuals (actual-predicted values) in a table or
another sequential format so that I may perform statistical analysis on it
later.
I have the following function, so how can I get the residuals ?

grid_search <- train(log10(Results) ~ ., data = tr,
                     method = "svmRadial",
                     ## Will create 48 parameter combinations
                     ##  tuneLength = 15,
                     metric = "MAE",
                     preProc = c("center", "scale", "zv"),
                     trControl = ctrl2)

getTrainPerf(grid_search)

My test data is ts.

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Dec 18 12:44:03 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 18 Dec 2019 14:44:03 +0300
Subject: [R] How to find absolute residuals
In-Reply-To: <CAJhui+tymFiH6V3+7ARuZkOnb+a1q7zt2hQnw_vbm1ib4WPi_Q@mail.gmail.com>
References: <CAJhui+tymFiH6V3+7ARuZkOnb+a1q7zt2hQnw_vbm1ib4WPi_Q@mail.gmail.com>
Message-ID: <20191218144403.1f4890b2@trisector>

On Wed, 18 Dec 2019 10:06:56 +0100
javed khan <javedbtk111 at gmail.com> wrote:

> grid_search <- train(log10(Results) ~ ., data = tr,
>                      method = "svmRadial",
>                      ## Will create 48 parameter combinations
>                      ##  tuneLength = 15,
>                      metric = "MAE",
>                      preProc = c("center", "scale", "zv"),
>                      trControl = ctrl2)

There is no "train" function in R core, so I'm going to invoke my
psychic debugging powers and determine that you are using the "caret"
package.

> I need the absolute residuals (actual-predicted values) in a table or
> another sequential format so that I may perform statistical analysis
> on it later.

Caret seems to provide a residuals() method for objects of class "train"
returned from the train() function. If all else fails, you could always
call predict() and compute the residuals yourself.

-- 
Best regards,
Ivan


From jun@y@n @end|ng |rom uconn@edu  Wed Dec 18 11:49:14 2019
From: jun@y@n @end|ng |rom uconn@edu (Yan, Jun)
Date: Wed, 18 Dec 2019 10:49:14 +0000
Subject: [R] 2020 Chambers Statistical Software Award submission deadline
 extended to December 31, 2019
Message-ID: <BL0PR05MB462769AB3AAE0E26EC76E525F0530@BL0PR05MB4627.namprd05.prod.outlook.com>

Dear R-help listers,

The deadline for the 2020 Chambers Statistical Software Award submission has been extended to December 31, 2019.

The Statistical Computing Section of the American Statistical Association announces the competition for the John M. Chambers Statistical Software Award. In 1998 the Association for Computing Machinery (ACM) presented the ACM Software System Award to John Chambers for the design and development of S. Dr. Chambers generously donated his award to the Statistical Computing Section to endow an annual prize for statistical software written by, or in collaboration with, an undergraduate or graduate student.

Please see http://asa.stat.uconn.edu/#chambers-2020 for detailed instructions.

Best regards


Jun Yan, Awards Chair

ASA Section on Statistical Computing

Professor, Department of Statistics

University of Connecticut


	[[alternative HTML version deleted]]


From cry@n @end|ng |rom b|ngh@mton@edu  Wed Dec 18 17:45:44 2019
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W Ryan)
Date: Wed, 18 Dec 2019 11:45:44 -0500
Subject: [R] how to change format of dates in a tibble
Message-ID: <CAM+rpYkAVEQ8TjsinSp6_C=eWSGU7+-9JSGR5Csq9FaFJtOKtA@mail.gmail.com>

I'm not understanding how the tidyverse handles date formats.

output of sessionInfo() at the end of my message.

dateRanges <- structure(list(apptType = structure(1:2, .Label = c("initial
visit",
"start of treatment visit"), class = "factor"), minMadeRequestDates =
structure(c(18124,
18115), class = "Date"), maxMadeRequestDates = structure(c(18187,
18199), class = "Date"), minApptDate = structure(c(18129, 18129
), class = "Date"), maxApptDate = structure(c(18199, 18214), class =
"Date")), class = c("tbl_df",
"tbl", "data.frame"), row.names = c(NA, -2L))
str(dateRanges)

## produces desired result
format(dateRanges, format = "%d %b %Y")

## does not produce desired result
library(dplyr)
format(dateRanges, format = "%d %b %Y")

## rather cumbersome, and also does not produce the desired output
mutate(dateRanges, minMRD = as.Date(minMadeRequestDates, format = "%d %b
%Y"))

How does one change the format of a date variable inside a tibble when
dplyr is loaded?

Thanks

Chris Ryan

======== session info ===========
> sessionInfo()
R version 3.6.1 (2019-07-05)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United
States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] dplyr_0.8.3

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.2       fansi_0.4.0      zeallot_0.1.0    utf8_1.1.4
crayon_1.3.4     assertthat_0.2.1 R6_2.4.0
 [8] backports_1.1.5  magrittr_1.5     pillar_1.4.2     rlang_0.4.0
 cli_1.1.0        vctrs_0.2.0      glue_1.3.1
[15] purrr_0.3.3      compiler_3.6.1   pkgconfig_2.0.3  tidyselect_0.2.5
tibble_2.1.3
====================================

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Dec 18 19:25:24 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 18 Dec 2019 12:25:24 -0600
Subject: [R] issue with numeric
Message-ID: <CAF9-5jP_awpOXT1=cc+yUU4ZtdRD8m1cTp5cq8T=mGyLHR=j+Q@mail.gmail.com>

Hello,

I was running this code, located at:
https://github.com/swvanderlaan/QTLToolKit/blob/master/SCRIPTS/runFDR_cis.R

Rscript runFDR_cis.R Retina_new_perms_full.txt 0.05 permutations_all

and I got this error:

Processing QTLtools output.
  * Input  = [ Retina_new_perms_full.txt ]
  * FDR    =  0.05
  * Output = [ permutations_all ]

Read Input data. Note: we expect a file with 19 columns i.e. it is
best to use the results from a permutation test.
  * Gene level correction detected
  * Number of molecular phenotypes = 17375
  * Number of NA lines = 15
Error in cor(D[, 18 + exon_offset], D[, 19 + exon_offset]) :
  'x' must be numeric
Calls: cat -> cor
Execution halted

> a=read.table("Retina_new_perms_full.txt", header=T)
> head(a)
               V1   V2     V3     V4 V5   V6      V7
1 ENSG00000227232 chr1  29571  29570  -  983 -828479
2 ENSG00000237613 chr1  36082  36081  - 1006  -38709
3 ENSG00000239945 chr1  91106  91105  - 1169 -782443
4 ENSG00000238009 chr1 133724 133723  - 1340   69986
5 ENSG00000241860 chr1 173863 173862  - 1441 -831895
6 ENSG00000279457 chr1 200323 200322  - 1620 -980529
                                   V8   V9     V10     V11   Effect_allele
1              rs200956863:793429:T:C chr1  858049  858049               T
2                rs13328700:74790:C:G chr1   74790   74790               G
3               rs11240780:808928:C:T chr1  873548  873548               C
4            rs201888535:63735:CCTA:C chr1   63735   63738               C
5 rs61703480:941137:AGCCCCCGCAGCAGT:A chr1 1005757 1005771 AGCCCCCGCAGCAGT
6              rs13374146:1116231:T:C chr1 1180851 1180851               C
  Baseline_allele V12     V13     V14     V15         V16       V17      V18
1               C 404 348.489 1.04262 139.753 0.000741814  0.269459 0.196180
2               C 404 346.832 1.03086 138.165 0.002822220 -0.687290 0.530547
3               T 404 347.109 1.02189 152.726 0.000626379 -0.284821 0.203080
4            CCTA 404 338.804 1.04423 154.301 0.000797573 -0.398402 0.264974
5               A 404 341.822 1.04355 171.178 0.002893770  0.340855 0.638936
6               T 404 338.232 1.05240 180.879 0.001846080 -0.458547 0.528947
       V19
1 0.198142
2 0.529105
3 0.199394
4 0.261441
5 0.633917
6 0.524186


Please advise,
Ana


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Dec 18 20:32:52 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 18 Dec 2019 19:32:52 +0000
Subject: [R] how to change format of dates in a tibble
In-Reply-To: <CAM+rpYkAVEQ8TjsinSp6_C=eWSGU7+-9JSGR5Csq9FaFJtOKtA@mail.gmail.com>
References: <CAM+rpYkAVEQ8TjsinSp6_C=eWSGU7+-9JSGR5Csq9FaFJtOKtA@mail.gmail.com>
Message-ID: <84c2da4b-5620-da29-be9b-fcab13accfea@sapo.pt>

Hello,

You are passing a tbl_df to functions that expect a vector.
Here is a first, simpler example.


library(tidyverse)

df1 <- tibble(Date = Sys.Date() + 0:9)

## both produce expected result
format(df1$Date, format = "%d %b %Y")

df1 %>%
   mutate(d = format(Date, format = "%d %b %Y"))


Now your with data.

## does NOT produces desired result, dateRanges is an
## object of classes 'tbl_df', 'tbl' and 'data.frame'
format(dateRanges, format = "%d %b %Y")


## produces desired result
dateRanges %>%
   mutate(minMRD = format(minMadeRequestDates, format = "%d %b %Y")) %>%
   select(minMRD)

## rather cumbersome, and also produces the desired output
mutate(dateRanges, minMRD = format(minMadeRequestDates, format = "%d %b 
%Y")) %>%
   select(minMRD)



Hope this helps,

Rui Barradas


?s 16:45 de 18/12/19, Christopher W Ryan escreveu:
> I'm not understanding how the tidyverse handles date formats.
> 
> output of sessionInfo() at the end of my message.
> 
> dateRanges <- structure(list(apptType = structure(1:2, .Label = c("initial
> visit",
> "start of treatment visit"), class = "factor"), minMadeRequestDates =
> structure(c(18124,
> 18115), class = "Date"), maxMadeRequestDates = structure(c(18187,
> 18199), class = "Date"), minApptDate = structure(c(18129, 18129
> ), class = "Date"), maxApptDate = structure(c(18199, 18214), class =
> "Date")), class = c("tbl_df",
> "tbl", "data.frame"), row.names = c(NA, -2L))
> str(dateRanges)
> 
> ## produces desired result
> format(dateRanges, format = "%d %b %Y")
> 
> ## does not produce desired result
> library(dplyr)
> format(dateRanges, format = "%d %b %Y")
> 
> ## rather cumbersome, and also does not produce the desired output
> mutate(dateRanges, minMRD = as.Date(minMadeRequestDates, format = "%d %b
> %Y"))
> 
> How does one change the format of a date variable inside a tibble when
> dplyr is loaded?
> 
> Thanks
> 
> Chris Ryan
> 
> ======== session info ===========
>> sessionInfo()
> R version 3.6.1 (2019-07-05)
> Platform: i386-w64-mingw32/i386 (32-bit)
> Running under: Windows 7 (build 7601) Service Pack 1
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United
> States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] dplyr_0.8.3
> 
> loaded via a namespace (and not attached):
>   [1] Rcpp_1.0.2       fansi_0.4.0      zeallot_0.1.0    utf8_1.1.4
> crayon_1.3.4     assertthat_0.2.1 R6_2.4.0
>   [8] backports_1.1.5  magrittr_1.5     pillar_1.4.2     rlang_0.4.0
>   cli_1.1.0        vctrs_0.2.0      glue_1.3.1
> [15] purrr_0.3.3      compiler_3.6.1   pkgconfig_2.0.3  tidyselect_0.2.5
> tibble_2.1.3
> ====================================
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Dec 18 20:42:46 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 18 Dec 2019 14:42:46 -0500
Subject: [R] how to change format of dates in a tibble
In-Reply-To: <CAM+rpYkAVEQ8TjsinSp6_C=eWSGU7+-9JSGR5Csq9FaFJtOKtA@mail.gmail.com>
References: <CAM+rpYkAVEQ8TjsinSp6_C=eWSGU7+-9JSGR5Csq9FaFJtOKtA@mail.gmail.com>
Message-ID: <b6532f6f-6f57-c552-4a05-3554b21e3ee9@gmail.com>

On 18/12/2019 11:45 a.m., Christopher W Ryan wrote:
> I'm not understanding how the tidyverse handles date formats.
> 
> output of sessionInfo() at the end of my message.
> 
> dateRanges <- structure(list(apptType = structure(1:2, .Label = c("initial
> visit",
> "start of treatment visit"), class = "factor"), minMadeRequestDates =
> structure(c(18124,
> 18115), class = "Date"), maxMadeRequestDates = structure(c(18187,
> 18199), class = "Date"), minApptDate = structure(c(18129, 18129
> ), class = "Date"), maxApptDate = structure(c(18199, 18214), class =
> "Date")), class = c("tbl_df",
> "tbl", "data.frame"), row.names = c(NA, -2L))
> str(dateRanges)
> 
> ## produces desired result
> format(dateRanges, format = "%d %b %Y")
> 
> ## does not produce desired result
> library(dplyr)
> format(dateRanges, format = "%d %b %Y")
> 
> ## rather cumbersome, and also does not produce the desired output
> mutate(dateRanges, minMRD = as.Date(minMadeRequestDates, format = "%d %b
> %Y"))
> 
> How does one change the format of a date variable inside a tibble when
> dplyr is loaded?
In the first example, the class of dateRanges is c("tbl_df", "tbl", 
"data.frame").   Since you don't have any tbl methods loaded, you get 
the format.data.frame method.

When you attach dplyr, it loads the tibble package, and it has a 
"format.tbl" method that gives the output you don't like.

One simple way to work around this is to call the format.data.frame 
method directly:

  format.data.frame(dateRanges, format = "%d %b %Y")

Similarly,

  format(as.data.frame(dateRanges), format = "%d %b %Y")

calls that method.

You can also convert the date columns to char using something like

   dateRanges %>% mutate_all(function(x) format(x, format = "%d %b %Y"))

and then auto-printing will show you the formatted output.  This is a 
little risky, since it applies the formatting function to all columns; 
in your example it works, but you might need to use mutate_if() instead:

   dateRanges %>% mutate_if(~ inherits(.x, "Date"), ~ format(.x, "%d %b 
%Y"))

Duncan Murdoch

> 
> Thanks
> 
> Chris Ryan
> 
> ======== session info ===========
>> sessionInfo()
> R version 3.6.1 (2019-07-05)
> Platform: i386-w64-mingw32/i386 (32-bit)
> Running under: Windows 7 (build 7601) Service Pack 1
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United
> States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] dplyr_0.8.3
> 
> loaded via a namespace (and not attached):
>   [1] Rcpp_1.0.2       fansi_0.4.0      zeallot_0.1.0    utf8_1.1.4
> crayon_1.3.4     assertthat_0.2.1 R6_2.4.0
>   [8] backports_1.1.5  magrittr_1.5     pillar_1.4.2     rlang_0.4.0
>   cli_1.1.0        vctrs_0.2.0      glue_1.3.1
> [15] purrr_0.3.3      compiler_3.6.1   pkgconfig_2.0.3  tidyselect_0.2.5
> tibble_2.1.3
> ====================================
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Dec 18 20:44:26 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 18 Dec 2019 19:44:26 +0000
Subject: [R] issue with numeric
In-Reply-To: <CAF9-5jP_awpOXT1=cc+yUU4ZtdRD8m1cTp5cq8T=mGyLHR=j+Q@mail.gmail.com>
References: <CAF9-5jP_awpOXT1=cc+yUU4ZtdRD8m1cTp5cq8T=mGyLHR=j+Q@mail.gmail.com>
Message-ID: <388218ec-9fcf-166b-e1da-988169a5ba12@sapo.pt>

Hello,

It's hard to tell without data but:


1) The data is read in in code line 19. Check if it has 19 columns and 
if columns 18 and 19 are numeric.
If they are of class factor run

D[18:19] <- lapply(D[18:19], function(x) as.numeric(as.character(x)))


2) code line nr 20 is
exon_offset = ifelse(ncol(D) == 19, 0, 2)

So if the data has 19 columns, as expected, exon_offset = 0.

3) The error comes from computing the correlation between D[, 18 + 
exon_offset] and D[, 19 + exon_offset] in code line 27:


cat("  * Correlation between Beta approx. and Empirical p-values =", 
round(cor(D[, 18+exon_offset], D[, 19+exon_offset]), 4), "\n")

This includes cor(D[, 18+exon_offset], D[, 19+exon_offset])


So check what are the values of ncol(D) and of exon_offset. Their sum 
cannot be bigger than ncol(D).


If none of the above, say something.


Hope this helps,

Rui Barradas




?s 18:25 de 18/12/19, Ana Marija escreveu:
> Hello,
> 
> I was running this code, located at:
> https://github.com/swvanderlaan/QTLToolKit/blob/master/SCRIPTS/runFDR_cis.R
> 
> Rscript runFDR_cis.R Retina_new_perms_full.txt 0.05 permutations_all
> 
> and I got this error:
> 
> Processing QTLtools output.
>    * Input  = [ Retina_new_perms_full.txt ]
>    * FDR    =  0.05
>    * Output = [ permutations_all ]
> 
> Read Input data. Note: we expect a file with 19 columns i.e. it is
> best to use the results from a permutation test.
>    * Gene level correction detected
>    * Number of molecular phenotypes = 17375
>    * Number of NA lines = 15
> Error in cor(D[, 18 + exon_offset], D[, 19 + exon_offset]) :
>    'x' must be numeric
> Calls: cat -> cor
> Execution halted
> 
>> a=read.table("Retina_new_perms_full.txt", header=T)
>> head(a)
>                 V1   V2     V3     V4 V5   V6      V7
> 1 ENSG00000227232 chr1  29571  29570  -  983 -828479
> 2 ENSG00000237613 chr1  36082  36081  - 1006  -38709
> 3 ENSG00000239945 chr1  91106  91105  - 1169 -782443
> 4 ENSG00000238009 chr1 133724 133723  - 1340   69986
> 5 ENSG00000241860 chr1 173863 173862  - 1441 -831895
> 6 ENSG00000279457 chr1 200323 200322  - 1620 -980529
>                                     V8   V9     V10     V11   Effect_allele
> 1              rs200956863:793429:T:C chr1  858049  858049               T
> 2                rs13328700:74790:C:G chr1   74790   74790               G
> 3               rs11240780:808928:C:T chr1  873548  873548               C
> 4            rs201888535:63735:CCTA:C chr1   63735   63738               C
> 5 rs61703480:941137:AGCCCCCGCAGCAGT:A chr1 1005757 1005771 AGCCCCCGCAGCAGT
> 6              rs13374146:1116231:T:C chr1 1180851 1180851               C
>    Baseline_allele V12     V13     V14     V15         V16       V17      V18
> 1               C 404 348.489 1.04262 139.753 0.000741814  0.269459 0.196180
> 2               C 404 346.832 1.03086 138.165 0.002822220 -0.687290 0.530547
> 3               T 404 347.109 1.02189 152.726 0.000626379 -0.284821 0.203080
> 4            CCTA 404 338.804 1.04423 154.301 0.000797573 -0.398402 0.264974
> 5               A 404 341.822 1.04355 171.178 0.002893770  0.340855 0.638936
> 6               T 404 338.232 1.05240 180.879 0.001846080 -0.458547 0.528947
>         V19
> 1 0.198142
> 2 0.529105
> 3 0.199394
> 4 0.261441
> 5 0.633917
> 6 0.524186
> 
> 
> Please advise,
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Dec 18 20:45:53 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 18 Dec 2019 22:45:53 +0300
Subject: [R] issue with numeric
In-Reply-To: <CAF9-5jP_awpOXT1=cc+yUU4ZtdRD8m1cTp5cq8T=mGyLHR=j+Q@mail.gmail.com>
References: <CAF9-5jP_awpOXT1=cc+yUU4ZtdRD8m1cTp5cq8T=mGyLHR=j+Q@mail.gmail.com>
Message-ID: <20191218224553.3f1e9838@Tarkus>

On Wed, 18 Dec 2019 12:25:24 -0600
Ana Marija <sokovic.anamarija at gmail.com> wrote:

> Error in cor(D[, 18 + exon_offset], D[, 19 + exon_offset]) :
>   'x' must be numeric

Try str(a) to find out the types of the columns. A stray typo could
make a representation of a number impossible to parse and make the
whole column textual. Use
which(is.na(as.numeric(as.character(a[,column_number])))) to find out
the row number where it happened (using extra as.character() here in
case the column is a factor).

-- 
Best regards,
Ivan


From m@|||P@dpo@t @end|ng |rom gm@||@com  Wed Dec 18 21:33:48 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Wed, 18 Dec 2019 23:33:48 +0300
Subject: [R] choose randomly
Message-ID: <CAH6117+U4kO4JgvvX=8r+qHmXUHhX0DMbwsAbirozp4d36KEyQ@mail.gmail.com>

Variable temperature:
mydata$temperature
has N values.
With what code to ?hoice (without return) n values from them RANDOMLY?


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Dec 18 21:44:24 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 18 Dec 2019 14:44:24 -0600
Subject: [R] issue with numeric
In-Reply-To: <20191218224553.3f1e9838@Tarkus>
References: <CAF9-5jP_awpOXT1=cc+yUU4ZtdRD8m1cTp5cq8T=mGyLHR=j+Q@mail.gmail.com>
 <20191218224553.3f1e9838@Tarkus>
Message-ID: <CAF9-5jOESNeWWWjY2pwEN1NnoC5CNyEtLYfuFbrTzY4T7EeWuA@mail.gmail.com>

Hi Ivan,

here it is:

> str(a)
'data.frame':    17389 obs. of  21 variables:
 $ V1             : Factor w/ 17389 levels "ENSG00000000419",..: 14093
14622 14705 14651 14784 17138 14773 14163 14569 15156 ...
 $ V2             : Factor w/ 22 levels "chr1","chr10",..: 1 1 1 1 1 1
1 1 1 1 ...
 $ V3             : int  29571 36082 91106 133724 173863 200323 259025
297503 348367 493242 ...
 $ V4             : int  29570 36081 91105 133723 173862 200322 259024
297502 348366 493241 ...
 $ V5             : Factor w/ 2 levels "-","+": 1 1 1 1 1 1 1 1 1 1 ...
 $ V6             : int  983 1006 1169 1340 1441 1620 1897 2032 2175 2697 ...
 $ V7             : int  -828479 -38709 -782443 69986 -831895 -980529
-647609 -946918 -631093 -886444 ...
 $ V8             : Factor w/ 17104 levels "1:10095977:G:GT",..: 7339
4761 2344 7480 12580 4781 14856 3061 9397 6938 ...
 $ V9             : Factor w/ 22 levels "chr1","chr10",..: 1 1 1 1 1 1
1 1 1 1 ...
 $ V10            : int  858049 74790 873548 63735 1005757 1180851
906633 1244420 979459 1379685 ...
 $ V11            : int  858049 74790 873548 63738 1005771 1180851
906633 1244420 979459 1379685 ...
 $ Effect_allele  : Factor w/ 358 levels "A","AAAAACAAAAC",..: 267 190
92 92 54 92 190 1 267 267 ...
 $ Baseline_allele: Factor w/ 435 levels "A","AAAAAAAAAATAAAAAT",..:
112 112 325 175 1 325 325 237 112 237 ...
 $ V12            : int  404 404 404 404 404 404 404 404 404 404 ...
 $ V13            : num  348 347 347 339 342 ...
 $ V14            : num  1.04 1.03 1.02 1.04 1.04 ...
 $ V15            : num  140 138 153 154 171 ...
 $ V16            : num  0.000742 0.002822 0.000626 0.000798 0.002894 ...
 $ V17            : num  0.269 -0.687 -0.285 -0.398 0.341 ...
 $ V18            : num  0.196 0.531 0.203 0.265 0.639 ...
 $ V19            : num  0.198 0.529 0.199 0.261 0.634 ...

and this:

> which(is.na(as.numeric(as.character(a[,18]))))
 [1] 10757 11062 11063 11064 11065 11066 11067 11068 11069 11070 11071 11072
[13] 11073 11074 11075
> which(is.na(as.numeric(as.character(a[,19]))))
 [1] 10757 11062 11063 11064 11065 11066 11067 11068 11069 11070 11071 11072
[13] 11073 11074 11075

columns 18 and 19 seems to be numeric, what is could be the issue?

On Wed, Dec 18, 2019 at 1:49 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Wed, 18 Dec 2019 12:25:24 -0600
> Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> > Error in cor(D[, 18 + exon_offset], D[, 19 + exon_offset]) :
> >   'x' must be numeric
>
> Try str(a) to find out the types of the columns. A stray typo could
> make a representation of a number impossible to parse and make the
> whole column textual. Use
> which(is.na(as.numeric(as.character(a[,column_number])))) to find out
> the row number where it happened (using extra as.character() here in
> case the column is a factor).
>
> --
> Best regards,
> Ivan


From drj|m|emon @end|ng |rom gm@||@com  Wed Dec 18 21:37:49 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 19 Dec 2019 07:37:49 +1100
Subject: [R] choose randomly
In-Reply-To: <CAH6117+U4kO4JgvvX=8r+qHmXUHhX0DMbwsAbirozp4d36KEyQ@mail.gmail.com>
References: <CAH6117+U4kO4JgvvX=8r+qHmXUHhX0DMbwsAbirozp4d36KEyQ@mail.gmail.com>
Message-ID: <CA+8X3fWXyPzgQ-yNC=djBJfQAPG2htQxvFiU3HWF9y4-AUkscg@mail.gmail.com>

Hi Medic,
mydata$Temperature[sample(1:N,N)
should do the trick. You will just get a pseudo-randomly shuffled set
of the same values.

Jim

On Thu, Dec 19, 2019 at 7:34 AM Medic <mailiPadpost at gmail.com> wrote:
>
> Variable temperature:
> mydata$temperature
> has N values.
> With what code to ?hoice (without return) n values from them RANDOMLY?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Dec 18 22:11:19 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 18 Dec 2019 15:11:19 -0600
Subject: [R] issue with numeric
In-Reply-To: <CAF9-5jOESNeWWWjY2pwEN1NnoC5CNyEtLYfuFbrTzY4T7EeWuA@mail.gmail.com>
References: <CAF9-5jP_awpOXT1=cc+yUU4ZtdRD8m1cTp5cq8T=mGyLHR=j+Q@mail.gmail.com>
 <20191218224553.3f1e9838@Tarkus>
 <CAF9-5jOESNeWWWjY2pwEN1NnoC5CNyEtLYfuFbrTzY4T7EeWuA@mail.gmail.com>
Message-ID: <CAF9-5jPP0eGCkpnOWtSjBu7aqGTVC-cTOSnCpuMhq-2uvp8PqA@mail.gmail.com>

Hello,

the error was in the code:
D = read.table(opt_input, head = FALSE, stringsAsFactors = FALSE)

I should have there header=TRUE

Sorry for bothering with this,

Ana

On Wed, Dec 18, 2019 at 2:44 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Ivan,
>
> here it is:
>
> > str(a)
> 'data.frame':    17389 obs. of  21 variables:
>  $ V1             : Factor w/ 17389 levels "ENSG00000000419",..: 14093
> 14622 14705 14651 14784 17138 14773 14163 14569 15156 ...
>  $ V2             : Factor w/ 22 levels "chr1","chr10",..: 1 1 1 1 1 1
> 1 1 1 1 ...
>  $ V3             : int  29571 36082 91106 133724 173863 200323 259025
> 297503 348367 493242 ...
>  $ V4             : int  29570 36081 91105 133723 173862 200322 259024
> 297502 348366 493241 ...
>  $ V5             : Factor w/ 2 levels "-","+": 1 1 1 1 1 1 1 1 1 1 ...
>  $ V6             : int  983 1006 1169 1340 1441 1620 1897 2032 2175 2697 ...
>  $ V7             : int  -828479 -38709 -782443 69986 -831895 -980529
> -647609 -946918 -631093 -886444 ...
>  $ V8             : Factor w/ 17104 levels "1:10095977:G:GT",..: 7339
> 4761 2344 7480 12580 4781 14856 3061 9397 6938 ...
>  $ V9             : Factor w/ 22 levels "chr1","chr10",..: 1 1 1 1 1 1
> 1 1 1 1 ...
>  $ V10            : int  858049 74790 873548 63735 1005757 1180851
> 906633 1244420 979459 1379685 ...
>  $ V11            : int  858049 74790 873548 63738 1005771 1180851
> 906633 1244420 979459 1379685 ...
>  $ Effect_allele  : Factor w/ 358 levels "A","AAAAACAAAAC",..: 267 190
> 92 92 54 92 190 1 267 267 ...
>  $ Baseline_allele: Factor w/ 435 levels "A","AAAAAAAAAATAAAAAT",..:
> 112 112 325 175 1 325 325 237 112 237 ...
>  $ V12            : int  404 404 404 404 404 404 404 404 404 404 ...
>  $ V13            : num  348 347 347 339 342 ...
>  $ V14            : num  1.04 1.03 1.02 1.04 1.04 ...
>  $ V15            : num  140 138 153 154 171 ...
>  $ V16            : num  0.000742 0.002822 0.000626 0.000798 0.002894 ...
>  $ V17            : num  0.269 -0.687 -0.285 -0.398 0.341 ...
>  $ V18            : num  0.196 0.531 0.203 0.265 0.639 ...
>  $ V19            : num  0.198 0.529 0.199 0.261 0.634 ...
>
> and this:
>
> > which(is.na(as.numeric(as.character(a[,18]))))
>  [1] 10757 11062 11063 11064 11065 11066 11067 11068 11069 11070 11071 11072
> [13] 11073 11074 11075
> > which(is.na(as.numeric(as.character(a[,19]))))
>  [1] 10757 11062 11063 11064 11065 11066 11067 11068 11069 11070 11071 11072
> [13] 11073 11074 11075
>
> columns 18 and 19 seems to be numeric, what is could be the issue?
>
> On Wed, Dec 18, 2019 at 1:49 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
> >
> > On Wed, 18 Dec 2019 12:25:24 -0600
> > Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > > Error in cor(D[, 18 + exon_offset], D[, 19 + exon_offset]) :
> > >   'x' must be numeric
> >
> > Try str(a) to find out the types of the columns. A stray typo could
> > make a representation of a number impossible to parse and make the
> > whole column textual. Use
> > which(is.na(as.numeric(as.character(a[,column_number])))) to find out
> > the row number where it happened (using extra as.character() here in
> > case the column is a factor).
> >
> > --
> > Best regards,
> > Ivan


From bgunter@4567 @end|ng |rom gm@||@com  Thu Dec 19 00:08:12 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 18 Dec 2019 15:08:12 -0800
Subject: [R] choose randomly
In-Reply-To: <CA+8X3fWXyPzgQ-yNC=djBJfQAPG2htQxvFiU3HWF9y4-AUkscg@mail.gmail.com>
References: <CAH6117+U4kO4JgvvX=8r+qHmXUHhX0DMbwsAbirozp4d36KEyQ@mail.gmail.com>
 <CA+8X3fWXyPzgQ-yNC=djBJfQAPG2htQxvFiU3HWF9y4-AUkscg@mail.gmail.com>
Message-ID: <CAGxFJbSZwrJRx_F8O09aCetf7vs00wzrPjS5YQcweSDSrdaFDA@mail.gmail.com>

If n = N, then this is unnecessarily complicated.

sample(mydata$Temperature)

is all you need (see ?sample).

If n < N, then the "trick" is not done.

sample(mydata$Temperature, n)

is what is wanted.

Bert



On Wed, Dec 18, 2019 at 12:54 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Medic,
> mydata$Temperature[sample(1:N,N)
> should do the trick. You will just get a pseudo-randomly shuffled set
> of the same values.
>
> Jim
>
> On Thu, Dec 19, 2019 at 7:34 AM Medic <mailiPadpost at gmail.com> wrote:
> >
> > Variable temperature:
> > mydata$temperature
> > has N values.
> > With what code to ?hoice (without return) n values from them RANDOMLY?
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@|||P@dpo@t @end|ng |rom gm@||@com  Thu Dec 19 00:27:22 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Thu, 19 Dec 2019 02:27:22 +0300
Subject: [R] choose randomly
Message-ID: <CAH6117+NVc7Nvwm0GhUKjab+sb7U4xhD2+C+FXnuwD-GFUuz5Q@mail.gmail.com>

Bert, I am very grateful for your clear explanation!!!
  Bert Gunter
  If n = N, then this is unnecessarily complicated.
  sample(mydata$Temperature)
  is all you need (see ?sample).
  If n < N, then the "trick" is not done.
  sample(mydata$Temperature, n)
  is what is wanted.
  Bert

Thank you, Jim, you always come to the rescue!
  Jim Lemon
  mydata$Temperature[sample(1:N,N)
  should do the trick. You will just get a pseudo-randomly shuffled set
  of the same values.
  Jim

Medic <mailiPadpost at gmail.com> wrote:
> > Variable temperature:
> > mydata$temperature
> > has N values.
> > With what code to ?hoice (without return) n values from them RANDOMLY?


From br|@n@kreeger @end|ng |rom gm@||@com  Wed Dec 18 20:22:58 2019
From: br|@n@kreeger @end|ng |rom gm@||@com (Brian Kreeger)
Date: Wed, 18 Dec 2019 13:22:58 -0600
Subject: [R] issue with numeric
In-Reply-To: <CAF9-5jP_awpOXT1=cc+yUU4ZtdRD8m1cTp5cq8T=mGyLHR=j+Q@mail.gmail.com>
References: <CAF9-5jP_awpOXT1=cc+yUU4ZtdRD8m1cTp5cq8T=mGyLHR=j+Q@mail.gmail.com>
Message-ID: <CAN7h_v3efOC73QFQ76=i0mySD9QiAx4Y-tjF6gi4=nSR3WMOcg@mail.gmail.com>

*snip*
Error in cor(D[, 18 + exon_offset], D[, 19 + exon_offset]) :
  'x' must be numeric
*snip*

You are applying the correlation function to non-numeric variables.

Brian

On Wed, Dec 18, 2019 at 12:23 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I was running this code, located at:
> https://github.com/swvanderlaan/QTLToolKit/blob/master/SCRIPTS/runFDR_cis.R
>
> Rscript runFDR_cis.R Retina_new_perms_full.txt 0.05 permutations_all
>
> and I got this error:
>
> Processing QTLtools output.
>   * Input  = [ Retina_new_perms_full.txt ]
>   * FDR    =  0.05
>   * Output = [ permutations_all ]
>
> Read Input data. Note: we expect a file with 19 columns i.e. it is
> best to use the results from a permutation test.
>   * Gene level correction detected
>   * Number of molecular phenotypes = 17375
>   * Number of NA lines = 15
> Error in cor(D[, 18 + exon_offset], D[, 19 + exon_offset]) :
>   'x' must be numeric
> Calls: cat -> cor
> Execution halted
>
> > a=read.table("Retina_new_perms_full.txt", header=T)
> > head(a)
>                V1   V2     V3     V4 V5   V6      V7
> 1 ENSG00000227232 chr1  29571  29570  -  983 -828479
> 2 ENSG00000237613 chr1  36082  36081  - 1006  -38709
> 3 ENSG00000239945 chr1  91106  91105  - 1169 -782443
> 4 ENSG00000238009 chr1 133724 133723  - 1340   69986
> 5 ENSG00000241860 chr1 173863 173862  - 1441 -831895
> 6 ENSG00000279457 chr1 200323 200322  - 1620 -980529
>                                    V8   V9     V10     V11   Effect_allele
> 1              rs200956863:793429:T:C chr1  858049  858049               T
> 2                rs13328700:74790:C:G chr1   74790   74790               G
> 3               rs11240780:808928:C:T chr1  873548  873548               C
> 4            rs201888535:63735:CCTA:C chr1   63735   63738               C
> 5 rs61703480:941137:AGCCCCCGCAGCAGT:A chr1 1005757 1005771 AGCCCCCGCAGCAGT
> 6              rs13374146:1116231:T:C chr1 1180851 1180851               C
>   Baseline_allele V12     V13     V14     V15         V16       V17
> V18
> 1               C 404 348.489 1.04262 139.753 0.000741814  0.269459
> 0.196180
> 2               C 404 346.832 1.03086 138.165 0.002822220 -0.687290
> 0.530547
> 3               T 404 347.109 1.02189 152.726 0.000626379 -0.284821
> 0.203080
> 4            CCTA 404 338.804 1.04423 154.301 0.000797573 -0.398402
> 0.264974
> 5               A 404 341.822 1.04355 171.178 0.002893770  0.340855
> 0.638936
> 6               T 404 338.232 1.05240 180.879 0.001846080 -0.458547
> 0.528947
>        V19
> 1 0.198142
> 2 0.529105
> 3 0.199394
> 4 0.261441
> 5 0.633917
> 6 0.524186
>
>
> Please advise,
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Dec 19 03:04:47 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 19 Dec 2019 13:04:47 +1100
Subject: [R] 
 How to create a new data.frame based on calculation of subsets
 of an existing data.frame
In-Reply-To: <CA+8X3fWnLBOPNxc1_AJVndjd0x3NrGD6UTKiK9JugZawHjwdbg@mail.gmail.com>
References: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fUbFmch8gORE9huB+1Ts50uNU1T14obR4e7V401eaNVfg@mail.gmail.com>
 <DB8PR01MB56752F156F6C4DBEC2AB0C02C9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fWnLBOPNxc1_AJVndjd0x3NrGD6UTKiK9JugZawHjwdbg@mail.gmail.com>
Message-ID: <CA+8X3fURQd+nvf=JER5kf=N7MfwUKNrzinvtiYHAa_w2XRN37w@mail.gmail.com>

Hi Ioanna,
I looked at the problem this morning and tried to work out what you
wanted. With a problem like this, it is often easy when you have
someone point to the data and say "I want this added to that and this
multiplied by that". I have probably made the wrong guesses, but I
hope that you can correct my guesses and I can get the calculations
correct for you. For example, I have assumed that you want the sum of
the IM_* values for each set of damage states as the values for VC_1,
VC_2 etc.

D<-data.frame(Ref.No = c(1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629),
 Region = rep(c('South America'), times = 8),
 IM.type = c('PGA', 'PGA', 'PGA', 'PGA', 'Sa', 'Sa', 'Sa', 'Sa'),
 Damage.state = c('DS1', 'DS2', 'DS3', 'DS4','DS1', 'DS2', 'DS3', 'DS4'),
 Taxonomy = c('ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H2',
 'ER+ETR_H2','ER+ETR_H2','ER+ETR_H2'),
 IM_1 = c(0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00),
 IM_2 = c(0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08),
 IM_3 = c(0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16),
 IM_4 = c(0.24, 0.24, 0.24, 0.24, 0.24, 0.24, 0.24, 0.24),
 Prob.of.exceedance_1 = c(0,0,0,0,0,0,0,0),
 Prob.of.exceedance_2 = c(0,0,0,0,0,0,0,0),
 Prob.of.exceedance_3 =
 c(0.26,0.001,0.00019,0.000000573,0.04,0.00017,0.000215,0.000472),
 Prob.of.exceedance_4 =
 c(0.72,0.03,0.008,0.000061,0.475,0.0007,0.00435,0.000405),
 stringsAsFactors=FALSE)
# assume the above has been read in
# add the four columns to the data frame filled with NAs
D$VC_1<-D$VC_2<-D$VC_3<-D$VC_4<-NA
# names of the variables used in the calculations
calc_vars<-paste("Prob.of.exceedance",1:4,sep="_")
# get the rows for the four damage states
DS1_rows<-D$Damage.state == "DS1"
DS2_rows<-D$Damage.state == "DS2"
DS3_rows<-D$Damage.state == "DS3"
DS4_rows<-D$Damage.state == "DS4"
# step through all possible values of IM.type and Taxonomy
for(IM in unique(D$IM.type)) {
 for(Tax in unique(D$Taxonomy)) {
  # get a logical vector of the rows to be used in this calculation
  calc_rows<-D$IM.type == IM & D$Taxonomy == Tax
  cat(IM,Tax,calc_rows,"\n")
  # check that there are any such rows in the data frame
  if(sum(calc_rows)) {
   # if so, fill in the four values for these rows
   D$VC_1[calc_rows]<-sum(0.01 * (D[calc_rows & DS1_rows,calc_vars] -
    D[calc_rows & DS2_rows,calc_vars]))
   D$VC_2[calc_rows]<-sum(0.02 * (D[calc_rows & DS2_rows,calc_vars] -
    D[calc_rows & DS3_rows,calc_vars]))
   D$VC_3[calc_rows]<-sum(0.43 * (D[calc_rows & DS3_rows,calc_vars] -
    D[calc_rows & DS4_rows,calc_vars]))
   D$VC_4[calc_rows]<-sum(D[calc_rows & DS4_rows,calc_vars])
  }
 }
}

Jim


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Dec 19 09:31:08 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 19 Dec 2019 09:31:08 +0100
Subject: [R] date
In-Reply-To: <CAKZQJMBN+cEZbTcD-70dFEj4u=tpOER=Cux6BS_W9Wk1corX8A@mail.gmail.com>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
 <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>
 <E0F0810E-4808-47EE-B455-A00A7C3641E5@gmail.com>
 <CAKZQJMBN+cEZbTcD-70dFEj4u=tpOER=Cux6BS_W9Wk1corX8A@mail.gmail.com>
Message-ID: <24059.13644.667102.761870@stat.math.ethz.ch>

>>>>> John Kane 
>>>>>     on Tue, 17 Dec 2019 20:28:17 -0500 writes:

    > library(lubridate)
    > gs$dat1  <-  mdy(gs$date)

there's really no reason for going beyond base R.

Using the proper format as per Patrick and Peter's advice
(below) is perfectly clear and actually
more robust (for the next data set etc)
than going via "good guessing" in extra packages.

    > On Tue, 17 Dec 2019 at 18:38, peter dalgaard <pdalgd at gmail.com> wrote:
    >> 
    >> ...and switch the order, and use %y for 2-digit years.
    >> 
    >> > On 17 Dec 2019, at 23:57 , Patrick (Malone Quantitative) <malone at malonequantitative.com> wrote:
    >> >
    >> > Try putting / instead of - in your format, to match the data.
    >> >
    >> > On Tue, Dec 17, 2019 at 5:52 PM Val <valkremk at gmail.com> wrote:
    >> >>
    >> >> Hi All,
    >> >>
    >> >> I wanted to to convert character date  mm/dd/yy  to YYYY-mm-dd
    >> >> The sample data and my attempt is shown below
    >> >>
    >> >> gs <-read.table(text="ID date
    >> >> A1   09/27/03
    >> >> A2   05/27/16
    >> >> A3   01/25/13
    >> >> A4   09/27/19",header=TRUE,stringsAsFactors=F)
    >> >>
    >> >> Desired output
    >> >>  ID     date      d1
    >> >> A1 09/27/03 2003-09-27
    >> >> A2 05/27/16 2016-05-27
    >> >> A3 01/25/13 2012-04-25
    >> >> A4 09/27/19 2019-09-27
    >> >>
    >> >> I used this
    >> >> gs$d1 = as.Date(as.character(gs$date), format = "%Y-%m-%d")
    >> >>
    >> >> but I got NA's.
    >> >>
    >> >> How do I get my desired result?
    >> >> Thank you.
    >> >>
    >> >> ______________________________________________
    >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> >> and provide commented, minimal, self-contained, reproducible code.
    >> >
    >> > ______________________________________________
    >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> > https://stat.ethz.ch/mailman/listinfo/r-help
    >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> > and provide commented, minimal, self-contained, reproducible code.
    >> 
    >> --
    >> Peter Dalgaard, Professor,
    >> Center for Statistics, Copenhagen Business School
    >> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    >> Phone: (+45)38153501
    >> Office: A 4.23
    >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.



    > -- 
    > John Kane
    > Kingston ON Canada

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Thu Dec 19 09:52:39 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 19 Dec 2019 10:52:39 +0200
Subject: [R] date
In-Reply-To: <24059.13644.667102.761870@stat.math.ethz.ch>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
 <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>
 <E0F0810E-4808-47EE-B455-A00A7C3641E5@gmail.com>
 <CAKZQJMBN+cEZbTcD-70dFEj4u=tpOER=Cux6BS_W9Wk1corX8A@mail.gmail.com>
 <24059.13644.667102.761870@stat.math.ethz.ch>
Message-ID: <CAGgJW74cKu7Pb3g+e6VLa9DeMBxqont5ZVEzQAwx6vExxVdbDg@mail.gmail.com>

Martin  writes: "there's really no reason for going beyond base R"

I disagree. Lubridate is a fantastic package. I use it all the time. It
makes working with dates really easy, as evidenced by John Kane's
suggestion. I strongly recommend learning to work with it.

The bottom line: as is often the case, there are many different ways to
accomplish a task in R.


On Thu, Dec 19, 2019 at 10:31 AM Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> John Kane
> >>>>>     on Tue, 17 Dec 2019 20:28:17 -0500 writes:
>
>     > library(lubridate)
>     > gs$dat1  <-  mdy(gs$date)
>
> there's really no reason for going beyond base R.
>
> Using the proper format as per Patrick and Peter's advice
> (below) is perfectly clear and actually
> more robust (for the next data set etc)
> than going via "good guessing" in extra packages.
>
>     > On Tue, 17 Dec 2019 at 18:38, peter dalgaard <pdalgd at gmail.com>
> wrote:
>     >>
>     >> ...and switch the order, and use %y for 2-digit years.
>     >>
>     >> > On 17 Dec 2019, at 23:57 , Patrick (Malone Quantitative) <
> malone at malonequantitative.com> wrote:
>     >> >
>     >> > Try putting / instead of - in your format, to match the data.
>     >> >
>     >> > On Tue, Dec 17, 2019 at 5:52 PM Val <valkremk at gmail.com> wrote:
>     >> >>
>     >> >> Hi All,
>     >> >>
>     >> >> I wanted to to convert character date  mm/dd/yy  to YYYY-mm-dd
>     >> >> The sample data and my attempt is shown below
>     >> >>
>     >> >> gs <-read.table(text="ID date
>     >> >> A1   09/27/03
>     >> >> A2   05/27/16
>     >> >> A3   01/25/13
>     >> >> A4   09/27/19",header=TRUE,stringsAsFactors=F)
>     >> >>
>     >> >> Desired output
>     >> >>  ID     date      d1
>     >> >> A1 09/27/03 2003-09-27
>     >> >> A2 05/27/16 2016-05-27
>     >> >> A3 01/25/13 2012-04-25
>     >> >> A4 09/27/19 2019-09-27
>     >> >>
>     >> >> I used this
>     >> >> gs$d1 = as.Date(as.character(gs$date), format = "%Y-%m-%d")
>     >> >>
>     >> >> but I got NA's.
>     >> >>
>     >> >> How do I get my desired result?
>     >> >> Thank you.
>     >> >>
>     >> >> ______________________________________________
>     >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
>     >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     >> >> and provide commented, minimal, self-contained, reproducible
> code.
>     >> >
>     >> > ______________________________________________
>     >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> > https://stat.ethz.ch/mailman/listinfo/r-help
>     >> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     >> > and provide commented, minimal, self-contained, reproducible code.
>     >>
>     >> --
>     >> Peter Dalgaard, Professor,
>     >> Center for Statistics, Copenhagen Business School
>     >> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>     >> Phone: (+45)38153501
>     >> Office: A 4.23
>     >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>     > --
>     > John Kane
>     > Kingston ON Canada
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Dec 19 11:49:02 2019
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 19 Dec 2019 11:49:02 +0100
Subject: [R] date
In-Reply-To: <CAGgJW74cKu7Pb3g+e6VLa9DeMBxqont5ZVEzQAwx6vExxVdbDg@mail.gmail.com>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
 <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>
 <E0F0810E-4808-47EE-B455-A00A7C3641E5@gmail.com>
 <CAKZQJMBN+cEZbTcD-70dFEj4u=tpOER=Cux6BS_W9Wk1corX8A@mail.gmail.com>
 <24059.13644.667102.761870@stat.math.ethz.ch>
 <CAGgJW74cKu7Pb3g+e6VLa9DeMBxqont5ZVEzQAwx6vExxVdbDg@mail.gmail.com>
Message-ID: <20191219114902.Horde.AIT_yQYZgBKLh1F1bpiq1pf@webmail.your-server.de>


Quoting Eric Berger <ericjberger at gmail.com>:

> Martin  writes: "there's really no reason for going beyond base R"
>
> I disagree. Lubridate is a fantastic package. I use it all the time. It
> makes working with dates really easy, as evidenced by John Kane's
> suggestion. I strongly recommend learning to work with it.
>
> The bottom line: as is often the case, there are many different ways to
> accomplish a task in R.

I apologise beforehand if this sparks an unnecessary discussion ;-)

But the important point is:
If you know the structure of the data you want to
parse, then it is best to tell R (or any other language)
this structure explicitly.


> On Thu, Dec 19, 2019 at 10:31 AM Martin Maechler <maechler at stat.math.ethz.ch>
> wrote:
>
>> >>>>> John Kane
>> >>>>>     on Tue, 17 Dec 2019 20:28:17 -0500 writes:
>>
>>     > library(lubridate)
>>     > gs$dat1  <-  mdy(gs$date)
>>
>> there's really no reason for going beyond base R.
>>
>> Using the proper format as per Patrick and Peter's advice
>> (below) is perfectly clear and actually
>> more robust (for the next data set etc)
>> than going via "good guessing" in extra packages.
>>
>>     > On Tue, 17 Dec 2019 at 18:38, peter dalgaard <pdalgd at gmail.com>
>> wrote:
>>     >>
>>     >> ...and switch the order, and use %y for 2-digit years.
>>     >>
>>     >> > On 17 Dec 2019, at 23:57 , Patrick (Malone Quantitative) <
>> malone at malonequantitative.com> wrote:
>>     >> >
>>     >> > Try putting / instead of - in your format, to match the data.
>>     >> >
>>     >> > On Tue, Dec 17, 2019 at 5:52 PM Val <valkremk at gmail.com> wrote:
>>     >> >>
>>     >> >> Hi All,
>>     >> >>
>>     >> >> I wanted to to convert character date  mm/dd/yy  to YYYY-mm-dd
>>     >> >> The sample data and my attempt is shown below
>>     >> >>
>>     >> >> gs <-read.table(text="ID date
>>     >> >> A1   09/27/03
>>     >> >> A2   05/27/16
>>     >> >> A3   01/25/13
>>     >> >> A4   09/27/19",header=TRUE,stringsAsFactors=F)
>>     >> >>
>>     >> >> Desired output
>>     >> >>  ID     date      d1
>>     >> >> A1 09/27/03 2003-09-27
>>     >> >> A2 05/27/16 2016-05-27
>>     >> >> A3 01/25/13 2012-04-25
>>     >> >> A4 09/27/19 2019-09-27
>>     >> >>
>>     >> >> I used this
>>     >> >> gs$d1 = as.Date(as.character(gs$date), format = "%Y-%m-%d")
>>     >> >>
>>     >> >> but I got NA's.
>>     >> >>
>>     >> >> How do I get my desired result?
>>     >> >> Thank you.
>>     >> >>
>>     >>
>>     >> --
>>     >> Peter Dalgaard, Professor,
>>     >> Center for Statistics, Copenhagen Business School
>>     >> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>     >> Phone: (+45)38153501
>>     >> Office: A 4.23
>>     >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>     >>
>>
>>     > --
>>     > John Kane
>>     > Kingston ON Canada



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From bgunter@4567 @end|ng |rom gm@||@com  Thu Dec 19 13:30:07 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 19 Dec 2019 04:30:07 -0800
Subject: [R] date
In-Reply-To: <20191219114902.Horde.AIT_yQYZgBKLh1F1bpiq1pf@webmail.your-server.de>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
 <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>
 <E0F0810E-4808-47EE-B455-A00A7C3641E5@gmail.com>
 <CAKZQJMBN+cEZbTcD-70dFEj4u=tpOER=Cux6BS_W9Wk1corX8A@mail.gmail.com>
 <24059.13644.667102.761870@stat.math.ethz.ch>
 <CAGgJW74cKu7Pb3g+e6VLa9DeMBxqont5ZVEzQAwx6vExxVdbDg@mail.gmail.com>
 <20191219114902.Horde.AIT_yQYZgBKLh1F1bpiq1pf@webmail.your-server.de>
Message-ID: <CAGxFJbR08Mu1cb0FzAJJa4x0XXcL12a1m8fGSTxmrcQ8QRrSwQ@mail.gmail.com>

"But the important point is:
If you know the structure of the data you want to
parse, then it is best to tell R (or any other language)
this structure explicitly. "

Fortune nomination!

-- Bert






Thu, Dec 19, 2019, 2:49 AM Enrico Schumann <es at enricoschumann.net> wrote:

>
> Quoting Eric Berger <ericjberger at gmail.com>:
>
> > Martin  writes: "there's really no reason for going beyond base R"
> >
> > I disagree. Lubridate is a fantastic package. I use it all the time. It
> > makes working with dates really easy, as evidenced by John Kane's
> > suggestion. I strongly recommend learning to work with it.
> >
> > The bottom line: as is often the case, there are many different ways to
> > accomplish a task in R.
>
> I apologise beforehand if this sparks an unnecessary discussion ;-)
>
> But the important point is:
> If you know the structure of the data you want to
> parse, then it is best to tell R (or any other language)
> this structure explicitly.
>
>
> > On Thu, Dec 19, 2019 at 10:31 AM Martin Maechler <
> maechler at stat.math.ethz.ch>
> > wrote:
> >
> >> >>>>> John Kane
> >> >>>>>     on Tue, 17 Dec 2019 20:28:17 -0500 writes:
> >>
> >>     > library(lubridate)
> >>     > gs$dat1  <-  mdy(gs$date)
> >>
> >> there's really no reason for going beyond base R.
> >>
> >> Using the proper format as per Patrick and Peter's advice
> >> (below) is perfectly clear and actually
> >> more robust (for the next data set etc)
> >> than going via "good guessing" in extra packages.
> >>
> >>     > On Tue, 17 Dec 2019 at 18:38, peter dalgaard <pdalgd at gmail.com>
> >> wrote:
> >>     >>
> >>     >> ...and switch the order, and use %y for 2-digit years.
> >>     >>
> >>     >> > On 17 Dec 2019, at 23:57 , Patrick (Malone Quantitative) <
> >> malone at malonequantitative.com> wrote:
> >>     >> >
> >>     >> > Try putting / instead of - in your format, to match the data.
> >>     >> >
> >>     >> > On Tue, Dec 17, 2019 at 5:52 PM Val <valkremk at gmail.com>
> wrote:
> >>     >> >>
> >>     >> >> Hi All,
> >>     >> >>
> >>     >> >> I wanted to to convert character date  mm/dd/yy  to YYYY-mm-dd
> >>     >> >> The sample data and my attempt is shown below
> >>     >> >>
> >>     >> >> gs <-read.table(text="ID date
> >>     >> >> A1   09/27/03
> >>     >> >> A2   05/27/16
> >>     >> >> A3   01/25/13
> >>     >> >> A4   09/27/19",header=TRUE,stringsAsFactors=F)
> >>     >> >>
> >>     >> >> Desired output
> >>     >> >>  ID     date      d1
> >>     >> >> A1 09/27/03 2003-09-27
> >>     >> >> A2 05/27/16 2016-05-27
> >>     >> >> A3 01/25/13 2012-04-25
> >>     >> >> A4 09/27/19 2019-09-27
> >>     >> >>
> >>     >> >> I used this
> >>     >> >> gs$d1 = as.Date(as.character(gs$date), format = "%Y-%m-%d")
> >>     >> >>
> >>     >> >> but I got NA's.
> >>     >> >>
> >>     >> >> How do I get my desired result?
> >>     >> >> Thank you.
> >>     >> >>
> >>     >>
> >>     >> --
> >>     >> Peter Dalgaard, Professor,
> >>     >> Center for Statistics, Copenhagen Business School
> >>     >> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> >>     >> Phone: (+45)38153501
> >>     >> Office: A 4.23
> >>     >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >>     >>
> >>
> >>     > --
> >>     > John Kane
> >>     > Kingston ON Canada
>
>
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Dec 19 13:45:41 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 19 Dec 2019 14:45:41 +0200
Subject: [R] date
In-Reply-To: <CAGxFJbR08Mu1cb0FzAJJa4x0XXcL12a1m8fGSTxmrcQ8QRrSwQ@mail.gmail.com>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
 <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>
 <E0F0810E-4808-47EE-B455-A00A7C3641E5@gmail.com>
 <CAKZQJMBN+cEZbTcD-70dFEj4u=tpOER=Cux6BS_W9Wk1corX8A@mail.gmail.com>
 <24059.13644.667102.761870@stat.math.ethz.ch>
 <CAGgJW74cKu7Pb3g+e6VLa9DeMBxqont5ZVEzQAwx6vExxVdbDg@mail.gmail.com>
 <20191219114902.Horde.AIT_yQYZgBKLh1F1bpiq1pf@webmail.your-server.de>
 <CAGxFJbR08Mu1cb0FzAJJa4x0XXcL12a1m8fGSTxmrcQ8QRrSwQ@mail.gmail.com>
Message-ID: <CAGgJW74eiij=OzU+8kCrnJLut5o9m2cxnh_wKBO0=RDv48xn8w@mail.gmail.com>

[ ... taking the bait regarding the "unnecessary discussion" ... ]

The "Fortune nomination" that Bert sent includes the phrase

"...then it is best to tell R ..."

What metric is being used to do the ranking to get the "best"? If the
metric is related to "providing the most unambiguous information to R"
then I agree that providing the structure explicitly is best.
However, often what is "best" is to minimize programmer time. With
lubridate, I know that providing the clue 'ymd' is enough to have it
perform the date conversion correctly. That is minimal effort on my part,
which gives it a top ranking from my point of view.

Also, to broaden this "unnecessary discussion" I would argue that the
lubridate package may even be more "in the spirit of R" than what is being
proposed with the explicit structural information. Clearly R is far from
being a strongly typed language. If you really want to provide explicit
structural information maybe you would be better off with a language such
as C++. :-)





On Thu, Dec 19, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

>
>
> "But the important point is:
> If you know the structure of the data you want to
> parse, then it is best to tell R (or any other language)
> this structure explicitly. "
>
> Fortune nomination!
>
> -- Bert
>
>
>
>
>
>
> Thu, Dec 19, 2019, 2:49 AM Enrico Schumann <es at enricoschumann.net> wrote:
>
>>
>> Quoting Eric Berger <ericjberger at gmail.com>:
>>
>> > Martin  writes: "there's really no reason for going beyond base R"
>> >
>> > I disagree. Lubridate is a fantastic package. I use it all the time. It
>> > makes working with dates really easy, as evidenced by John Kane's
>> > suggestion. I strongly recommend learning to work with it.
>> >
>> > The bottom line: as is often the case, there are many different ways to
>> > accomplish a task in R.
>>
>> I apologise beforehand if this sparks an unnecessary discussion ;-)
>>
>> But the important point is:
>> If you know the structure of the data you want to
>> parse, then it is best to tell R (or any other language)
>> this structure explicitly.
>>
>>
>> > On Thu, Dec 19, 2019 at 10:31 AM Martin Maechler <
>> maechler at stat.math.ethz.ch>
>> > wrote:
>> >
>> >> >>>>> John Kane
>> >> >>>>>     on Tue, 17 Dec 2019 20:28:17 -0500 writes:
>> >>
>> >>     > library(lubridate)
>> >>     > gs$dat1  <-  mdy(gs$date)
>> >>
>> >> there's really no reason for going beyond base R.
>> >>
>> >> Using the proper format as per Patrick and Peter's advice
>> >> (below) is perfectly clear and actually
>> >> more robust (for the next data set etc)
>> >> than going via "good guessing" in extra packages.
>> >>
>> >>     > On Tue, 17 Dec 2019 at 18:38, peter dalgaard <pdalgd at gmail.com>
>> >> wrote:
>> >>     >>
>> >>     >> ...and switch the order, and use %y for 2-digit years.
>> >>     >>
>> >>     >> > On 17 Dec 2019, at 23:57 , Patrick (Malone Quantitative) <
>> >> malone at malonequantitative.com> wrote:
>> >>     >> >
>> >>     >> > Try putting / instead of - in your format, to match the data.
>> >>     >> >
>> >>     >> > On Tue, Dec 17, 2019 at 5:52 PM Val <valkremk at gmail.com>
>> wrote:
>> >>     >> >>
>> >>     >> >> Hi All,
>> >>     >> >>
>> >>     >> >> I wanted to to convert character date  mm/dd/yy  to
>> YYYY-mm-dd
>> >>     >> >> The sample data and my attempt is shown below
>> >>     >> >>
>> >>     >> >> gs <-read.table(text="ID date
>> >>     >> >> A1   09/27/03
>> >>     >> >> A2   05/27/16
>> >>     >> >> A3   01/25/13
>> >>     >> >> A4   09/27/19",header=TRUE,stringsAsFactors=F)
>> >>     >> >>
>> >>     >> >> Desired output
>> >>     >> >>  ID     date      d1
>> >>     >> >> A1 09/27/03 2003-09-27
>> >>     >> >> A2 05/27/16 2016-05-27
>> >>     >> >> A3 01/25/13 2012-04-25
>> >>     >> >> A4 09/27/19 2019-09-27
>> >>     >> >>
>> >>     >> >> I used this
>> >>     >> >> gs$d1 = as.Date(as.character(gs$date), format = "%Y-%m-%d")
>> >>     >> >>
>> >>     >> >> but I got NA's.
>> >>     >> >>
>> >>     >> >> How do I get my desired result?
>> >>     >> >> Thank you.
>> >>     >> >>
>> >>     >>
>> >>     >> --
>> >>     >> Peter Dalgaard, Professor,
>> >>     >> Center for Statistics, Copenhagen Business School
>> >>     >> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> >>     >> Phone: (+45)38153501
>> >>     >> Office: A 4.23
>> >>     >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> >>     >>
>> >>
>> >>     > --
>> >>     > John Kane
>> >>     > Kingston ON Canada
>>
>>
>>
>> --
>> Enrico Schumann
>> Lucerne, Switzerland
>> http://enricoschumann.net
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From |r@nk||n_copper||e|d @end|ng |rom 126@com  Thu Dec 19 14:27:50 2019
From: |r@nk||n_copper||e|d @end|ng |rom 126@com (=?GBK?B?uLXHvw==?=)
Date: Thu, 19 Dec 2019 21:27:50 +0800 (CST)
Subject: [R] How to convert ARMA process to infinite AR?
Message-ID: <45f00776.83ef.16f1e57d5c5.Coremail.franklin_copperfield@126.com>

Hi,

 AR<-c(.4,.45)

MA<-c(1,.25)

ARMAtoMA(ar =AR, ma = MA, lag.max = 30)

 

picoefs <- c(1, ARMAtoMA(ar = -MA, ma = -AR, lag.max = 30))

picoefs

Maybe it works!
	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Dec 19 15:34:13 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 19 Dec 2019 06:34:13 -0800
Subject: [R] date
In-Reply-To: <CAGgJW74eiij=OzU+8kCrnJLut5o9m2cxnh_wKBO0=RDv48xn8w@mail.gmail.com>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
 <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>
 <E0F0810E-4808-47EE-B455-A00A7C3641E5@gmail.com>
 <CAKZQJMBN+cEZbTcD-70dFEj4u=tpOER=Cux6BS_W9Wk1corX8A@mail.gmail.com>
 <24059.13644.667102.761870@stat.math.ethz.ch>
 <CAGgJW74cKu7Pb3g+e6VLa9DeMBxqont5ZVEzQAwx6vExxVdbDg@mail.gmail.com>
 <20191219114902.Horde.AIT_yQYZgBKLh1F1bpiq1pf@webmail.your-server.de>
 <CAGxFJbR08Mu1cb0FzAJJa4x0XXcL12a1m8fGSTxmrcQ8QRrSwQ@mail.gmail.com>
 <CAGgJW74eiij=OzU+8kCrnJLut5o9m2cxnh_wKBO0=RDv48xn8w@mail.gmail.com>
Message-ID: <9072E5F9-CF04-4B28-9CAB-E8EA078DAD3C@dcn.davis.ca.us>

I agree that having convenience functions can be in the spirit of R, but I find that lubridate puts the cart before the horse so I avoid it. Specifically, the conceptual sequence

- convert character to timestamp in GMT
- "fix" erroneous timestamps to correct time zone

more inefficient and error-prone than

- convert character to timestamp specifying correct timezone

or

- specify default timezone
- convert character to timestamp using default timezone

but apparently others disagree so we have a whole sub-culture working with GMT by default.

On December 19, 2019 4:45:41 AM PST, Eric Berger <ericjberger at gmail.com> wrote:
>[ ... taking the bait regarding the "unnecessary discussion" ... ]
>
>The "Fortune nomination" that Bert sent includes the phrase
>
>"...then it is best to tell R ..."
>
>What metric is being used to do the ranking to get the "best"? If the
>metric is related to "providing the most unambiguous information to R"
>then I agree that providing the structure explicitly is best.
>However, often what is "best" is to minimize programmer time. With
>lubridate, I know that providing the clue 'ymd' is enough to have it
>perform the date conversion correctly. That is minimal effort on my
>part,
>which gives it a top ranking from my point of view.
>
>Also, to broaden this "unnecessary discussion" I would argue that the
>lubridate package may even be more "in the spirit of R" than what is
>being
>proposed with the explicit structural information. Clearly R is far
>from
>being a strongly typed language. If you really want to provide explicit
>structural information maybe you would be better off with a language
>such
>as C++. :-)
>
>
>
>
>
>On Thu, Dec 19, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>
>>
>>
>> "But the important point is:
>> If you know the structure of the data you want to
>> parse, then it is best to tell R (or any other language)
>> this structure explicitly. "
>>
>> Fortune nomination!
>>
>> -- Bert
>>
>>
>>
>>
>>
>>
>> Thu, Dec 19, 2019, 2:49 AM Enrico Schumann <es at enricoschumann.net>
>wrote:
>>
>>>
>>> Quoting Eric Berger <ericjberger at gmail.com>:
>>>
>>> > Martin  writes: "there's really no reason for going beyond base R"
>>> >
>>> > I disagree. Lubridate is a fantastic package. I use it all the
>time. It
>>> > makes working with dates really easy, as evidenced by John Kane's
>>> > suggestion. I strongly recommend learning to work with it.
>>> >
>>> > The bottom line: as is often the case, there are many different
>ways to
>>> > accomplish a task in R.
>>>
>>> I apologise beforehand if this sparks an unnecessary discussion ;-)
>>>
>>> But the important point is:
>>> If you know the structure of the data you want to
>>> parse, then it is best to tell R (or any other language)
>>> this structure explicitly.
>>>
>>>
>>> > On Thu, Dec 19, 2019 at 10:31 AM Martin Maechler <
>>> maechler at stat.math.ethz.ch>
>>> > wrote:
>>> >
>>> >> >>>>> John Kane
>>> >> >>>>>     on Tue, 17 Dec 2019 20:28:17 -0500 writes:
>>> >>
>>> >>     > library(lubridate)
>>> >>     > gs$dat1  <-  mdy(gs$date)
>>> >>
>>> >> there's really no reason for going beyond base R.
>>> >>
>>> >> Using the proper format as per Patrick and Peter's advice
>>> >> (below) is perfectly clear and actually
>>> >> more robust (for the next data set etc)
>>> >> than going via "good guessing" in extra packages.
>>> >>
>>> >>     > On Tue, 17 Dec 2019 at 18:38, peter dalgaard
><pdalgd at gmail.com>
>>> >> wrote:
>>> >>     >>
>>> >>     >> ...and switch the order, and use %y for 2-digit years.
>>> >>     >>
>>> >>     >> > On 17 Dec 2019, at 23:57 , Patrick (Malone Quantitative)
><
>>> >> malone at malonequantitative.com> wrote:
>>> >>     >> >
>>> >>     >> > Try putting / instead of - in your format, to match the
>data.
>>> >>     >> >
>>> >>     >> > On Tue, Dec 17, 2019 at 5:52 PM Val <valkremk at gmail.com>
>>> wrote:
>>> >>     >> >>
>>> >>     >> >> Hi All,
>>> >>     >> >>
>>> >>     >> >> I wanted to to convert character date  mm/dd/yy  to
>>> YYYY-mm-dd
>>> >>     >> >> The sample data and my attempt is shown below
>>> >>     >> >>
>>> >>     >> >> gs <-read.table(text="ID date
>>> >>     >> >> A1   09/27/03
>>> >>     >> >> A2   05/27/16
>>> >>     >> >> A3   01/25/13
>>> >>     >> >> A4   09/27/19",header=TRUE,stringsAsFactors=F)
>>> >>     >> >>
>>> >>     >> >> Desired output
>>> >>     >> >>  ID     date      d1
>>> >>     >> >> A1 09/27/03 2003-09-27
>>> >>     >> >> A2 05/27/16 2016-05-27
>>> >>     >> >> A3 01/25/13 2012-04-25
>>> >>     >> >> A4 09/27/19 2019-09-27
>>> >>     >> >>
>>> >>     >> >> I used this
>>> >>     >> >> gs$d1 = as.Date(as.character(gs$date), format =
>"%Y-%m-%d")
>>> >>     >> >>
>>> >>     >> >> but I got NA's.
>>> >>     >> >>
>>> >>     >> >> How do I get my desired result?
>>> >>     >> >> Thank you.
>>> >>     >> >>
>>> >>     >>
>>> >>     >> --
>>> >>     >> Peter Dalgaard, Professor,
>>> >>     >> Center for Statistics, Copenhagen Business School
>>> >>     >> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> >>     >> Phone: (+45)38153501
>>> >>     >> Office: A 4.23
>>> >>     >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> >>     >>
>>> >>
>>> >>     > --
>>> >>     > John Kane
>>> >>     > Kingston ON Canada
>>>
>>>
>>>
>>> --
>>> Enrico Schumann
>>> Lucerne, Switzerland
>>> http://enricoschumann.net
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jun@y@n @end|ng |rom uconn@edu  Thu Dec 19 13:01:18 2019
From: jun@y@n @end|ng |rom uconn@edu (Yan, Jun)
Date: Thu, 19 Dec 2019 12:01:18 +0000
Subject: [R] Nominations sought for the 2021 ASA Statistical Computing and
 Graphics Award
Message-ID: <BL0PR05MB4627CE74D6B870F99C4A8792F0520@BL0PR05MB4627.namprd05.prod.outlook.com>

(Apologies for cross-posting)

Dear Colleagues,

The ASA Section on?Statistical?Computing?and Section on?Statistical Graphics are inviting nominations of deserving individuals or teams for the 2021 ASA?Statistical?Computing?and Graphics?Award (https://community.amstat.org/jointscsg-section/awards/computing-graphics-award). 

The Statistical?Computing?and Graphics?Award?recognizes an individual or team for innovation in?computing, software, or graphics that has had a significant impact on?statistical?practice or research. The past awardees are Luke Tierney (2019), Bill Cleveland (2016), and Robert Gentleman and Ross Ihaka (2010). The prize carries with it a cash award?of $5,000 plus an allowance of up to $1,000 for travel to the Joint?Statistical?Meetings (JSM) where the?award?will be presented. Nominations packets have to be submitted by email to Dr. Jun Yan, the Awards?Chair of the two sections, at?jun.yan at uconn.edu?by May 31, 2020. Dr. Jun Yan is the?Award?Chair of the two sections and will be pleased to answer any questions about the submission process and the preparation of the nomination materials.

Qualifications

The prize-winning contribution will have had significant and lasting impacts on?statistical?computing, software or graphics.

The nominee should be a member of the ASA. The?Statistical?Computing and Graphics?Award?Committee will review the nominations and make the final determination of who, if any, should receive the?award. The award?may not be given to a sitting member of the?Awards?Committee or a sitting member of the Executive Committee of the Section of Statistical?Computing?or the Section of?Statistical?Graphics.

Nomination and?Award?Dates

Nominations are due by May 31, 2020 for an?award?to be presented at the 2021 JSM.

Nominations should be submitted as a complete packet, consisting of:

+ a nomination letter, no longer than four pages, addressing points in the selection criteria
+ nominee?s curriculum vita(e)
+ a minimum of 3 (and no more than 4) supporting letters, each no longer than two pages

Selection Process

The Committee will consist of the Chairs and Past Chairs of the Section of?Statistical?Computing?and the Section of?Statistical Graphics. The committee will meet at the 2020 JSM to select the recipient(s) of the?award.

Jun Yan, Awards Chair
ASA Section on Statistical Computing and
Section on Statistical Graphics

From d@v|d@@teven@ @end|ng |rom u@u@edu  Thu Dec 19 20:24:14 2019
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David Stevens)
Date: Thu, 19 Dec 2019 19:24:14 +0000
Subject: [R] date
In-Reply-To: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
Message-ID: <de24dc97-4035-0e40-373a-8e98c209fd78@usu.edu>

Val

Another all-base R solution:

as.Date(strptime(gs$date,format="%m/%d/%y"))

or if you want to add a time field later

as.POSIXct(strptime(gs$date,format="%m/%d/%y")))

since strptime produces a list version of the date: class is POSIXt and the subclass is POSIXlt, that can be convenient for extracting elements like month, day of the year, minute, etc. The actual date/time information is returned as the number of seconds since 1970-01-01 00:00:00 UTC but the representation is as in your gs.d1 below.

It can be a bit tricky when daylight savings time comes into play but that's for another post.

David


On 12/17/2019 3:51 PM, Val wrote:

Hi All,

I wanted to to convert character date  mm/dd/yy  to YYYY-mm-dd
The sample data and my attempt is shown below

gs <-read.table(text="ID date
A1   09/27/03
A2   05/27/16
A3   01/25/13
A4   09/27/19",header=TRUE,stringsAsFactors=F)

Desired output
  ID     date      d1
 A1 09/27/03 2003-09-27
 A2 05/27/16 2016-05-27
 A3 01/25/13 2012-04-25
 A4 09/27/19 2019-09-27

I used this
gs$d1 = as.Date(as.character(gs$date), format = "%Y-%m-%d")

but I got NA's.

How do I get my desired result?
Thank you.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


--
David K Stevens, PhD, PE
Environmental Engineering Division
Civil and Environmental Engineering
Utah State University
8200 Old Main Hill
Logan, UT 83200-8200
(435) 797-3229
david.stevens at usu.edu<mailto:david.stevens at usu.edu>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Dec 19 23:35:08 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 20 Dec 2019 11:35:08 +1300
Subject: [R] [FORGED] Re:  date
In-Reply-To: <CAGxFJbR08Mu1cb0FzAJJa4x0XXcL12a1m8fGSTxmrcQ8QRrSwQ@mail.gmail.com>
References: <CAJOiR6b6CxDFYQVw0-u=XNZLpweA5W2ahx73S4Z5VhqyUZ4EMg@mail.gmail.com>
 <CAJc=yOGP=rFjezJdxb5GiWXCs0oGAPSO1Kn5KzKAQBVMudUnZg@mail.gmail.com>
 <E0F0810E-4808-47EE-B455-A00A7C3641E5@gmail.com>
 <CAKZQJMBN+cEZbTcD-70dFEj4u=tpOER=Cux6BS_W9Wk1corX8A@mail.gmail.com>
 <24059.13644.667102.761870@stat.math.ethz.ch>
 <CAGgJW74cKu7Pb3g+e6VLa9DeMBxqont5ZVEzQAwx6vExxVdbDg@mail.gmail.com>
 <20191219114902.Horde.AIT_yQYZgBKLh1F1bpiq1pf@webmail.your-server.de>
 <CAGxFJbR08Mu1cb0FzAJJa4x0XXcL12a1m8fGSTxmrcQ8QRrSwQ@mail.gmail.com>
Message-ID: <1a0e6889-8f53-3a9a-bd8a-521a4b836b50@auckland.ac.nz>

On 20/12/19 1:30 am, Bert Gunter wrote:
> "But the important point is:
> If you know the structure of the data you want to
> parse, then it is best to tell R (or any other language)
> this structure explicitly. "
> 
> Fortune nomination!

Second the nomination!

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ycd|ng @end|ng |rom coh@org  Fri Dec 20 03:01:00 2019
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Fri, 20 Dec 2019 02:01:00 +0000
Subject: [R] data reshape
Message-ID: <A86C6438FB909A409DDEF926277952B6113B4F9E@PPWEXCH2KX14.coh.org>

Hi R users,

I have a folder (called genotype) with 652 files; the file names are  GTEX-1A3MV.out, GTEX-1A3MX.out, GTEX-1B8SF.out, etc; in each file,  only one column of data without a header as below
201
2/2
238
3/4
245
1/2
.....
983255
3/3
983766
None


A total of 20528 rows;

I need to read all those 652 files in the genotype folder and then reshape the one column in each file as:
SampleID             201        238        245        ....   983255         983766
GTEX-1A3MV     2/2         3/4        1/2                         3/3         None

There are 10264 data columns plus the sample ID column, so 10265 columns in total after data reshaping.

After reading those 652 file and reshape the one column in each file, I will stack them by the rbind function, then I have a file with a dimension of 653 row, 10265 column.


Thank you,

Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Dec 20 03:51:56 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 19 Dec 2019 18:51:56 -0800
Subject: [R] data reshape
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113B4F9E@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113B4F9E@PPWEXCH2KX14.coh.org>
Message-ID: <CAGxFJbRNuHj29Yb+JZWQZDCj75nt2nteG7X1fVQCi4mMHrJcxA@mail.gmail.com>

Did you even make an attempt to do this? -- or would you like us do all
your work for you?

If you made an attempt, show us your code and errors.
If not, we usually expect you to try on your own first.
If you have no idea where to start, perhaps you need to spend some more
time with tutorials to learn basic R functionality before proceeding.

Bert

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 19, 2019 at 6:01 PM Yuan Chun Ding <ycding at coh.org> wrote:

> Hi R users,
>
> I have a folder (called genotype) with 652 files; the file names are
> GTEX-1A3MV.out, GTEX-1A3MX.out, GTEX-1B8SF.out, etc; in each file,  only
> one column of data without a header as below
> 201
> 2/2
> 238
> 3/4
> 245
> 1/2
> .....
> 983255
> 3/3
> 983766
> None
>
>
> A total of 20528 rows;
>
> I need to read all those 652 files in the genotype folder and then reshape
> the one column in each file as:
> SampleID             201        238        245        ....   983255
>  983766
> GTEX-1A3MV     2/2         3/4        1/2                         3/3
>    None
>
> There are 10264 data columns plus the sample ID column, so 10265 columns
> in total after data reshaping.
>
> After reading those 652 file and reshape the one column in each file, I
> will stack them by the rbind function, then I have a file with a dimension
> of 653 row, 10265 column.
>
>
> Thank you,
>
> Ding
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to rec
>  eive further communications via e-mail, please reply to this message and
> inform the sender that you do not wish to receive further e-mail from the
> sender. (LCP301)
> ------------------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||54250 @end|ng |rom m@n@com  Fri Dec 20 12:27:43 2019
From: ||54250 @end|ng |rom m@n@com (Ioanna Ioannou)
Date: Fri, 20 Dec 2019 11:27:43 +0000
Subject: [R] How to save output of multiple unique loops in R.
Message-ID: <DBBPR05MB65703BC0C5FD5DE4AC0AB6D6F32D0@DBBPR05MB6570.eurprd05.prod.outlook.com>

Hello everyone,

Could you please let me know how to create a new data.frame with the output of the 2 unique loops. Essentially i want a data.frame with the IM, Taxonomy and VC . MInd you VC is a vector with 33 elements.

Any ideas?

best,
ioanna

D<- data.frame(Ref.No = c(1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629),  Region = rep(c('South America'), times = 8),
               IM.type = c('PGA', 'PGA', 'PGA', 'PGA', 'Sa', 'Sa', 'Sa', 'Sa'),
               Damage.state = c('DS1', 'DS2', 'DS3', 'DS4','DS1', 'DS2', 'DS3', 'DS4'),
               Taxonomy = c('ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H2','ER+ETR_H2','ER+ETR_H2','ER+ETR_H2'),
               Prob.of.exceedance_1 = c(0,0,0,0,0,0,0,0),
               Prob.of.exceedance_2 = c(0,0,0,0,0,0,0,0),
              Prob.of.exceedance_3 =c(0.26,0.001,0.00019,0.000000573,0.04,0.00017,0.000215,0.000472),
              Prob.of.exceedance_4 =
                c(0.72,0.03,0.008,0.000061,0.475,0.0007,0.00435,0.000405),
              stringsAsFactors=FALSE)



# names of the variables used in the calculations
calc_vars<-paste("Prob.of.exceedance",1:4,sep="_")
# get the rows for the four damage states
DS1_rows <-D$Damage.state == "DS1"
DS2_rows <-D$Damage.state == "DS2"
DS3_rows <-D$Damage.state == "DS3"
DS4_rows <-D$Damage.state == "DS4"
# step through all possible values of IM.type and Taxonomy
for(IM in unique(D$IM.type)) {  for(Tax in unique(D$Taxonomy)) {
# get a logical vector of the rows to be used in this calculation
calc_rows <- D$IM.type == IM & D$Taxonomy == Tax
cat(IM,Tax,calc_rows,"\n")
# check that there are any such rows in the data frame
if(sum(calc_rows)) {
  # if so, fill in the four values for these rows
  VC <- 0.0 * (1- D[calc_rows & DS1_rows,calc_vars]) +
    0.02* (D[calc_rows & DS1_rows,calc_vars] -
               D[calc_rows & DS2_rows,calc_vars]) +
    0.10* (D[calc_rows & DS2_rows,calc_vars] -
                                   D[calc_rows & DS3_rows,calc_vars]) +
    0.43 * (D[calc_rows & DS3_rows,calc_vars] -
                                   D[calc_rows & DS4_rows,calc_vars]) +
    1.0*   D[calc_rows & DS4_rows,calc_vars]

}
}
}



	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Dec 20 12:40:28 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 20 Dec 2019 22:40:28 +1100
Subject: [R] 
 How to create a new data.frame based on calculation of subsets
 of an existing data.frame
In-Reply-To: <DB8PR01MB56759F3B055EE157D6AC764CC92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
References: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fUbFmch8gORE9huB+1Ts50uNU1T14obR4e7V401eaNVfg@mail.gmail.com>
 <DB8PR01MB56752F156F6C4DBEC2AB0C02C9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fWnLBOPNxc1_AJVndjd0x3NrGD6UTKiK9JugZawHjwdbg@mail.gmail.com>
 <CA+8X3fURQd+nvf=JER5kf=N7MfwUKNrzinvtiYHAa_w2XRN37w@mail.gmail.com>
 <DB8PR01MB56759F3B055EE157D6AC764CC92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fX7oDs93643w31n1cS5ZwmAT0Ov0n5593+Be4hQGQMOnw@mail.gmail.com>

Hi Ioanna,
For simplicity assume that the new data frame will be named E:

E<-D[,c("Taxonomy","IM.type",paste("VC,1:4,sep="_"))]

While I haven't tested this, I'm pretty sure I have it correct. Just
extract the columns you want from D and assign that to E.

Jim

On Fri, Dec 20, 2019 at 9:02 PM Ioannou, Ioanna
<ioanna.ioannou at ucl.ac.uk> wrote:
>
> Hello Jim,
>
> Thank you every so  much it ws very helful. In fact what I want to calculate is the following. My very last question is if I want to save the outcome VC, IM.type and Taxonomy in a new data.frame how can I do it?
>


From |o@nn@@|o@nnou @end|ng |rom uc|@@c@uk  Fri Dec 20 11:01:58 2019
From: |o@nn@@|o@nnou @end|ng |rom uc|@@c@uk (Ioannou, Ioanna)
Date: Fri, 20 Dec 2019 10:01:58 +0000
Subject: [R] 
 How to create a new data.frame based on calculation of subsets
 of an existing data.frame
In-Reply-To: <CA+8X3fURQd+nvf=JER5kf=N7MfwUKNrzinvtiYHAa_w2XRN37w@mail.gmail.com>
References: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fUbFmch8gORE9huB+1Ts50uNU1T14obR4e7V401eaNVfg@mail.gmail.com>
 <DB8PR01MB56752F156F6C4DBEC2AB0C02C9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fWnLBOPNxc1_AJVndjd0x3NrGD6UTKiK9JugZawHjwdbg@mail.gmail.com>
 <CA+8X3fURQd+nvf=JER5kf=N7MfwUKNrzinvtiYHAa_w2XRN37w@mail.gmail.com>
Message-ID: <DB8PR01MB56759F3B055EE157D6AC764CC92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>

Hello Jim, 

Thank you every so  much it ws very helful. In fact what I want to calculate is the following. My very last question is if I want to save the outcome VC, IM.type and Taxonomy in a new data.frame how can I do it?

# names of the variables used in the calculations
calc_vars<-paste("Prob.of.exceedance",1:4,sep="_")
# get the rows for the four damage states 
DS1_rows <-D$Damage.state == "DS1"
DS2_rows <-D$Damage.state == "DS2"
DS3_rows <-D$Damage.state == "DS3"
DS4_rows <-D$Damage.state == "DS4"
# step through all possible values of IM.type and Taxonomy 
for(IM in unique(D$IM.type)) {  for(Tax in unique(D$Taxonomy)) {
# get a logical vector of the rows to be used in this calculation
calc_rows <- D$IM.type == IM & D$Taxonomy == Tax
cat(IM,Tax,calc_rows,"\n")
# check that there are any such rows in the data frame
if(sum(calc_rows)) {
  # if so, fill in the four values for these rows
  VC <- 0.0 * (1- D[calc_rows & DS1_rows,calc_vars]) +
    0.02* (D[calc_rows & DS1_rows,calc_vars] -
               D[calc_rows & DS2_rows,calc_vars]) +
    0.10* (D[calc_rows & DS2_rows,calc_vars] -
                                   D[calc_rows & DS3_rows,calc_vars]) +
    0.43 * (D[calc_rows & DS3_rows,calc_vars] -
                                   D[calc_rows & DS4_rows,calc_vars]) +
    1.0*   D[calc_rows & DS4_rows,calc_vars]

}
}
}

-----Original Message-----
From: Jim Lemon [mailto:drjimlemon at gmail.com] 
Sent: Thursday, December 19, 2019 2:05 AM
To: Ioannou, Ioanna <ioanna.ioannou at ucl.ac.uk>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] How to create a new data.frame based on calculation of subsets of an existing data.frame

Hi Ioanna,
I looked at the problem this morning and tried to work out what you wanted. With a problem like this, it is often easy when you have someone point to the data and say "I want this added to that and this multiplied by that". I have probably made the wrong guesses, but I hope that you can correct my guesses and I can get the calculations correct for you. For example, I have assumed that you want the sum of the IM_* values for each set of damage states as the values for VC_1,
VC_2 etc.

D<-data.frame(Ref.No = c(1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629),  Region = rep(c('South America'), times = 8),  IM.type = c('PGA', 'PGA', 'PGA', 'PGA', 'Sa', 'Sa', 'Sa', 'Sa'),  Damage.state = c('DS1', 'DS2', 'DS3', 'DS4','DS1', 'DS2', 'DS3', 'DS4'),  Taxonomy = c('ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H2',
 'ER+ETR_H2','ER+ETR_H2','ER+ETR_H2'),
 IM_1 = c(0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00),
 IM_2 = c(0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08),
 IM_3 = c(0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16),
 IM_4 = c(0.24, 0.24, 0.24, 0.24, 0.24, 0.24, 0.24, 0.24),
 Prob.of.exceedance_1 = c(0,0,0,0,0,0,0,0),
 Prob.of.exceedance_2 = c(0,0,0,0,0,0,0,0),
 Prob.of.exceedance_3 =
 c(0.26,0.001,0.00019,0.000000573,0.04,0.00017,0.000215,0.000472),
 Prob.of.exceedance_4 =
 c(0.72,0.03,0.008,0.000061,0.475,0.0007,0.00435,0.000405),
 stringsAsFactors=FALSE)
# assume the above has been read in
# add the four columns to the data frame filled with NAs D$VC_1<-D$VC_2<-D$VC_3<-D$VC_4<-NA
# names of the variables used in the calculations
calc_vars<-paste("Prob.of.exceedance",1:4,sep="_")
# get the rows for the four damage states DS1_rows<-D$Damage.state == "DS1"
DS2_rows<-D$Damage.state == "DS2"
DS3_rows<-D$Damage.state == "DS3"
DS4_rows<-D$Damage.state == "DS4"
# step through all possible values of IM.type and Taxonomy for(IM in unique(D$IM.type)) {  for(Tax in unique(D$Taxonomy)) {
  # get a logical vector of the rows to be used in this calculation
  calc_rows<-D$IM.type == IM & D$Taxonomy == Tax
  cat(IM,Tax,calc_rows,"\n")
  # check that there are any such rows in the data frame
  if(sum(calc_rows)) {
   # if so, fill in the four values for these rows
   D$VC_1[calc_rows]<-sum(0.01 * (D[calc_rows & DS1_rows,calc_vars] -
    D[calc_rows & DS2_rows,calc_vars]))
   D$VC_2[calc_rows]<-sum(0.02 * (D[calc_rows & DS2_rows,calc_vars] -
    D[calc_rows & DS3_rows,calc_vars]))
   D$VC_3[calc_rows]<-sum(0.43 * (D[calc_rows & DS3_rows,calc_vars] -
    D[calc_rows & DS4_rows,calc_vars]))
   D$VC_4[calc_rows]<-sum(D[calc_rows & DS4_rows,calc_vars])
  }
 }
}

Jim

From |o@nn@@|o@nnou @end|ng |rom uc|@@c@uk  Fri Dec 20 14:45:50 2019
From: |o@nn@@|o@nnou @end|ng |rom uc|@@c@uk (Ioannou, Ioanna)
Date: Fri, 20 Dec 2019 13:45:50 +0000
Subject: [R] 
 How to create a new data.frame based on calculation of subsets
 of an existing data.frame
In-Reply-To: <CA+8X3fX7oDs93643w31n1cS5ZwmAT0Ov0n5593+Be4hQGQMOnw@mail.gmail.com>
References: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fUbFmch8gORE9huB+1Ts50uNU1T14obR4e7V401eaNVfg@mail.gmail.com>
 <DB8PR01MB56752F156F6C4DBEC2AB0C02C9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fWnLBOPNxc1_AJVndjd0x3NrGD6UTKiK9JugZawHjwdbg@mail.gmail.com>
 <CA+8X3fURQd+nvf=JER5kf=N7MfwUKNrzinvtiYHAa_w2XRN37w@mail.gmail.com>
 <DB8PR01MB56759F3B055EE157D6AC764CC92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>,
 <CA+8X3fX7oDs93643w31n1cS5ZwmAT0Ov0n5593+Be4hQGQMOnw@mail.gmail.com>
Message-ID: <DB8PR01MB567575DA16F823A401DF94A2C92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>

Hello Jim,

I made some changes to the code essentially I substitute each 4 lines DS1-4 with one. I estimate VC which in an ideal world should be a matrix with 4 columns one for every exceedance_probability_1-4 and 2 rowsfor each unique combination of taxonomy and IM.Type. Coukd you please check the code I sent last and based on that give your solution?

Many thanks.

Get Outlook for Android<https://aka.ms/ghei36>

________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Friday, December 20, 2019 11:40:28 AM
To: Ioannou, Ioanna <ioanna.ioannou at ucl.ac.uk>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] How to create a new data.frame based on calculation of subsets of an existing data.frame

Hi Ioanna,
For simplicity assume that the new data frame will be named E:

E<-D[,c("Taxonomy","IM.type",paste("VC,1:4,sep="_"))]

While I haven't tested this, I'm pretty sure I have it correct. Just
extract the columns you want from D and assign that to E.

Jim

On Fri, Dec 20, 2019 at 9:02 PM Ioannou, Ioanna
<ioanna.ioannou at ucl.ac.uk> wrote:
>
> Hello Jim,
>
> Thank you every so  much it ws very helful. In fact what I want to calculate is the following. My very last question is if I want to save the outcome VC, IM.type and Taxonomy in a new data.frame how can I do it?
>

	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Fri Dec 20 17:24:43 2019
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sat, 21 Dec 2019 00:24:43 +0800
Subject: [R] Using older version of R
Message-ID: <d80c86b7-8a90-d28b-6eef-b7b4c18a1070@ntu.edu.tw>

I had to use an older version of R (as old as R3.0.3) for a reason. I 
myself have no problem installing a package built under a newer version, 
but my student (who also installed R3.0.3) could not install the package 
(newer version). Had an error message saying package xxxxx is not 
available under R3.0.3. Is there a get-arround----to be able to install 
while running an older R version? (Don't ask me why I run an older R. An 
essential package I need works well only in R3.0.3). Thank you all.

-- 
styen at ntu.edu.tw (S.T. Yen)


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Dec 20 17:55:30 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 20 Dec 2019 08:55:30 -0800
Subject: [R] Using older version of R
In-Reply-To: <d80c86b7-8a90-d28b-6eef-b7b4c18a1070@ntu.edu.tw>
References: <d80c86b7-8a90-d28b-6eef-b7b4c18a1070@ntu.edu.tw>
Message-ID: <CAGxFJbTAPfyK=RpXXprQuUVNLDdboj6XpyuuxeY7OTHKAk+9ow@mail.gmail.com>

No.

You can install both versions side by side, use the newer version and
xxxxxx package as needed, use the older version and your essential package
as needed, and shift results in .Rdata files -- or even as text files of
data -- between them as necessary.

This is obviously a nightmare and may be impossible for your needs, but it
is a problem of your own choosing.

Note: Please wait for other replies before trying this, as someone else may
have better ideas.

Cheers,
Bert




On Fri, Dec 20, 2019 at 8:43 AM Steven Yen <styen at ntu.edu.tw> wrote:

> I had to use an older version of R (as old as R3.0.3) for a reason. I
> myself have no problem installing a package built under a newer version,
> but my student (who also installed R3.0.3) could not install the package
> (newer version). Had an error message saying package xxxxx is not
> available under R3.0.3. Is there a get-arround----to be able to install
> while running an older R version? (Don't ask me why I run an older R. An
> essential package I need works well only in R3.0.3). Thank you all.
>
> --
> styen at ntu.edu.tw (S.T. Yen)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ycd|ng @end|ng |rom coh@org  Fri Dec 20 18:00:00 2019
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Fri, 20 Dec 2019 17:00:00 +0000
Subject: [R] data reshape
In-Reply-To: <CAGxFJbRNuHj29Yb+JZWQZDCj75nt2nteG7X1fVQCi4mMHrJcxA@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6113B4F9E@PPWEXCH2KX14.coh.org>
 <CAGxFJbRNuHj29Yb+JZWQZDCj75nt2nteG7X1fVQCi4mMHrJcxA@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6113B50A7@PPWEXCH2KX14.coh.org>

Hi Bert,

Sorry that I was in a hurry  going home yesterday afternoon and just posted my question and hoped to get some advice.

Here is what I got yesterday before going home.
---------------------------------------------------------------
setwd("C:/Awork/VNTR/GETXdata/GTEx_genotypes")

file_list <- list.files(pattern="*.out")

#to read all 652 files into Rstudio and found that NOT all files have same number of rows
for (i in 1:length(file_list)){

  assign( substr(file_list[i], 1, nchar(file_list[i]) -4) ,

         read.delim(file_list[i], head=F))
}

#the first file, GTEX_1117F, in the following format,  one column and 19482 rows
#4 is marker id, 25/48 is its marker value;
#  V1
#  4
# 25/48
# 201
# 2/2
# ...
# 648589
# None

#to make this one-column file into a two-column file as below
# so first column is marker id, second is corresponding marker values for the sample GTEX_1117F
#  VNTRid      GTEX_1117F
#   4               25/48
#   201            2/2
#    ...          ...
# 648589          None

for (i in 1:length(file_list)){
  temp <- read.delim(file_list[i], head=F)
  even <-seq(2, length(temp$V1),2)
  odd <-seq(1, length(temp$V1)-1, 2)
  output <-matrix(0, ncol=2, nrow=length(temp$V1)/2)
  colnames(output)<- c("VNTRid",substr(file_list[i], 1, nchar(file_list[i]) -4))
  for (j in 1:length(temp$V1)/2){
  output[j,1]<- as.character(temp$V1)[odd[j]]
  output[j,2]<- as.character(temp$V1)[even[j]]}
  assign(gsub("-","_", substr(file_list[i], 1, nchar(file_list[i])-4)), as.data.frame(output))
                             }

Yesterday, I intended to reshape the output file above from long to wide using VNTRid as key.
Since not all files have the same number of rows, after reshaping, those file would not bind correctly using rbind function.
One my way to work place this morning, I changed my intension; I will not reshape to wide format and actually like the long format I generated. I will read in a VNTR marker annotation file including VNTRid in first column and marker locations in human chromosomes in the second column, this annotation file should include all the VNTR markers.  I know the VNTRid in the annotation file are same as the VNTRid in the 652 file I read in.

Do you know a good way to merge all those 652 files (with two columns) ?

Thank you,

Ding


#merge all 652 files into one file with VNTRid as first column, 2nd to 653th column are genotype with header
#as sample ID,  so

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Thursday, December 19, 2019 6:52 PM
To: Yuan Chun Ding
Cc: r-help at r-project.org
Subject: Re: [R] data reshape

________________________________
[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
________________________________
Did you even make an attempt to do this? -- or would you like us do all your work for you?

If you made an attempt, show us your code and errors.
If not, we usually expect you to try on your own first.
If you have no idea where to start, perhaps you need to spend some more time with tutorials to learn basic R functionality before proceeding.

Bert

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 19, 2019 at 6:01 PM Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>> wrote:
Hi R users,

I have a folder (called genotype) with 652 files; the file names are  GTEX-1A3MV.out, GTEX-1A3MX.out, GTEX-1B8SF.out, etc; in each file,  only one column of data without a header as below
201
2/2
238
3/4
245
1/2
.....
983255
3/3
983766
None


A total of 20528 rows;

I need to read all those 652 files in the genotype folder and then reshape the one column in each file as:
SampleID             201        238        245        ....   983255         983766
GTEX-1A3MV     2/2         3/4        1/2                         3/3         None

There are 10264 data columns plus the sample ID column, so 10265 columns in total after data reshaping.

After reading those 652 file and reshape the one column in each file, I will stack them by the rbind function, then I have a file with a dimension of 653 row, 10265 column.


Thank you,

Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
 eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!8ZMVp6KEM5teZqzisPd2_VC4UWgOKsPv57IKfSREDz7-G68yAohVXLf7Sf4L$>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!8ZMVp6KEM5teZqzisPd2_VC4UWgOKsPv57IKfSREDz7-G68yAohVXNnRAp_Y$>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From t@ub|@ @end|ng |rom |mgprec|@|on@com  Fri Dec 20 18:16:00 2019
From: t@ub|@ @end|ng |rom |mgprec|@|on@com (Thomas Subia)
Date: Fri, 20 Dec 2019 17:16:00 +0000
Subject: [R] Readxl Question
Message-ID: <CH2PR17MB374905BB2FB3F94DCB14E99AB82D0@CH2PR17MB3749.namprd17.prod.outlook.com>

Colleagues,

I am using readxl to extract a serial number and its associated data using the following code.

library(readxl)
files <- list.files(pattern="*.xls", full.names = FALSE)
serials <- lapply(files, read_excel, sheet="Flow Data", range=("c6"))
flow.datum <- lapply(files, read_excel, sheet="Flow Data", range=("c22:c70"))
dates <- lapply(files, read_excel, sheet="Flow Data", range=("h14"))

Here each serial and date is associated with 49 data points in flow.datum.

Now I write the serials, flow data and dates into a text file using:

datesdf <- as.data.frame(dates)
mydates <- list(datesdf)
write.table(mydates,"dates.txt",sep="\t")

serialdf <- as.data.frame(serials)
myserials <- list(serialdf)
write.table(myserials,"serials.txt",sep="\t")

flowdf <-as.data.frame(flow.datum)
myflow <- list(flowdf)
write.table(myflow,"myflow.txt",sep=",")

The problem with the dates.txt and the serials.txt is that they need to associated with its 49 corresponding values in myflow.txt.

The objective is to create a text file having this format:

Serial	Date	Flow

I'm not sure how to do this. Any suggestions would be appreciated.

Thomas Subia 
Statistician / Senior Quality Engineer
ASQ CQE

IMG Companies?
225 Mountain Vista Parkway
Livermore, CA 94551
T.?(925) 273-1106
F.?(925) 273-1111
E. tsubia at imgprecision.com


Precision Manufacturing for Emerging Technologies
imgprecision.com?

The contents of this message, together with any attachments, are intended only for the use of the individual or entity to which they are addressed and may contain information that is legally privileged, confidential and exempt from disclosure. If you are not the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this message, or any attachment, is strictly prohibited. If you have received this message in error, please notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and delete this message, along with any attachments, from your computer. Thank you.


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Dec 20 18:17:58 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 20 Dec 2019 12:17:58 -0500
Subject: [R] Using older version of R
In-Reply-To: <d80c86b7-8a90-d28b-6eef-b7b4c18a1070@ntu.edu.tw>
References: <d80c86b7-8a90-d28b-6eef-b7b4c18a1070@ntu.edu.tw>
Message-ID: <1e197bf4-c127-847f-743e-fe9026327039@gmail.com>

On 20/12/2019 11:24 a.m., Steven Yen wrote:
> I had to use an older version of R (as old as R3.0.3) for a reason. I
> myself have no problem installing a package built under a newer version,
> but my student (who also installed R3.0.3) could not install the package
> (newer version). Had an error message saying package xxxxx is not
> available under R3.0.3. Is there a get-arround----to be able to install
> while running an older R version? (Don't ask me why I run an older R. An
> essential package I need works well only in R3.0.3). Thank you all.

CRAN doesn't make binaries of packages available for ancient versions, 
so you'll need to build each package yourself.  That's easy for packages 
without compiled code (C, Fortran, C++), but harder with it.

If you are using Windows, you will need to install Rtools; that version 
of R will need an older version of ?t (I think 3.0 or 3.1 should work). 
If you are on some other platform, it's possible you may need an older 
version of the compilers for that platform.

The other issue is that many packages depend on recent features of R, 
but don't state the dependency (because the author didn't notice it). 
This means you may need to go to the CRAN archives for older versions of 
some packages.  One approach is to use Microsoft's daily CRAN snapshots 
and get everything that was current in the past, but even they don't go 
back to March 2014 when 3.0.3 was current.

Duncan Murdoch


From bgunter@4567 @end|ng |rom gm@||@com  Fri Dec 20 18:37:39 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 20 Dec 2019 09:37:39 -0800
Subject: [R] data reshape
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113B50A7@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113B4F9E@PPWEXCH2KX14.coh.org>
 <CAGxFJbRNuHj29Yb+JZWQZDCj75nt2nteG7X1fVQCi4mMHrJcxA@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6113B50A7@PPWEXCH2KX14.coh.org>
Message-ID: <CAGxFJbSmNKhMO07rpSAkW2ZAZB0Zo0P0GDowaVPfB8vV4weyCA@mail.gmail.com>

?merge ## note the all.x option
Example:
> a <- data.frame(x = 1:3, y1 = 11:13)
> b <- data.frame(x = c(1,3), y2 = 21:22)

> merge(a,b, all.x = TRUE)
  x y1 y2
1 1 11 21
2 2 12 NA
3 3 13 22


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Dec 20, 2019 at 9:00 AM Yuan Chun Ding <ycding at coh.org> wrote:

> Hi Bert,
>
>
>
> Sorry that I was in a hurry  going home yesterday afternoon and just
> posted my question and hoped to get some advice.
>
>
>
> Here is what I got yesterday before going home.
>
> ---------------------------------------------------------------
>
> setwd("C:/Awork/VNTR/GETXdata/GTEx_genotypes")
>
>
>
> file_list <- list.files(pattern="*.out")
>
>
>
> #to read all 652 files into Rstudio and found that NOT all files have same
> number of rows
>
> for (i in 1:length(file_list)){
>
>
>
>   assign( substr(file_list[i], 1, nchar(file_list[i]) -4) ,
>
>
>
>          read.delim(file_list[i], head=F))
>
> }
>
>
>
> #the first file, GTEX_1117F, in the following format,  one column and
> 19482 rows
>
> #4 is marker id, 25/48 is its marker value;
>
> #  V1
>
> #  4
>
> # 25/48
>
> # 201
>
> # 2/2
>
> # ...
>
> # 648589
>
> # None
>
>
>
> #to make this one-column file into a two-column file as below
>
> # so first column is marker id, second is corresponding marker values for
> the sample GTEX_1117F
>
> #  VNTRid      GTEX_1117F
>
> #   4               25/48
>
> #   201            2/2
>
> #    ...          ...
>
> # 648589          None
>
>
>
> for (i in 1:length(file_list)){
>
>   temp <- read.delim(file_list[i], head=F)
>
>   even <-seq(2, length(temp$V1),2)
>
>   odd <-seq(1, length(temp$V1)-1, 2)
>
>   output <-matrix(0, ncol=2, nrow=length(temp$V1)/2)
>
>   colnames(output)<- c("VNTRid",substr(file_list[i], 1,
> nchar(file_list[i]) -4))
>
>   for (j in 1:length(temp$V1)/2){
>
>   output[j,1]<- as.character(temp$V1)[odd[j]]
>
>   output[j,2]<- as.character(temp$V1)[even[j]]}
>
>   assign(gsub("-","_", substr(file_list[i], 1, nchar(file_list[i])-4)),
> as.data.frame(output))
>
>                              }
>
>
>
> Yesterday, I intended to reshape the output file above from long to wide
> using VNTRid as key.
>
> Since not all files have the same number of rows, after reshaping, those
> file would not bind correctly using rbind function.
>
> One my way to work place this morning, I changed my intension; I will not
> reshape to wide format and actually like the long format I generated. I
> will read in a VNTR marker annotation file including VNTRid in first column
> and marker locations in human chromosomes in the second column, this
> annotation file should include all the VNTR markers.  I know the VNTRid in
> the annotation file are same as the VNTRid in the 652 file I read in.
>
>
>
> Do you know a good way to merge all those 652 files (with two columns) ?
>
>
>
> Thank you,
>
>
>
> Ding
>
>
>
>
>
> #merge all 652 files into one file with VNTRid as first column, 2nd to
> 653th column are genotype with header
>
> #as sample ID,  so
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Thursday, December 19, 2019 6:52 PM
> *To:* Yuan Chun Ding
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] data reshape
>
>
> ------------------------------
>
> [Attention: This email came from an external source. Do not open
> attachments or click on links from unknown senders or unexpected emails.]
> ------------------------------
>
> Did you even make an attempt to do this? -- or would you like us do all
> your work for you?
>
>
>
> If you made an attempt, show us your code and errors.
>
> If not, we usually expect you to try on your own first.
>
> If you have no idea where to start, perhaps you need to spend some more
> time with tutorials to learn basic R functionality before proceeding.
>
>
>
> Bert
>
>
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
>
>
> On Thu, Dec 19, 2019 at 6:01 PM Yuan Chun Ding <ycding at coh.org> wrote:
>
> Hi R users,
>
> I have a folder (called genotype) with 652 files; the file names are
> GTEX-1A3MV.out, GTEX-1A3MX.out, GTEX-1B8SF.out, etc; in each file,  only
> one column of data without a header as below
> 201
> 2/2
> 238
> 3/4
> 245
> 1/2
> .....
> 983255
> 3/3
> 983766
> None
>
>
> A total of 20528 rows;
>
> I need to read all those 652 files in the genotype folder and then reshape
> the one column in each file as:
> SampleID             201        238        245        ....   983255
>  983766
> GTEX-1A3MV     2/2         3/4        1/2                         3/3
>    None
>
> There are 10264 data columns plus the sample ID column, so 10265 columns
> in total after data reshaping.
>
> After reading those 652 file and reshape the one column in each file, I
> will stack them by the rbind function, then I have a file with a dimension
> of 653 row, 10265 column.
>
>
> Thank you,
>
> Ding
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to rec
>  eive further communications via e-mail, please reply to this message and
> inform the sender that you do not wish to receive further e-mail from the
> sender. (LCP301)
> ------------------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!8ZMVp6KEM5teZqzisPd2_VC4UWgOKsPv57IKfSREDz7-G68yAohVXLf7Sf4L$>
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!8ZMVp6KEM5teZqzisPd2_VC4UWgOKsPv57IKfSREDz7-G68yAohVXNnRAp_Y$>
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Dec 20 20:47:01 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 20 Dec 2019 11:47:01 -0800
Subject: [R] data reshape
In-Reply-To: <CAGxFJbSmNKhMO07rpSAkW2ZAZB0Zo0P0GDowaVPfB8vV4weyCA@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6113B4F9E@PPWEXCH2KX14.coh.org>
 <CAGxFJbRNuHj29Yb+JZWQZDCj75nt2nteG7X1fVQCi4mMHrJcxA@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6113B50A7@PPWEXCH2KX14.coh.org>
 <CAGxFJbSmNKhMO07rpSAkW2ZAZB0Zo0P0GDowaVPfB8vV4weyCA@mail.gmail.com>
Message-ID: <CAGxFJbQ4EQXY9dJmgw0hVSKPADC-TVvkRLM4tneeVqieY1z+VQ@mail.gmail.com>

It is perhaps worth noting that (assuming I understand correctly) this can
easily be done in one go without any overt looping as a nice application of
Reduce() after all your files are read into your global environment as a
nice application of Reduce().

Example:

> a.out <- data.frame(x = 1:3, y1 = 11:13)
> b.out <- data.frame(x = c(1,3), y2 = 21:22)
> d.out <- data.frame(x = c(2:3), y3 = c(.5,.6))

> nm <- ls(pat = ".*out$")
> f <- function(dat, y) merge(dat, get(y), all = TRUE)
> allofthem <- Reduce(f, nm[-1], init = get(nm[1]))
> allofthem
  x y1 y2  y3
1 1 11 21  NA
2 2 12 NA 0.5
3 3 13 22 0.6

## note the change to "all = TRUE" in the merge() call

Cheers,
Bert



On Fri, Dec 20, 2019 at 9:37 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ?merge ## note the all.x option
> Example:
> > a <- data.frame(x = 1:3, y1 = 11:13)
> > b <- data.frame(x = c(1,3), y2 = 21:22)
>
> > merge(a,b, all.x = TRUE)
>   x y1 y2
> 1 1 11 21
> 2 2 12 NA
> 3 3 13 22
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Dec 20, 2019 at 9:00 AM Yuan Chun Ding <ycding at coh.org> wrote:
>
>> Hi Bert,
>>
>>
>>
>> Sorry that I was in a hurry  going home yesterday afternoon and just
>> posted my question and hoped to get some advice.
>>
>>
>>
>> Here is what I got yesterday before going home.
>>
>> ---------------------------------------------------------------
>>
>> setwd("C:/Awork/VNTR/GETXdata/GTEx_genotypes")
>>
>>
>>
>> file_list <- list.files(pattern="*.out")
>>
>>
>>
>> #to read all 652 files into Rstudio and found that NOT all files have
>> same number of rows
>>
>> for (i in 1:length(file_list)){
>>
>>
>>
>>   assign( substr(file_list[i], 1, nchar(file_list[i]) -4) ,
>>
>>
>>
>>          read.delim(file_list[i], head=F))
>>
>> }
>>
>>
>>
>> #the first file, GTEX_1117F, in the following format,  one column and
>> 19482 rows
>>
>> #4 is marker id, 25/48 is its marker value;
>>
>> #  V1
>>
>> #  4
>>
>> # 25/48
>>
>> # 201
>>
>> # 2/2
>>
>> # ...
>>
>> # 648589
>>
>> # None
>>
>>
>>
>> #to make this one-column file into a two-column file as below
>>
>> # so first column is marker id, second is corresponding marker values for
>> the sample GTEX_1117F
>>
>> #  VNTRid      GTEX_1117F
>>
>> #   4               25/48
>>
>> #   201            2/2
>>
>> #    ...          ...
>>
>> # 648589          None
>>
>>
>>
>> for (i in 1:length(file_list)){
>>
>>   temp <- read.delim(file_list[i], head=F)
>>
>>   even <-seq(2, length(temp$V1),2)
>>
>>   odd <-seq(1, length(temp$V1)-1, 2)
>>
>>   output <-matrix(0, ncol=2, nrow=length(temp$V1)/2)
>>
>>   colnames(output)<- c("VNTRid",substr(file_list[i], 1,
>> nchar(file_list[i]) -4))
>>
>>   for (j in 1:length(temp$V1)/2){
>>
>>   output[j,1]<- as.character(temp$V1)[odd[j]]
>>
>>   output[j,2]<- as.character(temp$V1)[even[j]]}
>>
>>   assign(gsub("-","_", substr(file_list[i], 1, nchar(file_list[i])-4)),
>> as.data.frame(output))
>>
>>                              }
>>
>>
>>
>> Yesterday, I intended to reshape the output file above from long to wide
>> using VNTRid as key.
>>
>> Since not all files have the same number of rows, after reshaping, those
>> file would not bind correctly using rbind function.
>>
>> One my way to work place this morning, I changed my intension; I will not
>> reshape to wide format and actually like the long format I generated. I
>> will read in a VNTR marker annotation file including VNTRid in first column
>> and marker locations in human chromosomes in the second column, this
>> annotation file should include all the VNTR markers.  I know the VNTRid in
>> the annotation file are same as the VNTRid in the 652 file I read in.
>>
>>
>>
>> Do you know a good way to merge all those 652 files (with two columns) ?
>>
>>
>>
>> Thank you,
>>
>>
>>
>> Ding
>>
>>
>>
>>
>>
>> #merge all 652 files into one file with VNTRid as first column, 2nd to
>> 653th column are genotype with header
>>
>> #as sample ID,  so
>>
>>
>>
>> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> *Sent:* Thursday, December 19, 2019 6:52 PM
>> *To:* Yuan Chun Ding
>> *Cc:* r-help at r-project.org
>> *Subject:* Re: [R] data reshape
>>
>>
>> ------------------------------
>>
>> [Attention: This email came from an external source. Do not open
>> attachments or click on links from unknown senders or unexpected emails.]
>> ------------------------------
>>
>> Did you even make an attempt to do this? -- or would you like us do all
>> your work for you?
>>
>>
>>
>> If you made an attempt, show us your code and errors.
>>
>> If not, we usually expect you to try on your own first.
>>
>> If you have no idea where to start, perhaps you need to spend some more
>> time with tutorials to learn basic R functionality before proceeding.
>>
>>
>>
>> Bert
>>
>>
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>
>>
>>
>> On Thu, Dec 19, 2019 at 6:01 PM Yuan Chun Ding <ycding at coh.org> wrote:
>>
>> Hi R users,
>>
>> I have a folder (called genotype) with 652 files; the file names are
>> GTEX-1A3MV.out, GTEX-1A3MX.out, GTEX-1B8SF.out, etc; in each file,  only
>> one column of data without a header as below
>> 201
>> 2/2
>> 238
>> 3/4
>> 245
>> 1/2
>> .....
>> 983255
>> 3/3
>> 983766
>> None
>>
>>
>> A total of 20528 rows;
>>
>> I need to read all those 652 files in the genotype folder and then
>> reshape the one column in each file as:
>> SampleID             201        238        245        ....   983255
>>    983766
>> GTEX-1A3MV     2/2         3/4        1/2                         3/3
>>      None
>>
>> There are 10264 data columns plus the sample ID column, so 10265 columns
>> in total after data reshaping.
>>
>> After reading those 652 file and reshape the one column in each file, I
>> will stack them by the rbind function, then I have a file with a dimension
>> of 653 row, 10265 column.
>>
>>
>> Thank you,
>>
>> Ding
>>
>> ----------------------------------------------------------------------
>> ------------------------------------------------------------
>> -SECURITY/CONFIDENTIALITY WARNING-
>>
>> This message and any attachments are intended solely for the individual
>> or entity to which they are addressed. This communication may contain
>> information that is privileged, confidential, or exempt from disclosure
>> under applicable law (e.g., personal health information, research data,
>> financial information). Because this e-mail has been sent without
>> encryption, individuals other than the intended recipient may be able to
>> view the information, forward it to others or tamper with the information
>> without the knowledge or consent of the sender. If you are not the intended
>> recipient, or the employee or person responsible for delivering the message
>> to the intended recipient, any dissemination, distribution or copying of
>> the communication is strictly prohibited. If you received the communication
>> in error, please notify the sender immediately by replying to this message
>> and deleting the message and any accompanying files from your system. If,
>> due to the security risks, you do not wish to rec
>>  eive further communications via e-mail, please reply to this message and
>> inform the sender that you do not wish to receive further e-mail from the
>> sender. (LCP301)
>> ------------------------------------------------------------
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!8ZMVp6KEM5teZqzisPd2_VC4UWgOKsPv57IKfSREDz7-G68yAohVXLf7Sf4L$>
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!8ZMVp6KEM5teZqzisPd2_VC4UWgOKsPv57IKfSREDz7-G68yAohVXNnRAp_Y$>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From j@vedbtk111 @end|ng |rom gm@||@com  Fri Dec 20 20:53:10 2019
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Fri, 20 Dec 2019 20:53:10 +0100
Subject: [R] contrasts can be applied only to factors with 2 or more levels
Message-ID: <CAJhui+vPs6=uj1f_FKMFn12CBpXXFC4raWE-FoV6MHV=SLu5_A@mail.gmail.com>

I am using the folowing code and it give me the error message like

" contrasts can be applied only to factors with 2 or more levels".

What could be the problem

d=read.csv("Result.csv")
index <- createDataPartition(log10(d$Results), p = .70,list = FALSE)
tr <- d[index, ]
ts <- d[-index, ]
index_2 <- createFolds(log10(tr$Results), returnTrain = TRUE, list = TRUE)
ctrl <- trainControl(method = "cv", index = index_2)

set.seed(30218)

grid_search <- train(log10(Results) ~ ., data = tr,
                     method = "svmRadial",

                     tuneLength = 8,
                     metric = "MAE",
                     preProc = c("center", "scale", "zv"),
                     trControl = ctrl)

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Fri Dec 20 21:08:15 2019
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Fri, 20 Dec 2019 15:08:15 -0500
Subject: [R] 
 contrasts can be applied only to factors with 2 or more levels
In-Reply-To: <CAJhui+vPs6=uj1f_FKMFn12CBpXXFC4raWE-FoV6MHV=SLu5_A@mail.gmail.com>
References: <CAJhui+vPs6=uj1f_FKMFn12CBpXXFC4raWE-FoV6MHV=SLu5_A@mail.gmail.com>
Message-ID: <CAJc=yOHm6oTnRnXomYJjQQBBMQ5nejAwabnrYYOMxaJ0s5To1A@mail.gmail.com>

Seems self-explanatory. It sounds like one of your predictors has no
variability.

On Fri, Dec 20, 2019 at 3:01 PM javed khan <javedbtk111 at gmail.com> wrote:
>
> I am using the folowing code and it give me the error message like
>
> " contrasts can be applied only to factors with 2 or more levels".
>
> What could be the problem
>
> d=read.csv("Result.csv")
> index <- createDataPartition(log10(d$Results), p = .70,list = FALSE)
> tr <- d[index, ]
> ts <- d[-index, ]
> index_2 <- createFolds(log10(tr$Results), returnTrain = TRUE, list = TRUE)
> ctrl <- trainControl(method = "cv", index = index_2)
>
> set.seed(30218)
>
> grid_search <- train(log10(Results) ~ ., data = tr,
>                      method = "svmRadial",
>
>                      tuneLength = 8,
>                      metric = "MAE",
>                      preProc = c("center", "scale", "zv"),
>                      trControl = ctrl)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ycd|ng @end|ng |rom coh@org  Fri Dec 20 22:00:54 2019
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Fri, 20 Dec 2019 21:00:54 +0000
Subject: [R] data reshape
In-Reply-To: <CAGxFJbQ4EQXY9dJmgw0hVSKPADC-TVvkRLM4tneeVqieY1z+VQ@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6113B4F9E@PPWEXCH2KX14.coh.org>
 <CAGxFJbRNuHj29Yb+JZWQZDCj75nt2nteG7X1fVQCi4mMHrJcxA@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6113B50A7@PPWEXCH2KX14.coh.org>
 <CAGxFJbSmNKhMO07rpSAkW2ZAZB0Zo0P0GDowaVPfB8vV4weyCA@mail.gmail.com>
 <CAGxFJbQ4EQXY9dJmgw0hVSKPADC-TVvkRLM4tneeVqieY1z+VQ@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6113B51F8@PPWEXCH2KX14.coh.org>

Hi Bert,

Thank you for the elegant code example.  I achieved my goal using lapply function and do.call function together.  Reduce function is nicer one and I am looking into it.

Ding

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Friday, December 20, 2019 11:47 AM
To: Yuan Chun Ding
Cc: r-help at r-project.org
Subject: Re: [R] data reshape

________________________________
[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
________________________________
It is perhaps worth noting that (assuming I understand correctly) this can easily be done in one go without any overt looping as a nice application of Reduce() after all your files are read into your global environment as a nice application of Reduce().

Example:

> a.out <- data.frame(x = 1:3, y1 = 11:13)
> b.out <- data.frame(x = c(1,3), y2 = 21:22)
> d.out <- data.frame(x = c(2:3), y3 = c(.5,.6))

> nm <- ls(pat = ".*out$")
> f <- function(dat, y) merge(dat, get(y), all = TRUE)
> allofthem <- Reduce(f, nm[-1], init = get(nm[1]))
> allofthem
  x y1 y2  y3
1 1 11 21  NA
2 2 12 NA 0.5
3 3 13 22 0.6

## note the change to "all = TRUE" in the merge() call

Cheers,
Bert



On Fri, Dec 20, 2019 at 9:37 AM Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>> wrote:
?merge ## note the all.x option
Example:
> a <- data.frame(x = 1:3, y1 = 11:13)
> b <- data.frame(x = c(1,3), y2 = 21:22)

> merge(a,b, all.x = TRUE)
  x y1 y2
1 1 11 21
2 2 12 NA
3 3 13 22


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Dec 20, 2019 at 9:00 AM Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>> wrote:
Hi Bert,

Sorry that I was in a hurry  going home yesterday afternoon and just posted my question and hoped to get some advice.

Here is what I got yesterday before going home.
---------------------------------------------------------------
setwd("C:/Awork/VNTR/GETXdata/GTEx_genotypes")

file_list <- list.files(pattern="*.out")

#to read all 652 files into Rstudio and found that NOT all files have same number of rows
for (i in 1:length(file_list)){

  assign( substr(file_list[i], 1, nchar(file_list[i]) -4) ,

         read.delim(file_list[i], head=F))
}

#the first file, GTEX_1117F, in the following format,  one column and 19482 rows
#4 is marker id, 25/48 is its marker value;
#  V1
#  4
# 25/48
# 201
# 2/2
# ...
# 648589
# None

#to make this one-column file into a two-column file as below
# so first column is marker id, second is corresponding marker values for the sample GTEX_1117F
#  VNTRid      GTEX_1117F
#   4               25/48
#   201            2/2
#    ...          ...
# 648589          None

for (i in 1:length(file_list)){
  temp <- read.delim(file_list[i], head=F)
  even <-seq(2, length(temp$V1),2)
  odd <-seq(1, length(temp$V1)-1, 2)
  output <-matrix(0, ncol=2, nrow=length(temp$V1)/2)
  colnames(output)<- c("VNTRid",substr(file_list[i], 1, nchar(file_list[i]) -4))
  for (j in 1:length(temp$V1)/2){
  output[j,1]<- as.character(temp$V1)[odd[j]]
  output[j,2]<- as.character(temp$V1)[even[j]]}
  assign(gsub("-","_", substr(file_list[i], 1, nchar(file_list[i])-4)), as.data.frame(output))
                             }

Yesterday, I intended to reshape the output file above from long to wide using VNTRid as key.
Since not all files have the same number of rows, after reshaping, those file would not bind correctly using rbind function.
One my way to work place this morning, I changed my intension; I will not reshape to wide format and actually like the long format I generated. I will read in a VNTR marker annotation file including VNTRid in first column and marker locations in human chromosomes in the second column, this annotation file should include all the VNTR markers.  I know the VNTRid in the annotation file are same as the VNTRid in the 652 file I read in.

Do you know a good way to merge all those 652 files (with two columns) ?

Thank you,

Ding


#merge all 652 files into one file with VNTRid as first column, 2nd to 653th column are genotype with header
#as sample ID,  so

From: Bert Gunter [mailto:bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>]
Sent: Thursday, December 19, 2019 6:52 PM
To: Yuan Chun Ding
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] data reshape

________________________________
[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
________________________________
Did you even make an attempt to do this? -- or would you like us do all your work for you?

If you made an attempt, show us your code and errors.
If not, we usually expect you to try on your own first.
If you have no idea where to start, perhaps you need to spend some more time with tutorials to learn basic R functionality before proceeding.

Bert

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 19, 2019 at 6:01 PM Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>> wrote:
Hi R users,

I have a folder (called genotype) with 652 files; the file names are  GTEX-1A3MV.out, GTEX-1A3MX.out, GTEX-1B8SF.out, etc; in each file,  only one column of data without a header as below
201
2/2
238
3/4
245
1/2
.....
983255
3/3
983766
None


A total of 20528 rows;

I need to read all those 652 files in the genotype folder and then reshape the one column in each file as:
SampleID             201        238        245        ....   983255         983766
GTEX-1A3MV     2/2         3/4        1/2                         3/3         None

There are 10264 data columns plus the sample ID column, so 10265 columns in total after data reshaping.

After reading those 652 file and reshape the one column in each file, I will stack them by the rbind function, then I have a file with a dimension of 653 row, 10265 column.


Thank you,

Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
 eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!8ZMVp6KEM5teZqzisPd2_VC4UWgOKsPv57IKfSREDz7-G68yAohVXLf7Sf4L$>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!8ZMVp6KEM5teZqzisPd2_VC4UWgOKsPv57IKfSREDz7-G68yAohVXNnRAp_Y$>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Dec 20 22:04:29 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 21 Dec 2019 08:04:29 +1100
Subject: [R] 
 How to create a new data.frame based on calculation of subsets
 of an existing data.frame
In-Reply-To: <DB8PR01MB567575DA16F823A401DF94A2C92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
References: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fUbFmch8gORE9huB+1Ts50uNU1T14obR4e7V401eaNVfg@mail.gmail.com>
 <DB8PR01MB56752F156F6C4DBEC2AB0C02C9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fWnLBOPNxc1_AJVndjd0x3NrGD6UTKiK9JugZawHjwdbg@mail.gmail.com>
 <CA+8X3fURQd+nvf=JER5kf=N7MfwUKNrzinvtiYHAa_w2XRN37w@mail.gmail.com>
 <DB8PR01MB56759F3B055EE157D6AC764CC92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fX7oDs93643w31n1cS5ZwmAT0Ov0n5593+Be4hQGQMOnw@mail.gmail.com>
 <DB8PR01MB567575DA16F823A401DF94A2C92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fUmu_mtaM5yP8iu3oPC2tNUfg9QHKRg3vrRzHu0WL10rw@mail.gmail.com>

Hi Ioanna,
We're getting somewhere, but there are four unique combinations  of
Taxonomy and IM.type:

ER+ETR_H1,PGA
ER+ETR_H2,PGA
ER+ETR_H1,Sa
ER+ETR_H2,Sa

Perhaps you mean that ER+ETR_H1 only occurs with PGA and ER+ETR_H2
only occurs with Sa. I handled that by checking that there were any
rows that corresponded to the condition requested.

Also you want a matrix for each row containing Taxonomy and IM.type in
the output. When I run what I think you are asking, I only get a two
element list, each a vector of values. Maybe this is what you want,
and it could be coerced into matrix format:

D<- data.frame(Ref.No = c(1622, 1623, 1624, 1625, 1626, 1627, 1628,
1629),  Region = rep(c('South America'), times = 8),
 IM.type = c('PGA', 'PGA', 'PGA', 'PGA', 'Sa', 'Sa', 'Sa', 'Sa'),
 Damage.state = c('DS1', 'DS2', 'DS3', 'DS4','DS1', 'DS2', 'DS3', 'DS4'),
 Taxonomy = c('ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H2','ER+ETR_H2','ER+ETR_H2','ER+ETR_H2'),
 Prob.of.exceedance_1 = c(0,0,0,0,0,0,0,0),
 Prob.of.exceedance_2 = c(0,0,0,0,0,0,0,0),
 Prob.of.exceedance_3 =
  c(0.26,0.001,0.00019,0.000000573,0.04,0.00017,0.000215,0.000472),
 Prob.of.exceedance_4 =
  c(0.72,0.03,0.008,0.000061,0.475,0.0007,0.00435,0.000405),
 stringsAsFactors=FALSE)

# names of the variables used in the calculations
calc_vars<-paste("Prob.of.exceedance",1:4,sep="_")
# get the rows for the four damage states
DS1_rows <-D$Damage.state == "DS1"
DS2_rows <-D$Damage.state == "DS2"
DS3_rows <-D$Damage.state == "DS3"
DS4_rows <-D$Damage.state == "DS4"
# create an empty list
VC<-list()
# set an index variable for VC
VCindex<-1
# step through all possible values of IM.type and Taxonomy
for(IM in unique(D$IM.type)) {
 for(Tax in unique(D$Taxonomy)) {
  # get a logical vector of the rows to be used in this calculation
  calc_rows <- D$IM.type == IM & D$Taxonomy == Tax
  cat(IM,Tax,calc_rows,"\n")
  # check that there are any such rows in the data frame
  if(sum(calc_rows)) {
   # if so, fill in the four values for these rows
   VC[[VCindex]] <- 0.0 * (1- D[calc_rows & DS1_rows,calc_vars]) +
    0.02* (D[calc_rows & DS1_rows,calc_vars] -
               D[calc_rows & DS2_rows,calc_vars]) +
    0.10* (D[calc_rows & DS2_rows,calc_vars] -
                                   D[calc_rows & DS3_rows,calc_vars]) +
    0.43 * (D[calc_rows & DS3_rows,calc_vars] -
                                   D[calc_rows & DS4_rows,calc_vars]) +
    1.0*   D[calc_rows & DS4_rows,calc_vars]
   # increment the index
   VCindex<-VCindex+1
  }
 }
}

I think we'll get there.

Jim


On Sat, Dec 21, 2019 at 12:45 AM Ioannou, Ioanna
<ioanna.ioannou at ucl.ac.uk> wrote:
>
> Hello Jim,
>
> I made some changes to the code essentially I substitute each 4 lines DS1-4 with one. I estimate VC which in an ideal world should be a matrix with 4 columns one for every exceedance_probability_1-4 and 2 rowsfor each unique combination of taxonomy and IM.Type. Coukd you please check the code I sent last and based on that give your solution?


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Fri Dec 20 22:20:34 2019
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Fri, 20 Dec 2019 16:20:34 -0500
Subject: [R] 
 contrasts can be applied only to factors with 2 or more levels
In-Reply-To: <CAJhui+sWdDHeU23do+hda8UAXtZH09C0S1jLuxfFiSyR9niePw@mail.gmail.com>
References: <CAJhui+vPs6=uj1f_FKMFn12CBpXXFC4raWE-FoV6MHV=SLu5_A@mail.gmail.com>
 <CAJc=yOHm6oTnRnXomYJjQQBBMQ5nejAwabnrYYOMxaJ0s5To1A@mail.gmail.com>
 <CAJhui+sWdDHeU23do+hda8UAXtZH09C0S1jLuxfFiSyR9niePw@mail.gmail.com>
Message-ID: <CAJc=yOHxK3X6MbHJAgNtYSW+td5VSS_p9a+o+WEJ_RySQSEqLw@mail.gmail.com>

As the Posting Guide directs, please make all replies to the list.

Basically, you need to inspect your data. Using "~ ." adds everything
in the dataframe that's not elsewhere in the function as predictors.
Check the descriptive statistics on every one (variance/standard
deviation for numeric data, table for string/factor).

On Fri, Dec 20, 2019 at 3:32 PM javed khan <javedbtk111 at gmail.com> wrote:
>
> Hi Patrick
>
> I have no idea about this type of error. Is it a categorical predictor? How to find variability?
>
> Thanks
>
> On Fri, Dec 20, 2019 at 9:08 PM Patrick (Malone Quantitative) <malone at malonequantitative.com> wrote:
>>
>> Seems self-explanatory. It sounds like one of your predictors has no
>> variability.
>>
>> On Fri, Dec 20, 2019 at 3:01 PM javed khan <javedbtk111 at gmail.com> wrote:
>> >
>> > I am using the folowing code and it give me the error message like
>> >
>> > " contrasts can be applied only to factors with 2 or more levels".
>> >
>> > What could be the problem
>> >
>> > d=read.csv("Result.csv")
>> > index <- createDataPartition(log10(d$Results), p = .70,list = FALSE)
>> > tr <- d[index, ]
>> > ts <- d[-index, ]
>> > index_2 <- createFolds(log10(tr$Results), returnTrain = TRUE, list = TRUE)
>> > ctrl <- trainControl(method = "cv", index = index_2)
>> >
>> > set.seed(30218)
>> >
>> > grid_search <- train(log10(Results) ~ ., data = tr,
>> >                      method = "svmRadial",
>> >
>> >                      tuneLength = 8,
>> >                      metric = "MAE",
>> >                      preProc = c("center", "scale", "zv"),
>> >                      trControl = ctrl)
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From wdun|@p @end|ng |rom t|bco@com  Fri Dec 20 22:56:28 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 20 Dec 2019 13:56:28 -0800
Subject: [R] 
 contrasts can be applied only to factors with 2 or more levels
In-Reply-To: <CAJc=yOHxK3X6MbHJAgNtYSW+td5VSS_p9a+o+WEJ_RySQSEqLw@mail.gmail.com>
References: <CAJhui+vPs6=uj1f_FKMFn12CBpXXFC4raWE-FoV6MHV=SLu5_A@mail.gmail.com>
 <CAJc=yOHm6oTnRnXomYJjQQBBMQ5nejAwabnrYYOMxaJ0s5To1A@mail.gmail.com>
 <CAJhui+sWdDHeU23do+hda8UAXtZH09C0S1jLuxfFiSyR9niePw@mail.gmail.com>
 <CAJc=yOHxK3X6MbHJAgNtYSW+td5VSS_p9a+o+WEJ_RySQSEqLw@mail.gmail.com>
Message-ID: <CAF8bMcYzMTm05NgYXhGTE1r9a2n7ceOaWYGG1zOmoE=Xuwj-nw@mail.gmail.com>

You can also get this error from caret::grid_search() if you have 2-valued
string variables with one value pretty rare, so that a sample may include
just one of the values.  You can get this if you've set
options(stringsAsFactors=FALSE) or call read.table() with
stringsAsFactors=FALSE.  E.g., in R-3.6.2:

> set.seed(1)
> d <- data.frame(Results=1:1000, x1=ifelse((1:1000)==1, "one", "not one"),
x2=ifelse((1:1000)==2,"two", "not two"), stringsAsFactors=FALSE)
> index <- createDataPartition(log10(d$Results), p = 0.25, list = FALSE)
> tr <- d[index, ]
> ts <- d[-index, ]
> index_2 <- createFolds(log10(tr$Results), returnTrain = TRUE, list = TRUE)
> ctrl <- trainControl(method = "cv", index = index_2)
> grid_search <- train(log10(Results) ~ ., data = tr, method="lm",
trControl=ctrl)
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels

Converting all character columns to factor columns can help.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Dec 20, 2019 at 1:21 PM Patrick (Malone Quantitative) <
malone at malonequantitative.com> wrote:

> As the Posting Guide directs, please make all replies to the list.
>
> Basically, you need to inspect your data. Using "~ ." adds everything
> in the dataframe that's not elsewhere in the function as predictors.
> Check the descriptive statistics on every one (variance/standard
> deviation for numeric data, table for string/factor).
>
> On Fri, Dec 20, 2019 at 3:32 PM javed khan <javedbtk111 at gmail.com> wrote:
> >
> > Hi Patrick
> >
> > I have no idea about this type of error. Is it a categorical predictor?
> How to find variability?
> >
> > Thanks
> >
> > On Fri, Dec 20, 2019 at 9:08 PM Patrick (Malone Quantitative) <
> malone at malonequantitative.com> wrote:
> >>
> >> Seems self-explanatory. It sounds like one of your predictors has no
> >> variability.
> >>
> >> On Fri, Dec 20, 2019 at 3:01 PM javed khan <javedbtk111 at gmail.com>
> wrote:
> >> >
> >> > I am using the folowing code and it give me the error message like
> >> >
> >> > " contrasts can be applied only to factors with 2 or more levels".
> >> >
> >> > What could be the problem
> >> >
> >> > d=read.csv("Result.csv")
> >> > index <- createDataPartition(log10(d$Results), p = .70,list = FALSE)
> >> > tr <- d[index, ]
> >> > ts <- d[-index, ]
> >> > index_2 <- createFolds(log10(tr$Results), returnTrain = TRUE, list =
> TRUE)
> >> > ctrl <- trainControl(method = "cv", index = index_2)
> >> >
> >> > set.seed(30218)
> >> >
> >> > grid_search <- train(log10(Results) ~ ., data = tr,
> >> >                      method = "svmRadial",
> >> >
> >> >                      tuneLength = 8,
> >> >                      metric = "MAE",
> >> >                      preProc = c("center", "scale", "zv"),
> >> >                      trControl = ctrl)
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Dec 20 23:07:59 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 21 Dec 2019 09:07:59 +1100
Subject: [R] 
 How to create a new data.frame based on calculation of subsets
 of an existing data.frame
In-Reply-To: <DB8PR01MB5675402A85082FA26A56DF20C92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
References: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fUbFmch8gORE9huB+1Ts50uNU1T14obR4e7V401eaNVfg@mail.gmail.com>
 <DB8PR01MB56752F156F6C4DBEC2AB0C02C9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fWnLBOPNxc1_AJVndjd0x3NrGD6UTKiK9JugZawHjwdbg@mail.gmail.com>
 <CA+8X3fURQd+nvf=JER5kf=N7MfwUKNrzinvtiYHAa_w2XRN37w@mail.gmail.com>
 <DB8PR01MB56759F3B055EE157D6AC764CC92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fX7oDs93643w31n1cS5ZwmAT0Ov0n5593+Be4hQGQMOnw@mail.gmail.com>
 <DB8PR01MB567575DA16F823A401DF94A2C92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fUmu_mtaM5yP8iu3oPC2tNUfg9QHKRg3vrRzHu0WL10rw@mail.gmail.com>
 <DB8PR01MB5675402A85082FA26A56DF20C92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fVRoG-Jjc_OnRg4V_=qOKuAthKBdy8WXmk5f354RAjJxA@mail.gmail.com>

I'm probably misunderstanding what you want. I get this from the code I sent:

 VC
[[1]]
 Prob.of.exceedance_1 Prob.of.exceedance_2 Prob.of.exceedance_3
1                    0                    0          0.005343027
 Prob.of.exceedance_4
1           0.01947477

[[2]]
 Prob.of.exceedance_1 Prob.of.exceedance_2 Prob.of.exceedance_3
5                    0                    0           0.00115359
 Prob.of.exceedance_4
5           0.01122235

Two list elements with four values. Perhaps you want a matrix for each
block of Taxonomy and IM.type that has a row for each element of the
block? This often happens with a remotely specified problem.

Jim

On Sat, Dec 21, 2019 at 8:33 AM Ioannou, Ioanna
<ioanna.ioannou at ucl.ac.uk> wrote:
>
> Hello Jim ,
>
> Thank you ever so much for your help. I was truly stuck!
>
> This looks much better and yes I can turn them into a matrix no problem. Indeed I need only the results for ER+ETR_H1,PGA and ER+ETR_H2,Sa. One minor point as it is the VC has 4 values for three cases instead of the aforementioned two. In fact, the third is identical to the first. Could you please optimize?
>


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Fri Dec 20 23:31:34 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Fri, 20 Dec 2019 23:31:34 +0100
Subject: [R] script execution stops and give the error
Message-ID: <CA+nrPntt_6vhwLKUf40MW9cJiS-LxDf3Cj4sEPXWPsSgSLpR8Q@mail.gmail.com>

  When I run my code, I get the following error and suddenly the execution
of the script stops. Where in my data is the problem?

Something is wrong; all the MAE metric values are missing:
      RMSE        Rsquared        MAE
 Min.   : NA   Min.   : NA   Min.   : NA
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
 Median : NA   Median : NA   Median : NA
 Mean   :NaN   Mean   :NaN   Mean   :NaN
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
 Max.   : NA   Max.   : NA   Max.   : NA
 NA's   :8     NA's   :8     NA's   :8
Error: Stopping

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Sat Dec 21 00:06:02 2019
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Fri, 20 Dec 2019 18:06:02 -0500
Subject: [R] script execution stops and give the error
In-Reply-To: <CA+nrPntt_6vhwLKUf40MW9cJiS-LxDf3Cj4sEPXWPsSgSLpR8Q@mail.gmail.com>
References: <CA+nrPntt_6vhwLKUf40MW9cJiS-LxDf3Cj4sEPXWPsSgSLpR8Q@mail.gmail.com>
Message-ID: <CAJc=yOHj=5KZ2P1atZDpaHXkGOcit8riMYR+hJSjHdSp=VEzpg@mail.gmail.com>

Per the posting guide, post your script and use plain text. There's no
way anyone can possibly help with only this information.

On Fri, Dec 20, 2019 at 5:33 PM Neha gupta <neha.bologna90 at gmail.com> wrote:
>
>   When I run my code, I get the following error and suddenly the execution
> of the script stops. Where in my data is the problem?
>
> Something is wrong; all the MAE metric values are missing:
>       RMSE        Rsquared        MAE
>  Min.   : NA   Min.   : NA   Min.   : NA
>  1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
>  Median : NA   Median : NA   Median : NA
>  Mean   :NaN   Mean   :NaN   Mean   :NaN
>  3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
>  Max.   : NA   Max.   : NA   Max.   : NA
>  NA's   :8     NA's   :8     NA's   :8
> Error: Stopping
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sat Dec 21 00:23:14 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sat, 21 Dec 2019 00:23:14 +0100
Subject: [R] script execution stops and give the error
In-Reply-To: <CA+nrPntt_6vhwLKUf40MW9cJiS-LxDf3Cj4sEPXWPsSgSLpR8Q@mail.gmail.com>
References: <CA+nrPntt_6vhwLKUf40MW9cJiS-LxDf3Cj4sEPXWPsSgSLpR8Q@mail.gmail.com>
Message-ID: <CA+nrPnuuo7mMsv911_CLe2YiOaZ=k8WwsjoWd-kmz+ZnzxYLng@mail.gmail.com>

The code is described below: I need to find the RMSE and MAE

///read data which have data types of integer and number.
data=read.csv("fault.csv")

inTraining <- createDataPartition(data$bug , p = .75,list = FALSE)
training <- data [inTraining, ]
testings <- data [-inTraining, ]
ctrol = trainControl(method = "repeatedcv", number=5)
myTrain <- train(bug ~ ., data = training,
                     method = "rf",
                    tuneLength = 15,
                     metric = "MAE",
                     preProc = c("center", "scale", "zv"),
                     trControl = ctrol)

On Fri, Dec 20, 2019 at 11:31 PM Neha gupta <neha.bologna90 at gmail.com>
wrote:

>   When I run my code, I get the following error and suddenly the execution
> of the script stops. Where in my data is the problem?
>
> Something is wrong; all the MAE metric values are missing:
>       RMSE        Rsquared        MAE
>  Min.   : NA   Min.   : NA   Min.   : NA
>  1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
>  Median : NA   Median : NA   Median : NA
>  Mean   :NaN   Mean   :NaN   Mean   :NaN
>  3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
>  Max.   : NA   Max.   : NA   Max.   : NA
>  NA's   :8     NA's   :8     NA's   :8
> Error: Stopping
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Dec 21 00:37:53 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 20 Dec 2019 15:37:53 -0800
Subject: [R] script execution stops and give the error
In-Reply-To: <CA+nrPnuuo7mMsv911_CLe2YiOaZ=k8WwsjoWd-kmz+ZnzxYLng@mail.gmail.com>
References: <CA+nrPntt_6vhwLKUf40MW9cJiS-LxDf3Cj4sEPXWPsSgSLpR8Q@mail.gmail.com>
 <CA+nrPnuuo7mMsv911_CLe2YiOaZ=k8WwsjoWd-kmz+ZnzxYLng@mail.gmail.com>
Message-ID: <8BB5FA26-6EE2-47FC-BD70-7654C1807D4E@dcn.davis.ca.us>

A) Plain text is a setting that you must choose in many modern email clients. Failing to do so tends to cause us to see something more or less different than what you intended us to see.

B) Repeating your incomplete example is a more significant issue in this case. If you supply a reproducible example [1][2][3] we can see problems that you don't know exist... so giving us only what you think we need to see makes it that much less likely that you will even get an answer because you are not showing us the relevant information.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

On December 20, 2019 3:23:14 PM PST, Neha gupta <neha.bologna90 at gmail.com> wrote:
>The code is described below: I need to find the RMSE and MAE
>
>///read data which have data types of integer and number.
>data=read.csv("fault.csv")
>
>inTraining <- createDataPartition(data$bug , p = .75,list = FALSE)
>training <- data [inTraining, ]
>testings <- data [-inTraining, ]
>ctrol = trainControl(method = "repeatedcv", number=5)
>myTrain <- train(bug ~ ., data = training,
>                     method = "rf",
>                    tuneLength = 15,
>                     metric = "MAE",
>                     preProc = c("center", "scale", "zv"),
>                     trControl = ctrol)
>
>On Fri, Dec 20, 2019 at 11:31 PM Neha gupta <neha.bologna90 at gmail.com>
>wrote:
>
>>   When I run my code, I get the following error and suddenly the
>execution
>> of the script stops. Where in my data is the problem?
>>
>> Something is wrong; all the MAE metric values are missing:
>>       RMSE        Rsquared        MAE
>>  Min.   : NA   Min.   : NA   Min.   : NA
>>  1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
>>  Median : NA   Median : NA   Median : NA
>>  Mean   :NaN   Mean   :NaN   Mean   :NaN
>>  3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
>>  Max.   : NA   Max.   : NA   Max.   : NA
>>  NA's   :8     NA's   :8     NA's   :8
>> Error: Stopping
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sat Dec 21 00:46:55 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sat, 21 Dec 2019 00:46:55 +0100
Subject: [R] script execution stops and give the error
In-Reply-To: <CA+nrPnuuo7mMsv911_CLe2YiOaZ=k8WwsjoWd-kmz+ZnzxYLng@mail.gmail.com>
References: <CA+nrPntt_6vhwLKUf40MW9cJiS-LxDf3Cj4sEPXWPsSgSLpR8Q@mail.gmail.com>
 <CA+nrPnuuo7mMsv911_CLe2YiOaZ=k8WwsjoWd-kmz+ZnzxYLng@mail.gmail.com>
Message-ID: <CA+nrPnvTSXgVzFY6RNx7ofDb5czQdt1+rn-D4pR+cdiTHdZJnQ@mail.gmail.com>

This is the whole code I provided except the libraries such as

library(caret)
library(randomForest)

data=read.csv("fault.csv")

inTraining <- createDataPartition(data$bug , p = .75,list = FALSE)
training <- data [inTraining, ]
testings <- data [-inTraining, ]
ctrol = trainControl(method = "repeatedcv", number=5)
myTrain <- train(bug ~ ., data = training,
                     method = "rf",
                    tuneLength = 15,
                     metric = "MAE",
                     preProc = c("center", "scale", "zv"),
                     trControl = ctrol)

On Sat, Dec 21, 2019 at 12:23 AM Neha gupta <neha.bologna90 at gmail.com>
wrote:

>
> The code is described below: I need to find the RMSE and MAE
>
> ///read data which have data types of integer and number.
> data=read.csv("fault.csv")
>
> inTraining <- createDataPartition(data$bug , p = .75,list = FALSE)
> training <- data [inTraining, ]
> testings <- data [-inTraining, ]
> ctrol = trainControl(method = "repeatedcv", number=5)
> myTrain <- train(bug ~ ., data = training,
>                      method = "rf",
>                     tuneLength = 15,
>                      metric = "MAE",
>                      preProc = c("center", "scale", "zv"),
>                      trControl = ctrol)
>
> On Fri, Dec 20, 2019 at 11:31 PM Neha gupta <neha.bologna90 at gmail.com>
> wrote:
>
>>   When I run my code, I get the following error and suddenly the
>> execution of the script stops. Where in my data is the problem?
>>
>> Something is wrong; all the MAE metric values are missing:
>>       RMSE        Rsquared        MAE
>>  Min.   : NA   Min.   : NA   Min.   : NA
>>  1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
>>  Median : NA   Median : NA   Median : NA
>>  Mean   :NaN   Mean   :NaN   Mean   :NaN
>>  3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
>>  Max.   : NA   Max.   : NA   Max.   : NA
>>  NA's   :8     NA's   :8     NA's   :8
>> Error: Stopping
>>
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Dec 21 02:54:31 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 20 Dec 2019 17:54:31 -0800
Subject: [R] script execution stops and give the error
In-Reply-To: <CA+nrPnvTSXgVzFY6RNx7ofDb5czQdt1+rn-D4pR+cdiTHdZJnQ@mail.gmail.com>
References: <CA+nrPntt_6vhwLKUf40MW9cJiS-LxDf3Cj4sEPXWPsSgSLpR8Q@mail.gmail.com>
 <CA+nrPnuuo7mMsv911_CLe2YiOaZ=k8WwsjoWd-kmz+ZnzxYLng@mail.gmail.com>
 <CA+nrPnvTSXgVzFY6RNx7ofDb5czQdt1+rn-D4pR+cdiTHdZJnQ@mail.gmail.com>
Message-ID: <6B4B9DA9-C02D-4BF8-B693-C37C7E637D05@dcn.davis.ca.us>

We don't have your data file. Therefore your example is not yet reproducible.

If you read the references I provided you in my other email then you will find hints and discussion about how to make your example reproducible without giving out your actual data. The reprex package mentioned in reference 3 lets you verify that we can run your example.

On December 20, 2019 3:46:55 PM PST, Neha gupta <neha.bologna90 at gmail.com> wrote:
>This is the whole code I provided except the libraries such as
>
>library(caret)
>library(randomForest)
>
>data=read.csv("fault.csv")
>
>inTraining <- createDataPartition(data$bug , p = .75,list = FALSE)
>training <- data [inTraining, ]
>testings <- data [-inTraining, ]
>ctrol = trainControl(method = "repeatedcv", number=5)
>myTrain <- train(bug ~ ., data = training,
>                     method = "rf",
>                    tuneLength = 15,
>                     metric = "MAE",
>                     preProc = c("center", "scale", "zv"),
>                     trControl = ctrol)
>
>On Sat, Dec 21, 2019 at 12:23 AM Neha gupta <neha.bologna90 at gmail.com>
>wrote:
>
>>
>> The code is described below: I need to find the RMSE and MAE
>>
>> ///read data which have data types of integer and number.
>> data=read.csv("fault.csv")
>>
>> inTraining <- createDataPartition(data$bug , p = .75,list = FALSE)
>> training <- data [inTraining, ]
>> testings <- data [-inTraining, ]
>> ctrol = trainControl(method = "repeatedcv", number=5)
>> myTrain <- train(bug ~ ., data = training,
>>                      method = "rf",
>>                     tuneLength = 15,
>>                      metric = "MAE",
>>                      preProc = c("center", "scale", "zv"),
>>                      trControl = ctrol)
>>
>> On Fri, Dec 20, 2019 at 11:31 PM Neha gupta
><neha.bologna90 at gmail.com>
>> wrote:
>>
>>>   When I run my code, I get the following error and suddenly the
>>> execution of the script stops. Where in my data is the problem?
>>>
>>> Something is wrong; all the MAE metric values are missing:
>>>       RMSE        Rsquared        MAE
>>>  Min.   : NA   Min.   : NA   Min.   : NA
>>>  1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
>>>  Median : NA   Median : NA   Median : NA
>>>  Mean   :NaN   Mean   :NaN   Mean   :NaN
>>>  3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
>>>  Max.   : NA   Max.   : NA   Max.   : NA
>>>  NA's   :8     NA's   :8     NA's   :8
>>> Error: Stopping
>>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Sat Dec 21 07:26:26 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 21 Dec 2019 17:26:26 +1100
Subject: [R] Readxl Question
In-Reply-To: <CH2PR17MB374905BB2FB3F94DCB14E99AB82D0@CH2PR17MB3749.namprd17.prod.outlook.com>
References: <CH2PR17MB374905BB2FB3F94DCB14E99AB82D0@CH2PR17MB3749.namprd17.prod.outlook.com>
Message-ID: <CA+8X3fXVvb4zCJ0SDwc7Q88cw059XYBDJ8M=DEmRU0smU677ew@mail.gmail.com>

Hi Thomas,
Perhaps this is what you are seeking:

my_read_excel<-function(filename) {
 serials<-read_excel(filename,sheet="Flow Data",range=("c6"))
 flow.data<-read_excel(filename,sheet="Flow Data",range=("c22:c70"))
 dates<-read_excel(filename,sheet="Flow Data",range=("h14"))
 return(data.frame(Serial=rep(serials,49),Date=rep(dates,49),
  Flow=flow.data),stringsAsFactors=FALSE)
}
lapply(files,my_read_excel)

Should return a list of data frames in the format you want. If you
want just one big data frame, rbind the results. You should also be
able to convert the dates from character to date type without striking
the factor problem.

Jim

On Sat, Dec 21, 2019 at 4:16 AM Thomas Subia <tsubia at imgprecision.com> wrote:
>
> Colleagues,
>
> The objective is to create a text file having this format:
>
> Serial  Date    Flow
>


From t@t|k@gn@@@| @end|ng |rom gm@||@com  Sat Dec 21 10:33:16 2019
From: t@t|k@gn@@@| @end|ng |rom gm@||@com (Aissata Kagnassi)
Date: Sat, 21 Dec 2019 10:33:16 +0100
Subject: [R] Hyperbolic code in R studio ?
Message-ID: <CAEatF2DqX4HwFh0kpT5CzjUuD_MtTvkEL5H6Bwody19VPm5i1Q@mail.gmail.com>

Good morning everyone,



I don't want to bother you. I'm new at using R. :)

1. I was wondering if someone could help me figure out why I can't generate
the code to get a hyperbolic function.



2. My second question is, I generated the code. I don't have any problem
with other distributions but I still can't get the graphics displayed.



Here are the instructions for my exercise and here is the code I used:



**Instructions**

Project: hereafter the series of financial returns will be refered to as yt
and the series of fundamentals as xt. Here are the questions you need to
raise and answer:

Part 1: maximum likelihood estimation, student test and goodness of fit.

1. Consider the following model:

yt =?+??t, with ?t a disturbance such that E[?t] = 0 and V[?t] = 1.

*Estimate the parameters of the following distributions by maximum
likelihood using the Yt:*

? Gaussian distribution N(0,1)

? Student-t distribution with parameter ?

? A mixture of Gaussian distribution MN(?, ?1, ?1, ?2, ?2)

? A generalized hyperbolic distribution GH(?, ?, ?, ?, ?).



2. *Test the parameters for their significance using a Student test. Are
all the parameters statistically significant?*



**My code:**

For the first three distributions, I answered well for questions one and
two which are in italics. But I have a problem with the last one.

library(readxl)

Data <- read_excel("Data_project.xlsx", sheet = 2, skip = 5, col_names =
FALSE)

#y variable to explain, Nikkei 225 index

y <- Data[16]

# x variable explanatory variable, Australian Dollar vs. US Dollar

x <- Data[30]



returns_y = diff(as.matrix(log(y)),1)

returns_x = diff(as.matrix(log(x)),1)

returnsy_std = scale(returns_y)



#1. Estimate the parameters by maximum likelihood

#Gaussian distribution N(0, 1)



mu=0

sigma=0.1

para0 = c(mu,sigma)



loglikG<-function(para,returns_y)

{

  mu = para[1]

  sigma =  para[2]

  print(para)

 logl=sum(log(dnorm((returns_y-mu)/sigma, 0, 1)/sigma))

  return(-logl)

}



loglikG(para0,returns_y)

fit <- optim(para0, loglikG, gr=NULL, returns_y, method="BFGS",hessian=T)



paraopt<- fit[["par"]]



Hessian = fit$hessian

invh = solve(Hessian)



t1= sqrt(invh[1,1])

t2=sqrt(invh[2,2])

testzmu = paraopt[1]/t1

testzvar = paraopt[2]/t2

print(testzmu)

print(testzvar)





#T-student



para_t=c(0,0.012,5)



loglikt <- function(para,returns_y){

  mut=para[1]

  sigmat=para[2]

  nu=para[3]

 m=-sum(log(dt((returns_y-mut)/sigmat, df=nu)/sigmat))



  return(m)

}



loglikt(para_t,returns_y)



output_t= optim(para_t, loglikt, gr=NULL, returns_y, method="BFGS",
hessian=TRUE)

paraopt_t <- output_t[["par"]]



Hessian_t = output_t$hessian

invh_t = solve(Hessian_t)



t1_t= sqrt(invh_t[1,1])

t2_t=sqrt(invh_t[2,2])

t3_t= sqrt(invh_t[3,3])

testzmu_t = paraopt_t[1]/t1_t

testzvar_t = paraopt_t[2]/t2_t

testznu_t = paraopt_t[3]/t3_t

print(testzmu_t)

print(testzvar_t)

print(testznu_t)



#Mixture of Gaussian finding initial values

library(LaplacesDemon)

eps = 0.001

tolerance = 0.95

paraMG = c(-0.02,0.03,0.6,0.8,0.7)



likehoodMG <- function(para,returnsy_std)

{

  muM12 = para[1:2]

  sigmaM12 = para[3:4]

  phi = para[5]

  p = c(phi,1-phi)

 LM=sum(log(dnormm(returnsy_std,muM12,sigmaM12,p=p)))

  mean_w = p[1]*muM12[1] + p[2]*muM12[2]

  var_w = p[1]*sqrt(sigmaM12[1]) + p[2]*sqrt(sigmaM12[2])

 if((abs(mean_w)>tolerance) || (abs(var_w-1)>tolerance)){

    return(NaN)

  }

  return(-LM)

}



likehoodMG(paraMG,returnsy_std)



outputMG = optim(paraMG, likehoodMG, gr=NULL, returnsy_std, method =
"L-BFGS-B", hessian=TRUE,

                  lower = c(eps,eps,-Inf,-Inf,eps), upper =
c(Inf,Inf,Inf,Inf,1-eps))



paraoptMG = outputMG[["par"]]



#Mixture of Gaussian

#(0.000345,0.023306)

paraM
=c(0.000345,0.023306,0.0253514,0.0010000,0.8715856,2.7857329,0.9659020)



likehoodM <- function(para,returns_y)

{

  muM1 = para[1]

  sigmaM = para[2]

  muM12 = para[3:4]

  sigmaM12 = para[5:6]

  phi = para[7]

  p = c(phi,1-phi)

 LM=sum(log(dnormm((returns_y-muM1)/sigmaM,muM12,sigmaM12,p=p)/sigmaM))

  return(-LM)

}



likehoodM(paraM,returns_y)



outputM = optim(paraM, likehoodM, gr=NULL, returns_y, method = "L-BFGS-B",
hessian=TRUE,

                lower = c(-Inf,eps,eps,eps,-Inf,-Inf,eps), upper =
c(Inf,Inf,Inf,Inf,Inf,Inf,1-eps))



paraoptM = outputM[["par"]]



HM = outputM[["hessian"]]

invHM = solve(HM)



tm1 = sqrt(invHM[1,1])

tm2 = sqrt(invHM[2,2])

tm3 = sqrt(invHM[3,3])

tm4 = sqrt(invHM[4,4])

tm5 = sqrt(invHM[5,5])

tm6 = sqrt(invHM[6,6])

tm7 = sqrt(invHM[7,7])



testtmum = (paraoptM[1]-0)/tm1

testtsigmam = paraoptM[2]/tm2

testtmum1 = (paraoptM[3])/tm3

testtmum2 = paraoptM[4]/tm4

testtvarm1 = paraoptM[5]/tm5

testtvarm2 = paraoptM[6]/tm6

testtphi = paraoptM[7]/tm7

print(testtmum)

print(testtsigmam)

print(testtmum1)

print(testtmum2)

print(testtvarm1)

print(testtvarm2)

print(testtphi)



#A generalized hyperbolic distribution GH(??, ??, ??, ??, ?).

library(readxl)

Data <- read_excel("Data_project.xlsx", sheet = 2, skip = 5, col_names =
FALSE)

#y variable to explain, Nikkei 225 index

y <- Data[16]

# x variable explanatory variable, Australian Dollar vs. US Dollar

x <- Data[30]



returns_y = diff(as.matrix(log(y)),1)

returns_x = diff(as.matrix(log(x)),1)

returnsy_std = scale(returns_y)





#A generalized hyperbolic distribution GH(??, ??, ??, ??, ?).



library(ghyp)



para_gh= c(-0.00002,0.005,1,0,1,0.1,0.1) # mu,delta,alpha,beta,lambda



loglikGH <- function(para,returns_y){

  mugh=para[1]

  sigmagh=para[2]

  alpha=para[3]

  beta = para[4]

  delta=para[5]

  chi=para[6]

  lamda=para[7]

  if(delta < abs(chi)){

    return(10000)

  }else{

   return(-sum(log(dghyp(((returns_y-mugh)/sigmagh),object =
ghyp(alpha,beta,delta,chi,lamda))/sigmagh)))

  }

}





loglikGH(para_gh,returns_y)



eps = 0.001



outputGH= optim(para_gh, loglikGH, gr=NULL, returns_y, method = "L-BFGS-B",
hessian=TRUE,

                lower = c(-Inf,eps,eps,eps,-Inf,-Inf,eps), upper =
c(Inf,Inf,Inf,Inf,Inf,Inf,Inf))



paraoptGH = outputGH[["par"]]



HGH = outputGH[["hessian"]]

invHGM = solve(HGH)

tm1_H = sqrt(invHGM[1,1])

tm2_H = sqrt(invHGM[2,2])

tm3_H = sqrt(invHGM[3,3])

tm4_H = sqrt(invHGM[4,4])

tm5_H = sqrt(invHGM[5,5])

tm6_H = sqrt(invHGM[6,6])

tm7_H = sqrt(invHGM[7,7])



testtmuH = (paraoptGH[1]-0)/tm1_H

testtsigmaH = paraoptGH[2]/tm2_H

testtalpha = (paraoptGH[3])/tm3_H

testtbetha = paraoptGH[4]/tm4_H

testtdelta = paraoptGH[5]/tm5_H

testtvchi = paraoptGH[6]/tm6_H

testtlambda = paraoptGH[7]/tm7



print(testtmuH)

print(testtsigmaH)

testtalpha

testtbetha

testtdelta

testtvchi

testtlambda

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Dec 21 16:45:56 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 21 Dec 2019 07:45:56 -0800
Subject: [R] Hyperbolic code in R studio ?
In-Reply-To: <CAEatF2DqX4HwFh0kpT5CzjUuD_MtTvkEL5H6Bwody19VPm5i1Q@mail.gmail.com>
References: <CAEatF2DqX4HwFh0kpT5CzjUuD_MtTvkEL5H6Bwody19VPm5i1Q@mail.gmail.com>
Message-ID: <A757DA8A-C287-431F-8CB7-8A3937EB6DC7@dcn.davis.ca.us>

It is not so much a question of "bother us" as it is of "following the Posting Guide" and "not interfering with an educational institution by helping to cheat".

Please read the Posting Guide (espm about homework help) and next time change your mail program settings so you send plain text to the list (HTML formatted email can become unreadable on our end of your transmission).

On December 21, 2019 1:33:16 AM PST, Aissata Kagnassi <tatikagnassi at gmail.com> wrote:
>Good morning everyone,
>
>
>
>I don't want to bother you. I'm new at using R. :)
>
>1. I was wondering if someone could help me figure out why I can't
>generate
>the code to get a hyperbolic function.
>
>
>
>2. My second question is, I generated the code. I don't have any
>problem
>with other distributions but I still can't get the graphics displayed.
>
>
>
>Here are the instructions for my exercise and here is the code I used:
>
>
>
>**Instructions**
>
>Project: hereafter the series of financial returns will be refered to
>as yt
>and the series of fundamentals as xt. Here are the questions you need
>to
>raise and answer:
>
>Part 1: maximum likelihood estimation, student test and goodness of
>fit.
>
>1. Consider the following model:
>
>yt =?+??t, with ?t a disturbance such that E[?t] = 0 and V[?t] = 1.
>
>*Estimate the parameters of the following distributions by maximum
>likelihood using the Yt:*
>
>? Gaussian distribution N(0,1)
>
>? Student-t distribution with parameter ?
>
>? A mixture of Gaussian distribution MN(?, ?1, ?1, ?2, ?2)
>
>? A generalized hyperbolic distribution GH(?, ?, ?, ?, ?).
>
>
>
>2. *Test the parameters for their significance using a Student test.
>Are
>all the parameters statistically significant?*
>
>
>
>**My code:**
>
>For the first three distributions, I answered well for questions one
>and
>two which are in italics. But I have a problem with the last one.
>
>library(readxl)
>
>Data <- read_excel("Data_project.xlsx", sheet = 2, skip = 5, col_names
>=
>FALSE)
>
>#y variable to explain, Nikkei 225 index
>
>y <- Data[16]
>
># x variable explanatory variable, Australian Dollar vs. US Dollar
>
>x <- Data[30]
>
>
>
>returns_y = diff(as.matrix(log(y)),1)
>
>returns_x = diff(as.matrix(log(x)),1)
>
>returnsy_std = scale(returns_y)
>
>
>
>#1. Estimate the parameters by maximum likelihood
>
>#Gaussian distribution N(0, 1)
>
>
>
>mu=0
>
>sigma=0.1
>
>para0 = c(mu,sigma)
>
>
>
>loglikG<-function(para,returns_y)
>
>{
>
>  mu = para[1]
>
>  sigma =  para[2]
>
>  print(para)
>
> logl=sum(log(dnorm((returns_y-mu)/sigma, 0, 1)/sigma))
>
>  return(-logl)
>
>}
>
>
>
>loglikG(para0,returns_y)
>
>fit <- optim(para0, loglikG, gr=NULL, returns_y,
>method="BFGS",hessian=T)
>
>
>
>paraopt<- fit[["par"]]
>
>
>
>Hessian = fit$hessian
>
>invh = solve(Hessian)
>
>
>
>t1= sqrt(invh[1,1])
>
>t2=sqrt(invh[2,2])
>
>testzmu = paraopt[1]/t1
>
>testzvar = paraopt[2]/t2
>
>print(testzmu)
>
>print(testzvar)
>
>
>
>
>
>#T-student
>
>
>
>para_t=c(0,0.012,5)
>
>
>
>loglikt <- function(para,returns_y){
>
>  mut=para[1]
>
>  sigmat=para[2]
>
>  nu=para[3]
>
> m=-sum(log(dt((returns_y-mut)/sigmat, df=nu)/sigmat))
>
>
>
>  return(m)
>
>}
>
>
>
>loglikt(para_t,returns_y)
>
>
>
>output_t= optim(para_t, loglikt, gr=NULL, returns_y, method="BFGS",
>hessian=TRUE)
>
>paraopt_t <- output_t[["par"]]
>
>
>
>Hessian_t = output_t$hessian
>
>invh_t = solve(Hessian_t)
>
>
>
>t1_t= sqrt(invh_t[1,1])
>
>t2_t=sqrt(invh_t[2,2])
>
>t3_t= sqrt(invh_t[3,3])
>
>testzmu_t = paraopt_t[1]/t1_t
>
>testzvar_t = paraopt_t[2]/t2_t
>
>testznu_t = paraopt_t[3]/t3_t
>
>print(testzmu_t)
>
>print(testzvar_t)
>
>print(testznu_t)
>
>
>
>#Mixture of Gaussian finding initial values
>
>library(LaplacesDemon)
>
>eps = 0.001
>
>tolerance = 0.95
>
>paraMG = c(-0.02,0.03,0.6,0.8,0.7)
>
>
>
>likehoodMG <- function(para,returnsy_std)
>
>{
>
>  muM12 = para[1:2]
>
>  sigmaM12 = para[3:4]
>
>  phi = para[5]
>
>  p = c(phi,1-phi)
>
> LM=sum(log(dnormm(returnsy_std,muM12,sigmaM12,p=p)))
>
>  mean_w = p[1]*muM12[1] + p[2]*muM12[2]
>
>  var_w = p[1]*sqrt(sigmaM12[1]) + p[2]*sqrt(sigmaM12[2])
>
> if((abs(mean_w)>tolerance) || (abs(var_w-1)>tolerance)){
>
>    return(NaN)
>
>  }
>
>  return(-LM)
>
>}
>
>
>
>likehoodMG(paraMG,returnsy_std)
>
>
>
>outputMG = optim(paraMG, likehoodMG, gr=NULL, returnsy_std, method =
>"L-BFGS-B", hessian=TRUE,
>
>                  lower = c(eps,eps,-Inf,-Inf,eps), upper =
>c(Inf,Inf,Inf,Inf,1-eps))
>
>
>
>paraoptMG = outputMG[["par"]]
>
>
>
>#Mixture of Gaussian
>
>#(0.000345,0.023306)
>
>paraM
>=c(0.000345,0.023306,0.0253514,0.0010000,0.8715856,2.7857329,0.9659020)
>
>
>
>likehoodM <- function(para,returns_y)
>
>{
>
>  muM1 = para[1]
>
>  sigmaM = para[2]
>
>  muM12 = para[3:4]
>
>  sigmaM12 = para[5:6]
>
>  phi = para[7]
>
>  p = c(phi,1-phi)
>
> LM=sum(log(dnormm((returns_y-muM1)/sigmaM,muM12,sigmaM12,p=p)/sigmaM))
>
>  return(-LM)
>
>}
>
>
>
>likehoodM(paraM,returns_y)
>
>
>
>outputM = optim(paraM, likehoodM, gr=NULL, returns_y, method =
>"L-BFGS-B",
>hessian=TRUE,
>
>                lower = c(-Inf,eps,eps,eps,-Inf,-Inf,eps), upper =
>c(Inf,Inf,Inf,Inf,Inf,Inf,1-eps))
>
>
>
>paraoptM = outputM[["par"]]
>
>
>
>HM = outputM[["hessian"]]
>
>invHM = solve(HM)
>
>
>
>tm1 = sqrt(invHM[1,1])
>
>tm2 = sqrt(invHM[2,2])
>
>tm3 = sqrt(invHM[3,3])
>
>tm4 = sqrt(invHM[4,4])
>
>tm5 = sqrt(invHM[5,5])
>
>tm6 = sqrt(invHM[6,6])
>
>tm7 = sqrt(invHM[7,7])
>
>
>
>testtmum = (paraoptM[1]-0)/tm1
>
>testtsigmam = paraoptM[2]/tm2
>
>testtmum1 = (paraoptM[3])/tm3
>
>testtmum2 = paraoptM[4]/tm4
>
>testtvarm1 = paraoptM[5]/tm5
>
>testtvarm2 = paraoptM[6]/tm6
>
>testtphi = paraoptM[7]/tm7
>
>print(testtmum)
>
>print(testtsigmam)
>
>print(testtmum1)
>
>print(testtmum2)
>
>print(testtvarm1)
>
>print(testtvarm2)
>
>print(testtphi)
>
>
>
>#A generalized hyperbolic distribution GH(??, ??, ??, ??, ?).
>
>library(readxl)
>
>Data <- read_excel("Data_project.xlsx", sheet = 2, skip = 5, col_names
>=
>FALSE)
>
>#y variable to explain, Nikkei 225 index
>
>y <- Data[16]
>
># x variable explanatory variable, Australian Dollar vs. US Dollar
>
>x <- Data[30]
>
>
>
>returns_y = diff(as.matrix(log(y)),1)
>
>returns_x = diff(as.matrix(log(x)),1)
>
>returnsy_std = scale(returns_y)
>
>
>
>
>
>#A generalized hyperbolic distribution GH(??, ??, ??, ??, ?).
>
>
>
>library(ghyp)
>
>
>
>para_gh= c(-0.00002,0.005,1,0,1,0.1,0.1) # mu,delta,alpha,beta,lambda
>
>
>
>loglikGH <- function(para,returns_y){
>
>  mugh=para[1]
>
>  sigmagh=para[2]
>
>  alpha=para[3]
>
>  beta = para[4]
>
>  delta=para[5]
>
>  chi=para[6]
>
>  lamda=para[7]
>
>  if(delta < abs(chi)){
>
>    return(10000)
>
>  }else{
>
>   return(-sum(log(dghyp(((returns_y-mugh)/sigmagh),object =
>ghyp(alpha,beta,delta,chi,lamda))/sigmagh)))
>
>  }
>
>}
>
>
>
>
>
>loglikGH(para_gh,returns_y)
>
>
>
>eps = 0.001
>
>
>
>outputGH= optim(para_gh, loglikGH, gr=NULL, returns_y, method =
>"L-BFGS-B",
>hessian=TRUE,
>
>                lower = c(-Inf,eps,eps,eps,-Inf,-Inf,eps), upper =
>c(Inf,Inf,Inf,Inf,Inf,Inf,Inf))
>
>
>
>paraoptGH = outputGH[["par"]]
>
>
>
>HGH = outputGH[["hessian"]]
>
>invHGM = solve(HGH)
>
>tm1_H = sqrt(invHGM[1,1])
>
>tm2_H = sqrt(invHGM[2,2])
>
>tm3_H = sqrt(invHGM[3,3])
>
>tm4_H = sqrt(invHGM[4,4])
>
>tm5_H = sqrt(invHGM[5,5])
>
>tm6_H = sqrt(invHGM[6,6])
>
>tm7_H = sqrt(invHGM[7,7])
>
>
>
>testtmuH = (paraoptGH[1]-0)/tm1_H
>
>testtsigmaH = paraoptGH[2]/tm2_H
>
>testtalpha = (paraoptGH[3])/tm3_H
>
>testtbetha = paraoptGH[4]/tm4_H
>
>testtdelta = paraoptGH[5]/tm5_H
>
>testtvchi = paraoptGH[6]/tm6_H
>
>testtlambda = paraoptGH[7]/tm7
>
>
>
>print(testtmuH)
>
>print(testtsigmaH)
>
>testtalpha
>
>testtbetha
>
>testtdelta
>
>testtvchi
>
>testtlambda
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sat Dec 21 16:55:05 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sat, 21 Dec 2019 16:55:05 +0100
Subject: [R] script execution stops and give the error
In-Reply-To: <8BB5FA26-6EE2-47FC-BD70-7654C1807D4E@dcn.davis.ca.us>
References: <CA+nrPntt_6vhwLKUf40MW9cJiS-LxDf3Cj4sEPXWPsSgSLpR8Q@mail.gmail.com>
 <CA+nrPnuuo7mMsv911_CLe2YiOaZ=k8WwsjoWd-kmz+ZnzxYLng@mail.gmail.com>
 <8BB5FA26-6EE2-47FC-BD70-7654C1807D4E@dcn.davis.ca.us>
Message-ID: <CA+nrPnsphYLt+KyQ2Hi3y_EKkd53BKPT+Gv+smSbxMN+3KHwtg@mail.gmail.com>

My data is as follows:

d=readARFF("ant.arff")
dput( head( d, 50 ) )
d-> structure(list(version = c(1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7,
                               1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7,
1.7, 1.7, 1.7, 1.7,
                               1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7,
1.7, 1.7, 1.7, 1.7,
                               1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7,
1.7, 1.7, 1.7, 1.7,
                               1.7, 1.7, 1.7, 1.7), wmc = c(3, 5, 1, 8, 9,
3, 20, 13, 9, 7,
                                                            9, 3, 1, 9, 19,
10, 3, 20, 6, 3, 5, 1, 11, 3, 3, 16, 4, 15, 11,
                                                            2, 15, 14, 27,
5, 3, 4, 6, 55, 3, 8, 11, 10, 1, 3, 9, 7, 9, 63,
                                                            6, 2), dit =
c(1, 2, 2, 1, 3, 2, 1, 1, 1, 5, 6, 2, 1, 1, 4, 4,

 2, 1, 1, 4, 2, 1, 2, 4, 2, 3, 4, 1, 3, 3, 3, 4, 3, 4, 1, 5, 1,

 3, 2, 1, 2, 1, 3, 2, 1, 1, 1, 1, 3, 1), noc = c(0, 0, 0, 9, 0,

                                               5, 0, 0, 0, 0, 0, 0, 0, 0,
0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

                                               8, 0, 0, 0, 0, 3, 0, 0, 0,
0, 0, 8, 0, 0, 0, 0, 0, 1, 0, 0, 1,

                                               2, 2, 0), cbo = c(10, 4, 1,
13, 5, 7, 4, 7, 5, 9, 5, 19, 10,

                                                                 3, 7, 13,
2, 7, 8, 5, 7, 1, 7, 5, 5, 15, 12, 11, 3, 1, 9, 11,

                                                                 8, 8, 2,
5, 2, 20, 4, 4, 1, 10, 1, 12, 32, 24, 4, 61, 20, 6),
                   rfc = c(18, 13, 3, 20, 26, 4, 40, 28, 19, 25, 17, 10, 1,
                           12, 40, 26, 5, 79, 6, 11, 14, 1, 26, 15, 7, 65,
5, 65, 24,
                           3, 41, 29, 101, 23, 3, 19, 11, 106, 19, 22, 23,
29, 2, 22,
                           36, 8, 19, 144, 13, 2), lcom = c(3, 0, 0, 12,
16, 1, 130,
                                                            20, 8, 0, 26,
3, 0, 20, 129, 0, 0, 136, 15, 1, 6, 0, 0, 3,
                                                            1, 76, 0, 75,
17, 1, 0, 85, 157, 4, 3, 6, 3, 1313, 3, 0,
                                                            39, 43, 0, 3,
36, 3, 30, 1603, 7, 1), ca = c(1, 1, 0, 9,

                             0, 6, 0, 2, 4, 6, 0, 14, 8, 1, 0, 7, 1, 5, 7,
1, 0, 0, 5,

                             0, 1, 0, 8, 0, 0, 1, 0, 3, 5, 4, 2, 0, 1, 8,
0, 0, 1, 7,

                             0, 2, 32, 24, 1, 51, 17, 6), ce = c(9, 4, 1,
4, 5, 1, 4,

                                                                 5, 1, 3,
5, 5, 2, 2, 7, 7, 1, 5, 1, 4, 7, 1, 2, 5, 4, 15,

                                                                 4, 11, 3,
0, 9, 8, 3, 8, 0, 5, 1, 12, 4, 4, 0, 3, 1, 10,

                                                                 0, 0, 3,
10, 3, 0), npm = c(1, 4, 1, 8, 7, 2, 18, 12, 9,


                 7, 6, 3, 1, 8, 16, 9, 3, 10, 6, 1, 4, 1, 11, 2, 3, 13, 3,


                 11, 10, 2, 15, 11, 15, 5, 3, 4, 4, 9, 2, 6, 10, 8, 1, 2,


                 7, 7, 7, 31, 3, 2), loc = c(106, 76, 7, 101, 185, 16, 345,


                                             183, 119, 255, 71, 38, 1, 54,
252, 110, 34, 835, 6, 41, 70,


                                             1, 181, 51, 29, 483, 18, 443,
309, 7, 204, 108, 1286, 249,


                                             4, 57, 53, 1133, 136, 169,
136, 91, 4, 72, 281, 43, 130,


                                             2303, 56, 2), moa = c(0, 1, 0,
1, 0, 0, 1, 2, 0, 0, 0, 0,


                                                                   0, 3, 0,
1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,


                                                                   1, 1, 0,
0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0),
                   ic = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 1,
1,
                          0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,
2, 0, 2,
                          0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0), cbm =
c(0, 0,

 0, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 3, 1, 2, 0, 0, 2, 0,

 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 7, 2, 0, 4, 0, 0, 0, 0,

 1, 0, 0, 0, 0, 0, 0, 0, 4, 0), max_cc = c(1, 1, 0, 1, 2,

                                           1, 3, 7, 3, 9, 3, 1, 1, 1, 6, 3,
1, 10, 1, 3, 4, 1, 1, 2,

                                           1, 9, 1, 5, 11, 1, 2, 4, 4, 1,
1, 2, 1, 10, 2, 7, 1, 3, 0,

                                           1, 11, 1, 4, 35, 1, 1), bug =
c(0, 0, 0, 0, 1, 0, 1, 0, 0,


 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,


 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,


 3, 0, 0)), row.names = c(NA, 50L), class = "data.frame")

On Sat, Dec 21, 2019 at 12:37 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> A) Plain text is a setting that you must choose in many modern email
> clients. Failing to do so tends to cause us to see something more or less
> different than what you intended us to see.
>
> B) Repeating your incomplete example is a more significant issue in this
> case. If you supply a reproducible example [1][2][3] we can see problems
> that you don't know exist... so giving us only what you think we need to
> see makes it that much less likely that you will even get an answer because
> you are not showing us the relevant information.
>
> [1]
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> [2] http://adv-r.had.co.nz/Reproducibility.html
>
> [3] https://cran.r-project.org/web/packages/reprex/index.html (read the
> vignette)
>
> On December 20, 2019 3:23:14 PM PST, Neha gupta <neha.bologna90 at gmail.com>
> wrote:
> >The code is described below: I need to find the RMSE and MAE
> >
> >///read data which have data types of integer and number.
> >data=read.csv("fault.csv")
> >
> >inTraining <- createDataPartition(data$bug , p = .75,list = FALSE)
> >training <- data [inTraining, ]
> >testings <- data [-inTraining, ]
> >ctrol = trainControl(method = "repeatedcv", number=5)
> >myTrain <- train(bug ~ ., data = training,
> >                     method = "rf",
> >                    tuneLength = 15,
> >                     metric = "MAE",
> >                     preProc = c("center", "scale", "zv"),
> >                     trControl = ctrol)
> >
> >On Fri, Dec 20, 2019 at 11:31 PM Neha gupta <neha.bologna90 at gmail.com>
> >wrote:
> >
> >>   When I run my code, I get the following error and suddenly the
> >execution
> >> of the script stops. Where in my data is the problem?
> >>
> >> Something is wrong; all the MAE metric values are missing:
> >>       RMSE        Rsquared        MAE
> >>  Min.   : NA   Min.   : NA   Min.   : NA
> >>  1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
> >>  Median : NA   Median : NA   Median : NA
> >>  Mean   :NaN   Mean   :NaN   Mean   :NaN
> >>  3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
> >>  Max.   : NA   Max.   : NA   Max.   : NA
> >>  NA's   :8     NA's   :8     NA's   :8
> >> Error: Stopping
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From |o@nn@@|o@nnou @end|ng |rom uc|@@c@uk  Fri Dec 20 22:33:33 2019
From: |o@nn@@|o@nnou @end|ng |rom uc|@@c@uk (Ioannou, Ioanna)
Date: Fri, 20 Dec 2019 21:33:33 +0000
Subject: [R] 
 How to create a new data.frame based on calculation of subsets
 of an existing data.frame
In-Reply-To: <CA+8X3fUmu_mtaM5yP8iu3oPC2tNUfg9QHKRg3vrRzHu0WL10rw@mail.gmail.com>
References: <DB8PR01MB56753355D342F34AF536E74EC9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fUbFmch8gORE9huB+1Ts50uNU1T14obR4e7V401eaNVfg@mail.gmail.com>
 <DB8PR01MB56752F156F6C4DBEC2AB0C02C9500@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fWnLBOPNxc1_AJVndjd0x3NrGD6UTKiK9JugZawHjwdbg@mail.gmail.com>
 <CA+8X3fURQd+nvf=JER5kf=N7MfwUKNrzinvtiYHAa_w2XRN37w@mail.gmail.com>
 <DB8PR01MB56759F3B055EE157D6AC764CC92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fX7oDs93643w31n1cS5ZwmAT0Ov0n5593+Be4hQGQMOnw@mail.gmail.com>
 <DB8PR01MB567575DA16F823A401DF94A2C92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>
 <CA+8X3fUmu_mtaM5yP8iu3oPC2tNUfg9QHKRg3vrRzHu0WL10rw@mail.gmail.com>
Message-ID: <DB8PR01MB5675402A85082FA26A56DF20C92D0@DB8PR01MB5675.eurprd01.prod.exchangelabs.com>

Hello Jim , 

Thank you ever so much for your help. I was truly stuck! 

This looks much better and yes I can turn them into a matrix no problem. Indeed I need only the results for ER+ETR_H1,PGA and ER+ETR_H2,Sa. One minor point as it is the VC has 4 values for three cases instead of the aforementioned two. In fact, the third is identical to the first. Could you please optimize? 

Thank you very much again, 
Best, 
ioanna

-----Original Message-----
From: Jim Lemon [mailto:drjimlemon at gmail.com] 
Sent: Friday, December 20, 2019 9:04 PM
To: Ioannou, Ioanna <ioanna.ioannou at ucl.ac.uk>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] How to create a new data.frame based on calculation of subsets of an existing data.frame

Hi Ioanna,
We're getting somewhere, but there are four unique combinations  of Taxonomy and IM.type:

ER+ETR_H1,PGA
ER+ETR_H2,PGA
ER+ETR_H1,Sa
ER+ETR_H2,Sa

Perhaps you mean that ER+ETR_H1 only occurs with PGA and ER+ETR_H2 only occurs with Sa. I handled that by checking that there were any rows that corresponded to the condition requested.

Also you want a matrix for each row containing Taxonomy and IM.type in the output. When I run what I think you are asking, I only get a two element list, each a vector of values. Maybe this is what you want, and it could be coerced into matrix format:

D<- data.frame(Ref.No = c(1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629),  Region = rep(c('South America'), times = 8),  IM.type = c('PGA', 'PGA', 'PGA', 'PGA', 'Sa', 'Sa', 'Sa', 'Sa'),  Damage.state = c('DS1', 'DS2', 'DS3', 'DS4','DS1', 'DS2', 'DS3', 'DS4'),  Taxonomy = c('ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H1','ER+ETR_H2','ER+ETR_H2','ER+ETR_H2','ER+ETR_H2'),
 Prob.of.exceedance_1 = c(0,0,0,0,0,0,0,0),
 Prob.of.exceedance_2 = c(0,0,0,0,0,0,0,0),
 Prob.of.exceedance_3 =
  c(0.26,0.001,0.00019,0.000000573,0.04,0.00017,0.000215,0.000472),
 Prob.of.exceedance_4 =
  c(0.72,0.03,0.008,0.000061,0.475,0.0007,0.00435,0.000405),
 stringsAsFactors=FALSE)

# names of the variables used in the calculations
calc_vars<-paste("Prob.of.exceedance",1:4,sep="_")
# get the rows for the four damage states DS1_rows <-D$Damage.state == "DS1"
DS2_rows <-D$Damage.state == "DS2"
DS3_rows <-D$Damage.state == "DS3"
DS4_rows <-D$Damage.state == "DS4"
# create an empty list
VC<-list()
# set an index variable for VC
VCindex<-1
# step through all possible values of IM.type and Taxonomy for(IM in unique(D$IM.type)) {  for(Tax in unique(D$Taxonomy)) {
  # get a logical vector of the rows to be used in this calculation
  calc_rows <- D$IM.type == IM & D$Taxonomy == Tax
  cat(IM,Tax,calc_rows,"\n")
  # check that there are any such rows in the data frame
  if(sum(calc_rows)) {
   # if so, fill in the four values for these rows
   VC[[VCindex]] <- 0.0 * (1- D[calc_rows & DS1_rows,calc_vars]) +
    0.02* (D[calc_rows & DS1_rows,calc_vars] -
               D[calc_rows & DS2_rows,calc_vars]) +
    0.10* (D[calc_rows & DS2_rows,calc_vars] -
                                   D[calc_rows & DS3_rows,calc_vars]) +
    0.43 * (D[calc_rows & DS3_rows,calc_vars] -
                                   D[calc_rows & DS4_rows,calc_vars]) +
    1.0*   D[calc_rows & DS4_rows,calc_vars]
   # increment the index
   VCindex<-VCindex+1
  }
 }
}

I think we'll get there.

Jim


On Sat, Dec 21, 2019 at 12:45 AM Ioannou, Ioanna <ioanna.ioannou at ucl.ac.uk> wrote:
>
> Hello Jim,
>
> I made some changes to the code essentially I substitute each 4 lines DS1-4 with one. I estimate VC which in an ideal world should be a matrix with 4 columns one for every exceedance_probability_1-4 and 2 rowsfor each unique combination of taxonomy and IM.Type. Coukd you please check the code I sent last and based on that give your solution?

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Dec 21 18:02:48 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 21 Dec 2019 17:02:48 +0000
Subject: [R] Hyperbolic code in R studio ?
In-Reply-To: <A757DA8A-C287-431F-8CB7-8A3937EB6DC7@dcn.davis.ca.us>
References: <CAEatF2DqX4HwFh0kpT5CzjUuD_MtTvkEL5H6Bwody19VPm5i1Q@mail.gmail.com>
 <A757DA8A-C287-431F-8CB7-8A3937EB6DC7@dcn.davis.ca.us>
Message-ID: <c667676f-59f3-96d6-2f08-2e5bb028e2b4@sapo.pt>

Hello,

I agree with Jeff and also:

I don't want to be snarky but can't resit, the question's subject title 
is provocative.

A hyperbole is the figure of speech that consists of exaggeration of 
expression, enlarging the true dimension of things. In simplified terms, 
hyperbole is the overtly exaggerated expression of an idea.


*Minimal* reproducible examples must be, well, minimal.
Do you really need all that code to show you are finding the generation 
of a hyperbolic function difficult? If the question is on how to create 
a function, why several functions?

?s 15:45 de 21/12/19, Jeff Newmiller escreveu:
> It is not so much a question of "bother us" as it is of "following the Posting Guide" and "not interfering with an educational institution by helping to cheat".
> 
> Please read the Posting Guide (espm about homework help) and next time change your mail program settings so you send plain text to the list (HTML formatted email can become unreadable on our end of your transmission).
> 
> On December 21, 2019 1:33:16 AM PST, Aissata Kagnassi <tatikagnassi at gmail.com> wrote:
>> Good morning everyone,
>>
>>
>>
>> I don't want to bother you. I'm new at using R. :)
>>
>> 1. I was wondering if someone could help me figure out why I can't
>> generate
>> the code to get a hyperbolic function.
>>
>>
>>
>> 2. My second question is, I generated the code. I don't have any
>> problem
>> with other distributions but I still can't get the graphics displayed.
>>
>>
>>
>> Here are the instructions for my exercise and here is the code I used:
>>
>>
>>
>> **Instructions**
>>
>> Project: hereafter the series of financial returns will be refered to
>> as yt
>> and the series of fundamentals as xt. Here are the questions you need
>> to
>> raise and answer:
>>
>> Part 1: maximum likelihood estimation, student test and goodness of
>> fit.
>>
>> 1. Consider the following model:
>>
>> yt =?+??t, with ?t a disturbance such that E[?t] = 0 and V[?t] = 1.
>>
>> *Estimate the parameters of the following distributions by maximum
>> likelihood using the Yt:*
>>
>> ? Gaussian distribution N(0,1)
>>
>> ? Student-t distribution with parameter ?
>>
>> ? A mixture of Gaussian distribution MN(?, ?1, ?1, ?2, ?2)
>>
>> ? A generalized hyperbolic distribution GH(?, ?, ?, ?, ?).
>>
>>
>>
>> 2. *Test the parameters for their significance using a Student test.
>> Are
>> all the parameters statistically significant?*
>>
>>
>>
>> **My code:**
>>
>> For the first three distributions, I answered well for questions one
>> and
>> two which are in italics. But I have a problem with the last one.
>>
>> library(readxl)
>>
>> Data <- read_excel("Data_project.xlsx", sheet = 2, skip = 5, col_names
>> =
>> FALSE)
>>
>> #y variable to explain, Nikkei 225 index
>>
>> y <- Data[16]
>>
>> # x variable explanatory variable, Australian Dollar vs. US Dollar
>>
>> x <- Data[30]
>>
>>
>>
>> returns_y = diff(as.matrix(log(y)),1)
>>
>> returns_x = diff(as.matrix(log(x)),1)
>>
>> returnsy_std = scale(returns_y)
>>
>>
>>
>> #1. Estimate the parameters by maximum likelihood
>>
>> #Gaussian distribution N(0, 1)
>>
>>
>>
>> mu=0
>>
>> sigma=0.1
>>
>> para0 = c(mu,sigma)
>>
>>
>>
>> loglikG<-function(para,returns_y)
>>
>> {
>>
>>   mu = para[1]
>>
>>   sigma =  para[2]
>>
>>   print(para)
>>
>> logl=sum(log(dnorm((returns_y-mu)/sigma, 0, 1)/sigma))
>>
>>   return(-logl)
>>
>> }
>>
>>
>>
>> loglikG(para0,returns_y)
>>
>> fit <- optim(para0, loglikG, gr=NULL, returns_y,
>> method="BFGS",hessian=T)
>>
>>
>>
>> paraopt<- fit[["par"]]
>>
>>
>>
>> Hessian = fit$hessian
>>
>> invh = solve(Hessian)
>>
>>
>>
>> t1= sqrt(invh[1,1])
>>
>> t2=sqrt(invh[2,2])
>>
>> testzmu = paraopt[1]/t1
>>
>> testzvar = paraopt[2]/t2
>>
>> print(testzmu)
>>
>> print(testzvar)
>>
>>
>>
>>
>>
>> #T-student
>>
>>
>>
>> para_t=c(0,0.012,5)
>>
>>
>>
>> loglikt <- function(para,returns_y){
>>
>>   mut=para[1]
>>
>>   sigmat=para[2]
>>
>>   nu=para[3]
>>
>> m=-sum(log(dt((returns_y-mut)/sigmat, df=nu)/sigmat))
>>
>>
>>
>>   return(m)
>>
>> }
>>
>>
>>
>> loglikt(para_t,returns_y)
>>
>>
>>
>> output_t= optim(para_t, loglikt, gr=NULL, returns_y, method="BFGS",
>> hessian=TRUE)
>>
>> paraopt_t <- output_t[["par"]]
>>
>>
>>
>> Hessian_t = output_t$hessian
>>
>> invh_t = solve(Hessian_t)
>>
>>
>>
>> t1_t= sqrt(invh_t[1,1])
>>
>> t2_t=sqrt(invh_t[2,2])
>>
>> t3_t= sqrt(invh_t[3,3])
>>
>> testzmu_t = paraopt_t[1]/t1_t
>>
>> testzvar_t = paraopt_t[2]/t2_t
>>
>> testznu_t = paraopt_t[3]/t3_t
>>
>> print(testzmu_t)
>>
>> print(testzvar_t)
>>
>> print(testznu_t)
>>
>>
>>
>> #Mixture of Gaussian finding initial values
>>
>> library(LaplacesDemon)
>>
>> eps = 0.001
>>
>> tolerance = 0.95
>>
>> paraMG = c(-0.02,0.03,0.6,0.8,0.7)
>>
>>
>>
>> likehoodMG <- function(para,returnsy_std)
>>
>> {
>>
>>   muM12 = para[1:2]
>>
>>   sigmaM12 = para[3:4]
>>
>>   phi = para[5]
>>
>>   p = c(phi,1-phi)
>>
>> LM=sum(log(dnormm(returnsy_std,muM12,sigmaM12,p=p)))
>>
>>   mean_w = p[1]*muM12[1] + p[2]*muM12[2]
>>
>>   var_w = p[1]*sqrt(sigmaM12[1]) + p[2]*sqrt(sigmaM12[2])
>>
>> if((abs(mean_w)>tolerance) || (abs(var_w-1)>tolerance)){
>>
>>     return(NaN)
>>
>>   }
>>
>>   return(-LM)
>>
>> }
>>
>>
>>
>> likehoodMG(paraMG,returnsy_std)
>>
>>
>>
>> outputMG = optim(paraMG, likehoodMG, gr=NULL, returnsy_std, method =
>> "L-BFGS-B", hessian=TRUE,
>>
>>                   lower = c(eps,eps,-Inf,-Inf,eps), upper =
>> c(Inf,Inf,Inf,Inf,1-eps))
>>
>>
>>
>> paraoptMG = outputMG[["par"]]
>>
>>
>>
>> #Mixture of Gaussian
>>
>> #(0.000345,0.023306)
>>
>> paraM
>> =c(0.000345,0.023306,0.0253514,0.0010000,0.8715856,2.7857329,0.9659020)
>>
>>
>>
>> likehoodM <- function(para,returns_y)
>>
>> {
>>
>>   muM1 = para[1]
>>
>>   sigmaM = para[2]
>>
>>   muM12 = para[3:4]
>>
>>   sigmaM12 = para[5:6]
>>
>>   phi = para[7]
>>
>>   p = c(phi,1-phi)
>>
>> LM=sum(log(dnormm((returns_y-muM1)/sigmaM,muM12,sigmaM12,p=p)/sigmaM))
>>
>>   return(-LM)
>>
>> }
>>
>>
>>
>> likehoodM(paraM,returns_y)
>>
>>
>>
>> outputM = optim(paraM, likehoodM, gr=NULL, returns_y, method =
>> "L-BFGS-B",
>> hessian=TRUE,
>>
>>                 lower = c(-Inf,eps,eps,eps,-Inf,-Inf,eps), upper =
>> c(Inf,Inf,Inf,Inf,Inf,Inf,1-eps))
>>
>>
>>
>> paraoptM = outputM[["par"]]
>>
>>
>>
>> HM = outputM[["hessian"]]
>>
>> invHM = solve(HM)
>>
>>
>>
>> tm1 = sqrt(invHM[1,1])
>>
>> tm2 = sqrt(invHM[2,2])
>>
>> tm3 = sqrt(invHM[3,3])
>>
>> tm4 = sqrt(invHM[4,4])
>>
>> tm5 = sqrt(invHM[5,5])
>>
>> tm6 = sqrt(invHM[6,6])
>>
>> tm7 = sqrt(invHM[7,7])
>>
>>
>>
>> testtmum = (paraoptM[1]-0)/tm1
>>
>> testtsigmam = paraoptM[2]/tm2
>>
>> testtmum1 = (paraoptM[3])/tm3
>>
>> testtmum2 = paraoptM[4]/tm4
>>
>> testtvarm1 = paraoptM[5]/tm5
>>
>> testtvarm2 = paraoptM[6]/tm6
>>
>> testtphi = paraoptM[7]/tm7
>>
>> print(testtmum)
>>
>> print(testtsigmam)
>>
>> print(testtmum1)
>>
>> print(testtmum2)
>>
>> print(testtvarm1)
>>
>> print(testtvarm2)
>>
>> print(testtphi)
>>
>>
>>
>> #A generalized hyperbolic distribution GH(??, ??, ??, ??, ?).
>>
>> library(readxl)
>>
>> Data <- read_excel("Data_project.xlsx", sheet = 2, skip = 5, col_names
>> =
>> FALSE)
>>
>> #y variable to explain, Nikkei 225 index
>>
>> y <- Data[16]
>>
>> # x variable explanatory variable, Australian Dollar vs. US Dollar
>>
>> x <- Data[30]
>>
>>
>>
>> returns_y = diff(as.matrix(log(y)),1)
>>
>> returns_x = diff(as.matrix(log(x)),1)
>>
>> returnsy_std = scale(returns_y)
>>
>>
>>
>>
>>
>> #A generalized hyperbolic distribution GH(??, ??, ??, ??, ?).
>>
>>
>>
>> library(ghyp)
>>
>>
>>
>> para_gh= c(-0.00002,0.005,1,0,1,0.1,0.1) # mu,delta,alpha,beta,lambda
>>
>>
>>
>> loglikGH <- function(para,returns_y){
>>
>>   mugh=para[1]
>>
>>   sigmagh=para[2]
>>
>>   alpha=para[3]
>>
>>   beta = para[4]
>>
>>   delta=para[5]
>>
>>   chi=para[6]
>>
>>   lamda=para[7]
>>
>>   if(delta < abs(chi)){
>>
>>     return(10000)
>>
>>   }else{
>>
>>    return(-sum(log(dghyp(((returns_y-mugh)/sigmagh),object =
>> ghyp(alpha,beta,delta,chi,lamda))/sigmagh)))
>>
>>   }
>>
>> }
>>
>>
>>
>>
>>
>> loglikGH(para_gh,returns_y)
>>
>>
>>
>> eps = 0.001
>>
>>
>>
>> outputGH= optim(para_gh, loglikGH, gr=NULL, returns_y, method =
>> "L-BFGS-B",
>> hessian=TRUE,
>>
>>                 lower = c(-Inf,eps,eps,eps,-Inf,-Inf,eps), upper =
>> c(Inf,Inf,Inf,Inf,Inf,Inf,Inf))
>>
>>
>>
>> paraoptGH = outputGH[["par"]]
>>
>>
>>
>> HGH = outputGH[["hessian"]]
>>
>> invHGM = solve(HGH)
>>
>> tm1_H = sqrt(invHGM[1,1])
>>
>> tm2_H = sqrt(invHGM[2,2])
>>
>> tm3_H = sqrt(invHGM[3,3])
>>
>> tm4_H = sqrt(invHGM[4,4])
>>
>> tm5_H = sqrt(invHGM[5,5])
>>
>> tm6_H = sqrt(invHGM[6,6])
>>
>> tm7_H = sqrt(invHGM[7,7])
>>
>>
>>
>> testtmuH = (paraoptGH[1]-0)/tm1_H
>>
>> testtsigmaH = paraoptGH[2]/tm2_H
>>
>> testtalpha = (paraoptGH[3])/tm3_H
>>
>> testtbetha = paraoptGH[4]/tm4_H
>>
>> testtdelta = paraoptGH[5]/tm5_H
>>
>> testtvchi = paraoptGH[6]/tm6_H
>>
>> testtlambda = paraoptGH[7]/tm7
>>
>>
>>
>> print(testtmuH)
>>
>> print(testtsigmaH)
>>
>> testtalpha
>>
>> testtbetha
>>
>> testtdelta
>>
>> testtvchi
>>
>> testtlambda
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Dec 21 18:14:39 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 21 Dec 2019 17:14:39 +0000
Subject: [R] Hyperbolic code in R studio ?
In-Reply-To: <c667676f-59f3-96d6-2f08-2e5bb028e2b4@sapo.pt>
References: <CAEatF2DqX4HwFh0kpT5CzjUuD_MtTvkEL5H6Bwody19VPm5i1Q@mail.gmail.com>
 <A757DA8A-C287-431F-8CB7-8A3937EB6DC7@dcn.davis.ca.us>
 <c667676f-59f3-96d6-2f08-2e5bb028e2b4@sapo.pt>
Message-ID: <8ce99eb3-404e-0196-fcca-4e203b5bcac7@sapo.pt>

Hello again,

Sorry, clicked <Send> before signing.

Rui Barradas

?s 17:02 de 21/12/19, Rui Barradas escreveu:
> Hello,
> 
> I agree with Jeff and also:
> 
> I don't want to be snarky but can't resit, the question's subject title 
> is provocative.
> 
> A hyperbole is the figure of speech that consists of exaggeration of 
> expression, enlarging the true dimension of things. In simplified terms, 
> hyperbole is the overtly exaggerated expression of an idea.
> 
> 
> *Minimal* reproducible examples must be, well, minimal.
> Do you really need all that code to show you are finding the generation 
> of a hyperbolic function difficult? If the question is on how to create 
> a function, why several functions?
> 
> ?s 15:45 de 21/12/19, Jeff Newmiller escreveu:
>> It is not so much a question of "bother us" as it is of "following the 
>> Posting Guide" and "not interfering with an educational institution by 
>> helping to cheat".
>>
>> Please read the Posting Guide (espm about homework help) and next time 
>> change your mail program settings so you send plain text to the list 
>> (HTML formatted email can become unreadable on our end of your 
>> transmission).
>>
>> On December 21, 2019 1:33:16 AM PST, Aissata Kagnassi 
>> <tatikagnassi at gmail.com> wrote:
>>> Good morning everyone,
>>>
>>>
>>>
>>> I don't want to bother you. I'm new at using R. :)
>>>
>>> 1. I was wondering if someone could help me figure out why I can't
>>> generate
>>> the code to get a hyperbolic function.
>>>
>>>
>>>
>>> 2. My second question is, I generated the code. I don't have any
>>> problem
>>> with other distributions but I still can't get the graphics displayed.
>>>
>>>
>>>
>>> Here are the instructions for my exercise and here is the code I used:
>>>
>>>
>>>
>>> **Instructions**
>>>
>>> Project: hereafter the series of financial returns will be refered to
>>> as yt
>>> and the series of fundamentals as xt. Here are the questions you need
>>> to
>>> raise and answer:
>>>
>>> Part 1: maximum likelihood estimation, student test and goodness of
>>> fit.
>>>
>>> 1. Consider the following model:
>>>
>>> yt =?+??t, with ?t a disturbance such that E[?t] = 0 and V[?t] = 1.
>>>
>>> *Estimate the parameters of the following distributions by maximum
>>> likelihood using the Yt:*
>>>
>>> ? Gaussian distribution N(0,1)
>>>
>>> ? Student-t distribution with parameter ?
>>>
>>> ? A mixture of Gaussian distribution MN(?, ?1, ?1, ?2, ?2)
>>>
>>> ? A generalized hyperbolic distribution GH(?, ?, ?, ?, ?).
>>>
>>>
>>>
>>> 2. *Test the parameters for their significance using a Student test.
>>> Are
>>> all the parameters statistically significant?*
>>>
>>>
>>>
>>> **My code:**
>>>
>>> For the first three distributions, I answered well for questions one
>>> and
>>> two which are in italics. But I have a problem with the last one.
>>>
>>> library(readxl)
>>>
>>> Data <- read_excel("Data_project.xlsx", sheet = 2, skip = 5, col_names
>>> =
>>> FALSE)
>>>
>>> #y variable to explain, Nikkei 225 index
>>>
>>> y <- Data[16]
>>>
>>> # x variable explanatory variable, Australian Dollar vs. US Dollar
>>>
>>> x <- Data[30]
>>>
>>>
>>>
>>> returns_y = diff(as.matrix(log(y)),1)
>>>
>>> returns_x = diff(as.matrix(log(x)),1)
>>>
>>> returnsy_std = scale(returns_y)
>>>
>>>
>>>
>>> #1. Estimate the parameters by maximum likelihood
>>>
>>> #Gaussian distribution N(0, 1)
>>>
>>>
>>>
>>> mu=0
>>>
>>> sigma=0.1
>>>
>>> para0 = c(mu,sigma)
>>>
>>>
>>>
>>> loglikG<-function(para,returns_y)
>>>
>>> {
>>>
>>> ? mu = para[1]
>>>
>>> ? sigma =? para[2]
>>>
>>> ? print(para)
>>>
>>> logl=sum(log(dnorm((returns_y-mu)/sigma, 0, 1)/sigma))
>>>
>>> ? return(-logl)
>>>
>>> }
>>>
>>>
>>>
>>> loglikG(para0,returns_y)
>>>
>>> fit <- optim(para0, loglikG, gr=NULL, returns_y,
>>> method="BFGS",hessian=T)
>>>
>>>
>>>
>>> paraopt<- fit[["par"]]
>>>
>>>
>>>
>>> Hessian = fit$hessian
>>>
>>> invh = solve(Hessian)
>>>
>>>
>>>
>>> t1= sqrt(invh[1,1])
>>>
>>> t2=sqrt(invh[2,2])
>>>
>>> testzmu = paraopt[1]/t1
>>>
>>> testzvar = paraopt[2]/t2
>>>
>>> print(testzmu)
>>>
>>> print(testzvar)
>>>
>>>
>>>
>>>
>>>
>>> #T-student
>>>
>>>
>>>
>>> para_t=c(0,0.012,5)
>>>
>>>
>>>
>>> loglikt <- function(para,returns_y){
>>>
>>> ? mut=para[1]
>>>
>>> ? sigmat=para[2]
>>>
>>> ? nu=para[3]
>>>
>>> m=-sum(log(dt((returns_y-mut)/sigmat, df=nu)/sigmat))
>>>
>>>
>>>
>>> ? return(m)
>>>
>>> }
>>>
>>>
>>>
>>> loglikt(para_t,returns_y)
>>>
>>>
>>>
>>> output_t= optim(para_t, loglikt, gr=NULL, returns_y, method="BFGS",
>>> hessian=TRUE)
>>>
>>> paraopt_t <- output_t[["par"]]
>>>
>>>
>>>
>>> Hessian_t = output_t$hessian
>>>
>>> invh_t = solve(Hessian_t)
>>>
>>>
>>>
>>> t1_t= sqrt(invh_t[1,1])
>>>
>>> t2_t=sqrt(invh_t[2,2])
>>>
>>> t3_t= sqrt(invh_t[3,3])
>>>
>>> testzmu_t = paraopt_t[1]/t1_t
>>>
>>> testzvar_t = paraopt_t[2]/t2_t
>>>
>>> testznu_t = paraopt_t[3]/t3_t
>>>
>>> print(testzmu_t)
>>>
>>> print(testzvar_t)
>>>
>>> print(testznu_t)
>>>
>>>
>>>
>>> #Mixture of Gaussian finding initial values
>>>
>>> library(LaplacesDemon)
>>>
>>> eps = 0.001
>>>
>>> tolerance = 0.95
>>>
>>> paraMG = c(-0.02,0.03,0.6,0.8,0.7)
>>>
>>>
>>>
>>> likehoodMG <- function(para,returnsy_std)
>>>
>>> {
>>>
>>> ? muM12 = para[1:2]
>>>
>>> ? sigmaM12 = para[3:4]
>>>
>>> ? phi = para[5]
>>>
>>> ? p = c(phi,1-phi)
>>>
>>> LM=sum(log(dnormm(returnsy_std,muM12,sigmaM12,p=p)))
>>>
>>> ? mean_w = p[1]*muM12[1] + p[2]*muM12[2]
>>>
>>> ? var_w = p[1]*sqrt(sigmaM12[1]) + p[2]*sqrt(sigmaM12[2])
>>>
>>> if((abs(mean_w)>tolerance) || (abs(var_w-1)>tolerance)){
>>>
>>> ??? return(NaN)
>>>
>>> ? }
>>>
>>> ? return(-LM)
>>>
>>> }
>>>
>>>
>>>
>>> likehoodMG(paraMG,returnsy_std)
>>>
>>>
>>>
>>> outputMG = optim(paraMG, likehoodMG, gr=NULL, returnsy_std, method =
>>> "L-BFGS-B", hessian=TRUE,
>>>
>>> ????????????????? lower = c(eps,eps,-Inf,-Inf,eps), upper =
>>> c(Inf,Inf,Inf,Inf,1-eps))
>>>
>>>
>>>
>>> paraoptMG = outputMG[["par"]]
>>>
>>>
>>>
>>> #Mixture of Gaussian
>>>
>>> #(0.000345,0.023306)
>>>
>>> paraM
>>> =c(0.000345,0.023306,0.0253514,0.0010000,0.8715856,2.7857329,0.9659020)
>>>
>>>
>>>
>>> likehoodM <- function(para,returns_y)
>>>
>>> {
>>>
>>> ? muM1 = para[1]
>>>
>>> ? sigmaM = para[2]
>>>
>>> ? muM12 = para[3:4]
>>>
>>> ? sigmaM12 = para[5:6]
>>>
>>> ? phi = para[7]
>>>
>>> ? p = c(phi,1-phi)
>>>
>>> LM=sum(log(dnormm((returns_y-muM1)/sigmaM,muM12,sigmaM12,p=p)/sigmaM))
>>>
>>> ? return(-LM)
>>>
>>> }
>>>
>>>
>>>
>>> likehoodM(paraM,returns_y)
>>>
>>>
>>>
>>> outputM = optim(paraM, likehoodM, gr=NULL, returns_y, method =
>>> "L-BFGS-B",
>>> hessian=TRUE,
>>>
>>> ??????????????? lower = c(-Inf,eps,eps,eps,-Inf,-Inf,eps), upper =
>>> c(Inf,Inf,Inf,Inf,Inf,Inf,1-eps))
>>>
>>>
>>>
>>> paraoptM = outputM[["par"]]
>>>
>>>
>>>
>>> HM = outputM[["hessian"]]
>>>
>>> invHM = solve(HM)
>>>
>>>
>>>
>>> tm1 = sqrt(invHM[1,1])
>>>
>>> tm2 = sqrt(invHM[2,2])
>>>
>>> tm3 = sqrt(invHM[3,3])
>>>
>>> tm4 = sqrt(invHM[4,4])
>>>
>>> tm5 = sqrt(invHM[5,5])
>>>
>>> tm6 = sqrt(invHM[6,6])
>>>
>>> tm7 = sqrt(invHM[7,7])
>>>
>>>
>>>
>>> testtmum = (paraoptM[1]-0)/tm1
>>>
>>> testtsigmam = paraoptM[2]/tm2
>>>
>>> testtmum1 = (paraoptM[3])/tm3
>>>
>>> testtmum2 = paraoptM[4]/tm4
>>>
>>> testtvarm1 = paraoptM[5]/tm5
>>>
>>> testtvarm2 = paraoptM[6]/tm6
>>>
>>> testtphi = paraoptM[7]/tm7
>>>
>>> print(testtmum)
>>>
>>> print(testtsigmam)
>>>
>>> print(testtmum1)
>>>
>>> print(testtmum2)
>>>
>>> print(testtvarm1)
>>>
>>> print(testtvarm2)
>>>
>>> print(testtphi)
>>>
>>>
>>>
>>> #A generalized hyperbolic distribution GH(??, ??, ??, ??, ?).
>>>
>>> library(readxl)
>>>
>>> Data <- read_excel("Data_project.xlsx", sheet = 2, skip = 5, col_names
>>> =
>>> FALSE)
>>>
>>> #y variable to explain, Nikkei 225 index
>>>
>>> y <- Data[16]
>>>
>>> # x variable explanatory variable, Australian Dollar vs. US Dollar
>>>
>>> x <- Data[30]
>>>
>>>
>>>
>>> returns_y = diff(as.matrix(log(y)),1)
>>>
>>> returns_x = diff(as.matrix(log(x)),1)
>>>
>>> returnsy_std = scale(returns_y)
>>>
>>>
>>>
>>>
>>>
>>> #A generalized hyperbolic distribution GH(??, ??, ??, ??, ?).
>>>
>>>
>>>
>>> library(ghyp)
>>>
>>>
>>>
>>> para_gh= c(-0.00002,0.005,1,0,1,0.1,0.1) # mu,delta,alpha,beta,lambda
>>>
>>>
>>>
>>> loglikGH <- function(para,returns_y){
>>>
>>> ? mugh=para[1]
>>>
>>> ? sigmagh=para[2]
>>>
>>> ? alpha=para[3]
>>>
>>> ? beta = para[4]
>>>
>>> ? delta=para[5]
>>>
>>> ? chi=para[6]
>>>
>>> ? lamda=para[7]
>>>
>>> ? if(delta < abs(chi)){
>>>
>>> ??? return(10000)
>>>
>>> ? }else{
>>>
>>> ?? return(-sum(log(dghyp(((returns_y-mugh)/sigmagh),object =
>>> ghyp(alpha,beta,delta,chi,lamda))/sigmagh)))
>>>
>>> ? }
>>>
>>> }
>>>
>>>
>>>
>>>
>>>
>>> loglikGH(para_gh,returns_y)
>>>
>>>
>>>
>>> eps = 0.001
>>>
>>>
>>>
>>> outputGH= optim(para_gh, loglikGH, gr=NULL, returns_y, method =
>>> "L-BFGS-B",
>>> hessian=TRUE,
>>>
>>> ??????????????? lower = c(-Inf,eps,eps,eps,-Inf,-Inf,eps), upper =
>>> c(Inf,Inf,Inf,Inf,Inf,Inf,Inf))
>>>
>>>
>>>
>>> paraoptGH = outputGH[["par"]]
>>>
>>>
>>>
>>> HGH = outputGH[["hessian"]]
>>>
>>> invHGM = solve(HGH)
>>>
>>> tm1_H = sqrt(invHGM[1,1])
>>>
>>> tm2_H = sqrt(invHGM[2,2])
>>>
>>> tm3_H = sqrt(invHGM[3,3])
>>>
>>> tm4_H = sqrt(invHGM[4,4])
>>>
>>> tm5_H = sqrt(invHGM[5,5])
>>>
>>> tm6_H = sqrt(invHGM[6,6])
>>>
>>> tm7_H = sqrt(invHGM[7,7])
>>>
>>>
>>>
>>> testtmuH = (paraoptGH[1]-0)/tm1_H
>>>
>>> testtsigmaH = paraoptGH[2]/tm2_H
>>>
>>> testtalpha = (paraoptGH[3])/tm3_H
>>>
>>> testtbetha = paraoptGH[4]/tm4_H
>>>
>>> testtdelta = paraoptGH[5]/tm5_H
>>>
>>> testtvchi = paraoptGH[6]/tm6_H
>>>
>>> testtlambda = paraoptGH[7]/tm7
>>>
>>>
>>>
>>> print(testtmuH)
>>>
>>> print(testtsigmaH)
>>>
>>> testtalpha
>>>
>>> testtbetha
>>>
>>> testtdelta
>>>
>>> testtvchi
>>>
>>> testtlambda
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sat Dec 21 19:38:06 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sat, 21 Dec 2019 19:38:06 +0100
Subject: [R] how to initialize values of mtry for R.Forest
Message-ID: <CA+nrPnuwKtS5=EsH7sTD93rHPsqWrhQ8Z5enaKuxKV2DJZPmcg@mail.gmail.com>

Hi, I am using Simulated Annealing to tune the parameters of the R.Forest.
The code I use is below:

My question is that did I do correctly when I used the values 1:24 in the
optim function of the Simulated annealing? I used 1:24 because my number of
features in the dataset are 24, and the mtry should be between 1-num of
features I guess.

obj <- function(param, maximize = FALSE) {
  mod <- train(log10(bugs) ~ ., data = training,
               method = "rf",
               preProc = c("center", "scale", "zv"),
               metric = "MAE",
               trControl = ctrl,

               tuneGrid = data.frame(mtry = 10^(param[1])))

                if(maximize)
    -getTrainPerf(mod)[, "TrainMAE"] else
      getTrainPerf(mod)[, "TrainMAE"]
}
num_mods <- 50

## Simulated annealing from base R

san_res <- optim(par = c(1:24), fn = obj, method = "SANN",
                 control = list(maxit = num_mods))
san_res

	[[alternative HTML version deleted]]


From j@vedbtk111 @end|ng |rom gm@||@com  Sun Dec 22 15:10:24 2019
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Sun, 22 Dec 2019 15:10:24 +0100
Subject: [R] How to find the absolute residuals in train function
Message-ID: <CAJhui+vsNfJD9Ha96S7GTPboSQ64zCViOjYXq+W-v9UdO0UikQ@mail.gmail.com>

Hello

I am using caret's train function and it gives me the results (MAE or RMSE
in this case). How can I find the absolute residuals i.e. the difference
between the predicted and actual values of test data. I am using the
following code, but it does not work (give error message).

bo_mod <- train(log10(Price) ~ ., data = tr,
                method = "svmRadial",

                metric = "MAE",
                trControl = ctrl,

                preProc = c("center", "scale", "zv"),
                tuneGrid = data.frame(sigma = 10^(bo_search$Best_Par[1]),
                C = 10^(1)))
postResample(predict(bo_mod, ts), log10(ts$Price))/// till here I get the
output, but when I use the following

res=log10(tr$Price) - predict(bo_search, tr)

I get the error:  Error in UseMethod("predict") :
  no applicable method for 'predict' applied to an object of class
"c('double', 'numeric')"

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Sun Dec 22 17:07:59 2019
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Sun, 22 Dec 2019 16:07:59 +0000
Subject: [R] How to find the absolute residuals in train function
In-Reply-To: <CAJhui+vsNfJD9Ha96S7GTPboSQ64zCViOjYXq+W-v9UdO0UikQ@mail.gmail.com>
References: <CAJhui+vsNfJD9Ha96S7GTPboSQ64zCViOjYXq+W-v9UdO0UikQ@mail.gmail.com>
Message-ID: <452add27-d185-d8d0-7c95-a805c8170d1b@dewey.myzen.co.uk>

Dear Javed

Comment in-line

On 22/12/2019 14:10, javed khan wrote:
> Hello
> 
> I am using caret's train function and it gives me the results (MAE or RMSE
> in this case). How can I find the absolute residuals i.e. the difference
> between the predicted and actual values of test data. I am using the
> following code, but it does not work (give error message).
> 
> bo_mod <- train(log10(Price) ~ ., data = tr,
>                  method = "svmRadial",
> 
>                  metric = "MAE",
>                  trControl = ctrl,
> 
>                  preProc = c("center", "scale", "zv"),
>                  tuneGrid = data.frame(sigma = 10^(bo_search$Best_Par[1]),
>                  C = 10^(1)))
> postResample(predict(bo_mod, ts), log10(ts$Price))/// till here I get the
> output, but when I use the following
> 
> res=log10(tr$Price) - predict(bo_search, tr)

Did you mean bo_search or bo_mod?
> 
> I get the error:  Error in UseMethod("predict") :
>    no applicable method for 'predict' applied to an object of class
> "c('double', 'numeric')"
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sun Dec 22 18:15:56 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sun, 22 Dec 2019 18:15:56 +0100
Subject: [R] all the MAE metric values are missing (Error message)
Message-ID: <CA+nrPnvK7zH7SKhfiumHGxf-9MxgN2Mb2D-RJt83bBEb_86jbA@mail.gmail.com>

I am using the following code to tune the 4 parameters of Gradient Boosting
algorithm using Simulated annealing (optim). When I run the program, after
few seconds it stops and displays the following error:

I point out here that the same code works for RF ( mtry parameter) and SVM
(cost and sigma parameters). So, I guess the problem should be in the 4
parameters of GBM

Something is wrong; all the MAE metric values are missing:
      RMSE        Rsquared        MAE
 Min.   : NA   Min.   : NA   Min.   : NA
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
 Median : NA   Median : NA   Median : NA
 Mean   :NaN   Mean   :NaN   Mean   :NaN
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
 Max.   : NA   Max.   : NA   Max.   : NA
 NA's   :1     NA's   :1     NA's   :1

Code is here/// If you need the  dataset, I can attach in the email

d=readARFF("dat.arff")   ///DATA IS REGRESSION BASED

index <- createDataPartition(log10(d$Price), p = .70,list = FALSE)
tr <- d[index, ]
ts <- d[-index, ]

index_2 <- createFolds(log10(tr$Price), returnTrain = TRUE, list = TRUE)
ctrl <- trainControl(method = "cv", index = index_2)

obj <- function(param, maximize = FALSE) {
  mod <- train(log10(Price) ~ ., data = tr,
               method = "gbm",
               preProc = c("center", "scale", "zv"),
               metric = "MAE",
               trControl = ctrl,
       //HERE IN tuneGrid WHEN I USE PARAMETERS FOR SVM    AND RF, IT
WORKS, BUT FOR GBM, IT DOES NOT WORK

               tuneGrid = data.frame(n.trees = 10^(param[1]),
interaction.depth = 10^(param[2]),
                                     shrinkage=10^(param[3]),
n.minobsinnode=10^(param[4])))

  if(maximize)
    -getTrainPerf(mod)[, "TrainMAE"] else
      getTrainPerf(mod)[, "TrainMAE"]
}
num_mods <- 50

## Simulated annealing from base R

/// I JUST USED HERE SOME INITIAL POINTS OF THE 4 PARAMETERS OF GBM

san_res <- optim(par = c(10,1,0.1,1), fn = obj, method = "SANN",
                 control = list(maxit = num_mods))
san_res

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Dec 22 18:23:29 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 22 Dec 2019 09:23:29 -0800
Subject: [R] all the MAE metric values are missing (Error message)
In-Reply-To: <CA+nrPnvK7zH7SKhfiumHGxf-9MxgN2Mb2D-RJt83bBEb_86jbA@mail.gmail.com>
References: <CA+nrPnvK7zH7SKhfiumHGxf-9MxgN2Mb2D-RJt83bBEb_86jbA@mail.gmail.com>
Message-ID: <8a4cdcf4-96f6-42e6-263b-7a28f3e44183@comcast.net>

You need to read the Posting Guide (and study the options of the gmail 
interface). This is a plain text mailing list and the server does not 
accept attachments that are anything other than .txt or .pdf files.


-- 

David.

On 12/22/19 9:15 AM, Neha gupta wrote:
> I am using the following code to tune the 4 parameters of Gradient Boosting
> algorithm using Simulated annealing (optim). When I run the program, after
> few seconds it stops and displays the following error:
>
> I point out here that the same code works for RF ( mtry parameter) and SVM
> (cost and sigma parameters). So, I guess the problem should be in the 4
> parameters of GBM
>
> Something is wrong; all the MAE metric values are missing:
>        RMSE        Rsquared        MAE
>   Min.   : NA   Min.   : NA   Min.   : NA
>   1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
>   Median : NA   Median : NA   Median : NA
>   Mean   :NaN   Mean   :NaN   Mean   :NaN
>   3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
>   Max.   : NA   Max.   : NA   Max.   : NA
>   NA's   :1     NA's   :1     NA's   :1
>
> Code is here/// If you need the  dataset, I can attach in the email
>
> d=readARFF("dat.arff")   ///DATA IS REGRESSION BASED
>
> index <- createDataPartition(log10(d$Price), p = .70,list = FALSE)
> tr <- d[index, ]
> ts <- d[-index, ]
>
> index_2 <- createFolds(log10(tr$Price), returnTrain = TRUE, list = TRUE)
> ctrl <- trainControl(method = "cv", index = index_2)
>
> obj <- function(param, maximize = FALSE) {
>    mod <- train(log10(Price) ~ ., data = tr,
>                 method = "gbm",
>                 preProc = c("center", "scale", "zv"),
>                 metric = "MAE",
>                 trControl = ctrl,
>         //HERE IN tuneGrid WHEN I USE PARAMETERS FOR SVM    AND RF, IT
> WORKS, BUT FOR GBM, IT DOES NOT WORK
>
>                 tuneGrid = data.frame(n.trees = 10^(param[1]),
> interaction.depth = 10^(param[2]),
>                                       shrinkage=10^(param[3]),
> n.minobsinnode=10^(param[4])))
>
>    if(maximize)
>      -getTrainPerf(mod)[, "TrainMAE"] else
>        getTrainPerf(mod)[, "TrainMAE"]
> }
> num_mods <- 50
>
> ## Simulated annealing from base R
>
> /// I JUST USED HERE SOME INITIAL POINTS OF THE 4 PARAMETERS OF GBM
>
> san_res <- optim(par = c(10,1,0.1,1), fn = obj, method = "SANN",
>                   control = list(maxit = num_mods))
> san_res
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sun Dec 22 23:22:01 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 23 Dec 2019 09:22:01 +1100
Subject: [R] all the MAE metric values are missing (Error message)
In-Reply-To: <CA+nrPnvK7zH7SKhfiumHGxf-9MxgN2Mb2D-RJt83bBEb_86jbA@mail.gmail.com>
References: <CA+nrPnvK7zH7SKhfiumHGxf-9MxgN2Mb2D-RJt83bBEb_86jbA@mail.gmail.com>
Message-ID: <CA+8X3fW7b35KhR9LGAAZMNJYx1A7BmUH+dwairvX1gVWWQUsyQ@mail.gmail.com>

Hi Neha,
The error message looks suspicious, as it refers to "all the MAEs"
while there is only one NA value in the summary. I would carefully
check the object that you are passing to san_res.

Jim

On Mon, Dec 23, 2019 at 4:17 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>
> I am using the following code to tune the 4 parameters of Gradient Boosting
> algorithm using Simulated annealing (optim). When I run the program, after
> few seconds it stops and displays the following error:
>
> I point out here that the same code works for RF ( mtry parameter) and SVM
> (cost and sigma parameters). So, I guess the problem should be in the 4
> parameters of GBM
>
> Something is wrong; all the MAE metric values are missing:
>       RMSE        Rsquared        MAE
>  Min.   : NA   Min.   : NA   Min.   : NA
>  1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
>  Median : NA   Median : NA   Median : NA
>  Mean   :NaN   Mean   :NaN   Mean   :NaN
>  3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
>  Max.   : NA   Max.   : NA   Max.   : NA
>  NA's   :1     NA's   :1     NA's   :1
>


From v|n|@h@v|@h @end|ng |rom gm@||@com  Mon Dec 23 00:02:04 2019
From: v|n|@h@v|@h @end|ng |rom gm@||@com (Vinish Vishwanathan)
Date: Mon, 23 Dec 2019 10:02:04 +1100
Subject: [R] R API Call Failure Help
Message-ID: <CAEAxrNqx81rhJL6Vg+mb6QAb1yAoDXOgo_1A261TEAhzHZB64w@mail.gmail.com>

Hello All,

I just subscribed to this mail list and needed some help on an ongoing
issue with details stated below

Issue: An API call from R Shiny App to a server in Cloud fails with error:

Error:*  SSL read: error:00000000:lib(0):func(0):reason(0), errno 110
*  Connection died, retrying a fresh connect
*  Closing connection 18

Details: I am using the httr to do a POST call to the API.

Help Needed: Anyone from experience calling APIs from R, if can help to
identify the cause for the error.

My feeling is, its because of http Keep Alive and anyone parameter of it
which is not respected/expired, but not sure.

-- 
Regards
Vinish Viswanathan

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Dec 23 00:44:19 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 22 Dec 2019 15:44:19 -0800
Subject: [R] R API Call Failure Help
In-Reply-To: <CAEAxrNqx81rhJL6Vg+mb6QAb1yAoDXOgo_1A261TEAhzHZB64w@mail.gmail.com>
References: <CAEAxrNqx81rhJL6Vg+mb6QAb1yAoDXOgo_1A261TEAhzHZB64w@mail.gmail.com>
Message-ID: <CAGxFJbRkGObn-aYMWHa2_Xvo0gitf20pKG-zi8K6cZ3tY-Pawg@mail.gmail.com>

I think this is the wrong list. Shiny is an RStudio app and is not part of
R. You need to post on the RStudio site.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Dec 22, 2019 at 3:15 PM Vinish Vishwanathan <vinish.vish at gmail.com>
wrote:

> Hello All,
>
> I just subscribed to this mail list and needed some help on an ongoing
> issue with details stated below
>
> Issue: An API call from R Shiny App to a server in Cloud fails with error:
>
> Error:*  SSL read: error:00000000:lib(0):func(0):reason(0), errno 110
> *  Connection died, retrying a fresh connect
> *  Closing connection 18
>
> Details: I am using the httr to do a POST call to the API.
>
> Help Needed: Anyone from experience calling APIs from R, if can help to
> identify the cause for the error.
>
> My feeling is, its because of http Keep Alive and anyone parameter of it
> which is not respected/expired, but not sure.
>
> --
> Regards
> Vinish Viswanathan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Mon Dec 23 00:54:15 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Mon, 23 Dec 2019 00:54:15 +0100
Subject: [R] all the MAE metric values are missing (Error message)
In-Reply-To: <CA+8X3fW7b35KhR9LGAAZMNJYx1A7BmUH+dwairvX1gVWWQUsyQ@mail.gmail.com>
References: <CA+nrPnvK7zH7SKhfiumHGxf-9MxgN2Mb2D-RJt83bBEb_86jbA@mail.gmail.com>
 <CA+8X3fW7b35KhR9LGAAZMNJYx1A7BmUH+dwairvX1gVWWQUsyQ@mail.gmail.com>
Message-ID: <CA+nrPns37wQrFPKiHcf=ZDkJAOy1EFE2BrqTr3GWd_GjBxun4w@mail.gmail.com>

Hi Jim

The objective function is passed to san_res where we have defined the 4
parameters of gbm and the values are initialized in san_res.

The output variable price has only three values: 0, 1, 2 (like categorical
values), so someone told me try to remove the log10 from the price.

I am not sure what to do, I spent two days but did not fix this issue.


On Sun, Dec 22, 2019 at 11:22 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Neha,
> The error message looks suspicious, as it refers to "all the MAEs"
> while there is only one NA value in the summary. I would carefully
> check the object that you are passing to san_res.
>
> Jim
>
> On Mon, Dec 23, 2019 at 4:17 AM Neha gupta <neha.bologna90 at gmail.com>
> wrote:
> >
> > I am using the following code to tune the 4 parameters of Gradient
> Boosting
> > algorithm using Simulated annealing (optim). When I run the program,
> after
> > few seconds it stops and displays the following error:
> >
> > I point out here that the same code works for RF ( mtry parameter) and
> SVM
> > (cost and sigma parameters). So, I guess the problem should be in the 4
> > parameters of GBM
> >
> > Something is wrong; all the MAE metric values are missing:
> >       RMSE        Rsquared        MAE
> >  Min.   : NA   Min.   : NA   Min.   : NA
> >  1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
> >  Median : NA   Median : NA   Median : NA
> >  Mean   :NaN   Mean   :NaN   Mean   :NaN
> >  3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
> >  Max.   : NA   Max.   : NA   Max.   : NA
> >  NA's   :1     NA's   :1     NA's   :1
> >
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Mon Dec 23 03:12:06 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 23 Dec 2019 13:12:06 +1100
Subject: [R] all the MAE metric values are missing (Error message)
In-Reply-To: <CA+nrPns37wQrFPKiHcf=ZDkJAOy1EFE2BrqTr3GWd_GjBxun4w@mail.gmail.com>
References: <CA+nrPnvK7zH7SKhfiumHGxf-9MxgN2Mb2D-RJt83bBEb_86jbA@mail.gmail.com>
 <CA+8X3fW7b35KhR9LGAAZMNJYx1A7BmUH+dwairvX1gVWWQUsyQ@mail.gmail.com>
 <CA+nrPns37wQrFPKiHcf=ZDkJAOy1EFE2BrqTr3GWd_GjBxun4w@mail.gmail.com>
Message-ID: <CA+8X3fXRTHZrYGq3CNDQhbEnk0bMcpxTd+uadLo5r8X3-ZPPow@mail.gmail.com>

Hi Neha,
Well, that's a clue to why you are getting NAs:

log10(0)
[1] -Inf

Another possibility is that the values used in the initial calculation
have been read in as factors.

Jim

On Mon, Dec 23, 2019 at 10:55 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>
> Hi Jim
>
> The objective function is passed to san_res where we have defined the 4 parameters of gbm and the values are initialized in san_res.
>
> The output variable price has only three values: 0, 1, 2 (like categorical values), so someone told me try to remove the log10 from the price.
>


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Mon Dec 23 12:45:35 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Mon, 23 Dec 2019 12:45:35 +0100
Subject: [R] all the MAE metric values are missing (Error message)
In-Reply-To: <CA+8X3fXRTHZrYGq3CNDQhbEnk0bMcpxTd+uadLo5r8X3-ZPPow@mail.gmail.com>
References: <CA+nrPnvK7zH7SKhfiumHGxf-9MxgN2Mb2D-RJt83bBEb_86jbA@mail.gmail.com>
 <CA+8X3fW7b35KhR9LGAAZMNJYx1A7BmUH+dwairvX1gVWWQUsyQ@mail.gmail.com>
 <CA+nrPns37wQrFPKiHcf=ZDkJAOy1EFE2BrqTr3GWd_GjBxun4w@mail.gmail.com>
 <CA+8X3fXRTHZrYGq3CNDQhbEnk0bMcpxTd+uadLo5r8X3-ZPPow@mail.gmail.com>
Message-ID: <CA+nrPns0dwx42FeCMYYC3ERkVPaBco21vjUzQ=qdxhES48ARiQ@mail.gmail.com>

Hi Jim,

Another possibility is that the values used in the initial calculation
have been read in as factors

Which calculation you are talking about? I did not use factors as variable.

Regards

On Mon, Dec 23, 2019 at 3:12 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Neha,
> Well, that's a clue to why you are getting NAs:
>
> log10(0)
> [1] -Inf
>
> Another possibility is that the values used in the initial calculation
> have been read in as factors.
>
> Jim
>
> On Mon, Dec 23, 2019 at 10:55 AM Neha gupta <neha.bologna90 at gmail.com>
> wrote:
> >
> > Hi Jim
> >
> > The objective function is passed to san_res where we have defined the 4
> parameters of gbm and the values are initialized in san_res.
> >
> > The output variable price has only three values: 0, 1, 2 (like
> categorical values), so someone told me try to remove the log10 from the
> price.
> >
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Dec 23 15:29:05 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 23 Dec 2019 06:29:05 -0800
Subject: [R] R API Call Failure Help
In-Reply-To: <CAGxFJbRkGObn-aYMWHa2_Xvo0gitf20pKG-zi8K6cZ3tY-Pawg@mail.gmail.com>
References: <CAEAxrNqx81rhJL6Vg+mb6QAb1yAoDXOgo_1A261TEAhzHZB64w@mail.gmail.com>
 <CAGxFJbRkGObn-aYMWHa2_Xvo0gitf20pKG-zi8K6cZ3tY-Pawg@mail.gmail.com>
Message-ID: <56E8FBF9-8E36-4695-AF73-F19C618FADA3@dcn.davis.ca.us>

Shiny is not an app... it is a contributed R package on CRAN. Of course, with 15000 packages on CRAN this mailing list cannot necessarily support questions about all of them (read the Posting Guide).

That said, this question does not seem like the use of shiny is necessarily relevant because shiny itself does not define nor support calls to APIs. That is, I am not convinced that a shiny support forum is the right place to get an answer.

Given this, you (OP) may be able to make a reproducible example in R [1][2][3] that does not involve shiny and we could at least help identify which forum should be consulted. Of course this reprex would be useful to post in whatever forum appears to be relevant, or it could help you to understand the problem well enough to solve it yourself.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 


On December 22, 2019 3:44:19 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>I think this is the wrong list. Shiny is an RStudio app and is not part
>of
>R. You need to post on the RStudio site.
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sun, Dec 22, 2019 at 3:15 PM Vinish Vishwanathan
><vinish.vish at gmail.com>
>wrote:
>
>> Hello All,
>>
>> I just subscribed to this mail list and needed some help on an
>ongoing
>> issue with details stated below
>>
>> Issue: An API call from R Shiny App to a server in Cloud fails with
>error:
>>
>> Error:*  SSL read: error:00000000:lib(0):func(0):reason(0), errno 110
>> *  Connection died, retrying a fresh connect
>> *  Closing connection 18
>>
>> Details: I am using the httr to do a POST call to the API.
>>
>> Help Needed: Anyone from experience calling APIs from R, if can help
>to
>> identify the cause for the error.
>>
>> My feeling is, its because of http Keep Alive and anyone parameter of
>it
>> which is not respected/expired, but not sure.
>>
>> --
>> Regards
>> Vinish Viswanathan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jo@ec|@ud|o@|@r|@ @end|ng |rom gm@||@com  Mon Dec 23 15:36:00 2019
From: jo@ec|@ud|o@|@r|@ @end|ng |rom gm@||@com (Jose Claudio Faria)
Date: Mon, 23 Dec 2019 11:36:00 -0300
Subject: [R] Tinn-R project: new version (6.01.01.03) released
Message-ID: <CAN+Emd_dhnRNv3AmcTu4JA7S8yp2FJEQz8zqCSf91T9mWqTiSw@mail.gmail.com>

Hi,

A new version of Tinn-R project (6.01.01.03) was released today.

Download:
- https://nbcgib.uesc.br/tinnr/en/download
- https://sourceforge.net/projects/tinn-r/files/Tinn-R setup/

What is new:
- https://nbcgib.uesc.br/tinnr/en/download#patch
- https://sourceforge.net/projects/tinn-r/files/Tinn-R setup/6.1.1.3/

Best,
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms;
if you have good software, you have arms and legs;
if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

	[[alternative HTML version deleted]]


From m@|||P@dpo@t @end|ng |rom gm@||@com  Mon Dec 23 15:56:35 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Mon, 23 Dec 2019 17:56:35 +0300
Subject: [R] Split
Message-ID: <CAH6117KOzTBkx_z=Ya3HRRztCY_H9HDV+Mw1bqKd6q1_+FF5xQ@mail.gmail.com>

I have
mydata$var

and I have
mydata$group #two group

I would like to split
mydata$var
by
mydata$group #to get var1 and var2

And then get
summary (var1, var2)  #this is my finite aim

How to encode it all?


From bgunter@4567 @end|ng |rom gm@||@com  Mon Dec 23 16:18:29 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 23 Dec 2019 07:18:29 -0800
Subject: [R] Split
In-Reply-To: <CAH6117KOzTBkx_z=Ya3HRRztCY_H9HDV+Mw1bqKd6q1_+FF5xQ@mail.gmail.com>
References: <CAH6117KOzTBkx_z=Ya3HRRztCY_H9HDV+Mw1bqKd6q1_+FF5xQ@mail.gmail.com>
Message-ID: <CAGxFJbSmoS6wwzgsQmXZFq6PJdH6GUiBo87ppObnEUH2QWShAA@mail.gmail.com>

?ave

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 23, 2019 at 6:57 AM Medic <mailiPadpost at gmail.com> wrote:

> I have
> mydata$var
>
> and I have
> mydata$group #two group
>
> I would like to split
> mydata$var
> by
> mydata$group #to get var1 and var2
>
> And then get
> summary (var1, var2)  #this is my finite aim
>
> How to encode it all?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Dec 23 16:24:01 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 23 Dec 2019 07:24:01 -0800
Subject: [R] R API Call Failure Help
In-Reply-To: <56E8FBF9-8E36-4695-AF73-F19C618FADA3@dcn.davis.ca.us>
References: <CAEAxrNqx81rhJL6Vg+mb6QAb1yAoDXOgo_1A261TEAhzHZB64w@mail.gmail.com>
 <CAGxFJbRkGObn-aYMWHa2_Xvo0gitf20pKG-zi8K6cZ3tY-Pawg@mail.gmail.com>
 <56E8FBF9-8E36-4695-AF73-F19C618FADA3@dcn.davis.ca.us>
Message-ID: <CAGxFJbQ9j96vrpWhMFE+jWrBHPtO0b0hJfkmprg5DRtsGaKNPQ@mail.gmail.com>

Thanks. I stand corrected. But...

https://shiny.rstudio.com/

Cheers,
Bert

On Mon, Dec 23, 2019 at 6:29 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Shiny is not an app... it is a contributed R package on CRAN. Of course,
> with 15000 packages on CRAN this mailing list cannot necessarily support
> questions about all of them (read the Posting Guide).
>
> That said, this question does not seem like the use of shiny is
> necessarily relevant because shiny itself does not define nor support calls
> to APIs. That is, I am not convinced that a shiny support forum is the
> right place to get an answer.
>
> Given this, you (OP) may be able to make a reproducible example in R
> [1][2][3] that does not involve shiny and we could at least help identify
> which forum should be consulted. Of course this reprex would be useful to
> post in whatever forum appears to be relevant, or it could help you to
> understand the problem well enough to solve it yourself.
>
> [1]
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> [2] http://adv-r.had.co.nz/Reproducibility.html
>
> [3] https://cran.r-project.org/web/packages/reprex/index.html (read the
> vignette)
>
>
> On December 22, 2019 3:44:19 PM PST, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >I think this is the wrong list. Shiny is an RStudio app and is not part
> >of
> >R. You need to post on the RStudio site.
> >
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Sun, Dec 22, 2019 at 3:15 PM Vinish Vishwanathan
> ><vinish.vish at gmail.com>
> >wrote:
> >
> >> Hello All,
> >>
> >> I just subscribed to this mail list and needed some help on an
> >ongoing
> >> issue with details stated below
> >>
> >> Issue: An API call from R Shiny App to a server in Cloud fails with
> >error:
> >>
> >> Error:*  SSL read: error:00000000:lib(0):func(0):reason(0), errno 110
> >> *  Connection died, retrying a fresh connect
> >> *  Closing connection 18
> >>
> >> Details: I am using the httr to do a POST call to the API.
> >>
> >> Help Needed: Anyone from experience calling APIs from R, if can help
> >to
> >> identify the cause for the error.
> >>
> >> My feeling is, its because of http Keep Alive and anyone parameter of
> >it
> >> which is not respected/expired, but not sure.
> >>
> >> --
> >> Regards
> >> Vinish Viswanathan
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Dec 23 16:30:29 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 23 Dec 2019 07:30:29 -0800
Subject: [R] Split
In-Reply-To: <CAH6117KOzTBkx_z=Ya3HRRztCY_H9HDV+Mw1bqKd6q1_+FF5xQ@mail.gmail.com>
References: <CAH6117KOzTBkx_z=Ya3HRRztCY_H9HDV+Mw1bqKd6q1_+FF5xQ@mail.gmail.com>
Message-ID: <78CD1208-4C67-402B-82D9-C85C8269AB47@dcn.davis.ca.us>

Not clear what you mean by 

summary (var1, var2)

? That is not a legal way to call summary. Perhaps

mt <- mtcars[,c("cyl","hp")]
mt$cyl <- factor( mt$cyl )
mtl <- split(mt[,"hp",drop=FALSE], mt$cyl)
lapply(mtl,summary)

On December 23, 2019 6:56:35 AM PST, Medic <mailiPadpost at gmail.com> wrote:
>I have
>mydata$var
>
>and I have
>mydata$group #two group
>
>I would like to split
>mydata$var
>by
>mydata$group #to get var1 and var2
>
>And then get
>summary (var1, var2)  #this is my finite aim
>
>How to encode it all?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@|||P@dpo@t @end|ng |rom gm@||@com  Mon Dec 23 18:14:53 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Mon, 23 Dec 2019 20:14:53 +0300
Subject: [R] Split
Message-ID: <CAH6117KU4rFg18335kqsf5pbE2eLHinFSR3JTV6h1eXReCHPVw@mail.gmail.com>

I have
mydata$var
#this is ONE group of patients

And I would like to get
median and ICR of mydata$var.

How can I get this?
With summary (mydata$var)!

Ok!

And now I would like to get THE SAME, but for TWO group: male and
female (which are contained in the group mydata$var)

How can I get this?
First I need to split mydata$var by mydata$sex, and then take:

summary (for male)
and
summary (for female)

That's all I want

Bert,
ave(mydata$var, madata$sex, FUN=median)
gives me:
[1] 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6
5.6 5.6 5.6 5.6
[21] 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0
6.0 6.0 6.0 6.0
What is it?
It is an endless(???) repetition of the median.
Moreover, there is no ICR.

Jeff,
your constructions are too complicated for me
===
P.S. Such simple thing and so difficult?! (I begin think about the Excel.)


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Dec 23 18:41:07 2019
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 23 Dec 2019 17:41:07 +0000
Subject: [R] all the MAE metric values are missing (Error message)
In-Reply-To: <CA+nrPns0dwx42FeCMYYC3ERkVPaBco21vjUzQ=qdxhES48ARiQ@mail.gmail.com>
References: <CA+nrPnvK7zH7SKhfiumHGxf-9MxgN2Mb2D-RJt83bBEb_86jbA@mail.gmail.com>
 <CA+8X3fW7b35KhR9LGAAZMNJYx1A7BmUH+dwairvX1gVWWQUsyQ@mail.gmail.com>
 <CA+nrPns37wQrFPKiHcf=ZDkJAOy1EFE2BrqTr3GWd_GjBxun4w@mail.gmail.com>
 <CA+8X3fXRTHZrYGq3CNDQhbEnk0bMcpxTd+uadLo5r8X3-ZPPow@mail.gmail.com>
 <CA+nrPns0dwx42FeCMYYC3ERkVPaBco21vjUzQ=qdxhES48ARiQ@mail.gmail.com>
Message-ID: <f93033fb-1e58-fc43-1bf5-8e6905f50ef3@dewey.myzen.co.uk>

What Jim is alluding to is that sometimes in the process of reading in 
data a small typo can mean that what was intended to be a numeric 
variable is read in as a factor. So he was suggesting that you double 
check that this has not happened to you.

Michael

On 23/12/2019 11:45, Neha gupta wrote:
> Hi Jim,
> 
> Another possibility is that the values used in the initial calculation
> have been read in as factors
> 
> Which calculation you are talking about? I did not use factors as variable.
> 
> Regards
> 
> On Mon, Dec 23, 2019 at 3:12 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> 
>> Hi Neha,
>> Well, that's a clue to why you are getting NAs:
>>
>> log10(0)
>> [1] -Inf
>>
>> Another possibility is that the values used in the initial calculation
>> have been read in as factors.
>>
>> Jim
>>
>> On Mon, Dec 23, 2019 at 10:55 AM Neha gupta <neha.bologna90 at gmail.com>
>> wrote:
>>>
>>> Hi Jim
>>>
>>> The objective function is passed to san_res where we have defined the 4
>> parameters of gbm and the values are initialized in san_res.
>>>
>>> The output variable price has only three values: 0, 1, 2 (like
>> categorical values), so someone told me try to remove the log10 from the
>> price.
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Dec 23 18:44:07 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 23 Dec 2019 20:44:07 +0300
Subject: [R] Split
In-Reply-To: <CAH6117KOzTBkx_z=Ya3HRRztCY_H9HDV+Mw1bqKd6q1_+FF5xQ@mail.gmail.com>
References: <CAH6117KOzTBkx_z=Ya3HRRztCY_H9HDV+Mw1bqKd6q1_+FF5xQ@mail.gmail.com>
Message-ID: <20191223204407.6a34fa1d@trisector>

On Mon, 23 Dec 2019 17:56:35 +0300
Medic <mailiPadpost at gmail.com> wrote:

> I would like to split
> mydata$var
> by
> mydata$group #to get var1 and var2

There is the split() function that does exactly that (except it returns
a list instead of multiple variables)...

> And then get
> summary (var1, var2)  #this is my finite aim

...and you can either use lapply() on the list returned by split() or
tapply() to both split the dataset into groups and call summary() on
each in one expression. See ?tapply and example(tapply) for more info.

-- 
Best regards,
Ivan


From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Dec 23 19:14:28 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 23 Dec 2019 13:14:28 -0500
Subject: [R] Converting AIS Message to Number
Message-ID: <CAMOcQfPAiA9UEirBdcEu4rRX6ZM6ufX-MJRk=E75WoXqWwdbGA@mail.gmail.com>

Dear friends,

Hope you are doing great. I would like to process an AIS file (which comes
in either a .txt or .csv format). The AIS file is contained in a specific
path, say C:/AISFiles/File.txt. The file contains messages like the
following:
!AIVDM,2,1,2,A,5EPtgd42CRtIADNU at N0<E98v1 at TM8F222222220m1HB586R`0?0kk3k`40CP,0*2D,1532995201
(all of this is a single message).

Is there a way to make R automatically retrieve the latest file saved on
the path, take each message and convert it to a number?

Best regards,

Paul

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Dec 23 20:06:50 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 23 Dec 2019 11:06:50 -0800
Subject: [R] Converting AIS Message to Number
In-Reply-To: <CAMOcQfPAiA9UEirBdcEu4rRX6ZM6ufX-MJRk=E75WoXqWwdbGA@mail.gmail.com>
References: <CAMOcQfPAiA9UEirBdcEu4rRX6ZM6ufX-MJRk=E75WoXqWwdbGA@mail.gmail.com>
Message-ID: <CAGxFJbSLBZSDq6FQhDs2VB7WVjMqcY-D0YUi8AgU0Qcv+SE80A@mail.gmail.com>

The "digest" package might be what you're looking for: messages --> numerics
Or perhaps you want to create a hash in R. Search on "hashing in R" or
similar for info on this.

See ?file.info  for obtaining file info, including date/time info.



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 23, 2019 at 10:14 AM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear friends,
>
> Hope you are doing great. I would like to process an AIS file (which comes
> in either a .txt or .csv format). The AIS file is contained in a specific
> path, say C:/AISFiles/File.txt. The file contains messages like the
> following:
> !AIVDM,2,1,2,A,5EPtgd42CRtIADNU at N0<E98v1 at TM8F222222220m1HB586R
> `0?0kk3k`40CP,0*2D,1532995201
> (all of this is a single message).
>
> Is there a way to make R automatically retrieve the latest file saved on
> the path, take each message and convert it to a number?
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m||o@@z@rkov|c @end|ng |rom gm@||@com  Mon Dec 23 20:18:08 2019
From: m||o@@z@rkov|c @end|ng |rom gm@||@com (=?UTF-8?B?TWlsb8WhIMW9YXJrb3ZpxIc=?=)
Date: Mon, 23 Dec 2019 20:18:08 +0100
Subject: [R] Split
In-Reply-To: <CAH6117KOzTBkx_z=Ya3HRRztCY_H9HDV+Mw1bqKd6q1_+FF5xQ@mail.gmail.com>
References: <CAH6117KOzTBkx_z=Ya3HRRztCY_H9HDV+Mw1bqKd6q1_+FF5xQ@mail.gmail.com>
Message-ID: <CANgWSHC67Z9+iySW0UU2SMXVVHOYso=X1C2iR0GZxqkVN1HfJw@mail.gmail.com>

If I understand correctly you need summary by group. I would suggest
arsenal package and tableby

tab1 <- tableby(group ~ anova(var, "meansd", digits=1) +  #mean and sd +
round to 1 digit + anova
                  kwt(var, "medianq1q3", digits=1) , #median q1 and q3 +
round to 1 digit + Kruskal-Wallis
                 data=sn.l.v2.t0)
summary(tab1,text=TRUE) #output as txt to console
write2word(tab1,"tab1.docx", pfootnote=TRUE) #save as formatted word table

or even simpler using Rcmdr - Statistics - Numerical summaries and tha
choose summarize by groups

Milos

On Mon, 23 Dec 2019 at 15:57, Medic <mailiPadpost at gmail.com> wrote:

> I have
> mydata$var
>
> and I have
> mydata$group #two group
>
> I would like to split
> mydata$var
> by
> mydata$group #to get var1 and var2
>
> And then get
> summary (var1, var2)  #this is my finite aim
>
> How to encode it all?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Dec 23 20:27:05 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 23 Dec 2019 11:27:05 -0800
Subject: [R] Split
In-Reply-To: <CAH6117KU4rFg18335kqsf5pbE2eLHinFSR3JTV6h1eXReCHPVw@mail.gmail.com>
References: <CAH6117KU4rFg18335kqsf5pbE2eLHinFSR3JTV6h1eXReCHPVw@mail.gmail.com>
Message-ID: <CAGxFJbQvk-OJJ1LGf11AY=e2v+RiQtcqPOJ1T1=Qi1jmC-xTJA@mail.gmail.com>

Do you mean IQR? -- I don't know what ICR means.
If so, see IQR.

More generally see ?by or more generally ?tapply to obtain whatever sort of
summary you want.

e.g.

> d <-data.frame( x = runif(10), w = rep(c("a","b"),5))
> by(d$x, d$w, FUN = function(x)c(median = median(x),IQR = IQR(x)))
d$w: a
   median       IQR
0.5469662 0.4548506
--------------------------------------------------------------
d$w: b
   median       IQR
0.6860975 0.3456893


-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 23, 2019 at 9:15 AM Medic <mailiPadpost at gmail.com> wrote:

> I have
> mydata$var
> #this is ONE group of patients
>
> And I would like to get
> median and ICR of mydata$var.
>
> How can I get this?
> With summary (mydata$var)!
>
> Ok!
>
> And now I would like to get THE SAME, but for TWO group: male and
> female (which are contained in the group mydata$var)
>
> How can I get this?
> First I need to split mydata$var by mydata$sex, and then take:
>
> summary (for male)
> and
> summary (for female)
>
> That's all I want
>
> Bert,
> ave(mydata$var, madata$sex, FUN=median)
> gives me:
> [1] 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6
> 5.6 5.6 5.6 5.6
> [21] 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0
> 6.0 6.0 6.0 6.0
> What is it?
> It is an endless(???) repetition of the median.
> Moreover, there is no ICR.
>
> Jeff,
> your constructions are too complicated for me
> ===
> P.S. Such simple thing and so difficult?! (I begin think about the Excel.)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m||o@@z@rkov|c @end|ng |rom gm@||@com  Mon Dec 23 20:44:57 2019
From: m||o@@z@rkov|c @end|ng |rom gm@||@com (=?UTF-8?B?TWlsb8WhIMW9YXJrb3ZpxIc=?=)
Date: Mon, 23 Dec 2019 20:44:57 +0100
Subject: [R] Split
In-Reply-To: <CAGxFJbQvk-OJJ1LGf11AY=e2v+RiQtcqPOJ1T1=Qi1jmC-xTJA@mail.gmail.com>
References: <CAH6117KU4rFg18335kqsf5pbE2eLHinFSR3JTV6h1eXReCHPVw@mail.gmail.com>
 <CAGxFJbQvk-OJJ1LGf11AY=e2v+RiQtcqPOJ1T1=Qi1jmC-xTJA@mail.gmail.com>
Message-ID: <CANgWSHB+=ANvextt7Q+5uKyWkgQJpEHu95Tb0KB2GSAUZpGrfg@mail.gmail.com>

J have just seen your follow-up post (out of tread). I don?t want to be
rude or patronizing but few caveats.

Neither R nor R help are meant to be user friendly. Learning curve is steep
but very rewarding at the end.

Problem you have can be solved in a literary hundred ways. Unfortunately,
your question was not a reproducible example and you got most complicated
answer. Apply entourage is kind of dark art in R, so I offered different
solutions, and hope that my answer helped.

Being medic too, I understand your pain, but for the star I suggest Rcmdr.


Regards,


Milo?


On Mon, 23 Dec 2019 at 20:36, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Do you mean IQR? -- I don't know what ICR means.
> If so, see IQR.
>
> More generally see ?by or more generally ?tapply to obtain whatever sort of
> summary you want.
>
> e.g.
>
> > d <-data.frame( x = runif(10), w = rep(c("a","b"),5))
> > by(d$x, d$w, FUN = function(x)c(median = median(x),IQR = IQR(x)))
> d$w: a
>    median       IQR
> 0.5469662 0.4548506
> --------------------------------------------------------------
> d$w: b
>    median       IQR
> 0.6860975 0.3456893
>
>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Dec 23, 2019 at 9:15 AM Medic <mailiPadpost at gmail.com> wrote:
>
> > I have
> > mydata$var
> > #this is ONE group of patients
> >
> > And I would like to get
> > median and ICR of mydata$var.
> >
> > How can I get this?
> > With summary (mydata$var)!
> >
> > Ok!
> >
> > And now I would like to get THE SAME, but for TWO group: male and
> > female (which are contained in the group mydata$var)
> >
> > How can I get this?
> > First I need to split mydata$var by mydata$sex, and then take:
> >
> > summary (for male)
> > and
> > summary (for female)
> >
> > That's all I want
> >
> > Bert,
> > ave(mydata$var, madata$sex, FUN=median)
> > gives me:
> > [1] 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6 5.6
> > 5.6 5.6 5.6 5.6
> > [21] 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0
> > 6.0 6.0 6.0 6.0
> > What is it?
> > It is an endless(???) repetition of the median.
> > Moreover, there is no ICR.
> >
> > Jeff,
> > your constructions are too complicated for me
> > ===
> > P.S. Such simple thing and so difficult?! (I begin think about the
> Excel.)
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon Dec 23 21:14:36 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 24 Dec 2019 09:14:36 +1300
Subject: [R] Tinn-R project: new version (6.01.01.03) released
In-Reply-To: <CAN+Emd_dhnRNv3AmcTu4JA7S8yp2FJEQz8zqCSf91T9mWqTiSw@mail.gmail.com>
References: <CAN+Emd_dhnRNv3AmcTu4JA7S8yp2FJEQz8zqCSf91T9mWqTiSw@mail.gmail.com>
Message-ID: <CAB8pepzD7YthuwQP9iP2_rTrrGZH3Z=xtVeLPk0AXORm-=QndA@mail.gmail.com>

Hi Jose,

That's awesome.
I used Tinn-R, back in 2006, when I starting learning nontrivial R programming.
I used it extensively, before shifting to my own (still incomplete)
programming environment.

Back then, Emacs (with ESS) had the monopoly on Linux, and Tinn-R was
leading the race on Windows.
You've made extremely valuable contributions to the R community.
And I look forward to seeing future progress...


Abs


On Tue, Dec 24, 2019 at 3:40 AM Jose Claudio Faria
<joseclaudio.faria at gmail.com> wrote:
>
> Hi,
>
> A new version of Tinn-R project (6.01.01.03) was released today.
>
> Download:
> - https://nbcgib.uesc.br/tinnr/en/download
> - https://sourceforge.net/projects/tinn-r/files/Tinn-R setup/
>
> What is new:
> - https://nbcgib.uesc.br/tinnr/en/download#patch
> - https://sourceforge.net/projects/tinn-r/files/Tinn-R setup/6.1.1.3/
>
> Best,
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> Jose Claudio Faria
> UESC/DCET/Brasil
> joseclaudio.faria at gmail.com
> Telefones:
> 55(73)3680.5545 - UESC
> 55(73)99966.9100 - VIVO
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>
> If you have software to deal with statistics, you have arms;
> if you have good software, you have arms and legs;
> if you have software like R, you have arms, legs and wings...
> the height of your flight depends only on you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @@|w@_e|@ty11 @end|ng |rom hotm@||@com  Mon Dec 23 15:32:26 2019
From: @@|w@_e|@ty11 @end|ng |rom hotm@||@com (Salwa El-Aty)
Date: Mon, 23 Dec 2019 14:32:26 +0000
Subject: [R] R code required
Message-ID: <MR2P264MB057824C496854C894A452E1D9D2E0@MR2P264MB0578.FRAP264.PROD.OUTLOOK.COM>



Dear Sir
I want to help me about to send  the  R Code of paper which title
Inference of Generalized  endpoint inflated  binomial regression . In .   2017
Best Regards
Salwa. A.Mousa

Sent from my Samsung device

	[[alternative HTML version deleted]]


From K|mber|y@Ste|nm@nn @end|ng |rom cdpr@c@@gov  Mon Dec 23 20:14:01 2019
From: K|mber|y@Ste|nm@nn @end|ng |rom cdpr@c@@gov (Steinmann, Kimberly@CDPR)
Date: Mon, 23 Dec 2019 19:14:01 +0000
Subject: [R] help with if statement with two conditions
Message-ID: <BY5PR09MB42638C93B70146DAC5D5FBA7CB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>

Hi - i am not super familiar with R, but need to modify my predecessor's R code so that if a variable is >0 and < 0.5, it will be replaced with <1. I have looked at a bunch of forum threads on the subject, but cannot seem to get anything to work Any help at what i might be doing wrong much appreciated. I am definitely an R newbie!

current code that works:
      v_lbs_list <- ""
      for (j in 2:(p_num_years+1)) {
         if (is.na(v_trends_lbs[i, j])) {
            v_lbs <- ' 0 '
         } else if (v_trends_lbs[i, j] < 0.5) {
            v_lbs <- ' $<$1 '
         } else {
            v_lbs <- format(round(v_trends_lbs[i, j]), big.mark=",", scientific=FALSE)
         }
         v_lbs_list <- paste(v_lbs_list, ' & ', v_lbs)
      }

my attempt to add a >0 that gets an error  pointing at the & sign:
      v_lbs_list <- ""
      for (j in 2:(p_num_years+1)) {
         if (is.na(v_trends_lbs[i, j])) {
            v_lbs <- ' 0 '
         } else if (v_trends_lbs[i, j] < 0.5) & (v_trends_lbs[i, j] > 0) {
            v_lbs <- ' $<$1 '
         } else {
            v_lbs <- format(round(v_trends_lbs[i, j]), big.mark=",", scientific=FALSE)
         }
         v_lbs_list <- paste(v_lbs_list, ' & ', v_lbs)
      }

Thanks for any help!


CONFIDENTIALITY NOTICE: This e-mail message, including a...{{dropped:10}}


From m@z@t|@nmex|co @end|ng |rom y@hoo@com  Mon Dec 23 21:36:37 2019
From: m@z@t|@nmex|co @end|ng |rom y@hoo@com (Felipe Carrillo)
Date: Mon, 23 Dec 2019 20:36:37 +0000 (UTC)
Subject: [R] Tinn-R project: new version (6.01.01.03) released
In-Reply-To: <CAB8pepzD7YthuwQP9iP2_rTrrGZH3Z=xtVeLPk0AXORm-=QndA@mail.gmail.com>
References: <CAN+Emd_dhnRNv3AmcTu4JA7S8yp2FJEQz8zqCSf91T9mWqTiSw@mail.gmail.com>
 <CAB8pepzD7YthuwQP9iP2_rTrrGZH3Z=xtVeLPk0AXORm-=QndA@mail.gmail.com>
Message-ID: <1264833425.3016890.1577133397512@mail.yahoo.com>

Jos?

Sent from Yahoo Mail on Android 
 
  On Mon, Dec 23, 2019 at 12:15 PM, Abby Spurdle<spurdle.a at gmail.com> wrote:   Hi Jose,Same here, I use tinn-R on a daily basis..thanks for the update and have a merry christmas!!!!

That's awesome.
I used Tinn-R, back in 2006, when I starting learning nontrivial R programming.
I used it extensively, before shifting to my own (still incomplete)
programming environment.

Back then, Emacs (with ESS) had the monopoly on Linux, and Tinn-R was
leading the race on Windows.
You've made extremely valuable contributions to the R community.
And I look forward to seeing future progress...


Abs


On Tue, Dec 24, 2019 at 3:40 AM Jose Claudio Faria
<joseclaudio.faria at gmail.com> wrote:
>
> Hi,
>
> A new version of Tinn-R project (6.01.01.03) was released today.
>
> Download:
> - https://nbcgib.uesc.br/tinnr/en/download
> - https://sourceforge.net/projects/tinn-r/files/Tinn-R setup/
>
> What is new:
> - https://nbcgib.uesc.br/tinnr/en/download#patch
> - https://sourceforge.net/projects/tinn-r/files/Tinn-R setup/6.1.1.3/
>
> Best,
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> Jose Claudio Faria
> UESC/DCET/Brasil
> joseclaudio.faria at gmail.com
> Telefones:
> 55(73)3680.5545 - UESC
> 55(73)99966.9100 - VIVO
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>
> If you have software to deal with statistics, you have arms;
> if you have good software, you have arms and legs;
> if you have software like R, you have arms, legs and wings...
> the height of your flight depends only on you!
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Mon Dec 23 21:49:03 2019
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Mon, 23 Dec 2019 15:49:03 -0500
Subject: [R] help with if statement with two conditions
In-Reply-To: <BY5PR09MB42638C93B70146DAC5D5FBA7CB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>
References: <BY5PR09MB42638C93B70146DAC5D5FBA7CB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>
Message-ID: <CAJc=yOH8SxnFx5402-E1L7a1Xos8zguJPz=EV=0bYnu=ecQgcg@mail.gmail.com>

What does the error message say?

On Mon, Dec 23, 2019, 3:33 PM Steinmann, Kimberly at CDPR <
Kimberly.Steinmann at cdpr.ca.gov> wrote:

> Hi - i am not super familiar with R, but need to modify my predecessor's R
> code so that if a variable is >0 and < 0.5, it will be replaced with <1. I
> have looked at a bunch of forum threads on the subject, but cannot seem to
> get anything to work Any help at what i might be doing wrong much
> appreciated. I am definitely an R newbie!
>
> current code that works:
>       v_lbs_list <- ""
>       for (j in 2:(p_num_years+1)) {
>          if (is.na(v_trends_lbs[i, j])) {
>             v_lbs <- ' 0 '
>          } else if (v_trends_lbs[i, j] < 0.5) {
>             v_lbs <- ' $<$1 '
>          } else {
>             v_lbs <- format(round(v_trends_lbs[i, j]), big.mark=",",
> scientific=FALSE)
>          }
>          v_lbs_list <- paste(v_lbs_list, ' & ', v_lbs)
>       }
>
> my attempt to add a >0 that gets an error  pointing at the & sign:
>       v_lbs_list <- ""
>       for (j in 2:(p_num_years+1)) {
>          if (is.na(v_trends_lbs[i, j])) {
>             v_lbs <- ' 0 '
>          } else if (v_trends_lbs[i, j] < 0.5) & (v_trends_lbs[i, j] > 0) {
>             v_lbs <- ' $<$1 '
>          } else {
>             v_lbs <- format(round(v_trends_lbs[i, j]), big.mark=",",
> scientific=FALSE)
>          }
>          v_lbs_list <- paste(v_lbs_list, ' & ', v_lbs)
>       }
>
> Thanks for any help!
>
>
> CONFIDENTIALITY NOTICE: This e-mail message, including a...{{dropped:10}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Dec 23 22:08:55 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 23 Dec 2019 13:08:55 -0800
Subject: [R] R code required
In-Reply-To: <MR2P264MB057824C496854C894A452E1D9D2E0@MR2P264MB0578.FRAP264.PROD.OUTLOOK.COM>
References: <MR2P264MB057824C496854C894A452E1D9D2E0@MR2P264MB0578.FRAP264.PROD.OUTLOOK.COM>
Message-ID: <0F525538-D328-4DEA-91EF-6795F0FB6503@dcn.davis.ca.us>

You are corresponding to a mailing list, but you need to be corresponding with the author of the paper you are referring to. I have no idea who that is or what the paper is that you are referring to.

On December 23, 2019 6:32:26 AM PST, Salwa El-Aty <salwa_elaty11 at hotmail.com> wrote:
>
>
>Dear Sir
>I want to help me about to send  the  R Code of paper which title
>Inference of Generalized  endpoint inflated  binomial regression . In .
>  2017
>Best Regards
>Salwa. A.Mousa
>
>Sent from my Samsung device
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Dec 23 22:12:01 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 23 Dec 2019 13:12:01 -0800
Subject: [R] help with if statement with two conditions
In-Reply-To: <BY5PR09MB42638C93B70146DAC5D5FBA7CB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>
References: <BY5PR09MB42638C93B70146DAC5D5FBA7CB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>
Message-ID: <CAGxFJbQ+dh32YG7Qy+EwVHJwT7m_PHfOrRj-5nfM0eoSWGFZng@mail.gmail.com>

WITHOUT going through your code carefully (but where is v_lbs first
defined?), maybe something like this is what you want:

> x <- seq(-2,2,.25)
> x
 [1] -2.00 -1.75 -1.50 -1.25 -1.00 -0.75 -0.50 -0.25  0.00  0.25  0.50
 0.75  1.00
[14]  1.25  1.50  1.75  2.00
> x <- ifelse(x>0 & x<1, '<1', format(round(x,2), big.mark=",",
scientific=FALSE) )
> x
 [1] "-2.00" "-1.75" "-1.50" "-1.25" "-1.00" "-0.75" "-0.50" "-0.25" " 0.00"
[10] "<1"    "<1"    "<1"    " 1.00" " 1.25" " 1.50" " 1.75" " 2.00"

... or maybe not. You decide.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 23, 2019 at 12:33 PM Steinmann, Kimberly at CDPR <
Kimberly.Steinmann at cdpr.ca.gov> wrote:

> Hi - i am not super familiar with R, but need to modify my predecessor's R
> code so that if a variable is >0 and < 0.5, it will be replaced with <1. I
> have looked at a bunch of forum threads on the subject, but cannot seem to
> get anything to work Any help at what i might be doing wrong much
> appreciated. I am definitely an R newbie!
>
> current code that works:
>       v_lbs_list <- ""
>       for (j in 2:(p_num_years+1)) {
>          if (is.na(v_trends_lbs[i, j])) {
>             v_lbs <- ' 0 '
>          } else if (v_trends_lbs[i, j] < 0.5) {
>             v_lbs <- ' $<$1 '
>          } else {
>             v_lbs <- format(round(v_trends_lbs[i, j]), big.mark=",",
> scientific=FALSE)
>          }
>          v_lbs_list <- paste(v_lbs_list, ' & ', v_lbs)
>       }
>
> my attempt to add a >0 that gets an error  pointing at the & sign:
>       v_lbs_list <- ""
>       for (j in 2:(p_num_years+1)) {
>          if (is.na(v_trends_lbs[i, j])) {
>             v_lbs <- ' 0 '
>          } else if (v_trends_lbs[i, j] < 0.5) & (v_trends_lbs[i, j] > 0) {
>             v_lbs <- ' $<$1 '
>          } else {
>             v_lbs <- format(round(v_trends_lbs[i, j]), big.mark=",",
> scientific=FALSE)
>          }
>          v_lbs_list <- paste(v_lbs_list, ' & ', v_lbs)
>       }
>
> Thanks for any help!
>
>
> CONFIDENTIALITY NOTICE: This e-mail message, including a...{{dropped:10}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@|||P@dpo@t @end|ng |rom gm@||@com  Mon Dec 23 22:27:14 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Tue, 24 Dec 2019 00:27:14 +0300
Subject: [R] Split
Message-ID: <CAH6117Lo=oPNDF98NA0GkFh9DK=-zx0h89EPkzZvXPMmswyDMA@mail.gmail.com>

Dear Burt, you gave a very elegant solution. Many thanks!
Jeff, I understand your solution, thank you very much for your time!
Colleague Milos, patronage is exactly what I need. I hope for your
further guidance! (Rcmdr is not enough for some purposes.)
Dear Ivan, I used your solution! It's the most understandable for me! Thanks!!!


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Dec 23 23:26:13 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 24 Dec 2019 11:26:13 +1300
Subject: [R] Alignment of the title in a key for xyplot in lattice.
Message-ID: <f642747d-2dc8-b69c-2e41-720acd5cea32@auckland.ac.nz>


The title of a key seems to be horizontally centred in the key; I would 
like to have it aligned with the left hand edge.  I.e. I would like the 
first letter of the title to have the same horizontal position as the 
first letters of the text strings.

E.g. in the attached example I would like the "P" in "Point type" to be 
directly above the "o" in "obsd" and "f" in "fitted".

Is there any way to effect this?  Thanks.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
A non-text attachment was scrubbed...
Name: xmpl.pdf
Type: application/pdf
Size: 10139 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20191224/8b4f5eb6/attachment.pdf>

From drj|m|emon @end|ng |rom gm@||@com  Tue Dec 24 00:33:24 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 24 Dec 2019 10:33:24 +1100
Subject: [R] help with if statement with two conditions
In-Reply-To: <BY5PR09MB42638C93B70146DAC5D5FBA7CB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>
References: <BY5PR09MB42638C93B70146DAC5D5FBA7CB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>
Message-ID: <CA+8X3fXgVD2qqjjYp2w2dAhK+GqJNW94pXU9suvgDu-sROvF+g@mail.gmail.com>

Hi Kimberley,
Since you are using a loop and therefore testing one value of
v_trends_lbs at a time, the "&" in the "if" statement should be "&&".
Pinching Bert's example but using a for loop instead of ifelse:

x <- seq(-2,2,.25)
v_lbs<-rep("",length(x))
for(i in 1:length(x)) {
 if(is.na(x[i])) v_lbs<-"0"
  else {
   if(x[i] < 0.51 && x[i] > 0) v_lbs[i]<-"<1"
   else v_lbs[i] <- format(round(x[i]), big.mark=",",scientific=FALSE)
 }
}
x
v_lbs

I think this gives you the "right" answer, as I have used 0.51 to
avoid the rounding problem at 0.5. I can see that the output is
feeding into something else, and an incorrect value at the end of your
calculations would be more difficult to track back. Bert's "ifelse" is
a more elegant way to do this, although not quote as easy for the
beginner to understand.

Jim

On Tue, Dec 24, 2019 at 7:33 AM Steinmann, Kimberly at CDPR
<Kimberly.Steinmann at cdpr.ca.gov> wrote:
>
> Hi - i am not super familiar with R, but need to modify my predecessor's R code so that if a variable is >0 and < 0.5, it will be replaced with <1. I have looked at a bunch of forum threads on the subject, but cannot seem to get anything to work Any help at what i might be doing wrong much appreciated. I am definitely an R newbie!
>
> current code that works:
>       v_lbs_list <- ""
>       for (j in 2:(p_num_years+1)) {
>          if (is.na(v_trends_lbs[i, j])) {
>             v_lbs <- ' 0 '
>          } else if (v_trends_lbs[i, j] < 0.5) {
>             v_lbs <- ' $<$1 '
>          } else {
>             v_lbs <- format(round(v_trends_lbs[i, j]), big.mark=",", scientific=FALSE)
>          }
>          v_lbs_list <- paste(v_lbs_list, ' & ', v_lbs)
>       }
>
> my attempt to add a >0 that gets an error  pointing at the & sign:
>       v_lbs_list <- ""
>       for (j in 2:(p_num_years+1)) {
>          if (is.na(v_trends_lbs[i, j])) {
>             v_lbs <- ' 0 '
>          } else if (v_trends_lbs[i, j] < 0.5) & (v_trends_lbs[i, j] > 0) {
>             v_lbs <- ' $<$1 '
>          } else {
>             v_lbs <- format(round(v_trends_lbs[i, j]), big.mark=",", scientific=FALSE)
>          }
>          v_lbs_list <- paste(v_lbs_list, ' & ', v_lbs)
>       }
>
> Thanks for any help!
>
>
> CONFIDENTIALITY NOTICE: This e-mail message, including a...{{dropped:10}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Dec 24 00:45:48 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 24 Dec 2019 10:45:48 +1100
Subject: [R] Converting AIS Message to Number
In-Reply-To: <CAMOcQfPAiA9UEirBdcEu4rRX6ZM6ufX-MJRk=E75WoXqWwdbGA@mail.gmail.com>
References: <CAMOcQfPAiA9UEirBdcEu4rRX6ZM6ufX-MJRk=E75WoXqWwdbGA@mail.gmail.com>
Message-ID: <CA+8X3fUWBBqFfvMCwQGnvB05GbAaGeU+mjVBKGAJzbZ1RKg=zw@mail.gmail.com>

Hi Paul,
For your first question:

max(file.info(".")$mtime)
[1] "2019-12-21 21:04:19 AEDT"

As for the second, I didn't know what an AIS file was, so I googled
it. I still don't know, so I don't have a clue how to turn a string
like that into a number.

Jim

On Tue, Dec 24, 2019 at 5:14 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends,
>
> Hope you are doing great. I would like to process an AIS file (which comes
> in either a .txt or .csv format). The AIS file is contained in a specific
> path, say C:/AISFiles/File.txt. The file contains messages like the
> following:
> !AIVDM,2,1,2,A,5EPtgd42CRtIADNU at N0<E98v1 at TM8F222222220m1HB586R`0?0kk3k`40CP,0*2D,1532995201
> (all of this is a single message).
>
> Is there a way to make R automatically retrieve the latest file saved on
> the path, take each message and convert it to a number?
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Dec 24 00:49:37 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 24 Dec 2019 10:49:37 +1100
Subject: [R] help with if statement with two conditions
In-Reply-To: <BY5PR09MB4263C4082187AC46D0FA04DACB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>
References: <BY5PR09MB42638C93B70146DAC5D5FBA7CB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>
 <CA+8X3fXgVD2qqjjYp2w2dAhK+GqJNW94pXU9suvgDu-sROvF+g@mail.gmail.com>
 <BY5PR09MB4263C4082187AC46D0FA04DACB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>
Message-ID: <CA+8X3fV-G5qgJiN2bGdX=8V1NEJp+c4J-g=gf6+YvWfoz6JaBQ@mail.gmail.com>

Hi Kimberley,
Given the number of posts that read "I have a problem, please advise",
your concern for our mental welfare is a great Xmas present.

Jim

On Tue, Dec 24, 2019 at 10:38 AM Steinmann, Kimberly at CDPR
<Kimberly.Steinmann at cdpr.ca.gov> wrote:
>
> I am not sure how to close the thread - I hate to waste anyone's time on a problem that is no longer a problem! I am new to this forum
>


From drj|m|emon @end|ng |rom gm@||@com  Tue Dec 24 02:29:11 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 24 Dec 2019 12:29:11 +1100
Subject: [R] Alignment of the title in a key for xyplot in lattice.
In-Reply-To: <f642747d-2dc8-b69c-2e41-720acd5cea32@auckland.ac.nz>
References: <f642747d-2dc8-b69c-2e41-720acd5cea32@auckland.ac.nz>
Message-ID: <CA+8X3fXyGboXUfuA_e5PgnkS5Xm86Nw5hiiFbuTxSgZiVT6MSg@mail.gmail.com>

Hi Rolf,
Following the docs back to draw.key, It looks like the ellipsis
argument is ignored. I was hoping for a brilliant solution along the
lines of:

adj=0

that could be passed down the functions like a hot potato, but was disappointed.

Jim

On Tue, Dec 24, 2019 at 9:26 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> The title of a key seems to be horizontally centred in the key; I would
> like to have it aligned with the left hand edge.  I.e. I would like the
> first letter of the title to have the same horizontal position as the
> first letters of the text strings.
>
> E.g. in the attached example I would like the "P" in "Point type" to be
> directly above the "o" in "obsd" and "f" in "fitted".
>
> Is there any way to effect this?  Thanks.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From K|mber|y@Ste|nm@nn @end|ng |rom cdpr@c@@gov  Tue Dec 24 00:38:41 2019
From: K|mber|y@Ste|nm@nn @end|ng |rom cdpr@c@@gov (Steinmann, Kimberly@CDPR)
Date: Mon, 23 Dec 2019 23:38:41 +0000
Subject: [R] help with if statement with two conditions
In-Reply-To: <CA+8X3fXgVD2qqjjYp2w2dAhK+GqJNW94pXU9suvgDu-sROvF+g@mail.gmail.com>
References: <BY5PR09MB42638C93B70146DAC5D5FBA7CB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>
 <CA+8X3fXgVD2qqjjYp2w2dAhK+GqJNW94pXU9suvgDu-sROvF+g@mail.gmail.com>
Message-ID: <BY5PR09MB4263C4082187AC46D0FA04DACB2E0@BY5PR09MB4263.namprd09.prod.outlook.com>

Hi Jim, Burt and all who have been so helpful - very much appreciated!
I have managed to get the code to run correctly by extending the parentheses around the whole statement, including the &, rather than parentheses around the two clauses on either side of the &.
It seems to have done the trick!
I am not sure how to close the thread - I hate to waste anyone's time on a problem that is no longer a problem! I am new to this forum

Thanks again for all the feedback and help everyone!

-Kimberly

-----Original Message-----
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Monday, December 23, 2019 3:33 PM
To: Steinmann, Kimberly at CDPR <Kimberly.Steinmann at cdpr.ca.gov>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] help with if statement with two conditions

EXTERNAL:


Hi Kimberley,
Since you are using a loop and therefore testing one value of v_trends_lbs at a time, the "&" in the "if" statement should be "&&".
Pinching Bert's example but using a for loop instead of ifelse:

x <- seq(-2,2,.25)
v_lbs<-rep("",length(x))
for(i in 1:length(x)) {
 if(is.na(x[i])) v_lbs<-"0"
  else {
   if(x[i] < 0.51 && x[i] > 0) v_lbs[i]<-"<1"
   else v_lbs[i] <- format(round(x[i]), big.mark=",",scientific=FALSE)  } } x v_lbs

I think this gives you the "right" answer, as I have used 0.51 to avoid the rounding problem at 0.5. I can see that the output is feeding into something else, and an incorrect value at the end of your calculations would be more difficult to track back. Bert's "ifelse" is a more elegant way to do this, although not quote as easy for the beginner to understand.

Jim

On Tue, Dec 24, 2019 at 7:33 AM Steinmann, Kimberly at CDPR <Kimberly.Steinmann at cdpr.ca.gov> wrote:
>
> Hi - i am not super familiar with R, but need to modify my predecessor's R code so that if a variable is >0 and < 0.5, it will be replaced with <1. I have looked at a bunch of forum threads on the subject, but cannot seem to get anything to work Any help at what i might be doing wrong much appreciated. I am definitely an R newbie!
>
> current code that works:
>       v_lbs_list <- ""
>       for (j in 2:(p_num_years+1)) {
>          if (is.na(v_trends_lbs[i, j])) {
>             v_lbs <- ' 0 '
>          } else if (v_trends_lbs[i, j] < 0.5) {
>             v_lbs <- ' $<$1 '
>          } else {
>             v_lbs <- format(round(v_trends_lbs[i, j]), big.mark=",", scientific=FALSE)
>          }
>          v_lbs_list <- paste(v_lbs_list, ' & ', v_lbs)
>       }
>
> my attempt to add a >0 that gets an error  pointing at the & sign:
>       v_lbs_list <- ""
>       for (j in 2:(p_num_years+1)) {
>          if (is.na(v_trends_lbs[i, j])) {
>             v_lbs <- ' 0 '
>          } else if (v_trends_lbs[i, j] < 0.5) & (v_trends_lbs[i, j] > 0) {
>             v_lbs <- ' $<$1 '
>          } else {
>             v_lbs <- format(round(v_trends_lbs[i, j]), big.mark=",", scientific=FALSE)
>          }
>          v_lbs_list <- paste(v_lbs_list, ' & ', v_lbs)
>       }
>
> Thanks for any help!
>
>
> CONFIDENTIALITY NOTICE: This e-mail message, including
> a...{{dropped:10}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://gcc02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7CKimberly.Ste
> inmann%40cdpr.ca.gov%7C7007357d15244e97a63108d7880088a1%7C0fc528a55d14
> 4d0da7bef2487d8d0e30%7C0%7C1%7C637127408183702102&amp;sdata=x2ugp%2Bs%
> 2BYE%2BmCANwK0QIGtKnfOcHJ0Xpf%2BYZzUTgPxs%3D&amp;reserved=0
> PLEASE do read the posting guide
> https://gcc02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R
> -project.org%2Fposting-guide.html&amp;data=02%7C01%7CKimberly.Steinman
> n%40cdpr.ca.gov%7C7007357d15244e97a63108d7880088a1%7C0fc528a55d144d0da
> 7bef2487d8d0e30%7C0%7C1%7C637127408183702102&amp;sdata=sFBbNktlRfA4FZX
> 5qTQdkcNYOx8xNX6MGU2MKnFLoSE%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.
CONFIDENTIALITY NOTICE: This e-mail message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure, or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.

From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Dec 24 07:41:35 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 24 Dec 2019 19:41:35 +1300
Subject: [R] Alignment of the title in a key for xyplot in lattice.
In-Reply-To: <CA+8X3fXyGboXUfuA_e5PgnkS5Xm86Nw5hiiFbuTxSgZiVT6MSg@mail.gmail.com>
References: <f642747d-2dc8-b69c-2e41-720acd5cea32@auckland.ac.nz>
 <CA+8X3fXyGboXUfuA_e5PgnkS5Xm86Nw5hiiFbuTxSgZiVT6MSg@mail.gmail.com>
Message-ID: <8a9a9b07-88b4-9c11-3d3d-4e35f92632d3@auckland.ac.nz>


On 24/12/19 2:29 pm, Jim Lemon wrote:

> Hi Rolf,
> Following the docs back to draw.key, It looks like the ellipsis
> argument is ignored. I was hoping for a brilliant solution along the
> lines of:
> 
> adj=0
> 
> that could be passed down the functions like a hot potato, but was disappointed.

Thanks for giving it some thought.  Actually I've found a work-around: 
make the title the first entry of the text component of the key, with 
the corresponding entries of the other components being NA.  And 
omitting the "title" argument.

An example of the result is attached.  It satisfies me, at least! :-)

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
A non-text attachment was scrubbed...
Name: xmpl2.pdf
Type: application/pdf
Size: 10155 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20191224/2450278b/attachment.pdf>

From er|cjberger @end|ng |rom gm@||@com  Tue Dec 24 09:44:58 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 24 Dec 2019 10:44:58 +0200
Subject: [R] Alignment of the title in a key for xyplot in lattice.
In-Reply-To: <8a9a9b07-88b4-9c11-3d3d-4e35f92632d3@auckland.ac.nz>
References: <f642747d-2dc8-b69c-2e41-720acd5cea32@auckland.ac.nz>
 <CA+8X3fXyGboXUfuA_e5PgnkS5Xm86Nw5hiiFbuTxSgZiVT6MSg@mail.gmail.com>
 <8a9a9b07-88b4-9c11-3d3d-4e35f92632d3@auckland.ac.nz>
Message-ID: <CAGgJW77SJPK8HS4ODt5+mGRzY1LwudMc+XgccnSq03=ag96jwg@mail.gmail.com>

Lovely solution Rolf :-)

On Tue, Dec 24, 2019 at 8:42 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> On 24/12/19 2:29 pm, Jim Lemon wrote:
>
> > Hi Rolf,
> > Following the docs back to draw.key, It looks like the ellipsis
> > argument is ignored. I was hoping for a brilliant solution along the
> > lines of:
> >
> > adj=0
> >
> > that could be passed down the functions like a hot potato, but was
> disappointed.
>
> Thanks for giving it some thought.  Actually I've found a work-around:
> make the title the first entry of the text component of the key, with
> the corresponding entries of the other components being NA.  And
> omitting the "title" argument.
>
> An example of the result is attached.  It satisfies me, at least! :-)
>
> cheers,
>
> Rolf
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From deep@y@n@@@rk@r @end|ng |rom r-project@org  Tue Dec 24 08:08:49 2019
From: deep@y@n@@@rk@r @end|ng |rom r-project@org (Deepayan Sarkar)
Date: Tue, 24 Dec 2019 12:38:49 +0530
Subject: [R] Alignment of the title in a key for xyplot in lattice.
In-Reply-To: <CA+8X3fXyGboXUfuA_e5PgnkS5Xm86Nw5hiiFbuTxSgZiVT6MSg@mail.gmail.com>
References: <f642747d-2dc8-b69c-2e41-720acd5cea32@auckland.ac.nz>
 <CA+8X3fXyGboXUfuA_e5PgnkS5Xm86Nw5hiiFbuTxSgZiVT6MSg@mail.gmail.com>
Message-ID: <CADfFDC4QUMmTW5CgcpKXuKxm+DxsUarYivt=Q2QUmMzdVa4K4w@mail.gmail.com>

On Tue, Dec 24, 2019 at 6:59 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Rolf,
> Following the docs back to draw.key, It looks like the ellipsis
> argument is ignored. I was hoping for a brilliant solution along the
> lines of:
>
> adj=0
>
> that could be passed down the functions like a hot potato, but was disappointed.

Yes, the implementation of title is quite rudimentary, and should be
easy to enhance. The current invocation for drawing the title is
essentially

textGrob(label = key$title,
         gp = gpar(cex = key$cex.title,
                   lineheight = key$lineheight))

which translates to (with defaults)

textGrob(label = key$title,
         x = 0.5, y = 0.5, default.units = "npc", just = "centre",
         gp = gpar(cex = key$cex.title,
                   lineheight = key$lineheight))

To control the justification, the user needs to be able to specify at
least 'x' and 'just'. One should also be able to control other
graphical parameters.

A trickier issue is that the legend doesn't consider the title when
computing its width. I have never been able to decide whether it
should.

Anyway, I have some long-pending pull requests for improving legend
behaviour, which hopefully I will be able to get to soon. I will try
to address this at the same time.

-Deepayan


> Jim
>
> On Tue, Dec 24, 2019 at 9:26 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> >
> > The title of a key seems to be horizontally centred in the key; I would
> > like to have it aligned with the left hand edge.  I.e. I would like the
> > first letter of the title to have the same horizontal position as the
> > first letters of the text strings.
> >
> > E.g. in the attached example I would like the "P" in "Point type" to be
> > directly above the "o" in "obsd" and "f" in "fitted".
> >
> > Is there any way to effect this?  Thanks.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From A||@|@one1 @end|ng |rom hotm@||@com  Tue Dec 24 17:50:05 2019
From: A||@|@one1 @end|ng |rom hotm@||@com (Allaisone 1)
Date: Tue, 24 Dec 2019 16:50:05 +0000
Subject: [R] Time intervals is converted into seconds after converting list
 of dfs into a single Df.
Message-ID: <DB7PR09MB22984E3ABDB31217945EA31A80290@DB7PR09MB2298.eurprd09.prod.outlook.com>


Hi dear group ,

I have list of datframes with similar column names. I want to rebind all dataframes so I have a single dataframe. One of the column's in each df is of 'interval' time class which was generated from 'lubridate' package.

The problem is that when I convert the list of dfs into a single df using any of the below codes :

Library(plyr)
MySingleDf <- ldply(MyListOfDfs, data.frame)
Or
MySingleDf <- ldply(MyListOfDfs, rbind)
Or
MySingleDf <- rebind. fill (MyListOfDfs)

What heppens is that  time intervals which looks like : 2010-4-5 UTC--2011-7-9 UTC is converted into a single numeric value which seems to be the difference between the 2 dates in seconds.

When I use :
MySingleDf <- do.call ("rbind",MyListOfDfs)

The code is freezes and it shows like of the data are being analysed but no result. I have used this code previously for the same purpose but with another datse and it works perfectly.

What I want to see is that time intervals are shown as they are but not converted into seconds.

Could you please suggest any alternative syntax or modifications to my codes ?

Thank you so much in advance

Regards



	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Tue Dec 24 18:01:59 2019
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Tue, 24 Dec 2019 12:01:59 -0500
Subject: [R] 
 Time intervals is converted into seconds after converting list
 of dfs into a single Df.
In-Reply-To: <DB7PR09MB22984E3ABDB31217945EA31A80290@DB7PR09MB2298.eurprd09.prod.outlook.com>
References: <DB7PR09MB22984E3ABDB31217945EA31A80290@DB7PR09MB2298.eurprd09.prod.outlook.com>
Message-ID: <CAJc=yOFL3QzZSeG2MFnYOw=qkqTYd4bWp8tvWmDDQ3tb9e1WAg@mail.gmail.com>

You didn't provide a reproducible example for testing (or post in
plain text), but lubridate has an as.interval() function. You'll need
to be able to extract the start time, though, for use in the function.

On Tue, Dec 24, 2019 at 11:54 AM Allaisone 1 <Allaisone1 at hotmail.com> wrote:
>
>
> Hi dear group ,
>
> I have list of datframes with similar column names. I want to rebind all dataframes so I have a single dataframe. One of the column's in each df is of 'interval' time class which was generated from 'lubridate' package.
>
> The problem is that when I convert the list of dfs into a single df using any of the below codes :
>
> Library(plyr)
> MySingleDf <- ldply(MyListOfDfs, data.frame)
> Or
> MySingleDf <- ldply(MyListOfDfs, rbind)
> Or
> MySingleDf <- rebind. fill (MyListOfDfs)
>
> What heppens is that  time intervals which looks like : 2010-4-5 UTC--2011-7-9 UTC is converted into a single numeric value which seems to be the difference between the 2 dates in seconds.
>
> When I use :
> MySingleDf <- do.call ("rbind",MyListOfDfs)
>
> The code is freezes and it shows like of the data are being analysed but no result. I have used this code previously for the same purpose but with another datse and it works perfectly.
>
> What I want to see is that time intervals are shown as they are but not converted into seconds.
>
> Could you please suggest any alternative syntax or modifications to my codes ?
>
> Thank you so much in advance
>
> Regards
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From A||@|@one1 @end|ng |rom hotm@||@com  Tue Dec 24 19:53:20 2019
From: A||@|@one1 @end|ng |rom hotm@||@com (Allaisone 1)
Date: Tue, 24 Dec 2019 18:53:20 +0000
Subject: [R] 
 Time intervals is converted into seconds after converting list
 of dfs into a single Df.
In-Reply-To: <CAJc=yOFL3QzZSeG2MFnYOw=qkqTYd4bWp8tvWmDDQ3tb9e1WAg@mail.gmail.com>
References: <DB7PR09MB22984E3ABDB31217945EA31A80290@DB7PR09MB2298.eurprd09.prod.outlook.com>,
 <CAJc=yOFL3QzZSeG2MFnYOw=qkqTYd4bWp8tvWmDDQ3tb9e1WAg@mail.gmail.com>
Message-ID: <DB7PR09MB2298FDDF243F33411BCC404080290@DB7PR09MB2298.eurprd09.prod.outlook.com>

Hi dear Patrick ,

Thanks for your replay. Below is a reproducible example . First,  I generated two  similar Dfs with one column contains the interval. Then, I put the 2 dfs in a list. Now, converting this list into df provides different results depending on the code. See below for more details.


 # dataframe 1?

id <- c(1,1)?

dates1 <- c("2010/2/4","2011/2/4")?

dates2 <- c("2010/9/4","2011/1/1")?

df1 <- data.frame(id,dates1,dates2)?

df1[,2] <- as.Date(df1[,2])?

df1[,3] <- as.Date(df1[,3])?

df1$interaction <- intersect(interval(df1[1,2],df1[2,2]),interval(df1[1,3],df1[2,3]))?

  ?

  # Dataframe 2?

id <- c(2,2)?

dates1 <- c("2010/1/4","2011/2/4")?

dates2 <- c("2010/10/4","2011/1/16")?

df2 <- data.frame(id,dates1,dates2)?

df2[,2] <- as.Date(df1[,2])?

df2[,3] <- as.Date(df1[,3])?


df2$interaction <- intersect(interval(df1[1,2],df1[2,2]),interval(df1[1,3],df1[2,3]))?



 # 2 datframes in a list :?

 ListOfDFs <- list(df1,df2)?

 # Convert list of Dfs into a single df :-?

 SingDF <- ldply( ListOfDFs,data.frame)?

       # The interval has been converted into numbers which is not what I want.?

       #?but trying this code :
 SingDF <- do.call(rbind,ListOfDFs)?

       # It works perfectly but only with this example as? we have only 2 datframes. Howver, in my actual data I have? around 8000 datframes. Applying this code to it , make R code? freezes and I waited for many hours but it still freezes with? no results generated.?

 Could anyone please suggest any alternative syntax or modifications to the codes above?

Kind Regards
 ?



Sent from Outlook
________________________________
From: Patrick (Malone Quantitative) <malone at malonequantitative.com>
Sent: 24 December 2019 17:01:59
To: Allaisone 1 <Allaisone1 at hotmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Time intervals is converted into seconds after converting list of dfs into a single Df.

You didn't provide a reproducible example for testing (or post in
plain text), but lubridate has an as.interval() function. You'll need
to be able to extract the start time, though, for use in the function.

On Tue, Dec 24, 2019 at 11:54 AM Allaisone 1 <Allaisone1 at hotmail.com> wrote:
>
>
> Hi dear group ,
>
> I have list of datframes with similar column names. I want to rebind all dataframes so I have a single dataframe. One of the column's in each df is of 'interval' time class which was generated from 'lubridate' package.
>
> The problem is that when I convert the list of dfs into a single df using any of the below codes :
>
> Library(plyr)
> MySingleDf <- ldply(MyListOfDfs, data.frame)
> Or
> MySingleDf <- ldply(MyListOfDfs, rbind)
> Or
> MySingleDf <- rebind. fill (MyListOfDfs)
>
> What heppens is that  time intervals which looks like : 2010-4-5 UTC--2011-7-9 UTC is converted into a single numeric value which seems to be the difference between the 2 dates in seconds.
>
> When I use :
> MySingleDf <- do.call ("rbind",MyListOfDfs)
>
> The code is freezes and it shows like of the data are being analysed but no result. I have used this code previously for the same purpose but with another datse and it works perfectly.
>
> What I want to see is that time intervals are shown as they are but not converted into seconds.
>
> Could you please suggest any alternative syntax or modifications to my codes ?
>
> Thank you so much in advance
>
> Regards
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Dec 24 22:03:56 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 24 Dec 2019 13:03:56 -0800
Subject: [R] 
 Time intervals is converted into seconds after converting list
 of dfs into a single Df.
In-Reply-To: <DB7PR09MB2298FDDF243F33411BCC404080290@DB7PR09MB2298.eurprd09.prod.outlook.com>
References: <DB7PR09MB22984E3ABDB31217945EA31A80290@DB7PR09MB2298.eurprd09.prod.outlook.com>
 <CAJc=yOFL3QzZSeG2MFnYOw=qkqTYd4bWp8tvWmDDQ3tb9e1WAg@mail.gmail.com>
 <DB7PR09MB2298FDDF243F33411BCC404080290@DB7PR09MB2298.eurprd09.prod.outlook.com>
Message-ID: <CAGxFJbRdC_F68Lrtw_44UNpqtXNjYjS4CXgf82AbdCnkTQ69_g@mail.gmail.com>

1. "Similar" or "same" column names. The former is probably not going to
work.

2. Manipulations with data frames can consume a lot of memory. rbinding
8000 data frames is likely to be very slow with lots of time swapping
memory around(???). Perhaps try taking smaller bites (say 1000 at a time)
and then combining them. Or have you already tried this? If you do wish to
do this, wait to give experts a chance to tell you that my suggestion is
completely useless before you attempt it.

3. I'll let someone else resolve your dates problem, as I have never used
lubridate.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 24, 2019 at 12:38 PM Allaisone 1 <Allaisone1 at hotmail.com> wrote:

> Hi dear Patrick ,
>
> Thanks for your replay. Below is a reproducible example . First,  I
> generated two  similar Dfs with one column contains the interval. Then, I
> put the 2 dfs in a list. Now, converting this list into df provides
> different results depending on the code. See below for more details.
>
>
>  # dataframe 1
>
> id <- c(1,1)
>
> dates1 <- c("2010/2/4","2011/2/4")
>
> dates2 <- c("2010/9/4","2011/1/1")
>
> df1 <- data.frame(id,dates1,dates2)
>
> df1[,2] <- as.Date(df1[,2])
>
> df1[,3] <- as.Date(df1[,3])
>
> df1$interaction <-
> intersect(interval(df1[1,2],df1[2,2]),interval(df1[1,3],df1[2,3]))
>
>
>
>   # Dataframe 2
>
> id <- c(2,2)
>
> dates1 <- c("2010/1/4","2011/2/4")
>
> dates2 <- c("2010/10/4","2011/1/16")
>
> df2 <- data.frame(id,dates1,dates2)
>
> df2[,2] <- as.Date(df1[,2])
>
> df2[,3] <- as.Date(df1[,3])
>
>
> df2$interaction <-
> intersect(interval(df1[1,2],df1[2,2]),interval(df1[1,3],df1[2,3]))
>
>
>
>  # 2 datframes in a list :
>
>  ListOfDFs <- list(df1,df2)
>
>  # Convert list of Dfs into a single df :-
>
>  SingDF <- ldply( ListOfDFs,data.frame)
>
>        # The interval has been converted into numbers which is not what I
> want.
>
>        #but trying this code :
>  SingDF <- do.call(rbind,ListOfDFs)
>
>        # It works perfectly but only with this example as we have only 2
> datframes. Howver, in my actual data I have around 8000 datframes. Applying
> this code to it , make R code freezes and I waited for many hours but it
> still freezes with no results generated.
>
>  Could anyone please suggest any alternative syntax or modifications to
> the codes above?
>
> Kind Regards
>
>
>
>
> Sent from Outlook
> ________________________________
> From: Patrick (Malone Quantitative) <malone at malonequantitative.com>
> Sent: 24 December 2019 17:01:59
> To: Allaisone 1 <Allaisone1 at hotmail.com>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Subject: Re: [R] Time intervals is converted into seconds after converting
> list of dfs into a single Df.
>
> You didn't provide a reproducible example for testing (or post in
> plain text), but lubridate has an as.interval() function. You'll need
> to be able to extract the start time, though, for use in the function.
>
> On Tue, Dec 24, 2019 at 11:54 AM Allaisone 1 <Allaisone1 at hotmail.com>
> wrote:
> >
> >
> > Hi dear group ,
> >
> > I have list of datframes with similar column names. I want to rebind all
> dataframes so I have a single dataframe. One of the column's in each df is
> of 'interval' time class which was generated from 'lubridate' package.
> >
> > The problem is that when I convert the list of dfs into a single df
> using any of the below codes :
> >
> > Library(plyr)
> > MySingleDf <- ldply(MyListOfDfs, data.frame)
> > Or
> > MySingleDf <- ldply(MyListOfDfs, rbind)
> > Or
> > MySingleDf <- rebind. fill (MyListOfDfs)
> >
> > What heppens is that  time intervals which looks like : 2010-4-5
> UTC--2011-7-9 UTC is converted into a single numeric value which seems to
> be the difference between the 2 dates in seconds.
> >
> > When I use :
> > MySingleDf <- do.call ("rbind",MyListOfDfs)
> >
> > The code is freezes and it shows like of the data are being analysed but
> no result. I have used this code previously for the same purpose but with
> another datse and it works perfectly.
> >
> > What I want to see is that time intervals are shown as they are but not
> converted into seconds.
> >
> > Could you please suggest any alternative syntax or modifications to my
> codes ?
> >
> > Thank you so much in advance
> >
> > Regards
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Dec 25 00:45:40 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 24 Dec 2019 15:45:40 -0800
Subject: [R] 
 Time intervals is converted into seconds after converting list
 of dfs into a single Df.
In-Reply-To: <DB7PR09MB2298FDDF243F33411BCC404080290@DB7PR09MB2298.eurprd09.prod.outlook.com>
References: <DB7PR09MB22984E3ABDB31217945EA31A80290@DB7PR09MB2298.eurprd09.prod.outlook.com>
 <CAJc=yOFL3QzZSeG2MFnYOw=qkqTYd4bWp8tvWmDDQ3tb9e1WAg@mail.gmail.com>
 <DB7PR09MB2298FDDF243F33411BCC404080290@DB7PR09MB2298.eurprd09.prod.outlook.com>
Message-ID: <5cf1c6b8-1cb9-e831-8b80-7d98bfc0c140@comcast.net>

Perhaps some modification of

masterList <- list()

for( dfnum in seq_along(ListOfDFs)){

 ???????? masterList <- rbind(masterList, ListOfDFs[[dfnum]])

 ?????????????????????????????????????????????????????????????? }

 ?masterList

#---------------

 ?? id??? ? ?? dates1??? ? ? ? dates2 ? ? ? ?? ?? interaction
1? 1 2010-02-04 2010-09-04 2010-09-04 UTC--2011-01-01 UTC
2? 1 2011-02-04 2011-01-01 2010-09-04 UTC--2011-01-01 UTC
3? 2 2010-02-04 2010-09-04 2010-09-04 UTC--2011-01-01 UTC

4? 2 2011-02-04 2011-01-01 2010-09-04 UTC--2011-01-01


You could add features to the for-loop such as printing a message to the 
console every 100 dfs or perhaps garbage collection although that should 
be handled automagically. Messages would probably reassure you that the 
process was not "hanging". (My suspicion is that the process was 
continuing but you were just too impatient.)

Note; you are posting in HTML and including non-printing characters in 
you code.


-- 

David


On 12/24/19 10:53 AM, Allaisone 1 wrote:
> Hi dear Patrick ,
>
> Thanks for your replay. Below is a reproducible example . First,  I generated two  similar Dfs with one column contains the interval. Then, I put the 2 dfs in a list. Now, converting this list into df provides different results depending on the code. See below for more details.
>
>
>   # dataframe 1?
>
> id <- c(1,1)?
>
> dates1 <- c("2010/2/4","2011/2/4")?
>
> dates2 <- c("2010/9/4","2011/1/1")?
>
> df1 <- data.frame(id,dates1,dates2)?
>
> df1[,2] <- as.Date(df1[,2])?
>
> df1[,3] <- as.Date(df1[,3])?
>
> df1$interaction <- intersect(interval(df1[1,2],df1[2,2]),interval(df1[1,3],df1[2,3]))?
>
>    ?
>
>    # Dataframe 2?
>
> id <- c(2,2)?
>
> dates1 <- c("2010/1/4","2011/2/4")?
>
> dates2 <- c("2010/10/4","2011/1/16")?
>
> df2 <- data.frame(id,dates1,dates2)?
>
> df2[,2] <- as.Date(df1[,2])?
>
> df2[,3] <- as.Date(df1[,3])?
>
>
> df2$interaction <- intersect(interval(df1[1,2],df1[2,2]),interval(df1[1,3],df1[2,3]))?
>
>
>
>   # 2 datframes in a list :?
>
>   ListOfDFs <- list(df1,df2)?
>
>   # Convert list of Dfs into a single df :-?
>
>   SingDF <- ldply( ListOfDFs,data.frame)?
>
>         # The interval has been converted into numbers which is not what I want.?
>
>         #?but trying this code :
>   SingDF <- do.call(rbind,ListOfDFs)?
>
>         # It works perfectly but only with this example as? we have only 2 datframes. Howver, in my actual data I have? around 8000 datframes. Applying this code to it , make R code? freezes and I waited for many hours but it still freezes with? no results generated.?
>
>   Could anyone please suggest any alternative syntax or modifications to the codes above?
>
> Kind Regards
>   ?
>
>
>
> Sent from Outlook
> ________________________________
> From: Patrick (Malone Quantitative) <malone at malonequantitative.com>
> Sent: 24 December 2019 17:01:59
> To: Allaisone 1 <Allaisone1 at hotmail.com>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Subject: Re: [R] Time intervals is converted into seconds after converting list of dfs into a single Df.
>
> You didn't provide a reproducible example for testing (or post in
> plain text), but lubridate has an as.interval() function. You'll need
> to be able to extract the start time, though, for use in the function.
>
> On Tue, Dec 24, 2019 at 11:54 AM Allaisone 1 <Allaisone1 at hotmail.com> wrote:
>>
>> Hi dear group ,
>>
>> I have list of datframes with similar column names. I want to rebind all dataframes so I have a single dataframe. One of the column's in each df is of 'interval' time class which was generated from 'lubridate' package.
>>
>> The problem is that when I convert the list of dfs into a single df using any of the below codes :
>>
>> Library(plyr)
>> MySingleDf <- ldply(MyListOfDfs, data.frame)
>> Or
>> MySingleDf <- ldply(MyListOfDfs, rbind)
>> Or
>> MySingleDf <- rebind. fill (MyListOfDfs)
>>
>> What heppens is that  time intervals which looks like : 2010-4-5 UTC--2011-7-9 UTC is converted into a single numeric value which seems to be the difference between the 2 dates in seconds.
>>
>> When I use :
>> MySingleDf <- do.call ("rbind",MyListOfDfs)
>>
>> The code is freezes and it shows like of the data are being analysed but no result. I have used this code previously for the same purpose but with another datse and it works perfectly.
>>
>> What I want to see is that time intervals are shown as they are but not converted into seconds.
>>
>> Could you please suggest any alternative syntax or modifications to my codes ?
>>
>> Thank you so much in advance
>>
>> Regards
>>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From A||@|@one1 @end|ng |rom hotm@||@com  Tue Dec 24 23:49:11 2019
From: A||@|@one1 @end|ng |rom hotm@||@com (Allaisone 1)
Date: Tue, 24 Dec 2019 22:49:11 +0000
Subject: [R] 
 Time intervals is converted into seconds after converting list
 of dfs into a single Df.
In-Reply-To: <CAGxFJbRdC_F68Lrtw_44UNpqtXNjYjS4CXgf82AbdCnkTQ69_g@mail.gmail.com>
References: <DB7PR09MB22984E3ABDB31217945EA31A80290@DB7PR09MB2298.eurprd09.prod.outlook.com>
 <CAJc=yOFL3QzZSeG2MFnYOw=qkqTYd4bWp8tvWmDDQ3tb9e1WAg@mail.gmail.com>
 <DB7PR09MB2298FDDF243F33411BCC404080290@DB7PR09MB2298.eurprd09.prod.outlook.com>,
 <CAGxFJbRdC_F68Lrtw_44UNpqtXNjYjS4CXgf82AbdCnkTQ69_g@mail.gmail.com>
Message-ID: <DB7PR09MB229836A7C1522BF878D85B7480290@DB7PR09MB2298.eurprd09.prod.outlook.com>

Many thanks Bert for being so cooperative.
Deviding the data into small bites would be
a good suggestion but I will wait first to see
If someone else may have another idea.

Many thanks
________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: 24 December 2019 21:03:56
To: Allaisone 1 <Allaisone1 at hotmail.com>
Cc: Patrick (Malone Quantitative) <malone at malonequantitative.com>; r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Time intervals is converted into seconds after converting list of dfs into a single Df.

1. "Similar" or "same" column names. The former is probably not going to work.

2. Manipulations with data frames can consume a lot of memory. rbinding 8000 data frames is likely to be very slow with lots of time swapping memory around(???). Perhaps try taking smaller bites (say 1000 at a time) and then combining them. Or have you already tried this? If you do wish to do this, wait to give experts a chance to tell you that my suggestion is completely useless before you attempt it.

3. I'll let someone else resolve your dates problem, as I have never used lubridate.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 24, 2019 at 12:38 PM Allaisone 1 <Allaisone1 at hotmail.com<mailto:Allaisone1 at hotmail.com>> wrote:
Hi dear Patrick ,

Thanks for your replay. Below is a reproducible example . First,  I generated two  similar Dfs with one column contains the interval. Then, I put the 2 dfs in a list. Now, converting this list into df provides different results depending on the code. See below for more details.


 # dataframe 1

id <- c(1,1)

dates1 <- c("2010/2/4","2011/2/4")

dates2 <- c("2010/9/4","2011/1/1")

df1 <- data.frame(id,dates1,dates2)

df1[,2] <- as.Date(df1[,2])

df1[,3] <- as.Date(df1[,3])

df1$interaction <- intersect(interval(df1[1,2],df1[2,2]),interval(df1[1,3],df1[2,3]))



  # Dataframe 2

id <- c(2,2)

dates1 <- c("2010/1/4","2011/2/4")

dates2 <- c("2010/10/4","2011/1/16")

df2 <- data.frame(id,dates1,dates2)

df2[,2] <- as.Date(df1[,2])

df2[,3] <- as.Date(df1[,3])


df2$interaction <- intersect(interval(df1[1,2],df1[2,2]),interval(df1[1,3],df1[2,3]))



 # 2 datframes in a list :

 ListOfDFs <- list(df1,df2)

 # Convert list of Dfs into a single df :-

 SingDF <- ldply( ListOfDFs,data.frame)

       # The interval has been converted into numbers which is not what I want.

       #but trying this code :
 SingDF <- do.call(rbind,ListOfDFs)

       # It works perfectly but only with this example as we have only 2 datframes. Howver, in my actual data I have around 8000 datframes. Applying this code to it , make R code freezes and I waited for many hours but it still freezes with no results generated.

 Could anyone please suggest any alternative syntax or modifications to the codes above?

Kind Regards




Sent from Outlook
________________________________
From: Patrick (Malone Quantitative) <malone at malonequantitative.com<mailto:malone at malonequantitative.com>>
Sent: 24 December 2019 17:01:59
To: Allaisone 1 <Allaisone1 at hotmail.com<mailto:Allaisone1 at hotmail.com>>
Cc: r-help at r-project.org<mailto:r-help at r-project.org> <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Time intervals is converted into seconds after converting list of dfs into a single Df.

You didn't provide a reproducible example for testing (or post in
plain text), but lubridate has an as.interval() function. You'll need
to be able to extract the start time, though, for use in the function.

On Tue, Dec 24, 2019 at 11:54 AM Allaisone 1 <Allaisone1 at hotmail.com<mailto:Allaisone1 at hotmail.com>> wrote:
>
>
> Hi dear group ,
>
> I have list of datframes with similar column names. I want to rebind all dataframes so I have a single dataframe. One of the column's in each df is of 'interval' time class which was generated from 'lubridate' package.
>
> The problem is that when I convert the list of dfs into a single df using any of the below codes :
>
> Library(plyr)
> MySingleDf <- ldply(MyListOfDfs, data.frame)
> Or
> MySingleDf <- ldply(MyListOfDfs, rbind)
> Or
> MySingleDf <- rebind. fill (MyListOfDfs)
>
> What heppens is that  time intervals which looks like : 2010-4-5 UTC--2011-7-9 UTC is converted into a single numeric value which seems to be the difference between the 2 dates in seconds.
>
> When I use :
> MySingleDf <- do.call ("rbind",MyListOfDfs)
>
> The code is freezes and it shows like of the data are being analysed but no result. I have used this code previously for the same purpose but with another datse and it works perfectly.
>
> What I want to see is that time intervals are shown as they are but not converted into seconds.
>
> Could you please suggest any alternative syntax or modifications to my codes ?
>
> Thank you so much in advance
>
> Regards
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Wed Dec 25 13:28:54 2019
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Wed, 25 Dec 2019 07:28:54 -0500
Subject: [R] What is best way to calculate % of time?
In-Reply-To: <mailman.357216.1.1577185201.3968.r-help@r-project.org>
References: <mailman.357216.1.1577185201.3968.r-help@r-project.org>
Message-ID: <edfc3e5e-4d92-95be-da3e-537c79d34b8e@gmail.com>

Hi all,

It seems R has gotten better/more packages in dealing with time data.

I want to create "simple" summaries of time for bat activity.
Data is all in an Access relational database and exported as a CSV file 
with 4 columns in this format:
Species = a 6 letter code or "Buzz" to indicated when bats are feeding
Location = a 4 digit number
Date= MMDDYYYY
Time=HH:MM (24 hr format)

Species??? Location??? Date??? Time
Buzz??? 7716??? 1/25/2000??? 0:05
Buzz??? 7716??? 1/25/2000??? 0:05
Buzz??? 7716??? 1/25/2000??? 0:05
Buzz??? 7716??? 1/25/2000??? 0:47
Buzz??? 7716??? 1/25/2000??? 0:47
Buzz??? 7716??? 1/25/2000??? 0:47
Buzz??? 7716??? 1/25/2000??? 0:47
Buzz??? 7717??? 7/3/2000??? 20:17
Buzz??? 7717??? 7/3/2000??? 20:17
Buzz??? 7717??? 7/3/2000??? 20:17
Buzz??? 7717??? 7/3/2000??? 20:17
Buzz??? 7717??? 7/3/2000??? 20:30
Buzz??? 7717??? 7/3/2000??? 20:30
Buzz??? 7717??? 7/3/2000??? 20:30
Buzz??? 7717??? 7/3/2000??? 20:30
Ptedav??? 7717??? 7/3/2000??? 20:14
Ptedav??? 7717??? 7/3/2000??? 20:15
Ptedav??? 7717??? 7/3/2000??? 20:15
Ptedav??? 7717??? 7/3/2000??? 20:15
Ptedav??? 7717??? 7/3/2000??? 20:15
Ptedav??? 7717??? 7/3/2000??? 20:15
Ptedav??? 7717??? 7/3/2000??? 20:17
Ptedav??? 7717??? 7/3/2000??? 20:17
Ptedav??? 7717??? 7/3/2000??? 20:17
Ptedav??? 7717??? 7/3/2000??? 20:18
Ptedav??? 7717??? 7/3/2000??? 20:18
Ptedav??? 7717??? 7/3/2000??? 20:18
Ptedav??? 7717??? 7/3/2000??? 20:18
Ptedav??? 7717??? 7/3/2000??? 20:18
Ptemes??? 7717??? 7/3/2000??? 23:15
Ptemes??? 7717??? 7/3/2000??? 23:21
Ptemes??? 7717??? 7/3/2000??? 23:22
Ptemes??? 7717??? 7/3/2000??? 23:23
Ptemes??? 7717??? 7/3/2000??? 23:25
Ptemes??? 7717??? 7/3/2000??? 23:26
Ptemes??? 7717??? 7/3/2000??? 23:27
Ptemes??? 7717??? 7/3/2000??? 23:28
Ptemes??? 7717??? 7/3/2000??? 23:29
Ptemes??? 7717??? 7/3/2000??? 23:33
Ptemes??? 7717??? 7/3/2000??? 23:35
Ptemes??? 7717??? 7/3/2000??? 23:36
Ptemes??? 7717??? 7/3/2000??? 23:37

The above is clearly not a complete DF but only a format sample. Data 
begins when the first bat was recorded and ends when the last bat was 
recorded.? So all are times from sunset to sunrise.? Dates roll over so 
for example one night of data would begin at 18:00 1/1/2000 and end 
06:00 1/2/2000.

What I need to do is have a summary of Buzz events (feeding) and 
calculate the percentage of total time bats were active and have a 
summary of time feeding buzz was recorded and total bat activity to 
determine what percentage of time was spent with feeding attempts over 
the active period.

This by all bats by survey night and by single species by survey night.
Any suggestions welcomed.

Happy holidays all


-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


From jrkr|de@u @end|ng |rom gm@||@com  Wed Dec 25 16:15:59 2019
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Wed, 25 Dec 2019 10:15:59 -0500
Subject: [R] What is best way to calculate % of time?
In-Reply-To: <edfc3e5e-4d92-95be-da3e-537c79d34b8e@gmail.com>
References: <mailman.357216.1.1577185201.3968.r-help@r-project.org>
 <edfc3e5e-4d92-95be-da3e-537c79d34b8e@gmail.com>
Message-ID: <CAKZQJMBqQ0-aFAHjaYvGYj7zQB33Y8uWjz9fBOSuyjKhq_p+vw@mail.gmail.com>

I am sorry but I am at a loss here.
According to your sample data you have 3 Species : Buzz,  Ptedav,
Ptemes, but you say that "Buzz" indicates that the bat is feeding.
What has that to do with feeding?

Assuming Buzz is feeding activity, are all incidents of feeding
activity a single point in time?

Likewise the data has multiple entries such as
Ptedav    7717    7/3/2000    20:15
Ptedav    7717    7/3/2000    20:15
Ptedav    7717    7/3/2000    20:15
Ptedav    7717    7/3/2000    20:15

What does that represent?


On Wed, 25 Dec 2019 at 07:29, Neotropical bat risk assessments
<neotropical.bats at gmail.com> wrote:
>
> Hi all,
>
> It seems R has gotten better/more packages in dealing with time data.
>
> I want to create "simple" summaries of time for bat activity.
> Data is all in an Access relational database and exported as a CSV file
> with 4 columns in this format:
> Species = a 6 letter code or "Buzz" to indicated when bats are feeding
> Location = a 4 digit number
> Date= MMDDYYYY
> Time=HH:MM (24 hr format)
>
> Species    Location    Date    Time
> Buzz    7716    1/25/2000    0:05
> Buzz    7716    1/25/2000    0:05
> Buzz    7716    1/25/2000    0:05
> Buzz    7716    1/25/2000    0:47
> Buzz    7716    1/25/2000    0:47
> Buzz    7716    1/25/2000    0:47
> Buzz    7716    1/25/2000    0:47
> Buzz    7717    7/3/2000    20:17
> Buzz    7717    7/3/2000    20:17
> Buzz    7717    7/3/2000    20:17
> Buzz    7717    7/3/2000    20:17
> Buzz    7717    7/3/2000    20:30
> Buzz    7717    7/3/2000    20:30
> Buzz    7717    7/3/2000    20:30
> Buzz    7717    7/3/2000    20:30
> Ptedav    7717    7/3/2000    20:14
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:17
> Ptedav    7717    7/3/2000    20:17
> Ptedav    7717    7/3/2000    20:17
> Ptedav    7717    7/3/2000    20:18
> Ptedav    7717    7/3/2000    20:18
> Ptedav    7717    7/3/2000    20:18
> Ptedav    7717    7/3/2000    20:18
> Ptedav    7717    7/3/2000    20:18
> Ptemes    7717    7/3/2000    23:15
> Ptemes    7717    7/3/2000    23:21
> Ptemes    7717    7/3/2000    23:22
> Ptemes    7717    7/3/2000    23:23
> Ptemes    7717    7/3/2000    23:25
> Ptemes    7717    7/3/2000    23:26
> Ptemes    7717    7/3/2000    23:27
> Ptemes    7717    7/3/2000    23:28
> Ptemes    7717    7/3/2000    23:29
> Ptemes    7717    7/3/2000    23:33
> Ptemes    7717    7/3/2000    23:35
> Ptemes    7717    7/3/2000    23:36
> Ptemes    7717    7/3/2000    23:37
>
> The above is clearly not a complete DF but only a format sample. Data
> begins when the first bat was recorded and ends when the last bat was
> recorded.  So all are times from sunset to sunrise.  Dates roll over so
> for example one night of data would begin at 18:00 1/1/2000 and end
> 06:00 1/2/2000.
>
> What I need to do is have a summary of Buzz events (feeding) and
> calculate the percentage of total time bats were active and have a
> summary of time feeding buzz was recorded and total bat activity to
> determine what percentage of time was spent with feeding attempts over
> the active period.
>
> This by all bats by survey night and by single species by survey night.
> Any suggestions welcomed.
>
> Happy holidays all
>
>
> --
> Bruce W. Miller, PhD.
> Neotropical bat risk assessments
> Conservation Fellow - Wildlife Conservation Society
>
> If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
>
> Using acoustic sampling to identify and map species distributions
> and pioneering acoustic tools for ecology and conservation of bats for >25 years.
>
> Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
John Kane
Kingston ON Canada


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Wed Dec 25 17:50:14 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Wed, 25 Dec 2019 17:50:14 +0100
Subject: [R] Something is wrong; all the MAE metric values are missing
Message-ID: <CA+nrPntfv7v20fZ5uFNEs01T03g0bZ+TbuszhG7nXd6SvsMVzA@mail.gmail.com>

Hi

I am using Simulated annealing to tune the parameters of xgbtree for
regression dataset. When I run the code to tune the parameters of SVM and
RF, it works but when I run the same code for xgbTree, it gives stops and
give error:
Something is wrong; all the MAE metric values are missing:
      RMSE        Rsquared        MAE
 Min.   : NA   Min.   : NA   Min.   : NA
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
 Median : NA   Median : NA   Median : NA
 Mean   :NaN   Mean   :NaN   Mean   :NaN
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
 Max.   : NA   Max.   : NA   Max.   : NA
 NA's   :1     NA's   :1     NA's   :1

The code is given below:

library(xgboost)
d=readARFF("ant.arff")
dput( head( d, 50 ) )
d-> structure(list(version = c(1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7,
                               1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7,
1.7, 1.7, 1.7, 1.7,
                               1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7,
1.7, 1.7, 1.7, 1.7,
                               1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7, 1.7,
1.7, 1.7, 1.7, 1.7,
                               1.7, 1.7, 1.7, 1.7), wmc = c(3, 5, 1, 8, 9,
3, 20, 13, 9, 7,
                                                            9, 3, 1, 9, 19,
10, 3, 20, 6, 3, 5, 1, 11, 3, 3, 16, 4, 15, 11,
                                                            2, 15, 14, 27,
5, 3, 4, 6, 55, 3, 8, 11, 10, 1, 3, 9, 7, 9, 63,
                                                            6, 2), dit =
c(1, 2, 2, 1, 3, 2, 1, 1, 1, 5, 6, 2, 1, 1, 4, 4,

 2, 1, 1, 4, 2, 1, 2, 4, 2, 3, 4, 1, 3, 3, 3, 4, 3, 4, 1, 5, 1,

 3, 2, 1, 2, 1, 3, 2, 1, 1, 1, 1, 3, 1), noc = c(0, 0, 0, 9, 0,

                                               5, 0, 0, 0, 0, 0, 0, 0, 0,
0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

                                               8, 0, 0, 0, 0, 3, 0, 0, 0,
0, 0, 8, 0, 0, 0, 0, 0, 1, 0, 0, 1,

                                               2, 2, 0), cbo = c(10, 4, 1,
13, 5, 7, 4, 7, 5, 9, 5, 19, 10,

                                                                 3, 7, 13,
2, 7, 8, 5, 7, 1, 7, 5, 5, 15, 12, 11, 3, 1, 9, 11,

                                                                 8, 8, 2,
5, 2, 20, 4, 4, 1, 10, 1, 12, 32, 24, 4, 61, 20, 6),
                   rfc = c(18, 13, 3, 20, 26, 4, 40, 28, 19, 25, 17, 10, 1,
                           12, 40, 26, 5, 79, 6, 11, 14, 1, 26, 15, 7, 65,
5, 65, 24,
                           3, 41, 29, 101, 23, 3, 19, 11, 106, 19, 22, 23,
29, 2, 22,
                           36, 8, 19, 144, 13, 2), lcom = c(3, 0, 0, 12,
16, 1, 130,
                                                            20, 8, 0, 26,
3, 0, 20, 129, 0, 0, 136, 15, 1, 6, 0, 0, 3,
                                                            1, 76, 0, 75,
17, 1, 0, 85, 157, 4, 3, 6, 3, 1313, 3, 0,
                                                            39, 43, 0, 3,
36, 3, 30, 1603, 7, 1), ca = c(1, 1, 0, 9,

                             0, 6, 0, 2, 4, 6, 0, 14, 8, 1, 0, 7, 1, 5, 7,
1, 0, 0, 5,

                             0, 1, 0, 8, 0, 0, 1, 0, 3, 5, 4, 2, 0, 1, 8,
0, 0, 1, 7,

                             0, 2, 32, 24, 1, 51, 17, 6), ce = c(9, 4, 1,
4, 5, 1, 4,

                                                                 5, 1, 3,
5, 5, 2, 2, 7, 7, 1, 5, 1, 4, 7, 1, 2, 5, 4, 15,

                                                                 4, 11, 3,
0, 9, 8, 3, 8, 0, 5, 1, 12, 4, 4, 0, 3, 1, 10,

                                                                 0, 0, 3,
10, 3, 0), npm = c(1, 4, 1, 8, 7, 2, 18, 12, 9,


                 7, 6, 3, 1, 8, 16, 9, 3, 10, 6, 1, 4, 1, 11, 2, 3, 13, 3,


                 11, 10, 2, 15, 11, 15, 5, 3, 4, 4, 9, 2, 6, 10, 8, 1, 2,


                 7, 7, 7, 31, 3, 2), loc = c(106, 76, 7, 101, 185, 16, 345,


                                             183, 119, 255, 71, 38, 1, 54,
252, 110, 34, 835, 6, 41, 70,


                                             1, 181, 51, 29, 483, 18, 443,
309, 7, 204, 108, 1286, 249,


                                             4, 57, 53, 1133, 136, 169,
136, 91, 4, 72, 281, 43, 130,


                                             2303, 56, 2), moa = c(0, 1, 0,
1, 0, 0, 1, 2, 0, 0, 0, 0,


                                                                   0, 3, 0,
1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,


                                                                   1, 1, 0,
0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0),
                   ic = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1,
                          0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,
2, 0, 2,
                          0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0), cbm =
c(0, 0,

 0, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 3, 1, 2, 0, 0, 2, 0,

 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 7, 2, 0, 4, 0, 0, 0, 0,

 1, 0, 0, 0, 0, 0, 0, 0, 4, 0), max_cc = c(1, 1, 0, 1, 2,

                                           1, 3, 7, 3, 9, 3, 1, 1, 1, 6, 3,
1, 10, 1, 3, 4, 1, 1, 2,

                                           1, 9, 1, 5, 11, 1, 2, 4, 4, 1,
1, 2, 1, 10, 2, 7, 1, 3, 0,

                                           1, 11, 1, 4, 35, 1, 1), bug =
c(0, 0, 0, 0, 1, 0, 1, 0, 0,


 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,


 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,


 3, 0, 0)), row.names = c(NA, 50L), class = "data.frame")

index <- createDataPartition(log10(d$bug), p = .70,list = FALSE)
tr <- d[index, ]
ts <- d[-index, ]

index_2 <- createFolds(tr$bug, returnTrain = TRUE, list = TRUE)
ctrl <- trainControl(method = "repeatedcv", index = index_2)

obj <- function(param, maximize = FALSE) {
  mod <- train(bug ~ ., data = tr,
               method = "xgbTree",
               preProc = c("center", "scale", "zv"),
               metric = "MAE",
               trControl = ctrl,

                tuneGrid = data.frame(nrounds = (param[1]), max_depth =
(param[2]),
                                 eta=(param[3]), gamma=(param[4]),
                                 colsample_bytree= (param[5]),
min_child_weight=(param[6]),
                                 subsample=(param[7])))

                if(maximize)
    -getTrainPerf(mod)[, "TrainMAE"] else
      getTrainPerf(mod)[, "TrainMAE"]
}
num_mods <- 50

## Simulated annealing from base R
set.seed(30218)
tic()
san_res <- optim(par = c(20, 1, 0.1, 0, 0.1, 1, 0.1), fn = obj, method =
"SANN",
                 control = list(maxit = num_mods))
san_res

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Dec 25 18:06:15 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 25 Dec 2019 20:06:15 +0300
Subject: [R] Something is wrong; all the MAE metric values are missing
In-Reply-To: <CA+nrPntfv7v20fZ5uFNEs01T03g0bZ+TbuszhG7nXd6SvsMVzA@mail.gmail.com>
References: <CA+nrPntfv7v20fZ5uFNEs01T03g0bZ+TbuszhG7nXd6SvsMVzA@mail.gmail.com>
Message-ID: <20191225200615.22bd0643@trisector>

Try printing the value of `param` in your `obj` function before calling
train() or getTrainPerf(). Optimizers are prone to giving unexpected
values [*] in trying to lower the loss function. It might be the case
of an unconstrained optimizer leaving the realm of the feasible because
no-one told it not to.

-- 
Best regards,
Ivan

[*] See e.g. https://arxiv.org/abs/1803.03453 for examples of very
unorthodox ways of gaming the fitness fuction


From er|nm@hodge@@ @end|ng |rom gm@||@com  Wed Dec 25 18:13:28 2019
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Wed, 25 Dec 2019 09:13:28 -0800
Subject: [R] R CMD Batch on Windows and use of the ampersand
Message-ID: <CACxE24kG_BF-bPrB+zk6J08=ig-_oRd2vWJw2ibY-+t7urdHUQ@mail.gmail.com>

Hello!  Merry Christmas to those of you celebrating it, and happy
holidays to those celebrating other holidays.

Here is a question about R CMD BATCH on Windows.  We know that

R CMD BATCH infile outfile &

On Linux or Mac will let you continue interactively from the command line.
However, it does not work with the interactive component from Windows.  Is
there a workaround for this, please?
Thanks,
Sincerely,
Erin
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Dec 25 18:44:37 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 25 Dec 2019 20:44:37 +0300
Subject: [R] R CMD Batch on Windows and use of the ampersand
In-Reply-To: <CACxE24kG_BF-bPrB+zk6J08=ig-_oRd2vWJw2ibY-+t7urdHUQ@mail.gmail.com>
References: <CACxE24kG_BF-bPrB+zk6J08=ig-_oRd2vWJw2ibY-+t7urdHUQ@mail.gmail.com>
Message-ID: <20191225204437.47f141c4@trisector>

On Wed, 25 Dec 2019 09:13:28 -0800
Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> We know that
> 
> R CMD BATCH infile outfile &
> 
> On Linux or Mac will let you continue interactively from the command
> line.

This is a property of the command line shell being used, not of R CMD
BATCH itself. One way to do the same on Windows would be to use the
start command [*]:

start "" R CMD BATCH infile outfile

If a new window being created is a problem for you, try start "" /MIN
or start "" /B, but I am not sure it would help.

-- 
Best regards,
Ivan

[*] https://ss64.com/nt/start.html


From jrkr|de@u @end|ng |rom gm@||@com  Wed Dec 25 20:30:57 2019
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Wed, 25 Dec 2019 14:30:57 -0500
Subject: [R] What is best way to calculate % of time?
In-Reply-To: <4cd3b884-1055-86fc-0852-e8c5507a1a1b@gmail.com>
References: <mailman.357216.1.1577185201.3968.r-help@r-project.org>
 <edfc3e5e-4d92-95be-da3e-537c79d34b8e@gmail.com>
 <CAKZQJMBqQ0-aFAHjaYvGYj7zQB33Y8uWjz9fBOSuyjKhq_p+vw@mail.gmail.com>
 <4cd3b884-1055-86fc-0852-e8c5507a1a1b@gmail.com>
Message-ID: <CAKZQJMDXv1D0TBvbi7kEHhKJjsjRHs35nny7somrvFHyB1-ycw@mail.gmail.com>

Hi Bruce,
You replied just to me. I have taken the liberty of cc:ing R-help as there
lots of more knowledgeable people than me there who may be able to help.
In the meantime I remain confused.
Here is my impression of the sample data that you supplied. I have combined
Date & Time into a single POSIXct variable, dtime. Just paste it into
<b>R</b>
##===============================================================##
dat2 <- structure(list(Species = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
c("Buzz", "Ptedav", "Ptemes"), class = "factor"), Location = c(7716L,
7716L, 7716L, 7716L, 7716L, 7716L, 7716L, 7717L, 7717L, 7717L, 7717L,
7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L,
7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L,
7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L,
7717L), dtime = structure(c(948758700, 948758700, 948758700, 948761220,
948761220, 948761220, 948761220, 962655420, 962655420, 962655420,
962655420, 962656200, 962656200, 962656200, 962656200, 962655240,
962655300, 962655300, 962655300, 962655300, 962655300, 962655420,
962655420, 962655420, 962655480, 962655480, 962655480, 962655480,
962655480, 962666100, 962666460, 962666520, 962666580, 962666700,
962666760, 962666820, 962666880, 962666940, 962667180, 962667300,
962667360, 962667420), class = c("POSIXct", "POSIXt"), tzone = "UTC")),
class = "data.frame", row.names = c(NA, -42L))
##===============================================================##
<b>The 6 letter species codes relate to individual bat species and the Buzz
= Feeding buzz that indicates a feeding attempt by a given bat. So the
"codes" are both species and information on the call type.</b>
But, at the moment you have two variables in the one column, Species: The
type of bat and feeding behaviour.
<b>The date/time is when the species was recorded and is linked to the
location.</b>
Okay. Will this give us a unique key?
<b>Therefore to run the summary stats I need I will need to remove the
duplicate times that are rounded to the minute</b>
What duplicate times? Where are they? When are they rounded?
I have never used Access. Will it produce a data dictionary? Can it export
a small subset of the relevant data to another Access DB, some other DB or
in .csv format? At the moment I just cannot visualize what your data layout
looks like.
Can you point us to any documentation that explains what information in
being gathered?preferably in simple?minded English?

On Wed, 25 Dec 2019 at 12:08, Neotropical bat risk assessments <
neotropical.bats at gmail.com> wrote:

> Hi John,
>
> Likely TMI but....
>
> The example was only to show the data format, clearly not the entire data
> set. ;-)
> Analyses will be by locations, dates and species in any case so small
> subsets.
>
> My master relational database has >1.9 million records.  These are
> acoustic data recordings of bats and includes data fro >425 species.
>
> The 6 letter species codes relate to individual bat species and the Buzz =
> Feeding buzz that indicates a feeding attempt by a given bat.  So the
> "codes" are both species and information on the call type.
>
> So yes, if a call includes a feeding buzz it is noted as Buzz in addition
> to the species ID codes..
> A given 15 second acoustic recording may have up to 5 species recorded and
> when imported into the relational DB each individual species is parsed into
> its own record as well as records of call notes e.g. Buzz.
>
> The date/time is when the species was recorded and is linked to the
> location.
> Although the call data summary below is summarized by *minute* the actual
> data is recorded by time which includes seconds in addition to minutes.
> So there could be say 3+ files recorded during the same minute but at
> different time periods as seconds (0-59) are included.
>
> Therefore to run the summary stats I need I will need to remove the
> duplicate times that are rounded to the minute.
>
> Again tnx for taking time to reply.
>
> Cheers,
>
> Bruce
>
> I am sorry but I am at a loss here.
> According to your sample data you have 3 Species : Buzz,  Ptedav,
> Ptemes, but you say that "Buzz" indicates that the bat is feeding.
> What has that to do with feeding?
>
> Assuming Buzz is feeding activity, are all incidents of feeding
> activity a single point in time?
>
> Likewise the data has multiple entries such as
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
>
> What does that represent?
>
>
> On Wed, 25 Dec 2019 at 07:29, Neotropical bat risk assessments<neotropical.bats at gmail.com> <neotropical.bats at gmail.com> wrote:
>
> Hi all,
>
> It seems R has gotten better/more packages in dealing with time data.
>
> I want to create "simple" summaries of time for bat activity.
> Data is all in an Access relational database and exported as a CSV file
> with 4 columns in this format:
> Species = a 6 letter code or "Buzz" to indicated when bats are feeding
> Location = a 4 digit number
> Date= MMDDYYYY
> Time=HH:MM (24 hr format)
>
> Species    Location    Date    Time
> Buzz    7716    1/25/2000    0:05
> Buzz    7716    1/25/2000    0:05
> Buzz    7716    1/25/2000    0:05
> Buzz    7716    1/25/2000    0:47
> Buzz    7716    1/25/2000    0:47
> Buzz    7716    1/25/2000    0:47
> Buzz    7716    1/25/2000    0:47
> Buzz    7717    7/3/2000    20:17
> Buzz    7717    7/3/2000    20:17
> Buzz    7717    7/3/2000    20:17
> Buzz    7717    7/3/2000    20:17
> Buzz    7717    7/3/2000    20:30
> Buzz    7717    7/3/2000    20:30
> Buzz    7717    7/3/2000    20:30
> Buzz    7717    7/3/2000    20:30
> Ptedav    7717    7/3/2000    20:14
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:15
> Ptedav    7717    7/3/2000    20:17
> Ptedav    7717    7/3/2000    20:17
> Ptedav    7717    7/3/2000    20:17
> Ptedav    7717    7/3/2000    20:18
> Ptedav    7717    7/3/2000    20:18
> Ptedav    7717    7/3/2000    20:18
> Ptedav    7717    7/3/2000    20:18
> Ptedav    7717    7/3/2000    20:18
> Ptemes    7717    7/3/2000    23:15
> Ptemes    7717    7/3/2000    23:21
> Ptemes    7717    7/3/2000    23:22
> Ptemes    7717    7/3/2000    23:23
> Ptemes    7717    7/3/2000    23:25
> Ptemes    7717    7/3/2000    23:26
> Ptemes    7717    7/3/2000    23:27
> Ptemes    7717    7/3/2000    23:28
> Ptemes    7717    7/3/2000    23:29
> Ptemes    7717    7/3/2000    23:33
> Ptemes    7717    7/3/2000    23:35
> Ptemes    7717    7/3/2000    23:36
> Ptemes    7717    7/3/2000    23:37
>
> The above is clearly not a complete DF but only a format sample. Data
> begins when the first bat was recorded and ends when the last bat was
> recorded.  So all are times from sunset to sunrise.  Dates roll over so
> for example one night of data would begin at 18:00 1/1/2000 and end
> 06:00 1/2/2000.
>
> What I need to do is have a summary of Buzz events (feeding) and
> calculate the percentage of total time bats were active and have a
> summary of time feeding buzz was recorded and total bat activity to
> determine what percentage of time was spent with feeding attempts over
> the active period.
>
> This by all bats by survey night and by single species by survey night.
> Any suggestions welcomed.
>
> Happy holidays all
>
>
> --
> Bruce W. Miller, PhD.
> Neotropical bat risk assessments
> Conservation Fellow - Wildlife Conservation Society
>
> If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
>
> Using acoustic sampling to identify and map species distributions
> and pioneering acoustic tools for ecology and conservation of bats for >25 years.
>
> Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats
>
> ______________________________________________R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, seehttps://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> --
> John Kane
> Kingston ON Canada
>
>
>
> --
> Bruce W. Miller, PhD.
> Neotropical bat risk assessments
> Conservation Fellow - Wildlife Conservation Society
>
> If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
>
> Using acoustic sampling to identify and map species distributions
> and pioneering acoustic tools for ecology and conservation of bats for >25 years.
>
> Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats
>
>
>

-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Wed Dec 25 21:20:41 2019
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Wed, 25 Dec 2019 13:20:41 -0700
Subject: [R] R CMD Batch on Windows and use of the ampersand
In-Reply-To: <20191225204437.47f141c4@trisector>
References: <CACxE24kG_BF-bPrB+zk6J08=ig-_oRd2vWJw2ibY-+t7urdHUQ@mail.gmail.com>
 <20191225204437.47f141c4@trisector>
Message-ID: <CACxE24mP75aY-wk1y_W-xbor9BY78AsqOhub4dPd2NQuEZf8FA@mail.gmail.com>

This is great information!  Thank you so much!

Sincerely,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Wed, Dec 25, 2019 at 10:44 AM Ivan Krylov <krylov.r00t at gmail.com> wrote:

> On Wed, 25 Dec 2019 09:13:28 -0800
> Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
> > We know that
> >
> > R CMD BATCH infile outfile &
> >
> > On Linux or Mac will let you continue interactively from the command
> > line.
>
> This is a property of the command line shell being used, not of R CMD
> BATCH itself. One way to do the same on Windows would be to use the
> start command [*]:
>
> start "" R CMD BATCH infile outfile
>
> If a new window being created is a problem for you, try start "" /MIN
> or start "" /B, but I am not sure it would help.
>
> --
> Best regards,
> Ivan
>
> [*] https://ss64.com/nt/start.html
>

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Wed Dec 25 21:49:04 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 25 Dec 2019 15:49:04 -0500
Subject: [R] R CMD Batch on Windows and use of the ampersand
In-Reply-To: <CACxE24kG_BF-bPrB+zk6J08=ig-_oRd2vWJw2ibY-+t7urdHUQ@mail.gmail.com>
References: <CACxE24kG_BF-bPrB+zk6J08=ig-_oRd2vWJw2ibY-+t7urdHUQ@mail.gmail.com>
Message-ID: <CAGx1TMBXex486wmvHw87JVKB0p6ZHs2sw0V_dHTOZa48jO0wTg@mail.gmail.com>

Hi Erin.

I think the easiest way is to use sh, which is included as part of Rtools.

>From the CMD command line, enter
c:/Rtools/bin/sh -i

You are now running a Unix shell, and all the behaviors you expect are
there, including ";" and "&"

Rich

On Wed, Dec 25, 2019 at 12:16 PM Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
> Hello!  Merry Christmas to those of you celebrating it, and happy
> holidays to those celebrating other holidays.
>
> Here is a question about R CMD BATCH on Windows.  We know that
>
> R CMD BATCH infile outfile &
>
> On Linux or Mac will let you continue interactively from the command line.
> However, it does not work with the interactive component from Windows.  Is
> there a workaround for this, please?
> Thanks,
> Sincerely,
> Erin
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|nm@hodge@@ @end|ng |rom gm@||@com  Wed Dec 25 21:50:11 2019
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Wed, 25 Dec 2019 13:50:11 -0700
Subject: [R] R CMD Batch on Windows and use of the ampersand
In-Reply-To: <CAGx1TMBXex486wmvHw87JVKB0p6ZHs2sw0V_dHTOZa48jO0wTg@mail.gmail.com>
References: <CACxE24kG_BF-bPrB+zk6J08=ig-_oRd2vWJw2ibY-+t7urdHUQ@mail.gmail.com>
 <CAGx1TMBXex486wmvHw87JVKB0p6ZHs2sw0V_dHTOZa48jO0wTg@mail.gmail.com>
Message-ID: <CACxE24=g_pXht+RU0yPhB0S-e9=mJcFFK9TAVmBCppXVZFLAsw@mail.gmail.com>

Nice!
Thanks so much!

Take care,
Erin


On Wed, Dec 25, 2019 at 1:49 PM Richard M. Heiberger <rmh at temple.edu> wrote:

> Hi Erin.
>
> I think the easiest way is to use sh, which is included as part of Rtools.
>
> From the CMD command line, enter
> c:/Rtools/bin/sh -i
>
> You are now running a Unix shell, and all the behaviors you expect are
> there, including ";" and "&"
>
> Rich
>
> On Wed, Dec 25, 2019 at 12:16 PM Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >
> > Hello!  Merry Christmas to those of you celebrating it, and happy
> > holidays to those celebrating other holidays.
> >
> > Here is a question about R CMD BATCH on Windows.  We know that
> >
> > R CMD BATCH infile outfile &
> >
> > On Linux or Mac will let you continue interactively from the command
> line.
> > However, it does not work with the interactive component from Windows.
> Is
> > there a workaround for this, please?
> > Thanks,
> > Sincerely,
> > Erin
> > Erin Hodgess, PhD
> > mailto: erinm.hodgess at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Wed Dec 25 22:51:39 2019
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Wed, 25 Dec 2019 16:51:39 -0500
Subject: [R] What is best way to calculate % of time?
In-Reply-To: <CAKZQJMDXv1D0TBvbi7kEHhKJjsjRHs35nny7somrvFHyB1-ycw@mail.gmail.com>
References: <mailman.357216.1.1577185201.3968.r-help@r-project.org>
 <edfc3e5e-4d92-95be-da3e-537c79d34b8e@gmail.com>
 <CAKZQJMBqQ0-aFAHjaYvGYj7zQB33Y8uWjz9fBOSuyjKhq_p+vw@mail.gmail.com>
 <4cd3b884-1055-86fc-0852-e8c5507a1a1b@gmail.com>
 <CAKZQJMDXv1D0TBvbi7kEHhKJjsjRHs35nny7somrvFHyB1-ycw@mail.gmail.com>
Message-ID: <6a446c99-eae0-289d-5601-11c24aa2397c@gmail.com>

Tnx John,
Yep failed to "reply all" my bad.

Yes the mix of "information" on call type and species are in the same 
field.? It will be a single mouse click to export only the "buzz" data 
from the master DB as a separate CSV file from the species data. So this 
could be a new DF/data set for R.
This is due to the legacy issues of how the acoustic data are added to 
the metadata of the bat call recordings.
Combining date and times does not provide for sampling nights that roll 
over after midnight.

I may need to reread Hadley's Tidy Data manifesto re: data handling ;-).

The location, date and time does provide unique variables.
Duplicate times mentioned are the "duplicated" values you noted. This 
happens as the actual call files include seconds for a more precise time 
when the recordings were made.? Rounding to nearest minute suffices for 
a summary of total minutes spent? with "feeding attempts" vs total 
active time.

The data being gathered is reviewed in a purpose build bat acoustic 
software program when reviewing bat call files.? The metadata include 
the "Who", "Where" & "When" recorded. What is added to this as the 
acoustic files are reviewed are information on call types and species IDs.

This metadata is exported as a TXT file and imported into a master 
Access DB I developed over the past 15 years to manage "BIG DATA" as 
they say.? As a note I currently it have >1.9 million acoustic call 
records store in the relational DB.

The data output/exported from the DB is sufficient to provide wonderful 
temporal activity plots using GGplot2.? Original code for this was 
developed with huge assistance from Hadley eons ago and updated to more 
recent R releases and packages by a few others.

The graphics are great to visualize temporal activity but do not provide 
a simple summary of amount of time spent "foraging AKA feeding buzz 
data" vs total activity time for each species.

Perhaps this is /was not a simple question on how to summarize time data 
to derive a % of each category, be it "buzz" or species.

Tnx again,
Bruce


>
> Hi Bruce,
> You replied just to me. I have taken the liberty of cc:ing R-help as 
> there lots of more knowledgeable people than me there who may be able 
> to help.
> In the meantime I remain confused.
> Here is my impression of the sample data that you supplied. I have 
> combined Date & Time into a single POSIXct variable, dtime. Just paste 
> it into <b>R</b>
> ##===============================================================##
> dat2 <- structure(list(Species = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
> 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
> 3L, 3L), .Label = c("Buzz", "Ptedav", "Ptemes"), class = "factor"), 
> Location = c(7716L, 7716L, 7716L, 7716L, 7716L, 7716L, 7716L, 7717L, 
> 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 
> 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 
> 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 
> 7717L, 7717L, 7717L, 7717L), dtime = structure(c(948758700, 948758700, 
> 948758700, 948761220, 948761220, 948761220, 948761220, 962655420, 
> 962655420, 962655420, 962655420, 962656200, 962656200, 962656200, 
> 962656200, 962655240, 962655300, 962655300, 962655300, 962655300, 
> 962655300, 962655420, 962655420, 962655420, 962655480, 962655480, 
> 962655480, 962655480, 962655480, 962666100, 962666460, 962666520, 
> 962666580, 962666700, 962666760, 962666820, 962666880, 962666940, 
> 962667180, 962667300, 962667360, 962667420), class = c("POSIXct", 
> "POSIXt"), tzone = "UTC")), class = "data.frame", row.names = c(NA, -42L))
> ##===============================================================##
> <b>The 6 letter species codes relate to individual bat species and the 
> Buzz = Feeding buzz that indicates a feeding attempt by a given bat. 
> So the "codes" are both species and information on the call type.</b>
> But, at the moment you have two variables in the one column, Species: 
> The type of bat and feeding behaviour.
> <b>The date/time is when the species was recorded and is linked to the 
> location.</b>
> Okay. Will this give us a unique key?
> <b>Therefore to run the summary stats I need I will need to remove the 
> duplicate times that are rounded to the minute</b>
> What duplicate times? Where are they? When are they rounded?
> I have never used Access. Will it produce a data dictionary? Can it 
> export a small subset of the relevant data to another Access DB, some 
> other DB or in .csv format? At the moment I just cannot visualize what 
> your data layout looks like.
> Can you point us to any documentation that explains what information 
> in being gathered?preferably in simple?minded English?
>
> On Wed, 25 Dec 2019 at 12:08, Neotropical bat risk assessments 
> <neotropical.bats at gmail.com <mailto:neotropical.bats at gmail.com>> wrote:
>
>     Hi John,
>
>     Likely TMI but....
>
>     The example was only to show the data format, clearly not the
>     entire data set. ;-)
>     Analyses will be by locations, dates and species in any case so
>     small subsets.
>
>     My master relational database has >1.9 million records.? These are
>     acoustic data recordings of bats and includes data fro >425 species.
>
>     The 6 letter species codes relate to individual bat species and
>     the Buzz = Feeding buzz that indicates a feeding attempt by a
>     given bat.? So the "codes" are both species and information on the
>     call type.
>
>     So yes, if a call includes a feeding buzz it is noted as Buzz in
>     addition to the species ID codes..
>     A given 15 second acoustic recording may have up to 5 species
>     recorded and when imported into the relational DB each individual
>     species is parsed into its own record as well as records of call
>     notes e.g. Buzz.
>
>     The date/time is when the species was recorded and is linked to
>     the location.
>     Although the call data summary below is summarized by *minute* the
>     actual data is recorded by time which includes seconds in addition
>     to minutes.
>     So there could be say 3+ files recorded during the same minute but
>     at different time periods as seconds (0-59) are included.
>
>     Therefore to run the summary stats I need I will need to remove
>     the duplicate times that are rounded to the minute.
>
>     Again tnx for taking time to reply.
>
>     Cheers,
>
>     Bruce
>>     I am sorry but I am at a loss here.
>>     According to your sample data you have 3 Species : Buzz,  Ptedav,
>>     Ptemes, but you say that "Buzz" indicates that the bat is feeding.
>>     What has that to do with feeding?
>>
>>     Assuming Buzz is feeding activity, are all incidents of feeding
>>     activity a single point in time?
>>
>>     Likewise the data has multiple entries such as
>>     Ptedav    7717    7/3/2000    20:15
>>     Ptedav    7717    7/3/2000    20:15
>>     Ptedav    7717    7/3/2000    20:15
>>     Ptedav    7717    7/3/2000    20:15
>>
>>     What does that represent?
>>
>>
>>     On Wed, 25 Dec 2019 at 07:29, Neotropical bat risk assessments
>>     <neotropical.bats at gmail.com>  <mailto:neotropical.bats at gmail.com>  wrote:
>>>     Hi all,
>>>
>>>     It seems R has gotten better/more packages in dealing with time data.
>>>
>>>     I want to create "simple" summaries of time for bat activity.
>>>     Data is all in an Access relational database and exported as a CSV file
>>>     with 4 columns in this format:
>>>     Species = a 6 letter code or "Buzz" to indicated when bats are feeding
>>>     Location = a 4 digit number
>>>     Date= MMDDYYYY
>>>     Time=HH:MM (24 hr format)
>>>
>>>     Species    Location    Date    Time
>>>     Buzz    7716    1/25/2000    0:05
>>>     Buzz    7716    1/25/2000    0:05
>>>     Buzz    7716    1/25/2000    0:05
>>>     Buzz    7716    1/25/2000    0:47
>>>     Buzz    7716    1/25/2000    0:47
>>>     Buzz    7716    1/25/2000    0:47
>>>     Buzz    7716    1/25/2000    0:47
>>>     Buzz    7717    7/3/2000    20:17
>>>     Buzz    7717    7/3/2000    20:17
>>>     Buzz    7717    7/3/2000    20:17
>>>     Buzz    7717    7/3/2000    20:17
>>>     Buzz    7717    7/3/2000    20:30
>>>     Buzz    7717    7/3/2000    20:30
>>>     Buzz    7717    7/3/2000    20:30
>>>     Buzz    7717    7/3/2000    20:30
>>>     Ptedav    7717    7/3/2000    20:14
>>>     Ptedav    7717    7/3/2000    20:15
>>>     Ptedav    7717    7/3/2000    20:15
>>>     Ptedav    7717    7/3/2000    20:15
>>>     Ptedav    7717    7/3/2000    20:15
>>>     Ptedav    7717    7/3/2000    20:15
>>>     Ptedav    7717    7/3/2000    20:17
>>>     Ptedav    7717    7/3/2000    20:17
>>>     Ptedav    7717    7/3/2000    20:17
>>>     Ptedav    7717    7/3/2000    20:18
>>>     Ptedav    7717    7/3/2000    20:18
>>>     Ptedav    7717    7/3/2000    20:18
>>>     Ptedav    7717    7/3/2000    20:18
>>>     Ptedav    7717    7/3/2000    20:18
>>>     Ptemes    7717    7/3/2000    23:15
>>>     Ptemes    7717    7/3/2000    23:21
>>>     Ptemes    7717    7/3/2000    23:22
>>>     Ptemes    7717    7/3/2000    23:23
>>>     Ptemes    7717    7/3/2000    23:25
>>>     Ptemes    7717    7/3/2000    23:26
>>>     Ptemes    7717    7/3/2000    23:27
>>>     Ptemes    7717    7/3/2000    23:28
>>>     Ptemes    7717    7/3/2000    23:29
>>>     Ptemes    7717    7/3/2000    23:33
>>>     Ptemes    7717    7/3/2000    23:35
>>>     Ptemes    7717    7/3/2000    23:36
>>>     Ptemes    7717    7/3/2000    23:37
>>>
>>>     The above is clearly not a complete DF but only a format sample. Data
>>>     begins when the first bat was recorded and ends when the last bat was
>>>     recorded.  So all are times from sunset to sunrise.  Dates roll over so
>>>     for example one night of data would begin at 18:00 1/1/2000 and end
>>>     06:00 1/2/2000.
>>>
>>>     What I need to do is have a summary of Buzz events (feeding) and
>>>     calculate the percentage of total time bats were active and have a
>>>     summary of time feeding buzz was recorded and total bat activity to
>>>     determine what percentage of time was spent with feeding attempts over
>>>     the active period.
>>>
>>>     This by all bats by survey night and by single species by survey night.
>>>     Any suggestions welcomed.
>>>
>>>     Happy holidays all
>>>
>>>
>>>     --
>>>     Bruce W. Miller, PhD.
>>>     Neotropical bat risk assessments
>>>     Conservation Fellow - Wildlife Conservation Society
>>>
>>>     If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
>>>
>>>     Using acoustic sampling to identify and map species distributions
>>>     and pioneering acoustic tools for ecology and conservation of bats for >25 years.
>>>
>>>     Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats
>>>
>>>     ______________________________________________
>>>     R-help at r-project.org  <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>     PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>>>     and provide commented, minimal, self-contained, reproducible code.
>>     --
>>     John Kane
>>     Kingston ON Canada
>
>
>     -- 
>     Bruce W. Miller, PhD.
>     Neotropical bat risk assessments
>     Conservation Fellow - Wildlife Conservation Society
>
>     If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
>
>     Using acoustic sampling to identify and map species distributions
>     and pioneering acoustic tools for ecology and conservation of bats for >25 years.
>
>     Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats
>
>
>
> -- 
> John Kane
> Kingston ON Canada


-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Dec 25 23:39:09 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 25 Dec 2019 14:39:09 -0800
Subject: [R] What is best way to calculate % of time?
In-Reply-To: <6a446c99-eae0-289d-5601-11c24aa2397c@gmail.com>
References: <mailman.357216.1.1577185201.3968.r-help@r-project.org>
 <edfc3e5e-4d92-95be-da3e-537c79d34b8e@gmail.com>
 <CAKZQJMBqQ0-aFAHjaYvGYj7zQB33Y8uWjz9fBOSuyjKhq_p+vw@mail.gmail.com>
 <4cd3b884-1055-86fc-0852-e8c5507a1a1b@gmail.com>
 <CAKZQJMDXv1D0TBvbi7kEHhKJjsjRHs35nny7somrvFHyB1-ycw@mail.gmail.com>
 <6a446c99-eae0-289d-5601-11c24aa2397c@gmail.com>
Message-ID: <CAGxFJbQNqLM=ODqddzbABTdspe_crXMLhyEbu0BySLnE6o1Rnw@mail.gmail.com>

I will not get into your explanation of details that, like John, I find
opaque. Please DO read Hadley's manifesto, as it appears that you need to
organize your data more appropriately.

AFAICS, however, strictly speaking your data cannot answer the question you
have posed. **Strictly speaking** to know the proportion of active time
bats spend feeding, **for each bat** you would need to know when it is
active and when it is feeding during that time. You could then summarize
this for all bats (e.g. take the average or median proportion) in a species
or whatever. As you cannot identify individual bats in your data, you
cannot do this -- i.e. you cannot answer your question.

So the question then becomes: precisely **how** exactly do you propose
using the data you have to determine when a *group* of bats are active and
when they are feeding? How are the groups explicitly identified and how are
their times active and feeding determined? In short, you need to have
information that is something like:

Bat.Group   date   active.time.start  active.time.end  feeding.time.start
feeding.time.end

( for a given date and bat group, there may be many multiple entries;
perhaps for a given group, date, and active time start and end, several
feeding time start/stop entries ( I have no idea how bats behave)).

Until you can expicitly explain how your data can generate such
information, I think it will be difficult/impossible to help you.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Dec 25, 2019 at 1:52 PM Neotropical bat risk assessments <
neotropical.bats at gmail.com> wrote:

> Tnx John,
> Yep failed to "reply all" my bad.
>
> Yes the mix of "information" on call type and species are in the same
> field.  It will be a single mouse click to export only the "buzz" data
> from the master DB as a separate CSV file from the species data. So this
> could be a new DF/data set for R.
> This is due to the legacy issues of how the acoustic data are added to
> the metadata of the bat call recordings.
> Combining date and times does not provide for sampling nights that roll
> over after midnight.
>
> I may need to reread Hadley's Tidy Data manifesto re: data handling ;-).
>
> The location, date and time does provide unique variables.
> Duplicate times mentioned are the "duplicated" values you noted. This
> happens as the actual call files include seconds for a more precise time
> when the recordings were made.  Rounding to nearest minute suffices for
> a summary of total minutes spent  with "feeding attempts" vs total
> active time.
>
> The data being gathered is reviewed in a purpose build bat acoustic
> software program when reviewing bat call files.  The metadata include
> the "Who", "Where" & "When" recorded. What is added to this as the
> acoustic files are reviewed are information on call types and species IDs.
>
> This metadata is exported as a TXT file and imported into a master
> Access DB I developed over the past 15 years to manage "BIG DATA" as
> they say.  As a note I currently it have >1.9 million acoustic call
> records store in the relational DB.
>
> The data output/exported from the DB is sufficient to provide wonderful
> temporal activity plots using GGplot2.  Original code for this was
> developed with huge assistance from Hadley eons ago and updated to more
> recent R releases and packages by a few others.
>
> The graphics are great to visualize temporal activity but do not provide
> a simple summary of amount of time spent "foraging AKA feeding buzz
> data" vs total activity time for each species.
>
> Perhaps this is /was not a simple question on how to summarize time data
> to derive a % of each category, be it "buzz" or species.
>
> Tnx again,
> Bruce
>
>
> >
> > Hi Bruce,
> > You replied just to me. I have taken the liberty of cc:ing R-help as
> > there lots of more knowledgeable people than me there who may be able
> > to help.
> > In the meantime I remain confused.
> > Here is my impression of the sample data that you supplied. I have
> > combined Date & Time into a single POSIXct variable, dtime. Just paste
> > it into <b>R</b>
> > ##===============================================================##
> > dat2 <- structure(list(Species = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > 3L, 3L), .Label = c("Buzz", "Ptedav", "Ptemes"), class = "factor"),
> > Location = c(7716L, 7716L, 7716L, 7716L, 7716L, 7716L, 7716L, 7717L,
> > 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L,
> > 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L,
> > 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L, 7717L,
> > 7717L, 7717L, 7717L, 7717L), dtime = structure(c(948758700, 948758700,
> > 948758700, 948761220, 948761220, 948761220, 948761220, 962655420,
> > 962655420, 962655420, 962655420, 962656200, 962656200, 962656200,
> > 962656200, 962655240, 962655300, 962655300, 962655300, 962655300,
> > 962655300, 962655420, 962655420, 962655420, 962655480, 962655480,
> > 962655480, 962655480, 962655480, 962666100, 962666460, 962666520,
> > 962666580, 962666700, 962666760, 962666820, 962666880, 962666940,
> > 962667180, 962667300, 962667360, 962667420), class = c("POSIXct",
> > "POSIXt"), tzone = "UTC")), class = "data.frame", row.names = c(NA,
> -42L))
> > ##===============================================================##
> > <b>The 6 letter species codes relate to individual bat species and the
> > Buzz = Feeding buzz that indicates a feeding attempt by a given bat.
> > So the "codes" are both species and information on the call type.</b>
> > But, at the moment you have two variables in the one column, Species:
> > The type of bat and feeding behaviour.
> > <b>The date/time is when the species was recorded and is linked to the
> > location.</b>
> > Okay. Will this give us a unique key?
> > <b>Therefore to run the summary stats I need I will need to remove the
> > duplicate times that are rounded to the minute</b>
> > What duplicate times? Where are they? When are they rounded?
> > I have never used Access. Will it produce a data dictionary? Can it
> > export a small subset of the relevant data to another Access DB, some
> > other DB or in .csv format? At the moment I just cannot visualize what
> > your data layout looks like.
> > Can you point us to any documentation that explains what information
> > in being gathered?preferably in simple?minded English?
> >
> > On Wed, 25 Dec 2019 at 12:08, Neotropical bat risk assessments
> > <neotropical.bats at gmail.com <mailto:neotropical.bats at gmail.com>> wrote:
> >
> >     Hi John,
> >
> >     Likely TMI but....
> >
> >     The example was only to show the data format, clearly not the
> >     entire data set. ;-)
> >     Analyses will be by locations, dates and species in any case so
> >     small subsets.
> >
> >     My master relational database has >1.9 million records.  These are
> >     acoustic data recordings of bats and includes data fro >425 species.
> >
> >     The 6 letter species codes relate to individual bat species and
> >     the Buzz = Feeding buzz that indicates a feeding attempt by a
> >     given bat.  So the "codes" are both species and information on the
> >     call type.
> >
> >     So yes, if a call includes a feeding buzz it is noted as Buzz in
> >     addition to the species ID codes..
> >     A given 15 second acoustic recording may have up to 5 species
> >     recorded and when imported into the relational DB each individual
> >     species is parsed into its own record as well as records of call
> >     notes e.g. Buzz.
> >
> >     The date/time is when the species was recorded and is linked to
> >     the location.
> >     Although the call data summary below is summarized by *minute* the
> >     actual data is recorded by time which includes seconds in addition
> >     to minutes.
> >     So there could be say 3+ files recorded during the same minute but
> >     at different time periods as seconds (0-59) are included.
> >
> >     Therefore to run the summary stats I need I will need to remove
> >     the duplicate times that are rounded to the minute.
> >
> >     Again tnx for taking time to reply.
> >
> >     Cheers,
> >
> >     Bruce
> >>     I am sorry but I am at a loss here.
> >>     According to your sample data you have 3 Species : Buzz,  Ptedav,
> >>     Ptemes, but you say that "Buzz" indicates that the bat is feeding.
> >>     What has that to do with feeding?
> >>
> >>     Assuming Buzz is feeding activity, are all incidents of feeding
> >>     activity a single point in time?
> >>
> >>     Likewise the data has multiple entries such as
> >>     Ptedav    7717    7/3/2000    20:15
> >>     Ptedav    7717    7/3/2000    20:15
> >>     Ptedav    7717    7/3/2000    20:15
> >>     Ptedav    7717    7/3/2000    20:15
> >>
> >>     What does that represent?
> >>
> >>
> >>     On Wed, 25 Dec 2019 at 07:29, Neotropical bat risk assessments
> >>     <neotropical.bats at gmail.com>  <mailto:neotropical.bats at gmail.com>
> wrote:
> >>>     Hi all,
> >>>
> >>>     It seems R has gotten better/more packages in dealing with time
> data.
> >>>
> >>>     I want to create "simple" summaries of time for bat activity.
> >>>     Data is all in an Access relational database and exported as a CSV
> file
> >>>     with 4 columns in this format:
> >>>     Species = a 6 letter code or "Buzz" to indicated when bats are
> feeding
> >>>     Location = a 4 digit number
> >>>     Date= MMDDYYYY
> >>>     Time=HH:MM (24 hr format)
> >>>
> >>>     Species    Location    Date    Time
> >>>     Buzz    7716    1/25/2000    0:05
> >>>     Buzz    7716    1/25/2000    0:05
> >>>     Buzz    7716    1/25/2000    0:05
> >>>     Buzz    7716    1/25/2000    0:47
> >>>     Buzz    7716    1/25/2000    0:47
> >>>     Buzz    7716    1/25/2000    0:47
> >>>     Buzz    7716    1/25/2000    0:47
> >>>     Buzz    7717    7/3/2000    20:17
> >>>     Buzz    7717    7/3/2000    20:17
> >>>     Buzz    7717    7/3/2000    20:17
> >>>     Buzz    7717    7/3/2000    20:17
> >>>     Buzz    7717    7/3/2000    20:30
> >>>     Buzz    7717    7/3/2000    20:30
> >>>     Buzz    7717    7/3/2000    20:30
> >>>     Buzz    7717    7/3/2000    20:30
> >>>     Ptedav    7717    7/3/2000    20:14
> >>>     Ptedav    7717    7/3/2000    20:15
> >>>     Ptedav    7717    7/3/2000    20:15
> >>>     Ptedav    7717    7/3/2000    20:15
> >>>     Ptedav    7717    7/3/2000    20:15
> >>>     Ptedav    7717    7/3/2000    20:15
> >>>     Ptedav    7717    7/3/2000    20:17
> >>>     Ptedav    7717    7/3/2000    20:17
> >>>     Ptedav    7717    7/3/2000    20:17
> >>>     Ptedav    7717    7/3/2000    20:18
> >>>     Ptedav    7717    7/3/2000    20:18
> >>>     Ptedav    7717    7/3/2000    20:18
> >>>     Ptedav    7717    7/3/2000    20:18
> >>>     Ptedav    7717    7/3/2000    20:18
> >>>     Ptemes    7717    7/3/2000    23:15
> >>>     Ptemes    7717    7/3/2000    23:21
> >>>     Ptemes    7717    7/3/2000    23:22
> >>>     Ptemes    7717    7/3/2000    23:23
> >>>     Ptemes    7717    7/3/2000    23:25
> >>>     Ptemes    7717    7/3/2000    23:26
> >>>     Ptemes    7717    7/3/2000    23:27
> >>>     Ptemes    7717    7/3/2000    23:28
> >>>     Ptemes    7717    7/3/2000    23:29
> >>>     Ptemes    7717    7/3/2000    23:33
> >>>     Ptemes    7717    7/3/2000    23:35
> >>>     Ptemes    7717    7/3/2000    23:36
> >>>     Ptemes    7717    7/3/2000    23:37
> >>>
> >>>     The above is clearly not a complete DF but only a format sample.
> Data
> >>>     begins when the first bat was recorded and ends when the last bat
> was
> >>>     recorded.  So all are times from sunset to sunrise.  Dates roll
> over so
> >>>     for example one night of data would begin at 18:00 1/1/2000 and end
> >>>     06:00 1/2/2000.
> >>>
> >>>     What I need to do is have a summary of Buzz events (feeding) and
> >>>     calculate the percentage of total time bats were active and have a
> >>>     summary of time feeding buzz was recorded and total bat activity to
> >>>     determine what percentage of time was spent with feeding attempts
> over
> >>>     the active period.
> >>>
> >>>     This by all bats by survey night and by single species by survey
> night.
> >>>     Any suggestions welcomed.
> >>>
> >>>     Happy holidays all
> >>>
> >>>
> >>>     --
> >>>     Bruce W. Miller, PhD.
> >>>     Neotropical bat risk assessments
> >>>     Conservation Fellow - Wildlife Conservation Society
> >>>
> >>>     If we lose the bats, we may lose much of the tropical vegetation
> and the lungs of the planet
> >>>
> >>>     Using acoustic sampling to identify and map species distributions
> >>>     and pioneering acoustic tools for ecology and conservation of bats
> for >25 years.
> >>>
> >>>     Key projects include providing free interactive identification
> keys and call fact sheets for the vocal signatures of New World Bats
> >>>
> >>>     ______________________________________________
> >>>     R-help at r-project.org  <mailto:R-help at r-project.org>  mailing list
> -- To UNSUBSCRIBE and more, see
> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>     PLEASE do read the posting guidehttp://
> www.R-project.org/posting-guide.html
> >>>     and provide commented, minimal, self-contained, reproducible code.
> >>     --
> >>     John Kane
> >>     Kingston ON Canada
> >
> >
> >     --
> >     Bruce W. Miller, PhD.
> >     Neotropical bat risk assessments
> >     Conservation Fellow - Wildlife Conservation Society
> >
> >     If we lose the bats, we may lose much of the tropical vegetation and
> the lungs of the planet
> >
> >     Using acoustic sampling to identify and map species distributions
> >     and pioneering acoustic tools for ecology and conservation of bats
> for >25 years.
> >
> >     Key projects include providing free interactive identification keys
> and call fact sheets for the vocal signatures of New World Bats
> >
> >
> >
> > --
> > John Kane
> > Kingston ON Canada
>
>
> --
> Bruce W. Miller, PhD.
> Neotropical bat risk assessments
> Conservation Fellow - Wildlife Conservation Society
>
> If we lose the bats, we may lose much of the tropical vegetation and the
> lungs of the planet
>
> Using acoustic sampling to identify and map species distributions
> and pioneering acoustic tools for ecology and conservation of bats for >25
> years.
>
> Key projects include providing free interactive identification keys and
> call fact sheets for the vocal signatures of New World Bats
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Thu Dec 26 00:10:36 2019
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Wed, 25 Dec 2019 18:10:36 -0500
Subject: [R] What is best way to calculate % of time?
In-Reply-To: <CAGxFJbQNqLM=ODqddzbABTdspe_crXMLhyEbu0BySLnE6o1Rnw@mail.gmail.com>
References: <mailman.357216.1.1577185201.3968.r-help@r-project.org>
 <edfc3e5e-4d92-95be-da3e-537c79d34b8e@gmail.com>
 <CAKZQJMBqQ0-aFAHjaYvGYj7zQB33Y8uWjz9fBOSuyjKhq_p+vw@mail.gmail.com>
 <4cd3b884-1055-86fc-0852-e8c5507a1a1b@gmail.com>
 <CAKZQJMDXv1D0TBvbi7kEHhKJjsjRHs35nny7somrvFHyB1-ycw@mail.gmail.com>
 <6a446c99-eae0-289d-5601-11c24aa2397c@gmail.com>
 <CAGxFJbQNqLM=ODqddzbABTdspe_crXMLhyEbu0BySLnE6o1Rnw@mail.gmail.com>
Message-ID: <4aa864c4-107e-52a2-b649-a5f4833545b6@gmail.com>

Hi Bert,

Tnx for taking time to reply.
For clarification... the data do EXPLICITLY indicate when each species 
is active and when a feeding buzz is recorded.
That is ALL it provides based on acoustic data recorded in the field.? 
Only when a species is recorded? is it identified as active.
How this is accomplished is of no importance to the question I asked.

Note this is Not "individuals" per se. but species as a group.

I appreciate you taking time to reply.
Clearly this is not a simple solution to what I assumed to be a simple 
question.
Restated as...
*How best to use R to calculate occurrence of event( (A) over time vs 
all events (b...n) over the same time period give the data frame work I 
have.*

Cheers,
Bruce


> I will not get into your explanation of details that, like John, I 
> find opaque. Please DO read Hadley's manifesto, as it appears that you 
> need to organize your data more appropriately.
>
> AFAICS, however, strictly speaking your data cannot answer the 
> question you have posed. **Strictly speaking** to know the proportion 
> of active time bats spend feeding, **for each bat** you would need to 
> know when it is active and when it is feeding during that time. You 
> could then summarize this for all bats (e.g. take the average or 
> median proportion) in a species or whatever. As you cannot identify 
> individual bats in your data, you cannot do this -- i.e. you cannot 
> answer your question.
>
> So the question then becomes: precisely **how** exactly do you propose 
> using the data you have to determine when a *group* of bats are active 
> and when they are feeding? How are the groups explicitly identified 
> and how are their times active and feeding determined? In short, you 
> need to have information that is something like:
>
> Bat.Group date?? active.time.start? active.time.end? 
> feeding.time.start feeding.time.end
>
> ( for a given date and bat group, there may be many multiple entries; 
> perhaps for a given group, date, and active time start and end, 
> several feeding time start/stop entries ( I have no idea how bats 
> behave)).
>
> Until you can expicitly explain how your data can generate such 
> information, I think it will be difficult/impossible to help you.
>
> Cheers,
> Bert
>

	[[alternative HTML version deleted]]


From jrkr|de@u @end|ng |rom gm@||@com  Thu Dec 26 00:50:36 2019
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Wed, 25 Dec 2019 18:50:36 -0500
Subject: [R] What is best way to calculate % of time?
In-Reply-To: <4aa864c4-107e-52a2-b649-a5f4833545b6@gmail.com>
References: <mailman.357216.1.1577185201.3968.r-help@r-project.org>
 <edfc3e5e-4d92-95be-da3e-537c79d34b8e@gmail.com>
 <CAKZQJMBqQ0-aFAHjaYvGYj7zQB33Y8uWjz9fBOSuyjKhq_p+vw@mail.gmail.com>
 <4cd3b884-1055-86fc-0852-e8c5507a1a1b@gmail.com>
 <CAKZQJMDXv1D0TBvbi7kEHhKJjsjRHs35nny7somrvFHyB1-ycw@mail.gmail.com>
 <6a446c99-eae0-289d-5601-11c24aa2397c@gmail.com>
 <CAGxFJbQNqLM=ODqddzbABTdspe_crXMLhyEbu0BySLnE6o1Rnw@mail.gmail.com>
 <4aa864c4-107e-52a2-b649-a5f4833545b6@gmail.com>
Message-ID: <CAKZQJMATQs+RU1WyKByzWcV2b4iXiYqZPo4PDNPD0jHLZSVX4A@mail.gmail.com>

 LyX Document
Hi Bruce,
<b> Combining date and times does not provide for sampling nights that roll
over after midnight. </b>
Ah yesss legacies
<b>The location, date and time does provide unique variables.</b>
Ah, i thought so
<b>Rounding to nearest minute suffices for a summary of total minutes spent
with "feeding attempts" vs total active time.</b>
Okay, that removes my worry about durations. We can just treat each entry
as one elapsed minute?
however I still do not grasp the duplicated issue. we have in my dataframe:
Species Location dtime
Ptedav 7717 2000-07-03 20:15:00
Ptedav 7717 2000-07-03 20:15:00
Ptedav 7717 2000-07-03 20:15:00
Ptedav 7717 2000-07-03 20:15:00
Ptedav 7717 2000-07-03 20:15:00
I assume that this represents 5 separate recording but that they can be
collapsed into one 1-minute data point?  If so then would not all you need
to do is run a simple table() command? To handle the Buzz one mould produce
the Buzz data.frame and merge it with the new species data.frame?
I must be missing something. It looks too simple.



On Wed, 25 Dec 2019 at 18:11, Neotropical bat risk assessments <
neotropical.bats at gmail.com> wrote:

> Hi Bert,
>
> Tnx for taking time to reply.
> For clarification... the data do EXPLICITLY indicate when each species
> is active and when a feeding buzz is recorded.
> That is ALL it provides based on acoustic data recorded in the field.
> Only when a species is recorded  is it identified as active.
> How this is accomplished is of no importance to the question I asked.
>
> Note this is Not "individuals" per se. but species as a group.
>
> I appreciate you taking time to reply.
> Clearly this is not a simple solution to what I assumed to be a simple
> question.
> Restated as...
> *How best to use R to calculate occurrence of event( (A) over time vs
> all events (b...n) over the same time period give the data frame work I
> have.*
>
> Cheers,
> Bruce
>
>
> > I will not get into your explanation of details that, like John, I
> > find opaque. Please DO read Hadley's manifesto, as it appears that you
> > need to organize your data more appropriately.
> >
> > AFAICS, however, strictly speaking your data cannot answer the
> > question you have posed. **Strictly speaking** to know the proportion
> > of active time bats spend feeding, **for each bat** you would need to
> > know when it is active and when it is feeding during that time. You
> > could then summarize this for all bats (e.g. take the average or
> > median proportion) in a species or whatever. As you cannot identify
> > individual bats in your data, you cannot do this -- i.e. you cannot
> > answer your question.
> >
> > So the question then becomes: precisely **how** exactly do you propose
> > using the data you have to determine when a *group* of bats are active
> > and when they are feeding? How are the groups explicitly identified
> > and how are their times active and feeding determined? In short, you
> > need to have information that is something like:
> >
> > Bat.Group date   active.time.start  active.time.end
> > feeding.time.start feeding.time.end
> >
> > ( for a given date and bat group, there may be many multiple entries;
> > perhaps for a given group, date, and active time start and end,
> > several feeding time start/stop entries ( I have no idea how bats
> > behave)).
> >
> > Until you can expicitly explain how your data can generate such
> > information, I think it will be difficult/impossible to help you.
> >
> > Cheers,
> > Bert
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From t@ub|@ @end|ng |rom |mgprec|@|on@com  Thu Dec 26 18:54:16 2019
From: t@ub|@ @end|ng |rom |mgprec|@|on@com (Thomas Subia)
Date: Thu, 26 Dec 2019 17:54:16 +0000
Subject: [R] Checking for similar file names in two different directories
Message-ID: <CH2PR17MB3749BF7968796E4758864893B82B0@CH2PR17MB3749.namprd17.prod.outlook.com>

Colleagues,

I have two locations where my data resides.
One folder is for data taken under treatment A
One folder is for data taken under treatment B

"G:\ 0020-49785 10806.xls"
"Q:\ 301864 4519 10806.xls"

Here the 10806 is the part which is common to both directories.

Is there a way to have R extract parts common to both directories?

Thomas Subia 
Statistician / Senior Quality Engineer
ASQ CQE

IMG Companies?
225 Mountain Vista Parkway
Livermore, CA 94551
T.?(925) 273-1106
F.?(925) 273-1111
E. tsubia at imgprecision.com


Precision Manufacturing for Emerging Technologies
imgprecision.com?

The contents of this message, together with any attachments, are intended only for the use of the individual or entity to which they are addressed and may contain information that is legally privileged, confidential and exempt from disclosure. If you are not the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this message, or any attachment, is strictly prohibited. If you have received this message in error, please notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and delete this message, along with any attachments, from your computer. Thank you.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Dec 26 19:48:49 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 26 Dec 2019 10:48:49 -0800
Subject: [R] 
 Checking for similar file names in two different directories
In-Reply-To: <CH2PR17MB3749BF7968796E4758864893B82B0@CH2PR17MB3749.namprd17.prod.outlook.com>
References: <CH2PR17MB3749BF7968796E4758864893B82B0@CH2PR17MB3749.namprd17.prod.outlook.com>
Message-ID: <CAGxFJbT8XZ2Vh4LLkhQ9M_-uKmSVpJdYdg0KkaN4Pm4JO8x9tw@mail.gmail.com>

?list.files and ?regexp

Warning: following obviously untested:

Gfiles <- list.files("G:", pattern = ".*10806\\.xls$")

should then give you a vector of character names of the files you want to
feed to read.xls() or whatever function exists in the favored package is
for reading Excel files these days.

Cheers,
Bert



On Thu, Dec 26, 2019 at 9:54 AM Thomas Subia <tsubia at imgprecision.com>
wrote:

> Colleagues,
>
> I have two locations where my data resides.
> One folder is for data taken under treatment A
> One folder is for data taken under treatment B
>
> "G:\ 0020-49785 10806.xls"
> "Q:\ 301864 4519 10806.xls"
>
> Here the 10806 is the part which is common to both directories.
>
> Is there a way to have R extract parts common to both directories?
>
> Thomas Subia
> Statistician / Senior Quality Engineer
> ASQ CQE
>
> IMG Companies
> 225 Mountain Vista Parkway
> Livermore, CA 94551
> T. (925) 273-1106
> F. (925) 273-1111
> E. tsubia at imgprecision.com
>
>
> Precision Manufacturing for Emerging Technologies
> imgprecision.com
>
> The contents of this message, together with any attachments, are intended
> only for the use of the individual or entity to which they are addressed
> and may contain information that is legally privileged, confidential and
> exempt from disclosure. If you are not the intended recipient, you are
> hereby notified that any dissemination, distribution, or copying of this
> message, or any attachment, is strictly prohibited. If you have received
> this message in error, please notify the original sender or IMG Companies,
> LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and
> delete this message, along with any attachments, from your computer. Thank
> you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Dec 26 19:59:29 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 26 Dec 2019 18:59:29 +0000
Subject: [R] 
 Checking for similar file names in two different directories
In-Reply-To: <CH2PR17MB3749BF7968796E4758864893B82B0@CH2PR17MB3749.namprd17.prod.outlook.com>
References: <CH2PR17MB3749BF7968796E4758864893B82B0@CH2PR17MB3749.namprd17.prod.outlook.com>
Message-ID: <906ee614-c8cb-9db8-f0a5-267e6d0ee533@sapo.pt>

Hello,

I am not sure if the following code is what you need but maybe you can 
get some inspiration from it.


x <- c("G:\ 0020-49785 10806.xls", "Q:\ 301864 4519 10806.xls")

y <- strsplit(x, split = "[^[:alnum:]]+")
eq <- sapply(y[[1]], `==`, y[[2]])
i <- apply(eq, 1, function(e) Reduce(`|`, e))

y[[1]][i]
#[1] "10806" "xls"


This returns "10806" but also returns the file extension "xls".
And it could be made to loop through a vector of filenames.


Hope this helps,

Rui Barradas

?s 17:54 de 26/12/19, Thomas Subia escreveu:
> Colleagues,
> 
> I have two locations where my data resides.
> One folder is for data taken under treatment A
> One folder is for data taken under treatment B
> 
> "G:\ 0020-49785 10806.xls"
> "Q:\ 301864 4519 10806.xls"
> 
> Here the 10806 is the part which is common to both directories.
> 
> Is there a way to have R extract parts common to both directories?
> 
> Thomas Subia
> Statistician / Senior Quality Engineer
> ASQ CQE
> 
> IMG Companies
> 225 Mountain Vista Parkway
> Livermore, CA 94551
> T.?(925) 273-1106
> F.?(925) 273-1111
> E. tsubia at imgprecision.com
> 
> 
> Precision Manufacturing for Emerging Technologies
> imgprecision.com
> 
> The contents of this message, together with any attachments, are intended only for the use of the individual or entity to which they are addressed and may contain information that is legally privileged, confidential and exempt from disclosure. If you are not the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this message, or any attachment, is strictly prohibited. If you have received this message in error, please notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and delete this message, along with any attachments, from your computer. Thank you.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@oknz @end|ng |rom gm@||@com  Fri Dec 27 02:34:12 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 27 Dec 2019 14:34:12 +1300
Subject: [R] 
 Checking for similar file names in two different directories
In-Reply-To: <CH2PR17MB3749BF7968796E4758864893B82B0@CH2PR17MB3749.namprd17.prod.outlook.com>
References: <CH2PR17MB3749BF7968796E4758864893B82B0@CH2PR17MB3749.namprd17.prod.outlook.com>
Message-ID: <CABcYAdKu4_Qjet4Q-bQnfZUJ4sXrj7B7bvTchczZpHH4cx+Yow@mail.gmail.com>

I think you had better start by defining what you mean by "similar".
Examples are good, but not enough.

On Fri, 27 Dec 2019 at 06:54, Thomas Subia <tsubia at imgprecision.com> wrote:
>
> Colleagues,
>
> I have two locations where my data resides.
> One folder is for data taken under treatment A
> One folder is for data taken under treatment B
>
> "G:\ 0020-49785 10806.xls"
> "Q:\ 301864 4519 10806.xls"
>
> Here the 10806 is the part which is common to both directories.
>
> Is there a way to have R extract parts common to both directories?
>
> Thomas Subia
> Statistician / Senior Quality Engineer
> ASQ CQE
>
> IMG Companies
> 225 Mountain Vista Parkway
> Livermore, CA 94551
> T. (925) 273-1106
> F. (925) 273-1111
> E. tsubia at imgprecision.com
>
>
> Precision Manufacturing for Emerging Technologies
> imgprecision.com
>
> The contents of this message, together with any attachments, are intended only for the use of the individual or entity to which they are addressed and may contain information that is legally privileged, confidential and exempt from disclosure. If you are not the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this message, or any attachment, is strictly prohibited. If you have received this message in error, please notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and delete this message, along with any attachments, from your computer. Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Dec 27 05:22:55 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 26 Dec 2019 20:22:55 -0800
Subject: [R] 
 Checking for similar file names in two different directories
In-Reply-To: <CH2PR17MB3749BF7968796E4758864893B82B0@CH2PR17MB3749.namprd17.prod.outlook.com>
References: <CH2PR17MB3749BF7968796E4758864893B82B0@CH2PR17MB3749.namprd17.prod.outlook.com>
Message-ID: <CAGxFJbQT-KNFRqqiPi_VAfJn8S9qPRy0mBTnyJJ3HzrfuXqUOg@mail.gmail.com>

AHA! -- I think I now see what you mean.

My previous suggestion was almost useless as it assumes you already know
what the "common" parts are ... but you don't.

However, if it is the filename parts at the end are separated by spaces
from the preceding part of the filename, i.e. like "stuff xxxxxxx.xls",
then something like the following example would work I think:

## Read in *all* the filenames from both directories as I previously
suggested.

Gfiles <- list.files("G:")
Qfiles <- list.files("Q:")

Suppose this gave you (a simplified example):

> Gfiles
 [1] "kjqdx 157.xls" "aorgz 287.xls" "ioldc 380.xls" "fpnxr 509.xls"
 [5] "wytcg 853.xls" "xujos 964.xls" "xdeto 217.xls" "nqriu 574.xls"
 [9] "jclir 480.xls" "fndyu 769.xls"
> Qfiles
 [1] "vexrb 509.xls" "jxeio 770.xls" "zhmwf 920.xls" "cajdq 287.xls"
 [5] "nwdic 259.xls" "sqjkb 889.xls" "brhfu 157.xls" "uyirq 574.xls"
 [9] "ijfqm 480.xls" "nedhj 982.xls"

## all that's important is the " xxx.xls" at the end
## extract the filename part, omitting the ".xls" using regex's
> Gnm <- sub("^.+ (.+)\\.xls$","\\1",Gfiles)
> Qnm <- sub("^.+ (.+)\\.xls$","\\1",Qfiles)

> Gnm
 [1] "157" "287" "380" "509" "853" "964" "217" "574" "480" "769"
> Qnm
 [1] "509" "770" "920" "287" "259" "889" "157" "574" "480" "982"

> ## The 'common' parts are:
> intersect(Gnm,Qnm)
[1] "157" "287" "509" "574" "480"

You can now use these as I described previously to extract your common
files.

A similar strategy can be used for any other definition of "common" you
wish to use *provided* you can uniquely and specifically define "common" to
match  in the filenames.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 26, 2019 at 9:54 AM Thomas Subia <tsubia at imgprecision.com>
wrote:

> Colleagues,
>
> I have two locations where my data resides.
> One folder is for data taken under treatment A
> One folder is for data taken under treatment B
>
> "G:\ 0020-49785 10806.xls"
> "Q:\ 301864 4519 10806.xls"
>
> Here the 10806 is the part which is common to both directories.
>
> Is there a way to have R extract parts common to both directories?
>
> Thomas Subia
> Statistician / Senior Quality Engineer
> ASQ CQE
>
> IMG Companies
> 225 Mountain Vista Parkway
> Livermore, CA 94551
> T. (925) 273-1106
> F. (925) 273-1111
> E. tsubia at imgprecision.com
>
>
> Precision Manufacturing for Emerging Technologies
> imgprecision.com
>
> The contents of this message, together with any attachments, are intended
> only for the use of the individual or entity to which they are addressed
> and may contain information that is legally privileged, confidential and
> exempt from disclosure. If you are not the intended recipient, you are
> hereby notified that any dissemination, distribution, or copying of this
> message, or any attachment, is strictly prohibited. If you have received
> this message in error, please notify the original sender or IMG Companies,
> LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and
> delete this message, along with any attachments, from your computer. Thank
> you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Dec 27 11:24:03 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 27 Dec 2019 10:24:03 +0000
Subject: [R] What is best way to calculate % of time?
In-Reply-To: <4aa864c4-107e-52a2-b649-a5f4833545b6@gmail.com>
References: <mailman.357216.1.1577185201.3968.r-help@r-project.org>
 <edfc3e5e-4d92-95be-da3e-537c79d34b8e@gmail.com>
 <CAKZQJMBqQ0-aFAHjaYvGYj7zQB33Y8uWjz9fBOSuyjKhq_p+vw@mail.gmail.com>
 <4cd3b884-1055-86fc-0852-e8c5507a1a1b@gmail.com>
 <CAKZQJMDXv1D0TBvbi7kEHhKJjsjRHs35nny7somrvFHyB1-ycw@mail.gmail.com>
 <6a446c99-eae0-289d-5601-11c24aa2397c@gmail.com>
 <CAGxFJbQNqLM=ODqddzbABTdspe_crXMLhyEbu0BySLnE6o1Rnw@mail.gmail.com>
 <4aa864c4-107e-52a2-b649-a5f4833545b6@gmail.com>
Message-ID: <d94ed7a289b14849ac704a8aaf5440c7@SRVEXCHCM1302.precheza.cz>

Well

If you can make ggplot based on your data, there should be a way to produce 
summary. Just as curiosity, the data you showed us are the same as you use for 
ggplot construction?

Maybe I misunderstood your question but let's assume you have records from 
each location but only BUZZ time is indicated rounded to minutes.

I would use few steps
First step - sort data frame according to time and aggregate it to get minutes 
of BUZZ time during a time period

Second step - merge artificial data frame with full time in minutes (either 
525600 or  527040 rows if full day should be considered) with your BUZZ data 
frame. This is partly complicated step if you want to consider only night time 
and before merging you should remove daytime. Or maybe you are already able to 
extract one data frame with Buzz activity and one data frame with timespan for 
each day. Again the result of this merging step should be data frame in which 
you have one time column for total time in minutes and one column indicating 
when the buzz was observed.

Third step - aggregate resulting data frame to get BUZZ time in each day 
either by table as suggested or by ?aggregate

Based on data from John

Here is aggregated data frame
dat2.ag<- aggregate(dat2$dtime, list(dat2$Species, dat2$Location, 
format(dat2$dtime, "%d.%m.%Y %H:%M")), min)

And result of table
> table(dat2.ag$Group.1, dat2.ag$Group.2)

         7716 7717
  Buzz      2    2
  Ptedav    0    4
  Ptemes    0   13

indicating 2 minutes Buzz in location 7716 and 2 minutes in location 7717.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Neotropical bat
> risk assessments
> Sent: Thursday, December 26, 2019 12:11 AM
> To: Bert Gunter <bgunter.4567 at gmail.com>
> Cc: R. Help Mailing List <r-help at r-project.org>
> Subject: Re: [R] What is best way to calculate % of time?
>
> Hi Bert,
>
> Tnx for taking time to reply.
> For clarification... the data do EXPLICITLY indicate when each species is
> active and when a feeding buzz is recorded.
> That is ALL it provides based on acoustic data recorded in the field. Only
> when a species is recorded  is it identified as active.
> How this is accomplished is of no importance to the question I asked.
>
> Note this is Not "individuals" per se. but species as a group.
>
> I appreciate you taking time to reply.
> Clearly this is not a simple solution to what I assumed to be a simple
> question.
> Restated as...
> *How best to use R to calculate occurrence of event( (A) over time vs all
> events (b...n) over the same time period give the data frame work I
> have.*
>
> Cheers,
> Bruce
>
>
> > I will not get into your explanation of details that, like John, I
> > find opaque. Please DO read Hadley's manifesto, as it appears that you
> > need to organize your data more appropriately.
> >
> > AFAICS, however, strictly speaking your data cannot answer the
> > question you have posed. **Strictly speaking** to know the proportion
> > of active time bats spend feeding, **for each bat** you would need to
> > know when it is active and when it is feeding during that time. You
> > could then summarize this for all bats (e.g. take the average or
> > median proportion) in a species or whatever. As you cannot identify
> > individual bats in your data, you cannot do this -- i.e. you cannot
> > answer your question.
> >
> > So the question then becomes: precisely **how** exactly do you propose
> > using the data you have to determine when a *group* of bats are active
> > and when they are feeding? How are the groups explicitly identified
> > and how are their times active and feeding determined? In short, you
> > need to have information that is something like:
> >
> > Bat.Group date   active.time.start  active.time.end feeding.time.start
> > feeding.time.end
> >
> > ( for a given date and bat group, there may be many multiple entries;
> > perhaps for a given group, date, and active time start and end,
> > several feeding time start/stop entries ( I have no idea how bats
> > behave)).
> >
> > Until you can expicitly explain how your data can generate such
> > information, I think it will be difficult/impossible to help you.
> >
> > Cheers,
> > Bert
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Fri Dec 27 13:33:07 2019
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Fri, 27 Dec 2019 07:33:07 -0500
Subject: [R] What is best way to calculate % of time?
In-Reply-To: <d94ed7a289b14849ac704a8aaf5440c7@SRVEXCHCM1302.precheza.cz>
References: <mailman.357216.1.1577185201.3968.r-help@r-project.org>
 <edfc3e5e-4d92-95be-da3e-537c79d34b8e@gmail.com>
 <CAKZQJMBqQ0-aFAHjaYvGYj7zQB33Y8uWjz9fBOSuyjKhq_p+vw@mail.gmail.com>
 <4cd3b884-1055-86fc-0852-e8c5507a1a1b@gmail.com>
 <CAKZQJMDXv1D0TBvbi7kEHhKJjsjRHs35nny7somrvFHyB1-ycw@mail.gmail.com>
 <6a446c99-eae0-289d-5601-11c24aa2397c@gmail.com>
 <CAGxFJbQNqLM=ODqddzbABTdspe_crXMLhyEbu0BySLnE6o1Rnw@mail.gmail.com>
 <4aa864c4-107e-52a2-b649-a5f4833545b6@gmail.com>
 <d94ed7a289b14849ac704a8aaf5440c7@SRVEXCHCM1302.precheza.cz>
Message-ID: <d29fa51f-371a-4e59-2eaa-64db86c64623@gmail.com>

Tnx all for the helpful suggestions.

Life is good.
Happy holidays
Bruce

-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


From p@u|bern@|07 @end|ng |rom gm@||@com  Fri Dec 27 16:42:36 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 27 Dec 2019 10:42:36 -0500
Subject: [R] Converting Decimal numbers into Binary
Message-ID: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>

Dear friends,

Hope you are all doing well. I need to find a way to convert ascii numbers
to six digit binary numbers:

I am working with this example, I converted the string to ascii, and
finally to decimal, but I am having trouble converting the decimal numbers
into their six digit binary representation. The code below is exactly what
I have so far:

ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
ascii_datformat

Base <- ascii_datformat - 48

ifelse(Base > 40, Base-8, Base)

x <- rev(intToBits(Base))
dec2bin <- function(x) paste(as.integer(rev(intToBits(x))), collapse = "")
dec2bin

any guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Dec 27 17:11:11 2019
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 27 Dec 2019 11:11:11 -0500
Subject: [R] Converting Decimal numbers into Binary
In-Reply-To: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
References: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
Message-ID: <A640D5AF-6B45-41D8-BEF4-B63E1C36328B@me.com>


> On Dec 27, 2019, at 10:42 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends,
> 
> Hope you are all doing well. I need to find a way to convert ascii numbers
> to six digit binary numbers:
> 
> I am working with this example, I converted the string to ascii, and
> finally to decimal, but I am having trouble converting the decimal numbers
> into their six digit binary representation. The code below is exactly what
> I have so far:
> 
> ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
> ascii_datformat
> 
> Base <- ascii_datformat - 48
> 
> ifelse(Base > 40, Base-8, Base)
> 
> x <- rev(intToBits(Base))
> dec2bin <- function(x) paste(as.integer(rev(intToBits(x))), collapse = "")
> dec2bin
> 
> any guidance will be greatly appreciated,
> 
> Best regards,
> 
> Paul


You might look at the intToBin() function in Henrik's R.utils package on CRAN:

https://cran.r-project.org/web/packages/R.utils/index.html

Regards,

Marc Schwartz


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Dec 27 17:18:09 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Dec 2019 08:18:09 -0800
Subject: [R] Converting Decimal numbers into Binary
In-Reply-To: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
References: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
Message-ID: <9F6F2063-D483-4CA7-9DA6-7A41FF09A0A9@dcn.davis.ca.us>

Your question is incomplete... what do you expect the result to be?

Perhaps [1] is relevant?

[1] https://stackoverflow.com/questions/52298995/r-binary-decimal-conversion-confusion-ais-data

On December 27, 2019 7:42:36 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear friends,
>
>Hope you are all doing well. I need to find a way to convert ascii
>numbers
>to six digit binary numbers:
>
>I am working with this example, I converted the string to ascii, and
>finally to decimal, but I am having trouble converting the decimal
>numbers
>into their six digit binary representation. The code below is exactly
>what
>I have so far:
>
>ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
>ascii_datformat
>
>Base <- ascii_datformat - 48
>
>ifelse(Base > 40, Base-8, Base)
>
>x <- rev(intToBits(Base))
>dec2bin <- function(x) paste(as.integer(rev(intToBits(x))), collapse =
>"")
>dec2bin
>
>any guidance will be greatly appreciated,
>
>Best regards,
>
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From p@u|bern@|07 @end|ng |rom gm@||@com  Fri Dec 27 17:30:44 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 27 Dec 2019 11:30:44 -0500
Subject: [R] Converting Decimal numbers into Binary
In-Reply-To: <9F6F2063-D483-4CA7-9DA6-7A41FF09A0A9@dcn.davis.ca.us>
References: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
 <9F6F2063-D483-4CA7-9DA6-7A41FF09A0A9@dcn.davis.ca.us>
Message-ID: <CAMOcQfMNXEiSSjRspof-g9cgJu97DHpQy9xETWE=3SLgntyaFw@mail.gmail.com>

Dear Jeff,

Hope you are doing great. The link I provide below has the results I am
expecting. I am doing a test, trying to convert this string: "133m at ogP00PD
;88MD5MTDww at 2D7k" into ascii numbers, then to decimal, and ultimately, into
binary. I am trying to recreate the results obtained in the link below.

http://www.it-digin.com/blog/?p=20

Hope this answers your question.

Thanks for any guidance you can provide,

Cheers,

Paul

El vie., 27 dic. 2019 a las 11:18, Jeff Newmiller (<jdnewmil at dcn.davis.ca.us>)
escribi?:

> Your question is incomplete... what do you expect the result to be?
>
> Perhaps [1] is relevant?
>
> [1]
> https://stackoverflow.com/questions/52298995/r-binary-decimal-conversion-confusion-ais-data
>
> On December 27, 2019 7:42:36 AM PST, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >Dear friends,
> >
> >Hope you are all doing well. I need to find a way to convert ascii
> >numbers
> >to six digit binary numbers:
> >
> >I am working with this example, I converted the string to ascii, and
> >finally to decimal, but I am having trouble converting the decimal
> >numbers
> >into their six digit binary representation. The code below is exactly
> >what
> >I have so far:
> >
> >ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
> >ascii_datformat
> >
> >Base <- ascii_datformat - 48
> >
> >ifelse(Base > 40, Base-8, Base)
> >
> >x <- rev(intToBits(Base))
> >dec2bin <- function(x) paste(as.integer(rev(intToBits(x))), collapse =
> >"")
> >dec2bin
> >
> >any guidance will be greatly appreciated,
> >
> >Best regards,
> >
> >Paul
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Dec 27 17:34:16 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 27 Dec 2019 11:34:16 -0500
Subject: [R] Converting Decimal numbers into Binary
In-Reply-To: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
References: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
Message-ID: <CAGx1TMC2JXEjiGPWe5_59aLgXxj2xOpjKUuKuWKKEQK5CRvbwQ@mail.gmail.com>

Use the Rmpfr  package.
it will print numbers in any base from 2  to 62
> library(Rmpfr)
> ?Rmpfr
> b15 <- mpfr(15, precBits=6)
> formatBin(b15)
[1] +0b1.11100p+3
>

On Fri, Dec 27, 2019 at 10:43 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends,
>
> Hope you are all doing well. I need to find a way to convert ascii numbers
> to six digit binary numbers:
>
> I am working with this example, I converted the string to ascii, and
> finally to decimal, but I am having trouble converting the decimal numbers
> into their six digit binary representation. The code below is exactly what
> I have so far:
>
> ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
> ascii_datformat
>
> Base <- ascii_datformat - 48
>
> ifelse(Base > 40, Base-8, Base)
>
> x <- rev(intToBits(Base))
> dec2bin <- function(x) paste(as.integer(rev(intToBits(x))), collapse = "")
> dec2bin
>
> any guidance will be greatly appreciated,
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Fri Dec 27 17:43:29 2019
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Fri, 27 Dec 2019 08:43:29 -0800
Subject: [R] Converting Decimal numbers into Binary
In-Reply-To: <A640D5AF-6B45-41D8-BEF4-B63E1C36328B@me.com>
References: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
 <A640D5AF-6B45-41D8-BEF4-B63E1C36328B@me.com>
Message-ID: <CAA99HCwMtUnVTNAzytBCnT1f0ga7SshE0kxdjxJ1B18HNBDbYA@mail.gmail.com>

Hi Paul,

Since you start from strings, it's not clear to me where ASCII enters
the picture. If you really need ASCII, you can use the charToInt()
function in the "R.oo" package. Also there's the AsciiToInt() function
in the  "sfsmisc" package. If you just want to use R's native
as.numeric() conversion, there's the digitsBase() function in the
"sfsmisc" package:

> library(sfsmisc)
> digitsBase(as.numeric("63"), base = 2)
Class 'basedInt'(base = 2) [1:1]
     [,1]
[1,]    1
[2,]    1
[3,]    1
[4,]    1
[5,]    1
[6,]    1
>

HTH, Bill.

W. Michels, Ph.D.


On Fri, Dec 27, 2019 at 8:11 AM Marc Schwartz via R-help
<r-help at r-project.org> wrote:
>
>
> > On Dec 27, 2019, at 10:42 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> > Dear friends,
> >
> > Hope you are all doing well. I need to find a way to convert ascii numbers
> > to six digit binary numbers:
> >
> > I am working with this example, I converted the string to ascii, and
> > finally to decimal, but I am having trouble converting the decimal numbers
> > into their six digit binary representation. The code below is exactly what
> > I have so far:
> >
> > ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
> > ascii_datformat
> >
> > Base <- ascii_datformat - 48
> >
> > ifelse(Base > 40, Base-8, Base)
> >
> > x <- rev(intToBits(Base))
> > dec2bin <- function(x) paste(as.integer(rev(intToBits(x))), collapse = "")
> > dec2bin
> >
> > any guidance will be greatly appreciated,
> >
> > Best regards,
> >
> > Paul
>
>
> You might look at the intToBin() function in Henrik's R.utils package on CRAN:
>
> https://cran.r-project.org/web/packages/R.utils/index.html
>
> Regards,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Dec 27 18:31:41 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 27 Dec 2019 17:31:41 +0000
Subject: [R] Converting Decimal numbers into Binary
In-Reply-To: <CAMOcQfMNXEiSSjRspof-g9cgJu97DHpQy9xETWE=3SLgntyaFw@mail.gmail.com>
References: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
 <9F6F2063-D483-4CA7-9DA6-7A41FF09A0A9@dcn.davis.ca.us>
 <CAMOcQfMNXEiSSjRspof-g9cgJu97DHpQy9xETWE=3SLgntyaFw@mail.gmail.com>
Message-ID: <b749f5a6-c863-e5a3-8a95-fca30da3597e@sapo.pt>

Hello,


Your code and the answers provided, specially Marc's, led me to


utf8ToBin <- function(x, out = c("ascii", "dec", "bin")){
   out <- match.arg(out)
   ascii_datformat <- utf8ToInt(x)
   Base <- ascii_datformat - 48
   Base <- ifelse(Base > 40, Base - 8, Base)
   Bin <- R.utils::intToBin(Base)
   switch (out,
     "ascii" = ascii_datformat,
     "dec" = Base,
     "bin" = Bin
   )
}

utf8ToBin("133m@", out = "ascii")
utf8ToBin("133m@", out = "dec")
utf8ToBin("133m@", out = "bin")


Hope this helps,

Rui Barradas

?s 16:30 de 27/12/19, Paul Bernal escreveu:
> Dear Jeff,
> 
> Hope you are doing great. The link I provide below has the results I am
> expecting. I am doing a test, trying to convert this string: "133m at ogP00PD
> ;88MD5MTDww at 2D7k" into ascii numbers, then to decimal, and ultimately, into
> binary. I am trying to recreate the results obtained in the link below.
> 
> http://www.it-digin.com/blog/?p=20
> 
> Hope this answers your question.
> 
> Thanks for any guidance you can provide,
> 
> Cheers,
> 
> Paul
> 
> El vie., 27 dic. 2019 a las 11:18, Jeff Newmiller (<jdnewmil at dcn.davis.ca.us>)
> escribi?:
> 
>> Your question is incomplete... what do you expect the result to be?
>>
>> Perhaps [1] is relevant?
>>
>> [1]
>> https://stackoverflow.com/questions/52298995/r-binary-decimal-conversion-confusion-ais-data
>>
>> On December 27, 2019 7:42:36 AM PST, Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>> Dear friends,
>>>
>>> Hope you are all doing well. I need to find a way to convert ascii
>>> numbers
>>> to six digit binary numbers:
>>>
>>> I am working with this example, I converted the string to ascii, and
>>> finally to decimal, but I am having trouble converting the decimal
>>> numbers
>>> into their six digit binary representation. The code below is exactly
>>> what
>>> I have so far:
>>>
>>> ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
>>> ascii_datformat
>>>
>>> Base <- ascii_datformat - 48
>>>
>>> ifelse(Base > 40, Base-8, Base)
>>>
>>> x <- rev(intToBits(Base))
>>> dec2bin <- function(x) paste(as.integer(rev(intToBits(x))), collapse =
>>> "")
>>> dec2bin
>>>
>>> any guidance will be greatly appreciated,
>>>
>>> Best regards,
>>>
>>> Paul
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From b@ye@|@n|og|c@1 @end|ng |rom gm@||@com  Fri Dec 27 21:27:01 2019
From: b@ye@|@n|og|c@1 @end|ng |rom gm@||@com (Jan Galkowski)
Date: Fri, 27 Dec 2019 15:27:01 -0500
Subject: [R] spurious locking of packages
In-Reply-To: <mailman.357243.1.1577444401.20251.r-help@r-project.org>
References: <mailman.357243.1.1577444401.20251.r-help@r-project.org>
Message-ID: <b43c72ad-c214-47f8-9539-33870cd2c996@www.fastmail.com>

I have been having a problem installing binary packages on Windows, since 3.6.x hit the streets.


I am using the
> 
> INSTALL_opts = c('--no-lock')
> 
option, but it occurs nevertheless. My habit is to install an update of R (latest, 3.6.2), then run update.packages(.):

> 
> trying URL 'https://cran.cnr.berkeley.edu/bin/windows/contrib/3.6/zoib_1.5.4.zip'
> Content type 'application/zip' length 350788 bytes (342 KB)
> downloaded 342 KB
> 
> package ?elasticnet? successfully unpacked and MD5 sums checked
> package ?ellipse? successfully unpacked and MD5 sums checked
> package ?elliptic? successfully unpacked and MD5 sums checked
> package ?EMCluster? successfully unpacked and MD5 sums checked
> package ?EMD? successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package ?EMD?
> Warning in file.copy(savedcopy, lib, recursive = TRUE) :
>  problem copying C:\Program Files\R\R-2.13.1\library\00LOCK\EMD\libs\x64\EMD.dll to C:\Program Files\R\R-2.13.1\library\EMD\libs\x64\EMD.dll: Permission denied
> Warning: restored ?EMD?
> package ?emdbook? successfully unpacked and MD5 sums checked
> package ?emdist? successfully unpacked and MD5 sums checked
> package ?emmeans? successfully unpacked and MD5 sums checked
> package ?emoa? successfully unpacked and MD5 sums checked
> Error in unpackPkgZip(foundpkgs[okp, 2L], foundpkgs[okp, 1L], lib, libs_only, :
>  ERROR: failed to lock directory ?C:\Program Files\R\R-2.13.1\library? for modifying
> Try removing ?C:\Program Files\R\R-2.13.1\library/00LOCK?
> >
> 


Note the above is preceded by a long list of packages which are, in each case, re-loaded from whatever repo at a mirror being used.

I have found the p_unlock() from package pacman useful. After assigning global variable P to the results of available.packages(), I repeatedly do:
> 
> > p_unlock()
> The following 00LOCK has been deleted:
> C:/Program Files/R/R-2.13.1/library/00LOCK
> > match(c("emoa"), P)
> [1] 13
> > P<- P[13:length(P)]
> > update.packages(method=NULL, ask=FALSE, checkBuilt=TRUE, type="win.binary", instPkgs=P,
> + dependencies=c("Imports", "Depends", "Suggests"), INSTALL_opts=c("--no-lock"))
> 

where *emoa* is a stand-in for whatever package faulted during the load. (I also have no idea why *EMD* is locked in the above.)

My *sessionInfo()* is:

> > sessionInfo()
> R version 3.6.2 (2019-12-12)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252 LC_CTYPE=English_United States.1252 LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
> [5] LC_TIME=English_United States.1252 
> 
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base 
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.6.2
> >
> 

Eventually, I get to the end of P and call it done.

Anyone have a suggestion for an easier workaround?

 - Jan Galkowski


	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Dec 27 22:22:16 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 27 Dec 2019 21:22:16 +0000
Subject: [R] Converting Decimal numbers into Binary
In-Reply-To: <CAMOcQfPNtOk=SoDCciVuTyepU6ngngmR8C2xda+VgudmMHE_4g@mail.gmail.com>
References: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
 <9F6F2063-D483-4CA7-9DA6-7A41FF09A0A9@dcn.davis.ca.us>
 <CAMOcQfMNXEiSSjRspof-g9cgJu97DHpQy9xETWE=3SLgntyaFw@mail.gmail.com>
 <b749f5a6-c863-e5a3-8a95-fca30da3597e@sapo.pt>
 <CAMOcQfPNtOk=SoDCciVuTyepU6ngngmR8C2xda+VgudmMHE_4g@mail.gmail.com>
Message-ID: <cd5d2944-bfe5-e264-d3a1-37c60bb06807@sapo.pt>

Hello,

You forgot to cc the list, I'm replying all to have a complete thread so 
that others now and in the future can search similar problems they might 
encounter.
The following function bin2dec works as expected.


bin2dec <- function(x){
   s <- strsplit(x, "")
   s <- lapply(s, function(x){
     sum(as.integer(x)*2^((length(x) - 1):0))
   })
   unlist(s)
}


bin2dec("001100001111010101000011011110")
#[1] 205344990

b <- utf8ToBin("133m at ogP00PD;88MD5MTDww at 2D7k", out = "bin")
bin2dec(b)
# [1]  1  3  3 53 16 55 47 32  0  0 32 20 11  8  8 29 20  5 29 36
#[21] 20 63 63 16  2 20  7 51


Hope this helps,

Rui Barradas

?s 20:52 de 27/12/19, Paul Bernal escreveu:
>  ? Dear friend Rui,
> 
> Hope you are doing well, thanks for the previous feedback,
> 
> I have tried different things but have not been able to convert binary 
> numbers back to decimal, to test if the output is? correct, I am taking 
> the binary sequence = "001100001111010101000011011110" as a string, and 
> this should give the following value (after converting back to decimal) 
> = 205,344,990?
> 
> I have labeled my different attempts as (Attempt 1, ..., Attempt 3) but 
> none have worked (see the code below):
> 
> library(stringi)
> library(dplyr)
> library(R.utils)
> 
> 
> #dataset1 <- data.frame(maml.mapInputPort(1)) # class: data.frame
> 
> 
> ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
> ascii_datformat
> 
> Base <- ascii_datformat - 48
> 
> decy <- ifelse(Base > 40, Base-8, Base)
> 
> 
> biny <- intToBin(decy)
> 
> binyframe <- data.frame(biny)
> 
> tbinyframe <- paste(t(binyframe[,1]), collapse="")
> 
> binyframe
> tbinyframe
> 
> # Attempt 1
> 
> bin2dec <- function(x)
> {
>  ? x <- as.character(as.numeric(x))
>  ? b <- as.numeric(unlist(strsplit(x, "")))
>  ? pow <- 2 ^ ((length(b) - 1):0)
>  ? sum(pow[b == 1])
> }
> 
> # Attempt 2
> #bin2dec.easy <- function(binaryvector) {
> # ?sum(2^(which(rev(binaryvector)==TRUE)-1))
> #}
> 
> # Attempt 3
> 
> #utf8ToBin <- function(x, out = c("ascii", "dec", "bin")){
> # ? out <- match.arg(out)
> # ? ascii_datformat <- utf8ToInt(x)
> # ? Base <- ascii_datformat - 48
> # ? Base <- ifelse(Base > 40, Base - 8, Base)
> # ? Bin <- R.utils::intToBin(Base)
> # ? switch (out,
> # ? ? "ascii" = ascii_datformat,
> # ? ? "dec" = Base,
> # ? ? "bin" = Bin
> # ? )
> #}
> 
> 
> z <- substr(tbinyframe, 9, 38)
> 
> result <- bin2dec(z)
> result
> 
> Any guidance will be greatly appreciated,
> 
> Best regards,
> 
> Paul
> 
> El vie., 27 dic. 2019 a las 12:31, Rui Barradas (<ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>>) escribi?:
> 
>     Hello,
> 
> 
>     Your code and the answers provided, specially Marc's, led me to
> 
> 
>     utf8ToBin <- function(x, out = c("ascii", "dec", "bin")){
>      ? ?out <- match.arg(out)
>      ? ?ascii_datformat <- utf8ToInt(x)
>      ? ?Base <- ascii_datformat - 48
>      ? ?Base <- ifelse(Base > 40, Base - 8, Base)
>      ? ?Bin <- R.utils::intToBin(Base)
>      ? ?switch (out,
>      ? ? ?"ascii" = ascii_datformat,
>      ? ? ?"dec" = Base,
>      ? ? ?"bin" = Bin
>      ? ?)
>     }
> 
>     utf8ToBin("133m@", out = "ascii")
>     utf8ToBin("133m@", out = "dec")
>     utf8ToBin("133m@", out = "bin")
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 16:30 de 27/12/19, Paul Bernal escreveu:
>      > Dear Jeff,
>      >
>      > Hope you are doing great. The link I provide below has the
>     results I am
>      > expecting. I am doing a test, trying to convert this string:
>     "133m at ogP00PD
>      > ;88MD5MTDww at 2D7k" into ascii numbers, then to decimal, and
>     ultimately, into
>      > binary. I am trying to recreate the results obtained in the link
>     below.
>      >
>      > http://www.it-digin.com/blog/?p=20
>      >
>      > Hope this answers your question.
>      >
>      > Thanks for any guidance you can provide,
>      >
>      > Cheers,
>      >
>      > Paul
>      >
>      > El vie., 27 dic. 2019 a las 11:18, Jeff Newmiller
>     (<jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>)
>      > escribi?:
>      >
>      >> Your question is incomplete... what do you expect the result to be?
>      >>
>      >> Perhaps [1] is relevant?
>      >>
>      >> [1]
>      >>
>     https://stackoverflow.com/questions/52298995/r-binary-decimal-conversion-confusion-ais-data
>      >>
>      >> On December 27, 2019 7:42:36 AM PST, Paul Bernal
>     <paulbernal07 at gmail.com <mailto:paulbernal07 at gmail.com>>
>      >> wrote:
>      >>> Dear friends,
>      >>>
>      >>> Hope you are all doing well. I need to find a way to convert ascii
>      >>> numbers
>      >>> to six digit binary numbers:
>      >>>
>      >>> I am working with this example, I converted the string to
>     ascii, and
>      >>> finally to decimal, but I am having trouble converting the decimal
>      >>> numbers
>      >>> into their six digit binary representation. The code below is
>     exactly
>      >>> what
>      >>> I have so far:
>      >>>
>      >>> ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
>      >>> ascii_datformat
>      >>>
>      >>> Base <- ascii_datformat - 48
>      >>>
>      >>> ifelse(Base > 40, Base-8, Base)
>      >>>
>      >>> x <- rev(intToBits(Base))
>      >>> dec2bin <- function(x) paste(as.integer(rev(intToBits(x))),
>     collapse =
>      >>> "")
>      >>> dec2bin
>      >>>
>      >>> any guidance will be greatly appreciated,
>      >>>
>      >>> Best regards,
>      >>>
>      >>> Paul
>      >>>
>      >>>? ? ? ? [[alternative HTML version deleted]]
>      >>>
>      >>> ______________________________________________
>      >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      >>> https://stat.ethz.ch/mailman/listinfo/r-help
>      >>> PLEASE do read the posting guide
>      >>> http://www.R-project.org/posting-guide.html
>      >>> and provide commented, minimal, self-contained, reproducible code.
>      >>
>      >> --
>      >> Sent from my phone. Please excuse my brevity.
>      >>
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From r@oknz @end|ng |rom gm@||@com  Fri Dec 27 22:27:28 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 28 Dec 2019 10:27:28 +1300
Subject: [R] Converting Decimal numbers into Binary
In-Reply-To: <CAMOcQfMNXEiSSjRspof-g9cgJu97DHpQy9xETWE=3SLgntyaFw@mail.gmail.com>
References: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
 <9F6F2063-D483-4CA7-9DA6-7A41FF09A0A9@dcn.davis.ca.us>
 <CAMOcQfMNXEiSSjRspof-g9cgJu97DHpQy9xETWE=3SLgntyaFw@mail.gmail.com>
Message-ID: <CABcYAdLgTbyUJaTpTuxB3GdB-TQ_LVB9Zp=S3zbcUnO27LmbZA@mail.gmail.com>

The specific problem you are trying to solve is so constrained that
you do not need a
general purpose method.
You start with a string that contains characters drawn from a *subset*
of ASCII with
at most 64 elements.  Accordingly, all you need is a table mapping characters to
6-character strings.
table <- c("8" = "001000", w = "111111", ...)
Then you just split your 28-character string into a character vector,
index the table with that vector, and paste the results together.

(By the way, at no point in the process do you have the least interest
in converting
anything to decimal.)

On Sat, 28 Dec 2019 at 05:31, Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear Jeff,
>
> Hope you are doing great. The link I provide below has the results I am
> expecting. I am doing a test, trying to convert this string: "133m at ogP00PD
> ;88MD5MTDww at 2D7k" into ascii numbers, then to decimal, and ultimately, into
> binary. I am trying to recreate the results obtained in the link below.
>
> http://www.it-digin.com/blog/?p=20
>
> Hope this answers your question.
>
> Thanks for any guidance you can provide,
>
> Cheers,
>
> Paul
>
> El vie., 27 dic. 2019 a las 11:18, Jeff Newmiller (<jdnewmil at dcn.davis.ca.us>)
> escribi?:
>
> > Your question is incomplete... what do you expect the result to be?
> >
> > Perhaps [1] is relevant?
> >
> > [1]
> > https://stackoverflow.com/questions/52298995/r-binary-decimal-conversion-confusion-ais-data
> >
> > On December 27, 2019 7:42:36 AM PST, Paul Bernal <paulbernal07 at gmail.com>
> > wrote:
> > >Dear friends,
> > >
> > >Hope you are all doing well. I need to find a way to convert ascii
> > >numbers
> > >to six digit binary numbers:
> > >
> > >I am working with this example, I converted the string to ascii, and
> > >finally to decimal, but I am having trouble converting the decimal
> > >numbers
> > >into their six digit binary representation. The code below is exactly
> > >what
> > >I have so far:
> > >
> > >ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
> > >ascii_datformat
> > >
> > >Base <- ascii_datformat - 48
> > >
> > >ifelse(Base > 40, Base-8, Base)
> > >
> > >x <- rev(intToBits(Base))
> > >dec2bin <- function(x) paste(as.integer(rev(intToBits(x))), collapse =
> > >"")
> > >dec2bin
> > >
> > >any guidance will be greatly appreciated,
> > >
> > >Best regards,
> > >
> > >Paul
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Dec 28 00:41:22 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 27 Dec 2019 18:41:22 -0500
Subject: [R] Converting Decimal numbers into Binary
In-Reply-To: <cd5d2944-bfe5-e264-d3a1-37c60bb06807@sapo.pt>
References: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
 <9F6F2063-D483-4CA7-9DA6-7A41FF09A0A9@dcn.davis.ca.us>
 <CAMOcQfMNXEiSSjRspof-g9cgJu97DHpQy9xETWE=3SLgntyaFw@mail.gmail.com>
 <b749f5a6-c863-e5a3-8a95-fca30da3597e@sapo.pt>
 <CAMOcQfPNtOk=SoDCciVuTyepU6ngngmR8C2xda+VgudmMHE_4g@mail.gmail.com>
 <cd5d2944-bfe5-e264-d3a1-37c60bb06807@sapo.pt>
Message-ID: <CAMOcQfM3h8C57JCU-XoWn7kL90LLq845rM=qjrZXo8qqz4iYSQ@mail.gmail.com>

Thank you very much Rui.

Best regards!

El vie., 27 de diciembre de 2019 4:22 p. m., Rui Barradas <
ruipbarradas at sapo.pt> escribi?:

> Hello,
>
> You forgot to cc the list, I'm replying all to have a complete thread so
> that others now and in the future can search similar problems they might
> encounter.
> The following function bin2dec works as expected.
>
>
> bin2dec <- function(x){
>    s <- strsplit(x, "")
>    s <- lapply(s, function(x){
>      sum(as.integer(x)*2^((length(x) - 1):0))
>    })
>    unlist(s)
> }
>
>
> bin2dec("001100001111010101000011011110")
> #[1] 205344990
>
> b <- utf8ToBin("133m at ogP00PD;88MD5MTDww at 2D7k", out = "bin")
> bin2dec(b)
> # [1]  1  3  3 53 16 55 47 32  0  0 32 20 11  8  8 29 20  5 29 36
> #[21] 20 63 63 16  2 20  7 51
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 20:52 de 27/12/19, Paul Bernal escreveu:
> >    Dear friend Rui,
> >
> > Hope you are doing well, thanks for the previous feedback,
> >
> > I have tried different things but have not been able to convert binary
> > numbers back to decimal, to test if the output is  correct, I am taking
> > the binary sequence = "001100001111010101000011011110" as a string, and
> > this should give the following value (after converting back to decimal)
> > = 205,344,990?
> >
> > I have labeled my different attempts as (Attempt 1, ..., Attempt 3) but
> > none have worked (see the code below):
> >
> > library(stringi)
> > library(dplyr)
> > library(R.utils)
> >
> >
> > #dataset1 <- data.frame(maml.mapInputPort(1)) # class: data.frame
> >
> >
> > ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
> > ascii_datformat
> >
> > Base <- ascii_datformat - 48
> >
> > decy <- ifelse(Base > 40, Base-8, Base)
> >
> >
> > biny <- intToBin(decy)
> >
> > binyframe <- data.frame(biny)
> >
> > tbinyframe <- paste(t(binyframe[,1]), collapse="")
> >
> > binyframe
> > tbinyframe
> >
> > # Attempt 1
> >
> > bin2dec <- function(x)
> > {
> >    x <- as.character(as.numeric(x))
> >    b <- as.numeric(unlist(strsplit(x, "")))
> >    pow <- 2 ^ ((length(b) - 1):0)
> >    sum(pow[b == 1])
> > }
> >
> > # Attempt 2
> > #bin2dec.easy <- function(binaryvector) {
> > #  sum(2^(which(rev(binaryvector)==TRUE)-1))
> > #}
> >
> > # Attempt 3
> >
> > #utf8ToBin <- function(x, out = c("ascii", "dec", "bin")){
> > #   out <- match.arg(out)
> > #   ascii_datformat <- utf8ToInt(x)
> > #   Base <- ascii_datformat - 48
> > #   Base <- ifelse(Base > 40, Base - 8, Base)
> > #   Bin <- R.utils::intToBin(Base)
> > #   switch (out,
> > #     "ascii" = ascii_datformat,
> > #     "dec" = Base,
> > #     "bin" = Bin
> > #   )
> > #}
> >
> >
> > z <- substr(tbinyframe, 9, 38)
> >
> > result <- bin2dec(z)
> > result
> >
> > Any guidance will be greatly appreciated,
> >
> > Best regards,
> >
> > Paul
> >
> > El vie., 27 dic. 2019 a las 12:31, Rui Barradas (<ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>>) escribi?:
> >
> >     Hello,
> >
> >
> >     Your code and the answers provided, specially Marc's, led me to
> >
> >
> >     utf8ToBin <- function(x, out = c("ascii", "dec", "bin")){
> >         out <- match.arg(out)
> >         ascii_datformat <- utf8ToInt(x)
> >         Base <- ascii_datformat - 48
> >         Base <- ifelse(Base > 40, Base - 8, Base)
> >         Bin <- R.utils::intToBin(Base)
> >         switch (out,
> >           "ascii" = ascii_datformat,
> >           "dec" = Base,
> >           "bin" = Bin
> >         )
> >     }
> >
> >     utf8ToBin("133m@", out = "ascii")
> >     utf8ToBin("133m@", out = "dec")
> >     utf8ToBin("133m@", out = "bin")
> >
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >     ?s 16:30 de 27/12/19, Paul Bernal escreveu:
> >      > Dear Jeff,
> >      >
> >      > Hope you are doing great. The link I provide below has the
> >     results I am
> >      > expecting. I am doing a test, trying to convert this string:
> >     "133m at ogP00PD
> >      > ;88MD5MTDww at 2D7k" into ascii numbers, then to decimal, and
> >     ultimately, into
> >      > binary. I am trying to recreate the results obtained in the link
> >     below.
> >      >
> >      > http://www.it-digin.com/blog/?p=20
> >      >
> >      > Hope this answers your question.
> >      >
> >      > Thanks for any guidance you can provide,
> >      >
> >      > Cheers,
> >      >
> >      > Paul
> >      >
> >      > El vie., 27 dic. 2019 a las 11:18, Jeff Newmiller
> >     (<jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>)
> >      > escribi?:
> >      >
> >      >> Your question is incomplete... what do you expect the result to
> be?
> >      >>
> >      >> Perhaps [1] is relevant?
> >      >>
> >      >> [1]
> >      >>
> >
> https://stackoverflow.com/questions/52298995/r-binary-decimal-conversion-confusion-ais-data
> >      >>
> >      >> On December 27, 2019 7:42:36 AM PST, Paul Bernal
> >     <paulbernal07 at gmail.com <mailto:paulbernal07 at gmail.com>>
> >      >> wrote:
> >      >>> Dear friends,
> >      >>>
> >      >>> Hope you are all doing well. I need to find a way to convert
> ascii
> >      >>> numbers
> >      >>> to six digit binary numbers:
> >      >>>
> >      >>> I am working with this example, I converted the string to
> >     ascii, and
> >      >>> finally to decimal, but I am having trouble converting the
> decimal
> >      >>> numbers
> >      >>> into their six digit binary representation. The code below is
> >     exactly
> >      >>> what
> >      >>> I have so far:
> >      >>>
> >      >>> ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
> >      >>> ascii_datformat
> >      >>>
> >      >>> Base <- ascii_datformat - 48
> >      >>>
> >      >>> ifelse(Base > 40, Base-8, Base)
> >      >>>
> >      >>> x <- rev(intToBits(Base))
> >      >>> dec2bin <- function(x) paste(as.integer(rev(intToBits(x))),
> >     collapse =
> >      >>> "")
> >      >>> dec2bin
> >      >>>
> >      >>> any guidance will be greatly appreciated,
> >      >>>
> >      >>> Best regards,
> >      >>>
> >      >>> Paul
> >      >>>
> >      >>>        [[alternative HTML version deleted]]
> >      >>>
> >      >>> ______________________________________________
> >      >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >      >>> PLEASE do read the posting guide
> >      >>> http://www.R-project.org/posting-guide.html
> >      >>> and provide commented, minimal, self-contained, reproducible
> code.
> >      >>
> >      >> --
> >      >> Sent from my phone. Please excuse my brevity.
> >      >>
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >      > and provide commented, minimal, self-contained, reproducible code.
> >      >
> >
>

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Dec 28 00:41:56 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 27 Dec 2019 18:41:56 -0500
Subject: [R] Converting Decimal numbers into Binary
In-Reply-To: <CABcYAdLgTbyUJaTpTuxB3GdB-TQ_LVB9Zp=S3zbcUnO27LmbZA@mail.gmail.com>
References: <CAMOcQfN7agoqUCDH2HeU-aWmdHVnA+nx33+QBzB-BrH52M+SMA@mail.gmail.com>
 <9F6F2063-D483-4CA7-9DA6-7A41FF09A0A9@dcn.davis.ca.us>
 <CAMOcQfMNXEiSSjRspof-g9cgJu97DHpQy9xETWE=3SLgntyaFw@mail.gmail.com>
 <CABcYAdLgTbyUJaTpTuxB3GdB-TQ_LVB9Zp=S3zbcUnO27LmbZA@mail.gmail.com>
Message-ID: <CAMOcQfNvx5e7HxAn0kKXzn3-isWvUOTVOduswar6oRdGkNnvEg@mail.gmail.com>

Thank you Richard.

Best regards,

Paul

El vie., 27 de diciembre de 2019 4:27 p. m., Richard O'Keefe <
raoknz at gmail.com> escribi?:

> The specific problem you are trying to solve is so constrained that
> you do not need a
> general purpose method.
> You start with a string that contains characters drawn from a *subset*
> of ASCII with
> at most 64 elements.  Accordingly, all you need is a table mapping
> characters to
> 6-character strings.
> table <- c("8" = "001000", w = "111111", ...)
> Then you just split your 28-character string into a character vector,
> index the table with that vector, and paste the results together.
>
> (By the way, at no point in the process do you have the least interest
> in converting
> anything to decimal.)
>
> On Sat, 28 Dec 2019 at 05:31, Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> > Dear Jeff,
> >
> > Hope you are doing great. The link I provide below has the results I am
> > expecting. I am doing a test, trying to convert this string:
> "133m at ogP00PD
> > ;88MD5MTDww at 2D7k" into ascii numbers, then to decimal, and ultimately,
> into
> > binary. I am trying to recreate the results obtained in the link below.
> >
> > http://www.it-digin.com/blog/?p=20
> >
> > Hope this answers your question.
> >
> > Thanks for any guidance you can provide,
> >
> > Cheers,
> >
> > Paul
> >
> > El vie., 27 dic. 2019 a las 11:18, Jeff Newmiller (<
> jdnewmil at dcn.davis.ca.us>)
> > escribi?:
> >
> > > Your question is incomplete... what do you expect the result to be?
> > >
> > > Perhaps [1] is relevant?
> > >
> > > [1]
> > >
> https://stackoverflow.com/questions/52298995/r-binary-decimal-conversion-confusion-ais-data
> > >
> > > On December 27, 2019 7:42:36 AM PST, Paul Bernal <
> paulbernal07 at gmail.com>
> > > wrote:
> > > >Dear friends,
> > > >
> > > >Hope you are all doing well. I need to find a way to convert ascii
> > > >numbers
> > > >to six digit binary numbers:
> > > >
> > > >I am working with this example, I converted the string to ascii, and
> > > >finally to decimal, but I am having trouble converting the decimal
> > > >numbers
> > > >into their six digit binary representation. The code below is exactly
> > > >what
> > > >I have so far:
> > > >
> > > >ascii_datformat <- utf8ToInt("133m at ogP00PD;88MD5MTDww at 2D7k")
> > > >ascii_datformat
> > > >
> > > >Base <- ascii_datformat - 48
> > > >
> > > >ifelse(Base > 40, Base-8, Base)
> > > >
> > > >x <- rev(intToBits(Base))
> > > >dec2bin <- function(x) paste(as.integer(rev(intToBits(x))), collapse =
> > > >"")
> > > >dec2bin
> > > >
> > > >any guidance will be greatly appreciated,
> > > >
> > > >Best regards,
> > > >
> > > >Paul
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > >______________________________________________
> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >https://stat.ethz.ch/mailman/listinfo/r-help
> > > >PLEASE do read the posting guide
> > > >http://www.R-project.org/posting-guide.html
> > > >and provide commented, minimal, self-contained, reproducible code.
> > >
> > > --
> > > Sent from my phone. Please excuse my brevity.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sun Dec 29 17:28:42 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sun, 29 Dec 2019 17:28:42 +0100
Subject: [R] Statistical tests on residuals
Message-ID: <CA+nrPnv9ezg+GCMa84Jk2KABkywJfOAzObO6xR7x6HKLL0nZaw@mail.gmail.com>

Hi

I have continuous data I.e regression based. If I have residuals for
algorithm 1 and algorithm 2 like this,

X=resid(alg1) and y=resid (alg2)

Can we perform the Wilcoxon test as.

Wilcox.test(x,y)

Thanks

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Dec 29 17:41:35 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 29 Dec 2019 16:41:35 +0000
Subject: [R] Statistical tests on residuals
In-Reply-To: <CA+nrPnv9ezg+GCMa84Jk2KABkywJfOAzObO6xR7x6HKLL0nZaw@mail.gmail.com>
References: <CA+nrPnv9ezg+GCMa84Jk2KABkywJfOAzObO6xR7x6HKLL0nZaw@mail.gmail.com>
Message-ID: <d12d82c3-5bc0-6dd8-729c-3abc782faa26@sapo.pt>

Hello,

Inline.

?s 16:28 de 29/12/19, Neha gupta escreveu:
> Hi
> 
> I have continuous data I.e regression based. If I have residuals for
> algorithm 1 and algorithm 2 like this,
> 
> X=resid(alg1) and y=resid (alg2)
> 
> Can we perform the Wilcoxon test as.
> 
> Wilcox.test(x,y)

Probably not, R is case sensitive and without loading an external 
package that instruction will give an error. Try

wilcox.test(x, y)


with *lower* case *w*.

By the way, why would you test the residuals of regression fits?
It doesn't make sense, especially if the models (algorithms) assume 
residuals with mean zero. I suggest you learn more about the techniques 
you are using to model your data before trying to test.


Hope this helps,

Rui Barradas


> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Dec 29 18:20:30 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 29 Dec 2019 17:20:30 +0000
Subject: [R] Statistical tests on residuals
In-Reply-To: <CA+nrPnsAT2N_GY3mJGCs_Rkjr9PiM3uai2-L_SbjXV35oqri1g@mail.gmail.com>
References: <CA+nrPnv9ezg+GCMa84Jk2KABkywJfOAzObO6xR7x6HKLL0nZaw@mail.gmail.com>
 <d12d82c3-5bc0-6dd8-729c-3abc782faa26@sapo.pt>
 <CA+nrPnsAT2N_GY3mJGCs_Rkjr9PiM3uai2-L_SbjXV35oqri1g@mail.gmail.com>
Message-ID: <66273178-cdfe-cd49-09dd-3b0d35ac439c@sapo.pt>

Hello,

Please cc the list.

Yes, that's what I mean.
Besides, the code as provided doesn't produce an object (search) with a 
resid method. Are you sure resid(search) runs without errors?

Hope this helps,

Rui Barradas

?s 16:55 de 29/12/19, Neha gupta escreveu:
> Hello Rui,
> 
> I use caret and CART
> 
> search <- train(Results ~ ., data = training,
>  ? ? ? ? ? ? ? ? ? ? ?method = "rpart",
> 
>  ? ? ? ? ? ? ? ? ? ? ?metric = "MAE",
>  ? ? ? ? ? ? ? ? ? ? ?preProc = c("center", "scale", "zv" ),
> 
> getTrainPerf(search)
> x=resid(search)
> 
> You mean its not the right way for statistical test?
> 
> On Sun, Dec 29, 2019 at 5:41 PM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     Inline.
> 
>     ?s 16:28 de 29/12/19, Neha gupta escreveu:
>      > Hi
>      >
>      > I have continuous data I.e regression based. If I have residuals for
>      > algorithm 1 and algorithm 2 like this,
>      >
>      > X=resid(alg1) and y=resid (alg2)
>      >
>      > Can we perform the Wilcoxon test as.
>      >
>      > Wilcox.test(x,y)
> 
>     Probably not, R is case sensitive and without loading an external
>     package that instruction will give an error. Try
> 
>     wilcox.test(x, y)
> 
> 
>     with *lower* case *w*.
> 
>     By the way, why would you test the residuals of regression fits?
>     It doesn't make sense, especially if the models (algorithms) assume
>     residuals with mean zero. I suggest you learn more about the techniques
>     you are using to model your data before trying to test.
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
> 
>      >
>      > Thanks
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sun Dec 29 18:34:35 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sun, 29 Dec 2019 18:34:35 +0100
Subject: [R] Statistical tests on residuals
In-Reply-To: <66273178-cdfe-cd49-09dd-3b0d35ac439c@sapo.pt>
References: <CA+nrPnv9ezg+GCMa84Jk2KABkywJfOAzObO6xR7x6HKLL0nZaw@mail.gmail.com>
 <d12d82c3-5bc0-6dd8-729c-3abc782faa26@sapo.pt>
 <CA+nrPnsAT2N_GY3mJGCs_Rkjr9PiM3uai2-L_SbjXV35oqri1g@mail.gmail.com>
 <66273178-cdfe-cd49-09dd-3b0d35ac439c@sapo.pt>
Message-ID: <CA+nrPnuPK=PKBwn0esZbf8h+cxy-kHDDqSRr-G_RM7rHXnX50A@mail.gmail.com>

Hello Rui, thanks for your input

Yes, it runs. In fact, it gives me the result like below: (I just copied
few, the list is high)

   X2           X3           X4           X5           X6           X7
      X8
  -95.835556  -182.235556  -177.435556  -188.235556  -205.035556
 -202.635556   139.364444
         X10          X11          X16          X17          X21
 X22          X23
 -141.435556  -189.435556   146.564444   110.564444  -153.435556
 86.564444   -93.435556
         X24          X25          X27          X28          X30
 X31          X32
 -123.435556    -3.435556  -143.435556    25.564444  -151.435556
-43.435556   -2

On Sun, Dec 29, 2019 at 6:20 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Please cc the list.
>
> Yes, that's what I mean.
> Besides, the code as provided doesn't produce an object (search) with a
> resid method. Are you sure resid(search) runs without errors?
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 16:55 de 29/12/19, Neha gupta escreveu:
> > Hello Rui,
> >
> > I use caret and CART
> >
> > search <- train(Results ~ ., data = training,
> >                       method = "rpart",
> >
> >                       metric = "MAE",
> >                       preProc = c("center", "scale", "zv" ),
> >
> > getTrainPerf(search)
> > x=resid(search)
> >
> > You mean its not the right way for statistical test?
> >
> > On Sun, Dec 29, 2019 at 5:41 PM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     Inline.
> >
> >     ?s 16:28 de 29/12/19, Neha gupta escreveu:
> >      > Hi
> >      >
> >      > I have continuous data I.e regression based. If I have residuals
> for
> >      > algorithm 1 and algorithm 2 like this,
> >      >
> >      > X=resid(alg1) and y=resid (alg2)
> >      >
> >      > Can we perform the Wilcoxon test as.
> >      >
> >      > Wilcox.test(x,y)
> >
> >     Probably not, R is case sensitive and without loading an external
> >     package that instruction will give an error. Try
> >
> >     wilcox.test(x, y)
> >
> >
> >     with *lower* case *w*.
> >
> >     By the way, why would you test the residuals of regression fits?
> >     It doesn't make sense, especially if the models (algorithms) assume
> >     residuals with mean zero. I suggest you learn more about the
> techniques
> >     you are using to model your data before trying to test.
> >
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >
> >      >
> >      > Thanks
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >      > and provide commented, minimal, self-contained, reproducible code.
> >      >
> >
>

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Sun Dec 29 20:50:58 2019
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Sun, 29 Dec 2019 13:50:58 -0600
Subject: [R] rnoaa library
References: <001101d5be81$4af70920$e0e51b60$.ref@sbcglobal.net>
Message-ID: <001101d5be81$4af70920$e0e51b60$@sbcglobal.net>

r-help Forum

Anyone familiar with the "rnoaa" library?  I'm trying to pull NOAA  temp
data. I have a key but when I run the code highlighted in yellow  ..

Warning message:
Sorry, no data found 

No matter what station_id I use. 

# library
library(rnoaa)
library(lubridate)

# set key
options(noaakey = "<Enter key>")

start_date = "2018-01-15"
end_date = "2018-01-31"
station_id = "USW00013994"

weather_data <- ncdc(datasetid='NORMAL_HLY', stationid=paste0('GHCND:',
station_id),
                     datatypeid = "HLY-TEMP-NORMAL",
                     startdate = start_date, enddate = end_date, limit=500)
data <- weather_data$data 

data$year <- year(data$date)
data$month <- month(data$date)
data$day <- day(data$date)
# summarize to average daily temps
aggregate(value ~ year + month + day, mean, data = data)

Sincerely

Jeff Reichman


	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sun Dec 29 21:37:24 2019
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sun, 29 Dec 2019 21:37:24 +0100
Subject: [R] How to perform test for significance difference?
Message-ID: <CA+nrPnvopYe24Xej0EjLjUfbD9OUDzs2Z_Atfi_Oz4zt9ZMMNQ@mail.gmail.com>

Hello to all.

I have a small confusion, kindly if you could suggest something?

I need to compare two algorithms, CART and NNET in R. The results show that
NNET has better MAE value, but I want to find if there is any significance
difference between the results of both algorithms? The dataset I used is
about regression problem. Hence, I used wilcoxon test as:

//For CART

search <- train(Results ~ ., data = training,
method = "rpart",

metric = "MAE",
preProc = c("center", "scale", "zv" ),

getTrainPerf(search)
x=resid(search)

Then
<https://www.facebook.com/thenmozhi.ramagounder?__tn__=%2CdK-R-R&eid=ARBBMjI1AS5FYMfsAWEjxzbMRUd3GZnEPAAuE2ci8UORtsysXGV9i9TGqCy_e6m3hE_e-t8V7TXcVo-F&fref=mentions>
for
NNET

search2 <- train(Results ~ ., data = training,
method = "nnet",

metric = "MAE",
preProc = c("center", "scale", "zv" ),

getTrainPerf(search2)
x2=resid(search2)
wilcox.test(x,x2)

I want to ask is it the right way to find the significance test? And , if
not what is the better way. Kindly suggest me a solution as I have searched
a lot related to it on the web but found nothing.

	[[alternative HTML version deleted]]


From pcoretto @end|ng |rom un|@@@|t  Mon Dec 30 11:59:19 2019
From: pcoretto @end|ng |rom un|@@@|t (Pietro Coretto)
Date: Mon, 30 Dec 2019 11:59:19 +0100
Subject: [R] rmgarch: source package installation problem
Message-ID: <dceaea78-0b5d-79c6-1651-9c9315651916@unisa.it>



Dear Users

I tried to install the package "rmgarch". While installing binaries for 
Windows and MacOS didn't cause any issue. The source package 
installation doesn't work.

I tried it on three different OS: Linux Ubuntu 18.04 (64bit), Windows 10 
Pro (64bit) and MacOS Catalina. In all three cases I have worked with a 
fresh R 3.6.2 install. I contacted the maintainer of the package who 
said that it can't reproduce the same issue and that CRAN checks are fine.

Below I report the console output when installing "rmgarch" on my Ubuntu 
18.04 LTS (64bit). I skip the messages regarding installation of the 
required packages (they all installed without issues):


https://pastebin.com/J6XHaP28

I have installed many other packages from source (unsing C, C++, RCpp, 
fortran code, etc) without any issue.


Here the output of  sessionInfo() at the end.

https://pastebin.com/z7ZwU9iR


I hope somebody can tell me what may cause this.

Regards
Pietro


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Dec 30 12:11:31 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 30 Dec 2019 06:11:31 -0500
Subject: [R] rmgarch: source package installation problem
In-Reply-To: <dceaea78-0b5d-79c6-1651-9c9315651916@unisa.it>
References: <dceaea78-0b5d-79c6-1651-9c9315651916@unisa.it>
Message-ID: <1a60a51b-18d9-df7e-cd99-3e0fa47184df@gmail.com>

On 30/12/2019 5:59 a.m., Pietro Coretto wrote:
> 
> 
> Dear Users
> 
> I tried to install the package "rmgarch". While installing binaries for
> Windows and MacOS didn't cause any issue. The source package
> installation doesn't work.
> 
> I tried it on three different OS: Linux Ubuntu 18.04 (64bit), Windows 10
> Pro (64bit) and MacOS Catalina. In all three cases I have worked with a
> fresh R 3.6.2 install. I contacted the maintainer of the package who
> said that it can't reproduce the same issue and that CRAN checks are fine.
> 
> Below I report the console output when installing "rmgarch" on my Ubuntu
> 18.04 LTS (64bit). I skip the messages regarding installation of the
> required packages (they all installed without issues):
> 
> 
> https://pastebin.com/J6XHaP28
> 
> I have installed many other packages from source (unsing C, C++, RCpp,
> fortran code, etc) without any issue.
> 
> 
> Here the output of  sessionInfo() at the end.
> 
> https://pastebin.com/z7ZwU9iR
> 
> 
> I hope somebody can tell me what may cause this.

You didn't show us the command you used to install it.

Duncan Murdoch


From pcoretto @end|ng |rom un|@@@|t  Mon Dec 30 12:29:01 2019
From: pcoretto @end|ng |rom un|@@@|t (Pietro Coretto)
Date: Mon, 30 Dec 2019 12:29:01 +0100
Subject: [R] rmgarch: source package installation problem
In-Reply-To: <1a60a51b-18d9-df7e-cd99-3e0fa47184df@gmail.com>
References: <dceaea78-0b5d-79c6-1651-9c9315651916@unisa.it>
 <1a60a51b-18d9-df7e-cd99-3e0fa47184df@gmail.com>
Message-ID: <5728d95b-782b-7518-57c0-ac845cea21be@unisa.it>

On 30/12/2019 12.11, Duncan Murdoch wrote:
> On 30/12/2019 5:59 a.m., Pietro Coretto wrote:
[...]
> You didn't show us the command you used to install it.
> 
> Duncan Murdoch


Sorry for this,


I used the following:

install.packages("rmgarch")

from the linux command line, using both a regular user account and root. 
Same issue anyway

Thanks
Pietro


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Dec 31 00:01:53 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 31 Dec 2019 12:01:53 +1300
Subject: [R] [FORGED] Re:  rmgarch: source package installation problem
In-Reply-To: <5728d95b-782b-7518-57c0-ac845cea21be@unisa.it>
References: <dceaea78-0b5d-79c6-1651-9c9315651916@unisa.it>
 <1a60a51b-18d9-df7e-cd99-3e0fa47184df@gmail.com>
 <5728d95b-782b-7518-57c0-ac845cea21be@unisa.it>
Message-ID: <ceded949-2ecf-2db9-6737-4646a6f61244@auckland.ac.nz>


On 31/12/19 12:29 am, Pietro Coretto wrote:

> On 30/12/2019 12.11, Duncan Murdoch wrote:
>> On 30/12/2019 5:59 a.m., Pietro Coretto wrote:
> [...]
>> You didn't show us the command you used to install it.
>>
>> Duncan Murdoch
> 
> 
> Sorry for this,
> 
> 
> I used the following:
> 
> install.packages("rmgarch")
> 
> from the linux command line, using both a regular user account and root. 
> Same issue anyway.

Did you *really* issue that command from the linux command line?  This 
makes no sense at all.  That is a command to be issued from the R console.

Under Linux, that command, issued from the R console, will I believe 
install from source.  Under Windoze or Mac OS this is (as I understand 
it) not the case.

To install from source under Mac OS I *think* you should:

(1) Download the source package rmgarch_1.3-7.tar.gz from CRAN

(2) From the command line (in a terminal window) issue the command

     R CMD INSTALL rmgarch_1.3-7.tar.gz -l <library name>

     where "<library name>" is the name of the directory in which you
     keep your "privately" installed packages.

     You need ("of course") to have all the necessary tools and compilers
     installed for this to work.

     The source "rmgarch_1.3-7.tar.gz" must be place in the same
     directory as that from which you opened the terminal window.

Something like this should also work under Windoze, but there are 
probably extra "gotchas" under that system, and I can give you no 
guidance there.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Tue Dec 31 07:41:40 2019
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Mon, 30 Dec 2019 22:41:40 -0800
Subject: [R] rnoaa library
In-Reply-To: <001101d5be81$4af70920$e0e51b60$@sbcglobal.net>
References: <001101d5be81$4af70920$e0e51b60$.ref@sbcglobal.net>
 <001101d5be81$4af70920$e0e51b60$@sbcglobal.net>
Message-ID: <CAA99HCwAKoXap6_uZVBUEaxj=5x=WUuoWecsgj=EYzNCu2FAXA@mail.gmail.com>

Hi Jeff,

You might have better luck posting your question on the R-SIG-Geo
mailing list, or perusing their archive. I've found a thread
pertaining to the rnoaa package from August 2016, along with a
particularly informative reply (reply link below):

https://stat.ethz.ch/mailman/listinfo/R-SIG-Geo
https://stat.ethz.ch/pipermail/r-sig-geo/
https://stat.ethz.ch/pipermail/r-sig-geo/2016-August/024768.html

If the above links don't help, you might consider checking for open
(or even closed) issues on Github:

https://github.com/ropensci/rnoaa/issues

HTH, Bill.

W. Michels, Ph.D.



On Sun, Dec 29, 2019 at 11:51 AM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>
> r-help Forum
>
> Anyone familiar with the "rnoaa" library?  I'm trying to pull NOAA  temp
> data. I have a key but when I run the code highlighted in yellow  ..
>
> Warning message:
> Sorry, no data found
>
> No matter what station_id I use.
>
> # library
> library(rnoaa)
> library(lubridate)
>
> # set key
> options(noaakey = "<Enter key>")
>
> start_date = "2018-01-15"
> end_date = "2018-01-31"
> station_id = "USW00013994"
>
> weather_data <- ncdc(datasetid='NORMAL_HLY', stationid=paste0('GHCND:',
> station_id),
>                      datatypeid = "HLY-TEMP-NORMAL",
>                      startdate = start_date, enddate = end_date, limit=500)
> data <- weather_data$data
>
> data$year <- year(data$date)
> data$month <- month(data$date)
> data$day <- day(data$date)
> # summarize to average daily temps
> aggregate(value ~ year + month + day, mean, data = data)
>
> Sincerely
>
> Jeff Reichman
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


