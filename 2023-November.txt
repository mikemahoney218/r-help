From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Nov  1 07:08:37 2023
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 31 Oct 2023 23:08:37 -0700
Subject: [R] running crossvalidation many times MSE for Lasso regression
In-Reply-To: <CAGxFJbQ26vOFLgHbSiqObOz+amAY94xVMx0d8UUTg8OPaLLdjg@mail.gmail.com>
References: <1823742611.1400069.1698006976815.ref@mail.yahoo.com>
 <1823742611.1400069.1698006976815@mail.yahoo.com>
 <CAGxFJbQ26vOFLgHbSiqObOz+amAY94xVMx0d8UUTg8OPaLLdjg@mail.gmail.com>
Message-ID: <32DB26CD-B94E-40FF-BCC1-D85221D466A7@comcast.net>



> On Oct 22, 2023, at 4:01 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> No error message shown Please include the error message so that it is
> not necessary to rerun your code. This might enable someone to see the
> problem without running the code (e.g. downloading packages, etc.)
> 
> -- Bert
> 
> On Sun, Oct 22, 2023 at 1:36?PM varin sacha via R-help
> <r-help at r-project.org> wrote:
>> 
>> Dear R-experts,
>> 
>> Here below my R code with an error message. Can somebody help me to fix this error?
>> Really appreciate your help.
>> 
>> Best,
>> 
>> ############################################################
>> # MSE CROSSVALIDATION Lasso regression
>> 
>> library(glmnet)
>> 
>> 
>> x1=c(34,35,12,13,15,37,65,45,47,67,87,45,46,39,87,98,67,51,10,30,65,34,57,68,98,86,45,65,34,78,98,123,202,231,154,21,34,26,56,78,99,83,46,58,91)
>> x2=c(1,3,2,4,5,6,7,3,8,9,10,11,12,1,3,4,2,3,4,5,4,6,8,7,9,4,3,6,7,9,8,4,7,6,1,3,2,5,6,8,7,1,1,2,9)
>> y=c(2,6,5,4,6,7,8,10,11,2,3,1,3,5,4,6,5,3.4,5.6,-2.4,-5.4,5,3,6,5,-3,-5,3,2,-1,-8,5,8,6,9,4,5,-3,-7,-9,-9,8,7,1,2)
>> T=data.frame(y,x1,x2)
>> 
>> z=matrix(c(x1,x2), ncol=2)
>> cv_model=glmnet(z,y,alpha=1)
>> best_lambda=cv_model$lambda.min
>> best_lambda
>> 
>> 
>> # Create a list to store the results
>> lst<-list()
>> 
>> # This statement does the repetitions (looping)
>> for(i in 1 :1000) {
>> 
>> n=45
>> 
>> p=0.667
>> 
>> sam=sample(1 :n,floor(p*n),replace=FALSE)
>> 
>> Training =T [sam,]
>> Testing = T [-sam,]
>> 
>> test1=matrix(c(Testing$x1,Testing$x2),ncol=2)
>> 
>> predictLasso=predict(cv_model, newx=test1)
>> 
>> 
>> ypred=predict(predictLasso,newdata=test1)

The error I got was:

Error in UseMethod("predict") : 
  no applicable method for 'predict' applied to an object of class "c('matrix', 'array', 'double', 'numeric')"


I'm not sure why the name of the object was cv_model since it was not created as a cross-validation result.

The loops called predict() twice and it was the second call that produced the error since the predictLasso object was not a glmnet classed object.

If the OP had left out the second use of predict and then subtracted predictLasso from the y vector a result would have appeared

y=T[-sam,]$y
MSE = mean((y-predictLasso)^2)
...
> mean(unlist(lst))
[1] 23.39621

Whether this is meaningful is hard to tell. It also makes the fundamental error of overwriting the original data object `y` with another intermediate result.

-- 
David
>> y=T[-sam,]$y
>> 
>> MSE = mean((y-ypred)^2)
>> MSE
>> lst[i]<-MSE
>> }
>> mean(unlist(lst))
>> ##################################################################
>> 
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From k|mem|||@029 @end|ng |rom gm@||@com  Wed Nov  1 14:06:27 2023
From: k|mem|||@029 @end|ng |rom gm@||@com (Kim Emilia)
Date: Wed, 1 Nov 2023 22:06:27 +0900
Subject: [R] How can I remove my packages from rdrr.io?
Message-ID: <CAFmxOoHUE1Hr4NkUWXNAxjk-Xjrqv30WbqrFJTM99ukpu8MjMA@mail.gmail.com>

Hello all,

I would like to take down my packages posted/created on the website rdrr.io.
[https://rdrr.io/] Is there any way to take down packages from the website?
It would be appreciated if you suggested/offered a way to remove the
package from the website.

Thank you.

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Nov  1 14:40:49 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 1 Nov 2023 16:40:49 +0300
Subject: [R] How can I remove my packages from rdrr.io?
In-Reply-To: <CAFmxOoHUE1Hr4NkUWXNAxjk-Xjrqv30WbqrFJTM99ukpu8MjMA@mail.gmail.com>
References: <CAFmxOoHUE1Hr4NkUWXNAxjk-Xjrqv30WbqrFJTM99ukpu8MjMA@mail.gmail.com>
Message-ID: <20231101164049.2176bcce@arachnoid>

? Wed, 1 Nov 2023 22:06:27 +0900
Kim Emilia <kimemilia029 at gmail.com> ?????:

> I would like to take down my packages posted/created on the website
> rdrr.io.

I think it's unlikely to find people affiliated with rdrr.io here on
the R-help mailing list. Have you tried contacting the website author
via the links at the bottom of the page? They reference both the
author's e-mail address and the dedicated GitHub issue repo.

-- 
Best regards,
Ivan


From bbo|ker @end|ng |rom gm@||@com  Wed Nov  1 14:38:50 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 1 Nov 2023 09:38:50 -0400
Subject: [R] How can I remove my packages from rdrr.io?
In-Reply-To: <CAFmxOoHUE1Hr4NkUWXNAxjk-Xjrqv30WbqrFJTM99ukpu8MjMA@mail.gmail.com>
References: <CAFmxOoHUE1Hr4NkUWXNAxjk-Xjrqv30WbqrFJTM99ukpu8MjMA@mail.gmail.com>
Message-ID: <92071c91-8946-42cc-88dc-bbe4c3d070f5@gmail.com>

   There is a github site with an issues list: 
https://github.com/rdrr-io/rdrr-issues/issues

   It looks like people have successfully requested removal in the past, 
e.g. https://github.com/rdrr-io/rdrr-issues/issues/113

On 2023-11-01 9:06 a.m., Kim Emilia wrote:
> Hello all,
> 
> I would like to take down my packages posted/created on the website rdrr.io.
> [https://rdrr.io/] Is there any way to take down packages from the website?
> It would be appreciated if you suggested/offered a way to remove the
> package from the website.
> 
> Thank you.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Nov  1 14:42:52 2023
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 1 Nov 2023 06:42:52 -0700
Subject: [R] How can I remove my packages from rdrr.io?
In-Reply-To: <CAFmxOoHUE1Hr4NkUWXNAxjk-Xjrqv30WbqrFJTM99ukpu8MjMA@mail.gmail.com>
References: <CAFmxOoHUE1Hr4NkUWXNAxjk-Xjrqv30WbqrFJTM99ukpu8MjMA@mail.gmail.com>
Message-ID: <EBF36825-7994-47EC-BB61-90E862F115DD@comcast.net>



> On Nov 1, 2023, at 6:06 AM, Kim Emilia <kimemilia029 at gmail.com> wrote:
> 
> Hello all,
> 
> I would like to take down my packages posted/created on the website rdrr.io.
> [https://rdrr.io/] Is there any way to take down packages from the website?
> It would be appreciated if you suggested/offered a way to remove the
> package from the website.
> 

The website you are concerned about is not maintained by the R-project. A but of link-following suggested to me that the person you need to be addressing this to has a "personal" webpage at:  https://ianhowson.com/

There will be many other sites that hold most or all of the extensive list of CRAN packages, although it is certainly true that rrio.io has become a favorite of Google. 

-- 
David
> Thank you.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Thu Nov  2 08:28:19 2023
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 2 Nov 2023 08:28:19 +0100
Subject: [R] weights vs. offset (negative binomial regression)
In-Reply-To: <acfecb0b-b3b1-4074-ae8a-ccfc27ce3346@gmail.com>
References: <CAPFqpxHHhbkVhiJTV8GKMmsRNgbjogHrXrb8d3sZmJm22B53Cw@mail.gmail.com>
 <322cd6d4-3223-4cbe-b958-e8fd8f38f9cb@gmail.com>
 <CAPFqpxHp09pQoF+hfhMYPt-Kv-=ahtbKF==uQ7iNn6708x5yoA@mail.gmail.com>
 <acfecb0b-b3b1-4074-ae8a-ccfc27ce3346@gmail.com>
Message-ID: <3372ED8B-9C57-44D5-8C7E-EA13CDF8670D@gmail.com>

I think it is more clear-cut than so, at least if the Poisson situation is something to go by. 

There, you can do either of these and get equivalent results

> fit.lung <- glm(cases ~ age + city,  offset=log(pop), 
+                 family=poisson, data=lungcancer)
> fit.lung2 <- glm(cases/pop ~ age + city,  weights=pop, 
+                 family=poisson, data=lungcancer)
There were 12 warnings (use warnings() to see them)

(Except for the warnings about non-integer responses, which have annoyed some epidemiologists trying to work with non-log link fuctions.)

The point is that you need to convert to rates on the LHS and then compensate for the fact that this has a smaller variance when the population is larger. Counts on the LHS combined with weights wouldn't be right. So I would expect that the weighted version of the OP's code should model Catch/Effort, although I'm not quite sure how glm.nb reacts to non-integer responses.

-pd


> On 31 Oct 2023, at 17:59 , Ben Bolker <bbolker at gmail.com> wrote:
> 
>  [Please keep r-help in the cc: list]
> 
>  I don't quite know how to interpret the difference between specifying effort as an offset vs. as weights; I would have to spend more time thinking about it/working through it than I have available at the moment.
> 
>   I don't know that specifying effort as weights is *wrong*, but I don't know that it's right or what it is doing: if I were the reviewer of a paper (for example) I would require you to explain what the difference is and convince me that it was appropriate. (Furthermore, "I want to do it this way because it gives me significant effects" is automatically suspicious.)
> 
>  This would be a good question for CrossValidated (https://stats.stackexchange.com), you could try posting it there (I would be interested in the answer!)
> 
>  cheers
>    Ben Bolker
> 
> 
> On 2023-10-30 8:19 p.m., ??? wrote:
>> Dear Mr. Bolker,
>> Thank you for the fast response.
>> I also know that a poisson (or negative binomial ) regression of glm is  generally modelled using an offset variable.
>> In this case, when a weights term instead of the offset is used, this gave me significant coefficients of covariance.
>> I understand that the weights function for exponential family distributions in glm affects the variance of response variable.
>> I was just wondering whether my first model is a completely wrong model and the use of offset variable is valid in the case that
>> response variable is  not proportional to offset variable such as my dataset.
>> Sincerely,
>> Joon-Taek
>> 2023? 10? 29? (?) ?? 3:25, Ben Bolker <bbolker at gmail.com <mailto:bbolker at gmail.com>>?? ??:
>>        Using an offset of log(Effort) as in your second model is the more
>>    standard way to approach this problem; it corresponds to assuming that
>>    catch is strictly proportional to effort. Adding log(Effort) as a
>>    covariate (as illustrated below) tests whether a power-law model (catch
>>    propto (Effort)^(b+1), b!=0) is a better description of the data.  (In
>>    this case it is not, although the confidence intervals on b are very
>>    wide, indicating that we have very little information -- this is not
>>    surprising since the proportional range of effort is very small
>>    (246-258) in this data set.
>>        In general you should *not* check overdispersion of the raw data
>>    (i.e., the *marginal distribution* of the data, you should check
>>    overdispersion of a fitted (e.g. Poisson) model, as below.
>>        cheers
>>         Ben Bolker
>>    edata <- data.frame(Catch, Effort, xx1, xx2, xx3)
>>    ## graphical exploration
>>    library(ggplot2); theme_set(theme_bw())
>>    library(tidyr)
>>    edata_long <- edata |> pivot_longer(names_to="var", cols =-c("Catch",
>>    "Effort"))
>>    ggplot(edata_long, aes(value, Catch)) +
>>          geom_point(alpha = 0.2, aes(size = Effort)) +
>>          facet_wrap(~var, scale="free_x") +
>>          geom_smooth(method = "glm", method.args = list(family =
>>    "quasipoisson"))
>>    #
>>    library(MASS)
>>    g1 <- glm.nb(Catch~xx1+xx2+xx3+offset(log(Effort)), data=edata)
>>    g2 <- update(g1, . ~ . + log(Effort))
>>    g0 <- glm(Catch~xx1+xx2+xx3+offset(log(Effort)), data=edata,
>>                family = poisson)
>>    performance::check_overdispersion(g0)
>>    summary(g1)
>>    summary(g2)
>>    options(digits = 3)
>>    confint(g2)
>>    summary(g1)
>>    On 2023-10-28 3:30 a.m., ??? wrote:
>>     > Colleagues,
>>     >
>>     >
>>     >
>>     > I have a dataset that includes five variables.
>>     >
>>     > - Catch: the catch number counted in some species (ind.)
>>     >
>>     > - Effort: fishing effort (the number of fishing vessels)
>>     >
>>     > - xx1, xx2, xx3: some environmental factors
>>     >
>>     > As an overdispersion test on the ?Catch? variable, I modeled with
>>    negative
>>     > binomial distribution using a GLM. The ?Effort? variable showed a
>>    gradually
>>     > decreasing trend during the study period. I was able to get the
>>    results I
>>     > wanted when considered ?Effort? function as a weights function in the
>>     > negative binomial regression as follows:
>>     >
>>     >
>>     >
>>     > library(qcc)
>>     >
>>     >
>>    Catch=c(25,2,7,6,75,5,1,4,66,15,9,25,40,8,7,4,36,11,1,14,141,9,74,38,126,3)
>>     >
>>     >
>>    Effort=c(258,258,258,258,258,258,258,254,252,252,252,252,252,252,252,252,252,252,252,248,246,246,246,246,246,246)
>>     >
>>     >
>>    xx1=c(0.8,0.5,1.2,0.5,1.1,1.1,1.0,0.6,0.9,0.5,1.2,0.6,1.2,0.7,1.0,0.6,1.6,0.7,0.8,0.6,1.7,0.9,1.1,0.5,1.4,0.5)
>>     >
>>     >
>>    xx2=c(1.7,1.6,2.7,2.6,1.5,1.5,2.8,2.5,1.7,1.9,2.2,2.4,1.6,1.4,3.0,2.4,1.4,1.5,2.2,2.3,1.7,1.7,1.9,1.9,1.4,1.4)
>>     >
>>     >
>>    xx3=c(188,40,2,10,210,102,117,14,141,28,48,15,220,115,10,14,320,20,3,10,400,150,145,160,460,66)
>>     >
>>     > #
>>     >
>>     > edata <- data.frame(Catch, Effort, xx1, xx2, xx3)
>>     >
>>     > #
>>     >
>>     > qcc.overdispersion.test(edata$Catch, type="poisson")
>>     >
>>     > #
>>     >
>>     > summary(glm.nb(Catch~xx1+xx2+xx3, weights=Effort, data=edata))
>>     >
>>     > summary(glm.nb(Catch~xx1+xx2+xx3+offset(log(Effort)), data=edata))
>>     >
>>     >
>>     >
>>     > I am not sure the application of the weights function to the negative
>>     > binomial regression is correct. Also I wonder if there is a
>>    better way
>>     > doing this. Can anyone help?
>>     >
>>     >       [[alternative HTML version deleted]]
>>     >
>>     > ______________________________________________
>>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>    -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>    <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     > PLEASE do read the posting guide
>>    http://www.R-project.org/posting-guide.html
>>    <http://www.R-project.org/posting-guide.html>
>>     > and provide commented, minimal, self-contained, reproducible code.
>>    ______________________________________________
>>    R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>    To UNSUBSCRIBE and more, see
>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>    <https://stat.ethz.ch/mailman/listinfo/r-help>
>>    PLEASE do read the posting guide
>>    http://www.R-project.org/posting-guide.html
>>    <http://www.R-project.org/posting-guide.html>
>>    and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Nov  2 12:27:12 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 2 Nov 2023 14:27:12 +0300
Subject: [R] Bug in print for data frames?
In-Reply-To: <a52edbd7-3291-4c99-b42e-5ff9aeaefdc9@app.fastmail.com>
References: <a52edbd7-3291-4c99-b42e-5ff9aeaefdc9@app.fastmail.com>
Message-ID: <20231102142712.16321aed@arachnoid>

? Wed, 25 Oct 2023 09:18:26 +0300
"Christian Asseburg" <rhelp at moin.fi> ?????:

> > str(x)  
> 'data.frame':   1 obs. of  3 variables:
>  $ A: num 1
>  $ B: num 1
>  $ C:'data.frame':      1 obs. of  1 variable:
>   ..$ A: num 1
> 
> Why does the print(x) not show "C" as the name of the third element?

Interesting problem.

print.data.frame() calls format.data.frame() to prepare its argument
for printing, which in turn calls as.data.frame.list() to reconstruct a
data.frame from the formatted arguments, which in turn uses
data.frame() to actually construct the object.

data.frame() is able to return combined column names, but only if the
inner data.frame has more than one column:

names(data.frame(A = 1:3, B = data.frame(C = 4:6, D = 7:9)))
# [1] "A"   "B.C" "B.D"
names(data.frame(A = 1:3, B = data.frame(C = 4:6)))
# [1] "A" "C"

This matches the behaviour documented in ?data.frame:

>> For a named or unnamed matrix/list/data frame argument that contains
>> a single column, the column name in the result is the column name in
>> the argument.

Still, changing the presentational code like print.data.frame() or
format.data.frame() could be safe. I've tried writing a patch for
format.data.frame(), but it looks clumsy and breaks regression tests
(that do actually check capture.output()):

--- src/library/base/R/format.R (revision 85459)
+++ src/library/base/R/format.R (working copy)
@@ -243,8 +243,16 @@
     if(!nc) return(x) # 0 columns: evade problems, notably for nrow() > 0
     nr <- .row_names_info(x, 2L)
     rval <- vector("list", nc)
-    for(i in seq_len(nc))
+    for(i in seq_len(nc)) {
        rval[[i]] <- format(x[[i]], ..., justify = justify)
+       # avoid data.frame(foo = data.frame(bar = ...)) overwriting
+       # the single column name
+       if (
+           identical(ncol(rval[[i]]), 1L) &&
+           !is.null(colnames(rval[[i]])) &&
+           colnames(rval[[i]]) != ''
+       ) colnames(rval[[i]]) <- paste(names(x)[[i]], colnames(rval[[i]]), sep = '.')
+    }
     lens <- vapply(rval, NROW, 1)
     if(any(lens != nr)) { # corrupt data frame, must have at least one column
        warning("corrupt data frame: columns will be truncated or
        padded with NAs")

Is it worth changing the behaviour of {print,format}.data.frame() (and
fixing the regression tests to accept the new behaviour), or would that
break too much?

-- 
Best regards,
Ivan


From ro@||n@ump @end|ng |rom gm@||@com  Fri Nov  3 00:23:49 2023
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Fri, 3 Nov 2023 07:23:49 +0800
Subject: [R] Sum data according to date in sequence
Message-ID: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>

Dear all,

I have this set of data. I would like to sum the EnergykWh according date
sequences.

> head(dt1,20)                   StationName      date  time EnergykWh
1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500

I have tried this:
library(dplyr)
sums <- dt1 %>%
  group_by(date) %>%
  summarise(EnergykWh = sum(EnergykWh))

head(sums,20)

The date is not by daily sequence but by year sequence.

> head(sums,20)# A tibble: 20 ? 2
   date      EnergykWh
   <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3
1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6
1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9
1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12
1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15
1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18
1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.



Thank you very much for any help given.


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From cry@n @end|ng |rom b|ngh@mton@edu  Fri Nov  3 01:08:40 2023
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Thu, 2 Nov 2023 20:08:40 -0400
Subject: [R] Sum data according to date in sequence
In-Reply-To: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
Message-ID: <38d92f12-49cb-752e-83c2-12db9fe41bc7@binghamton.edu>

date appears to be a character variable, and R is treating it as such.

str(dt1)

might give you some insight.  Or the dplyr equivalent

glimpse(dt1)

I think R did what you asked, but if you want to be able to order
records by date, in temporal order, you need to tell R that it is a date:

library(dplyr)
sums <- dt1 %>%
    mutate(realDate = as.Date(date, format = "%m/%d/%Y") %>%
    group_by(realDate) %>%
    summarise(EnergykWh = sum(EnergykWh))


--Chris Ryan


roslinazairimah zakaria wrote:
> Dear all,
> 
> I have this set of data. I would like to sum the EnergykWh according date
> sequences.
> 
>> head(dt1,20)                   StationName      date  time EnergykWh
> 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
> 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
> 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
> 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
> 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
> 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
> 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
> 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
> 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
> 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
> 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
> 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
> 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
> 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
> 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
> 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
> 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
> 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
> 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
> 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
> 
> I have tried this:
> library(dplyr)
> sums <- dt1 %>%
>   group_by(date) %>%
>   summarise(EnergykWh = sum(EnergykWh))
> 
> head(sums,20)
> 
> The date is not by daily sequence but by year sequence.
> 
>> head(sums,20)# A tibble: 20 ? 2
>    date      EnergykWh
>    <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3
> 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6
> 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9
> 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12
> 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15
> 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18
> 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
> 
> 
> 
> Thank you very much for any help given.
> 
>


From jho|tm@n @end|ng |rom gm@||@com  Fri Nov  3 01:10:08 2023
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Thu, 2 Nov 2023 17:10:08 -0700
Subject: [R] Sum data according to date in sequence
In-Reply-To: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
Message-ID: <CAAxdm-74kKpsFMG1qUJmNxV8hA2LyDyjCjyVwiKz3KqvuUQgNQ@mail.gmail.com>

How about send a 'dput' of some sample data.  My guess is that your date is
'character' and not 'Date'.

Thanks

Jim Holtman
*Data Munger Guru*


*What is the problem that you are trying to solve?Tell me what you want to
do, not how you want to do it.*


On Thu, Nov 2, 2023 at 4:24?PM roslinazairimah zakaria <roslinaump at gmail.com>
wrote:

> Dear all,
>
> I have this set of data. I would like to sum the EnergykWh according date
> sequences.
>
> > head(dt1,20)                   StationName      date  time EnergykWh
> 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
> 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
> 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
> 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
> 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
> 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
> 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
> 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
> 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
> 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
> 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
> 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
> 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
> 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
> 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
> 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
> 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
> 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
> 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
> 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
>
> I have tried this:
> library(dplyr)
> sums <- dt1 %>%
>   group_by(date) %>%
>   summarise(EnergykWh = sum(EnergykWh))
>
> head(sums,20)
>
> The date is not by daily sequence but by year sequence.
>
> > head(sums,20)# A tibble: 20 ? 2
>    date      EnergykWh
>    <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3
> 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6
> 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9
> 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12
> 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15
> 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18
> 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
>
>
>
> Thank you very much for any help given.
>
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ro@||n@ump @end|ng |rom gm@||@com  Fri Nov  3 02:49:57 2023
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Fri, 3 Nov 2023 09:49:57 +0800
Subject: [R] Sum data according to date in sequence
In-Reply-To: <CAAxdm-74kKpsFMG1qUJmNxV8hA2LyDyjCjyVwiKz3KqvuUQgNQ@mail.gmail.com>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
 <CAAxdm-74kKpsFMG1qUJmNxV8hA2LyDyjCjyVwiKz3KqvuUQgNQ@mail.gmail.com>
Message-ID: <CANTvJZLZDkdT68sU0a-E35v_vAUtDvWWUcMV0x840XSM1KQDvA@mail.gmail.com>

Hi all,

This is the data:

> dput(head(dt1,20))structure(list(StationName = c("PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1"), date = c("1/14/2016", "1/14/2016",
"1/14/2016", "1/15/2016", "1/15/2016", "1/15/2016", "1/15/2016",
"1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016",
"1/16/2016", "1/16/2016", "1/17/2016", "1/17/2016", "1/17/2016",
"1/17/2016", "1/17/2016", "1/18/2016"), time = c("12:09", "19:50",
"20:22", "8:25", "14:23", "18:17", "21:46", "10:19", "12:12",
"14:12", "16:22", "19:16", "19:19", "20:24", "9:54", "12:16",
"13:53", "19:03", "22:00", "8:58"), EnergykWh = c(4.680496, 6.272414,
1.032782, 11.004884, 10.096824, 6.658797, 4.808874, 1.469384,
2.996239, 0.303222, 4.988339, 8.131804, 0.117156, 3.285669, 1.175608,
3.677487, 1.068393, 8.820755, 8.138583, 9.0575)), row.names = c(NA,
20L), class = "data.frame")


I would like to sum EnergykW data by the date. E.g. all values for
EnergykWh on 1/14/2016


On Fri, Nov 3, 2023 at 8:10?AM jim holtman <jholtman at gmail.com> wrote:

> How about send a 'dput' of some sample data.  My guess is that your date
> is 'character' and not 'Date'.
>
> Thanks
>
> Jim Holtman
> *Data Munger Guru*
>
>
> *What is the problem that you are trying to solve?Tell me what you want to
> do, not how you want to do it.*
>
>
> On Thu, Nov 2, 2023 at 4:24?PM roslinazairimah zakaria <
> roslinaump at gmail.com> wrote:
>
>> Dear all,
>>
>> I have this set of data. I would like to sum the EnergykWh according date
>> sequences.
>>
>> > head(dt1,20)                   StationName      date  time EnergykWh
>> 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
>> 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
>> 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
>> 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
>> 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
>> 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
>> 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
>> 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
>> 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
>> 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
>> 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
>> 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
>> 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
>> 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
>> 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
>> 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
>> 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
>> 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
>> 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
>> 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
>>
>> I have tried this:
>> library(dplyr)
>> sums <- dt1 %>%
>>   group_by(date) %>%
>>   summarise(EnergykWh = sum(EnergykWh))
>>
>> head(sums,20)
>>
>> The date is not by daily sequence but by year sequence.
>>
>> > head(sums,20)# A tibble: 20 ? 2
>>    date      EnergykWh
>>    <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3
>> 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6
>> 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9
>> 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12
>> 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15
>> 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18
>> 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
>>
>>
>>
>> Thank you very much for any help given.
>>
>>
>> --
>> *Roslinazairimah Zakaria*
>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>
>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> roslinaump at gmail.com <roslinaump at gmail.com>*
>> Faculty of Industrial Sciences & Technology
>> University Malaysia Pahang
>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From ro@||n@ump @end|ng |rom gm@||@com  Fri Nov  3 04:04:23 2023
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Fri, 3 Nov 2023 11:04:23 +0800
Subject: [R] Sum data according to date in sequence
In-Reply-To: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
Message-ID: <CANTvJZL96njE2sQ+VwGYU57N1S4Q2Uz__4zVCVC3=canAPsedg@mail.gmail.com>

Thank you very much for your help. It is very much appreciated.

On Fri, Nov 3, 2023 at 7:23?AM roslinazairimah zakaria <roslinaump at gmail.com>
wrote:

> Dear all,
>
> I have this set of data. I would like to sum the EnergykWh according date
> sequences.
>
> > head(dt1,20)                   StationName      date  time EnergykWh
> 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
> 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
> 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
> 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
> 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
> 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
> 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
> 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
> 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
> 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
> 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
> 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
> 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
> 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
> 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
> 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
> 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
> 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
> 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
> 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
>
> I have tried this:
> library(dplyr)
> sums <- dt1 %>%
>   group_by(date) %>%
>   summarise(EnergykWh = sum(EnergykWh))
>
> head(sums,20)
>
> The date is not by daily sequence but by year sequence.
>
> > head(sums,20)# A tibble: 20 ? 2
>    date      EnergykWh
>    <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
>
>
>
> Thank you very much for any help given.
>
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From ro@||n@ump @end|ng |rom gm@||@com  Fri Nov  3 10:51:20 2023
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Fri, 3 Nov 2023 17:51:20 +0800
Subject: [R] Sum data according to date in sequence
In-Reply-To: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
Message-ID: <CANTvJZ+S2rKDzQt9sZhTb26rS7-+mmZbxo1H6DH7yxM1rNjKZA@mail.gmail.com>

Hi,
I tried this:
# extract date from the time stamp
dt1 <- cbind(as.Date(dt$EndDate, format="%m/%d/%Y"), dt$EnergykWh)
head(dt1)
colnames(dt1) <- c("date", "EnergykWh")
and
my dt1 becomes these, the dates are replace by numbers.

dt1 <- cbind(as.Date(dt$EndDate, format="%m/%d/%Y"), dt$EnergykWh)
dput(head(dt1))
colnames(dt1) <- c("date", "EnergykWh")
dput(head(dt1))


> dput(head(dt1))structure(c(16814, 16814, 16814, 16815, 16815, 16815, 4.680496,
6.272414, 1.032782, 11.004884, 10.096824, 6.658797), dim = c(6L,
2L), dimnames = list(NULL, c("date", "EnergykWh")))

Then I tried this:
library(dplyr)
dt1 %>%
  group_by(date) %>%
  summarise(EnergykWh.sum = sum(EnergykWh))
and got this errors

dt1 %>%+   group_by(date) %>%+   summarise(EnergykWh.sum =
sum(EnergykWh))Error in UseMethod("group_by") :
  no applicable method for 'group_by' applied to an object of class
"c('matrix', 'array', 'double', 'numeric')"



On Fri, Nov 3, 2023 at 7:23?AM roslinazairimah zakaria <roslinaump at gmail.com>
wrote:

> Dear all,
>
> I have this set of data. I would like to sum the EnergykWh according date
> sequences.
>
> > head(dt1,20)                   StationName      date  time EnergykWh
> 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
> 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
> 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
> 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
> 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
> 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
> 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
> 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
> 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
> 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
> 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
> 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
> 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
> 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
> 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
> 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
> 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
> 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
> 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
> 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
>
> I have tried this:
> library(dplyr)
> sums <- dt1 %>%
>   group_by(date) %>%
>   summarise(EnergykWh = sum(EnergykWh))
>
> head(sums,20)
>
> The date is not by daily sequence but by year sequence.
>
> > head(sums,20)# A tibble: 20 ? 2
>    date      EnergykWh
>    <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
>
>
>
> Thank you very much for any help given.
>
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From mkz@m@n@m @end|ng |rom gm@||@com  Fri Nov  3 01:40:49 2023
From: mkz@m@n@m @end|ng |rom gm@||@com (Md. Kamruzzaman)
Date: Fri, 3 Nov 2023 11:10:49 +1030
Subject: [R] I need to create new variables based on two numeric variables
 and one dichotomize conditional category variables.
Message-ID: <CAGbxoeGjsxZKQ6qijEMq-X-5doqnQQS1jjPDDrGT6hH5xWqOKQ@mail.gmail.com>

Hello Everyone,
I have three variables: Waist circumference (WC), serum triglyceride (TG)
level and gender. Waist circumference and serum triglyceride is numeric and
gender (male and female) is categorical. From these three variables, I want
to calculate the "Lipid Accumulation Product (LAP) Index". The equation to
calculate LAP is different for male and females. I am giving both equations
below.

LAP for male = (WC-65)*TG
LAP for female = (WC-58)*TG

My question is 'how can I calculate the LAP and create a single new column?

Your cooperation will be highly appreciated.

Thanks in advance.

With Regards

*--------------------------------*

*Md Kamruzzaman*

*PhD **Research Fellow (**Medicine**)*
Discipline of Medicine and Centre of Research Excellence in Translating
Nutritional Science to Good Health
Adelaide Medical School | Faculty of Health and Medical Sciences
The University of Adelaide
Adelaide SA 5005

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Fri Nov  3 13:12:47 2023
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 3 Nov 2023 13:12:47 +0100
Subject: [R] Bug in print for data frames?
In-Reply-To: <54e89da3-c9fe-4a61-b59b-ec225cb8b1ca@gmail.com>
References: <a52edbd7-3291-4c99-b42e-5ff9aeaefdc9@app.fastmail.com>
 <54e89da3-c9fe-4a61-b59b-ec225cb8b1ca@gmail.com>
Message-ID: <0146352C-8CCC-4AF8-A4DA-EC5B5C7978BE@gmail.com>

It's still kind of weird; embedded 2-column data frames print differently than 1-column ones:

> d <- data.frame(a=1, b=I(data.frame(d=1,e=2)))
> d
  a b.d b.e
1 1   1   2
> str(d)
'data.frame':	1 obs. of  2 variables:
 $ a: num 1
 $ b:Classes 'AsIs' and 'data.frame':	1 obs. of  2 variables:
  ..$ d: num 1
  ..$ e: num 2
> names(d)
[1] "a" "b"
> d <- data.frame(a=1, b=I(data.frame(d=1)))
> d
  a d
1 1 1
> str(d)
'data.frame':	1 obs. of  2 variables:
 $ a: num 1
 $ b:Classes 'AsIs' and 'data.frame':	1 obs. of  1 variable:
  ..$ d: num 1
> names(d)
[1] "a" "b"

It is happening inside format.data.frame() or as.data.frame.list() but I can't figure out the logic at this point.

-pd


> On 26 Oct 2023, at 10:55 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 25/10/2023 2:18 a.m., Christian Asseburg wrote:
>> Hi! I came across this unexpected behaviour in R. First I thought it was a bug in the assignment operator <- but now I think it's maybe a bug in the way data frames are being printed. What do you think?
>> Using R 4.3.1:
>>> x <- data.frame(A = 1, B = 2, C = 3)
>>> y <- data.frame(A = 1)
>>> x
>>   A B C
>> 1 1 2 3
>>> x$B <- y$A # works as expected
>>> x
>>   A B C
>> 1 1 1 3
>>> x$C <- y[1] # makes C disappear
>>> x
>>   A B A
>> 1 1 1 1
>>> str(x)
>> 'data.frame':   1 obs. of  3 variables:
>>  $ A: num 1
>>  $ B: num 1
>>  $ C:'data.frame':      1 obs. of  1 variable:
>>   ..$ A: num 1
>> Why does the print(x) not show "C" as the name of the third element? I did mess up the data frame (and this was a mistake on my part), but finding the bug was harder because print(x) didn't show the C any longer.
> 
> y[1] is a dataframe with one column, i.e. it is identical to y.  To get the result you expected, you should have used y[[1]], to extract column 1.
> 
> Since dataframes are lists, you can assign them as columns of other dataframes, and you'll create a single column in the result whose rows are the columns of the dataframe you're assigning.  This means that
> 
> x$C <- y[1]
> 
> replaces the C column of x with a dataframe.  It retains the name C (you can see this if you print names(x) ), but since the column contains a dataframe, it chooses to use the column name of y when printing.
> 
> If you try
> 
> x$D <- x
> 
> you'll see it generate new names when printing, but the names within x remain as A, B, C, D.
> 
> This is a situation where tibbles do a better job than dataframes:  if you created x and y as tibbles instead of dataframes and executed your code, you'd see this:
> 
>  library(tibble)
>  x <- tibble(A = 1, B = 2, C = 3)
>  y <- tibble(A = 1)
>  x$C <- y[1]
>  x
>  #> # A tibble: 1 ? 3
>  #>       A     B   C$A
>  #>   <dbl> <dbl> <dbl>
>  #> 1     1     2     1
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j|ox @end|ng |rom mcm@@ter@c@  Fri Nov  3 13:44:34 2023
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Fri, 3 Nov 2023 08:44:34 -0400
Subject: [R] [R-pkgs] new cv package: cross-validation of regression models
Message-ID: <e64f1971-9441-4779-88ed-153712cfbac3@mcmaster.ca>

Georges Monette and I would like to announce a new package, cv, now on 
CRAN, which implements cross-validation of regression models.

Some of the functions supplied by the package:

-   cv() is a generic function with a default method and computationally 
efficient "lm" and "glm" methods, along with a method for a list of 
competing models. There are also experimental "merMod", "lme", and 
"glmmTMB" methods for mixed-effects models. cv() supports parallel 
computations.

-   mse() (mean-squared error) and BayesRule() are cross-validation 
criteria ("cost functions"), suitable for use with cv().

-   cvSelect() cross-validates a selection procedure for a regression 
model. cvSelect() also supports parallel computations.

-   selectStepAIC() is a model-selection procedure, suitable for use 
with cvSelect(), based on the stepAIC() function in the MASS package.

-   selectTrans() is a procedure for selecting predictor and response 
transformations in regression, also suitable for use with cvSelect(), 
based on the powerTransform() function in the car package.

For additional information on using the cv package, see the 
"Cross-validation of regression models" vignette, in the package and at 
<https://cran.r-project.org/web/packages/cv/vignettes/cv.html>. The cv 
package is designed to be extensible to other classes of regression 
models and other model-selection procedures; for details, see the 
"Extending the cv package" vignette, also in the package and at 
<https://cran.r-project.org/web/packages/cv/vignettes/cv-extend.html>.

Comments and suggestions would be appreciated. Bug reports and problems 
can be filed at <https://github.com/gmonette/cv/issues>.

Thank you for your attention,
  John and Georges


-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://www.john-fox.ca/

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From bgunter@4567 @end|ng |rom gm@||@com  Fri Nov  3 15:43:35 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 3 Nov 2023 07:43:35 -0700
Subject: [R] 
 I need to create new variables based on two numeric variables
 and one dichotomize conditional category variables.
In-Reply-To: <CAGbxoeGjsxZKQ6qijEMq-X-5doqnQQS1jjPDDrGT6hH5xWqOKQ@mail.gmail.com>
References: <CAGbxoeGjsxZKQ6qijEMq-X-5doqnQQS1jjPDDrGT6hH5xWqOKQ@mail.gmail.com>
Message-ID: <CAGxFJbS41wwYMDxRDE6s=WNEVchyAQv4uppMge2dFRdMnraCWQ@mail.gmail.com>

Well, something like:

LAP <- ifelse(gender =='male', (WC-65)*TG, (WC-58)*TG)

The exact code depends on whether your variables are in a data frame or
list or whatever, which you failed to specify. If so, ?with  may be useful.

Cheers,
Bert



On Fri, Nov 3, 2023 at 3:43?AM Md. Kamruzzaman <mkzaman.m at gmail.com> wrote:

> Hello Everyone,
> I have three variables: Waist circumference (WC), serum triglyceride (TG)
> level and gender. Waist circumference and serum triglyceride is numeric and
> gender (male and female) is categorical. From these three variables, I want
> to calculate the "Lipid Accumulation Product (LAP) Index". The equation to
> calculate LAP is different for male and females. I am giving both equations
> below.
>
> LAP for male = (WC-65)*TG
> LAP for female = (WC-58)*TG
>
> My question is 'how can I calculate the LAP and create a single new column?
>
> Your cooperation will be highly appreciated.
>
> Thanks in advance.
>
> With Regards
>
> *--------------------------------*
>
> *Md Kamruzzaman*
>
> *PhD **Research Fellow (**Medicine**)*
> Discipline of Medicine and Centre of Research Excellence in Translating
> Nutritional Science to Good Health
> Adelaide Medical School | Faculty of Health and Medical Sciences
> The University of Adelaide
> Adelaide SA 5005
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Nov  3 16:15:59 2023
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 03 Nov 2023 08:15:59 -0700
Subject: [R] Sum data according to date in sequence
In-Reply-To: <CANTvJZ+S2rKDzQt9sZhTb26rS7-+mmZbxo1H6DH7yxM1rNjKZA@mail.gmail.com>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
 <CANTvJZ+S2rKDzQt9sZhTb26rS7-+mmZbxo1H6DH7yxM1rNjKZA@mail.gmail.com>
Message-ID: <0735CADE-B135-4CD2-BEF8-AD0EF1A4997C@dcn.davis.ca.us>

Cbind is not a very good tool for adding columns to a data frame. Either use explicit column referencing like

dt1$x <- new_data_vector

but you do have to make sure the new data vector has the same number of values and in the same order as the other data in dt1. The transition from multiple records per day to one record per day would make the starting data and ending data incompatible.

library(dplyr)

dt1 <- structure(list(StationName = c("PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
"PALO ALTO CA / CAMBRIDGE #1"), date = c("1/14/2016", "1/14/2016",
"1/14/2016", "1/15/2016", "1/15/2016", "1/15/2016", "1/15/2016",
"1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016",
"1/16/2016", "1/16/2016", "1/17/2016", "1/17/2016", "1/17/2016",
"1/17/2016", "1/17/2016", "1/18/2016"), time = c("12:09", "19:50",
"20:22", "8:25", "14:23", "18:17", "21:46", "10:19", "12:12",
"14:12", "16:22", "19:16", "19:19", "20:24", "9:54", "12:16",
"13:53", "19:03", "22:00", "8:58"), EnergykWh = c(4.680496, 6.272414,
1.032782, 11.004884, 10.096824, 6.658797, 4.808874, 1.469384,
2.996239, 0.303222, 4.988339, 8.131804, 0.117156, 3.285669, 1.175608,
3.677487, 1.068393, 8.820755, 8.138583, 9.0575)), row.names = c(NA,
20L), class = "data.frame")

ans <- (
  dt1
  %>% mutate(
    Dt = as.Date( date, format = "%m/%d/%Y" )
  )
  %>% group_by( StationName, Dt )
  %>% summarize( DailyEnergykWh = sum( EnergykWh ) )
)


On November 3, 2023 2:51:20 AM PDT, roslinazairimah zakaria <roslinaump at gmail.com> wrote:
>Hi,
>I tried this:
># extract date from the time stamp
>dt1 <- cbind(as.Date(dt$EndDate, format="%m/%d/%Y"), dt$EnergykWh)
>head(dt1)
>colnames(dt1) <- c("date", "EnergykWh")
>and
>my dt1 becomes these, the dates are replace by numbers.
>
>dt1 <- cbind(as.Date(dt$EndDate, format="%m/%d/%Y"), dt$EnergykWh)
>dput(head(dt1))
>colnames(dt1) <- c("date", "EnergykWh")
>dput(head(dt1))
>
>
>> dput(head(dt1))structure(c(16814, 16814, 16814, 16815, 16815, 16815, 4.680496,
>6.272414, 1.032782, 11.004884, 10.096824, 6.658797), dim = c(6L,
>2L), dimnames = list(NULL, c("date", "EnergykWh")))
>
>Then I tried this:
>library(dplyr)
>dt1 %>%
>  group_by(date) %>%
>  summarise(EnergykWh.sum = sum(EnergykWh))
>and got this errors
>
>dt1 %>%+   group_by(date) %>%+   summarise(EnergykWh.sum =
>sum(EnergykWh))Error in UseMethod("group_by") :
>  no applicable method for 'group_by' applied to an object of class
>"c('matrix', 'array', 'double', 'numeric')"
>
>
>
>On Fri, Nov 3, 2023 at 7:23?AM roslinazairimah zakaria <roslinaump at gmail.com>
>wrote:
>
>> Dear all,
>>
>> I have this set of data. I would like to sum the EnergykWh according date
>> sequences.
>>
>> > head(dt1,20)                   StationName      date  time EnergykWh
>> 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
>> 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
>> 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
>> 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
>> 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
>> 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
>> 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
>> 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
>> 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
>> 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
>> 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
>> 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
>> 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
>> 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
>> 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
>> 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
>> 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
>> 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
>> 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
>> 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
>>
>> I have tried this:
>> library(dplyr)
>> sums <- dt1 %>%
>>   group_by(date) %>%
>>   summarise(EnergykWh = sum(EnergykWh))
>>
>> head(sums,20)
>>
>> The date is not by daily sequence but by year sequence.
>>
>> > head(sums,20)# A tibble: 20 ? 2
>>    date      EnergykWh
>>    <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
>>
>>
>>
>> Thank you very much for any help given.
>>
>>
>> --
>> *Roslinazairimah Zakaria*
>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>
>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> roslinaump at gmail.com <roslinaump at gmail.com>*
>> Faculty of Industrial Sciences & Technology
>> University Malaysia Pahang
>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>
>
>

-- 
Sent from my phone. Please excuse my brevity.


From JH@rm@e @end|ng |rom roku@com  Fri Nov  3 16:55:57 2023
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Fri, 3 Nov 2023 15:55:57 +0000
Subject: [R] 
 I need to create new variables based on two numeric variables
 and one dichotomize conditional category variables.
In-Reply-To: <mailman.370481.1.1699009201.56788.r-help@r-project.org>
References: <mailman.370481.1.1699009201.56788.r-help@r-project.org>
Message-ID: <LV3PR01MB86736581F1E69742E545FD59DCA5A@LV3PR01MB8673.prod.exchangelabs.com>

df$LAP <- with(df, ifelse(G=='male', (WC-65)*TG, (WC-58)*TG))

That will do both calculations and merge the two vectors appropriately. It will use extra memory, but it should be much faster than a 'for' loop.

Regards,
Jorgen Harmse.

------------------------------

Message: 8
Date: Fri, 3 Nov 2023 11:10:49 +1030
From: "Md. Kamruzzaman" <mkzaman.m at gmail.com>
To: r-help at r-project.org
Subject: [R] I need to create new variables based on two numeric
        variables and one dichotomize conditional category variables.
Message-ID:
        <CAGbxoeGjsxZKQ6qijEMq-X-5doqnQQS1jjPDDrGT6hH5xWqOKQ at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hello Everyone,
I have three variables: Waist circumference (WC), serum triglyceride (TG)
level and gender. Waist circumference and serum triglyceride is numeric and
gender (male and female) is categorical. From these three variables, I want
to calculate the "Lipid Accumulation Product (LAP) Index". The equation to
calculate LAP is different for male and females. I am giving both equations
below.

LAP for male = (WC-65)*TG
LAP for female = (WC-58)*TG

My question is 'how can I calculate the LAP and create a single new column?

Your cooperation will be highly appreciated.

Thanks in advance.

With Regards

*--------------------------------*

*Md Kamruzzaman*

*PhD **Research Fellow (**Medicine**)*
Discipline of Medicine and Centre of Research Excellence in Translating
Nutritional Science to Good Health
Adelaide Medical School | Faculty of Health and Medical Sciences
The University of Adelaide
Adelaide SA 5005

        [[alternative HTML version deleted]]



	[[alternative HTML version deleted]]


From jho|tm@n @end|ng |rom gm@||@com  Fri Nov  3 16:58:18 2023
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Fri, 3 Nov 2023 08:58:18 -0700
Subject: [R] Sum data according to date in sequence
In-Reply-To: <CANTvJZ+S2rKDzQt9sZhTb26rS7-+mmZbxo1H6DH7yxM1rNjKZA@mail.gmail.com>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
 <CANTvJZ+S2rKDzQt9sZhTb26rS7-+mmZbxo1H6DH7yxM1rNjKZA@mail.gmail.com>
Message-ID: <CAAxdm-7mHhR32n-dUxSK7d2pk9o2Frq1Cj_AorW2Q6C5PTbedA@mail.gmail.com>

Is this what you are after?

library(tidyverse)


library(lubridate)

input <- structure(list(StationName = c("PALO ALTO CA / CAMBRIDGE #1",
  "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
  "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
  "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
  "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
  "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
  "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
  "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
  "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
  "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
  "PALO ALTO CA / CAMBRIDGE #1"), date = c("1/14/2016", "1/14/2016",
   "1/14/2016", "1/15/2016", "1/15/2016", "1/15/2016", "1/15/2016",
   "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016",
   "1/16/2016", "1/16/2016", "1/17/2016", "1/17/2016", "1/17/2016",
   "1/17/2016", "1/17/2016", "1/18/2016"), time = c("12:09", "19:50",
  "20:22", "8:25", "14:23", "18:17", "21:46", "10:19", "12:12",
  "14:12", "16:22", "19:16", "19:19", "20:24", "9:54", "12:16",
  "13:53", "19:03", "22:00", "8:58"),
  EnergykWh = c(4.680496, 6.272414,
  1.032782, 11.004884, 10.096824, 6.658797, 4.808874, 1.469384,
  2.996239, 0.303222, 4.988339, 8.131804, 0.117156, 3.285669, 1.175608,
  3.677487, 1.068393, 8.820755, 8.138583, 9.0575)),
  row.names = c(NA, 20L), class = "data.frame")
# convert date from character to Date
byDate <- input |>
  mutate(newdate = mdy(date)) |>
  group_by(newdate) |>
  summarise(total = sum(EnergykWh))

byDate

## # A tibble: 5 ? 2
##   newdate    total
##   <date>     <dbl>
## 1 2016-01-14 12.0
## 2 2016-01-15 32.6
## 3 2016-01-16 21.3
## 4 2016-01-17 22.9
## 5 2016-01-18  9.06


Thanks

Jim Holtman
*Data Munger Guru*


*What is the problem that you are trying to solve?Tell me what you want to
do, not how you want to do it.*


On Fri, Nov 3, 2023 at 2:51?AM roslinazairimah zakaria <roslinaump at gmail.com>
wrote:

> Hi,
> I tried this:
> # extract date from the time stamp
> dt1 <- cbind(as.Date(dt$EndDate, format="%m/%d/%Y"), dt$EnergykWh)
> head(dt1)
> colnames(dt1) <- c("date", "EnergykWh")
> and
> my dt1 becomes these, the dates are replace by numbers.
>
> dt1 <- cbind(as.Date(dt$EndDate, format="%m/%d/%Y"), dt$EnergykWh)
> dput(head(dt1))
> colnames(dt1) <- c("date", "EnergykWh")
> dput(head(dt1))
>
>
> > dput(head(dt1))structure(c(16814, 16814, 16814, 16815, 16815, 16815,
> 4.680496,
> 6.272414, 1.032782, 11.004884, 10.096824, 6.658797), dim = c(6L,
> 2L), dimnames = list(NULL, c("date", "EnergykWh")))
>
> Then I tried this:
> library(dplyr)
> dt1 %>%
>   group_by(date) %>%
>   summarise(EnergykWh.sum = sum(EnergykWh))
> and got this errors
>
> dt1 %>%+   group_by(date) %>%+   summarise(EnergykWh.sum =
> sum(EnergykWh))Error in UseMethod("group_by") :
>   no applicable method for 'group_by' applied to an object of class
> "c('matrix', 'array', 'double', 'numeric')"
>
>
>
> On Fri, Nov 3, 2023 at 7:23?AM roslinazairimah zakaria <
> roslinaump at gmail.com>
> wrote:
>
> > Dear all,
> >
> > I have this set of data. I would like to sum the EnergykWh according date
> > sequences.
> >
> > > head(dt1,20)                   StationName      date  time EnergykWh
> > 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
> > 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
> > 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
> > 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
> > 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
> > 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
> > 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
> > 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
> > 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
> > 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
> > 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
> > 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
> > 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
> > 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
> > 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
> > 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
> > 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
> > 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
> > 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
> > 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
> >
> > I have tried this:
> > library(dplyr)
> > sums <- dt1 %>%
> >   group_by(date) %>%
> >   summarise(EnergykWh = sum(EnergykWh))
> >
> > head(sums,20)
> >
> > The date is not by daily sequence but by year sequence.
> >
> > > head(sums,20)# A tibble: 20 ? 2
> >    date      EnergykWh
> >    <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3
> 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6
> 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9
> 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12
> 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15
> 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18
> 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
> >
> >
> >
> > Thank you very much for any help given.
> >
> >
> > --
> > *Roslinazairimah Zakaria*
> > *Tel: +609-5492370; Fax. No.+609-5492766*
> >
> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> > roslinaump at gmail.com <roslinaump at gmail.com>*
> > Faculty of Industrial Sciences & Technology
> > University Malaysia Pahang
> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >
>
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ro@||n@ump @end|ng |rom gm@||@com  Fri Nov  3 21:21:40 2023
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Sat, 4 Nov 2023 04:21:40 +0800
Subject: [R] Sum data according to date in sequence
In-Reply-To: <CAAxdm-7mHhR32n-dUxSK7d2pk9o2Frq1Cj_AorW2Q6C5PTbedA@mail.gmail.com>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
 <CANTvJZ+S2rKDzQt9sZhTb26rS7-+mmZbxo1H6DH7yxM1rNjKZA@mail.gmail.com>
 <CAAxdm-7mHhR32n-dUxSK7d2pk9o2Frq1Cj_AorW2Q6C5PTbedA@mail.gmail.com>
Message-ID: <CANTvJZK6ze4ghswTxtk1btUfE1JOSOoKA+48dy492oL6iaeZ_g@mail.gmail.com>

Hi Jim,

Yes, that is exactly what I am trying to do. Once I get that, I want to
plot time series data.
Thank you very much Jim.

On Fri, Nov 3, 2023 at 11:58?PM jim holtman <jholtman at gmail.com> wrote:

> Is this what you are after?
>
> library(tidyverse)
>
>
> library(lubridate)
>
> input <- structure(list(StationName = c("PALO ALTO CA / CAMBRIDGE #1",
>   "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
>   "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
>   "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
>   "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
>   "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
>   "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
>   "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
>   "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
>   "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
>   "PALO ALTO CA / CAMBRIDGE #1"), date = c("1/14/2016", "1/14/2016",
>    "1/14/2016", "1/15/2016", "1/15/2016", "1/15/2016", "1/15/2016",
>    "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016",
>    "1/16/2016", "1/16/2016", "1/17/2016", "1/17/2016", "1/17/2016",
>    "1/17/2016", "1/17/2016", "1/18/2016"), time = c("12:09", "19:50",
>   "20:22", "8:25", "14:23", "18:17", "21:46", "10:19", "12:12",
>   "14:12", "16:22", "19:16", "19:19", "20:24", "9:54", "12:16",
>   "13:53", "19:03", "22:00", "8:58"),
>   EnergykWh = c(4.680496, 6.272414,
>   1.032782, 11.004884, 10.096824, 6.658797, 4.808874, 1.469384,
>   2.996239, 0.303222, 4.988339, 8.131804, 0.117156, 3.285669, 1.175608,
>   3.677487, 1.068393, 8.820755, 8.138583, 9.0575)),
>   row.names = c(NA, 20L), class = "data.frame")
> # convert date from character to Date
> byDate <- input |>
>   mutate(newdate = mdy(date)) |>
>   group_by(newdate) |>
>   summarise(total = sum(EnergykWh))
>
> byDate
>
> ## # A tibble: 5 ? 2
> ##   newdate    total
> ##   <date>     <dbl>
> ## 1 2016-01-14 12.0
> ## 2 2016-01-15 32.6
> ## 3 2016-01-16 21.3
> ## 4 2016-01-17 22.9
> ## 5 2016-01-18  9.06
>
>
> Thanks
>
> Jim Holtman
> *Data Munger Guru*
>
>
> *What is the problem that you are trying to solve?Tell me what you want to
> do, not how you want to do it.*
>
>
> On Fri, Nov 3, 2023 at 2:51?AM roslinazairimah zakaria <
> roslinaump at gmail.com> wrote:
>
>> Hi,
>> I tried this:
>> # extract date from the time stamp
>> dt1 <- cbind(as.Date(dt$EndDate, format="%m/%d/%Y"), dt$EnergykWh)
>> head(dt1)
>> colnames(dt1) <- c("date", "EnergykWh")
>> and
>> my dt1 becomes these, the dates are replace by numbers.
>>
>> dt1 <- cbind(as.Date(dt$EndDate, format="%m/%d/%Y"), dt$EnergykWh)
>> dput(head(dt1))
>> colnames(dt1) <- c("date", "EnergykWh")
>> dput(head(dt1))
>>
>>
>> > dput(head(dt1))structure(c(16814, 16814, 16814, 16815, 16815, 16815,
>> 4.680496,
>> 6.272414, 1.032782, 11.004884, 10.096824, 6.658797), dim = c(6L,
>> 2L), dimnames = list(NULL, c("date", "EnergykWh")))
>>
>> Then I tried this:
>> library(dplyr)
>> dt1 %>%
>>   group_by(date) %>%
>>   summarise(EnergykWh.sum = sum(EnergykWh))
>> and got this errors
>>
>> dt1 %>%+   group_by(date) %>%+   summarise(EnergykWh.sum =
>> sum(EnergykWh))Error in UseMethod("group_by") :
>>   no applicable method for 'group_by' applied to an object of class
>> "c('matrix', 'array', 'double', 'numeric')"
>>
>>
>>
>> On Fri, Nov 3, 2023 at 7:23?AM roslinazairimah zakaria <
>> roslinaump at gmail.com>
>> wrote:
>>
>> > Dear all,
>> >
>> > I have this set of data. I would like to sum the EnergykWh according
>> date
>> > sequences.
>> >
>> > > head(dt1,20)                   StationName      date  time EnergykWh
>> > 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
>> > 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
>> > 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
>> > 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
>> > 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
>> > 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
>> > 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
>> > 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
>> > 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
>> > 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
>> > 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
>> > 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
>> > 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
>> > 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
>> > 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
>> > 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
>> > 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
>> > 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
>> > 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
>> > 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
>> >
>> > I have tried this:
>> > library(dplyr)
>> > sums <- dt1 %>%
>> >   group_by(date) %>%
>> >   summarise(EnergykWh = sum(EnergykWh))
>> >
>> > head(sums,20)
>> >
>> > The date is not by daily sequence but by year sequence.
>> >
>> > > head(sums,20)# A tibble: 20 ? 2
>> >    date      EnergykWh
>> >    <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3
>> 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6
>> 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9
>> 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12
>> 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15
>> 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18
>> 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
>> >
>> >
>> >
>> > Thank you very much for any help given.
>> >
>> >
>> > --
>> > *Roslinazairimah Zakaria*
>> > *Tel: +609-5492370; Fax. No.+609-5492766*
>> >
>> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> > roslinaump at gmail.com <roslinaump at gmail.com>*
>> > Faculty of Industrial Sciences & Technology
>> > University Malaysia Pahang
>> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>> >
>>
>>
>> --
>> *Roslinazairimah Zakaria*
>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>
>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> roslinaump at gmail.com <roslinaump at gmail.com>*
>> Faculty of Industrial Sciences & Technology
>> University Malaysia Pahang
>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Fri Nov  3 22:11:53 2023
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Fri, 3 Nov 2023 17:11:53 -0400
Subject: [R] 
 I need to create new variables based on two numeric variables
 and one dichotomize conditional category variables.
In-Reply-To: <LV3PR01MB86736581F1E69742E545FD59DCA5A@LV3PR01MB8673.prod.exchangelabs.com>
References: <mailman.370481.1.1699009201.56788.r-help@r-project.org>
 <LV3PR01MB86736581F1E69742E545FD59DCA5A@LV3PR01MB8673.prod.exchangelabs.com>
Message-ID: <002d01da0e9a$5f1d2930$1d577b90$@gmail.com>

Just a minor point in the suggested solution:

df$LAP <- with(df, ifelse(G=='male', (WC-65)*TG, (WC-58)*TG))

since WC and TG are not conditional, would this be a slight improvement?

df$LAP <- with(df, TG*(WC - ifelse(G=='male', 65, 58)))



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jorgen Harmse via
R-help
Sent: Friday, November 3, 2023 11:56 AM
To: r-help at r-project.org; mkzaman.m at gmail.com
Subject: Re: [R] I need to create new variables based on two numeric
variables and one dichotomize conditional category variables.

df$LAP <- with(df, ifelse(G=='male', (WC-65)*TG, (WC-58)*TG))

That will do both calculations and merge the two vectors appropriately. It
will use extra memory, but it should be much faster than a 'for' loop.

Regards,
Jorgen Harmse.

------------------------------

Message: 8
Date: Fri, 3 Nov 2023 11:10:49 +1030
From: "Md. Kamruzzaman" <mkzaman.m at gmail.com>
To: r-help at r-project.org
Subject: [R] I need to create new variables based on two numeric
        variables and one dichotomize conditional category variables.
Message-ID:
        <CAGbxoeGjsxZKQ6qijEMq-X-5doqnQQS1jjPDDrGT6hH5xWqOKQ at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hello Everyone,
I have three variables: Waist circumference (WC), serum triglyceride (TG)
level and gender. Waist circumference and serum triglyceride is numeric and
gender (male and female) is categorical. From these three variables, I want
to calculate the "Lipid Accumulation Product (LAP) Index". The equation to
calculate LAP is different for male and females. I am giving both equations
below.

LAP for male = (WC-65)*TG
LAP for female = (WC-58)*TG

My question is 'how can I calculate the LAP and create a single new column?

Your cooperation will be highly appreciated.

Thanks in advance.

With Regards

*--------------------------------*

*Md Kamruzzaman*

*PhD **Research Fellow (**Medicine**)*
Discipline of Medicine and Centre of Research Excellence in Translating
Nutritional Science to Good Health
Adelaide Medical School | Faculty of Health and Medical Sciences
The University of Adelaide
Adelaide SA 5005

        [[alternative HTML version deleted]]



	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From JH@rm@e @end|ng |rom roku@com  Fri Nov  3 23:26:38 2023
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Fri, 3 Nov 2023 22:26:38 +0000
Subject: [R] [EXTERNAL] RE: I need to create new variables based on two
 numeric variables and one dichotomize conditional category variables.
In-Reply-To: <002d01da0e9a$5f1d2930$1d577b90$@gmail.com>
References: <mailman.370481.1.1699009201.56788.r-help@r-project.org>
 <LV3PR01MB86736581F1E69742E545FD59DCA5A@LV3PR01MB8673.prod.exchangelabs.com>
 <002d01da0e9a$5f1d2930$1d577b90$@gmail.com>
Message-ID: <LV3PR01MB867383C6F83525C671FE74E0DCA5A@LV3PR01MB8673.prod.exchangelabs.com>

Yes, that will halve the number of multiplications.

If you?re looking for such optimisations then you can also consider ifelse(G=='male', 65L, 58L). That will definitely use less time & memory if WC is integer, but the trade-offs are more complicated if WC is floating point.

Regards,
Jorgen Harmse.



From: avi.e.gross at gmail.com <avi.e.gross at gmail.com>
Date: Friday, November 3, 2023 at 16:12
To: Jorgen Harmse <JHarmse at roku.com>, r-help at r-project.org <r-help at r-project.org>, mkzaman.m at gmail.com <mkzaman.m at gmail.com>
Subject: [EXTERNAL] RE: [R] I need to create new variables based on two numeric variables and one dichotomize conditional category variables.
Just a minor point in the suggested solution:

df$LAP <- with(df, ifelse(G=='male', (WC-65)*TG, (WC-58)*TG))

since WC and TG are not conditional, would this be a slight improvement?

df$LAP <- with(df, TG*(WC - ifelse(G=='male', 65, 58)))



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jorgen Harmse via
R-help
Sent: Friday, November 3, 2023 11:56 AM
To: r-help at r-project.org; mkzaman.m at gmail.com
Subject: Re: [R] I need to create new variables based on two numeric
variables and one dichotomize conditional category variables.

df$LAP <- with(df, ifelse(G=='male', (WC-65)*TG, (WC-58)*TG))

That will do both calculations and merge the two vectors appropriately. It
will use extra memory, but it should be much faster than a 'for' loop.

Regards,
Jorgen Harmse.

------------------------------

Message: 8
Date: Fri, 3 Nov 2023 11:10:49 +1030
From: "Md. Kamruzzaman" <mkzaman.m at gmail.com>
To: r-help at r-project.org
Subject: [R] I need to create new variables based on two numeric
        variables and one dichotomize conditional category variables.
Message-ID:
        <CAGbxoeGjsxZKQ6qijEMq-X-5doqnQQS1jjPDDrGT6hH5xWqOKQ at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hello Everyone,
I have three variables: Waist circumference (WC), serum triglyceride (TG)
level and gender. Waist circumference and serum triglyceride is numeric and
gender (male and female) is categorical. From these three variables, I want
to calculate the "Lipid Accumulation Product (LAP) Index". The equation to
calculate LAP is different for male and females. I am giving both equations
below.

LAP for male = (WC-65)*TG
LAP for female = (WC-58)*TG

My question is 'how can I calculate the LAP and create a single new column?

Your cooperation will be highly appreciated.

Thanks in advance.

With Regards

*--------------------------------*

*Md Kamruzzaman*

*PhD **Research Fellow (**Medicine**)*
Discipline of Medicine and Centre of Research Excellence in Translating
Nutritional Science to Good Health
Adelaide Medical School | Faculty of Health and Medical Sciences
The University of Adelaide
Adelaide SA 5005

        [[alternative HTML version deleted]]



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Sat Nov  4 06:08:03 2023
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 4 Nov 2023 01:08:03 -0400
Subject: [R] [EXTERNAL] RE: I need to create new variables based on two
 numeric variables and one dichotomize conditional category variables.
In-Reply-To: <LV3PR01MB867383C6F83525C671FE74E0DCA5A@LV3PR01MB8673.prod.exchangelabs.com>
References: <mailman.370481.1.1699009201.56788.r-help@r-project.org>
 <LV3PR01MB86736581F1E69742E545FD59DCA5A@LV3PR01MB8673.prod.exchangelabs.com>
 <002d01da0e9a$5f1d2930$1d577b90$@gmail.com>
 <LV3PR01MB867383C6F83525C671FE74E0DCA5A@LV3PR01MB8673.prod.exchangelabs.com>
Message-ID: <019a01da0edc$e41c39e0$ac54ada0$@gmail.com>

To be fair, Jordan, I think R has some optimizations so that the arguments
in some cases are NOT evaluated until needed. So only one or the other
choice ever gets evaluated for each row. My suggestion merely has
typographic implications and some aspects of clarity and minor amounts of
less memory and parsing needed. 
 
But ifelse() is currently implemented somewhat too complexly for my taste.
Just type "ifelse" at the prompt and you will see many lines of code that
handle various scenarios.
 
If you KNOW you have a certain situation such as a data.frame with multiple
rows and are sure a simpler solution works, there may well be faster ways to
do this. Obviously you could write a function that can be called once per
line and returns the answer, or a vectorized version that returns a vector
of 65 and 58 entries. Or you could add a few lines of code creating a
vector, perhaps as a temporary new column that looks like:
 
logic_male <- df$G == "male"
 
age[logic_male] <- 65
age(!logic_male] <- 58
 
Then use the age column in a formula directly as it contains the part of the
ifelse needed. You can then delete "age" whether stand-alone or as a column.
 
What is more efficient depends on your data.
 
Do note though that an advantage of using ifelse() is when you have nested
conditions which cannot trivially be written out along the lines above, but
I find that sometimes such nested expressions may be easier to read using
other techniques such as the dplyr function case_when().
Here is an example of code where some entries are NA or not categorized:
 
library(tidyverse)
WC <- 100
TG <- 2
Gender <- c("male", "female", "no comment", NA, "female")
 
result <- TG * (WC -
                  case_when(
                    is.na(Gender) ~NA,
                    Gender == "male" ~ 65,
                    Gender == "female" ~ 58,
                    .default  = NA
                  ))
 
The result for the above example is a result:
 
> result
[1] 70 84 NA NA 84
 
 
If you later want to add categories such as "transgender" with a value of 61
or have other numbers for groups like "Hispanic male", you can amend the
instructions as long as you put your conditions in an order so that they are
tried until one of them matches, or it takes the default. Yes, in a sense
the above is doable using a deeply nested ifelse() but easier for me to read
and write and evaluate. It may not be more efficient or may be as some of
dplyr is compiled code.
 
Please note some here prefer discussions about base-R functionality and some
have qualms about the tidyverse for various reasons. I don't and find much
of their functionality more easy to use.
 
 
 
From: Jorgen Harmse <JHarmse at roku.com> 
Sent: Friday, November 3, 2023 6:27 PM
To: avi.e.gross at gmail.com; r-help at r-project.org; mkzaman.m at gmail.com
Subject: Re: [EXTERNAL] RE: [R] I need to create new variables based on two
numeric variables and one dichotomize conditional category variables.
 
Yes, that will halve the number of multiplications.
 
If you're looking for such optimisations then you can also consider
ifelse(G=='male', 65L, 58L). That will definitely use less time & memory if
WC is integer, but the trade-offs are more complicated if WC is floating
point.
 
Regards,
Jorgen Harmse.


 
From: avi.e.gross at gmail.com <mailto:avi.e.gross at gmail.com>
<avi.e.gross at gmail.com <mailto:avi.e.gross at gmail.com> >
Date: Friday, November 3, 2023 at 16:12
To: Jorgen Harmse <JHarmse at roku.com <mailto:JHarmse at roku.com> >,
r-help at r-project.org <mailto:r-help at r-project.org>  <r-help at r-project.org
<mailto:r-help at r-project.org> >, mkzaman.m at gmail.com
<mailto:mkzaman.m at gmail.com>  <mkzaman.m at gmail.com
<mailto:mkzaman.m at gmail.com> >
Subject: [EXTERNAL] RE: [R] I need to create new variables based on two
numeric variables and one dichotomize conditional category variables.
Just a minor point in the suggested solution:

df$LAP <- with(df, ifelse(G=='male', (WC-65)*TG, (WC-58)*TG))

since WC and TG are not conditional, would this be a slight improvement?

df$LAP <- with(df, TG*(WC - ifelse(G=='male', 65, 58)))



-----Original Message-----
From: R-help <r-help-bounces at r-project.org
<mailto:r-help-bounces at r-project.org> > On Behalf Of Jorgen Harmse via
R-help
Sent: Friday, November 3, 2023 11:56 AM
To: r-help at r-project.org <mailto:r-help at r-project.org> ; mkzaman.m at gmail.com
<mailto:mkzaman.m at gmail.com> 
Subject: Re: [R] I need to create new variables based on two numeric
variables and one dichotomize conditional category variables.

df$LAP <- with(df, ifelse(G=='male', (WC-65)*TG, (WC-58)*TG))

That will do both calculations and merge the two vectors appropriately. It
will use extra memory, but it should be much faster than a 'for' loop.

Regards,
Jorgen Harmse.

------------------------------

Message: 8
Date: Fri, 3 Nov 2023 11:10:49 +1030
From: "Md. Kamruzzaman" <mkzaman.m at gmail.com <mailto:mkzaman.m at gmail.com> >
To: r-help at r-project.org <mailto:r-help at r-project.org> 
Subject: [R] I need to create new variables based on two numeric
        variables and one dichotomize conditional category variables.
Message-ID:
        <CAGbxoeGjsxZKQ6qijEMq-X-5doqnQQS1jjPDDrGT6hH5xWqOKQ at mail.gmail.com
<mailto:CAGbxoeGjsxZKQ6qijEMq-X-5doqnQQS1jjPDDrGT6hH5xWqOKQ at mail.gmail.com>
>
Content-Type: text/plain; charset="utf-8"

Hello Everyone,
I have three variables: Waist circumference (WC), serum triglyceride (TG)
level and gender. Waist circumference and serum triglyceride is numeric and
gender (male and female) is categorical. From these three variables, I want
to calculate the "Lipid Accumulation Product (LAP) Index". The equation to
calculate LAP is different for male and females. I am giving both equations
below.

LAP for male = (WC-65)*TG
LAP for female = (WC-58)*TG

My question is 'how can I calculate the LAP and create a single new column?

Your cooperation will be highly appreciated.

Thanks in advance.

With Regards

*--------------------------------*

*Md Kamruzzaman*

*PhD **Research Fellow (**Medicine**)*
Discipline of Medicine and Centre of Research Excellence in Translating
Nutritional Science to Good Health
Adelaide Medical School | Faculty of Health and Medical Sciences
The University of Adelaide
Adelaide SA 5005

        [[alternative HTML version deleted]]



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To
UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @|e@@@ndro@pug||@| @end|ng |rom gm@||@com  Fri Nov  3 17:20:43 2023
From: @|e@@@ndro@pug||@| @end|ng |rom gm@||@com (Alessandro Puglisi)
Date: Fri, 3 Nov 2023 17:20:43 +0100
Subject: [R] Adding columns to a tibble based on a value in a different
 tibble
Message-ID: <CA+MLcG12KWOwGeR_fPNbazHCNAktmvcgvJ8TKVQdB1xbJ5jsQw@mail.gmail.com>

Hi everyone,

I have a tibble with various ids and associated information.

I need to add a new column to this tibble that retrieves a specific 'y'
value from a different tibble that has some of the mentioned ids in the
first column and a 'y' value in the second one. If the id, and so the 'y'
value is found, it will be included; otherwise, 'NA' will be used.

Could you please help me?

Thanks,
Alessandro

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Nov  4 15:35:18 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 4 Nov 2023 07:35:18 -0700
Subject: [R] Adding columns to a tibble based on a value in a different
 tibble
In-Reply-To: <CA+MLcG12KWOwGeR_fPNbazHCNAktmvcgvJ8TKVQdB1xbJ5jsQw@mail.gmail.com>
References: <CA+MLcG12KWOwGeR_fPNbazHCNAktmvcgvJ8TKVQdB1xbJ5jsQw@mail.gmail.com>
Message-ID: <CAGxFJbT+X6Gj-KUjZUYcGmiGn71-YmOkguH=rg=PTaSXq-=wtQ@mail.gmail.com>

I think a simple reproducible example ("reprex") may be necessary for you
to get a useful reply. Questions with vague specifications such as yours
often result in going round and round with attempts to clarify what you
mean without a satisfactory answer. Clarification at the outset with a
reprex may save you and others a lot of frustration.

Cheers,
Bert

On Sat, Nov 4, 2023 at 1:41?AM Alessandro Puglisi <
alessandro.puglisi at gmail.com> wrote:

> Hi everyone,
>
> I have a tibble with various ids and associated information.
>
> I need to add a new column to this tibble that retrieves a specific 'y'
> value from a different tibble that has some of the mentioned ids in the
> first column and a 'y' value in the second one. If the id, and so the 'y'
> value is found, it will be included; otherwise, 'NA' will be used.
>
> Could you please help me?
>
> Thanks,
> Alessandro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Sat Nov  4 16:25:13 2023
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 4 Nov 2023 11:25:13 -0400
Subject: [R] Adding columns to a tibble based on a value in a different
 tibble
In-Reply-To: <CAGxFJbT+X6Gj-KUjZUYcGmiGn71-YmOkguH=rg=PTaSXq-=wtQ@mail.gmail.com>
References: <CA+MLcG12KWOwGeR_fPNbazHCNAktmvcgvJ8TKVQdB1xbJ5jsQw@mail.gmail.com>
 <CAGxFJbT+X6Gj-KUjZUYcGmiGn71-YmOkguH=rg=PTaSXq-=wtQ@mail.gmail.com>
Message-ID: <003e01da0f33$1b45f810$51d1e830$@gmail.com>

Yes, Bert. At first glance I thought it was one of the merge/joins and then wondered at the wording that made it sound like the ids may not be one per column.

IFF the need is the simpler case, it is a straightforward enough and common need. An example might make it clear enough so actual code can be shared as compared to talking about a first and second tibble.

Here is one reference to consider:

https://r4ds.hadley.nz/joins.html#:~:text=dplyr%20provides%20six%20join%20functions,is%20primarily%20determined%20by%20x%20.


A left_join may be what works, and of course more basic R includes the merge() function:

https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/merge

If the column were to contain multiple ID, that changes things and a more complex approach could be needed.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
Sent: Saturday, November 4, 2023 10:35 AM
To: Alessandro Puglisi <alessandro.puglisi at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Adding columns to a tibble based on a value in a different tibble

I think a simple reproducible example ("reprex") may be necessary for you
to get a useful reply. Questions with vague specifications such as yours
often result in going round and round with attempts to clarify what you
mean without a satisfactory answer. Clarification at the outset with a
reprex may save you and others a lot of frustration.

Cheers,
Bert

On Sat, Nov 4, 2023 at 1:41?AM Alessandro Puglisi <
alessandro.puglisi at gmail.com> wrote:

> Hi everyone,
>
> I have a tibble with various ids and associated information.
>
> I need to add a new column to this tibble that retrieves a specific 'y'
> value from a different tibble that has some of the mentioned ids in the
> first column and a 'y' value in the second one. If the id, and so the 'y'
> value is found, it will be included; otherwise, 'NA' will be used.
>
> Could you please help me?
>
> Thanks,
> Alessandro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Nov  4 17:56:20 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 4 Nov 2023 16:56:20 +0000
Subject: [R] Sum data according to date in sequence
In-Reply-To: <CANTvJZLZDkdT68sU0a-E35v_vAUtDvWWUcMV0x840XSM1KQDvA@mail.gmail.com>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
 <CAAxdm-74kKpsFMG1qUJmNxV8hA2LyDyjCjyVwiKz3KqvuUQgNQ@mail.gmail.com>
 <CANTvJZLZDkdT68sU0a-E35v_vAUtDvWWUcMV0x840XSM1KQDvA@mail.gmail.com>
Message-ID: <a9c4f560-d376-4f65-bdeb-33e7e2e80484@sapo.pt>

?s 01:49 de 03/11/2023, roslinazairimah zakaria escreveu:
> Hi all,
> 
> This is the data:
> 
>> dput(head(dt1,20))structure(list(StationName = c("PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1"), date = c("1/14/2016", "1/14/2016",
> "1/14/2016", "1/15/2016", "1/15/2016", "1/15/2016", "1/15/2016",
> "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016",
> "1/16/2016", "1/16/2016", "1/17/2016", "1/17/2016", "1/17/2016",
> "1/17/2016", "1/17/2016", "1/18/2016"), time = c("12:09", "19:50",
> "20:22", "8:25", "14:23", "18:17", "21:46", "10:19", "12:12",
> "14:12", "16:22", "19:16", "19:19", "20:24", "9:54", "12:16",
> "13:53", "19:03", "22:00", "8:58"), EnergykWh = c(4.680496, 6.272414,
> 1.032782, 11.004884, 10.096824, 6.658797, 4.808874, 1.469384,
> 2.996239, 0.303222, 4.988339, 8.131804, 0.117156, 3.285669, 1.175608,
> 3.677487, 1.068393, 8.820755, 8.138583, 9.0575)), row.names = c(NA,
> 20L), class = "data.frame")
> 
> 
> I would like to sum EnergykW data by the date. E.g. all values for
> EnergykWh on 1/14/2016
> 
> 
> On Fri, Nov 3, 2023 at 8:10?AM jim holtman <jholtman at gmail.com> wrote:
> 
>> How about send a 'dput' of some sample data.  My guess is that your date
>> is 'character' and not 'Date'.
>>
>> Thanks
>>
>> Jim Holtman
>> *Data Munger Guru*
>>
>>
>> *What is the problem that you are trying to solve?Tell me what you want to
>> do, not how you want to do it.*
>>
>>
>> On Thu, Nov 2, 2023 at 4:24?PM roslinazairimah zakaria <
>> roslinaump at gmail.com> wrote:
>>
>>> Dear all,
>>>
>>> I have this set of data. I would like to sum the EnergykWh according date
>>> sequences.
>>>
>>>> head(dt1,20)                   StationName      date  time EnergykWh
>>> 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
>>> 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
>>> 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
>>> 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
>>> 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
>>> 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
>>> 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
>>> 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
>>> 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
>>> 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
>>> 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
>>> 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
>>> 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
>>> 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
>>> 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
>>> 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
>>> 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
>>> 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
>>> 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
>>> 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
>>>
>>> I have tried this:
>>> library(dplyr)
>>> sums <- dt1 %>%
>>>    group_by(date) %>%
>>>    summarise(EnergykWh = sum(EnergykWh))
>>>
>>> head(sums,20)
>>>
>>> The date is not by daily sequence but by year sequence.
>>>
>>>> head(sums,20)# A tibble: 20 ? 2
>>>     date      EnergykWh
>>>     <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3
>>> 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6
>>> 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9
>>> 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12
>>> 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15
>>> 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18
>>> 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
>>>
>>>
>>>
>>> Thank you very much for any help given.
>>>
>>>
>>> --
>>> *Roslinazairimah Zakaria*
>>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>>
>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>> Faculty of Industrial Sciences & Technology
>>> University Malaysia Pahang
>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 
Hello,

Here are two solutions.

1. Base R

Though I don't coerce the date column to class "Date", it seems to work.


aggregate(EnergykWh ~ date, dt1, sum)
#>        date EnergykWh
#> 1 1/14/2016  11.98569
#> 2 1/15/2016  32.56938
#> 3 1/16/2016  21.29181
#> 4 1/17/2016  22.88083
#> 5 1/18/2016   9.05750


2. Package dplyr.
First column date is coerced from class "character" to class "Date".
Then the grouped sums are computed.


suppressPackageStartupMessages(
   library(dplyr)
)

dt1 %>%
   mutate(date = as.Date(date, "%m/%d/%Y")) %>%
   summarise(EnergykWh = sum(EnergykWh), .by = date)
#>         date EnergykWh
#> 1 2016-01-14  11.98569
#> 2 2016-01-15  32.56938
#> 3 2016-01-16  21.29181
#> 4 2016-01-17  22.88083
#> 5 2016-01-18   9.05750


As you can see, the results are the same.

Also, this exact problem is one of the most asked on StackOverflow. 
Maybe you could try searching there for a solution. My code above is 
also exactly the code in [1], though I had already this answer written. 
I only checked after :(.


[1] 
https://stackoverflow.com/questions/61548758/r-how-sum-values-by-group-by-date


Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From mkz@m@n@m @end|ng |rom gm@||@com  Sat Nov  4 10:54:49 2023
From: mkz@m@n@m @end|ng |rom gm@||@com (Md. Kamruzzaman)
Date: Sat, 4 Nov 2023 20:24:49 +1030
Subject: [R] 
 I need to create new variables based on two numeric variables
 and one dichotomize conditional category variables.
In-Reply-To: <CAGxFJbS41wwYMDxRDE6s=WNEVchyAQv4uppMge2dFRdMnraCWQ@mail.gmail.com>
References: <CAGbxoeGjsxZKQ6qijEMq-X-5doqnQQS1jjPDDrGT6hH5xWqOKQ@mail.gmail.com>
 <CAGxFJbS41wwYMDxRDE6s=WNEVchyAQv4uppMge2dFRdMnraCWQ@mail.gmail.com>
Message-ID: <CAGbxoeEin+pM0Z1_9v0cBV38PeV31POpHejTW-0NycYSHu0J0g@mail.gmail.com>

Thanks Everyone,
My variables are in a dataframe with multiple other variables.

Thanks

-------------------------

*Md Kamruzzaman*


On Sat, Nov 4, 2023 at 1:13?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Well, something like:
>
> LAP <- ifelse(gender =='male', (WC-65)*TG, (WC-58)*TG)
>
> The exact code depends on whether your variables are in a data frame or
> list or whatever, which you failed to specify. If so, ?with  may be useful.
>
> Cheers,
> Bert
>
>
>
> On Fri, Nov 3, 2023 at 3:43?AM Md. Kamruzzaman <mkzaman.m at gmail.com>
> wrote:
>
>> Hello Everyone,
>> I have three variables: Waist circumference (WC), serum triglyceride (TG)
>> level and gender. Waist circumference and serum triglyceride is numeric
>> and
>> gender (male and female) is categorical. From these three variables, I
>> want
>> to calculate the "Lipid Accumulation Product (LAP) Index". The equation to
>> calculate LAP is different for male and females. I am giving both
>> equations
>> below.
>>
>> LAP for male = (WC-65)*TG
>> LAP for female = (WC-58)*TG
>>
>> My question is 'how can I calculate the LAP and create a single new
>> column?
>>
>> Your cooperation will be highly appreciated.
>>
>> Thanks in advance.
>>
>> With Regards
>>
>> *--------------------------------*
>>
>> *Md Kamruzzaman*
>>
>> *PhD **Research Fellow (**Medicine**)*
>> Discipline of Medicine and Centre of Research Excellence in Translating
>> Nutritional Science to Good Health
>> Adelaide Medical School | Faculty of Health and Medical Sciences
>> The University of Adelaide
>> Adelaide SA 5005
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Sat Nov  4 18:47:53 2023
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 4 Nov 2023 13:47:53 -0400
Subject: [R] Sum data according to date in sequence
In-Reply-To: <a9c4f560-d376-4f65-bdeb-33e7e2e80484@sapo.pt>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
 <CAAxdm-74kKpsFMG1qUJmNxV8hA2LyDyjCjyVwiKz3KqvuUQgNQ@mail.gmail.com>
 <CANTvJZLZDkdT68sU0a-E35v_vAUtDvWWUcMV0x840XSM1KQDvA@mail.gmail.com>
 <a9c4f560-d376-4f65-bdeb-33e7e2e80484@sapo.pt>
Message-ID: <008501da0f47$09624220$1c26c660$@gmail.com>

There may be a point to consider about the field containing dates in the request below. Yes, much code will "work" just fine if the column  are is seen as text as you can group by that too. The results will perhaps not be in the order by row that you expected but you can do your re-sorting perhaps even more efficiently after your summarise() either by converting the fewer remaining rows to a form of date or by transforming the text dates into an order of year/month/date that then sorts properly in forward or reverse order as needed. 

Converting lots of rows to date is not a cheap process and grouping by that more complex date data structure may be harder. Heck, it may even make sense to use the text form of dates organized as a factor as the grouping becomes sort of pre-done.

The above comments are not saying any other solutions offered are wrong but simply discussing whether, especially for larger data sets, there are ways that could be more efficient.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
Sent: Saturday, November 4, 2023 12:56 PM
To: roslinazairimah zakaria <roslinaump at gmail.com>; jim holtman <jholtman at gmail.com>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Sum data according to date in sequence

?s 01:49 de 03/11/2023, roslinazairimah zakaria escreveu:
> Hi all,
> 
> This is the data:
> 
>> dput(head(dt1,20))structure(list(StationName = c("PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> "PALO ALTO CA / CAMBRIDGE #1"), date = c("1/14/2016", "1/14/2016",
> "1/14/2016", "1/15/2016", "1/15/2016", "1/15/2016", "1/15/2016",
> "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016",
> "1/16/2016", "1/16/2016", "1/17/2016", "1/17/2016", "1/17/2016",
> "1/17/2016", "1/17/2016", "1/18/2016"), time = c("12:09", "19:50",
> "20:22", "8:25", "14:23", "18:17", "21:46", "10:19", "12:12",
> "14:12", "16:22", "19:16", "19:19", "20:24", "9:54", "12:16",
> "13:53", "19:03", "22:00", "8:58"), EnergykWh = c(4.680496, 6.272414,
> 1.032782, 11.004884, 10.096824, 6.658797, 4.808874, 1.469384,
> 2.996239, 0.303222, 4.988339, 8.131804, 0.117156, 3.285669, 1.175608,
> 3.677487, 1.068393, 8.820755, 8.138583, 9.0575)), row.names = c(NA,
> 20L), class = "data.frame")
> 
> 
> I would like to sum EnergykW data by the date. E.g. all values for
> EnergykWh on 1/14/2016
> 
> 
> On Fri, Nov 3, 2023 at 8:10?AM jim holtman <jholtman at gmail.com> wrote:
> 
>> How about send a 'dput' of some sample data.  My guess is that your date
>> is 'character' and not 'Date'.
>>
>> Thanks
>>
>> Jim Holtman
>> *Data Munger Guru*
>>
>>
>> *What is the problem that you are trying to solve?Tell me what you want to
>> do, not how you want to do it.*
>>
>>
>> On Thu, Nov 2, 2023 at 4:24?PM roslinazairimah zakaria <
>> roslinaump at gmail.com> wrote:
>>
>>> Dear all,
>>>
>>> I have this set of data. I would like to sum the EnergykWh according date
>>> sequences.
>>>
>>>> head(dt1,20)                   StationName      date  time EnergykWh
>>> 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
>>> 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
>>> 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
>>> 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
>>> 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
>>> 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
>>> 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
>>> 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
>>> 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
>>> 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
>>> 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
>>> 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
>>> 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
>>> 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
>>> 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
>>> 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
>>> 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
>>> 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
>>> 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
>>> 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
>>>
>>> I have tried this:
>>> library(dplyr)
>>> sums <- dt1 %>%
>>>    group_by(date) %>%
>>>    summarise(EnergykWh = sum(EnergykWh))
>>>
>>> head(sums,20)
>>>
>>> The date is not by daily sequence but by year sequence.
>>>
>>>> head(sums,20)# A tibble: 20 ? 2
>>>     date      EnergykWh
>>>     <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3
>>> 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6
>>> 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9
>>> 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12
>>> 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15
>>> 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18
>>> 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
>>>
>>>
>>>
>>> Thank you very much for any help given.
>>>
>>>
>>> --
>>> *Roslinazairimah Zakaria*
>>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>>
>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>> Faculty of Industrial Sciences & Technology
>>> University Malaysia Pahang
>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 
Hello,

Here are two solutions.

1. Base R

Though I don't coerce the date column to class "Date", it seems to work.


aggregate(EnergykWh ~ date, dt1, sum)
#>        date EnergykWh
#> 1 1/14/2016  11.98569
#> 2 1/15/2016  32.56938
#> 3 1/16/2016  21.29181
#> 4 1/17/2016  22.88083
#> 5 1/18/2016   9.05750


2. Package dplyr.
First column date is coerced from class "character" to class "Date".
Then the grouped sums are computed.


suppressPackageStartupMessages(
   library(dplyr)
)

dt1 %>%
   mutate(date = as.Date(date, "%m/%d/%Y")) %>%
   summarise(EnergykWh = sum(EnergykWh), .by = date)
#>         date EnergykWh
#> 1 2016-01-14  11.98569
#> 2 2016-01-15  32.56938
#> 3 2016-01-16  21.29181
#> 4 2016-01-17  22.88083
#> 5 2016-01-18   9.05750


As you can see, the results are the same.

Also, this exact problem is one of the most asked on StackOverflow. 
Maybe you could try searching there for a solution. My code above is 
also exactly the code in [1], though I had already this answer written. 
I only checked after :(.


[1] 
https://stackoverflow.com/questions/61548758/r-how-sum-values-by-group-by-date


Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ro@||n@ump @end|ng |rom gm@||@com  Sun Nov  5 00:05:40 2023
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Sun, 5 Nov 2023 07:05:40 +0800
Subject: [R] Sum data according to date in sequence
In-Reply-To: <a9c4f560-d376-4f65-bdeb-33e7e2e80484@sapo.pt>
References: <CANTvJZL-jS=mWPWSJXqWVvxZfEVcvHPNhqQu4O9eEQj7ru8qRw@mail.gmail.com>
 <CAAxdm-74kKpsFMG1qUJmNxV8hA2LyDyjCjyVwiKz3KqvuUQgNQ@mail.gmail.com>
 <CANTvJZLZDkdT68sU0a-E35v_vAUtDvWWUcMV0x840XSM1KQDvA@mail.gmail.com>
 <a9c4f560-d376-4f65-bdeb-33e7e2e80484@sapo.pt>
Message-ID: <CANTvJZJFRKNwJbyT0q_F8uBt1+AmS68s8wnrJsKz93isXnARYA@mail.gmail.com>

Hi all,
Thank you very much.
I learn a lot from your suggested solution.



On Sun, Nov 5, 2023 at 12:56?AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> ?s 01:49 de 03/11/2023, roslinazairimah zakaria escreveu:
> > Hi all,
> >
> > This is the data:
> >
> >> dput(head(dt1,20))structure(list(StationName = c("PALO ALTO CA /
> CAMBRIDGE #1",
> > "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> > "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> > "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> > "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> > "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> > "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> > "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> > "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> > "PALO ALTO CA / CAMBRIDGE #1", "PALO ALTO CA / CAMBRIDGE #1",
> > "PALO ALTO CA / CAMBRIDGE #1"), date = c("1/14/2016", "1/14/2016",
> > "1/14/2016", "1/15/2016", "1/15/2016", "1/15/2016", "1/15/2016",
> > "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016", "1/16/2016",
> > "1/16/2016", "1/16/2016", "1/17/2016", "1/17/2016", "1/17/2016",
> > "1/17/2016", "1/17/2016", "1/18/2016"), time = c("12:09", "19:50",
> > "20:22", "8:25", "14:23", "18:17", "21:46", "10:19", "12:12",
> > "14:12", "16:22", "19:16", "19:19", "20:24", "9:54", "12:16",
> > "13:53", "19:03", "22:00", "8:58"), EnergykWh = c(4.680496, 6.272414,
> > 1.032782, 11.004884, 10.096824, 6.658797, 4.808874, 1.469384,
> > 2.996239, 0.303222, 4.988339, 8.131804, 0.117156, 3.285669, 1.175608,
> > 3.677487, 1.068393, 8.820755, 8.138583, 9.0575)), row.names = c(NA,
> > 20L), class = "data.frame")
> >
> >
> > I would like to sum EnergykW data by the date. E.g. all values for
> > EnergykWh on 1/14/2016
> >
> >
> > On Fri, Nov 3, 2023 at 8:10?AM jim holtman <jholtman at gmail.com> wrote:
> >
> >> How about send a 'dput' of some sample data.  My guess is that your date
> >> is 'character' and not 'Date'.
> >>
> >> Thanks
> >>
> >> Jim Holtman
> >> *Data Munger Guru*
> >>
> >>
> >> *What is the problem that you are trying to solve?Tell me what you want
> to
> >> do, not how you want to do it.*
> >>
> >>
> >> On Thu, Nov 2, 2023 at 4:24?PM roslinazairimah zakaria <
> >> roslinaump at gmail.com> wrote:
> >>
> >>> Dear all,
> >>>
> >>> I have this set of data. I would like to sum the EnergykWh according
> date
> >>> sequences.
> >>>
> >>>> head(dt1,20)                   StationName      date  time EnergykWh
> >>> 1  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 12:09  4.680496
> >>> 2  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 19:50  6.272414
> >>> 3  PALO ALTO CA / CAMBRIDGE #1 1/14/2016 20:22  1.032782
> >>> 4  PALO ALTO CA / CAMBRIDGE #1 1/15/2016  8:25 11.004884
> >>> 5  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 14:23 10.096824
> >>> 6  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 18:17  6.658797
> >>> 7  PALO ALTO CA / CAMBRIDGE #1 1/15/2016 21:46  4.808874
> >>> 8  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 10:19  1.469384
> >>> 9  PALO ALTO CA / CAMBRIDGE #1 1/16/2016 12:12  2.996239
> >>> 10 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 14:12  0.303222
> >>> 11 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 16:22  4.988339
> >>> 12 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:16  8.131804
> >>> 13 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 19:19  0.117156
> >>> 14 PALO ALTO CA / CAMBRIDGE #1 1/16/2016 20:24  3.285669
> >>> 15 PALO ALTO CA / CAMBRIDGE #1 1/17/2016  9:54  1.175608
> >>> 16 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 12:16  3.677487
> >>> 17 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 13:53  1.068393
> >>> 18 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 19:03  8.820755
> >>> 19 PALO ALTO CA / CAMBRIDGE #1 1/17/2016 22:00  8.138583
> >>> 20 PALO ALTO CA / CAMBRIDGE #1 1/18/2016  8:58  9.057500
> >>>
> >>> I have tried this:
> >>> library(dplyr)
> >>> sums <- dt1 %>%
> >>>    group_by(date) %>%
> >>>    summarise(EnergykWh = sum(EnergykWh))
> >>>
> >>> head(sums,20)
> >>>
> >>> The date is not by daily sequence but by year sequence.
> >>>
> >>>> head(sums,20)# A tibble: 20 ? 2
> >>>     date      EnergykWh
> >>>     <chr>         <dbl> 1 1/1/2017     25.3   2 1/1/2018     61.0   3
> >>> 1/1/2019      0.627 4 1/1/2020     10.7   5 1/10/2017    69.4   6
> >>> 1/10/2018    54.5   7 1/10/2019    49.1   8 1/10/2020    45.9   9
> >>> 1/11/2017    73.9  10 1/11/2018    53.3  11 1/11/2019    93.5  12
> >>> 1/11/2020    66.7  13 1/12/2017    78.6  14 1/12/2018    42.2  15
> >>> 1/12/2019    22.7  16 1/12/2020    80.9  17 1/13/2017    85.6  18
> >>> 1/13/2018    46.4  19 1/13/2019    40.0  20 1/13/2020   121.
> >>>
> >>>
> >>>
> >>> Thank you very much for any help given.
> >>>
> >>>
> >>> --
> >>> *Roslinazairimah Zakaria*
> >>> *Tel: +609-5492370; Fax. No.+609-5492766*
> >>>
> >>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> >>> roslinaump at gmail.com <roslinaump at gmail.com>*
> >>> Faculty of Industrial Sciences & Technology
> >>> University Malaysia Pahang
> >>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >
> Hello,
>
> Here are two solutions.
>
> 1. Base R
>
> Though I don't coerce the date column to class "Date", it seems to work.
>
>
> aggregate(EnergykWh ~ date, dt1, sum)
> #>        date EnergykWh
> #> 1 1/14/2016  11.98569
> #> 2 1/15/2016  32.56938
> #> 3 1/16/2016  21.29181
> #> 4 1/17/2016  22.88083
> #> 5 1/18/2016   9.05750
>
>
> 2. Package dplyr.
> First column date is coerced from class "character" to class "Date".
> Then the grouped sums are computed.
>
>
> suppressPackageStartupMessages(
>    library(dplyr)
> )
>
> dt1 %>%
>    mutate(date = as.Date(date, "%m/%d/%Y")) %>%
>    summarise(EnergykWh = sum(EnergykWh), .by = date)
> #>         date EnergykWh
> #> 1 2016-01-14  11.98569
> #> 2 2016-01-15  32.56938
> #> 3 2016-01-16  21.29181
> #> 4 2016-01-17  22.88083
> #> 5 2016-01-18   9.05750
>
>
> As you can see, the results are the same.
>
> Also, this exact problem is one of the most asked on StackOverflow.
> Maybe you could try searching there for a solution. My code above is
> also exactly the code in [1], though I had already this answer written.
> I only checked after :(.
>
>
> [1]
>
> https://stackoverflow.com/questions/61548758/r-how-sum-values-by-group-by-date
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From po|c1410 @end|ng |rom gm@||@com  Sun Nov  5 00:14:05 2023
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Sat, 4 Nov 2023 23:14:05 +0000
Subject: [R] 
 I need to create new variables based on two numeric variables
 and one dichotomize conditional category variables.
In-Reply-To: <002d01da0e9a$5f1d2930$1d577b90$@gmail.com>
References: <mailman.370481.1.1699009201.56788.r-help@r-project.org>
 <LV3PR01MB86736581F1E69742E545FD59DCA5A@LV3PR01MB8673.prod.exchangelabs.com>
 <002d01da0e9a$5f1d2930$1d577b90$@gmail.com>
Message-ID: <CA+etgPmfSeWLs2t4Grjz98ypc4XeiSOGUPCBqeB=NR2JBxK0pg@mail.gmail.com>

I might have factored the gender.

I'm not sure it would in any way be quicker.  But might be to some extent
easier to develop variations of. And is sort of what factors should be
doing...

# make dummy data
gender <- c("Male", "Female", "Male", "Female")
WC <- c(70,60,75,65)
TG <- c(0.9, 1.1, 1.2, 1.0)
myDf <- data.frame( gender, WC, TG )

# label a factor
myDf$GF <- factor(myDf$gender, labels= c("Male"=65, "Female"=58))

# do the maths
myDf$LAP <- (myDf$WC - as.numeric(myDf$GF))* myDf$TG

#show results
head(myDf)

gender WC  TG GF  LAP
1   Male 70 0.9 58 61.2
2 Female 60 1.1 65 64.9
3   Male 75 1.2 58 87.6
4 Female 65 1.0 65 64.0


(Reality: I'd have probably used case_when in tidy to create a new numeric
column)





The equation to
> calculate LAP is different for male and females. I am giving both equations
> below.
>
> LAP for male = (WC-65)*TG
> LAP for female = (WC-58)*TG
>
> My question is 'how can I calculate the LAP and create a single new column?
>
>

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Nov  5 05:27:16 2023
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sun, 5 Nov 2023 00:27:16 -0400
Subject: [R] 
 I need to create new variables based on two numeric variables
 and one dichotomize conditional category variables.
In-Reply-To: <CA+etgPmfSeWLs2t4Grjz98ypc4XeiSOGUPCBqeB=NR2JBxK0pg@mail.gmail.com>
References: <mailman.370481.1.1699009201.56788.r-help@r-project.org>
 <LV3PR01MB86736581F1E69742E545FD59DCA5A@LV3PR01MB8673.prod.exchangelabs.com>
 <002d01da0e9a$5f1d2930$1d577b90$@gmail.com>
 <CA+etgPmfSeWLs2t4Grjz98ypc4XeiSOGUPCBqeB=NR2JBxK0pg@mail.gmail.com>
Message-ID: <006301da0fa0$5cbe99b0$163bcd10$@gmail.com>

There are many techniques Callum and yours is an interesting twist I had not considered. 
 
Yes, you can specify what integer a factor uses to represent things but not what I meant. Of course your trick does not work for some other forms of data like real numbers in double format. There is a cost to converting a column to a factor that is recouped best if it speeds things up multiple times.
 
The point I was making was that when you will be using group_by, especially if done many times, it might speed things up if the column is already a normal factor, perhaps just indexed from 1 onward. My guess is that underneath the covers, some programs implicitly do such a factor conversion if needed. An example might be aspects of the ggplot program where you may get a mysterious order of presentation in the graph unless you create a factor with the order you wish to have used and avoid it making one invisibly.
 
From: CALUM POLWART <polc1410 at gmail.com> 
Sent: Saturday, November 4, 2023 7:14 PM
To: avi.e.gross at gmail.com
Cc: Jorgen Harmse <JHarmse at roku.com>; r-help at r-project.org; mkzaman.m at gmail.com
Subject: Re: [R] I need to create new variables based on two numeric variables and one dichotomize conditional category variables.
 
I might have factored the gender.
 
I'm not sure it would in any way be quicker.  But might be to some extent easier to develop variations of. And is sort of what factors should be doing... 
 
# make dummy data
gender <- c("Male", "Female", "Male", "Female")
WC <- c(70,60,75,65)
TG <- c(0.9, 1.1, 1.2, 1.0)
myDf <- data.frame( gender, WC, TG )
 
# label a factor
myDf$GF <- factor(myDf$gender, labels= c("Male"=65, "Female"=58))
 
# do the maths
myDf$LAP <- (myDf$WC - as.numeric(myDf$GF))* myDf$TG
 
#show results
head(myDf)
 
gender WC  TG GF  LAP
1   Male 70 0.9 58 61.2
2 Female 60 1.1 65 64.9
3   Male 75 1.2 58 87.6
4 Female 65 1.0 65 64.0
 
 
(Reality: I'd have probably used case_when in tidy to create a new numeric column)
 
 
 
 
The equation to
calculate LAP is different for male and females. I am giving both equations
below.

LAP for male = (WC-65)*TG
LAP for female = (WC-58)*TG

My question is 'how can I calculate the LAP and create a single new column?

	[[alternative HTML version deleted]]


From po|c1410 @end|ng |rom gm@||@com  Sun Nov  5 09:27:17 2023
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Sun, 5 Nov 2023 08:27:17 +0000
Subject: [R] 
 I need to create new variables based on two numeric variables
 and one dichotomize conditional category variables.
In-Reply-To: <006301da0fa0$5cbe99b0$163bcd10$@gmail.com>
References: <mailman.370481.1.1699009201.56788.r-help@r-project.org>
 <LV3PR01MB86736581F1E69742E545FD59DCA5A@LV3PR01MB8673.prod.exchangelabs.com>
 <002d01da0e9a$5f1d2930$1d577b90$@gmail.com>
 <CA+etgPmfSeWLs2t4Grjz98ypc4XeiSOGUPCBqeB=NR2JBxK0pg@mail.gmail.com>
 <006301da0fa0$5cbe99b0$163bcd10$@gmail.com>
Message-ID: <CA+etgPkANBQ5ndDfWP3nEEWk_3wd3JB-eeqvJDLwHRWREY4imQ@mail.gmail.com>

In this case I think I've made the labels the number and so a double is
possible. But it wasn't what I actually set out to do!  (I'm a tidy fab so
would have to engage the brain in base too much)

When I thought 'I think I might say that's a factor (sometimes in medical
equations gender is shown as a "F" and described as a "factor". Not our
factors... But still a factor).

My programming is never efficient!

But I was planning for a scenario for where gender is not a binary concept,
adding unknowns, trans etc. and if the data set is very large then
obviously storing as factors is less memory intensive, but processing may
be more intensive.








On Sun, 5 Nov 2023, 04:27 , <avi.e.gross at gmail.com> wrote:

> There are many techniques Callum and yours is an interesting twist I had
> not considered.
>
> Yes, you can specify what integer a factor uses to represent things but
> not what I meant. Of course your trick does not work for some other forms
> of data like real numbers in double format. There is a cost to converting a
> column to a factor that is recouped best if it speeds things up multiple
> times.
>
> The point I was making was that when you will be using group_by,
> especially if done many times, it might speed things up if the column is
> already a normal factor, perhaps just indexed from 1 onward. My guess is
> that underneath the covers, some programs implicitly do such a factor
> conversion if needed. An example might be aspects of the ggplot program
> where you may get a mysterious order of presentation in the graph unless
> you create a factor with the order you wish to have used and avoid it
> making one invisibly.
>
> From: CALUM POLWART <polc1410 at gmail.com>
> Sent: Saturday, November 4, 2023 7:14 PM
> To: avi.e.gross at gmail.com
> Cc: Jorgen Harmse <JHarmse at roku.com>; r-help at r-project.org;
> mkzaman.m at gmail.com
> Subject: Re: [R] I need to create new variables based on two numeric
> variables and one dichotomize conditional category variables.
>
> I might have factored the gender.
>
> I'm not sure it would in any way be quicker.  But might be to some extent
> easier to develop variations of. And is sort of what factors should be
> doing...
>
> # make dummy data
> gender <- c("Male", "Female", "Male", "Female")
> WC <- c(70,60,75,65)
> TG <- c(0.9, 1.1, 1.2, 1.0)
> myDf <- data.frame( gender, WC, TG )
>
> # label a factor
> myDf$GF <- factor(myDf$gender, labels= c("Male"=65, "Female"=58))
>
> # do the maths
> myDf$LAP <- (myDf$WC - as.numeric(myDf$GF))* myDf$TG
>
> #show results
> head(myDf)
>
> gender WC  TG GF  LAP
> 1   Male 70 0.9 58 61.2
> 2 Female 60 1.1 65 64.9
> 3   Male 75 1.2 58 87.6
> 4 Female 65 1.0 65 64.0
>
>
> (Reality: I'd have probably used case_when in tidy to create a new numeric
> column)
>
>
>
>
> The equation to
> calculate LAP is different for male and females. I am giving both equations
> below.
>
> LAP for male = (WC-65)*TG
> LAP for female = (WC-58)*TG
>
> My question is 'how can I calculate the LAP and create a single new column?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Nov  6 00:45:01 2023
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 6 Nov 2023 12:45:01 +1300
Subject: [R] strptime with +03:00 zone designator
Message-ID: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>

I have some data that includes timestamps like this:
2017-02-28T13:35:00+03:00
The documentation for strptime says that %z expects
an offset like 0300.  I don't see any way in the documentation
to get it to accept +hh:mm with a colon separator, and
everything I tried gave me NA as the answer.

Section 4.2.5.1 of ISO 8601:2004(E) allows both the
absence of colons in +hh[mm] (basic format) and the
presence of colons in +hh:mm (extended format).
Again in section 4.2.5.2 where a zone offset is combined
with a time of day: if you have hh:mm:ss you are using
extended format and the offset MUST have a colon; if
you have hhmmss you are using basic format and the
offset MUST NOT have a colon.  And again in section
4.3.2 (complete representations of date and time of day).
If you use hyphens and colons in the date and time part
you MUST have a colon in the zone designator.

So I am dealing with timestamps in strict ISO 8601
complete extended representation, and it is rather
frustrating that strptime doesn't deal with it simply.

The simplest thing would be for R's own version of
strptime to allow an optional colon between the hour
digits and the minute digits of a zone designator.

I'm about to clone the data source and edit it to
remove the colons, but is there something obvious
I am missing?


From roy@mende|@@ohn @end|ng |rom no@@@gov  Mon Nov  6 00:56:47 2023
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Sun, 5 Nov 2023 15:56:47 -0800
Subject: [R] strptime with +03:00 zone designator
In-Reply-To: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
References: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
Message-ID: <23A4C381-E483-4F6A-AAB6-86330E047CF1@noaa.gov>

what if you try lubridate::as_datetime('2017-02-28T13:35:00+03:00?)

-Roy


> On Nov 5, 2023, at 3:45 PM, Richard O'Keefe <raoknz at gmail.com> wrote:
> 
> I have some data that includes timestamps like this:
> 2017-02-28T13:35:00+03:00
> The documentation for strptime says that %z expects
> an offset like 0300.  I don't see any way in the documentation
> to get it to accept +hh:mm with a colon separator, and
> everything I tried gave me NA as the answer.
> 
> Section 4.2.5.1 of ISO 8601:2004(E) allows both the
> absence of colons in +hh[mm] (basic format) and the
> presence of colons in +hh:mm (extended format).
> Again in section 4.2.5.2 where a zone offset is combined
> with a time of day: if you have hh:mm:ss you are using
> extended format and the offset MUST have a colon; if
> you have hhmmss you are using basic format and the
> offset MUST NOT have a colon.  And again in section
> 4.3.2 (complete representations of date and time of day).
> If you use hyphens and colons in the date and time part
> you MUST have a colon in the zone designator.
> 
> So I am dealing with timestamps in strict ISO 8601
> complete extended representation, and it is rather
> frustrating that strptime doesn't deal with it simply.
> 
> The simplest thing would be for R's own version of
> strptime to allow an optional colon between the hour
> digits and the minute digits of a zone designator.
> 
> I'm about to clone the data source and edit it to
> remove the colons, but is there something obvious
> I am missing?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Nov  6 01:07:38 2023
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 05 Nov 2023 16:07:38 -0800
Subject: [R] strptime with +03:00 zone designator
In-Reply-To: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
References: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
Message-ID: <AB45F9E7-4802-473B-ACC9-F732A67A6B58@dcn.davis.ca.us>

I usually just use a regex to strip the colon.

On November 5, 2023 3:45:01 PM PST, Richard O'Keefe <raoknz at gmail.com> wrote:
>I have some data that includes timestamps like this:
>2017-02-28T13:35:00+03:00
>The documentation for strptime says that %z expects
>an offset like 0300.  I don't see any way in the documentation
>to get it to accept +hh:mm with a colon separator, and
>everything I tried gave me NA as the answer.
>
>Section 4.2.5.1 of ISO 8601:2004(E) allows both the
>absence of colons in +hh[mm] (basic format) and the
>presence of colons in +hh:mm (extended format).
>Again in section 4.2.5.2 where a zone offset is combined
>with a time of day: if you have hh:mm:ss you are using
>extended format and the offset MUST have a colon; if
>you have hhmmss you are using basic format and the
>offset MUST NOT have a colon.  And again in section
>4.3.2 (complete representations of date and time of day).
>If you use hyphens and colons in the date and time part
>you MUST have a colon in the zone designator.
>
>So I am dealing with timestamps in strict ISO 8601
>complete extended representation, and it is rather
>frustrating that strptime doesn't deal with it simply.
>
>The simplest thing would be for R's own version of
>strptime to allow an optional colon between the hour
>digits and the minute digits of a zone designator.
>
>I'm about to clone the data source and edit it to
>remove the colons, but is there something obvious
>I am missing?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jho|tm@n @end|ng |rom gm@||@com  Mon Nov  6 01:18:00 2023
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Sun, 5 Nov 2023 16:18:00 -0800
Subject: [R] strptime with +03:00 zone designator
In-Reply-To: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
References: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
Message-ID: <CAAxdm-666SwXzBgKJEn-HWphspbWDb2ycyVzdAbvD+oX16xRVA@mail.gmail.com>

try using 'lubridate'

> library(lubridate)Attaching package: ?lubridate?

The following objects are masked from ?package:base?:

    date, intersect, setdiff, union
> x <- "2017-02-28T13:35:00+03:00"> ymd_hms(x)[1] "2017-02-28 10:35:00 UTC"

>



Thanks

Jim Holtman
*Data Munger Guru*


*What is the problem that you are trying to solve?Tell me what you want to
do, not how you want to do it.*


On Sun, Nov 5, 2023 at 3:45?PM Richard O'Keefe <raoknz at gmail.com> wrote:

> I have some data that includes timestamps like this:
> 2017-02-28T13:35:00+03:00
> The documentation for strptime says that %z expects
> an offset like 0300.  I don't see any way in the documentation
> to get it to accept +hh:mm with a colon separator, and
> everything I tried gave me NA as the answer.
>
> Section 4.2.5.1 of ISO 8601:2004(E) allows both the
> absence of colons in +hh[mm] (basic format) and the
> presence of colons in +hh:mm (extended format).
> Again in section 4.2.5.2 where a zone offset is combined
> with a time of day: if you have hh:mm:ss you are using
> extended format and the offset MUST have a colon; if
> you have hhmmss you are using basic format and the
> offset MUST NOT have a colon.  And again in section
> 4.3.2 (complete representations of date and time of day).
> If you use hyphens and colons in the date and time part
> you MUST have a colon in the zone designator.
>
> So I am dealing with timestamps in strict ISO 8601
> complete extended representation, and it is rather
> frustrating that strptime doesn't deal with it simply.
>
> The simplest thing would be for R's own version of
> strptime to allow an optional colon between the hour
> digits and the minute digits of a zone designator.
>
> I'm about to clone the data source and edit it to
> remove the colons, but is there something obvious
> I am missing?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Nov  6 06:37:12 2023
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 6 Nov 2023 18:37:12 +1300
Subject: [R] strptime with +03:00 zone designator
In-Reply-To: <CAAxdm-666SwXzBgKJEn-HWphspbWDb2ycyVzdAbvD+oX16xRVA@mail.gmail.com>
References: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
 <CAAxdm-666SwXzBgKJEn-HWphspbWDb2ycyVzdAbvD+oX16xRVA@mail.gmail.com>
Message-ID: <CABcYAdJpMibwW7Qjm_0A2D+1H=ddvow6S12RaKRUx-frR210tg@mail.gmail.com>

OK, so the consensus is
(1) One cannot make strptime accept ISO8601-compliant zone designators
(2) The lubridate package can
(3) Or one can hack away with regex.
Lubridate it is, then.

But I do regard strptime's inability to process ISO8601-compliant zone
designators as a bug.


On Mon, 6 Nov 2023 at 13:18, jim holtman <jholtman at gmail.com> wrote:

> try using 'lubridate'
>
> > library(lubridate)Attaching package: ?lubridate?
>
> The following objects are masked from ?package:base?:
>
>     date, intersect, setdiff, union
> > x <- "2017-02-28T13:35:00+03:00"> ymd_hms(x)[1] "2017-02-28 10:35:00 UTC"
>
> >
>
>
>
> Thanks
>
> Jim Holtman
> *Data Munger Guru*
>
>
> *What is the problem that you are trying to solve?Tell me what you want to
> do, not how you want to do it.*
>
>
> On Sun, Nov 5, 2023 at 3:45?PM Richard O'Keefe <raoknz at gmail.com> wrote:
>
>> I have some data that includes timestamps like this:
>> 2017-02-28T13:35:00+03:00
>> The documentation for strptime says that %z expects
>> an offset like 0300.  I don't see any way in the documentation
>> to get it to accept +hh:mm with a colon separator, and
>> everything I tried gave me NA as the answer.
>>
>> Section 4.2.5.1 of ISO 8601:2004(E) allows both the
>> absence of colons in +hh[mm] (basic format) and the
>> presence of colons in +hh:mm (extended format).
>> Again in section 4.2.5.2 where a zone offset is combined
>> with a time of day: if you have hh:mm:ss you are using
>> extended format and the offset MUST have a colon; if
>> you have hhmmss you are using basic format and the
>> offset MUST NOT have a colon.  And again in section
>> 4.3.2 (complete representations of date and time of day).
>> If you use hyphens and colons in the date and time part
>> you MUST have a colon in the zone designator.
>>
>> So I am dealing with timestamps in strict ISO 8601
>> complete extended representation, and it is rather
>> frustrating that strptime doesn't deal with it simply.
>>
>> The simplest thing would be for R's own version of
>> strptime to allow an optional colon between the hour
>> digits and the minute digits of a zone designator.
>>
>> I'm about to clone the data source and edit it to
>> remove the colons, but is there something obvious
>> I am missing?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Nov  6 06:37:34 2023
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 6 Nov 2023 18:37:34 +1300
Subject: [R] strptime with +03:00 zone designator
In-Reply-To: <CABcYAdJpMibwW7Qjm_0A2D+1H=ddvow6S12RaKRUx-frR210tg@mail.gmail.com>
References: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
 <CAAxdm-666SwXzBgKJEn-HWphspbWDb2ycyVzdAbvD+oX16xRVA@mail.gmail.com>
 <CABcYAdJpMibwW7Qjm_0A2D+1H=ddvow6S12RaKRUx-frR210tg@mail.gmail.com>
Message-ID: <CABcYAd+y6v7YTOtE0QrDciNNSpGZb22MFqsWA=xB+e1-q-QcLg@mail.gmail.com>

Thanks to all who replied.

On Mon, 6 Nov 2023 at 18:37, Richard O'Keefe <raoknz at gmail.com> wrote:

> OK, so the consensus is
> (1) One cannot make strptime accept ISO8601-compliant zone designators
> (2) The lubridate package can
> (3) Or one can hack away with regex.
> Lubridate it is, then.
>
> But I do regard strptime's inability to process ISO8601-compliant zone
> designators as a bug.
>
>
> On Mon, 6 Nov 2023 at 13:18, jim holtman <jholtman at gmail.com> wrote:
>
>> try using 'lubridate'
>>
>> > library(lubridate)Attaching package: ?lubridate?
>>
>> The following objects are masked from ?package:base?:
>>
>>     date, intersect, setdiff, union
>> > x <- "2017-02-28T13:35:00+03:00"> ymd_hms(x)[1] "2017-02-28 10:35:00 UTC"
>>
>> >
>>
>>
>>
>> Thanks
>>
>> Jim Holtman
>> *Data Munger Guru*
>>
>>
>> *What is the problem that you are trying to solve?Tell me what you want
>> to do, not how you want to do it.*
>>
>>
>> On Sun, Nov 5, 2023 at 3:45?PM Richard O'Keefe <raoknz at gmail.com> wrote:
>>
>>> I have some data that includes timestamps like this:
>>> 2017-02-28T13:35:00+03:00
>>> The documentation for strptime says that %z expects
>>> an offset like 0300.  I don't see any way in the documentation
>>> to get it to accept +hh:mm with a colon separator, and
>>> everything I tried gave me NA as the answer.
>>>
>>> Section 4.2.5.1 of ISO 8601:2004(E) allows both the
>>> absence of colons in +hh[mm] (basic format) and the
>>> presence of colons in +hh:mm (extended format).
>>> Again in section 4.2.5.2 where a zone offset is combined
>>> with a time of day: if you have hh:mm:ss you are using
>>> extended format and the offset MUST have a colon; if
>>> you have hhmmss you are using basic format and the
>>> offset MUST NOT have a colon.  And again in section
>>> 4.3.2 (complete representations of date and time of day).
>>> If you use hyphens and colons in the date and time part
>>> you MUST have a colon in the zone designator.
>>>
>>> So I am dealing with timestamps in strict ISO 8601
>>> complete extended representation, and it is rather
>>> frustrating that strptime doesn't deal with it simply.
>>>
>>> The simplest thing would be for R's own version of
>>> strptime to allow an optional colon between the hour
>>> digits and the minute digits of a zone designator.
>>>
>>> I'm about to clone the data source and edit it to
>>> remove the colons, but is there something obvious
>>> I am missing?
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Nov  6 10:01:53 2023
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 6 Nov 2023 10:01:53 +0100
Subject: [R] strptime with +03:00 zone designator
In-Reply-To: <CABcYAd+y6v7YTOtE0QrDciNNSpGZb22MFqsWA=xB+e1-q-QcLg@mail.gmail.com>
References: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
 <CAAxdm-666SwXzBgKJEn-HWphspbWDb2ycyVzdAbvD+oX16xRVA@mail.gmail.com>
 <CABcYAdJpMibwW7Qjm_0A2D+1H=ddvow6S12RaKRUx-frR210tg@mail.gmail.com>
 <CABcYAd+y6v7YTOtE0QrDciNNSpGZb22MFqsWA=xB+e1-q-QcLg@mail.gmail.com>
Message-ID: <25928.43905.917277.897930@stat.math.ethz.ch>

>>>>> Richard O'Keefe 
>>>>>     on Mon, 6 Nov 2023 18:37:34 +1300 writes:

    > Thanks to all who replied.  On Mon, 6 Nov 2023 at 18:37,
    > Richard O'Keefe <raoknz at gmail.com> wrote:

    >> OK, so the consensus is (1) One cannot make strptime
    >> accept ISO8601-compliant zone designators (2) The
    >> lubridate package can (3) Or one can hack away with
    >> regex.  Lubridate it is, then.
    >> 
    >> But I do regard strptime's inability to process
    >> ISO8601-compliant zone designators as a bug.

Did you try to submit it to R's bugzilla?

It's the first time I hear of this "Feature" of the ISO
standard, but then I'm not at all a timezone, and even less an
ISO standard expert.

Best,
Martin


    >> On Mon, 6 Nov 2023 at 13:18, jim holtman
    >> <jholtman at gmail.com> wrote:
    >> 
    >>> try using 'lubridate'
    >>> 
    >>> > library(lubridate)Attaching package: ?lubridate?
    >>> 
    >>> The following objects are masked from ?package:base?:
    >>> 
    >>> date, intersect, setdiff, union > x <-
    >>> "2017-02-28T13:35:00+03:00"> ymd_hms(x)[1] "2017-02-28
    >>> 10:35:00 UTC"
    >>> 
    >>> >
    >>> 
    >>> 
    >>> 
    >>> Thanks
    >>> 
    >>> Jim Holtman *Data Munger Guru*
    >>> 
    >>> 
    >>> *What is the problem that you are trying to solve?Tell
    >>> me what you want to do, not how you want to do it.*
    >>> 
    >>> 
    >>> On Sun, Nov 5, 2023 at 3:45?PM Richard O'Keefe
    >>> <raoknz at gmail.com> wrote:
    >>> 
    >>>> I have some data that includes timestamps like this:
    >>>> 2017-02-28T13:35:00+03:00 The documentation for
    >>>> strptime says that %z expects an offset like 0300.  I
    >>>> don't see any way in the documentation to get it to
    >>>> accept +hh:mm with a colon separator, and everything I
    >>>> tried gave me NA as the answer.
    >>>> 
    >>>> Section 4.2.5.1 of ISO 8601:2004(E) allows both the
    >>>> absence of colons in +hh[mm] (basic format) and the
    >>>> presence of colons in +hh:mm (extended format).  Again
    >>>> in section 4.2.5.2 where a zone offset is combined with
    >>>> a time of day: if you have hh:mm:ss you are using
    >>>> extended format and the offset MUST have a colon; if
    >>>> you have hhmmss you are using basic format and the
    >>>> offset MUST NOT have a colon.  And again in section
    >>>> 4.3.2 (complete representations of date and time of
    >>>> day).  If you use hyphens and colons in the date and
    >>>> time part you MUST have a colon in the zone designator.
    >>>> 
    >>>> So I am dealing with timestamps in strict ISO 8601
    >>>> complete extended representation, and it is rather
    >>>> frustrating that strptime doesn't deal with it simply.
    >>>> 
    >>>> The simplest thing would be for R's own version of
    >>>> strptime to allow an optional colon between the hour
    >>>> digits and the minute digits of a zone designator.
    >>>> 
    >>>> I'm about to clone the data source and edit it to
    >>>> remove the colons, but is there something obvious I am
    >>>> missing?
    >>>> 
    >>>> ______________________________________________
    >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >>>> PLEASE do read the posting guide
    >>>> http://www.R-project.org/posting-guide.html and provide
    >>>> commented, minimal, self-contained, reproducible code.
    >>>> 
    >>> 

    > 	[[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From th||eu @end|ng |rom @tudent@ethz@ch  Sun Nov  5 14:35:39 2023
From: th||eu @end|ng |rom @tudent@ethz@ch (Leu  Thierry)
Date: Sun, 5 Nov 2023 13:35:39 +0000
Subject: [R] Cryptic error for mscmt function
Message-ID: <33ec052e26e042688f68e59e6f80fd99@student.ethz.ch>

Hi everyone,


I am trying to conduct a synthetic control analysis using the MSCMT package. However, when trying to run it I get a very cryptic error message saying  "Error in lst[[nam]][intersect(tim, rownames(lst[[nam]])), cols, drop = FALSE]: subscript out of bounds". Does anyone know what this means and why I receive this error? I attached the code & dataset used in the attachment. Thanks a lot!


Best regards

Thierry


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Nov  6 14:53:14 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 6 Nov 2023 13:53:14 +0000
Subject: [R] Cryptic error for mscmt function
In-Reply-To: <33ec052e26e042688f68e59e6f80fd99@student.ethz.ch>
References: <33ec052e26e042688f68e59e6f80fd99@student.ethz.ch>
Message-ID: <72a74b31-c95b-4a07-ac36-824bb4d738d6@sapo.pt>

?s 13:35 de 05/11/2023, Leu Thierry escreveu:
> Hi everyone,
> 
> 
> I am trying to conduct a synthetic control analysis using the MSCMT package. However, when trying to run it I get a very cryptic error message saying  "Error in lst[[nam]][intersect(tim, rownames(lst[[nam]])), cols, drop = FALSE]: subscript out of bounds". Does anyone know what this means and why I receive this error? I attached the code & dataset used in the attachment. Thanks a lot!
> 
> 
> Best regards
> 
> Thierry
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

No attachment came through the filters, can you resend in plain text or 
if it was a .R file, rename it .txt?

See [1], section General Instructions for more on this

[1] https://www.r-project.org/mail.html#instructions

Hope this helps,

Rui Barradas

-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Nov  6 15:08:36 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 6 Nov 2023 17:08:36 +0300
Subject: [R] Cryptic error for mscmt function
In-Reply-To: <33ec052e26e042688f68e59e6f80fd99@student.ethz.ch>
References: <33ec052e26e042688f68e59e6f80fd99@student.ethz.ch>
Message-ID: <20231106170836.18b083d0@Tarkus>

? Sun, 5 Nov 2023 13:35:39 +0000
"Leu  Thierry" <thileu at student.ethz.ch> ?????:

> However, when trying to run it I get a very cryptic error message
> saying  "Error in lst[[nam]][intersect(tim, rownames(lst[[nam]])),
> cols, drop = FALSE]: subscript out of bounds".

Without a way to reproduce the error, I can offer a few bits of generic
advice:

1. Use traceback() to find out where the error happens. You can then
type the name of the function at the R prompt to read its source code
(although most likely without the comments).

2. Even better, set options(error = recover) before running your code
and have the debugger launched at the point where the error happens.
Use the debugger (see help(browser) to look at every variable and find
out why indeed lst[[nam]] doesn't seem to contain rows with names
intersect(tim, rownames(lst[[nam]])) and/or columns with names `cols`.

3. See the free book The R Inferno
<https://www.burns-stat.com/documents/books/the-r-inferno/> for more
advice on debugging R code.

-- 
Best regards,
Ivan


From JH@rm@e @end|ng |rom roku@com  Mon Nov  6 17:22:32 2023
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Mon, 6 Nov 2023 16:22:32 +0000
Subject: [R] [EXTERNAL] Re: I need to create new variables based on two
 numeric variables and one dichotomize conditional category variables.
In-Reply-To: <CA+etgPmfSeWLs2t4Grjz98ypc4XeiSOGUPCBqeB=NR2JBxK0pg@mail.gmail.com>
References: <mailman.370481.1.1699009201.56788.r-help@r-project.org>
 <LV3PR01MB86736581F1E69742E545FD59DCA5A@LV3PR01MB8673.prod.exchangelabs.com>
 <002d01da0e9a$5f1d2930$1d577b90$@gmail.com>
 <CA+etgPmfSeWLs2t4Grjz98ypc4XeiSOGUPCBqeB=NR2JBxK0pg@mail.gmail.com>
Message-ID: <LV3PR01MB86730118F2D4F630A8E7FA97DCAAA@LV3PR01MB8673.prod.exchangelabs.com>

That?s ingenious, but I would hesitate to rely on a specific mapping between strings and integers. (I usually read data frames with stringsAsFactors=FALSE or coerce to character later: I don?t think it takes more memory.) Maybe create another column with the coefficients. What if gender is part of another formula?

Regards,
Jorgen Harmse.

From: CALUM POLWART <polc1410 at gmail.com>
Date: Saturday, November 4, 2023 at 18:23
To: avi.e.gross at gmail.com <avi.e.gross at gmail.com>
Cc: Jorgen Harmse <JHarmse at roku.com>, r-help at r-project.org <r-help at r-project.org>, mkzaman.m at gmail.com <mkzaman.m at gmail.com>
Subject: [EXTERNAL] Re: [R] I need to create new variables based on two numeric variables and one dichotomize conditional category variables.
I might have factored the gender.

I'm not sure it would in any way be quicker.  But might be to some extent easier to develop variations of. And is sort of what factors should be doing...

# make dummy data
gender <- c("Male", "Female", "Male", "Female")
WC <- c(70,60,75,65)
TG <- c(0.9, 1.1, 1.2, 1.0)
myDf <- data.frame( gender, WC, TG )

# label a factor
myDf$GF <- factor(myDf$gender, labels= c("Male"=65, "Female"=58))

# do the maths
myDf$LAP <- (myDf$WC - as.numeric(myDf$GF))* myDf$TG

#show results
head(myDf)

gender WC  TG GF  LAP
1   Male 70 0.9 58 61.2
2 Female 60 1.1 65 64.9
3   Male 75 1.2 58 87.6
4 Female 65 1.0 65 64.0


(Reality: I'd have probably used case_when in tidy to create a new numeric column)




The equation to
calculate LAP is different for male and females. I am giving both equations
below.

LAP for male = (WC-65)*TG
LAP for female = (WC-58)*TG

My question is 'how can I calculate the LAP and create a single new column?

	[[alternative HTML version deleted]]


From JH@rm@e @end|ng |rom roku@com  Mon Nov  6 17:52:14 2023
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Mon, 6 Nov 2023 16:52:14 +0000
Subject: [R] 
 I need to create new variables based on two numeric variables
 and one dichotomize conditional category
In-Reply-To: <mailman.370492.1.1699095602.29524.r-help@r-project.org>
References: <mailman.370492.1.1699095602.29524.r-help@r-project.org>
Message-ID: <LV3PR01MB8673934678078681ACBD4646DCAAA@LV3PR01MB8673.prod.exchangelabs.com>

Avi: Thank you for checking. I think the optimization is limited. If test is all TRUE or all FALSE then at most one vector is evaluated. Anything beyond that would be very complicated. (Inspect the two expressions and verify that both specify elementwise computations. Then use indexing to shrink the input properly. Take into account all recycling rules for binary operations.)


> ifelse(0:1, log(-1:0), 1:2)

Warning in log(-1:0) : NaNs produced

[1]    1 -Inf

> ifelse(c(FALSE,FALSE), log(-1:0), 1:2)

[1] 1 2

I agree that nested ifelse is cumbersome. I wrote a function to address that:


#' Nested conditional element selection

#'

#' \code{ifelses(test1,yes1,test2,yes2,....,no)} is shorthand for

#' \code{ifelse(test1,yes1,ifelse(test2,yes2,....,no....))}. The inputs should

#' not be named.

#'

#' @param test1 usually \code{test} for the outer call to \code{\link{ifelse}}

#' @param yes1 \code{yes} for the outer call to \code{ifelse}

#' @param ... usually the \code{(test,yes)} for nested calls followed by \code{no}

#' for the innermost call to \code{ifelse}

#'

#' @note There must be an odd number of inputs. If there is exactly one input then it is

#' returned (unless it is named \code{yes1}): this supports the recursive implementation.

#'

#' @return a vector with entries from \code{yes1} where \code{test1} is \code{TRUE}, else from

#' \code{yes2} where \code{test2} is \code{TRUE}, ..., and from \code{no} where none of

#' the conditions holds

#'

#' @export



ifelses <- function(test1,yes1,...)

{ if (missing(test1))

  { if (!missing(yes1) || length(L <- list(...)) != 1L)

      stop("Wrong number of arguments or confusing argument names.")

    return(L[[1L]])

  }

  if (missing(yes1))

  { if (length(L <- list(...)) != 0L)

      stop("Wrong number of arguments or confusing argument names.")

    return(test1)

  }

  return( ifelse(test1, yes1, ifelses(...)) )

}

Regards,
Jorgen Harmse (not Jordan).

------------------------------

Message: 10
Date: Sat, 4 Nov 2023 01:08:03 -0400
From: <avi.e.gross at gmail.com>
To: "'Jorgen Harmse'" <JHarmse at roku.com>
Cc: <r-help at r-project.org>
Subject: Re: [R] [EXTERNAL] RE: I need to create new variables based
        on two numeric variables and one dichotomize conditional category
        variables.
Message-ID: <019a01da0edc$e41c39e0$ac54ada0$@gmail.com>
Content-Type: text/plain; charset="utf-8"

To be fair, Jordan, I think R has some optimizations so that the arguments
in some cases are NOT evaluated until needed. So only one or the other
choice ever gets evaluated for each row. My suggestion merely has
typographic implications and some aspects of clarity and minor amounts of
less memory and parsing needed.

But ifelse() is currently implemented somewhat too complexly for my taste.
Just type "ifelse" at the prompt and you will see many lines of code that
handle various scenarios.

?

If you later want to add categories such as ?transgender? with a value of 61 or have other numbers for groups like ?Hispanic male?, you can amend the instructions as long as you put your conditions in an order so that they are tried until one of them matches, or it takes the default. Yes, in a sense the above is doable using a deeply nested ifelse() but easier for me to read and write and evaluate. It may not be more efficient or may be as some of dplyr is compiled code.






	[[alternative HTML version deleted]]


From tr|ng @end|ng |rom gvdnet@dk  Mon Nov  6 17:53:49 2023
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Mon, 6 Nov 2023 17:53:49 +0100
Subject: [R] non-linear regression and root finding
Message-ID: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>

Dear friends - I have a function for the charge in a fluid (water) 
buffered with HEPES and otherwise only containing Na and Cl so that [Na] 
- [Cl] = SID (strong ion difference) goes from -1 mM to 1 mM. With known 
SID and total HEPES concentration I can calculate accurately the pH if I 
know 3 pK values for HEPES by finding the single root with uniroot

Now, the problem is that there is some disagreement in the literature 
what is the correct value for the 3 pKs. I know the 3 pK values have the 
relationship pK1 < pK2 <- pK3 and for the most common formulation of 
HEPES I know the charge on fully protonated species is 2. Hence I can 
generate a huge number of pK values from uniform distribution by taking 
sort(runif(3,-1,9) and make sure there are no ties and then run all 
those triplets of pK values to find pH values and thereby find the 
lowest deviation vis a vis measured values. That works but requires many 
triplets and is not satisfying. Hence I wonder if I could somehow have 
non linear regression to find the 3 pK values. Below is HEPESFUNC which 
delivers charge in the fluid for known pKs, HEPTOT and SID. Is it 
possible to have root-finding in the formula with nls? (I know the 
precision asked for is extreme but it has worked well in really many 
applications).

All best wishes

Troels Ring, MD
Aalborg, Denmark


HEPESFUNC <-
 ? function(H,SID,HEPTOT,pK1,pK2,pK3) {
 ??? XX <- (H^3/(10^-pK3*10^-pK2*10^-pK1)+H^2/(10^-pK3*10^-pK2)+H/(10^-pK3))
 ??? IV <- HEPTOT/(1+XX)
 ??? I <- IV*H^3/(10^-pK3*10^-pK2*10^-pK1)
 ??? II <- IV*H^2/(10^-pK3*10^-pK2)
 ??? III <- IV*H/10^-pK3
 ??? H - kw/H + SID + I*2 + II - IV
 ? }


HEPTOT <- 0.050
SID <- c(-seq(10,1)*1e-4,0,seq(1,10)*1e-4)

pHobs? <- c(4.63,4.68,4.72,4.77,4.83,4.9,4.96,5.04,5.12,5.21,5.3,
 ??????????? 5.39,5.48,5.55,5.63,5.69,5.74,5.8,5.85,5.89,5.93)

pK1 <- -1; pK2 <- 3; pK3 <- 7.55 # literature values
pK3 <- 7.6; pK2 <- 2.96 # values eye-balled to be better

pH <- c()
for (i in 1:length(SID)) {
 ? pH[i] <- -log10(uniroot(HEPESFUNC,c(1e-20,1),tol=1e-20,maxiter=1e4,
 ?????????????????????? HEPTOT=HEPTOT,SID = SID[i],
 ?????????????????????? pK1=pK1,pK2=pK2,pK3=pK3)$root)
}

plot(SID,pH)
points(SID,pHobs,col="red")


From jo@h@m@u|r|ch @end|ng |rom gm@||@com  Mon Nov  6 18:07:22 2023
From: jo@h@m@u|r|ch @end|ng |rom gm@||@com (Joshua Ulrich)
Date: Mon, 6 Nov 2023 11:07:22 -0600
Subject: [R] strptime with +03:00 zone designator
In-Reply-To: <25928.43905.917277.897930@stat.math.ethz.ch>
References: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
 <CAAxdm-666SwXzBgKJEn-HWphspbWDb2ycyVzdAbvD+oX16xRVA@mail.gmail.com>
 <CABcYAdJpMibwW7Qjm_0A2D+1H=ddvow6S12RaKRUx-frR210tg@mail.gmail.com>
 <CABcYAd+y6v7YTOtE0QrDciNNSpGZb22MFqsWA=xB+e1-q-QcLg@mail.gmail.com>
 <25928.43905.917277.897930@stat.math.ethz.ch>
Message-ID: <CAPPM_gQejVfnPjeCF7cUw9b22mHsnHcMh90rk9K9=ciY+dUpHg@mail.gmail.com>

On Mon, Nov 6, 2023 at 3:02?AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Richard O'Keefe
> >>>>>     on Mon, 6 Nov 2023 18:37:34 +1300 writes:
>
>     > Thanks to all who replied.  On Mon, 6 Nov 2023 at 18:37,
>     > Richard O'Keefe <raoknz at gmail.com> wrote:
>
>     >> OK, so the consensus is (1) One cannot make strptime
>     >> accept ISO8601-compliant zone designators (2) The
>     >> lubridate package can (3) Or one can hack away with
>     >> regex.  Lubridate it is, then.
>     >>
>     >> But I do regard strptime's inability to process
>     >> ISO8601-compliant zone designators as a bug.
>
> Did you try to submit it to R's bugzilla?
>
> It's the first time I hear of this "Feature" of the ISO
> standard, but then I'm not at all a timezone, and even less an
> ISO standard expert.
>
FWIW, the timezone offset format (%z) is handled in
src/main/Rstrptime.h around line 987. There's a comment that only the
RFC 822 form is recognized (+/-HHMM). The fix may be as simple as
ignoring the ':' in the while() loop.

> Best,
> Martin

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Nov  6 19:19:02 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 6 Nov 2023 21:19:02 +0300
Subject: [R] non-linear regression and root finding
In-Reply-To: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>
References: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>
Message-ID: <20231106211902.375d3b0a@Tarkus>

? Mon, 6 Nov 2023 17:53:49 +0100
Troels Ring <tring at gvdnet.dk> ?????:

> Hence I wonder if I could somehow have non linear regression to find
> the 3 pK values. Below is HEPESFUNC which delivers charge in the
> fluid for known pKs, HEPTOT and SID. Is it possible to have
> root-finding in the formula with nls?

Sure. Just reformulate the problem in terms of a function that takes a
vector of predictors (your independent variable SID) and the desired
parameters (pK1, pK2, pK3) as separate arguments and then returns
predicted values of the dependent variable (to compare against pHobs):

kw <- 1e-14 # I'm assuming
pHm <- Vectorize(function(SID, pK1, pK2, pK3)
 -log10(uniroot(HEPESFUNC,c(1e-20,1),tol=1e-20,maxiter=1e4,
        HEPTOT=HEPTOT,SID = SID, pK1=pK1,pK2=pK2,pK3=pK3)$root))

(Yes, Vectorize() doesn't make the function any faster, but I don't see
an easy way to rewrite this function to make it truly vectorised.)

Unfortunately, nls() seems to take a step somewhere where crossprod()
of the Jacobian of the model function cannot be inverted and fails with
the message "Singular gradient". I wish that R could have a more
reliable built-in nonlinear least squares solver. (I could also be
holding it wrong.) Meanwhile, we have excellent CRAN packages nlsr and
minpack.lm:

minpack.lm::nlsLM(
 pHobs ~ pHm(SID, pK1, pK2, pK3),
 data.frame(pHobs = pHobs, SID = SID),
 start = c(pK1 = pK1, pK2 = pK2, pK3 = pK3),
 # the following is also needed to avoid MINPACK failing to fit
 lower = rep(-1, 3), upper = rep(9, 3)
)
# Nonlinear regression model
#   model: pHobs ~ pHm(SID, pK1, pK2, pK3)
#    data: data.frame(pHobs = pHobs, SID = SID)
#    pK1     pK2    pK3
# -1.000   2.966  7.606
#  residual sum-of-squares: 0.001195
#
# Number of iterations to convergence: 15 
# Achieved convergence tolerance: 1.49e-08

(Unfortunately, your code seemed to have a lot of non-breakable spaces,
which confuse R's parser and make it harder to copy&paste it.)

I think that your function can also be presented as a degree-5
polynomial in H, so it should also be possible to use polyroot() to
obtain your solutions in a more exact manner.

-- 
Best regards,
Ivan


From pro|jcn@@h @end|ng |rom gm@||@com  Mon Nov  6 19:36:21 2023
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Mon, 6 Nov 2023 13:36:21 -0500
Subject: [R] non-linear regression and root finding
In-Reply-To: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>
References: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>
Message-ID: <87c26e00-7bd0-4929-b866-9fc0e6c6a5ba@gmail.com>

Your script is missing something (in particular kw).

I presume you are trying to estimate the pK values. You may have more success
with package nlsr than nls(). nlsr::nlxb() tries to get the Jacobian of the
model specified by a formula and do so by applying symbolic or automatic
differentiation. The multi expression function would probably not work.
(That is one advantage of nls(), but it has an unstabilized solver and unless
carefully called will use a simple forward derivative approximation.)
There is also nlsr::nlfb() that can use functions for the residuals and
jacobian. Your function is messy, but likely the jacobian can be developed
with a bit of work.

Some of the symbolic derivative features of R can help here. Alternatively,
there are several numerical approximations in nlsr and the vignette "Intro
to nlsr" explains how to use these. Note that simple forward and backward
approximations are generally not worth using, but central approximation is
quite good.

The solver in the nlsr package allows of bounds on the parameters. Since you
want them ordered, you may want to transform

    pK1 < pK2 <- pK3

to  pk1, deltapk2, deltapk3 so pK2 = pk1+deltapk2
and pk3 = pk2 + deltapk3 = pk1 + deltapk2 + deltapk3
and all values bounded below by 0 or possibly some small numbers to
keep the paramters apart.

I won't pretend any of this is trivial. It is VERY easy to make small errors
that still allow for output that is disastrously incorrect. If it is possible
to get a single "formula" as one expression even if spread over multiple lines,
then nlxb() might be able to handle it.


J Nash (maintainer of nlsr and optimx)

On 2023-11-06 11:53, Troels Ring wrote:

....
> HEPESFUNC <-
>  ? function(H,SID,HEPTOT,pK1,pK2,pK3) {
>  ??? XX <- (H^3/(10^-pK3*10^-pK2*10^-pK1)+H^2/(10^-pK3*10^-pK2)+H/(10^-pK3))
>  ??? IV <- HEPTOT/(1+XX)
>  ??? I <- IV*H^3/(10^-pK3*10^-pK2*10^-pK1)
>  ??? II <- IV*H^2/(10^-pK3*10^-pK2)
>  ??? III <- IV*H/10^-pK3
>  ??? H - kw/H + SID + I*2 + II - IV
>  ? }
> 
> 
> HEPTOT <- 0.050
> SID <- c(-seq(10,1)*1e-4,0,seq(1,10)*1e-4)
> 
> pHobs? <- c(4.63,4.68,4.72,4.77,4.83,4.9,4.96,5.04,5.12,5.21,5.3,
>  ??????????? 5.39,5.48,5.55,5.63,5.69,5.74,5.8,5.85,5.89,5.93)
> 
> pK1 <- -1; pK2 <- 3; pK3 <- 7.55 # literature values
> pK3 <- 7.6; pK2 <- 2.96 # values eye-balled to be better
> 
> pH <- c()
> for (i in 1:length(SID)) {
>  ? pH[i] <- -log10(uniroot(HEPESFUNC,c(1e-20,1),tol=1e-20,maxiter=1e4,
>  ?????????????????????? HEPTOT=HEPTOT,SID = SID[i],
>  ?????????????????????? pK1=pK1,pK2=pK2,pK3=pK3)$root)
> }
> 
> plot(SID,pH)
> points(SID,pHobs,col="red")


From tr|ng @end|ng |rom gvdnet@dk  Mon Nov  6 20:43:10 2023
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Mon, 6 Nov 2023 20:43:10 +0100
Subject: [R] non-linear regression and root finding
In-Reply-To: <20231106211902.375d3b0a@Tarkus>
References: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>
 <20231106211902.375d3b0a@Tarkus>
Message-ID: <7990e957-6f37-4d2c-9ff0-d586f30798c6@gvdnet.dk>

Thanks a lot! This was amazing. I'm not sure I see how the conditiion 
pK1 < pK2 < pK3 is enforced? - it comes from the derivation via 
generalized Henderson-Hasselbalch but perhaps it is not really 
necessary. Anyway, the use of Vectorize did the trick!

Best wishes
Troels

Den 06-11-2023 kl. 19:19 skrev Ivan Krylov:
> ? Mon, 6 Nov 2023 17:53:49 +0100
> Troels Ring <tring at gvdnet.dk> ?????:
>
>> Hence I wonder if I could somehow have non linear regression to find
>> the 3 pK values. Below is HEPESFUNC which delivers charge in the
>> fluid for known pKs, HEPTOT and SID. Is it possible to have
>> root-finding in the formula with nls?
> Sure. Just reformulate the problem in terms of a function that takes a
> vector of predictors (your independent variable SID) and the desired
> parameters (pK1, pK2, pK3) as separate arguments and then returns
> predicted values of the dependent variable (to compare against pHobs):
>
> kw <- 1e-14 # I'm assuming
> pHm <- Vectorize(function(SID, pK1, pK2, pK3)
>   -log10(uniroot(HEPESFUNC,c(1e-20,1),tol=1e-20,maxiter=1e4,
>          HEPTOT=HEPTOT,SID = SID, pK1=pK1,pK2=pK2,pK3=pK3)$root))
>
> (Yes, Vectorize() doesn't make the function any faster, but I don't see
> an easy way to rewrite this function to make it truly vectorised.)
>
> Unfortunately, nls() seems to take a step somewhere where crossprod()
> of the Jacobian of the model function cannot be inverted and fails with
> the message "Singular gradient". I wish that R could have a more
> reliable built-in nonlinear least squares solver. (I could also be
> holding it wrong.) Meanwhile, we have excellent CRAN packages nlsr and
> minpack.lm:
>
> minpack.lm::nlsLM(
>   pHobs ~ pHm(SID, pK1, pK2, pK3),
>   data.frame(pHobs = pHobs, SID = SID),
>   start = c(pK1 = pK1, pK2 = pK2, pK3 = pK3),
>   # the following is also needed to avoid MINPACK failing to fit
>   lower = rep(-1, 3), upper = rep(9, 3)
> )
> # Nonlinear regression model
> #   model: pHobs ~ pHm(SID, pK1, pK2, pK3)
> #    data: data.frame(pHobs = pHobs, SID = SID)
> #    pK1     pK2    pK3
> # -1.000   2.966  7.606
> #  residual sum-of-squares: 0.001195
> #
> # Number of iterations to convergence: 15
> # Achieved convergence tolerance: 1.49e-08
>
> (Unfortunately, your code seemed to have a lot of non-breakable spaces,
> which confuse R's parser and make it harder to copy&paste it.)
>
> I think that your function can also be presented as a degree-5
> polynomial in H, so it should also be possible to use polyroot() to
> obtain your solutions in a more exact manner.
>


From pro|jcn@@h @end|ng |rom gm@||@com  Mon Nov  6 20:55:39 2023
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Mon, 6 Nov 2023 14:55:39 -0500
Subject: [R] non-linear regression and root finding
In-Reply-To: <7990e957-6f37-4d2c-9ff0-d586f30798c6@gvdnet.dk>
References: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>
 <20231106211902.375d3b0a@Tarkus>
 <7990e957-6f37-4d2c-9ff0-d586f30798c6@gvdnet.dk>
Message-ID: <67c5ad87-6653-4d3d-be42-ba2e7aef08f7@gmail.com>

I won't send to list, but just to the two of you, as I don't have
anything to add at this time. However, I'm wondering if this approach
is worth writing up, at least as a vignette or blog post. It does need
a shorter example and some explanation of the "why" and some testing
perhaps.

If there's interest, I'll be happy to join in. And my own posting suggests
how the ordering is enforced by bounding the "delta" parameters from below.

Note that nls() can only handle bounds in the "port" algorithm, and the
man page rather pours cold water on using that algorithm.

Best, JN


On 2023-11-06 14:43, Troels Ring wrote:
> Thanks a lot! This was amazing. I'm not sure I see how the conditiion pK1 < pK2 < pK3 is enforced? - it comes from the 
> derivation via generalized Henderson-Hasselbalch but perhaps it is not really necessary. Anyway, the use of Vectorize 
> did the trick!
> 
> Best wishes
> Troels
> 
> Den 06-11-2023 kl. 19:19 skrev Ivan Krylov:
>> ? Mon, 6 Nov 2023 17:53:49 +0100
>> Troels Ring <tring at gvdnet.dk> ?????:
>>
>>> Hence I wonder if I could somehow have non linear regression to find
>>> the 3 pK values. Below is HEPESFUNC which delivers charge in the
>>> fluid for known pKs, HEPTOT and SID. Is it possible to have
>>> root-finding in the formula with nls?
>> Sure. Just reformulate the problem in terms of a function that takes a
>> vector of predictors (your independent variable SID) and the desired
>> parameters (pK1, pK2, pK3) as separate arguments and then returns
>> predicted values of the dependent variable (to compare against pHobs):
>>
>> kw <- 1e-14 # I'm assuming
>> pHm <- Vectorize(function(SID, pK1, pK2, pK3)
>> ? -log10(uniroot(HEPESFUNC,c(1e-20,1),tol=1e-20,maxiter=1e4,
>> ???????? HEPTOT=HEPTOT,SID = SID, pK1=pK1,pK2=pK2,pK3=pK3)$root))
>>
>> (Yes, Vectorize() doesn't make the function any faster, but I don't see
>> an easy way to rewrite this function to make it truly vectorised.)
>>
>> Unfortunately, nls() seems to take a step somewhere where crossprod()
>> of the Jacobian of the model function cannot be inverted and fails with
>> the message "Singular gradient". I wish that R could have a more
>> reliable built-in nonlinear least squares solver. (I could also be
>> holding it wrong.) Meanwhile, we have excellent CRAN packages nlsr and
>> minpack.lm:
>>
>> minpack.lm::nlsLM(
>> ? pHobs ~ pHm(SID, pK1, pK2, pK3),
>> ? data.frame(pHobs = pHobs, SID = SID),
>> ? start = c(pK1 = pK1, pK2 = pK2, pK3 = pK3),
>> ? # the following is also needed to avoid MINPACK failing to fit
>> ? lower = rep(-1, 3), upper = rep(9, 3)
>> )
>> # Nonlinear regression model
>> #?? model: pHobs ~ pHm(SID, pK1, pK2, pK3)
>> #??? data: data.frame(pHobs = pHobs, SID = SID)
>> #??? pK1???? pK2??? pK3
>> # -1.000?? 2.966? 7.606
>> #? residual sum-of-squares: 0.001195
>> #
>> # Number of iterations to convergence: 15
>> # Achieved convergence tolerance: 1.49e-08
>>
>> (Unfortunately, your code seemed to have a lot of non-breakable spaces,
>> which confuse R's parser and make it harder to copy&paste it.)
>>
>> I think that your function can also be presented as a degree-5
>> polynomial in H, so it should also be possible to use polyroot() to
>> obtain your solutions in a more exact manner.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Mon Nov  6 22:16:33 2023
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Mon, 6 Nov 2023 15:16:33 -0600
Subject: [R] understanding predict.lm
Message-ID: <40f8154c-a5d9-44e1-9221-f8dcd4d7f427@effectivedefense.org>

Hello, All:


	  I am unable to manually replicate predict.lm, specifically comparing 
se.fit with (fit[,3]-fit[,2]): I think their ratio should be 
2*qnorm((1-level)/2), and that's not what I'm getting.


	  Consider the following slight modification of the first example in 
help('predict.lm'):


set.seed(1)
x <- rnorm(15)
y <- x + rnorm(15)
predict(lm(y ~ x))
new <- data.frame(x = seq(-3, 3, 0.5))
predict(lm(y ~ x), new, se.fit = TRUE)
pred.w.plim <- predict(lm(y ~ x), new, interval = "prediction",
                        se.fit = TRUE)
pred.w.clim <- predict(lm(y ~ x), new, interval = "confidence",
                        se.fit = TRUE)

(z.confInt <- with(pred.w.clim, (fit[,3]-fit[,2])/se.fit))
pnorm(-z.confInt/2)

s.pred <- sqrt(with(pred.w.plim,
                     se.fit^2+residual.scale^2))
(z.predInt <- with(pred.w.plim, (fit[,3]-fit[,2])/s.pred))
pnorm(-z.predInt/2)


	  ** This gives me 0.01537207. I do not understand why it's not 0.025 
with level = 0.95.


	  Can someone help me understand this?
	  Thanks,
	  Spencer Graves


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Tue Nov  7 00:27:46 2023
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Mon, 6 Nov 2023 17:27:46 -0600
Subject: [R] understanding predict.lm
In-Reply-To: <093d2b57-076d-4a9f-9aa3-9ad83c101af6@mcmaster.ca>
References: <40f8154c-a5d9-44e1-9221-f8dcd4d7f427@effectivedefense.org>
 <093d2b57-076d-4a9f-9aa3-9ad83c101af6@mcmaster.ca>
Message-ID: <932599e8-903f-4d23-b548-6d4a5c034b9b@effectivedefense.org>

Doh! Thanks very much. sg


On 11/6/23 5:17 PM, John Fox wrote:
> Dear Spencer,
> 
> You need the t distribution with correct df, not the standard-normal 
> distribution:
> 
>  > pt(-z.confInt/2, df=13)
>  ??? 1???? 2???? 3???? 4???? 5???? 6???? 7???? 8???? 9??? 10??? 11
> 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025
>  ?? 12??? 13
> 0.025 0.025
> 
>  > pt(-z.predInt/2, df=13)
>  ??? 1???? 2???? 3???? 4???? 5???? 6???? 7???? 8???? 9??? 10??? 11
> 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025
>  ?? 12??? 13
> 0.025 0.025
> 
> I hope this helps,
>  ?John


From @tyen @end|ng |rom ntu@edu@tw  Tue Nov  7 02:09:33 2023
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Tue, 7 Nov 2023 09:09:33 +0800
Subject: [R] Concordance and Kendall's tau in copula
Message-ID: <f33ad3c9-fc61-4b8f-b8fb-2ca33453a078@ntu.edu.tw>

Dear

I estimate a sample selection model using the Clayton copula and Burr 
and Gaussian marginal. I need to derive ther Kendall'sw tau from the 
concordance coefficient by integration. I came across a way to do that 
in R long time ago but cannot find it again. Can somewone tell me what 
to read and what to use? Thank you.

Steven Yen


From berw|n@tur|@ch @end|ng |rom gm@||@com  Tue Nov  7 05:10:08 2023
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Tue, 7 Nov 2023 12:10:08 +0800
Subject: [R] non-linear regression and root finding
In-Reply-To: <7990e957-6f37-4d2c-9ff0-d586f30798c6@gvdnet.dk>
References: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>
 <20231106211902.375d3b0a@Tarkus>
 <7990e957-6f37-4d2c-9ff0-d586f30798c6@gvdnet.dk>
Message-ID: <20231107121008.3dcc71e6@dep59159.uniwa.uwa.edu.au>

G'day Troels,

On Mon, 6 Nov 2023 20:43:10 +0100
Troels Ring <tring at gvdnet.dk> wrote:

> Thanks a lot! This was amazing. I'm not sure I see how the conditiion
> pK1 < pK2 < pK3 is enforced? 

One way of enforcing such constraints (well, in finite computer
arithemtic only "<=" can be enforced) is to rewrite the parameters as:

pK1 = exp(theta1)       ## only if pK1 > 0
pK2 = pK1 + exp(theta2)
pK3 = pk2 + exp(theta3)

And then use your optimiser to optimise over theta1, theta2 and theta3.

There might be better approaches depending on the specific problem.

Cheers,

	Berwin


From tr|ng @end|ng |rom gvdnet@dk  Tue Nov  7 07:14:02 2023
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Tue, 7 Nov 2023 07:14:02 +0100
Subject: [R] non-linear regression and root finding
In-Reply-To: <20231107121008.3dcc71e6@dep59159.uniwa.uwa.edu.au>
References: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>
 <20231106211902.375d3b0a@Tarkus>
 <7990e957-6f37-4d2c-9ff0-d586f30798c6@gvdnet.dk>
 <20231107121008.3dcc71e6@dep59159.uniwa.uwa.edu.au>
Message-ID: <d258f5c5-9ae3-4bf5-9f6c-cccb64de37a1@gvdnet.dk>

Thanks a lot, Berwin. Unfortunately, pK1 may well be negative and as I 
understand the literature it may be poorly defined as such, and also 
seems to be at a boundary, since when lower is set to say rep(-4,3) pK1 
is returned as -4 while pK2 and pK3 are undisturbed. Perhaps the point 
is that pK1 is not carrying any information at the pH around 5. Fair 
enough, I guess. Only, I believe I need stick to including all three pK 
values to be in agreement with the molecular information about HEPES - 
although even this is contentious. Be as it may, I wonder if not your 
method might work if only we KNOW that pK1 is either positive OR 
negative, in which case we have pK1 = -exp(theta1)?

Best wishes
Troels

Den 07-11-2023 kl. 05:10 skrev Berwin A Turlach:
> G'day Troels,
>
> On Mon, 6 Nov 2023 20:43:10 +0100
> Troels Ring <tring at gvdnet.dk> wrote:
>
>> Thanks a lot! This was amazing. I'm not sure I see how the conditiion
>> pK1 < pK2 < pK3 is enforced?
> One way of enforcing such constraints (well, in finite computer
> arithemtic only "<=" can be enforced) is to rewrite the parameters as:
>
> pK1 = exp(theta1)       ## only if pK1 > 0
> pK2 = pK1 + exp(theta2)
> pK3 = pk2 + exp(theta3)
>
> And then use your optimiser to optimise over theta1, theta2 and theta3.
>
> There might be better approaches depending on the specific problem.
>
> Cheers,
>
> 	Berwin


From j|ox @end|ng |rom mcm@@ter@c@  Tue Nov  7 00:17:21 2023
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 6 Nov 2023 18:17:21 -0500
Subject: [R] understanding predict.lm
In-Reply-To: <40f8154c-a5d9-44e1-9221-f8dcd4d7f427@effectivedefense.org>
References: <40f8154c-a5d9-44e1-9221-f8dcd4d7f427@effectivedefense.org>
Message-ID: <093d2b57-076d-4a9f-9aa3-9ad83c101af6@mcmaster.ca>

Dear Spencer,

You need the t distribution with correct df, not the standard-normal 
distribution:

 > pt(-z.confInt/2, df=13)
     1     2     3     4     5     6     7     8     9    10    11
0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025
    12    13
0.025 0.025

 > pt(-z.predInt/2, df=13)
     1     2     3     4     5     6     7     8     9    10    11
0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025
    12    13
0.025 0.025

I hope this helps,
  John
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://www.john-fox.ca/

On 2023-11-06 4:16 p.m., Spencer Graves wrote:
> Caution: External email.
> 
> 
> Hello, All:
> 
> 
>  ???????? I am unable to manually replicate predict.lm, specifically 
> comparing
> se.fit with (fit[,3]-fit[,2]): I think their ratio should be
> 2*qnorm((1-level)/2), and that's not what I'm getting.
> 
> 
>  ???????? Consider the following slight modification of the first 
> example in
> help('predict.lm'):
> 
> 
> set.seed(1)
> x <- rnorm(15)
> y <- x + rnorm(15)
> predict(lm(y ~ x))
> new <- data.frame(x = seq(-3, 3, 0.5))
> predict(lm(y ~ x), new, se.fit = TRUE)
> pred.w.plim <- predict(lm(y ~ x), new, interval = "prediction",
>  ?????????????????????? se.fit = TRUE)
> pred.w.clim <- predict(lm(y ~ x), new, interval = "confidence",
>  ?????????????????????? se.fit = TRUE)
> 
> (z.confInt <- with(pred.w.clim, (fit[,3]-fit[,2])/se.fit))
> pnorm(-z.confInt/2)
> 
> s.pred <- sqrt(with(pred.w.plim,
>  ??????????????????? se.fit^2+residual.scale^2))
> (z.predInt <- with(pred.w.plim, (fit[,3]-fit[,2])/s.pred))
> pnorm(-z.predInt/2)
> 
> 
>  ???????? ** This gives me 0.01537207. I do not understand why it's not 
> 0.025
> with level = 0.95.
> 
> 
>  ???????? Can someone help me understand this?
>  ???????? Thanks,
>  ???????? Spencer Graves
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From berw|n@tur|@ch @end|ng |rom gm@||@com  Tue Nov  7 08:53:03 2023
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Tue, 7 Nov 2023 15:53:03 +0800
Subject: [R] non-linear regression and root finding
In-Reply-To: <d258f5c5-9ae3-4bf5-9f6c-cccb64de37a1@gvdnet.dk>
References: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>
 <20231106211902.375d3b0a@Tarkus>
 <7990e957-6f37-4d2c-9ff0-d586f30798c6@gvdnet.dk>
 <20231107121008.3dcc71e6@dep59159.uniwa.uwa.edu.au>
 <d258f5c5-9ae3-4bf5-9f6c-cccb64de37a1@gvdnet.dk>
Message-ID: <20231107155303.0d27333e@dep59159.uniwa.uwa.edu.au>

G'day Troels,

On Tue, 7 Nov 2023 07:14:02 +0100
Troels Ring <tring at gvdnet.dk> wrote:

> Be as it may, I wonder if not your method might work if only we KNOW
> that pK1 is either positive OR negative, in which case we have pK1 =
> -exp(theta1)?

If pK1 can be either negative or positive (or 0 :-) ), and it is just
the ordering that you want to have enforced, then I would try the
parameterisation:

pK1 = pK1
pK2 = pK1 + exp(theta2)
pK3 = pk2 + exp(theta3)

and optimise over pK1, theta2 and theta3.  

As long as you want to know the estimates only.  

Asking for standard errors of the original estimates would open another
can of worms. :-)

Cheers,

	Berwin


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Nov  7 10:03:58 2023
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 7 Nov 2023 10:03:58 +0100
Subject: [R] Concordance and Kendall's tau in copula
In-Reply-To: <f33ad3c9-fc61-4b8f-b8fb-2ca33453a078@ntu.edu.tw>
References: <f33ad3c9-fc61-4b8f-b8fb-2ca33453a078@ntu.edu.tw>
Message-ID: <25929.64894.937088.581822@stat.math.ethz.ch>

>>>>> Steven Yen 
>>>>>     on Tue, 7 Nov 2023 09:09:33 +0800 writes:

    > Dear
    > I estimate a sample selection model using the Clayton copula and Burr 
    > and Gaussian marginal. I need to derive ther Kendall'sw tau from the 
    > concordance coefficient by integration. I came across a way to do that 
    > in R long time ago but cannot find it again. Can somewone tell me what 
    > to read and what to use? Thank you.

    > Steven Yen


I think you can estimate your model relatively easily using our
package {copula}  and the function  fitMvdc()

   https://search.r-project.org/CRAN/refmans/copula/html/fitMvdc.html

MVDC := Multivariate Variate Distribution {built from} Copula

To solve the question you asked --- but would not need to answer if
using fitMvdc(),
you can use  e.g.,

    > iTau(claytonCopula(), tau = 1.4)
    [1] -7

or look up the formulas for tau() or its inverse 'iTau':

  > copClayton at tau
  function (theta) 
  {
      theta/(theta + 2)
  }

  > copClayton at iTau
  function (tau) 
  {
      2 * tau/(1 - tau)
  }

  > 

Best regards,
Martin

{and yes, consider getting our 'useR! Springer series book, as
 it's the only "real" book, I've been a coauthor.. https://copula.r-forge.r-project.org/book/ }

--
Martin Maechler
ETH Zurich  and  R Core team


From cry@n @end|ng |rom b|ngh@mton@edu  Tue Nov  7 17:01:50 2023
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher Ryan)
Date: Tue, 7 Nov 2023 11:01:50 -0500
Subject: [R] make a lattice dotplot with symbol size proportional to a
 variable in the plotted dataframe
Message-ID: <CAM+rpY=Mn9+osm2Ct4fNkDOKXP2zLDEa+tTkz0WB6rgzytKi5Q@mail.gmail.com>

Hello. My question is in the subject line. Using R 4.1.3 on Windows 10.
Commented MWE below. Thanks.

--Chris Ryan



library(dplyr)
library(lattice)

## fabricate a dataframe
dd <- data.frame(agency = sample(LETTERS, size = 5),
total = sample(100:200, size = 5),
las = sample(20:40, size = 5))
dd <- dd %>% mutate(proportion = las/total, bubble = total/100)


## attempt to make a dotplot with symbol size proportional
## to the variable named total

dotplot(agency ~ proportion, pch = 16, cex = bubble, data = dd)
##  object 'bubble' not found

dotplot(agency ~ proportion, pch = 16, cex = dd$bubble, data = dd)
## works



## also works in two commands
external.bubble <- dd$bubble
dotplot(agency ~ proportion, pch = 16, cex = external.bubble, data = dd)



## but how to chain it with pipes, dplyr-style,
## modifying the dataframe and then
## using the modified version in dotplot, all in one chain?

dd %>% mutate(new.proportion = las/total, new.bubble = total/100) %>%
    dotplot(agency ~ new.proportion, pch = 16, cex = new.bubble, data = .)
## object 'new.bubble' not found


dd %>% mutate(new.proportion = las/total, new.bubble = total/100) %>%
     dotplot(agency ~ new.proportion, pch = 16, cex = .$new.bubble, data =
.)
## the .$new.bubble syntax seems to work, but I've never
## used or seen that before, and it seems weird.
## Is there a "proper" syntax?

	[[alternative HTML version deleted]]


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Tue Nov  7 17:25:10 2023
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Tue, 7 Nov 2023 11:25:10 -0500
Subject: [R] make a lattice dotplot with symbol size proportional to a
 variable in the plotted dataframe
In-Reply-To: <CAM+rpY=Mn9+osm2Ct4fNkDOKXP2zLDEa+tTkz0WB6rgzytKi5Q@mail.gmail.com>
References: <CAM+rpY=Mn9+osm2Ct4fNkDOKXP2zLDEa+tTkz0WB6rgzytKi5Q@mail.gmail.com>
Message-ID: <CADfFDC4bns4YY7SC4mFQOsY68WQj=VFSPJAjHOU223km0vDq7w@mail.gmail.com>

Handling NSE in these kinds of examples is a pain in lattice. I would
suggest using with() and dropping the data argument for simple examples,
e.g.,

dd |> mutate(new.proportion = las/total, new.bubble = total/100) |>
    with(dotplot(agency ~ new.proportion, pch = 16, cex = new.bubble))

But if you care about multi-panel plots, you also need to be careful about
making sure that the 'cex' values get split properly. This is done
generally using the 'subscripts' argument provided to panel functions, so
something like this should be safer:

panel.bubble <- function(x, y, cex, ..., subscripts) {
    panel.dotplot(x, y, cex = cex[subscripts], ...)
}

dd |> mutate(new.proportion = las/total, new.bubble = total/100) |>
    with(dotplot(agency ~ new.proportion, pch = 16,
                 cex = new.bubble, panel = panel.bubble))

Best,
-Deepayan

On Tue, 7 Nov 2023 at 11:03, Christopher Ryan via R-help <
r-help at r-project.org> wrote:

> Hello. My question is in the subject line. Using R 4.1.3 on Windows 10.
> Commented MWE below. Thanks.
>
> --Chris Ryan
>
>
>
> library(dplyr)
> library(lattice)
>
> ## fabricate a dataframe
> dd <- data.frame(agency = sample(LETTERS, size = 5),
> total = sample(100:200, size = 5),
> las = sample(20:40, size = 5))
> dd <- dd %>% mutate(proportion = las/total, bubble = total/100)
>
>
> ## attempt to make a dotplot with symbol size proportional
> ## to the variable named total
>
> dotplot(agency ~ proportion, pch = 16, cex = bubble, data = dd)
> ##  object 'bubble' not found
>
> dotplot(agency ~ proportion, pch = 16, cex = dd$bubble, data = dd)
> ## works
>
>
>
> ## also works in two commands
> external.bubble <- dd$bubble
> dotplot(agency ~ proportion, pch = 16, cex = external.bubble, data = dd)
>
>
>
> ## but how to chain it with pipes, dplyr-style,
> ## modifying the dataframe and then
> ## using the modified version in dotplot, all in one chain?
>
> dd %>% mutate(new.proportion = las/total, new.bubble = total/100) %>%
>     dotplot(agency ~ new.proportion, pch = 16, cex = new.bubble, data = .)
> ## object 'new.bubble' not found
>
>
> dd %>% mutate(new.proportion = las/total, new.bubble = total/100) %>%
>      dotplot(agency ~ new.proportion, pch = 16, cex = .$new.bubble, data =
> .)
> ## the .$new.bubble syntax seems to work, but I've never
> ## used or seen that before, and it seems weird.
> ## Is there a "proper" syntax?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Nov  7 22:51:23 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 8 Nov 2023 00:51:23 +0300
Subject: [R] non-linear regression and root finding
In-Reply-To: <67c5ad87-6653-4d3d-be42-ba2e7aef08f7@gmail.com>
References: <eb487c2a-4b9d-4000-af86-f99de576d106@gvdnet.dk>
 <20231106211902.375d3b0a@Tarkus>
 <7990e957-6f37-4d2c-9ff0-d586f30798c6@gvdnet.dk>
 <67c5ad87-6653-4d3d-be42-ba2e7aef08f7@gmail.com>
Message-ID: <20231108005123.3dd0edb0@Tarkus>

On Mon, 6 Nov 2023 14:55:39 -0500
J C Nash <profjcnash at gmail.com> wrote:

> However, I'm wondering if this approach is worth writing up, at least
> as a vignette or blog post. It does need a shorter example and some
> explanation of the "why" and some testing perhaps.

Do you mean using this problem as a basis to illustrate ordering
constraints on parameters? Weird constraints do come up every now and
then in regression problems. I could definitely offer my help with at
least some of the text.

> If there's interest, I'll be happy to join in. And my own posting
> suggests how the ordering is enforced by bounding the "delta"
> parameters from below.

I have just tried nlsr::nlxb for a slightly larger dataset shared by
Troels off-list, and it worked great with the delta parameters as you
suggested, thank you!

It's interesting that nlxb and nlsLM give slightly different answers,
differing in 0.5 pK units for pK1 and (pK2-pK1) but not (pK3-pK2). Then
again, they both agree that the standard error for pK1 and (pK2-pK1) is
very large, so perhaps the problem is just very ill-conditioned.

-- 
Best regards,
Ivan


From cry@n @end|ng |rom b|ngh@mton@edu  Wed Nov  8 16:56:13 2023
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Wed, 8 Nov 2023 10:56:13 -0500
Subject: [R] make a lattice dotplot with symbol size proportional to a
 variable in the plotted dataframe
In-Reply-To: <CADfFDC4bns4YY7SC4mFQOsY68WQj=VFSPJAjHOU223km0vDq7w@mail.gmail.com>
References: <CAM+rpY=Mn9+osm2Ct4fNkDOKXP2zLDEa+tTkz0WB6rgzytKi5Q@mail.gmail.com>
 <CADfFDC4bns4YY7SC4mFQOsY68WQj=VFSPJAjHOU223km0vDq7w@mail.gmail.com>
Message-ID: <c479de42-706a-ca64-f330-7a4f49aa9b6b@binghamton.edu>

Very helpful, Deepayan, and educational. Thank you.

What does NSE stand for?

Thanks,
Chris

Deepayan Sarkar wrote:
> 
> --Chris Ryan


From bbo|ker @end|ng |rom gm@||@com  Wed Nov  8 16:58:59 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 8 Nov 2023 10:58:59 -0500
Subject: [R] make a lattice dotplot with symbol size proportional to a
 variable in the plotted dataframe
In-Reply-To: <c479de42-706a-ca64-f330-7a4f49aa9b6b@binghamton.edu>
References: <CAM+rpY=Mn9+osm2Ct4fNkDOKXP2zLDEa+tTkz0WB6rgzytKi5Q@mail.gmail.com>
 <CADfFDC4bns4YY7SC4mFQOsY68WQj=VFSPJAjHOU223km0vDq7w@mail.gmail.com>
 <c479de42-706a-ca64-f330-7a4f49aa9b6b@binghamton.edu>
Message-ID: <eccf2ede-8fb0-42b6-a9b4-700b30bfcdc7@gmail.com>

   Non-standard evaluation

On 2023-11-08 10:56 a.m., Christopher W. Ryan via R-help wrote:
> Very helpful, Deepayan, and educational. Thank you.
> 
> What does NSE stand for?
> 
> Thanks,
> Chris
> 
> Deepayan Sarkar wrote:
>>
>> --Chris Ryan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Wed Nov  8 17:02:22 2023
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Wed, 8 Nov 2023 11:02:22 -0500
Subject: [R] make a lattice dotplot with symbol size proportional to a
 variable in the plotted dataframe
In-Reply-To: <c479de42-706a-ca64-f330-7a4f49aa9b6b@binghamton.edu>
References: <CAM+rpY=Mn9+osm2Ct4fNkDOKXP2zLDEa+tTkz0WB6rgzytKi5Q@mail.gmail.com>
 <CADfFDC4bns4YY7SC4mFQOsY68WQj=VFSPJAjHOU223km0vDq7w@mail.gmail.com>
 <c479de42-706a-ca64-f330-7a4f49aa9b6b@binghamton.edu>
Message-ID: <CADfFDC4SpQmBtwVmOi0FAw2MT7z+5icqpp9fUDcYpAkcWw6WCQ@mail.gmail.com>

On Wed, 8 Nov 2023 at 10:56, Christopher W. Ryan via R-help
<r-help at r-project.org> wrote:
>
> Very helpful, Deepayan, and educational. Thank you.
>
> What does NSE stand for?

Non-standard evaluation, used widely in formula-interface functions as
well as the tidyverse. with() in my example is a less nuanced version
of this. See

http://adv-r.had.co.nz/Computing-on-the-language.html

https://developer.r-project.org/nonstandard-eval.pdf

Best,
-Deepayan


> Thanks,
> Chris
>
> Deepayan Sarkar wrote:
> >
> > --Chris Ryan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov  8 17:52:40 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 8 Nov 2023 08:52:40 -0800
Subject: [R] make a lattice dotplot with symbol size proportional to a
 variable in the plotted dataframe
In-Reply-To: <CADfFDC4SpQmBtwVmOi0FAw2MT7z+5icqpp9fUDcYpAkcWw6WCQ@mail.gmail.com>
References: <CAM+rpY=Mn9+osm2Ct4fNkDOKXP2zLDEa+tTkz0WB6rgzytKi5Q@mail.gmail.com>
 <CADfFDC4bns4YY7SC4mFQOsY68WQj=VFSPJAjHOU223km0vDq7w@mail.gmail.com>
 <c479de42-706a-ca64-f330-7a4f49aa9b6b@binghamton.edu>
 <CADfFDC4SpQmBtwVmOi0FAw2MT7z+5icqpp9fUDcYpAkcWw6WCQ@mail.gmail.com>
Message-ID: <CAGxFJbS3vt1_e0cQeF-aa83-YcYWReX7Z+CNinJc9rM7XD2skw@mail.gmail.com>

... and see also Section 3.5, Scope of Variables in the "R Language
Definition" manual that ships with R.

Cheers,
Bert

On Wed, Nov 8, 2023 at 8:06?AM Deepayan Sarkar <deepayan.sarkar at gmail.com>
wrote:

> On Wed, 8 Nov 2023 at 10:56, Christopher W. Ryan via R-help
> <r-help at r-project.org> wrote:
> >
> > Very helpful, Deepayan, and educational. Thank you.
> >
> > What does NSE stand for?
>
> Non-standard evaluation, used widely in formula-interface functions as
> well as the tidyverse. with() in my example is a less nuanced version
> of this. See
>
> http://adv-r.had.co.nz/Computing-on-the-language.html
>
> https://developer.r-project.org/nonstandard-eval.pdf
>
> Best,
> -Deepayan
>
>
> > Thanks,
> > Chris
> >
> > Deepayan Sarkar wrote:
> > >
> > > --Chris Ryan
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hwborcher@ @end|ng |rom gm@||@com  Thu Nov  9 06:42:51 2023
From: hwborcher@ @end|ng |rom gm@||@com (Hans W)
Date: Thu, 9 Nov 2023 06:42:51 +0100
Subject: [R] Dependency errors for package pracma
Message-ID: <CAML4n3N+UgaiFjM1uH_QFBqcLT=-+4zU2yH64OFbsh6up-yjMA@mail.gmail.com>

I tried to update my package {pracma} on CRAN from 2.4.2 (2022-09-21)
to version 2.4.4 (2023-11-08). This package reverse depends / imports
/ suggests on 350 packages on CRAN and 25 packages on Bioconductor.

The only changes are small corrections on some help files, a new
function for stereographic projection, and `gcd` and `Lcm` require
integer inputs now (these functions are not used in the packages
below).

I received a dependency report saying that
    *** Changes to worse in reverse dependencies ***
    celltrackR, geostatsp, gmvjoint, hypr, randnet

Example: geostatsp suggests pracma, but uses only the function 'trapz'
that has not changed for years and years.
I cannot check this package, as probably other packages (from
Bioconductor ?) are needed to install it.

Example: gmvjoint imports pracma and uses 'grad', 'hessian', and
'nearest_spd'; these functions have not changed for years.
On my system, gmvjoint gets checked without ERRORs !

What should I do? Frankly, I do not have the time to check these
packages or to test almost 400 packages before uploading to CRAN.
Okay, I can leave it as is and wait until it gets thrown off CRAN
(because of some new syntax checks, e.g.). I will not mind much. Are
there better alternatives?

Thanks, Hans Werner


From crown11||@me @end|ng |rom gm@||@com  Wed Nov  8 11:33:15 2023
From: crown11||@me @end|ng |rom gm@||@com (Crown Flame)
Date: Wed, 8 Nov 2023 16:03:15 +0530
Subject: [R] Problem in R code
Message-ID: <CAHoPVsd77gWDPFFCdTFPsZrGXjX0gskwef7eyBDTr+YFxMXhWw@mail.gmail.com>

Good afternoon,
I have been working on my thesis project on the topic "Urban Heat Island
Pattern in India". To achieve the results I am applying a* two-dimensional
Gaussian fit* on an LST raster of 1 km spatial resolution but I am facing
two errors in the following code.

library(raster)
LST <- raster("D:/Celsius_Day/MOD_01.tif")
gaussian2d <- function(x, y, mu_x, mu_y, sigma_x, sigma_y, amp)
{
  exp(-((x - mu_x)^2/(2*sigma_x^2) + (y - mu_y)^2/(2*sigma_y^2)))*amp
}

#define a function for the sum of squared errors between the data and the
Gaussian
sse <- function(p)
{ mu_x <- p
mu_y <- p
sigma_x <- p
sigma_y <- p
amp <- p[5]
fitted <- gaussian2d(x, y, mu_x, mu_y, sigma_x, sigma_y, amp)
sum((z - fitted)^2)
}

#loop over 8 cities
cities <-
c("Delhi","Jaipur","Kolkata","Mumbai","Pune","Hyderabad","Bangalore","Chennai")
lon <-
c(77.219934,75.793261,88.365394,72.900361,73.875199,78.47476,77.602114,80.192181)
lat <-
c(28.589256,26.892024,22.619754,19.110629,18.50269,17.422973,12.974087,13.044415)
results <- data.frame() #A data frame to store the results
for(i in 1:8)
{
  LST_city <- extract(LST, c(lon[i],lat[i]), fun = mean, buffer = 10000,
na.rm = TRUE)   #error
}

# Fit a 2D Gaussian surface to the LST data
x <- coordinates(LST)[,1]
y <- coordinates(LST)[,2]
z <- values(LST)
mu_x0 <- mean(x)
mu_y0 <- mean(y)
sigma_x0 <- sd(x)/2
sigma_y0 <- sd(y)/2
amp0 <- max(z)
opt <- optim(c(mu_x0, mu_y0, sigma_x0, sigma_y0, amp0), sse)     #error 2

#Calculate the footprint of SUHI effect (FP) by the Gaussian surface
FP <- which(gaussian2d(x, y, opt$par, opt$par, opt$par, opt$par,
opt$par[5]) >= threshold)

#store the results for each city in the data frame
results <- rbind(results, data.frame(city=cities[i], FP=mean(FP)))

#print the results
results


The two errors are in the row which are defining the variables "LST_city"
and "opt".
The first error is:
Error in .cellValues(x, y, ...) : unused arguments (fun =
new("standardGeneric", .Data = function (x, ...) standardGeneric("mean"),
generic = "mean", package = "base", group = list(), valueClass =
character(0), signature = "x", default = new("derivedDefaultMethod", .Data
= function (x, ...) UseMethod("mean"), target = new("signature", .Data =
"ANY", names = "x", package = "methods"), defined = new("signature", .Data
= "ANY", names = "x", package = "methods"), generic = "mean"), skeleton =
(new("derivedDefaultMethod", .Data = function (x, ...) UseMethod("mean"),
target = new("signature", .Data = "ANY", names = "x", package = "methods"),
defined = new("signature", .Data = "ANY", names = "x", package =
"methods"), generic = "mean"))(x, ...)), buffer = 20000, na.rm = TRUE)


The second error is:

Error in optim(c(mu_x0, mu_y0, sigma_x0, sigma_y0, amp0), sse) :
  non-finite value supplied by optim



What could be the possible reason behind these errors and most
importantly how can I get rid of these errors?



Thank you


Regards

DD

	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Thu Nov  9 09:59:12 2023
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Thu, 9 Nov 2023 09:59:12 +0100
Subject: [R] Dependency errors for package pracma
In-Reply-To: <CAML4n3N+UgaiFjM1uH_QFBqcLT=-+4zU2yH64OFbsh6up-yjMA@mail.gmail.com>
References: <CAML4n3N+UgaiFjM1uH_QFBqcLT=-+4zU2yH64OFbsh6up-yjMA@mail.gmail.com>
Message-ID: <f8899feb-eff0-07d7-cefa-b298ec1a0b8a@statistik.tu-dortmund.de>



On 09.11.2023 06:42, Hans W wrote:
> I tried to update my package {pracma} on CRAN from 2.4.2 (2022-09-21)
> to version 2.4.4 (2023-11-08). This package reverse depends / imports
> / suggests on 350 packages on CRAN and 25 packages on Bioconductor.
> 
> The only changes are small corrections on some help files, a new
> function for stereographic projection, and `gcd` and `Lcm` require
> integer inputs now (these functions are not used in the packages
> below).
> 
> I received a dependency report saying that
>      *** Changes to worse in reverse dependencies ***
>      celltrackR, geostatsp, gmvjoint, hypr, randnet

Most are from a recent Matrix update, hypr might not, so please check 
the above and tell us whether pracma casuses one of the issues (hypr?) 
and whether the maintainer has been informed in advance.

> 
> Example: geostatsp suggests pracma, but uses only the function 'trapz'
> that has not changed for years and years.
> I cannot check this package, as probably other packages (from
> Bioconductor ?) are needed to install it.
> 
> Example: gmvjoint imports pracma and uses 'grad', 'hessian', and
> 'nearest_spd'; these functions have not changed for years.
> On my system, gmvjoint gets checked without ERRORs !
> 
> What should I do? Frankly, I do not have the time to check these
> packages or to test almost 400 packages before uploading to CRAN.

The CRAN policies point you to functionality so that you can simply run 
these checks autiomatically on your machine. Let me read it for you:

"For a package update, please check that any packages depending on this 
one still pass R CMD check: it is especially expected that you will have 
checked your own packages. Reverse dependencies can conveniently be 
checked using tools::check_packages_in_dir(reverse = list()), and 
changes in check status subsequently be analyzed using 
tools::check_packages_in_dir_changes(). A listing of the reverse 
dependencies of the current version can be found on the CRAN web page 
for the package, or be obtained via tools::package_dependencies(reverse 
= TRUE). If possible, check reverse strong dependencies, reverse 
suggests and the recursive strong dependencies of these (by 
tools::package_dependencies(reverse = TRUE, which = "most", recursive = 
"strong")). "



Best,
Uwe Ligges


> Okay, I can leave it as is and wait until it gets thrown off CRAN
> (because of some new syntax checks, e.g.). I will not mind much. Are
> there better alternatives?
> 
> Thanks, Hans Werner
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |@go@g|ne @end|ng |rom @jd@e@  Thu Nov  9 11:59:44 2023
From: |@go@g|ne @end|ng |rom @jd@e@ (=?iso-8859-1?Q?Iago_Gin=E9_V=E1zquez?=)
Date: Thu, 9 Nov 2023 10:59:44 +0000
Subject: [R] Why Rprofile.site is not built with manual installation of R
 devel in linux?
Message-ID: <AM6PR02MB44230F37BC7E7A139581925F94AFA@AM6PR02MB4423.eurprd02.prod.outlook.com>

Hi all,

I downloaded R-devel as explicited in https://developer.r-project.org/SVNtips.html
Then, I tried to install it through instructions in https://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Installation
(taking into account also https://stat.ethz.ch/pipermail/r-devel/2016-May/072777.html)
So:
export REPOS=https://svn.r-project.org/R
export RTOP=~ #adjust as necessary
cd $RTOP
svn co $REPOS/trunk r-devel/R
cd r-devel/R
tools/rsync-recommended
mkdir ../build-R
 cd ../build-R
 ../R/configure --prefix=/where/you/want/R/to/go
 make
 make check
make install
make install-tests
cd tests
## followed by one of
../bin/R CMD make check
../bin/R CMD make check-devel

And here I get the following error
checking package 'base'
Error in file(filename, "r", encoding = encoding) :
  cannot open the connection
Calls: source -> file
In addition: Warning message:
In file(filename, "r", encoding = encoding) :
  cannot open file '.../etc/Rprofile.site': No such file or directory
Execution halted

where the dots ... specify the path to the build-R folder where R-devel was built. And I check the etc folder and indeed there is no the Rprofile.site
-rw-r--r-- 1 iago iago  209 Nov  9 08:27 javaconf
-rw-r--r-- 1 iago iago  770 Nov  9 08:35 ldpaths
-rw-r--r-- 1 iago iago 6672 Nov  9 08:35 Makeconf
-rw-r--r-- 1 iago iago 3336 Nov  9 08:27 Makefile
-rw-r--r-- 1 iago iago 1853 Nov  9 08:27 Renviron
-rw-r--r-- 1 iago iago 1173 Nov  9 08:32 repositories

I note that make install installed R in the path I specified in  ../R/configure --prefix=/where/you/want/R/to/go
however
    1. make install-tests installed the tests folder in build-R .
    2.  In the installed R in /where/you/want/R/to/go, there is no even etc folder, there are only the folders bin, lib and share.

Am I  skipping some step? I am on Debain 12.

Thank you!


Iago

	[[alternative HTML version deleted]]


From hwborcher@ @end|ng |rom gm@||@com  Thu Nov  9 12:22:52 2023
From: hwborcher@ @end|ng |rom gm@||@com (Hans W)
Date: Thu, 9 Nov 2023 12:22:52 +0100
Subject: [R] Dependency errors for package pracma
Message-ID: <CAML4n3PuLgFRyUdQb-24CvZo11fTEp0j7yckGLEHQrVErkdvKA@mail.gmail.com>

What really interests me:

With all those strict checking procedures, how is it possible that the
new 'Matrix' version got accepted on CRAN?

I think this happened twice to me before, and it takes a lot of time
to check package dependencies that turn out to be not dependent --
more time than checking dependencies that are real.


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Nov  9 12:59:46 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 9 Nov 2023 14:59:46 +0300
Subject: [R] Problem in R code
In-Reply-To: <CAHoPVsd77gWDPFFCdTFPsZrGXjX0gskwef7eyBDTr+YFxMXhWw@mail.gmail.com>
References: <CAHoPVsd77gWDPFFCdTFPsZrGXjX0gskwef7eyBDTr+YFxMXhWw@mail.gmail.com>
Message-ID: <20231109145946.775b142a@arachnoid>

? Wed, 8 Nov 2023 16:03:15 +0530
Crown Flame <crown11flame at gmail.com> ?????:

> for(i in 1:8)
> {
>   LST_city <- extract(LST, c(lon[i],lat[i]), fun = mean, buffer =
> 10000, na.rm = TRUE)   #error
> }

Three things you might need to change:

1. You are trying to assign the output of extract() to the same
variable LST_city in all 8 iterations of the loop. You will probably
need to make it a list and assign to the list elements, e.g.
LST_city[[i]] <- ...

It will also help to learn about lapply() and other functions that
encapsulate loops, although that is more of a matter of taste.

2. You are giving a single vector c(lon[i], lat[i]) to extract() as the
y=... argument. According to help(extract), this is interpreted as
_numbers_ of cells inside x, not coordinates. You should probably
construct a spPolygons() object and use that as the `y` argument to
extract().

3. The description of the 'raster' package says that it's been
superseded by the 'terra' package. You don't have to rewrite all your
code now, but it may be beneficial to check whether 'terra' can
accomplish what you want.

> Error in optim(c(mu_x0, mu_y0, sigma_x0, sigma_y0, amp0), sse) :
>   non-finite value supplied by optim

This must be self-explanatory: your `sse` function returns something
that is not a real number. Try options(error = recover) to see which
arguments it is given when it fails in such a manner. See the free book
"The R Inferno" for more R debugging tips
<https://www.burns-stat.com/documents/books/the-r-inferno/>. Consider
using the 'optimx' package which contains optimisation algorithms that
might work better for you.

-- 
Best regards,
Ivan


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Nov  9 14:27:37 2023
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 9 Nov 2023 14:27:37 +0100
Subject: [R] Dependency errors for package pracma
In-Reply-To: <CAML4n3PuLgFRyUdQb-24CvZo11fTEp0j7yckGLEHQrVErkdvKA@mail.gmail.com>
References: <CAML4n3PuLgFRyUdQb-24CvZo11fTEp0j7yckGLEHQrVErkdvKA@mail.gmail.com>
Message-ID: <25932.56905.565988.452850@stat.math.ethz.ch>

>>>>> Hans W 
>>>>>     on Thu, 9 Nov 2023 12:22:52 +0100 writes:

    > What really interests me:
    > With all those strict checking procedures, how is it possible that the
    > new 'Matrix' version got accepted on CRAN?

There > 2000 reverse dependencies for Matrix.

We have had some (in themselves small) inconsistency fixes some
of which make Matrix 'Matrices' more similar to base R matrices.

In any case we pre-tested all reverse dependencies and found 7 or 8
out of 22'000 CRAN+Bioc packages which needed to adapt to the
Matrix changes.  The package maintainer of the 7 packages were
told in advance that they should (very slightly) adapt their
code (sometimes only there *tests*) and mostly were even handed
out a *patch* to apply to the respective package for updating it.
One or two of these packages were updated on CRAN in time, the
other ~ 5 were not... this is  ~ 1 in 4000 packages.  So the
decision was made to release (from us pkg maintainers) and to
accept (from the CRAN team).

Also, to be fair, in our tests we did miss one package,
but then quickly told the maintainer, again providing him with a
complete patch file to update the package (working both with old
and new Matrix).

    > I think this happened twice to me before, and it takes a lot of time
    > to check package dependencies that turn out to be not dependent --
    > more time than checking dependencies that are real.

With Matrix there is some extra effort, because it also exports
a C API (so other packages can have  'LinkingTo: Matrix') and
this time it was necessary for CRAN to additionally re-install
those linking-reverse-dependent packages .. on all platforms, in
time, etc. a somewhat brittle task all with a CRAN check system
that simultaneously runs other package installations and checks.

I think you were slightly unlucky in the timing of your package
checks/submission.

Best regards,
Martin


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Nov  9 21:08:07 2023
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 09 Nov 2023 12:08:07 -0800
Subject: [R] 
 Why Rprofile.site is not built with manual installation of R
 devel in linux?
In-Reply-To: <AM6PR02MB44230F37BC7E7A139581925F94AFA@AM6PR02MB4423.eurprd02.prod.outlook.com>
References: <AM6PR02MB44230F37BC7E7A139581925F94AFA@AM6PR02MB4423.eurprd02.prod.outlook.com>
Message-ID: <205A4E17-50C5-45F0-8D91-F400C1B89E6E@dcn.davis.ca.us>

No clue. Tip: R-devel is the mailing list for anything related to development versions of R. Off-topic here.

On November 9, 2023 2:59:44 AM PST, "Iago Gin? V?zquez" <iago.gine at sjd.es> wrote:
>Hi all,
>
>I downloaded R-devel as explicited in https://developer.r-project.org/SVNtips.html
>Then, I tried to install it through instructions in https://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Installation
>(taking into account also https://stat.ethz.ch/pipermail/r-devel/2016-May/072777.html)
>So:
>export REPOS=https://svn.r-project.org/R
>export RTOP=~ #adjust as necessary
>cd $RTOP
>svn co $REPOS/trunk r-devel/R
>cd r-devel/R
>tools/rsync-recommended
>mkdir ../build-R
> cd ../build-R
> ../R/configure --prefix=/where/you/want/R/to/go
> make
> make check
>make install
>make install-tests
>cd tests
>## followed by one of
>../bin/R CMD make check
>../bin/R CMD make check-devel
>
>And here I get the following error
>checking package 'base'
>Error in file(filename, "r", encoding = encoding) :
>  cannot open the connection
>Calls: source -> file
>In addition: Warning message:
>In file(filename, "r", encoding = encoding) :
>  cannot open file '.../etc/Rprofile.site': No such file or directory
>Execution halted
>
>where the dots ... specify the path to the build-R folder where R-devel was built. And I check the etc folder and indeed there is no the Rprofile.site
>-rw-r--r-- 1 iago iago  209 Nov  9 08:27 javaconf
>-rw-r--r-- 1 iago iago  770 Nov  9 08:35 ldpaths
>-rw-r--r-- 1 iago iago 6672 Nov  9 08:35 Makeconf
>-rw-r--r-- 1 iago iago 3336 Nov  9 08:27 Makefile
>-rw-r--r-- 1 iago iago 1853 Nov  9 08:27 Renviron
>-rw-r--r-- 1 iago iago 1173 Nov  9 08:32 repositories
>
>I note that make install installed R in the path I specified in  ../R/configure --prefix=/where/you/want/R/to/go
>however
>    1. make install-tests installed the tests folder in build-R .
>    2.  In the installed R in /where/you/want/R/to/go, there is no even etc folder, there are only the folders bin, lib and share.
>
>Am I  skipping some step? I am on Debain 12.
>
>Thank you!
>
>
>Iago
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@oknz @end|ng |rom gm@||@com  Fri Nov 10 09:01:20 2023
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 10 Nov 2023 21:01:20 +1300
Subject: [R] strptime with +03:00 zone designator
In-Reply-To: <25928.43905.917277.897930@stat.math.ethz.ch>
References: <CABcYAd+CTsSRuay3uE0S-k5k+uLvjZX=ZWuy2P6sCbFzkbFmtg@mail.gmail.com>
 <CAAxdm-666SwXzBgKJEn-HWphspbWDb2ycyVzdAbvD+oX16xRVA@mail.gmail.com>
 <CABcYAdJpMibwW7Qjm_0A2D+1H=ddvow6S12RaKRUx-frR210tg@mail.gmail.com>
 <CABcYAd+y6v7YTOtE0QrDciNNSpGZb22MFqsWA=xB+e1-q-QcLg@mail.gmail.com>
 <25928.43905.917277.897930@stat.math.ethz.ch>
Message-ID: <CABcYAd+pvgu1RJVvOZSCxoovL8Xrmt=-AET-cKhbEgDeVR4O6w@mail.gmail.com>

(1) I hadn't tried to submit a bug report because (a) I wasn't sure
that it was an actual limitation in strptime() and not my ignorance or
stupidity and (b) I didn't actually know how to submit a bug report.
> bug.report(package = "base")
brings up a web page.  Clicking on "File a Bug" takes me to another page,
https://bugs.r-project.org/enter_bug.cgi
which says "
Bugzilla needs a legitimate login and password to continue
" and I don't have a login or a password for this.  The process is
more hassle than I really wanted to go through. Oh well, I'd better do
the thing properly.

(2) The relevant aspect of the ISO 8601 standard has been stable since
1988.  There are two ways to display any time thingy, a basic format
(where NONE of the optional separators are present) and an extended
format (where ALL of the optional separators are present).  There's no
half-and-half form.

On Mon, 6 Nov 2023 at 22:01, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Richard O'Keefe
> >>>>>     on Mon, 6 Nov 2023 18:37:34 +1300 writes:
>
>     > Thanks to all who replied.  On Mon, 6 Nov 2023 at 18:37,
>     > Richard O'Keefe <raoknz at gmail.com> wrote:
>
>     >> OK, so the consensus is (1) One cannot make strptime
>     >> accept ISO8601-compliant zone designators (2) The
>     >> lubridate package can (3) Or one can hack away with
>     >> regex.  Lubridate it is, then.
>     >>
>     >> But I do regard strptime's inability to process
>     >> ISO8601-compliant zone designators as a bug.
>
> Did you try to submit it to R's bugzilla?
>
> It's the first time I hear of this "Feature" of the ISO
> standard, but then I'm not at all a timezone, and even less an
> ISO standard expert.
>
> Best,
> Martin
>
>
>     >> On Mon, 6 Nov 2023 at 13:18, jim holtman
>     >> <jholtman at gmail.com> wrote:
>     >>
>     >>> try using 'lubridate'
>     >>>
>     >>> > library(lubridate)Attaching package: ?lubridate?
>     >>>
>     >>> The following objects are masked from ?package:base?:
>     >>>
>     >>> date, intersect, setdiff, union > x <-
>     >>> "2017-02-28T13:35:00+03:00"> ymd_hms(x)[1] "2017-02-28
>     >>> 10:35:00 UTC"
>     >>>
>     >>> >
>     >>>
>     >>>
>     >>>
>     >>> Thanks
>     >>>
>     >>> Jim Holtman *Data Munger Guru*
>     >>>
>     >>>
>     >>> *What is the problem that you are trying to solve?Tell
>     >>> me what you want to do, not how you want to do it.*
>     >>>
>     >>>
>     >>> On Sun, Nov 5, 2023 at 3:45?PM Richard O'Keefe
>     >>> <raoknz at gmail.com> wrote:
>     >>>
>     >>>> I have some data that includes timestamps like this:
>     >>>> 2017-02-28T13:35:00+03:00 The documentation for
>     >>>> strptime says that %z expects an offset like 0300.  I
>     >>>> don't see any way in the documentation to get it to
>     >>>> accept +hh:mm with a colon separator, and everything I
>     >>>> tried gave me NA as the answer.
>     >>>>
>     >>>> Section 4.2.5.1 of ISO 8601:2004(E) allows both the
>     >>>> absence of colons in +hh[mm] (basic format) and the
>     >>>> presence of colons in +hh:mm (extended format).  Again
>     >>>> in section 4.2.5.2 where a zone offset is combined with
>     >>>> a time of day: if you have hh:mm:ss you are using
>     >>>> extended format and the offset MUST have a colon; if
>     >>>> you have hhmmss you are using basic format and the
>     >>>> offset MUST NOT have a colon.  And again in section
>     >>>> 4.3.2 (complete representations of date and time of
>     >>>> day).  If you use hyphens and colons in the date and
>     >>>> time part you MUST have a colon in the zone designator.
>     >>>>
>     >>>> So I am dealing with timestamps in strict ISO 8601
>     >>>> complete extended representation, and it is rather
>     >>>> frustrating that strptime doesn't deal with it simply.
>     >>>>
>     >>>> The simplest thing would be for R's own version of
>     >>>> strptime to allow an optional colon between the hour
>     >>>> digits and the minute digits of a zone designator.
>     >>>>
>     >>>> I'm about to clone the data source and edit it to
>     >>>> remove the colons, but is there something obvious I am
>     >>>> missing?
>     >>>>
>     >>>> ______________________________________________
>     >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     >>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     >>>> PLEASE do read the posting guide
>     >>>> http://www.R-project.org/posting-guide.html and provide
>     >>>> commented, minimal, self-contained, reproducible code.
>     >>>>
>     >>>
>
>     >   [[alternative HTML version deleted]]
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     > more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html and provide
>     > commented, minimal, self-contained, reproducible code.


From |kw@|mmo @end|ng |rom gm@||@com  Fri Nov 10 09:43:40 2023
From: |kw@|mmo @end|ng |rom gm@||@com (Iris Simmons)
Date: Fri, 10 Nov 2023 03:43:40 -0500
Subject: [R] Calling Emacs Lisp Code/Function from R
Message-ID: <CADNULg_3vytsPFkWJTuXgwC9HNtZ7sJFcX=TX=kqHvSvoZjFgw@mail.gmail.com>

Hi,


I'm using R in Emacs and I'm interested in programatically knowing the
details of all opened buffers; details such a buffer name, size, mode,
and possibly associated filename. I've been able to write such a
function in Emacs Lisp, but now I'd like to be able to call that
function from R, or if that's not possible then calling it from C
would be fine.

Does anyone know if this is possible? And if so, could you perhaps
direct me towards an existing R package or program that calls an Emacs
Lisp function from R that I could use as a guide?


Thank you!
    Iris


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Nov 10 11:18:12 2023
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 10 Nov 2023 05:18:12 -0500
Subject: [R] Calling Emacs Lisp Code/Function from R
In-Reply-To: <CADNULg_3vytsPFkWJTuXgwC9HNtZ7sJFcX=TX=kqHvSvoZjFgw@mail.gmail.com>
References: <CADNULg_3vytsPFkWJTuXgwC9HNtZ7sJFcX=TX=kqHvSvoZjFgw@mail.gmail.com>
Message-ID: <6b5a51f6-af79-4382-97bd-4185f9dcd6f8@gmail.com>

I'm not an Emacs user, but the ESS-help mailing list (see 
ess.r-project.org) might be able to help with this.

Duncan Murdoch

On 10/11/2023 3:43 a.m., Iris Simmons wrote:
> Hi,
> 
> 
> I'm using R in Emacs and I'm interested in programatically knowing the
> details of all opened buffers; details such a buffer name, size, mode,
> and possibly associated filename. I've been able to write such a
> function in Emacs Lisp, but now I'd like to be able to call that
> function from R, or if that's not possible then calling it from C
> would be fine.
> 
> Does anyone know if this is possible? And if so, could you perhaps
> direct me towards an existing R package or program that calls an Emacs
> Lisp function from R that I could use as a guide?
> 
> 
> Thank you!
>      Iris
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rt|n@@@gregory @end|ng |rom |c|oud@com  Fri Nov 10 12:12:39 2023
From: m@rt|n@@@gregory @end|ng |rom |c|oud@com (Martin Gregory)
Date: Fri, 10 Nov 2023 12:12:39 +0100
Subject: [R] Calling Emacs Lisp Code/Function from R
In-Reply-To: <6b5a51f6-af79-4382-97bd-4185f9dcd6f8@gmail.com>
References: <CADNULg_3vytsPFkWJTuXgwC9HNtZ7sJFcX=TX=kqHvSvoZjFgw@mail.gmail.com>
 <6b5a51f6-af79-4382-97bd-4185f9dcd6f8@gmail.com>
Message-ID: <392e4973-651f-425d-a0a2-2828d2d3347f@icloud.com>

Hi,

if you run a server in your Emacs session you can use emacsclient to 
send a lisp call to the server. There's an example here:

https://emacs.stackexchange.com/questions/54156/how-can-i-query-emacs-from-a-separate-process/54161#54161

Regards,
Martin Gregory

On 11/10/23 11:18, Duncan Murdoch wrote:
> I'm not an Emacs user, but the ESS-help mailing list (see 
> ess.r-project.org) might be able to help with this.
> 
> Duncan Murdoch
> 
> On 10/11/2023 3:43 a.m., Iris Simmons wrote:
>> Hi,
>>
>>
>> I'm using R in Emacs and I'm interested in programatically knowing the
>> details of all opened buffers; details such a buffer name, size, mode,
>> and possibly associated filename. I've been able to write such a
>> function in Emacs Lisp, but now I'd like to be able to call that
>> function from R, or if that's not possible then calling it from C
>> would be fine.
>>
>> Does anyone know if this is possible? And if so, could you perhaps
>> direct me towards an existing R package or program that calls an Emacs
>> Lisp function from R that I could use as a guide?
>>
>>
>> Thank you!
>> ???? Iris
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |kw@|mmo @end|ng |rom gm@||@com  Sun Nov 12 09:56:24 2023
From: |kw@|mmo @end|ng |rom gm@||@com (Iris Simmons)
Date: Sun, 12 Nov 2023 03:56:24 -0500
Subject: [R] Calling Emacs Lisp Code/Function from R
In-Reply-To: <392e4973-651f-425d-a0a2-2828d2d3347f@icloud.com>
References: <CADNULg_3vytsPFkWJTuXgwC9HNtZ7sJFcX=TX=kqHvSvoZjFgw@mail.gmail.com>
 <6b5a51f6-af79-4382-97bd-4185f9dcd6f8@gmail.com>
 <392e4973-651f-425d-a0a2-2828d2d3347f@icloud.com>
Message-ID: <CADNULg-fVWh4W6Zt_yvTRvz0QsRS=O1h9vtz06G6OJr-EtBtvQ@mail.gmail.com>

Hi,


Thank you Duncan, I will check with that other mailing list to see if
they can guide me.
And thank you Martin, I was able to implement what I wanted using the
example you sent.

On Fri, Nov 10, 2023 at 6:55?AM Martin Gregory via R-help
<r-help at r-project.org> wrote:
>
> Hi,
>
> if you run a server in your Emacs session you can use emacsclient to
> send a lisp call to the server. There's an example here:
>
> https://emacs.stackexchange.com/questions/54156/how-can-i-query-emacs-from-a-separate-process/54161#54161
>
> Regards,
> Martin Gregory
>
> On 11/10/23 11:18, Duncan Murdoch wrote:
> > I'm not an Emacs user, but the ESS-help mailing list (see
> > ess.r-project.org) might be able to help with this.
> >
> > Duncan Murdoch
> >
> > On 10/11/2023 3:43 a.m., Iris Simmons wrote:
> >> Hi,
> >>
> >>
> >> I'm using R in Emacs and I'm interested in programatically knowing the
> >> details of all opened buffers; details such a buffer name, size, mode,
> >> and possibly associated filename. I've been able to write such a
> >> function in Emacs Lisp, but now I'd like to be able to call that
> >> function from R, or if that's not possible then calling it from C
> >> would be fine.
> >>
> >> Does anyone know if this is possible? And if so, could you perhaps
> >> direct me towards an existing R package or program that calls an Emacs
> >> Lisp function from R that I could use as a guide?
> >>
> >>
> >> Thank you!
> >>      Iris
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @@h|mk@poor @end|ng |rom gm@||@com  Tue Nov 14 05:33:23 2023
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Tue, 14 Nov 2023 10:03:23 +0530
Subject: [R] Can someone please have a look at this query on stackoverflow?
Message-ID: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>

Dear all,

I have posted a query which has received a response but that is not
working on my computer.

Here is the query:

https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169

Can someone please help me ?

Best Regards,
Ashim


From jrkr|de@u @end|ng |rom gm@||@com  Tue Nov 14 12:44:33 2023
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Tue, 14 Nov 2023 06:44:33 -0500
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
Message-ID: <CAKZQJMDcVLv8XoYtj9TO5Y-Jr81fbisM-Yv9TPC5f65N2oLc=A@mail.gmail.com>

I ran the code from the answer and it seems to work well. It, definitely,
is giving a landscape output.

---
title: "Testing landscape and aspect ratio"
output:
  pdf_document:
    number_sections: true
classoption:
  - landscape
  - "aspectratio=169"
header-includes:
   - \usepackage{dcolumn}
documentclass: article
geometry: margin=1.5cm---

```{r, out.extra='keepaspectratio=true', out.height='100%', out.width="100%"}
plot(rnorm(100))
```




On Mon, 13 Nov 2023 at 23:33, Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear all,
>
> I have posted a query which has received a response but that is not
> working on my computer.
>
> Here is the query:
>
>
> https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
>
> Can someone please help me ?
>
> Best Regards,
> Ashim
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

-------------- next part --------------
A non-text attachment was scrubbed...
Name: landscape.pdf
Type: application/pdf
Size: 80961 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20231114/ae3a6895/attachment.pdf>

From @@h|mk@poor @end|ng |rom gm@||@com  Wed Nov 15 05:47:32 2023
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Wed, 15 Nov 2023 10:17:32 +0530
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <CAKZQJMDcVLv8XoYtj9TO5Y-Jr81fbisM-Yv9TPC5f65N2oLc=A@mail.gmail.com>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <CAKZQJMDcVLv8XoYtj9TO5Y-Jr81fbisM-Yv9TPC5f65N2oLc=A@mail.gmail.com>
Message-ID: <CAC8=1epUTr-4vs5rfp30F8UNeGA-yfsh8SPaxDHNDGYw7hUAAA@mail.gmail.com>

Dear John,

Many thanks for your reply.

I wish 2 things :
1. Landscape mode
2. No wasted space on the sides when I maximise the pdf.

When I download an open and maximise the pdf it wastes space. Please
see the attached screenshot.

Query: When you maximise the PDF does it occupy the full screen ?

Best,
Ashim

On Tue, Nov 14, 2023 at 5:14?PM John Kane <jrkrideau at gmail.com> wrote:
>
> I ran the code from the answer and it seems to work well. It, definitely, is giving a landscape output.
>
> ---
> title: "Testing landscape and aspect ratio"
> output:
>   pdf_document:
>     number_sections: true
> classoption:
>   - landscape
>   - "aspectratio=169"
> header-includes:
>    - \usepackage{dcolumn}
> documentclass: article
> geometry: margin=1.5cm
> ---
>
> ```{r, out.extra='keepaspectratio=true', out.height='100%', out.width="100%"}
> plot(rnorm(100))
> ```
>
>
>
>
> On Mon, 13 Nov 2023 at 23:33, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>>
>> Dear all,
>>
>> I have posted a query which has received a response but that is not
>> working on my computer.
>>
>> Here is the query:
>>
>> https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
>>
>> Can someone please help me ?
>>
>> Best Regards,
>> Ashim
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> John Kane
> Kingston ON Canada

-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 68065 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20231115/f93d7439/attachment.png>

From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 15 18:02:18 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 15 Nov 2023 09:02:18 -0800
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <CAC8=1epUTr-4vs5rfp30F8UNeGA-yfsh8SPaxDHNDGYw7hUAAA@mail.gmail.com>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <CAKZQJMDcVLv8XoYtj9TO5Y-Jr81fbisM-Yv9TPC5f65N2oLc=A@mail.gmail.com>
 <CAC8=1epUTr-4vs5rfp30F8UNeGA-yfsh8SPaxDHNDGYw7hUAAA@mail.gmail.com>
Message-ID: <CAGxFJbSS1CV=zdnXVh116+7wXzb5JSy2CYTkvNvudKOenkaz1g@mail.gmail.com>

Well, as no one else has offered an answer ...

I haven't looked at this closely, but could it not simply be the case that
the aspect ratio set by "Landscape Mode" just differs from that of your
display device? -- i.e., it is impossible to have the figure displayed in
landscape ratio *and* simultaneously fill your display device?

If this is obviously wrong, feel free to ignore without replying.

Cheers,
Bert

On Tue, Nov 14, 2023 at 8:48?PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear John,
>
> Many thanks for your reply.
>
> I wish 2 things :
> 1. Landscape mode
> 2. No wasted space on the sides when I maximise the pdf.
>
> When I download an open and maximise the pdf it wastes space. Please
> see the attached screenshot.
>
> Query: When you maximise the PDF does it occupy the full screen ?
>
> Best,
> Ashim
>
> On Tue, Nov 14, 2023 at 5:14?PM John Kane <jrkrideau at gmail.com> wrote:
> >
> > I ran the code from the answer and it seems to work well. It,
> definitely, is giving a landscape output.
> >
> > ---
> > title: "Testing landscape and aspect ratio"
> > output:
> >   pdf_document:
> >     number_sections: true
> > classoption:
> >   - landscape
> >   - "aspectratio=169"
> > header-includes:
> >    - \usepackage{dcolumn}
> > documentclass: article
> > geometry: margin=1.5cm
> > ---
> >
> > ```{r, out.extra='keepaspectratio=true', out.height='100%',
> out.width="100%"}
> > plot(rnorm(100))
> > ```
> >
> >
> >
> >
> > On Mon, 13 Nov 2023 at 23:33, Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
> >>
> >> Dear all,
> >>
> >> I have posted a query which has received a response but that is not
> >> working on my computer.
> >>
> >> Here is the query:
> >>
> >>
> https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
> >>
> >> Can someone please help me ?
> >>
> >> Best Regards,
> >> Ashim
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > John Kane
> > Kingston ON Canada
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 15 18:06:51 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 15 Nov 2023 09:06:51 -0800
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <CAGxFJbSS1CV=zdnXVh116+7wXzb5JSy2CYTkvNvudKOenkaz1g@mail.gmail.com>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <CAKZQJMDcVLv8XoYtj9TO5Y-Jr81fbisM-Yv9TPC5f65N2oLc=A@mail.gmail.com>
 <CAC8=1epUTr-4vs5rfp30F8UNeGA-yfsh8SPaxDHNDGYw7hUAAA@mail.gmail.com>
 <CAGxFJbSS1CV=zdnXVh116+7wXzb5JSy2CYTkvNvudKOenkaz1g@mail.gmail.com>
Message-ID: <CAGxFJbS+b7KxwsR0x4r2M7YA8k=wdXk+9e8jASWNeUjAxJ=STA@mail.gmail.com>

... and note also that there may be clipping options you can change/set to
approximate your desiderata.

-- Bert

On Wed, Nov 15, 2023 at 9:02?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Well, as no one else has offered an answer ...
>
> I haven't looked at this closely, but could it not simply be the case that
> the aspect ratio set by "Landscape Mode" just differs from that of your
> display device? -- i.e., it is impossible to have the figure displayed in
> landscape ratio *and* simultaneously fill your display device?
>
> If this is obviously wrong, feel free to ignore without replying.
>
> Cheers,
> Bert
>
> On Tue, Nov 14, 2023 at 8:48?PM Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
>
>> Dear John,
>>
>> Many thanks for your reply.
>>
>> I wish 2 things :
>> 1. Landscape mode
>> 2. No wasted space on the sides when I maximise the pdf.
>>
>> When I download an open and maximise the pdf it wastes space. Please
>> see the attached screenshot.
>>
>> Query: When you maximise the PDF does it occupy the full screen ?
>>
>> Best,
>> Ashim
>>
>> On Tue, Nov 14, 2023 at 5:14?PM John Kane <jrkrideau at gmail.com> wrote:
>> >
>> > I ran the code from the answer and it seems to work well. It,
>> definitely, is giving a landscape output.
>> >
>> > ---
>> > title: "Testing landscape and aspect ratio"
>> > output:
>> >   pdf_document:
>> >     number_sections: true
>> > classoption:
>> >   - landscape
>> >   - "aspectratio=169"
>> > header-includes:
>> >    - \usepackage{dcolumn}
>> > documentclass: article
>> > geometry: margin=1.5cm
>> > ---
>> >
>> > ```{r, out.extra='keepaspectratio=true', out.height='100%',
>> out.width="100%"}
>> > plot(rnorm(100))
>> > ```
>> >
>> >
>> >
>> >
>> > On Mon, 13 Nov 2023 at 23:33, Ashim Kapoor <ashimkapoor at gmail.com>
>> wrote:
>> >>
>> >> Dear all,
>> >>
>> >> I have posted a query which has received a response but that is not
>> >> working on my computer.
>> >>
>> >> Here is the query:
>> >>
>> >>
>> https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
>> >>
>> >> Can someone please help me ?
>> >>
>> >> Best Regards,
>> >> Ashim
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>> > --
>> > John Kane
>> > Kingston ON Canada
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @@|k@tdutt@chowdhury @end|ng |rom gm@||@com  Wed Nov 15 19:24:51 2023
From: @@|k@tdutt@chowdhury @end|ng |rom gm@||@com (Saikat Dutta Chowdhury)
Date: Wed, 15 Nov 2023 23:54:51 +0530
Subject: [R] kindly unsubscribe
Message-ID: <CAHqQAzWQ3WiqSO0kp=ZG8QN_iKnKcDtHyf1J7YjA1ey5uWL_2Q@mail.gmail.com>

-- 
Saikat Dutta Chowdhury
Mobile: 8017650842

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 15 19:31:23 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 15 Nov 2023 10:31:23 -0800
Subject: [R] kindly unsubscribe
In-Reply-To: <CAHqQAzWQ3WiqSO0kp=ZG8QN_iKnKcDtHyf1J7YjA1ey5uWL_2Q@mail.gmail.com>
References: <CAHqQAzWQ3WiqSO0kp=ZG8QN_iKnKcDtHyf1J7YjA1ey5uWL_2Q@mail.gmail.com>
Message-ID: <CAGxFJbRrBf5iL7BdWX3j7i2WuZzJV_bvmHn5q=YbTiTNhduGEg@mail.gmail.com>

Please see the bottom of this and every message for the link to unsubscribe.

-- Bert

On Wed, Nov 15, 2023 at 10:25?AM Saikat Dutta Chowdhury <
saikatduttachowdhury at gmail.com> wrote:

> --
> Saikat Dutta Chowdhury
> Mobile: 8017650842
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cry@n @end|ng |rom b|ngh@mton@edu  Wed Nov 15 20:13:00 2023
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Wed, 15 Nov 2023 14:13:00 -0500
Subject: [R] anyone having trouble accesing CRAN?
Message-ID: <824e958a-e563-8e7e-8b6d-9ea245460d63@binghamton.edu>

at https://cran.r-project.org/ I get this error message:

=====================
Secure Connection Failed

An error occurred during a connection to cran.r-project.org.
PR_END_OF_FILE_ERROR

Error code: PR_END_OF_FILE_ERROR

    The page you are trying to view cannot be shown because the
authenticity of the received data could not be verified.
=======================

Three different browsers, two different devices, two different networks.
(The text of the error messages varies.)

Anyone seeing similar?

Thanks.

--Chris Ryan


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov 15 20:21:31 2023
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 15 Nov 2023 14:21:31 -0500
Subject: [R] anyone having trouble accesing CRAN?
In-Reply-To: <824e958a-e563-8e7e-8b6d-9ea245460d63@binghamton.edu>
References: <824e958a-e563-8e7e-8b6d-9ea245460d63@binghamton.edu>
Message-ID: <2d67c894-8871-4e76-ae8d-72daa646d177@gmail.com>

Yes, they posted a message about this recently.  There's some 
maintenance happening and CRAN will be unavailable for a while.  I can't 
find that message, but I think it was 2 or 3 days of downtime.

Duncan Murdoch

On 15/11/2023 2:13 p.m., Christopher W. Ryan via R-help wrote:
> at https://cran.r-project.org/ I get this error message:
> 
> =====================
> Secure Connection Failed
> 
> An error occurred during a connection to cran.r-project.org.
> PR_END_OF_FILE_ERROR
> 
> Error code: PR_END_OF_FILE_ERROR
> 
>      The page you are trying to view cannot be shown because the
> authenticity of the received data could not be verified.
> =======================
> 
> Three different browsers, two different devices, two different networks.
> (The text of the error messages varies.)
> 
> Anyone seeing similar?
> 
> Thanks.
> 
> --Chris Ryan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Nov 15 20:23:32 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 15 Nov 2023 22:23:32 +0300
Subject: [R] anyone having trouble accesing CRAN?
In-Reply-To: <824e958a-e563-8e7e-8b6d-9ea245460d63@binghamton.edu>
References: <824e958a-e563-8e7e-8b6d-9ea245460d63@binghamton.edu>
Message-ID: <20231115222332.7746cad7@Tarkus>

On Wed, 15 Nov 2023 14:13:00 -0500
"Christopher W. Ryan via R-help" <r-help at r-project.org> wrote:

> Anyone seeing similar?

Same for me.

While it worked, CRAN website had the following message:

>> The CRAN Admin Team will perform system upgrades during the period
>> Wednesday November 15 until Thursday November 16, 2023. There will
>> be intermittent outages in service during this time. 

Use chooseCRANmirror(local.only = TRUE) (or subset() the return value
of getCRANmirrors(local.only = TRUE)) to access a mirror that works.

-- 
Best regards,
Ivan


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Nov 15 20:25:25 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 15 Nov 2023 19:25:25 +0000
Subject: [R] anyone having trouble accesing CRAN?
In-Reply-To: <824e958a-e563-8e7e-8b6d-9ea245460d63@binghamton.edu>
References: <824e958a-e563-8e7e-8b6d-9ea245460d63@binghamton.edu>
Message-ID: <95795680-62d8-44de-8897-4391ad8f865c@sapo.pt>

?s 19:13 de 15/11/2023, Christopher W. Ryan via R-help escreveu:
> at https://cran.r-project.org/ I get this error message:
> 
> =====================
> Secure Connection Failed
> 
> An error occurred during a connection to cran.r-project.org.
> PR_END_OF_FILE_ERROR
> 
> Error code: PR_END_OF_FILE_ERROR
> 
>      The page you are trying to view cannot be shown because the
> authenticity of the received data could not be verified.
> =======================
> 
> Three different browsers, two different devices, two different networks.
> (The text of the error messages varies.)
> 
> Anyone seeing similar?
> 
> Thanks.
> 
> --Chris Ryan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Yes, CRAN is down.

I know last week there was an anouncement about a maintenance scheduled 
but I cannot place that e-mail right now and don't remember the date 
exactly so I cannot say for sure this is what is happening.

But it is probably a scheduled maintenance.

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From cry@n @end|ng |rom b|ngh@mton@edu  Wed Nov 15 20:38:09 2023
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Wed, 15 Nov 2023 14:38:09 -0500
Subject: [R] anyone having trouble accesing CRAN?
In-Reply-To: <20231115222332.7746cad7@Tarkus>
References: <824e958a-e563-8e7e-8b6d-9ea245460d63@binghamton.edu>
 <20231115222332.7746cad7@Tarkus>
Message-ID: <86bd770e-f526-496b-0977-02d77afe9f29@binghamton.edu>

Ah, thanks all. Guess I missed the message before they started the
maintenance.

--Chris

Ivan Krylov wrote:
> On Wed, 15 Nov 2023 14:13:00 -0500
> "Christopher W. Ryan via R-help" <r-help at r-project.org> wrote:
> 
>> Anyone seeing similar?
> 
> Same for me.
> 
> While it worked, CRAN website had the following message:
> 
>>> The CRAN Admin Team will perform system upgrades during the period
>>> Wednesday November 15 until Thursday November 16, 2023. There will
>>> be intermittent outages in service during this time. 
> 
> Use chooseCRANmirror(local.only = TRUE) (or subset() the return value
> of getCRANmirrors(local.only = TRUE)) to access a mirror that works.
>


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed Nov 15 21:53:54 2023
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 15 Nov 2023 20:53:54 +0000 (UTC)
Subject: [R] Cannot calculate confidence intervals NULL
References: <1916173554.6401526.1700081634822.ref@mail.yahoo.com>
Message-ID: <1916173554.6401526.1700081634822@mail.yahoo.com>

R-Experts,

Here below my R code working without error message but I don't get the results I am expecting.
Here is the result I get:

[1] "All values of t are equal to 0.28611928397257 \n Cannot calculate confidence intervals"
NULL

If someone knows how to solve my problem, really appreciate.
Best,
S


#########################################################
# Difference in Spearman rho?

library(boot)
?
x1=c(4,6,5,7,8,4,2,3,5.5,6.7,5.5,3.5,2,1,3,5,6,3.5,2.5,2,1,2,3,2,1,2,3,4,3,4)
?
y1=c(10,14,12.5,21,15,16,17.5,11,11.5,21,19,16,17.5,18,18.5,12,13,14,11,11,12,18,20,13,23,12,11,14,16,11)
?
x2=c(5,3,4,2,1,1,1,2,3,4,5,4,3,2,1,3,4.5,4.5,5.5,6,5,4,7,8,3,4,2,5,4,3)
?
y2=c(11,12,13,11,10,19,21,21,13,15,18,13,12,14,19,18.5,17.5,12.5,10,9,11,13,14,16,11,18,14,13,12,12)
?
# Function to calculate the difference in Spearman coefficients
pearson_diff <- function(data, indices) {
?
# Sample the data
? d <- data[indices, ]
?
?# Calculate the Spearman correlation coefficients for every sample
? cor1 <- cor(x1, y1, method="spearman")
? cor2 <- cor(x2, y2, method="spearman")
?
# Return the difference
? return(cor1 - cor2)
}
?
# Create a data.frame with the data
data <- data.frame(x1, y1, x2, y2)
?
# Use the boot function to apply the bootstrap
set.seed(123) # For reproducibility
bootstrap_results <- boot(data = data, statistic = pearson_diff, R = 1000)
?
# Calculate all the 95% confidence interval
boot.ci(bootstrap_results, type = "all")
###############################################################
?


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Nov 15 22:18:55 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 16 Nov 2023 00:18:55 +0300
Subject: [R] Cannot calculate confidence intervals NULL
In-Reply-To: <1916173554.6401526.1700081634822@mail.yahoo.com>
References: <1916173554.6401526.1700081634822.ref@mail.yahoo.com>
 <1916173554.6401526.1700081634822@mail.yahoo.com>
Message-ID: <20231116001855.2d81c592@Tarkus>

On Wed, 15 Nov 2023 20:53:54 +0000 (UTC)
varin sacha via R-help <r-help at r-project.org> wrote:

> # Sample the data
> ? d <- data[indices, ]
> ?
> ?# Calculate the Spearman correlation coefficients for every sample
> ? cor1 <- cor(x1, y1, method="spearman")
> ? cor2 <- cor(x2, y2, method="spearman")

You're sampling the data into the `d` variable, but then you use the
original `x1`, `y1`, `x2`, `y2` variables unchanged. You need to access
the columns in `d` instead.

-- 
Best regards,
Ivan


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 15 22:21:40 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 15 Nov 2023 13:21:40 -0800
Subject: [R] Cannot calculate confidence intervals NULL
In-Reply-To: <1916173554.6401526.1700081634822@mail.yahoo.com>
References: <1916173554.6401526.1700081634822.ref@mail.yahoo.com>
 <1916173554.6401526.1700081634822@mail.yahoo.com>
Message-ID: <CAGxFJbRFJ_HOmuvZ2XCHA00H974J8E7h3uGwdAcHjpdC1feyBw@mail.gmail.com>

I believe the problem is here:

cor1 <- cor(x1, y1, method="spearman")
 cor2 <- cor(x2, y2, method="spearman")

The x's and y's are not looked for in data (i.e. NSE) but in the
environment where the function was defined, which is standard evaluation.
Change the above to:

cor1 <- with(d, cor(x1, y1, method="spearman"))
 cor2 <- with(d, cor(x2, y2, method="spearman"))

and all should be fine.

-- Bert

On Wed, Nov 15, 2023 at 12:54?PM varin sacha via R-help <
r-help at r-project.org> wrote:

> R-Experts,
>
> Here below my R code working without error message but I don't get the
> results I am expecting.
> Here is the result I get:
>
> [1] "All values of t are equal to 0.28611928397257 \n Cannot calculate
> confidence intervals"
> NULL
>
> If someone knows how to solve my problem, really appreciate.
> Best,
> S
>
>
> #########################################################
> # Difference in Spearman rho
>
> library(boot)
>
>
> x1=c(4,6,5,7,8,4,2,3,5.5,6.7,5.5,3.5,2,1,3,5,6,3.5,2.5,2,1,2,3,2,1,2,3,4,3,4)
>
>
> y1=c(10,14,12.5,21,15,16,17.5,11,11.5,21,19,16,17.5,18,18.5,12,13,14,11,11,12,18,20,13,23,12,11,14,16,11)
>
> x2=c(5,3,4,2,1,1,1,2,3,4,5,4,3,2,1,3,4.5,4.5,5.5,6,5,4,7,8,3,4,2,5,4,3)
>
>
> y2=c(11,12,13,11,10,19,21,21,13,15,18,13,12,14,19,18.5,17.5,12.5,10,9,11,13,14,16,11,18,14,13,12,12)
>
> # Function to calculate the difference in Spearman coefficients
> pearson_diff <- function(data, indices) {
>
> # Sample the data
>   d <- data[indices, ]
>
>  # Calculate the Spearman correlation coefficients for every sample
>   cor1 <- cor(x1, y1, method="spearman")
>   cor2 <- cor(x2, y2, method="spearman")
>
> # Return the difference
>   return(cor1 - cor2)
> }
>
> # Create a data.frame with the data
> data <- data.frame(x1, y1, x2, y2)
>
> # Use the boot function to apply the bootstrap
> set.seed(123) # For reproducibility
> bootstrap_results <- boot(data = data, statistic = pearson_diff, R = 1000)
>
> # Calculate all the 95% confidence interval
> boot.ci(bootstrap_results, type = "all")
> ###############################################################
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Thu Nov 16 00:11:41 2023
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Thu, 16 Nov 2023 00:11:41 +0100
Subject: [R] anyone having trouble accesing CRAN?
In-Reply-To: <95795680-62d8-44de-8897-4391ad8f865c@sapo.pt>
References: <824e958a-e563-8e7e-8b6d-9ea245460d63@binghamton.edu>
 <95795680-62d8-44de-8897-4391ad8f865c@sapo.pt>
Message-ID: <28a6b5e7-82b4-4ee8-88a9-31bb299b7a4c@statistik.tu-dortmund.de>

Yes, the sysadmins at WU Vienna are upgrading the CRAN master. The 
mirrors should not be affected.

Best,
Uwe Ligges


On 15.11.2023 20:25, Rui Barradas wrote:
> ?s 19:13 de 15/11/2023, Christopher W. Ryan via R-help escreveu:
>> at https://cran.r-project.org/ I get this error message:
>>
>> =====================
>> Secure Connection Failed
>>
>> An error occurred during a connection to cran.r-project.org.
>> PR_END_OF_FILE_ERROR
>>
>> Error code: PR_END_OF_FILE_ERROR
>>
>> ???? The page you are trying to view cannot be shown because the
>> authenticity of the received data could not be verified.
>> =======================
>>
>> Three different browsers, two different devices, two different networks.
>> (The text of the error messages varies.)
>>
>> Anyone seeing similar?
>>
>> Thanks.
>>
>> --Chris Ryan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Hello,
> 
> Yes, CRAN is down.
> 
> I know last week there was an anouncement about a maintenance scheduled 
> but I cannot place that e-mail right now and don't remember the date 
> exactly so I cannot say for sure this is what is happening.
> 
> But it is probably a scheduled maintenance.
> 
> Rui Barradas
> 
>


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Nov 16 09:12:49 2023
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 16 Nov 2023 13:42:49 +0530
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <CAGxFJbSS1CV=zdnXVh116+7wXzb5JSy2CYTkvNvudKOenkaz1g@mail.gmail.com>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <CAKZQJMDcVLv8XoYtj9TO5Y-Jr81fbisM-Yv9TPC5f65N2oLc=A@mail.gmail.com>
 <CAC8=1epUTr-4vs5rfp30F8UNeGA-yfsh8SPaxDHNDGYw7hUAAA@mail.gmail.com>
 <CAGxFJbSS1CV=zdnXVh116+7wXzb5JSy2CYTkvNvudKOenkaz1g@mail.gmail.com>
Message-ID: <CAC8=1epwLPwwFw5iAq3VT9nQ9mU7idTod6V411fqED-ceajheA@mail.gmail.com>

Dear Bert,

Following your suggestion:

I checked my device resolution is : 1366 x 768 = 16:9

which is the same as is specified in the Rmd file.

I am out of ideas now. Any other idea?

Best Regards,
Ashim

On Wed, Nov 15, 2023 at 10:32?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Well, as no one else has offered an answer ...
>
> I haven't looked at this closely, but could it not simply be the case that the aspect ratio set by "Landscape Mode" just differs from that of your display device? -- i.e., it is impossible to have the figure displayed in landscape ratio *and* simultaneously fill your display device?
>
> If this is obviously wrong, feel free to ignore without replying.
>
> Cheers,
> Bert
>
> On Tue, Nov 14, 2023 at 8:48?PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>>
>> Dear John,
>>
>> Many thanks for your reply.
>>
>> I wish 2 things :
>> 1. Landscape mode
>> 2. No wasted space on the sides when I maximise the pdf.
>>
>> When I download an open and maximise the pdf it wastes space. Please
>> see the attached screenshot.
>>
>> Query: When you maximise the PDF does it occupy the full screen ?
>>
>> Best,
>> Ashim
>>
>> On Tue, Nov 14, 2023 at 5:14?PM John Kane <jrkrideau at gmail.com> wrote:
>> >
>> > I ran the code from the answer and it seems to work well. It, definitely, is giving a landscape output.
>> >
>> > ---
>> > title: "Testing landscape and aspect ratio"
>> > output:
>> >   pdf_document:
>> >     number_sections: true
>> > classoption:
>> >   - landscape
>> >   - "aspectratio=169"
>> > header-includes:
>> >    - \usepackage{dcolumn}
>> > documentclass: article
>> > geometry: margin=1.5cm
>> > ---
>> >
>> > ```{r, out.extra='keepaspectratio=true', out.height='100%', out.width="100%"}
>> > plot(rnorm(100))
>> > ```
>> >
>> >
>> >
>> >
>> > On Mon, 13 Nov 2023 at 23:33, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>> >>
>> >> Dear all,
>> >>
>> >> I have posted a query which has received a response but that is not
>> >> working on my computer.
>> >>
>> >> Here is the query:
>> >>
>> >> https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
>> >>
>> >> Can someone please help me ?
>> >>
>> >> Best Regards,
>> >> Ashim
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>> > --
>> > John Kane
>> > Kingston ON Canada
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Nov 16 09:15:27 2023
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 16 Nov 2023 13:45:27 +0530
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <CAC8=1epwLPwwFw5iAq3VT9nQ9mU7idTod6V411fqED-ceajheA@mail.gmail.com>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <CAKZQJMDcVLv8XoYtj9TO5Y-Jr81fbisM-Yv9TPC5f65N2oLc=A@mail.gmail.com>
 <CAC8=1epUTr-4vs5rfp30F8UNeGA-yfsh8SPaxDHNDGYw7hUAAA@mail.gmail.com>
 <CAGxFJbSS1CV=zdnXVh116+7wXzb5JSy2CYTkvNvudKOenkaz1g@mail.gmail.com>
 <CAC8=1epwLPwwFw5iAq3VT9nQ9mU7idTod6V411fqED-ceajheA@mail.gmail.com>
Message-ID: <CAC8=1ep4U2B-g_QxFnLko5ZMGAQYGbbW9vrv=kHMRbKmY0OE2Q@mail.gmail.com>

Hello,

> 1366/768
[1] 1.778646
> 16/9
[1] 1.777778
>

There is a mild difference. Is that causing the problem?

Best,
Ashim

On Thu, Nov 16, 2023 at 1:42?PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> Dear Bert,
>
> Following your suggestion:
>
> I checked my device resolution is : 1366 x 768 = 16:9
>
> which is the same as is specified in the Rmd file.
>
> I am out of ideas now. Any other idea?
>
> Best Regards,
> Ashim
>
> On Wed, Nov 15, 2023 at 10:32?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > Well, as no one else has offered an answer ...
> >
> > I haven't looked at this closely, but could it not simply be the case that the aspect ratio set by "Landscape Mode" just differs from that of your display device? -- i.e., it is impossible to have the figure displayed in landscape ratio *and* simultaneously fill your display device?
> >
> > If this is obviously wrong, feel free to ignore without replying.
> >
> > Cheers,
> > Bert
> >
> > On Tue, Nov 14, 2023 at 8:48?PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >>
> >> Dear John,
> >>
> >> Many thanks for your reply.
> >>
> >> I wish 2 things :
> >> 1. Landscape mode
> >> 2. No wasted space on the sides when I maximise the pdf.
> >>
> >> When I download an open and maximise the pdf it wastes space. Please
> >> see the attached screenshot.
> >>
> >> Query: When you maximise the PDF does it occupy the full screen ?
> >>
> >> Best,
> >> Ashim
> >>
> >> On Tue, Nov 14, 2023 at 5:14?PM John Kane <jrkrideau at gmail.com> wrote:
> >> >
> >> > I ran the code from the answer and it seems to work well. It, definitely, is giving a landscape output.
> >> >
> >> > ---
> >> > title: "Testing landscape and aspect ratio"
> >> > output:
> >> >   pdf_document:
> >> >     number_sections: true
> >> > classoption:
> >> >   - landscape
> >> >   - "aspectratio=169"
> >> > header-includes:
> >> >    - \usepackage{dcolumn}
> >> > documentclass: article
> >> > geometry: margin=1.5cm
> >> > ---
> >> >
> >> > ```{r, out.extra='keepaspectratio=true', out.height='100%', out.width="100%"}
> >> > plot(rnorm(100))
> >> > ```
> >> >
> >> >
> >> >
> >> >
> >> > On Mon, 13 Nov 2023 at 23:33, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >> >>
> >> >> Dear all,
> >> >>
> >> >> I have posted a query which has received a response but that is not
> >> >> working on my computer.
> >> >>
> >> >> Here is the query:
> >> >>
> >> >> https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
> >> >>
> >> >> Can someone please help me ?
> >> >>
> >> >> Best Regards,
> >> >> Ashim
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> >
> >> >
> >> > --
> >> > John Kane
> >> > Kingston ON Canada
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Nov 16 12:59:16 2023
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 16 Nov 2023 12:59:16 +0100
Subject: [R] Fast way to draw mean values and 95% confidence intervals of
 groups with ggplot2
Message-ID: <CAMk+s2RGw=GWfZLaTG1WgtS_8-sri4XXi1T1iSkgc5=WyCGDQw@mail.gmail.com>

Hello,
I have triplicate (column A) readings (column D) of samples exposed to
different concentrations (column C) over time (column B).
Is it possible to draw a line plot of the mean values for each
concentration (C)? At the moment, I get a single line.
Also, is there a simple way to draw the 95% CI around these data? I
know I need to use ribbon with the lower and upper limit, but is there
a simple way for ggplot2 to calculate directly these values?
Here is a working example:

```
A = c(rep(1, 28), rep(2, 28), rep(3, 28))
B = rep(c(0, 15, 30, 45, 60, 75, 90), 12)
C = rep(c(rep(0, 7), rep(0.6, 7), rep(1.2, 7),
          rep(2.5,7)),3)
D = c(731.33,    761.67,    730,    761.67,    741.67,    788.67,    784.33,
      686.67,    685.33,    680,    693.67,    684,    704,    709.67,    739,
      731,    719,    767,    760.67,    776.67,    768.67,    675,    671.67,
      668.67,    677.33,    673.67,    687,    696.67,    727,    750.67,
      752.67,    786.67,    794.67,    843.33,    946,    732.67,    737.33,
      775.33,    828,    918,    1063,    1270,    752.67,    742.33,
  735.67,
      747.67,    777.33,    803.67,    865.67,    700,    700.67,    705.67,
      722.67,    744,    779,    837,    748,    742,    754,    747.67,
      775.67,    808.67,    869,    705.67,    714.33,    702.33,    730,
      710.67,    731,    744,    686.33,    687.33,    670,    702.33,
      669.33,    707.33,    708.33,    724,    747,    761.33,    715,
      697.67,    728,    728)

df = data.frame(A, B, C, D)
library(ggplot2)
ggplot(data=df, aes(x=B, y=D, z=C, color =C)) +
  geom_line(stat = "summary", fun = "mean") +
  geom_ribbon()
```

Thank you


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Nov 16 13:39:20 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 16 Nov 2023 12:39:20 +0000
Subject: [R] 
 Fast way to draw mean values and 95% confidence intervals of
 groups with ggplot2
In-Reply-To: <CAMk+s2RGw=GWfZLaTG1WgtS_8-sri4XXi1T1iSkgc5=WyCGDQw@mail.gmail.com>
References: <CAMk+s2RGw=GWfZLaTG1WgtS_8-sri4XXi1T1iSkgc5=WyCGDQw@mail.gmail.com>
Message-ID: <866c21b7-93ec-43df-af24-cae8ac3acf47@sapo.pt>

?s 11:59 de 16/11/2023, Luigi Marongiu escreveu:
> Hello,
> I have triplicate (column A) readings (column D) of samples exposed to
> different concentrations (column C) over time (column B).
> Is it possible to draw a line plot of the mean values for each
> concentration (C)? At the moment, I get a single line.
> Also, is there a simple way to draw the 95% CI around these data? I
> know I need to use ribbon with the lower and upper limit, but is there
> a simple way for ggplot2 to calculate directly these values?
> Here is a working example:
> 
> ```
> A = c(rep(1, 28), rep(2, 28), rep(3, 28))
> B = rep(c(0, 15, 30, 45, 60, 75, 90), 12)
> C = rep(c(rep(0, 7), rep(0.6, 7), rep(1.2, 7),
>            rep(2.5,7)),3)
> D = c(731.33,    761.67,    730,    761.67,    741.67,    788.67,    784.33,
>        686.67,    685.33,    680,    693.67,    684,    704,    709.67,    739,
>        731,    719,    767,    760.67,    776.67,    768.67,    675,    671.67,
>        668.67,    677.33,    673.67,    687,    696.67,    727,    750.67,
>        752.67,    786.67,    794.67,    843.33,    946,    732.67,    737.33,
>        775.33,    828,    918,    1063,    1270,    752.67,    742.33,
>    735.67,
>        747.67,    777.33,    803.67,    865.67,    700,    700.67,    705.67,
>        722.67,    744,    779,    837,    748,    742,    754,    747.67,
>        775.67,    808.67,    869,    705.67,    714.33,    702.33,    730,
>        710.67,    731,    744,    686.33,    687.33,    670,    702.33,
>        669.33,    707.33,    708.33,    724,    747,    761.33,    715,
>        697.67,    728,    728)
> 
> df = data.frame(A, B, C, D)
> library(ggplot2)
> ggplot(data=df, aes(x=B, y=D, z=C, color =C)) +
>    geom_line(stat = "summary", fun = "mean") +
>    geom_ribbon()
> ```
> 
> Thank you
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

I am not sure that the code below is what you want.
The first 3 instructions are to create a named vector of colors.
The pipe is what tries to solve the problem. It computes means and se's 
by groups of time and concentration, then plots the ribbon below the lines.

It is important to not set color = C in the initial call to ggplot, 
since it would be effective in all the subsequent layers (try it).
To have one line per concentration I use group = C instead.



suppressPackageStartupMessages({
   library(ggplot2)
   library(dplyr)
})

n_colors <- df$C |> unique() |> length()
names_colors <- df$C |> unique() |> as.character()
clrs <- setNames(palette.colors(n_colors), names_colors)

df %>%
   mutate(C = factor(C)) %>%
   group_by(B, C) %>%
   mutate(mean_D = mean(D), se_D = sd(D)) %>%
   ungroup() %>%
   ggplot(aes(x = B, group = C)) +
   geom_ribbon(aes(ymin = mean_D - se_D, ymax = mean_D + se_D), fill = 
"grey", alpha = 0.5) +
   geom_line(aes(y = mean_D, color = C)) +
   geom_point(aes(y = D, color = C)) +
   scale_color_manual(name = "Concentration", values = clrs)


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Nov 16 15:14:56 2023
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 16 Nov 2023 15:14:56 +0100
Subject: [R] 
 Fast way to draw mean values and 95% confidence intervals of
 groups with ggplot2
In-Reply-To: <866c21b7-93ec-43df-af24-cae8ac3acf47@sapo.pt>
References: <CAMk+s2RGw=GWfZLaTG1WgtS_8-sri4XXi1T1iSkgc5=WyCGDQw@mail.gmail.com>
 <866c21b7-93ec-43df-af24-cae8ac3acf47@sapo.pt>
Message-ID: <CAMk+s2TbcB=pXuP-0w2x-O3JsfE9JQJ0abvv8daY0SvnrDL9JQ@mail.gmail.com>

Thank you for your answer. I will implement it, but still I reckon
ggplot2 cannot do the whole thing on its own terms: I need to prep the
data beforehand.
Cheers
Luigi

On Thu, Nov 16, 2023 at 1:39?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> ?s 11:59 de 16/11/2023, Luigi Marongiu escreveu:
> > Hello,
> > I have triplicate (column A) readings (column D) of samples exposed to
> > different concentrations (column C) over time (column B).
> > Is it possible to draw a line plot of the mean values for each
> > concentration (C)? At the moment, I get a single line.
> > Also, is there a simple way to draw the 95% CI around these data? I
> > know I need to use ribbon with the lower and upper limit, but is there
> > a simple way for ggplot2 to calculate directly these values?
> > Here is a working example:
> >
> > ```
> > A = c(rep(1, 28), rep(2, 28), rep(3, 28))
> > B = rep(c(0, 15, 30, 45, 60, 75, 90), 12)
> > C = rep(c(rep(0, 7), rep(0.6, 7), rep(1.2, 7),
> >            rep(2.5,7)),3)
> > D = c(731.33,    761.67,    730,    761.67,    741.67,    788.67,    784.33,
> >        686.67,    685.33,    680,    693.67,    684,    704,    709.67,    739,
> >        731,    719,    767,    760.67,    776.67,    768.67,    675,    671.67,
> >        668.67,    677.33,    673.67,    687,    696.67,    727,    750.67,
> >        752.67,    786.67,    794.67,    843.33,    946,    732.67,    737.33,
> >        775.33,    828,    918,    1063,    1270,    752.67,    742.33,
> >    735.67,
> >        747.67,    777.33,    803.67,    865.67,    700,    700.67,    705.67,
> >        722.67,    744,    779,    837,    748,    742,    754,    747.67,
> >        775.67,    808.67,    869,    705.67,    714.33,    702.33,    730,
> >        710.67,    731,    744,    686.33,    687.33,    670,    702.33,
> >        669.33,    707.33,    708.33,    724,    747,    761.33,    715,
> >        697.67,    728,    728)
> >
> > df = data.frame(A, B, C, D)
> > library(ggplot2)
> > ggplot(data=df, aes(x=B, y=D, z=C, color =C)) +
> >    geom_line(stat = "summary", fun = "mean") +
> >    geom_ribbon()
> > ```
> >
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Hello,
>
> I am not sure that the code below is what you want.
> The first 3 instructions are to create a named vector of colors.
> The pipe is what tries to solve the problem. It computes means and se's
> by groups of time and concentration, then plots the ribbon below the lines.
>
> It is important to not set color = C in the initial call to ggplot,
> since it would be effective in all the subsequent layers (try it).
> To have one line per concentration I use group = C instead.
>
>
>
> suppressPackageStartupMessages({
>    library(ggplot2)
>    library(dplyr)
> })
>
> n_colors <- df$C |> unique() |> length()
> names_colors <- df$C |> unique() |> as.character()
> clrs <- setNames(palette.colors(n_colors), names_colors)
>
> df %>%
>    mutate(C = factor(C)) %>%
>    group_by(B, C) %>%
>    mutate(mean_D = mean(D), se_D = sd(D)) %>%
>    ungroup() %>%
>    ggplot(aes(x = B, group = C)) +
>    geom_ribbon(aes(ymin = mean_D - se_D, ymax = mean_D + se_D), fill =
> "grey", alpha = 0.5) +
>    geom_line(aes(y = mean_D, color = C)) +
>    geom_point(aes(y = D, color = C)) +
>    scale_color_manual(name = "Concentration", values = clrs)
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
> www.avg.com



-- 
Best regards,
Luigi


From p@u|bern@|07 @end|ng |rom gm@||@com  Thu Nov 16 18:10:56 2023
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Thu, 16 Nov 2023 12:10:56 -0500
Subject: [R] Problems when trying to visualize clusters
Message-ID: <CAMOcQfODCjiR9Ms35pUiqpieo8ru8roWCfBW4C+UUWbp83+wqQ@mail.gmail.com>

Dear friends,

Hope you are all doing great. I am currently working with R version 4.3.1.

There are two things I wanted to accomplish:
1. Determine the optimal number of clusters for my dataset, which contains
11 market segments and two features, namely, toll revenue (aka tolls) and
number of transits (aka transits), and
2. Use a clustering algorithm and then plot the resulting cluster

I am working with the following packages:
install.packages("clustMixType")
install.packages("factoextra")
install.packages("NbClust")

This is my R code:
#Reading Required Datasets
df = as.data.frame(read_excel("dataforclustering.xlsx"))
df2 = df[,-1]
head(df2)
scaled_df = scale(df2)

#This part was to determine the optimal number of clusters
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss") +
  geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")

# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method")

# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(scaled_df, kmeans, nstart = 25,  method = "gap_stat", nboot =
50)+
  labs(subtitle = "Gap statistic method")

Based on the elbow method, which suggested k = 4, I then used the following
code to produce the clusters and try to plot them:

df$MarketSegment <- as.factor(df$MarketSegment)

#kproto comes from the  clustMixType package
kclustalgo = kproto(df,4)
summary(kclustalgo)
plot(kclustalgo, vars = c("tolls","transits"))

The problem is that, when using the plot function, it does not generate
anything, it does not plot anything.

Below my dataset:
structure(list(MarketSegment = structure(c(12L, 8L, 4L, 5L, 8L,
8L, 9L, 2L, 8L, 11L, 11L, 12L, 5L, 4L, 10L, 10L, 9L, 11L, 5L,
10L, 10L, 9L, 9L, 9L, 4L, 11L, 10L, 9L, 11L, 4L, 7L, 1L, 2L,
7L, 4L, 6L, 4L, 5L, 4L, 6L, 5L, 11L, 10L, 9L, 8L, 11L, 2L, 4L,
5L, 12L, 10L, 5L, 4L, 5L, 10L, 10L, 11L, 2L, 12L, 5L, 10L, 8L,
8L, 2L, 8L, 13L, 6L, 7L, 4L, 10L, 8L, 3L, 5L, 2L, 7L, 13L, 5L,
5L, 2L, 12L, 4L, 5L, 5L, 12L, 10L, 5L, 11L, 9L, 4L, 2L, 4L, 2L,
9L, 5L, 11L, 10L, 4L, 11L, 12L, 9L, 11L, 10L, 4L, 13L, 4L, 2L,
4L, 5L, 6L, 13L, 2L, 5L, 10L, 3L, 13L, 8L, 11L, 9L, 8L, 10L,
4L, 2L, 11L, 2L, 9L, 4L, 12L, 10L, 8L, 12L, 8L, 10L, 11L, 2L,
8L, 4L, 12L, 9L, 8L, 8L, 11L, 11L, 2L, 9L, 10L, 8L, 12L, 2L,
11L, 8L, 11L, 4L, 2L, 3L, 3L, 8L, 13L, 5L, 5L, 6L, 6L, 2L, 9L,
10L, 2L, 7L, 6L, 2L, 1L, 7L, 6L, 13L, 1L, 2L, 4L, 5L, 12L, 9L,
11L, 9L, 8L, 2L, 9L, 9L, 5L, 11L, 2L, 12L, 2L, 8L, 12L, 4L, 5L,
4L, 10L, 2L, 9L, 2L, 2L, 2L, 9L, 11L, 2L, 12L, 2L, 10L, 12L,
9L, 4L, 12L, 10L, 5L, 12L, 1L, 6L, 5L, 8L, 10L, 9L, 10L, 4L,
7L, 8L, 1L, 9L, 3L, 3L, 1L, 4L, 4L, 2L, 4L, 10L, 11L, 8L, 2L,
9L, 2L, 5L, 4L, 12L, 4L, 5L, 4L, 9L, 4L, 4L, 12L, 9L, 2L, 8L,
12L, 4L, 3L, 7L, 3L, 10L, 7L, 8L, 2L, 6L, 1L, 3L, 6L, 13L, 7L,
13L, 9L, 13L, 8L, 3L, 10L, 10L, 5L, 12L, 9L, 8L, 8L, 11L, 10L,
8L, 12L, 8L, 5L, 9L, 4L, 12L, 11L, 4L, 8L, 5L, 10L, 11L, 11L,
2L, 12L, 5L, 10L, 9L, 13L, 1L, 7L, 9L, 9L, 10L, 3L, 2L, 1L, 8L,
8L, 9L, 10L, 2L, 8L, 13L, 6L, 12L, 4L, 8L, 10L, 9L, 10L, 10L,
5L, 11L, 8L, 8L, 4L, 12L, 8L, 12L, 10L, 9L, 12L, 5L, 11L, 2L,
5L, 5L, 10L, 5L, 5L, 9L, 9L, 5L, 2L, 9L, 1L, 8L, 13L, 7L, 3L,
5L, 1L, 1L, 9L, 10L, 7L, 5L, 3L, 1L, 4L), levels = c("Chemical Tankers",
"Container", "Crude/Product Tankers", "Dry Bulk", "General Cargo",
"LNG Carrier", "LPG Carrier", "Others", "Passengers", "Refrigerated",
"Tankers", "Vehicle Carriers", "Vehicle Carriers/RoRo"), class = "factor"),
    Toll = c(45622373.27, 30399013.74, 176306593.66, 18971118.38,
    25835490.96, 23740969.7, 22570777.11, 144378273.06, 59115267.47,
    71971071.4, 94431934.17, 14252216.8, 25040195.72, 92607705.13,
    17595512.81, 22275409.83, 6291531.04, 51104161.27, 25181172.84,
    34816907.8, 32777647.65, 7099598.51, 27689930.37, 42046359.26,
    173706597.74, 143220682.62, 59053229.17, 39369534.57, 157970209.29,
    411908086.08, 30644932.62, 141530616.2, 1086950201, 222938133.49,
    347883155.9, 160051827.89, 376203394.59, 44232336.52, 410395911.78,
    218235220.1, 35274869.37, 73258945.88, 37821693.14, 81193.19,
    25461445.17, 61671172.38, 64984959.44, 166826321.18, 21076499.39,
    88337589.73, 46904254.95, 20029152.87, 143083949.3, 21959696.81,
    52382607.59, 3478831.59, 46284549.62, 48579258.24, 47417137.43,
    25768369.63, 52765742.89, 60329234.95, 52200921.5, 911170775.2,
    27854758.26, 188077540.25, 170069.18, 46979713.12, 324994117.34,
    42136353.11, 12495006.27, 93066248.53, 46588988.04, 1203041643,
    275586213.06, 224722357.56, 38114431.53, 24457874.42, 224106,
    52935575.5, 145149052.16, 24254689.17, 21355540.17, 77826892.53,
    37047616.49, 25895846.03, 81595647.93, 18824145.98, 157687486.69,
    252355857.97, 23554769.2, 42803289.58, 6970409.95, 25223571.18,
    44521560.29, 23846694.1, 123861794, 62133036.93, 49025354.84,
    27761074.11, 93221253.37, 67681581.53, 326040777.37, 0, 353324758.38,
    914308534.52, 375236325.91, 42896733.54, 18760255.6, 198508135.47,
    1367150804.75, 42296364.22, 32848434.94, 84984870.35, 209972507.43,
    131115.79, 636385.07, 15683638.27, 27432524.55, 34767287.97,
    174026078.65, 91872590.71, 77273064.3, 115418664.65, 24248775.39,
    184598288.14, 55702797.23, 35938942.48, 37876793.27, 67595978.53,
    37585563.97, 38058681.79, 70479369.62, 181080995.57, 43367438.62,
    152817300.67, 99222096.54, 29739623.79, 7027238.12, 25482814.45,
    52706796.25, 44227271.88, 49125255.46, 7273684.04, 31550474.77,
    45171138.63, 113147627.59, 736129089, 118847881.44, 48827559.85,
    175552816, 231472438.57, 972466186.8, 20939505.12, 74784961.28,
    22048526.85, 184182792.62, 50043224.13, 46567864.3, 64096942.63,
    133561525.43, 1184603445, 27481529.81, 35823758.59, 1241926985.25,
    336005108, 175196241.59, 1417836913.5, 219080343.22, 447793583.34,
    142244858.6, 211282556.89, 282402337.27, 73904457.86, 213236.53,
    23845925.9, 47069774.11, 17091622.26, 77288315.4, 20367261.33,
    58398395.39, 230933373.58, 26598884.35, 2406557.1, 6480102,
    13628284.31, 10263514.77, 66291278.83, 45203889.46, 24439458.61,
    62995994.42, 103545550.11, 23582006.69, 106841255.81, 30920698.81,
    57152783.67, 6788655.31, 58688264.46, 63623458.42, 381280927.57,
    26160209.37, 94398586.99, 548546815.6, 94377076.67, 660333530.6,
    58467965.42, 121250943.68, 39897634.25, 253784215.75, 123264396,
    58788870.55, 41450428.73, 116407322.67, 37073625.53, 80949.5,
    46479259.97, 17935104.29, 44743486.45, 50354870.76, 45978813.8,
    381104737.29, 144588856.56, 13453753.84, 215589051.87, 14640417.36,
    113367165.56, 100614565.26, 270041980.52, 436045596.44, 399693615.37,
    80310709.08, 178202292.6, 37426161.19, 84501310.47, 35095993.84,
    115887420.17, 25320445.08, 131720569.81, 20152178.46, 98738563.37,
    52761092.05, 126078172.3, 24618706.25, 136326542.07, 11518860.78,
    156025722.98, 170794953.78, 105383146.32, 33742975.52, 786732496.2,
    44558463.25, 138272099.98, 332758968.08, 73351527.91, 3711095.76,
    0, 49843621.55, 22795131.65, 23624194.51, 960690603.6, 0,
    174697284.22, 75560763.05, 231180, 196673683.99, 190737686.99,
    213184850.38, 43204339.22, 175208475.3, 14294438.32, 105373950.72,
    34354378.94, 36201953.3, 152644.76, 4271.52, 21467521.11,
    24714178.25, 23397907.04, 84318567.96, 41391735.09, 59207931.58,
    96631125.37, 26119366.87, 24050681.28, 6414468.87, 115073972.91,
    48806783.58, 53117026.48, 143925878.71, 54427083.34, 29621363.6,
    67914181.91, 208255468.52, 172563091.58, 783130968, 87885643.22,
    33623583.6, 49862226.49, 39581084.06, 47338366.37, 0, 0,
    42059174.7, 55196029.54, 45573526.31, 77542558.18, 948435917.2,
    184766344.51, 11715869.41, 11465772.13, 58348554.79, 34159529.23,
    1324615521.7, 14214065.75, 204448377.38, 133199367.48, 48301726.87,
    171342164.62, 27932981.26, 204453.32, 13799161.85, 36545009.39,
    40127237.59, 24856336.87, 81983152.36, 27475201.4, 40720204.5,
    143732024.58, 81736659.41, 54145665.75, 63195468.9, 17990069.83,
    7063003.98, 53943424.6, 27336061.94, 49141786, 56875952.23,
    25301093.8, 21993181.36, 52955818.55, 25793889.09, 28102485.94,
    39856771.5, 45181483.95, 42949296.26, 931539910.4, 34918600.8,
    134194366.11, 20115045.15, 203545729.19, 68836834.76, 85618322.31,
    41411914.83, 203629971.2, 200898608.18, 44469248.2, 35518487.49,
    326654852.92, 38518260.2, 99286360.37, 231011004.03, 368789029.42
    ), Transits = c(557, 2932, 3312, 1015, 3037, 2958, 257, 1797,
    2812, 1615, 1912, 251, 1836, 2861, 1592, 1908, 149, 1656,
    1596, 2613, 2409, 159, 205, 235, 2472, 2079, 1631, 202, 1838,
    3356, 298, 1489, 2493, 1148, 2614, 421, 2758, 651, 2925,
    519, 453, 2187, 2568, 2799, 2705, 1928, 1187, 3042, 968,
    789, 2216, 817, 2380, 882, 2371, 324, 1667, 1120, 646, 819,
    2108, 2737, 2586, 3255, 2210, 796, 4, 440, 2610, 838, 1217,
    667, 675, 2615, 1349, 886, 556, 1514, 37622, 665, 3431, 1537,
    1075, 721, 1997, 1333, 2081, 217, 2579, 2534, 703, 992, 226,
    1771, 1591, 1963, 3306, 1943, 611, 224, 1707, 2151, 3288,
    2510, 3081, 2892, 3075, 678, 58, 798, 2642, 616, 566, 413,
    691, 22076, 9415, 300, 2881, 2309, 3613, 1428, 1940, 1691,
    310, 3549, 561, 2021, 3071, 645, 2641, 2085, 1704, 2126,
    2668, 2851, 792, 243, 682, 2881, 1810, 1615, 1043, 170, 2140,
    2615, 833, 3524, 2027, 2497, 2342, 2982, 3326, 181, 596,
    1986, 787, 878, 813, 181, 340, 2616, 127, 746, 2537, 1526,
    425, 2843, 1987, 1552, 343, 782, 1850, 1334, 8088, 1431,
    509, 283, 2216, 228, 2625, 2451, 225, 75, 485, 472, 237,
    1091, 1069, 2785, 973, 3092, 1597, 3134, 2279, 1093, 155,
    1131, 1174, 3020, 221, 1744, 3419, 728, 3604, 2199, 765,
    215, 3033, 632, 1453, 926, 504, 431, 2, 913, 2001, 992, 265,
    954, 2904, 929, 1696, 2114, 53, 783, 628, 2362, 3004, 2781,
    1391, 3939, 2031, 2207, 2653, 1597, 299, 1749, 1061, 3019,
    731, 3206, 1558, 3275, 233, 2598, 2752, 810, 248, 3235, 2455,
    618, 3220, 647, 51, 3611, 1069, 240, 2086, 3132, 2975, 1799,
    610, 3, 802, 1027, 844, 170, 650, 1314, 631, 601, 459, 8494,
    1803, 297, 2909, 2941, 2129, 2172, 2643, 807, 2893, 1767,
    214, 3109, 676, 1804, 2346, 2692, 856, 1912, 2404, 2264,
    3094, 448, 900, 1088, 214, 202, 4921, 3567, 229, 249, 968,
    621, 2824, 1886, 1989, 2034, 265, 590, 2425, 1521, 762, 272,
    600, 3928, 2811, 5552, 308, 2474, 2442, 1379, 2280, 2897,
    2794, 2611, 761, 2795, 1110, 1623, 209, 810, 1681, 1642,
    1092, 1677, 825, 2246, 779, 816, 226, 214, 908, 3010, 204,
    1503, 1944, 849, 538, 666, 636, 2019, 1994, 196, 665, 1552,
    559, 569, 2048, 2170)), row.names = c(NA, -362L), class = "data.frame")

Any guidance will be greatly appreciated.

Best regards,
Paul

	[[alternative HTML version deleted]]


From o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r  Fri Nov 17 16:54:57 2023
From: o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r (Olivier Crouzet)
Date: Fri, 17 Nov 2023 16:54:57 +0100
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
Message-ID: <20231117165457.8604d4f30b1a5ccc5e242aa4@univ-nantes.fr>

Dear Ashim,

I don't think the aspectratio is appropriate in this context because
it would imply that the beamer (LaTeX) class is used but you're actually
using the article (LaTeX) class.

You may use specifications of the geometry package rather than
specifying options to the class:

e.g. replace your current header:

---
title: "Testing landscape and aspect ratio"
output: 
  pdf_document:
    number_sections: true
classoption:
  - landscape
  - "aspectratio=169"
header-includes:
   - \usepackage{dcolumn} 
documentclass: article
geometry: margin=1.5cm
---

with this one:

---
title: "Testing landscape and aspect ratio"
output: 
  pdf_document:
    number_sections: true
header-includes:
   - \usepackage{dcolumn} 
documentclass: article
geometry: margin=1.5cm, paperwidth=24cm, paperheight=13.5cm 
---

Of course, you may change the exact dimensions and it will impact the
relative font sizes. I've tested it and it generates what you want.

Yours.
Olivier.





 On Tue, 14 Nov 2023 10:03:23
+0530 Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear all,
> 
> I have posted a query which has received a response but that is not
> working on my computer.
> 
> Here is the query:
> 
> https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
> 
> Can someone please help me ?
> 
> Best Regards,
> Ashim
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  http://olivier.ghostinthemachine.space
  /Ma?tre de Conf?rences/
  @LLING - Laboratoire de Linguistique de Nantes
    UMR6310 CNRS / Universit? de Nantes


From @@h|mk@poor @end|ng |rom gm@||@com  Sat Nov 18 05:23:19 2023
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Sat, 18 Nov 2023 09:53:19 +0530
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <20231117165457.8604d4f30b1a5ccc5e242aa4@univ-nantes.fr>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <20231117165457.8604d4f30b1a5ccc5e242aa4@univ-nantes.fr>
Message-ID: <CAC8=1er4HB2UKXOATpPD=MiPWt0Zy70usjCV1v_AtxzJR0+qHg@mail.gmail.com>

Dear Olivier,

Many thanks for your reply.

This works well for me.

How did you come up with the pagewidth / pageheight numbers?  I do
understand that their ratio = 16:9,
but how did you choose these numbers?

Best Regards,
Ashim

On Fri, Nov 17, 2023 at 9:25?PM Olivier Crouzet
<olivier.crouzet at univ-nantes.fr> wrote:
>
> Dear Ashim,
>
> I don't think the aspectratio is appropriate in this context because
> it would imply that the beamer (LaTeX) class is used but you're actually
> using the article (LaTeX) class.
>
> You may use specifications of the geometry package rather than
> specifying options to the class:
>
> e.g. replace your current header:
>
> ---
> title: "Testing landscape and aspect ratio"
> output:
>   pdf_document:
>     number_sections: true
> classoption:
>   - landscape
>   - "aspectratio=169"
> header-includes:
>    - \usepackage{dcolumn}
> documentclass: article
> geometry: margin=1.5cm
> ---
>
> with this one:
>
> ---
> title: "Testing landscape and aspect ratio"
> output:
>   pdf_document:
>     number_sections: true
> header-includes:
>    - \usepackage{dcolumn}
> documentclass: article
> geometry: margin=1.5cm, paperwidth=24cm, paperheight=13.5cm
> ---
>
> Of course, you may change the exact dimensions and it will impact the
> relative font sizes. I've tested it and it generates what you want.
>
> Yours.
> Olivier.
>
>
>
>
>
>  On Tue, 14 Nov 2023 10:03:23
> +0530 Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> > Dear all,
> >
> > I have posted a query which has received a response but that is not
> > working on my computer.
> >
> > Here is the query:
> >
> > https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
> >
> > Can someone please help me ?
> >
> > Best Regards,
> > Ashim
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html and provide commented,
> > minimal, self-contained, reproducible code.
>
>
> --
>   Olivier Crouzet, PhD
>   http://olivier.ghostinthemachine.space
>   /Ma?tre de Conf?rences/
>   @LLING - Laboratoire de Linguistique de Nantes
>     UMR6310 CNRS / Universit? de Nantes
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r  Sat Nov 18 08:21:25 2023
From: o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r (Olivier Crouzet)
Date: Sat, 18 Nov 2023 08:21:25 +0100
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <CAC8=1er4HB2UKXOATpPD=MiPWt0Zy70usjCV1v_AtxzJR0+qHg@mail.gmail.com>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <20231117165457.8604d4f30b1a5ccc5e242aa4@univ-nantes.fr>
 <CAC8=1er4HB2UKXOATpPD=MiPWt0Zy70usjCV1v_AtxzJR0+qHg@mail.gmail.com>
Message-ID: <20231118082125.19d2c852185317ee068d772d@univ-nantes.fr>

Dear Ashim,

these are documented in the LaTeX 'geometry' package (see for example
on CTAN: https://ctan.org/pkg/geometry). As I added in my response on
Stackoverflow, several parts in the RMarkdown header actually concern
information that are processed by LaTeX to actually generate the PDF,
among which the 'geometry' line. For someone who is used to working with
LaTeX, it is relatively natural to 'identify' LaTeX options in these
lines even though they are not structured exactly this way in a LaTeX
document (but their names are the same).

Concerning the choice for these specific numbers, it is relatively
arbitrary. I've been doing this on LaTeX for years when I want to
generate slides without using the 'beamer' document class and the
things to take into account are:

- These dimensions express the physical sizes of the pdf page (in a
sense, what their size would be if you print the document without
adapting to the paper in your printer)
- If these sizes are reduced... the relative font size will increase
because LaTeX will project the same font on a smaller virtual paper,
- And if these sizes are increased... the relative font size will
decrease because LaTeX will project the same font on a larger
virtual paper, 
- I processed starting from 16x9cm sizes, resp. for paperwidth and
paperheight, and estimated that the fonts were too large to my taste,
then doubled them and felt that the fonts were too small for slides,
then I ended up trying multiplying 16x9cm by a factor of 1.5, which
gave me 24x13.5cm and I found it was ok.
- But one may vary these sizes arbitrary (even using smaller
steps and ratios differing from 16/9) depending on the aims to be
reached.
- It is also possible to specify different units (pt = points, in =
inches...)

Yours.
Olivier.

On Sat, 18 Nov 2023 09:53:19 +0530 Ashim Kapoor <ashimkapoor at gmail.com>
wrote:

> Dear Olivier,
> 
> Many thanks for your reply.
> 
> This works well for me.
> 
> How did you come up with the pagewidth / pageheight numbers?  I do
> understand that their ratio = 16:9,
> but how did you choose these numbers?
> 
> Best Regards,
> Ashim
> 
> On Fri, Nov 17, 2023 at 9:25?PM Olivier Crouzet
> <olivier.crouzet at univ-nantes.fr> wrote:
> >
> > Dear Ashim,
> >
> > I don't think the aspectratio is appropriate in this context because
> > it would imply that the beamer (LaTeX) class is used but you're
> > actually using the article (LaTeX) class.
> >
> > You may use specifications of the geometry package rather than
> > specifying options to the class:
> >
> > e.g. replace your current header:
> >
> > ---
> > title: "Testing landscape and aspect ratio"
> > output:
> >   pdf_document:
> >     number_sections: true
> > classoption:
> >   - landscape
> >   - "aspectratio=169"
> > header-includes:
> >    - \usepackage{dcolumn}
> > documentclass: article
> > geometry: margin=1.5cm
> > ---
> >
> > with this one:
> >
> > ---
> > title: "Testing landscape and aspect ratio"
> > output:
> >   pdf_document:
> >     number_sections: true
> > header-includes:
> >    - \usepackage{dcolumn}
> > documentclass: article
> > geometry: margin=1.5cm, paperwidth=24cm, paperheight=13.5cm
> > ---
> >
> > Of course, you may change the exact dimensions and it will impact
> > the relative font sizes. I've tested it and it generates what you
> > want.
> >
> > Yours.
> > Olivier.
> >
> >
> >
> >
> >
> >  On Tue, 14 Nov 2023 10:03:23
> > +0530 Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >
> > > Dear all,
> > >
> > > I have posted a query which has received a response but that is
> > > not working on my computer.
> > >
> > > Here is the query:
> > >
> > > https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
> > >
> > > Can someone please help me ?
> > >
> > > Best Regards,
> > > Ashim
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html and provide commented,
> > > minimal, self-contained, reproducible code.
> >
> >
> > --
> >   Olivier Crouzet, PhD
> >   http://olivier.ghostinthemachine.space
> >   /Ma?tre de Conf?rences/
> >   @LLING - Laboratoire de Linguistique de Nantes
> >     UMR6310 CNRS / Universit? de Nantes
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html and provide commented,
> > minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  http://olivier.ghostinthemachine.space
  /Ma?tre de Conf?rences/
  @LLING - Laboratoire de Linguistique de Nantes
    UMR6310 CNRS / Universit? de Nantes


From @@h|mk@poor @end|ng |rom gm@||@com  Sat Nov 18 08:50:49 2023
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Sat, 18 Nov 2023 13:20:49 +0530
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <20231118082125.19d2c852185317ee068d772d@univ-nantes.fr>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <20231117165457.8604d4f30b1a5ccc5e242aa4@univ-nantes.fr>
 <CAC8=1er4HB2UKXOATpPD=MiPWt0Zy70usjCV1v_AtxzJR0+qHg@mail.gmail.com>
 <20231118082125.19d2c852185317ee068d772d@univ-nantes.fr>
Message-ID: <CAC8=1eoX6yTXqGPC-rcbff4BvkiQFugaVwtzyyAnunfhdya7fQ@mail.gmail.com>

Dear Olivier,

Many thanks for your reply.

Very cool.

You know what I thought ? I thought you had modified the A4 sheet size
to compute the paperheight and paperwidth ?

I wonder if that's another way of proceeding.

Best,
Ashim

On Sat, Nov 18, 2023 at 12:51?PM Olivier Crouzet
<olivier.crouzet at univ-nantes.fr> wrote:
>
> Dear Ashim,
>
> these are documented in the LaTeX 'geometry' package (see for example
> on CTAN: https://ctan.org/pkg/geometry). As I added in my response on
> Stackoverflow, several parts in the RMarkdown header actually concern
> information that are processed by LaTeX to actually generate the PDF,
> among which the 'geometry' line. For someone who is used to working with
> LaTeX, it is relatively natural to 'identify' LaTeX options in these
> lines even though they are not structured exactly this way in a LaTeX
> document (but their names are the same).
>
> Concerning the choice for these specific numbers, it is relatively
> arbitrary. I've been doing this on LaTeX for years when I want to
> generate slides without using the 'beamer' document class and the
> things to take into account are:
>
> - These dimensions express the physical sizes of the pdf page (in a
> sense, what their size would be if you print the document without
> adapting to the paper in your printer)
> - If these sizes are reduced... the relative font size will increase
> because LaTeX will project the same font on a smaller virtual paper,
> - And if these sizes are increased... the relative font size will
> decrease because LaTeX will project the same font on a larger
> virtual paper,
> - I processed starting from 16x9cm sizes, resp. for paperwidth and
> paperheight, and estimated that the fonts were too large to my taste,
> then doubled them and felt that the fonts were too small for slides,
> then I ended up trying multiplying 16x9cm by a factor of 1.5, which
> gave me 24x13.5cm and I found it was ok.
> - But one may vary these sizes arbitrary (even using smaller
> steps and ratios differing from 16/9) depending on the aims to be
> reached.
> - It is also possible to specify different units (pt = points, in =
> inches...)
>
> Yours.
> Olivier.
>
> On Sat, 18 Nov 2023 09:53:19 +0530 Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
>
> > Dear Olivier,
> >
> > Many thanks for your reply.
> >
> > This works well for me.
> >
> > How did you come up with the pagewidth / pageheight numbers?  I do
> > understand that their ratio = 16:9,
> > but how did you choose these numbers?
> >
> > Best Regards,
> > Ashim
> >
> > On Fri, Nov 17, 2023 at 9:25?PM Olivier Crouzet
> > <olivier.crouzet at univ-nantes.fr> wrote:
> > >
> > > Dear Ashim,
> > >
> > > I don't think the aspectratio is appropriate in this context because
> > > it would imply that the beamer (LaTeX) class is used but you're
> > > actually using the article (LaTeX) class.
> > >
> > > You may use specifications of the geometry package rather than
> > > specifying options to the class:
> > >
> > > e.g. replace your current header:
> > >
> > > ---
> > > title: "Testing landscape and aspect ratio"
> > > output:
> > >   pdf_document:
> > >     number_sections: true
> > > classoption:
> > >   - landscape
> > >   - "aspectratio=169"
> > > header-includes:
> > >    - \usepackage{dcolumn}
> > > documentclass: article
> > > geometry: margin=1.5cm
> > > ---
> > >
> > > with this one:
> > >
> > > ---
> > > title: "Testing landscape and aspect ratio"
> > > output:
> > >   pdf_document:
> > >     number_sections: true
> > > header-includes:
> > >    - \usepackage{dcolumn}
> > > documentclass: article
> > > geometry: margin=1.5cm, paperwidth=24cm, paperheight=13.5cm
> > > ---
> > >
> > > Of course, you may change the exact dimensions and it will impact
> > > the relative font sizes. I've tested it and it generates what you
> > > want.
> > >
> > > Yours.
> > > Olivier.
> > >
> > >
> > >
> > >
> > >
> > >  On Tue, 14 Nov 2023 10:03:23
> > > +0530 Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > >
> > > > Dear all,
> > > >
> > > > I have posted a query which has received a response but that is
> > > > not working on my computer.
> > > >
> > > > Here is the query:
> > > >
> > > > https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
> > > >
> > > > Can someone please help me ?
> > > >
> > > > Best Regards,
> > > > Ashim
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html and provide commented,
> > > > minimal, self-contained, reproducible code.
> > >
> > >
> > > --
> > >   Olivier Crouzet, PhD
> > >   http://olivier.ghostinthemachine.space
> > >   /Ma?tre de Conf?rences/
> > >   @LLING - Laboratoire de Linguistique de Nantes
> > >     UMR6310 CNRS / Universit? de Nantes
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html and provide commented,
> > > minimal, self-contained, reproducible code.
>
>
> --
>   Olivier Crouzet, PhD
>   http://olivier.ghostinthemachine.space
>   /Ma?tre de Conf?rences/
>   @LLING - Laboratoire de Linguistique de Nantes
>     UMR6310 CNRS / Universit? de Nantes
>
>


From o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r  Sat Nov 18 10:03:31 2023
From: o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r (Olivier Crouzet)
Date: Sat, 18 Nov 2023 10:03:31 +0100
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <CAC8=1eoX6yTXqGPC-rcbff4BvkiQFugaVwtzyyAnunfhdya7fQ@mail.gmail.com>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <20231117165457.8604d4f30b1a5ccc5e242aa4@univ-nantes.fr>
 <CAC8=1er4HB2UKXOATpPD=MiPWt0Zy70usjCV1v_AtxzJR0+qHg@mail.gmail.com>
 <20231118082125.19d2c852185317ee068d772d@univ-nantes.fr>
 <CAC8=1eoX6yTXqGPC-rcbff4BvkiQFugaVwtzyyAnunfhdya7fQ@mail.gmail.com>
Message-ID: <20231118100331.efc067a613da11b653fe6754@univ-nantes.fr>

Indeed, it's not far from that. Actually stating these parameters
(paperwidht and paperheight) with the geometry package replaces the A4
size (or any default size as e.g. letterpaper...) with specific
dimensions. But the nuance is that common sizes are declared with, e.g.
the 'paper=a4paper' argument, but that in your situation this setup
will be replaced with specific dimensions (the paper argument only
accepts predefined names defining conventional dimensions, while the
paperwidth and paperheight arguments let you define arbitrary
dimensions).

Yours.
Olivier.



On Sat, 18 Nov 2023 13:20:49 +0530
Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear Olivier,
> 
> Many thanks for your reply.
> 
> Very cool.
> 
> You know what I thought ? I thought you had modified the A4 sheet size
> to compute the paperheight and paperwidth ?
> 
> I wonder if that's another way of proceeding.
> 
> Best,
> Ashim
> 
> On Sat, Nov 18, 2023 at 12:51?PM Olivier Crouzet
> <olivier.crouzet at univ-nantes.fr> wrote:
> >
> > Dear Ashim,
> >
> > these are documented in the LaTeX 'geometry' package (see for
> > example on CTAN: https://ctan.org/pkg/geometry). As I added in my
> > response on Stackoverflow, several parts in the RMarkdown header
> > actually concern information that are processed by LaTeX to
> > actually generate the PDF, among which the 'geometry' line. For
> > someone who is used to working with LaTeX, it is relatively natural
> > to 'identify' LaTeX options in these lines even though they are not
> > structured exactly this way in a LaTeX document (but their names
> > are the same).
> >
> > Concerning the choice for these specific numbers, it is relatively
> > arbitrary. I've been doing this on LaTeX for years when I want to
> > generate slides without using the 'beamer' document class and the
> > things to take into account are:
> >
> > - These dimensions express the physical sizes of the pdf page (in a
> > sense, what their size would be if you print the document without
> > adapting to the paper in your printer)
> > - If these sizes are reduced... the relative font size will increase
> > because LaTeX will project the same font on a smaller virtual paper,
> > - And if these sizes are increased... the relative font size will
> > decrease because LaTeX will project the same font on a larger
> > virtual paper,
> > - I processed starting from 16x9cm sizes, resp. for paperwidth and
> > paperheight, and estimated that the fonts were too large to my
> > taste, then doubled them and felt that the fonts were too small for
> > slides, then I ended up trying multiplying 16x9cm by a factor of
> > 1.5, which gave me 24x13.5cm and I found it was ok.
> > - But one may vary these sizes arbitrary (even using smaller
> > steps and ratios differing from 16/9) depending on the aims to be
> > reached.
> > - It is also possible to specify different units (pt = points, in =
> > inches...)
> >
> > Yours.
> > Olivier.
> >
> > On Sat, 18 Nov 2023 09:53:19 +0530 Ashim Kapoor
> > <ashimkapoor at gmail.com> wrote:
> >
> > > Dear Olivier,
> > >
> > > Many thanks for your reply.
> > >
> > > This works well for me.
> > >
> > > How did you come up with the pagewidth / pageheight numbers?  I do
> > > understand that their ratio = 16:9,
> > > but how did you choose these numbers?
> > >
> > > Best Regards,
> > > Ashim
> > >
> > > On Fri, Nov 17, 2023 at 9:25?PM Olivier Crouzet
> > > <olivier.crouzet at univ-nantes.fr> wrote:
> > > >
> > > > Dear Ashim,
> > > >
> > > > I don't think the aspectratio is appropriate in this context
> > > > because it would imply that the beamer (LaTeX) class is used
> > > > but you're actually using the article (LaTeX) class.
> > > >
> > > > You may use specifications of the geometry package rather than
> > > > specifying options to the class:
> > > >
> > > > e.g. replace your current header:
> > > >
> > > > ---
> > > > title: "Testing landscape and aspect ratio"
> > > > output:
> > > >   pdf_document:
> > > >     number_sections: true
> > > > classoption:
> > > >   - landscape
> > > >   - "aspectratio=169"
> > > > header-includes:
> > > >    - \usepackage{dcolumn}
> > > > documentclass: article
> > > > geometry: margin=1.5cm
> > > > ---
> > > >
> > > > with this one:
> > > >
> > > > ---
> > > > title: "Testing landscape and aspect ratio"
> > > > output:
> > > >   pdf_document:
> > > >     number_sections: true
> > > > header-includes:
> > > >    - \usepackage{dcolumn}
> > > > documentclass: article
> > > > geometry: margin=1.5cm, paperwidth=24cm, paperheight=13.5cm
> > > > ---
> > > >
> > > > Of course, you may change the exact dimensions and it will
> > > > impact the relative font sizes. I've tested it and it generates
> > > > what you want.
> > > >
> > > > Yours.
> > > > Olivier.
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >  On Tue, 14 Nov 2023 10:03:23
> > > > +0530 Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > > >
> > > > > Dear all,
> > > > >
> > > > > I have posted a query which has received a response but that
> > > > > is not working on my computer.
> > > > >
> > > > > Here is the query:
> > > > >
> > > > > https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
> > > > >
> > > > > Can someone please help me ?
> > > > >
> > > > > Best Regards,
> > > > > Ashim
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> > > > > http://www.R-project.org/posting-guide.html and provide
> > > > > commented, minimal, self-contained, reproducible code.
> > > >
> > > >
> > > > --
> > > >   Olivier Crouzet, PhD
> > > >   http://olivier.ghostinthemachine.space
> > > >   /Ma?tre de Conf?rences/
> > > >   @LLING - Laboratoire de Linguistique de Nantes
> > > >     UMR6310 CNRS / Universit? de Nantes
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html and provide
> > > > commented, minimal, self-contained, reproducible code.
> >
> >
> > --
> >   Olivier Crouzet, PhD
> >   http://olivier.ghostinthemachine.space
> >   /Ma?tre de Conf?rences/
> >   @LLING - Laboratoire de Linguistique de Nantes
> >     UMR6310 CNRS / Universit? de Nantes
> >
> >


-- 
  Olivier Crouzet, PhD
  http://olivier.ghostinthemachine.space
  /Ma?tre de Conf?rences/
  @LLING - Laboratoire de Linguistique de Nantes
    UMR6310 CNRS / Universit? de Nantes


From o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r  Sat Nov 18 10:06:43 2023
From: o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r (Olivier Crouzet)
Date: Sat, 18 Nov 2023 10:06:43 +0100
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <CAC8=1eoX6yTXqGPC-rcbff4BvkiQFugaVwtzyyAnunfhdya7fQ@mail.gmail.com>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <20231117165457.8604d4f30b1a5ccc5e242aa4@univ-nantes.fr>
 <CAC8=1er4HB2UKXOATpPD=MiPWt0Zy70usjCV1v_AtxzJR0+qHg@mail.gmail.com>
 <20231118082125.19d2c852185317ee068d772d@univ-nantes.fr>
 <CAC8=1eoX6yTXqGPC-rcbff4BvkiQFugaVwtzyyAnunfhdya7fQ@mail.gmail.com>
Message-ID: <20231118100643.495138754b2fbba2a35b1de0@univ-nantes.fr>

And indeed again (I did not understand your previous question exactly
at first), the 'hard-coded' definition of a landscape a4 sheet would
therefore be:

paperwidth=29.7cm, paperheight=21cm

Olivier.

On Sat, 18 Nov 2023 13:20:49 +0530
Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear Olivier,
> 
> Many thanks for your reply.
> 
> Very cool.
> 
> You know what I thought ? I thought you had modified the A4 sheet size
> to compute the paperheight and paperwidth ?
> 
> I wonder if that's another way of proceeding.
> 
> Best,
> Ashim
> 
> On Sat, Nov 18, 2023 at 12:51?PM Olivier Crouzet
> <olivier.crouzet at univ-nantes.fr> wrote:
> >
> > Dear Ashim,
> >
> > these are documented in the LaTeX 'geometry' package (see for
> > example on CTAN: https://ctan.org/pkg/geometry). As I added in my
> > response on Stackoverflow, several parts in the RMarkdown header
> > actually concern information that are processed by LaTeX to
> > actually generate the PDF, among which the 'geometry' line. For
> > someone who is used to working with LaTeX, it is relatively natural
> > to 'identify' LaTeX options in these lines even though they are not
> > structured exactly this way in a LaTeX document (but their names
> > are the same).
> >
> > Concerning the choice for these specific numbers, it is relatively
> > arbitrary. I've been doing this on LaTeX for years when I want to
> > generate slides without using the 'beamer' document class and the
> > things to take into account are:
> >
> > - These dimensions express the physical sizes of the pdf page (in a
> > sense, what their size would be if you print the document without
> > adapting to the paper in your printer)
> > - If these sizes are reduced... the relative font size will increase
> > because LaTeX will project the same font on a smaller virtual paper,
> > - And if these sizes are increased... the relative font size will
> > decrease because LaTeX will project the same font on a larger
> > virtual paper,
> > - I processed starting from 16x9cm sizes, resp. for paperwidth and
> > paperheight, and estimated that the fonts were too large to my
> > taste, then doubled them and felt that the fonts were too small for
> > slides, then I ended up trying multiplying 16x9cm by a factor of
> > 1.5, which gave me 24x13.5cm and I found it was ok.
> > - But one may vary these sizes arbitrary (even using smaller
> > steps and ratios differing from 16/9) depending on the aims to be
> > reached.
> > - It is also possible to specify different units (pt = points, in =
> > inches...)
> >
> > Yours.
> > Olivier.
> >
> > On Sat, 18 Nov 2023 09:53:19 +0530 Ashim Kapoor
> > <ashimkapoor at gmail.com> wrote:
> >
> > > Dear Olivier,
> > >
> > > Many thanks for your reply.
> > >
> > > This works well for me.
> > >
> > > How did you come up with the pagewidth / pageheight numbers?  I do
> > > understand that their ratio = 16:9,
> > > but how did you choose these numbers?
> > >
> > > Best Regards,
> > > Ashim
> > >
> > > On Fri, Nov 17, 2023 at 9:25?PM Olivier Crouzet
> > > <olivier.crouzet at univ-nantes.fr> wrote:
> > > >
> > > > Dear Ashim,
> > > >
> > > > I don't think the aspectratio is appropriate in this context
> > > > because it would imply that the beamer (LaTeX) class is used
> > > > but you're actually using the article (LaTeX) class.
> > > >
> > > > You may use specifications of the geometry package rather than
> > > > specifying options to the class:
> > > >
> > > > e.g. replace your current header:
> > > >
> > > > ---
> > > > title: "Testing landscape and aspect ratio"
> > > > output:
> > > >   pdf_document:
> > > >     number_sections: true
> > > > classoption:
> > > >   - landscape
> > > >   - "aspectratio=169"
> > > > header-includes:
> > > >    - \usepackage{dcolumn}
> > > > documentclass: article
> > > > geometry: margin=1.5cm
> > > > ---
> > > >
> > > > with this one:
> > > >
> > > > ---
> > > > title: "Testing landscape and aspect ratio"
> > > > output:
> > > >   pdf_document:
> > > >     number_sections: true
> > > > header-includes:
> > > >    - \usepackage{dcolumn}
> > > > documentclass: article
> > > > geometry: margin=1.5cm, paperwidth=24cm, paperheight=13.5cm
> > > > ---
> > > >
> > > > Of course, you may change the exact dimensions and it will
> > > > impact the relative font sizes. I've tested it and it generates
> > > > what you want.
> > > >
> > > > Yours.
> > > > Olivier.
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >  On Tue, 14 Nov 2023 10:03:23
> > > > +0530 Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > > >
> > > > > Dear all,
> > > > >
> > > > > I have posted a query which has received a response but that
> > > > > is not working on my computer.
> > > > >
> > > > > Here is the query:
> > > > >
> > > > > https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
> > > > >
> > > > > Can someone please help me ?
> > > > >
> > > > > Best Regards,
> > > > > Ashim
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> > > > > http://www.R-project.org/posting-guide.html and provide
> > > > > commented, minimal, self-contained, reproducible code.
> > > >
> > > >
> > > > --
> > > >   Olivier Crouzet, PhD
> > > >   http://olivier.ghostinthemachine.space
> > > >   /Ma?tre de Conf?rences/
> > > >   @LLING - Laboratoire de Linguistique de Nantes
> > > >     UMR6310 CNRS / Universit? de Nantes
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html and provide
> > > > commented, minimal, self-contained, reproducible code.
> >
> >
> > --
> >   Olivier Crouzet, PhD
> >   http://olivier.ghostinthemachine.space
> >   /Ma?tre de Conf?rences/
> >   @LLING - Laboratoire de Linguistique de Nantes
> >     UMR6310 CNRS / Universit? de Nantes
> >
> >


-- 
  Olivier Crouzet, PhD
  http://olivier.ghostinthemachine.space
  /Ma?tre de Conf?rences/
  @LLING - Laboratoire de Linguistique de Nantes
    UMR6310 CNRS / Universit? de Nantes


From @@h|mk@poor @end|ng |rom gm@||@com  Sat Nov 18 10:12:15 2023
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Sat, 18 Nov 2023 14:42:15 +0530
Subject: [R] 
 Can someone please have a look at this query on stackoverflow?
In-Reply-To: <20231118100643.495138754b2fbba2a35b1de0@univ-nantes.fr>
References: <CAC8=1erGNHt35GagCm=Su-Q0Wzx=9pGH3OLOQrc66pKq3+M+GQ@mail.gmail.com>
 <20231117165457.8604d4f30b1a5ccc5e242aa4@univ-nantes.fr>
 <CAC8=1er4HB2UKXOATpPD=MiPWt0Zy70usjCV1v_AtxzJR0+qHg@mail.gmail.com>
 <20231118082125.19d2c852185317ee068d772d@univ-nantes.fr>
 <CAC8=1eoX6yTXqGPC-rcbff4BvkiQFugaVwtzyyAnunfhdya7fQ@mail.gmail.com>
 <20231118100643.495138754b2fbba2a35b1de0@univ-nantes.fr>
Message-ID: <CAC8=1ertJBiH+dy7YbbgcUFT-_80oqvD-v27=dZv39V4wc_QLQ@mail.gmail.com>

Dear Olivier,

Many thanks.

Best Regards,
Ashim

On Sat, Nov 18, 2023 at 2:36?PM Olivier Crouzet
<olivier.crouzet at univ-nantes.fr> wrote:
>
> And indeed again (I did not understand your previous question exactly
> at first), the 'hard-coded' definition of a landscape a4 sheet would
> therefore be:
>
> paperwidth=29.7cm, paperheight=21cm
>
> Olivier.
>
> On Sat, 18 Nov 2023 13:20:49 +0530
> Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> > Dear Olivier,
> >
> > Many thanks for your reply.
> >
> > Very cool.
> >
> > You know what I thought ? I thought you had modified the A4 sheet size
> > to compute the paperheight and paperwidth ?
> >
> > I wonder if that's another way of proceeding.
> >
> > Best,
> > Ashim
> >
> > On Sat, Nov 18, 2023 at 12:51?PM Olivier Crouzet
> > <olivier.crouzet at univ-nantes.fr> wrote:
> > >
> > > Dear Ashim,
> > >
> > > these are documented in the LaTeX 'geometry' package (see for
> > > example on CTAN: https://ctan.org/pkg/geometry). As I added in my
> > > response on Stackoverflow, several parts in the RMarkdown header
> > > actually concern information that are processed by LaTeX to
> > > actually generate the PDF, among which the 'geometry' line. For
> > > someone who is used to working with LaTeX, it is relatively natural
> > > to 'identify' LaTeX options in these lines even though they are not
> > > structured exactly this way in a LaTeX document (but their names
> > > are the same).
> > >
> > > Concerning the choice for these specific numbers, it is relatively
> > > arbitrary. I've been doing this on LaTeX for years when I want to
> > > generate slides without using the 'beamer' document class and the
> > > things to take into account are:
> > >
> > > - These dimensions express the physical sizes of the pdf page (in a
> > > sense, what their size would be if you print the document without
> > > adapting to the paper in your printer)
> > > - If these sizes are reduced... the relative font size will increase
> > > because LaTeX will project the same font on a smaller virtual paper,
> > > - And if these sizes are increased... the relative font size will
> > > decrease because LaTeX will project the same font on a larger
> > > virtual paper,
> > > - I processed starting from 16x9cm sizes, resp. for paperwidth and
> > > paperheight, and estimated that the fonts were too large to my
> > > taste, then doubled them and felt that the fonts were too small for
> > > slides, then I ended up trying multiplying 16x9cm by a factor of
> > > 1.5, which gave me 24x13.5cm and I found it was ok.
> > > - But one may vary these sizes arbitrary (even using smaller
> > > steps and ratios differing from 16/9) depending on the aims to be
> > > reached.
> > > - It is also possible to specify different units (pt = points, in =
> > > inches...)
> > >
> > > Yours.
> > > Olivier.
> > >
> > > On Sat, 18 Nov 2023 09:53:19 +0530 Ashim Kapoor
> > > <ashimkapoor at gmail.com> wrote:
> > >
> > > > Dear Olivier,
> > > >
> > > > Many thanks for your reply.
> > > >
> > > > This works well for me.
> > > >
> > > > How did you come up with the pagewidth / pageheight numbers?  I do
> > > > understand that their ratio = 16:9,
> > > > but how did you choose these numbers?
> > > >
> > > > Best Regards,
> > > > Ashim
> > > >
> > > > On Fri, Nov 17, 2023 at 9:25?PM Olivier Crouzet
> > > > <olivier.crouzet at univ-nantes.fr> wrote:
> > > > >
> > > > > Dear Ashim,
> > > > >
> > > > > I don't think the aspectratio is appropriate in this context
> > > > > because it would imply that the beamer (LaTeX) class is used
> > > > > but you're actually using the article (LaTeX) class.
> > > > >
> > > > > You may use specifications of the geometry package rather than
> > > > > specifying options to the class:
> > > > >
> > > > > e.g. replace your current header:
> > > > >
> > > > > ---
> > > > > title: "Testing landscape and aspect ratio"
> > > > > output:
> > > > >   pdf_document:
> > > > >     number_sections: true
> > > > > classoption:
> > > > >   - landscape
> > > > >   - "aspectratio=169"
> > > > > header-includes:
> > > > >    - \usepackage{dcolumn}
> > > > > documentclass: article
> > > > > geometry: margin=1.5cm
> > > > > ---
> > > > >
> > > > > with this one:
> > > > >
> > > > > ---
> > > > > title: "Testing landscape and aspect ratio"
> > > > > output:
> > > > >   pdf_document:
> > > > >     number_sections: true
> > > > > header-includes:
> > > > >    - \usepackage{dcolumn}
> > > > > documentclass: article
> > > > > geometry: margin=1.5cm, paperwidth=24cm, paperheight=13.5cm
> > > > > ---
> > > > >
> > > > > Of course, you may change the exact dimensions and it will
> > > > > impact the relative font sizes. I've tested it and it generates
> > > > > what you want.
> > > > >
> > > > > Yours.
> > > > > Olivier.
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >  On Tue, 14 Nov 2023 10:03:23
> > > > > +0530 Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > > > >
> > > > > > Dear all,
> > > > > >
> > > > > > I have posted a query which has received a response but that
> > > > > > is not working on my computer.
> > > > > >
> > > > > > Here is the query:
> > > > > >
> > > > > > https://stackoverflow.com/questions/77387434/pdf-from-rmarkdown-landscape-and-aspectratio-169
> > > > > >
> > > > > > Can someone please help me ?
> > > > > >
> > > > > > Best Regards,
> > > > > > Ashim
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide
> > > > > > http://www.R-project.org/posting-guide.html and provide
> > > > > > commented, minimal, self-contained, reproducible code.
> > > > >
> > > > >
> > > > > --
> > > > >   Olivier Crouzet, PhD
> > > > >   http://olivier.ghostinthemachine.space
> > > > >   /Ma?tre de Conf?rences/
> > > > >   @LLING - Laboratoire de Linguistique de Nantes
> > > > >     UMR6310 CNRS / Universit? de Nantes
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> > > > > http://www.R-project.org/posting-guide.html and provide
> > > > > commented, minimal, self-contained, reproducible code.
> > >
> > >
> > > --
> > >   Olivier Crouzet, PhD
> > >   http://olivier.ghostinthemachine.space
> > >   /Ma?tre de Conf?rences/
> > >   @LLING - Laboratoire de Linguistique de Nantes
> > >     UMR6310 CNRS / Universit? de Nantes
> > >
> > >
>
>
> --
>   Olivier Crouzet, PhD
>   http://olivier.ghostinthemachine.space
>   /Ma?tre de Conf?rences/
>   @LLING - Laboratoire de Linguistique de Nantes
>     UMR6310 CNRS / Universit? de Nantes
>
>


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Sat Nov 18 12:44:07 2023
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Sat, 18 Nov 2023 11:44:07 +0000
Subject: [R] combine barchart and xyplot in lattice
Message-ID: <IA1P223MB0499A7A99A8AF622E29A0449FAB6A@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>

In below graph, I would like to add two vertical lines using
panel.abline(). ?Is this possible?

Thanks,
Naresh

mydf <- data.frame(hour = rep(6:20, 2),
traffic = c(round(dnorm(6:20, 9, 3) * 10000), round(dnorm(6:20, 17, 4) *
10000)),
direction = rep(c("inbound", "outbound"), c(15, 15)))

vehicles <- data.frame(hour = 6:20,
count = c(100, 120, 140, 125, 105, 80, 70, 75, 80, 100, 110, 120, 115,
110, 100))

library(lattice)
library(latticeExtra)

# This works
mybars <- barchart(traffic ~ as.factor(hour), groups = direction,
stack = TRUE, horizontal = FALSE, data = mydf,
auto.key = list(columns = 2, space = "bottom"), xlab = "hour")

mylines <- xyplot(count ~ as.factor(hour), type = "l", lwd = 2,
col = 2, data = vehicles)

mybars + mylines

# This does not work. ?Lines are not correctly placed.
mylines <- xyplot(count ~ as.factor(hour), type = "l", lwd = 2,
col = 2, data = vehicles, panel = function(x, y, ...) {
panel.xyplot(x, y, ...)
panel.abliine(v = as.factor(c(9, 17)), lty = 2, col = "gray")
})

From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sat Nov 18 16:08:47 2023
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sat, 18 Nov 2023 10:08:47 -0500
Subject: [R] combine barchart and xyplot in lattice
In-Reply-To: <IA1P223MB0499A7A99A8AF622E29A0449FAB6A@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
References: <IA1P223MB0499A7A99A8AF622E29A0449FAB6A@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
Message-ID: <CADfFDC4zUrvHsmZ1Kbdzx=ek4wVKdtLE8r1YGppq8hQoFof9mw@mail.gmail.com>

On Sat, 18 Nov 2023 at 06:44, Naresh Gurbuxani
<naresh_gurbuxani at hotmail.com> wrote:
>
> In below graph, I would like to add two vertical lines using
> panel.abline().  Is this possible?

I assume you want the 'v' variable in panel.abline() to be interpreted
in the context of your x-axis, which here represents a factor
variable. Unless two factor variables have the same levels, their
values don't really mean the same thing. So either you need to specify
the levels, or make the axis numeric:

# option 1 - factor
xyplot(count ~ as.factor(hour), type = "l", lwd = 2,
       col = 2, data = vehicles,
       panel = function(x, y, ...) {
           panel.xyplot(x, y, ...)
           panel.abline(v = factor(c("9", "17"), levels = levels(x)),
                        lty = 2, col = "gray")
       })

# option 2 - numeric
xyplot(count ~ hour, type = "l", lwd = 2,
       col = 2, data = vehicles,
       panel = function(x, y, ...) {
           panel.xyplot(x, y, ...)
           panel.abline(v = c(9, 17), lty = 2, col = "gray")
       })

Best,
-Deepayan

>
> Thanks,
> Naresh
>
> mydf <- data.frame(hour = rep(6:20, 2),
> traffic = c(round(dnorm(6:20, 9, 3) * 10000), round(dnorm(6:20, 17, 4) *
> 10000)),
> direction = rep(c("inbound", "outbound"), c(15, 15)))
>
> vehicles <- data.frame(hour = 6:20,
> count = c(100, 120, 140, 125, 105, 80, 70, 75, 80, 100, 110, 120, 115,
> 110, 100))
>
> library(lattice)
> library(latticeExtra)
>
> # This works
> mybars <- barchart(traffic ~ as.factor(hour), groups = direction,
> stack = TRUE, horizontal = FALSE, data = mydf,
> auto.key = list(columns = 2, space = "bottom"), xlab = "hour")
>
> mylines <- xyplot(count ~ as.factor(hour), type = "l", lwd = 2,
> col = 2, data = vehicles)
>
> mybars + mylines
>
> # This does not work.  Lines are not correctly placed.
> mylines <- xyplot(count ~ as.factor(hour), type = "l", lwd = 2,
> col = 2, data = vehicles, panel = function(x, y, ...) {
> panel.xyplot(x, y, ...)
> panel.abliine(v = as.factor(c(9, 17)), lty = 2, col = "gray")
> })
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Sat Nov 18 17:48:08 2023
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Sat, 18 Nov 2023 16:48:08 +0000
Subject: [R] combine barchart and xyplot in lattice
In-Reply-To: <CADfFDC4zUrvHsmZ1Kbdzx=ek4wVKdtLE8r1YGppq8hQoFof9mw@mail.gmail.com>
References: <CADfFDC4zUrvHsmZ1Kbdzx=ek4wVKdtLE8r1YGppq8hQoFof9mw@mail.gmail.com>
Message-ID: <IA1P223MB04998CDDEE408567C1F0024BFAB6A@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>

I converted to factor because, in barchart, x-axis seems to be factor only.  Without factor, x labels are 1, 2, 3, ?

Solution 1 works for me.  If there is a method for barchart, I am interested in looking at that as well.

Thanks,
Naresh
Sent from my iPhone

> On Nov 18, 2023, at 10:09?AM, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> 
> ?On Sat, 18 Nov 2023 at 06:44, Naresh Gurbuxani
> <naresh_gurbuxani at hotmail.com> wrote:
>> 
>> In below graph, I would like to add two vertical lines using
>> panel.abline().  Is this possible?
> 
> I assume you want the 'v' variable in panel.abline() to be interpreted
> in the context of your x-axis, which here represents a factor
> variable. Unless two factor variables have the same levels, their
> values don't really mean the same thing. So either you need to specify
> the levels, or make the axis numeric:
> 
> # option 1 - factor
> xyplot(count ~ as.factor(hour), type = "l", lwd = 2,
>       col = 2, data = vehicles,
>       panel = function(x, y, ...) {
>           panel.xyplot(x, y, ...)
>           panel.abline(v = factor(c("9", "17"), levels = levels(x)),
>                        lty = 2, col = "gray")
>       })
> 
> # option 2 - numeric
> xyplot(count ~ hour, type = "l", lwd = 2,
>       col = 2, data = vehicles,
>       panel = function(x, y, ...) {
>           panel.xyplot(x, y, ...)
>           panel.abline(v = c(9, 17), lty = 2, col = "gray")
>       })
> 
> Best,
> -Deepayan
> 
>> 
>> Thanks,
>> Naresh
>> 
>> mydf <- data.frame(hour = rep(6:20, 2),
>> traffic = c(round(dnorm(6:20, 9, 3) * 10000), round(dnorm(6:20, 17, 4) *
>> 10000)),
>> direction = rep(c("inbound", "outbound"), c(15, 15)))
>> 
>> vehicles <- data.frame(hour = 6:20,
>> count = c(100, 120, 140, 125, 105, 80, 70, 75, 80, 100, 110, 120, 115,
>> 110, 100))
>> 
>> library(lattice)
>> library(latticeExtra)
>> 
>> # This works
>> mybars <- barchart(traffic ~ as.factor(hour), groups = direction,
>> stack = TRUE, horizontal = FALSE, data = mydf,
>> auto.key = list(columns = 2, space = "bottom"), xlab = "hour")
>> 
>> mylines <- xyplot(count ~ as.factor(hour), type = "l", lwd = 2,
>> col = 2, data = vehicles)
>> 
>> mybars + mylines
>> 
>> # This does not work.  Lines are not correctly placed.
>> mylines <- xyplot(count ~ as.factor(hour), type = "l", lwd = 2,
>> col = 2, data = vehicles, panel = function(x, y, ...) {
>> panel.xyplot(x, y, ...)
>> panel.abliine(v = as.factor(c(9, 17)), lty = 2, col = "gray")
>> })
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

From pd@|gd @end|ng |rom gm@||@com  Mon Nov 20 10:47:55 2023
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 20 Nov 2023 10:47:55 +0100
Subject: [R] anyone having trouble accesing CRAN?
In-Reply-To: <20231115222332.7746cad7@Tarkus>
References: <824e958a-e563-8e7e-8b6d-9ea245460d63@binghamton.edu>
 <20231115222332.7746cad7@Tarkus>
Message-ID: <1AEF881D-C58C-4731-B71B-C7E4F1C16432@gmail.com>

Notice that getCRANmirrors() without the local.only=TRUE gets its list from ...tada.... cran.r-project.org. 

Arguably, that might be in for a change. Meanwhile, you might just use cloud.r-project.org right away.  

-pd

> On 15 Nov 2023, at 20:23 , Ivan Krylov <krylov.r00t at gmail.com> wrote:
> 
> On Wed, 15 Nov 2023 14:13:00 -0500
> "Christopher W. Ryan via R-help" <r-help at r-project.org> wrote:
> 
>> Anyone seeing similar?
> 
> Same for me.
> 
> While it worked, CRAN website had the following message:
> 
>>> The CRAN Admin Team will perform system upgrades during the period
>>> Wednesday November 15 until Thursday November 16, 2023. There will
>>> be intermittent outages in service during this time. 
> 
> Use chooseCRANmirror(local.only = TRUE) (or subset() the return value
> of getCRANmirrors(local.only = TRUE)) to access a mirror that works.
> 
> -- 
> Best regards,
> Ivan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j@b@y@t194 @end|ng |rom gm@||@com  Mon Nov 20 13:30:00 2023
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Mon, 20 Nov 2023 16:00:00 +0330
Subject: [R] Calculating volume under polygons
Message-ID: <CANTxAm+5tCrkbL=PnH_A0VMEDTOKZEcUjgB-Nu+H2ALDJfrNWQ@mail.gmail.com>

Dear all;
I am trying to calculate volume under each polygon of a shapefile according
to a DEM.
when I run the code, it gives me an error as follows.
"
Error in h(simpleError(msg, call)) :
  error in evaluating the argument 'x' in selecting a method for function
'addAttrToGeom': sp supports Z dimension only for POINT and MULTIPOINT.
use `st_zm(...)` to coerce to XY dimensions
"
I want to have a table that contains one column corresponding to the
polygon rank and another that contains the volume on that polyon.
I would be more than happy if anyone could help me.
I provided codes at the end of this email.
Sincerely


##########################################################################################
library(raster);
library(sf)
# Load the DEM raster and shapefile
r <- raster("E:/Base1.tif")
p <- read_sf(dsn = "E:/Sites.shp", layer = " Sites")
# Extract the values of the DEM raster for each polygon
values <- extract(r, p)
  Error in h(simpleError(msg, call)) :
  error in evaluating the argument 'x' in selecting a method for function
'addAttrToGeom': sp supports Z dimension only for POINT and MULTIPOINT.
use `st_zm(...)` to coerce to XY dimensions

# Calculate the volume of each polygon
volumes <- sapply(values, function(x) rasterVolume(x, r))
# Print the results
for (i in 1:length(volumes)) {
  cat(sprintf("Volume under polygon %d: %f\n", i, volumes[i]))
}
##########################################################################################





-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From t@v|b@r @end|ng |rom gm@||@com  Mon Nov 20 14:45:44 2023
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Mon, 20 Nov 2023 15:45:44 +0200
Subject: [R] Calculating volume under polygons
In-Reply-To: <CANTxAm+5tCrkbL=PnH_A0VMEDTOKZEcUjgB-Nu+H2ALDJfrNWQ@mail.gmail.com>
References: <CANTxAm+5tCrkbL=PnH_A0VMEDTOKZEcUjgB-Nu+H2ALDJfrNWQ@mail.gmail.com>
Message-ID: <67772a85-c138-442a-b5b9-9de71a67a11a@gmail.com>

Hi:

Some preliminary comments first

1- You might get a better response posting to R-sig-Geo

2- Probably better to switch to the `terra` package instead of the older 
`raster`

3- Furthermore, there is the package `exactextractr` that ensures that 
edge pixels are taken into account, weighted by the actual, partial 
coverage of each pixel by the polygon.

4- Can you post: your R version, and version of the relevant packages, 
and information about the polygons and DEM (i.e. `str(p)` and `str(r)` )


On 20/11/2023 14:30, javad bayat wrote:
> Dear all;
> I am trying to calculate volume under each polygon of a shapefile according
> to a DEM.
> when I run the code, it gives me an error as follows.
> "
> Error in h(simpleError(msg, call)) :
>    error in evaluating the argument 'x' in selecting a method for function
> 'addAttrToGeom': sp supports Z dimension only for POINT and MULTIPOINT.
> use `st_zm(...)` to coerce to XY dimensions
> "
> I want to have a table that contains one column corresponding to the
> polygon rank and another that contains the volume on that polyon.
> I would be more than happy if anyone could help me.
> I provided codes at the end of this email.
> Sincerely
>
>
> ##########################################################################################
> library(raster);
> library(sf)
> # Load the DEM raster and shapefile
> r <- raster("E:/Base1.tif")
> p <- read_sf(dsn = "E:/Sites.shp", layer = " Sites")


Now to the question:

In `read_sf()`, when the source is a shapefile, you do not need the 
'layer' option. It doesn't hurt, but in this case I see that you have an 
extra space before the layer name. Could that be causing the problem?



> # Extract the values of the DEM raster for each polygon
> values <- extract(r, p)
>    Error in h(simpleError(msg, call)) :
>    error in evaluating the argument 'x' in selecting a method for function
> 'addAttrToGeom': sp supports Z dimension only for POINT and MULTIPOINT.
> use `st_zm(...)` to coerce to XY dimensions
>
> # Calculate the volume of each polygon
> volumes <- sapply(values, function(x) rasterVolume(x, r))

What is this "rasterVolume" function that you call here?


> # Print the results
> for (i in 1:length(volumes)) {
>    cat(sprintf("Volume under polygon %d: %f\n", i, volumes[i]))
> }
> ##########################################################################################
>
>
>
>
>
-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From @nde|@@h @end|ng |rom ucm@e@  Mon Nov 20 12:18:11 2023
From: @nde|@@h @end|ng |rom ucm@e@ (Ana de las Heras Molina)
Date: Mon, 20 Nov 2023 12:18:11 +0100
Subject: [R] Error in setwd(dir) when initializing R
Message-ID: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>

Hello,
I am Ana de las Heras, and I write to you because every time I open RStudio
or R directly I have the following message, before I can do anything at
all:

Error in setwd(dir) : no es posible cambiar el directorio de trabajo


At first I didn't pay much attention to it, but I am having lots of
troubles with different programs, including LinDa, ANCOMBC or Genome
InfoDbdata (and thus, phyloseq). After asking in the different forus of
each program, they have told me that the issue is more related to my R
installation and that first message I obtain when I start the program.

I would be very grateful if someone could help me. This issue started when
I installed the latest version of R (4.3.1. and now 4.3.2.). I have already
uninstalled and reinstalled both programs, as well as Rtools. I am not sure
if the issue could be related to ONe Drive, since the HOME folder is in
OneDrive. I am currently working on Windows 10, 64 bits.

Yours faithfully,
Ana
-- 
*Ana de las Heras Molina*


Nutrici?n Animal
Departamento de  Producci?n Animal
Facultad de Veterinaria
Universidad Complutense de Madrid

*Contacto*: 913943855/anaherasm at ucm.es

	[[alternative HTML version deleted]]


From kev|n@thorpe @end|ng |rom utoronto@c@  Mon Nov 20 16:30:51 2023
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Mon, 20 Nov 2023 15:30:51 +0000
Subject: [R] Error in setwd(dir) when initializing R
In-Reply-To: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
Message-ID: <689F6BFE-91B9-4006-898D-8719D6860FB9@utoronto.ca>

I think that you may be correct about OneDrive being related.

I have seen OneDrive associated with problems before.

What happens if you manually set the working directory to that location? Does it work if your default home directory is local to your machine?


> On Nov 20, 2023, at 6:18 AM, Ana de las Heras Molina <andelash at ucm.es> wrote:
> 
> [You don't often get email from andelash at ucm.es. Learn why this is important at https://aka.ms/LearnAboutSenderIdentification ]
> 
> Hello,
> I am Ana de las Heras, and I write to you because every time I open RStudio
> or R directly I have the following message, before I can do anything at
> all:
> 
> Error in setwd(dir) : no es posible cambiar el directorio de trabajo
> 
> 
> At first I didn't pay much attention to it, but I am having lots of
> troubles with different programs, including LinDa, ANCOMBC or Genome
> InfoDbdata (and thus, phyloseq). After asking in the different forus of
> each program, they have told me that the issue is more related to my R
> installation and that first message I obtain when I start the program.
> 
> I would be very grateful if someone could help me. This issue started when
> I installed the latest version of R (4.3.1. and now 4.3.2.). I have already
> uninstalled and reinstalled both programs, as well as Rtools. I am not sure
> if the issue could be related to ONe Drive, since the HOME folder is in
> OneDrive. I am currently working on Windows 10, 64 bits.
> 
> Yours faithfully,
> Ana
> --
> *Ana de las Heras Molina*
> 
> 
> Nutrici?n Animal
> Departamento de  Producci?n Animal
> Facultad de Veterinaria
> Universidad Complutense de Madrid
> 
> *Contacto*: 913943855/anaherasm at ucm.es
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Nov 20 19:56:29 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 20 Nov 2023 21:56:29 +0300
Subject: [R] Error in setwd(dir) when initializing R
In-Reply-To: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
Message-ID: <20231120215629.7dd8d6f9@Tarkus>

On Mon, 20 Nov 2023 12:18:11 +0100
Ana de las Heras Molina <andelash at ucm.es> wrote:

> Error in setwd(dir) : no es posible cambiar el directorio de trabajo

If you run traceback() first thing after getting this error, does it
say anything useful? (Anything besides "No traceback available" would
count as useful.)

Do you have a file named .RData in your home directory? If yes, it may
help to move it away (or remove it if you don't use the saved session).

-- 
Best regards,
Ivan


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Mon Nov 20 22:45:46 2023
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Mon, 20 Nov 2023 21:45:46 +0000 (UTC)
Subject: [R] Cannot calculate confidence intervals NULL
In-Reply-To: <CAGxFJbRFJ_HOmuvZ2XCHA00H974J8E7h3uGwdAcHjpdC1feyBw@mail.gmail.com>
References: <1916173554.6401526.1700081634822.ref@mail.yahoo.com>
 <1916173554.6401526.1700081634822@mail.yahoo.com>
 <CAGxFJbRFJ_HOmuvZ2XCHA00H974J8E7h3uGwdAcHjpdC1feyBw@mail.gmail.com>
Message-ID: <1185747002.9435005.1700516746379@mail.yahoo.com>

Dear Bert,
Dear All,

Yes, thanks ! that was the problem!







Le mercredi 15 novembre 2023 ? 22:21:53 UTC+1, Bert Gunter <bgunter.4567 at gmail.com> a ?crit : 





I believe the problem is here:

cor1 <- cor(x1, y1, method="spearman")
?cor2 <- cor(x2, y2, method="spearman")

The x's and y's are not looked for in data (i.e. NSE) but in the environment where the function was defined, which is standard evaluation. Change the above to:

cor1 <- with(d, cor(x1, y1, method="spearman"))
?cor2 <- with(d, cor(x2, y2, method="spearman"))

and all should be fine.

-- Bert

On Wed, Nov 15, 2023 at 12:54?PM varin sacha via R-help <r-help at r-project.org> wrote:
> R-Experts,
> 
> Here below my R code working without error message but I don't get the results I am expecting.
> Here is the result I get:
> 
> [1] "All values of t are equal to 0.28611928397257 \n Cannot calculate confidence intervals"
> NULL
> 
> If someone knows how to solve my problem, really appreciate.
> Best,
> S
> 
> 
> #########################################################
> # Difference in Spearman rho?
> 
> library(boot)
> ?
> x1=c(4,6,5,7,8,4,2,3,5.5,6.7,5.5,3.5,2,1,3,5,6,3.5,2.5,2,1,2,3,2,1,2,3,4,3,4)
> ?
> y1=c(10,14,12.5,21,15,16,17.5,11,11.5,21,19,16,17.5,18,18.5,12,13,14,11,11,12,18,20,13,23,12,11,14,16,11)
> ?
> x2=c(5,3,4,2,1,1,1,2,3,4,5,4,3,2,1,3,4.5,4.5,5.5,6,5,4,7,8,3,4,2,5,4,3)
> ?
> y2=c(11,12,13,11,10,19,21,21,13,15,18,13,12,14,19,18.5,17.5,12.5,10,9,11,13,14,16,11,18,14,13,12,12)
> ?
> # Function to calculate the difference in Spearman coefficients
> pearson_diff <- function(data, indices) {
> ?
> # Sample the data
> ? d <- data[indices, ]
> ?
> ?# Calculate the Spearman correlation coefficients for every sample
> ? cor1 <- cor(x1, y1, method="spearman")
> ? cor2 <- cor(x2, y2, method="spearman")
> ?
> # Return the difference
> ? return(cor1 - cor2)
> }
> ?
> # Create a data.frame with the data
> data <- data.frame(x1, y1, x2, y2)
> ?
> # Use the boot function to apply the bootstrap
> set.seed(123) # For reproducibility
> bootstrap_results <- boot(data = data, statistic = pearson_diff, R = 1000)
> ?
> # Calculate all the 95% confidence interval
> boot.ci(bootstrap_results, type = "all")
> ###############################################################
> ?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From iuke-tier@ey m@iii@g oii uiow@@edu  Tue Nov 21 00:43:47 2023
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Mon, 20 Nov 2023 17:43:47 -0600 (CST)
Subject: [R] [External] Re:  Error in setwd(dir) when initializing R
In-Reply-To: <20231120215629.7dd8d6f9@Tarkus>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
 <20231120215629.7dd8d6f9@Tarkus>
Message-ID: <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>

On Mon, 20 Nov 2023, Ivan Krylov wrote:

> On Mon, 20 Nov 2023 12:18:11 +0100
> Ana de las Heras Molina <andelash at ucm.es> wrote:
>
>> Error in setwd(dir) : no es posible cambiar el directorio de trabajo
>
> If you run traceback() first thing after getting this error, does it
> say anything useful? (Anything besides "No traceback available" would
> count as useful.)
>
> Do you have a file named .RData in your home directory? If yes, it may
> help to move it away (or remove it if you don't use the saved session).

Also check for .Rprofile or other profile that might contain a setwd()
call.  Starting R with --vanilla should work if the issue is a startup
file.

Best,

luke

>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From t@v|b@r @end|ng |rom gm@||@com  Tue Nov 21 08:23:44 2023
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Tue, 21 Nov 2023 09:23:44 +0200
Subject: [R] Calculating volume under polygons
In-Reply-To: <CANTxAm+0HLEJ3K1VbCD=U66hMn9TtSeAamX+1g--dv78r0h54Q@mail.gmail.com>
References: <CANTxAm+5tCrkbL=PnH_A0VMEDTOKZEcUjgB-Nu+H2ALDJfrNWQ@mail.gmail.com>
 <67772a85-c138-442a-b5b9-9de71a67a11a@gmail.com>
 <CANTxAm+0HLEJ3K1VbCD=U66hMn9TtSeAamX+1g--dv78r0h54Q@mail.gmail.com>
Message-ID: <e9f4fa3b-045a-4f48-9ea3-d3931aff6116@gmail.com>

(Keeping on the list. And consider my suggestion to move this to R-sig-Geo)


What is the coordinate reference system of the polygon layer? Can you 
share these layers?


On 21/11/2023 4:58, javad bayat wrote:
> Dear Micha;
> Thank you for your reply.
> The R version is 4.3.2, the raster package is "raster_3.6-26", the sf 
> package is "sf_1.0-14".
> The str of the raster and polygon is as follow:
> > str(r)
> Formal class 'RasterLayer' [package "raster"] with 13 slots
> ? ..@ file ? ?:Formal class '.RasterFile' [package "raster"] with 13 slots
> ? .. .. ..@ name ? ? ? ?: chr "E:\Base1.tif"
> ? .. .. ..@ datanotation: chr "INT2S"
> ? .. .. ..@ byteorder ? : chr "little"
> ? .. .. ..@ nodatavalue : num -Inf
> ? .. .. ..@ NAchanged ? : logi FALSE
> ? .. .. ..@ nbands ? ? ?: int 1
> ? .. .. ..@ bandorder ? : chr "BIL"
> ? .. .. ..@ offset ? ? ?: int 0
> ? .. .. ..@ toptobottom : logi TRUE
> ? .. .. ..@ blockrows ? : Named int 128
> ? .. .. .. ..- attr(*, "names")= chr "rows"
> ? .. .. ..@ blockcols ? : Named int 128
> ? .. .. .. ..- attr(*, "names")= chr "cols"
> ? .. .. ..@ driver ? ? ?: chr "gdal"
> ? .. .. ..@ open ? ? ? ?: logi FALSE
> ? ..@ data ? ?:Formal class '.SingleLayerData' [package "raster"] with 
> 13 slots
> ? .. .. ..@ values ? ?: logi(0)
> ? .. .. ..@ offset ? ?: num 0
> ? .. .. ..@ gain ? ? ?: num 1
> ? .. .. ..@ inmemory ?: logi FALSE
> ? .. .. ..@ fromdisk ?: logi TRUE
> ? .. .. ..@ isfactor ?: logi FALSE
> ? .. .. ..@ attributes: list()
> ? .. .. ..@ haveminmax: logi TRUE
> ? .. .. ..@ min ? ? ? : num 1801
> ? .. .. ..@ max ? ? ? : num 3289
> ? .. .. ..@ band ? ? ?: int 1
> ? .. .. ..@ unit ? ? ?: chr ""
> ? .. .. ..@ names ? ? : chr "Base1"
> ? ..@ legend ?:Formal class '.RasterLegend' [package "raster"] with 5 
> slots
> ? .. .. ..@ type ? ? ?: chr(0)
> ? .. .. ..@ values ? ?: logi(0)
> ? .. .. ..@ color ? ? : logi(0)
> ? .. .. ..@ names ? ? : logi(0)
> ? .. .. ..@ colortable: logi(0)
> ? ..@ title ? : chr(0)
> ? ..@ extent ?:Formal class 'Extent' [package "raster"] with 4 slots
> ? .. .. ..@ xmin: num 330533
> ? .. .. ..@ xmax: num 402745
> ? .. .. ..@ ymin: num 3307321
> ? .. .. ..@ ymax: num 3345646
> ? ..@ rotated : logi FALSE
> ? ..@ rotation:Formal class '.Rotation' [package "raster"] with 2 slots
> ? .. .. ..@ geotrans: num(0)
> ? .. .. ..@ transfun:function ()
> ? ..@ ncols ? : int 5777
> ? ..@ nrows ? : int 3066
> ? ..@ crs ? ? :Formal class 'CRS' [package "sp"] with 1 slot
> ? .. .. ..@ projargs: chr NA
> ? ..@ srs ? ? : chr "+proj=utm +zone=40 +datum=WGS84 +units=m +no_defs"
> ? ..@ history : list()
> ? ..@ z ? ? ? : list()
>
> > str(p)
> sf [12 ? 10] (S3: sf/tbl_df/tbl/data.frame)
> ?$ Name ? ? ?: chr [1:12] "01" "02" "03" "04" ...
> ?$ FolderPath: chr [1:12]? ...
> ?$ SymbolID ?: num [1:12] 0 0 0 0 0 0 0 0 0 0 ...
> ?$ AltMode ? : int [1:12] 0 0 0 0 0 0 0 0 0 0 ...
> ?$ Base ? ? ?: num [1:12] 0 0 0 0 0 0 0 0 0 0 ...
> ?$ Clamped ? : int [1:12] -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
> ?$ Extruded ?: int [1:12] 0 0 0 0 0 0 0 0 0 0 ...
> ?$ Shape_Area: num [1:12] 63.51 15.28 9.23 39.19 642.38 ...
> ?$ Area ? ? ?: num [1:12] 64 15 9 39 642 56 36 16 53 39 ...
> ?$ geometry ?:sfc_POLYGON of length 12; first list element: List of 1
> ? ..$ : num [1:18, 1:3] 55.6 55.6 55.6 55.6 55.6 ...
> ? ..- attr(*, "class")= chr [1:3] "XYZ" "POLYGON" "sfg"
> ?- attr(*, "sf_column")= chr "geometry"
> ?- attr(*, "agr")= Factor w/ 3 levels "constant","aggregate",..: NA NA 
> NA NA NA NA NA NA NA
> ? ..- attr(*, "names")= chr [1:9] "Name" "FolderPath" "SymbolID" 
> "AltMode" ...
> Sincerely
>
>
>
>
>
>
>
> On Mon, Nov 20, 2023 at 5:15?PM Micha Silver <tsvibar at gmail.com> wrote:
>
>     Hi:
>
>     Some preliminary comments first
>
>     1- You might get a better response posting to R-sig-Geo
>
>     2- Probably better to switch to the `terra` package instead of the
>     older
>     `raster`
>
>     3- Furthermore, there is the package `exactextractr` that ensures
>     that
>     edge pixels are taken into account, weighted by the actual, partial
>     coverage of each pixel by the polygon.
>
>     4- Can you post: your R version, and version of the relevant
>     packages,
>     and information about the polygons and DEM (i.e. `str(p)` and
>     `str(r)` )
>
>
>     On 20/11/2023 14:30, javad bayat wrote:
>     > Dear all;
>     > I am trying to calculate volume under each polygon of a
>     shapefile according
>     > to a DEM.
>     > when I run the code, it gives me an error as follows.
>     > "
>     > Error in h(simpleError(msg, call)) :
>     >? ? error in evaluating the argument 'x' in selecting a method
>     for function
>     > 'addAttrToGeom': sp supports Z dimension only for POINT and
>     MULTIPOINT.
>     > use `st_zm(...)` to coerce to XY dimensions
>     > "
>     > I want to have a table that contains one column corresponding to the
>     > polygon rank and another that contains the volume on that polyon.
>     > I would be more than happy if anyone could help me.
>     > I provided codes at the end of this email.
>     > Sincerely
>     >
>     >
>     >
>     ##########################################################################################
>     > library(raster);
>     > library(sf)
>     > # Load the DEM raster and shapefile
>     > r <- raster("E:/Base1.tif")
>     > p <- read_sf(dsn = "E:/Sites.shp", layer = " Sites")
>
>
>     Now to the question:
>
>     In `read_sf()`, when the source is a shapefile, you do not need the
>     'layer' option. It doesn't hurt, but in this case I see that you
>     have an
>     extra space before the layer name. Could that be causing the problem?
>
>
>
>     > # Extract the values of the DEM raster for each polygon
>     > values <- extract(r, p)
>     >? ? Error in h(simpleError(msg, call)) :
>     >? ? error in evaluating the argument 'x' in selecting a method
>     for function
>     > 'addAttrToGeom': sp supports Z dimension only for POINT and
>     MULTIPOINT.
>     > use `st_zm(...)` to coerce to XY dimensions
>     >
>     > # Calculate the volume of each polygon
>     > volumes <- sapply(values, function(x) rasterVolume(x, r))
>
>     What is this "rasterVolume" function that you call here?
>
>
>     > # Print the results
>     > for (i in 1:length(volumes)) {
>     >? ? cat(sprintf("Volume under polygon %d: %f\n", i, volumes[i]))
>     > }
>     >
>     ##########################################################################################
>     >
>     >
>     >
>     >
>     >
>     -- 
>     Micha Silver
>     Ben Gurion Univ.
>     Sde Boker, Remote Sensing Lab
>     cell: +972-523-665918
>
>
>
> -- 
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From @nde|@@h @end|ng |rom ucm@e@  Tue Nov 21 08:46:25 2023
From: @nde|@@h @end|ng |rom ucm@e@ (Ana de las Heras Molina)
Date: Tue, 21 Nov 2023 08:46:25 +0100
Subject: [R] [External] Re:  Error in setwd(dir) when initializing R
In-Reply-To: <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
 <20231120215629.7dd8d6f9@Tarkus>
 <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>
Message-ID: <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>

Hello,

Thank you all for your responses. When I initialize R, the folder in which
it starts is:

getwd()
[1] "C:/Users/Ana/OneDrive - Universidad Complutense de Madrid
(UCM)/Documentos"

So it seems a problem with OneDrive
-Kevin: I do not really understand your question... You mean if I set my
working directory to my C:// or D:// folder in my computer? It doesn't work
either.

-Ivan: this is the message I got when running traceback(). So can I move
the.Rdata file without affecting the work?

-Luke: thank you for the idea, I will try it.

Error in setwd(dir) : no es posible cambiar el directorio de trabajo>
traceback()4: setwd(dir)
3: .rs.onAvailablePackagesStale(reposString)
2: .rs.availablePackages()
1: .rs.rpc.discover_package_dependencies("3C994FEC", ".R")


Best,

Ana


El mar, 21 nov 2023 a las 0:43, <luke-tierney at uiowa.edu> escribi?:

> On Mon, 20 Nov 2023, Ivan Krylov wrote:
>
> > On Mon, 20 Nov 2023 12:18:11 +0100
> > Ana de las Heras Molina <andelash at ucm.es> wrote:
> >
> >> Error in setwd(dir) : no es posible cambiar el directorio de trabajo
> >
> > If you run traceback() first thing after getting this error, does it
> > say anything useful? (Anything besides "No traceback available" would
> > count as useful.)
> >
> > Do you have a file named .RData in your home directory? If yes, it may
> > help to move it away (or remove it if you don't use the saved session).
>
> Also check for .Rprofile or other profile that might contain a setwd()
> call.  Starting R with --vanilla should work if the issue is a startup
> file.
>
> Best,
>
> luke
>
> >
> >
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>


-- 
*Ana de las Heras Molina*


Nutrici?n Animal
Departamento de  Producci?n Animal
Facultad de Veterinaria
Universidad Complutense de Madrid

*Contacto*: 913943855/anaherasm at ucm.es

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Nov 21 09:16:01 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 21 Nov 2023 11:16:01 +0300
Subject: [R] [External] Re:  Error in setwd(dir) when initializing R
In-Reply-To: <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
 <20231120215629.7dd8d6f9@Tarkus>
 <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>
 <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>
Message-ID: <20231121111601.44399393@Tarkus>

On Tue, 21 Nov 2023 08:46:25 +0100
Ana de las Heras Molina <andelash at ucm.es> wrote:

> > traceback()
> 4: setwd(dir)
> 3: .rs.onAvailablePackagesStale(reposString)
> 2: .rs.availablePackages()
> 1: .rs.rpc.discover_package_dependencies("3C994FEC", ".R")

This is something that RStudio (not R itself!) does, but it shouldn't
be failing. Here's what seems to be failing for you [*]:

   # prepare directory for discovery of available packages
   dir <- tempfile("rstudio-available-packages-")
   dir.create(dir, showWarnings = FALSE)

   # create a file in that directory
   saveRDS(Sys.time(), file = file.path(dir, "time.rds"))
   # (This doesn't fail because we keep executing the function, so the
   # directory must exist!) 

   # move there
   owd <- setwd(dir) # this somehow fails

Is it an option to disable OneDrive for the home directory? It's
clearly doing something terrible to your temporary files. If not, it
should be possible to create a separate temporary directory on your
computer (the path must not contain spaces) and list it in the
.Renviron file in the home directory as the TMPDIR variable:

TMPDIR=C:/my/R/temp/directory

See help(Startup) for more information on .Renviron.

Alternatively, we may try to perform some debugging. If you set
options(error = recover) and run .rs.availablePackages() again, it
should fail and give you a debugger prompt. Choose the deepest option
in the call stack and try to find out the value of the `dir` variable.
Does dir.exists(dir) still return TRUE? Does setwd(dir) still fail? Can
you open the directory in the Windows Explorer?

The last but not the least, do you see some of the same problems if you
launch Rgui.exe instead of RStudio?

-- 
Best regards,
Ivan

[*]
https://github.com/rstudio/rstudio/blob/45af283a7a5853399904ddc438f6cd89d9b5c137/src/cpp/session/modules/SessionPackages.R#L1625-L1636


From me @end|ng |rom n@nx@me  Mon Nov 20 17:08:25 2023
From: me @end|ng |rom n@nx@me (Nan Xiao)
Date: Mon, 20 Nov 2023 11:08:25 -0500
Subject: [R] [R-pkgs] gsDesign 3.6.0 is released
Message-ID: <97509799-f612-4579-881f-06c78e3e905b@app.fastmail.com>

Dear all,

I'm excited to announce that a new version of gsDesign (3.6.0) is now on CRAN (https://cran.r-project.org/package=gsDesign). gsDesign supports group sequential clinical trial design, largely as presented in Jennison and Turnbull (2000).

The 3.6.0 update introduces some significant new features and enhancements:

- New gsSurvCalendar() function to enable group sequential design for time-to-event outcomes using calendar timing of interim analysis specification.
- toInteger() and print.gsSurv() improvements for integer sample size and event count.
- toBinomialExact() and gsBinomialExact() now have improved error checking in bound computations, error messages, and documentation.
- New as_rtf() method for gsBinomialExact() objects to support RTF table outputs.

We have also updated the gsDesign Shiny app to 2023.11.0. This version supports the new key features added in gsDesign 3.5.0 and 3.6.0.

For the complete list of updates, please see the announcement: https://keaven.github.io/blog/gsdesign-3-6-0/.

Best regards,
-Nan

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Nov 21 12:06:43 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 21 Nov 2023 14:06:43 +0300
Subject: [R] [External] Re:  Error in setwd(dir) when initializing R
In-Reply-To: <CAD+E279rM4WjAmC9RKS1=Dv3ZLARsvN1hqk1bWV0stAvV4OB7g@mail.gmail.com>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
 <20231120215629.7dd8d6f9@Tarkus>
 <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>
 <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>
 <20231121111601.44399393@Tarkus>
 <CAD+E279rM4WjAmC9RKS1=Dv3ZLARsvN1hqk1bWV0stAvV4OB7g@mail.gmail.com>
Message-ID: <20231121140643.104d6271@arachnoid>

? Tue, 21 Nov 2023 10:51:59 +0100
Ana de las Heras Molina <andelash at ucm.es> ?????:

> I uninstalled onedrive, I eliminated all the folders and then
> reinstalled R and RStudio... but it is RStudio the one creating a
> folder called C:\Users\Ana\OneDrive - Universidad Complutense de
> Madrid (UCM)\Documentos.

Does Rgui.exe use a different home directory from RStudio? Perhaps you
need not to reinstall RStudio (which deletes and recreates the program
files which aren't damaged) but to wipe the profile (the settings
somewhere under %APPDATA% or %LOCALAPPDATA%), but it pays to be extra
careful about these directories. People at
<https://community.rstudio.com/> may know more about that.

I'm afraid I don't know how to disable OneDrive on a Windows 10
installation. If your university has a Microsoft support contract, it
could be worth asking the Microsoft representative to fix OneDrive so
that temporary files would work on it and telling them the steps to
reproduce the problem.

> Browse[1]> dir.exists(dir)
> [1] TRUE
> Browse[1]> setwd(dir)
> Error durante el wrapup: no es posible cambiar el directorio de
> trabajo

What is the value of `dir` at this point? (What does print(dir) say?)
Can you open this directory in Windows Explorer?

If possible, could you please set your mailer to compose messages in
plain text instead of HTML? The plain text versions of your messages
that your mailer generates from the HTML messages are somewhat mangled:
https://stat.ethz.ch/pipermail/r-help/2023-November/478593.html

-- 
Best regards,
Ivan


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Nov 21 14:14:12 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 21 Nov 2023 16:14:12 +0300
Subject: [R] [External] Re:  Error in setwd(dir) when initializing R
In-Reply-To: <CAD+E279OVDabN0Ko5-gcRKtW-X40Qi6ztkkJz9zZbHVRfQJReQ@mail.gmail.com>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
 <20231120215629.7dd8d6f9@Tarkus>
 <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>
 <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>
 <20231121111601.44399393@Tarkus>
 <CAD+E279rM4WjAmC9RKS1=Dv3ZLARsvN1hqk1bWV0stAvV4OB7g@mail.gmail.com>
 <20231121140643.104d6271@arachnoid>
 <CAD+E279OVDabN0Ko5-gcRKtW-X40Qi6ztkkJz9zZbHVRfQJReQ@mail.gmail.com>
Message-ID: <20231121161412.6b5dcf6b@arachnoid>

? Tue, 21 Nov 2023 13:41:41 +0100
Ana de las Heras Molina <andelash at ucm.es> ?????:

> I am sorry for my ignorance, but what is Rgui.exe?

It's the graphical user interface that comes with R itself:
https://cran.r-project.org/bin/windows/base/README.R-4.3.2

If you haven't changed any settings while installing R, it should be
located at C:\Program Files\R\R-4.3.2\bin\x64\Rgui.exe.

You won't see the errors from
.rs.rpc.discover_package_dependencies(...), but I'm curious whether
your problems with LinDa / ANCOMBC / phyloseq can be reproduced with
plain Rgui.exe.

-- 
Best regards,
Ivan


From pro|jcn@@h @end|ng |rom gm@||@com  Tue Nov 21 14:20:03 2023
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Tue, 21 Nov 2023 08:20:03 -0500
Subject: [R] [External] Re: Error in setwd(dir) when initializing R
In-Reply-To: <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
 <20231120215629.7dd8d6f9@Tarkus>
 <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>
 <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>
Message-ID: <56213adf-9719-4522-a701-99c3456c4092@gmail.com>

This is likely tangential, but as a Linux user I have learned to avoid
any directory name with - or ( or ) or other things, even spaces. Whether or not
those are "valid", they seem to cause trouble.

For example "-" can be picked up in bash scripts as a trigger for options.

And in this case, it looks like the OP does not have control of the name. Sigh.

John Nash


On 2023-11-21 02:46, Ana de las Heras Molina wrote:
> Hello,
> 
> Thank you all for your responses. When I initialize R, the folder in which
> it starts is:
> 
> getwd()
> [1] "C:/Users/Ana/OneDrive - Universidad Complutense de Madrid
> (UCM)/Documentos"
> 
> So it seems a problem with OneDrive
> -Kevin: I do not really understand your question... You mean if I set my
> working directory to my C:// or D:// folder in my computer? It doesn't work
> either.
> 
> -Ivan: this is the message I got when running traceback(). So can I move
> the.Rdata file without affecting the work?
> 
> -Luke: thank you for the idea, I will try it.
> 
> Error in setwd(dir) : no es posible cambiar el directorio de trabajo>
> traceback()4: setwd(dir)
> 3: .rs.onAvailablePackagesStale(reposString)
> 2: .rs.availablePackages()
> 1: .rs.rpc.discover_package_dependencies("3C994FEC", ".R")
> 
> 
> Best,
> 
> Ana
> 
> 
> El mar, 21 nov 2023 a las 0:43, <luke-tierney at uiowa.edu> escribi?:
> 
>> On Mon, 20 Nov 2023, Ivan Krylov wrote:
>>
>>> On Mon, 20 Nov 2023 12:18:11 +0100
>>> Ana de las Heras Molina <andelash at ucm.es> wrote:
>>>
>>>> Error in setwd(dir) : no es posible cambiar el directorio de trabajo
>>>
>>> If you run traceback() first thing after getting this error, does it
>>> say anything useful? (Anything besides "No traceback available" would
>>> count as useful.)
>>>
>>> Do you have a file named .RData in your home directory? If yes, it may
>>> help to move it away (or remove it if you don't use the saved session).
>>
>> Also check for .Rprofile or other profile that might contain a setwd()
>> call.  Starting R with --vanilla should work if the issue is a startup
>> file.
>>
>> Best,
>>
>> luke
>>
>>>
>>>
>>
>> --
>> Luke Tierney
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>      Actuarial Science
>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
> 
>


From t@v|b@r @end|ng |rom gm@||@com  Tue Nov 21 17:53:44 2023
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Tue, 21 Nov 2023 18:53:44 +0200
Subject: [R] Calculating volume under polygons
In-Reply-To: <CANTxAm+5z+5j8V66RpBKNTCQhYwZO9_w=hdMNiEqAAVjoPXRZA@mail.gmail.com>
References: <CANTxAm+5tCrkbL=PnH_A0VMEDTOKZEcUjgB-Nu+H2ALDJfrNWQ@mail.gmail.com>
 <67772a85-c138-442a-b5b9-9de71a67a11a@gmail.com>
 <CANTxAm+0HLEJ3K1VbCD=U66hMn9TtSeAamX+1g--dv78r0h54Q@mail.gmail.com>
 <e9f4fa3b-045a-4f48-9ea3-d3931aff6116@gmail.com>
 <CANTxAmJhFtB+_xN2az1hy7tqMNSu9md5tyu=AgeWnWNfg8_aYw@mail.gmail.com>
 <CANTxAm+5z+5j8V66RpBKNTCQhYwZO9_w=hdMNiEqAAVjoPXRZA@mail.gmail.com>
Message-ID: <8d12eef1-6c62-4cc8-a886-6e3fc2de7b61@gmail.com>

Again, please keep communication on the maillist, to help others as well.

The R spatial maillist is R-sig-Geo in case you want to continue there.


Here's my solution. I read in your layers, then looped over all 
polygons. Inside the loop I extract the minimum value of the DEM, then 
subtract that from the original values, to get the height above minimum. 
And finally, using extract_exact() I get the sum of all these height 
pixels within the polygon = volume.


After the loop, rbind to merge the new polygons with volume column.


Here's the code I tried:


# Load packages and Setup directories
pkgs <- c('terra', 'exactextractr', 'dplyr', 'sf')
invisible(lapply(pkgs, require, character.only = TRUE))
GIS_dir <- "./GIS"
dem_file <- file.path(GIS_dir, "Base1.tif")
poly_path <- file.path(GIS_dir, "Sites_Sarch.shp")

# Read the data
dem <- rast(dem_file)
polys <- st_read(poly_path)

# Start a loop over all polygons, and extract data from each
volumes_list <- lapply(1:length(polys$geometry), function(x) {
 ??? poly <- polys$geometry[x] # A single sfc object
 ??? poly <- st_as_sf(poly)??? # coerced to an sf object
 ??? poly_id <- polys$Name[x]
 ??? # Get minimum value in this polygon
 ??? dem_crop <- mask(crop(dem, poly), poly)
 ??? dem_min <- min(values(dem_crop), na.rm = TRUE)
 ??? # Make a new cropped raster
 ??? # that is the height above minimum
 ??? dem_height <- dem_crop - dem_min

 ??? # Get the sum of the values in this dem_height
 ??? volume <- exactextractr::exact_extract(dem_height,
 ?????????????????????????????????????????? poly, 'sum') # in m^3
 ??? # Make a data.frame of all necessary values:
 ??? # minimum and sum for this poly
 ??? # and the id of the poly
 ??? poly_sf <- data.frame("Name" = poly_id,
 ????????????????????????? "poly_min" = dem_min,
 ????????????????????????? "volume" = volume)
 ??? poly_sf <- st_set_geometry(poly_sf, st_geometry(poly))

 ??? return(poly_sf)
})

# Bind the list output into a merged sf object
result_polys <- do.call(rbind, volumes_list)
print(st_drop_geometry(result_polys))



HTH

On 21/11/2023 10:33, javad bayat wrote:
> Micha;
> I finally calculated the volumes. But it needs too many codes. Is 
> there any way to reduce the amount of codes?
> Do you have any idea regarding how to calculate the exact volume under 
> the polygon?
>
>
> x1 = as.data.frame(x[1])
> x2 = as.data.frame(x[2])
> x3 = as.data.frame(x[3])
> x4 = as.data.frame(x[4])
> x5 = as.data.frame(x[5])
> x6 = as.data.frame(x[6])
> x7 = as.data.frame(x[7])
> x8 = as.data.frame(x[8])
> x9 = as.data.frame(x[9])
> x10 = as.data.frame(x[10])
> x11 = as.data.frame(x[11])
> x12 = as.data.frame(x[12])
>
> x1$Depth = x1[,1] - min(x1[,1])
> x2$Depth = x2[,1] - min(x2[,1])
> x3$Depth = x3[,1] - min(x3[,1])
> x4$Depth = x4[,1] - min(x4[,1])
> x5$Depth = x5[,1] - min(x5[,1])
> x6$Depth = x6[,1] - min(x6[,1])
> x7$Depth = x7[,1] - min(x7[,1])
> x8$Depth = x8[,1] - min(x8[,1])
> x9$Depth = x9[,1] - min(x9[,1])
> x10$Depth = x10[,1] - min(x10[,1])
> x11$Depth = x11[,1] - min(x11[,1])
> x12$Depth = x12[,1] - min(x12[,1])
>
>
> x1$Vol = x1[,2] * x1[,3]
> x2$Vol = x2[,2] * x2[,3]
> x3$Vol = x3[,2] * x3[,3]
> x4$Vol = x4[,2] * x4[,3]
> x5$Vol = x5[,2] * x5[,3]
> x6$Vol = x6[,2] * x6[,3]
> x7$Vol = x7[,2] * x7[,3]
> x8$Vol = x8[,2] * x8[,3]
> x9$Vol = x9[,2] * x9[,3]
> x10$Vol = x10[,2] * x10[,3]
> x11$Vol = x11[,2] * x11[,3]
> x12$Vol = x12[,2] * x12[,3]
>
> Volume = data.frame(ID = c(1:12), Vol = c(sum(x1$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x2$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x3$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x4$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x5$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x6$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x7$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x8$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x9$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x10$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x11$Vol),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x12$Vol)))
> Volume
>
> On Tue, Nov 21, 2023 at 11:14?AM javad bayat <j.bayat194 at gmail.com> wrote:
>
>     Dear Micha, I have sent my question to the R-sig-Geosite too. To
>     clarify more, I am trying to calculate the volume of polygons by a
>     DEM raster. The shapefile has several polygons (12) and I want to
>     calculate the volume of the polygons based on their minimum
>     elevations. I tried these codes too, but I don't know how to
>     calculate the volumes at the end. The function I wrote uses the
>     minimum elevation of all polygons, not each polygon minimum.
>     You know I want to calculate the volume of the soil to be removed
>     on these sites. Maybe using the minimum elevation is not
>     appropriate for this work, maybe calculating the relation between
>     elevation and slope of the area under the polygons will act
>     better. I dont know how to do it.
>     I would be more than happy if you help me.
>     The coordinate system is UTM zone 40N.
>     I have uploaded the files.
>
>     Sincerely yours
>
>     ################################################################
>     library(terra)
>     library(exactextractr)
>     library(dplyr)
>     library(sf)
>
>     # Read the DEM raster file
>     r <- rast("E:/Base1.tif")
>     # Read the polygon shapefile that contains several polygons from
>     different sites
>     p <- st_read("E:/Sites.shp")
>     crop_r <- crop(r, extent(p))
>     mask_r <- mask(crop_r, p)
>     # Extract the area of each cell that is contained within each polygon
>     x <- exact_extract(r, p, coverage_area = TRUE)
>     # Add polygon names that the results will be grouped by
>     names(x) <- p$Name
>     a = values(mask_r)
>     # Bind the list output into a data frame and calculate the
>     proportion cover for each category
>     result <- bind_rows(x, .id = "Name") %>%
>     ? group_by(Name) %>% summarize(Area = sum(coverage_area)) %>%
>     ? group_by(Name) %>% mutate(Volume = Area * min(na.omit(a)))
>     ############################################################################################
>
>
>     On Tue, Nov 21, 2023 at 10:53?AM Micha Silver <tsvibar at gmail.com>
>     wrote:
>
>         (Keeping on the list. And consider my suggestion to move this
>         to R-sig-Geo)
>
>
>         What is the coordinate reference system of the polygon layer?
>         Can you
>         share these layers?
>
>
>         On 21/11/2023 4:58, javad bayat wrote:
>         > Dear Micha;
>         > Thank you for your reply.
>         > The R version is 4.3.2, the raster package is
>         "raster_3.6-26", the sf
>         > package is "sf_1.0-14".
>         > The str of the raster and polygon is as follow:
>         > > str(r)
>         > Formal class 'RasterLayer' [package "raster"] with 13 slots
>         > ? ..@ file ? ?:Formal class '.RasterFile' [package "raster"]
>         with 13 slots
>         > ? .. .. ..@ name ? ? ? ?: chr "E:\Base1.tif"
>         > ? .. .. ..@ datanotation: chr "INT2S"
>         > ? .. .. ..@ byteorder ? : chr "little"
>         > ? .. .. ..@ nodatavalue : num -Inf
>         > ? .. .. ..@ NAchanged ? : logi FALSE
>         > ? .. .. ..@ nbands ? ? ?: int 1
>         > ? .. .. ..@ bandorder ? : chr "BIL"
>         > ? .. .. ..@ offset ? ? ?: int 0
>         > ? .. .. ..@ toptobottom : logi TRUE
>         > ? .. .. ..@ blockrows ? : Named int 128
>         > ? .. .. .. ..- attr(*, "names")= chr "rows"
>         > ? .. .. ..@ blockcols ? : Named int 128
>         > ? .. .. .. ..- attr(*, "names")= chr "cols"
>         > ? .. .. ..@ driver ? ? ?: chr "gdal"
>         > ? .. .. ..@ open ? ? ? ?: logi FALSE
>         > ? ..@ data ? ?:Formal class '.SingleLayerData' [package
>         "raster"] with
>         > 13 slots
>         > ? .. .. ..@ values ? ?: logi(0)
>         > ? .. .. ..@ offset ? ?: num 0
>         > ? .. .. ..@ gain ? ? ?: num 1
>         > ? .. .. ..@ inmemory ?: logi FALSE
>         > ? .. .. ..@ fromdisk ?: logi TRUE
>         > ? .. .. ..@ isfactor ?: logi FALSE
>         > ? .. .. ..@ attributes: list()
>         > ? .. .. ..@ haveminmax: logi TRUE
>         > ? .. .. ..@ min ? ? ? : num 1801
>         > ? .. .. ..@ max ? ? ? : num 3289
>         > ? .. .. ..@ band ? ? ?: int 1
>         > ? .. .. ..@ unit ? ? ?: chr ""
>         > ? .. .. ..@ names ? ? : chr "Base1"
>         > ? ..@ legend ?:Formal class '.RasterLegend' [package
>         "raster"] with 5
>         > slots
>         > ? .. .. ..@ type ? ? ?: chr(0)
>         > ? .. .. ..@ values ? ?: logi(0)
>         > ? .. .. ..@ color ? ? : logi(0)
>         > ? .. .. ..@ names ? ? : logi(0)
>         > ? .. .. ..@ colortable: logi(0)
>         > ? ..@ title ? : chr(0)
>         > ? ..@ extent ?:Formal class 'Extent' [package "raster"] with
>         4 slots
>         > ? .. .. ..@ xmin: num 330533
>         > ? .. .. ..@ xmax: num 402745
>         > ? .. .. ..@ ymin: num 3307321
>         > ? .. .. ..@ ymax: num 3345646
>         > ? ..@ rotated : logi FALSE
>         > ? ..@ rotation:Formal class '.Rotation' [package "raster"]
>         with 2 slots
>         > ? .. .. ..@ geotrans: num(0)
>         > ? .. .. ..@ transfun:function ()
>         > ? ..@ ncols ? : int 5777
>         > ? ..@ nrows ? : int 3066
>         > ? ..@ crs ? ? :Formal class 'CRS' [package "sp"] with 1 slot
>         > ? .. .. ..@ projargs: chr NA
>         > ? ..@ srs ? ? : chr "+proj=utm +zone=40 +datum=WGS84
>         +units=m +no_defs"
>         > ? ..@ history : list()
>         > ? ..@ z ? ? ? : list()
>         >
>         > > str(p)
>         > sf [12 ? 10] (S3: sf/tbl_df/tbl/data.frame)
>         > ?$ Name ? ? ?: chr [1:12] "01" "02" "03" "04" ...
>         > ?$ FolderPath: chr [1:12]? ...
>         > ?$ SymbolID ?: num [1:12] 0 0 0 0 0 0 0 0 0 0 ...
>         > ?$ AltMode ? : int [1:12] 0 0 0 0 0 0 0 0 0 0 ...
>         > ?$ Base ? ? ?: num [1:12] 0 0 0 0 0 0 0 0 0 0 ...
>         > ?$ Clamped ? : int [1:12] -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
>         > ?$ Extruded ?: int [1:12] 0 0 0 0 0 0 0 0 0 0 ...
>         > ?$ Shape_Area: num [1:12] 63.51 15.28 9.23 39.19 642.38 ...
>         > ?$ Area ? ? ?: num [1:12] 64 15 9 39 642 56 36 16 53 39 ...
>         > ?$ geometry ?:sfc_POLYGON of length 12; first list element:
>         List of 1
>         > ? ..$ : num [1:18, 1:3] 55.6 55.6 55.6 55.6 55.6 ...
>         > ? ..- attr(*, "class")= chr [1:3] "XYZ" "POLYGON" "sfg"
>         > ?- attr(*, "sf_column")= chr "geometry"
>         > ?- attr(*, "agr")= Factor w/ 3 levels
>         "constant","aggregate",..: NA NA
>         > NA NA NA NA NA NA NA
>         > ? ..- attr(*, "names")= chr [1:9] "Name" "FolderPath"
>         "SymbolID"
>         > "AltMode" ...
>         > Sincerely
>         >
>         >
>         >
>         >
>         >
>         >
>         >
>         > On Mon, Nov 20, 2023 at 5:15?PM Micha Silver
>         <tsvibar at gmail.com> wrote:
>         >
>         >? ? ?Hi:
>         >
>         >? ? ?Some preliminary comments first
>         >
>         >? ? ?1- You might get a better response posting to R-sig-Geo
>         >
>         >? ? ?2- Probably better to switch to the `terra` package
>         instead of the
>         >? ? ?older
>         >? ? ?`raster`
>         >
>         >? ? ?3- Furthermore, there is the package `exactextractr`
>         that ensures
>         >? ? ?that
>         >? ? ?edge pixels are taken into account, weighted by the
>         actual, partial
>         >? ? ?coverage of each pixel by the polygon.
>         >
>         >? ? ?4- Can you post: your R version, and version of the relevant
>         >? ? ?packages,
>         >? ? ?and information about the polygons and DEM (i.e.
>         `str(p)` and
>         >? ? ?`str(r)` )
>         >
>         >
>         >? ? ?On 20/11/2023 14:30, javad bayat wrote:
>         >? ? ?> Dear all;
>         >? ? ?> I am trying to calculate volume under each polygon of a
>         >? ? ?shapefile according
>         >? ? ?> to a DEM.
>         >? ? ?> when I run the code, it gives me an error as follows.
>         >? ? ?> "
>         >? ? ?> Error in h(simpleError(msg, call)) :
>         >? ? ?>? ? error in evaluating the argument 'x' in selecting a
>         method
>         >? ? ?for function
>         >? ? ?> 'addAttrToGeom': sp supports Z dimension only for
>         POINT and
>         >? ? ?MULTIPOINT.
>         >? ? ?> use `st_zm(...)` to coerce to XY dimensions
>         >? ? ?> "
>         >? ? ?> I want to have a table that contains one column
>         corresponding to the
>         >? ? ?> polygon rank and another that contains the volume on
>         that polyon.
>         >? ? ?> I would be more than happy if anyone could help me.
>         >? ? ?> I provided codes at the end of this email.
>         >? ? ?> Sincerely
>         >? ? ?>
>         >? ? ?>
>         >? ? ?>
>         >
>         ?##########################################################################################
>         >? ? ?> library(raster);
>         >? ? ?> library(sf)
>         >? ? ?> # Load the DEM raster and shapefile
>         >? ? ?> r <- raster("E:/Base1.tif")
>         >? ? ?> p <- read_sf(dsn = "E:/Sites.shp", layer = " Sites")
>         >
>         >
>         >? ? ?Now to the question:
>         >
>         >? ? ?In `read_sf()`, when the source is a shapefile, you do
>         not need the
>         >? ? ?'layer' option. It doesn't hurt, but in this case I see
>         that you
>         >? ? ?have an
>         >? ? ?extra space before the layer name. Could that be causing
>         the problem?
>         >
>         >
>         >
>         >? ? ?> # Extract the values of the DEM raster for each polygon
>         >? ? ?> values <- extract(r, p)
>         >? ? ?>? ? Error in h(simpleError(msg, call)) :
>         >? ? ?>? ? error in evaluating the argument 'x' in selecting a
>         method
>         >? ? ?for function
>         >? ? ?> 'addAttrToGeom': sp supports Z dimension only for
>         POINT and
>         >? ? ?MULTIPOINT.
>         >? ? ?> use `st_zm(...)` to coerce to XY dimensions
>         >? ? ?>
>         >? ? ?> # Calculate the volume of each polygon
>         >? ? ?> volumes <- sapply(values, function(x) rasterVolume(x, r))
>         >
>         >? ? ?What is this "rasterVolume" function that you call here?
>         >
>         >
>         >? ? ?> # Print the results
>         >? ? ?> for (i in 1:length(volumes)) {
>         >? ? ?>? ? cat(sprintf("Volume under polygon %d: %f\n", i,
>         volumes[i]))
>         >? ? ?> }
>         >? ? ?>
>         >
>         ?##########################################################################################
>         >? ? ?>
>         >? ? ?>
>         >? ? ?>
>         >? ? ?>
>         >? ? ?>
>         >? ? ?--
>         >? ? ?Micha Silver
>         >? ? ?Ben Gurion Univ.
>         >? ? ?Sde Boker, Remote Sensing Lab
>         >? ? ?cell: +972-523-665918
>         >
>         >
>         >
>         > --
>         > Best Regards
>         > Javad Bayat
>         > M.Sc. Environment Engineering
>         > Alternative Mail: bayat194 at yahoo.com
>
>         -- 
>         Micha Silver
>         Ben Gurion Univ.
>         Sde Boker, Remote Sensing Lab
>         cell: +972-523-665918
>
>
>
>     -- 
>     Best Regards
>     Javad Bayat
>     M.Sc. Environment Engineering
>     Alternative Mail: bayat194 at yahoo.com
>
>
>
> -- 
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From @nde|@@h @end|ng |rom ucm@e@  Tue Nov 21 10:51:59 2023
From: @nde|@@h @end|ng |rom ucm@e@ (Ana de las Heras Molina)
Date: Tue, 21 Nov 2023 10:51:59 +0100
Subject: [R] [External] Re:  Error in setwd(dir) when initializing R
In-Reply-To: <20231121111601.44399393@Tarkus>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
 <20231120215629.7dd8d6f9@Tarkus>
 <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>
 <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>
 <20231121111601.44399393@Tarkus>
Message-ID: <CAD+E279rM4WjAmC9RKS1=Dv3ZLARsvN1hqk1bWV0stAvV4OB7g@mail.gmail.com>

Hi,

I uninstalled onedrive, I eliminated all the folders and then reinstalled R
and RStudio... but it is RStudio the one creating a folder
called C:\Users\Ana\OneDrive - Universidad Complutense de Madrid
(UCM)\Documentos.

This is what I obtained with the debugging

Error in setwd(dir) : no es posible cambiar el directorio de trabajo
Enter a frame number, or 0 to exit

1: .rs.availablePackages()
2: .rs.onAvailablePackagesStale(reposString)
3: setwd(dir)
Selection: 3Called from:
.rs.onAvailablePackagesStale(reposString)Browse[1]> dir.exists(dir)[1]
TRUEBrowse[1]> setwd(dir)Error durante el wrapup: no es posible
cambiar el directorio de trabajo
Error: no more error handlers available (recursive errors?); invoking
'abort' restart


El mar, 21 nov 2023 a las 9:16, Ivan Krylov (<krylov.r00t at gmail.com>)
escribi?:

> On Tue, 21 Nov 2023 08:46:25 +0100
> Ana de las Heras Molina <andelash at ucm.es> wrote:
>
> > > traceback()
> > 4: setwd(dir)
> > 3: .rs.onAvailablePackagesStale(reposString)
> > 2: .rs.availablePackages()
> > 1: .rs.rpc.discover_package_dependencies("3C994FEC", ".R")
>
> This is something that RStudio (not R itself!) does, but it shouldn't
> be failing. Here's what seems to be failing for you [*]:
>
>    # prepare directory for discovery of available packages
>    dir <- tempfile("rstudio-available-packages-")
>    dir.create(dir, showWarnings = FALSE)
>
>    # create a file in that directory
>    saveRDS(Sys.time(), file = file.path(dir, "time.rds"))
>    # (This doesn't fail because we keep executing the function, so the
>    # directory must exist!)
>
>    # move there
>    owd <- setwd(dir) # this somehow fails
>
> Is it an option to disable OneDrive for the home directory? It's
> clearly doing something terrible to your temporary files. If not, it
> should be possible to create a separate temporary directory on your
> computer (the path must not contain spaces) and list it in the
> .Renviron file in the home directory as the TMPDIR variable:
>
> TMPDIR=C:/my/R/temp/directory
>
> See help(Startup) for more information on .Renviron.
>
> Alternatively, we may try to perform some debugging. If you set
> options(error = recover) and run .rs.availablePackages() again, it
> should fail and give you a debugger prompt. Choose the deepest option
> in the call stack and try to find out the value of the `dir` variable.
> Does dir.exists(dir) still return TRUE? Does setwd(dir) still fail? Can
> you open the directory in the Windows Explorer?
>
> The last but not the least, do you see some of the same problems if you
> launch Rgui.exe instead of RStudio?
>
> --
> Best regards,
> Ivan
>
> [*]
>
> https://github.com/rstudio/rstudio/blob/45af283a7a5853399904ddc438f6cd89d9b5c137/src/cpp/session/modules/SessionPackages.R#L1625-L1636
>


-- 
*Ana de las Heras Molina*


Nutrici?n Animal
Departamento de  Producci?n Animal
Facultad de Veterinaria
Universidad Complutense de Madrid

*Contacto*: 913943855/anaherasm at ucm.es

	[[alternative HTML version deleted]]


From @nde|@@h @end|ng |rom ucm@e@  Tue Nov 21 13:41:41 2023
From: @nde|@@h @end|ng |rom ucm@e@ (Ana de las Heras Molina)
Date: Tue, 21 Nov 2023 13:41:41 +0100
Subject: [R] [External] Re:  Error in setwd(dir) when initializing R
In-Reply-To: <20231121140643.104d6271@arachnoid>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
 <20231120215629.7dd8d6f9@Tarkus>
 <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>
 <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>
 <20231121111601.44399393@Tarkus>
 <CAD+E279rM4WjAmC9RKS1=Dv3ZLARsvN1hqk1bWV0stAvV4OB7g@mail.gmail.com>
 <20231121140643.104d6271@arachnoid>
Message-ID: <CAD+E279OVDabN0Ko5-gcRKtW-X40Qi6ztkkJz9zZbHVRfQJReQ@mail.gmail.com>

Hello,

I am sorry for my ignorance, but what is Rgui.exe?

El mar, 21 nov 2023 a las 12:06, Ivan Krylov (<krylov.r00t at gmail.com>)
escribi?:

> ? Tue, 21 Nov 2023 10:51:59 +0100
> Ana de las Heras Molina <andelash at ucm.es> ?????:
>
> > I uninstalled onedrive, I eliminated all the folders and then
> > reinstalled R and RStudio... but it is RStudio the one creating a
> > folder called C:\Users\Ana\OneDrive - Universidad Complutense de
> > Madrid (UCM)\Documentos.
>
> Does Rgui.exe use a different home directory from RStudio? Perhaps you
> need not to reinstall RStudio (which deletes and recreates the program
> files which aren't damaged) but to wipe the profile (the settings
> somewhere under %APPDATA% or %LOCALAPPDATA%), but it pays to be extra
> careful about these directories. People at
> <https://community.rstudio.com/> may know more about that.
>
> I'm afraid I don't know how to disable OneDrive on a Windows 10
> installation. If your university has a Microsoft support contract, it
> could be worth asking the Microsoft representative to fix OneDrive so
> that temporary files would work on it and telling them the steps to
> reproduce the problem.
>
> > Browse[1]> dir.exists(dir)
> > [1] TRUE
> > Browse[1]> setwd(dir)
> > Error durante el wrapup: no es posible cambiar el directorio de
> > trabajo
>
> What is the value of `dir` at this point? (What does print(dir) say?)
> Can you open this directory in Windows Explorer?
>
> If possible, could you please set your mailer to compose messages in
> plain text instead of HTML? The plain text versions of your messages
> that your mailer generates from the HTML messages are somewhat mangled:
> https://stat.ethz.ch/pipermail/r-help/2023-November/478593.html
>
> --
> Best regards,
> Ivan
>


-- 
*Ana de las Heras Molina*


Nutrici?n Animal
Departamento de  Producci?n Animal
Facultad de Veterinaria
Universidad Complutense de Madrid

*Contacto*: 913943855/anaherasm at ucm.es

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Nov 21 19:41:45 2023
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 21 Nov 2023 18:41:45 +0000
Subject: [R] [External] Re: Error in setwd(dir) when initializing R
In-Reply-To: <CAD+E279OVDabN0Ko5-gcRKtW-X40Qi6ztkkJz9zZbHVRfQJReQ@mail.gmail.com>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
 <20231120215629.7dd8d6f9@Tarkus>
 <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>
 <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>
 <20231121111601.44399393@Tarkus>
 <CAD+E279rM4WjAmC9RKS1=Dv3ZLARsvN1hqk1bWV0stAvV4OB7g@mail.gmail.com>
 <20231121140643.104d6271@arachnoid>
 <CAD+E279OVDabN0Ko5-gcRKtW-X40Qi6ztkkJz9zZbHVRfQJReQ@mail.gmail.com>
Message-ID: <e4fe9697-4118-024a-848a-848996c013f7@dewey.myzen.co.uk>

Dear Ana

When you installed R it gave you an option to put a shortcut on the 
desktop. If you did that then you can start the R GUI by clicking on it. 
You may need to customise it for your preferences. Specifically it 
starts R with an option cd-user-docs which I delete and I then alter the 
starting option to start in the directory I want. You may have different 
preferences of course.

Try Rgui as Ivan suggests and report back what happened.

You may have to ask your local IT support as if this is something the 
Complutense is setting up it is surprising that all your collegues are 
free of problems. Have you asked around?

Michael

On 21/11/2023 12:41, Ana de las Heras Molina wrote:
> Hello,
> 
> I am sorry for my ignorance, but what is Rgui.exe?
> 
> El mar, 21 nov 2023 a las 12:06, Ivan Krylov (<krylov.r00t at gmail.com>)
> escribi?:
> 
>> ? Tue, 21 Nov 2023 10:51:59 +0100
>> Ana de las Heras Molina <andelash at ucm.es> ?????:
>>
>>> I uninstalled onedrive, I eliminated all the folders and then
>>> reinstalled R and RStudio... but it is RStudio the one creating a
>>> folder called C:\Users\Ana\OneDrive - Universidad Complutense de
>>> Madrid (UCM)\Documentos.
>>
>> Does Rgui.exe use a different home directory from RStudio? Perhaps you
>> need not to reinstall RStudio (which deletes and recreates the program
>> files which aren't damaged) but to wipe the profile (the settings
>> somewhere under %APPDATA% or %LOCALAPPDATA%), but it pays to be extra
>> careful about these directories. People at
>> <https://community.rstudio.com/> may know more about that.
>>
>> I'm afraid I don't know how to disable OneDrive on a Windows 10
>> installation. If your university has a Microsoft support contract, it
>> could be worth asking the Microsoft representative to fix OneDrive so
>> that temporary files would work on it and telling them the steps to
>> reproduce the problem.
>>
>>> Browse[1]> dir.exists(dir)
>>> [1] TRUE
>>> Browse[1]> setwd(dir)
>>> Error durante el wrapup: no es posible cambiar el directorio de
>>> trabajo
>>
>> What is the value of `dir` at this point? (What does print(dir) say?)
>> Can you open this directory in Windows Explorer?
>>
>> If possible, could you please set your mailer to compose messages in
>> plain text instead of HTML? The plain text versions of your messages
>> that your mailer generates from the HTML messages are somewhat mangled:
>> https://stat.ethz.ch/pipermail/r-help/2023-November/478593.html
>>
>> --
>> Best regards,
>> Ivan
>>
> 
> 

-- 
Michael


From @nde|@@h @end|ng |rom ucm@e@  Wed Nov 22 10:17:38 2023
From: @nde|@@h @end|ng |rom ucm@e@ (Ana de las Heras Molina)
Date: Wed, 22 Nov 2023 10:17:38 +0100
Subject: [R] [External] Re: Error in setwd(dir) when initializing R
In-Reply-To: <e4fe9697-4118-024a-848a-848996c013f7@dewey.myzen.co.uk>
References: <CAD+E27-8S-09FxzZGJUboqR2JjhmY7AEsTzo_0hDYBXtonFFmg@mail.gmail.com>
 <20231120215629.7dd8d6f9@Tarkus>
 <d8ee1734-bf2e-83db-3bb-ba5f2d1bf0c0@uiowa.edu>
 <CAD+E279MTw3UtXaELOr1Y=TPM_CNhhPrZAkXZo_B4VFTK1RU+A@mail.gmail.com>
 <20231121111601.44399393@Tarkus>
 <CAD+E279rM4WjAmC9RKS1=Dv3ZLARsvN1hqk1bWV0stAvV4OB7g@mail.gmail.com>
 <20231121140643.104d6271@arachnoid>
 <CAD+E279OVDabN0Ko5-gcRKtW-X40Qi6ztkkJz9zZbHVRfQJReQ@mail.gmail.com>
 <e4fe9697-4118-024a-848a-848996c013f7@dewey.myzen.co.uk>
Message-ID: <CAD+E279mgqc_GDPfODjvKQtDHe7aho8UmRJi0mCD6gMnLez+4w@mail.gmail.com>

Thank you all for your help. I was better with Rgui. I have the feeling
that it was me, doing something wrong when I uninstalled Onedrive from both
computers... I will talk with the IT in the university.

Again, thank you for your interest. I have learnt a lot.

El mar, 21 nov 2023 a las 19:41, Michael Dewey (<lists at dewey.myzen.co.uk>)
escribi?:

> Dear Ana
>
> When you installed R it gave you an option to put a shortcut on the
> desktop. If you did that then you can start the R GUI by clicking on it.
> You may need to customise it for your preferences. Specifically it
> starts R with an option cd-user-docs which I delete and I then alter the
> starting option to start in the directory I want. You may have different
> preferences of course.
>
> Try Rgui as Ivan suggests and report back what happened.
>
> You may have to ask your local IT support as if this is something the
> Complutense is setting up it is surprising that all your collegues are
> free of problems. Have you asked around?
>
> Michael
>
> On 21/11/2023 12:41, Ana de las Heras Molina wrote:
> > Hello,
> >
> > I am sorry for my ignorance, but what is Rgui.exe?
> >
> > El mar, 21 nov 2023 a las 12:06, Ivan Krylov (<krylov.r00t at gmail.com>)
> > escribi?:
> >
> >> ? Tue, 21 Nov 2023 10:51:59 +0100
> >> Ana de las Heras Molina <andelash at ucm.es> ?????:
> >>
> >>> I uninstalled onedrive, I eliminated all the folders and then
> >>> reinstalled R and RStudio... but it is RStudio the one creating a
> >>> folder called C:\Users\Ana\OneDrive - Universidad Complutense de
> >>> Madrid (UCM)\Documentos.
> >>
> >> Does Rgui.exe use a different home directory from RStudio? Perhaps you
> >> need not to reinstall RStudio (which deletes and recreates the program
> >> files which aren't damaged) but to wipe the profile (the settings
> >> somewhere under %APPDATA% or %LOCALAPPDATA%), but it pays to be extra
> >> careful about these directories. People at
> >> <https://community.rstudio.com/> may know more about that.
> >>
> >> I'm afraid I don't know how to disable OneDrive on a Windows 10
> >> installation. If your university has a Microsoft support contract, it
> >> could be worth asking the Microsoft representative to fix OneDrive so
> >> that temporary files would work on it and telling them the steps to
> >> reproduce the problem.
> >>
> >>> Browse[1]> dir.exists(dir)
> >>> [1] TRUE
> >>> Browse[1]> setwd(dir)
> >>> Error durante el wrapup: no es posible cambiar el directorio de
> >>> trabajo
> >>
> >> What is the value of `dir` at this point? (What does print(dir) say?)
> >> Can you open this directory in Windows Explorer?
> >>
> >> If possible, could you please set your mailer to compose messages in
> >> plain text instead of HTML? The plain text versions of your messages
> >> that your mailer generates from the HTML messages are somewhat mangled:
> >> https://stat.ethz.ch/pipermail/r-help/2023-November/478593.html
> >>
> >> --
> >> Best regards,
> >> Ivan
> >>
> >
> >
>
> --
> Michael
>


-- 
*Ana de las Heras Molina*


Nutrici?n Animal
Departamento de  Producci?n Animal
Facultad de Veterinaria
Universidad Complutense de Madrid

*Contacto*: 913943855/anaherasm at ucm.es

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 22 23:37:04 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Nov 2023 14:37:04 -0800
Subject: [R] **OFF TOPIC**: Fabrication of Scientific Data by Generative AI
Message-ID: <CAGxFJbQaxBpJf_ka3DPu_mOOgbOqW7vzvDxhuk0KqBobrLdkwA@mail.gmail.com>

All:
**OFF TOPIC** -- feel free to respond to me personally, but I will not
respond to on-list comments.

https://www.nature.com/articles/d41586-023-03635-w

Many of you will no doubt know of this already.  I hope it will be of
interest to all concerned with research replicability, integrity, and
the public's view of the value of scientific research.

Best to all (and happy Thanksgiving to US readers),

Bert


From sibyiie@stoeckii m@iii@g oii gmx@ch  Fri Nov 24 11:52:20 2023
From: sibyiie@stoeckii m@iii@g oii gmx@ch (sibyiie@stoeckii m@iii@g oii gmx@ch)
Date: Fri, 24 Nov 2023 11:52:20 +0100
Subject: [R] ggplot adjust two y-axis
Message-ID: <033201da1ec4$4c60b340$e52219c0$@gmx.ch>

Dear R-users

Is it possible to adjust two y-axis in a ggplot differently?
- First y axis (0-60)
- Second y axis (0-2500)


### Figure 1
ggplot(Fig1,aes(BFF,Wert,fill=Studien_Flaeche))+
  geom_bar(stat="identity",position='dodge')+
  scale_y_continuous(name="First Axis", sec.axis=sec_axis(trans=~.*50,
name="Second Axis"))+
  scale_fill_brewer(palette="Set1")

Thanks a lot
Sibylle

-------------- next part --------------
A non-text attachment was scrubbed...
Name: ggplot.pdf
Type: application/pdf
Size: 4806 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20231124/f84b6dbc/attachment.pdf>

From ce@g|guere @end|ng |rom gm@||@com  Fri Nov 24 15:10:48 2023
From: ce@g|guere @end|ng |rom gm@||@com (=?iso-8859-1?Q?Charles-=C9douard_Gigu=E8re?=)
Date: Fri, 24 Nov 2023 09:10:48 -0500
Subject: [R] ggplot adjust two y-axis
In-Reply-To: <033201da1ec4$4c60b340$e52219c0$@gmx.ch>
References: <033201da1ec4$4c60b340$e52219c0$@gmx.ch>
Message-ID: <007701da1ee0$062cae30$12860a90$@gmail.com>

Hi Sibylle, 
For that kind of data with two different scales, I generally use two graphs
that I name gg1 and gg2 and join them using gridExtra::grid.arrange(gg1,
gg2). This way, the red part of your graph is easier to interpret. 
Have a nice day, 
Charles-?douard 

-----Message d'origine-----
De?: R-help <r-help-bounces at r-project.org> De la part de
sibylle.stoeckli at gmx.ch
Envoy??: 24 novembre 2023 05:52
??: r-help at r-project.org
Objet?: [R] ggplot adjust two y-axis

Dear R-users

Is it possible to adjust two y-axis in a ggplot differently?
- First y axis (0-60)
- Second y axis (0-2500)


### Figure 1
ggplot(Fig1,aes(BFF,Wert,fill=Studien_Flaeche))+
  geom_bar(stat="identity",position='dodge')+
  scale_y_continuous(name="First Axis", sec.axis=sec_axis(trans=~.*50,
name="Second Axis"))+
  scale_fill_brewer(palette="Set1")

Thanks a lot
Sibylle


From ce@g|guere @end|ng |rom gm@||@com  Fri Nov 24 15:14:27 2023
From: ce@g|guere @end|ng |rom gm@||@com (=?iso-8859-1?Q?Charles-=C9douard_Gigu=E8re?=)
Date: Fri, 24 Nov 2023 09:14:27 -0500
Subject: [R] ggplot adjust two y-axis
In-Reply-To: <007701da1ee0$062cae30$12860a90$@gmail.com>
References: <033201da1ec4$4c60b340$e52219c0$@gmx.ch>
 <007701da1ee0$062cae30$12860a90$@gmail.com>
Message-ID: <00b601da1ee0$893b1870$9bb14950$@gmail.com>

You could also use more simply facet_wrap(~ Studien_Flaeche). 
Charles-?douard

-----Message d'origine-----
De?: Charles-?douard Gigu?re <ce.giguere at gmail.com> 
Envoy??: 24 novembre 2023 09:11
??: sibylle.stoeckli at gmx.ch; r-help at r-project.org
Objet?: RE: [R] ggplot adjust two y-axis

Hi Sibylle,
For that kind of data with two different scales, I generally use two graphs
that I name gg1 and gg2 and join them using gridExtra::grid.arrange(gg1,
gg2). This way, the red part of your graph is easier to interpret. 
Have a nice day,
Charles-?douard 

-----Message d'origine-----
De?: R-help <r-help-bounces at r-project.org> De la part de
sibylle.stoeckli at gmx.ch Envoy??: 24 novembre 2023 05:52 ??:
r-help at r-project.org Objet?: [R] ggplot adjust two y-axis

Dear R-users

Is it possible to adjust two y-axis in a ggplot differently?
- First y axis (0-60)
- Second y axis (0-2500)


### Figure 1
ggplot(Fig1,aes(BFF,Wert,fill=Studien_Flaeche))+
  geom_bar(stat="identity",position='dodge')+
  scale_y_continuous(name="First Axis", sec.axis=sec_axis(trans=~.*50,
name="Second Axis"))+
  scale_fill_brewer(palette="Set1")

Thanks a lot
Sibylle


From ce@g|guere @end|ng |rom gm@||@com  Fri Nov 24 15:57:05 2023
From: ce@g|guere @end|ng |rom gm@||@com (=?iso-8859-1?Q?Charles-=C9douard_Gigu=E8re?=)
Date: Fri, 24 Nov 2023 09:57:05 -0500
Subject: [R] ggplot adjust two y-axis
In-Reply-To: <03c201da1ee2$4e56bb40$eb0431c0$@gmx.ch>
References: <033201da1ec4$4c60b340$e52219c0$@gmx.ch>
 <007701da1ee0$062cae30$12860a90$@gmail.com>
 <00b601da1ee0$893b1870$9bb14950$@gmail.com>
 <03c201da1ee2$4e56bb40$eb0431c0$@gmx.ch>
Message-ID: <00ce01da1ee6$7d6b5b30$78421190$@gmail.com>

Hi,
 I don't know the axis mecanism well enough in ggplot but using the original
barplot function you can add an axis on the right using the axis function.

Here is an example: 

test <- as.table(matrix(c(2,10,3,11), 2,2))
barplot(test, beside = TRUE, col = scales::brewer_pal(palette = 1)(2))
axis(4, at = c(0, 5,  10), labels = c(0,50,100))


-----Message d'origine-----
De?: sibylle.stoeckli at gmx.ch <sibylle.stoeckli at gmx.ch> 
Envoy??: 24 novembre 2023 09:27
??: 'Charles-?douard Gigu?re' <ce.giguere at gmail.com>; r-help at r-project.org
Objet?: RE: [R] ggplot adjust two y-axis

Dear Charles-Edouard

Thanks a lot.
So no way in R to just simply have one ggplot with to axis as in Excel
(attachment)?

Kind regards
Sibylle

-----Original Message-----
From: Charles-?douard Gigu?re <ce.giguere at gmail.com>
Sent: Friday, November 24, 2023 3:14 PM
To: sibylle.stoeckli at gmx.ch; r-help at r-project.org
Subject: RE: [R] ggplot adjust two y-axis

You could also use more simply facet_wrap(~ Studien_Flaeche). 
Charles-?douard

-----Message d'origine-----
De?: Charles-?douard Gigu?re <ce.giguere at gmail.com> Envoy??: 24 novembre
2023 09:11 ??: sibylle.stoeckli at gmx.ch; r-help at r-project.org Objet?: RE: [R]
ggplot adjust two y-axis

Hi Sibylle,
For that kind of data with two different scales, I generally use two graphs
that I name gg1 and gg2 and join them using gridExtra::grid.arrange(gg1,
gg2). This way, the red part of your graph is easier to interpret. 
Have a nice day,
Charles-?douard 

-----Message d'origine-----
De?: R-help <r-help-bounces at r-project.org> De la part de
sibylle.stoeckli at gmx.ch Envoy??: 24 novembre 2023 05:52 ??:
r-help at r-project.org Objet?: [R] ggplot adjust two y-axis

Dear R-users

Is it possible to adjust two y-axis in a ggplot differently?
- First y axis (0-60)
- Second y axis (0-2500)


### Figure 1
ggplot(Fig1,aes(BFF,Wert,fill=Studien_Flaeche))+
  geom_bar(stat="identity",position='dodge')+
  scale_y_continuous(name="First Axis", sec.axis=sec_axis(trans=~.*50,
name="Second Axis"))+
  scale_fill_brewer(palette="Set1")

Thanks a lot
Sibylle


From sibyiie@stoeckii m@iii@g oii gmx@ch  Fri Nov 24 17:27:17 2023
From: sibyiie@stoeckii m@iii@g oii gmx@ch (sibyiie@stoeckii m@iii@g oii gmx@ch)
Date: Fri, 24 Nov 2023 17:27:17 +0100
Subject: [R] ggplot adjust two y-axis
In-Reply-To: <00ce01da1ee6$7d6b5b30$78421190$@gmail.com>
References: <033201da1ec4$4c60b340$e52219c0$@gmx.ch>
 <007701da1ee0$062cae30$12860a90$@gmail.com>
 <00b601da1ee0$893b1870$9bb14950$@gmail.com>
 <03c201da1ee2$4e56bb40$eb0431c0$@gmx.ch>
 <00ce01da1ee6$7d6b5b30$78421190$@gmail.com>
Message-ID: <03e801da1ef3$17cce0c0$4766a240$@gmx.ch>

Dear Charles-Edouard

Thanks a lot. Yes indeed barplot sounds excellent.

Unfortunately, the scale of the smaller axis is fixed, even If I am able to
draw to axes. The idea is to expand the scale to the scale to the second
axis for comparison.
F1 <- as.table(matrix(c(50,11,6,17,16,3,1,2237,611,403,240,280,0,0), 2,7))  
barplot(F1, beside = TRUE, col = c("blue", "grey")) 
axis(2, at=c(0,10,20,30,40,50,60, labels=c(0,10,20,30,40,50,60)))
axis(4, at = c(0,500,1000,1500,2000,2500), labels =
c(0,500,1000,1500,2000,2500))

Kind regards
Sibylle 


-----Original Message-----
From: Charles-?douard Gigu?re <ce.giguere at gmail.com> 
Sent: Friday, November 24, 2023 3:57 PM
To: sibylle.stoeckli at gmx.ch; r-help at r-project.org
Subject: RE: [R] ggplot adjust two y-axis

Hi,
 I don't know the axis mecanism well enough in ggplot but using the original
barplot function you can add an axis on the right using the axis function.

Here is an example: 

test <- as.table(matrix(c(2,10,3,11), 2,2)) barplot(test, beside = TRUE, col
= scales::brewer_pal(palette = 1)(2)) axis(4, at = c(0, 5,  10), labels =
c(0,50,100))


-----Message d'origine-----
De?: sibylle.stoeckli at gmx.ch <sibylle.stoeckli at gmx.ch> Envoy??: 24 novembre
2023 09:27 ??: 'Charles-?douard Gigu?re' <ce.giguere at gmail.com>;
r-help at r-project.org Objet?: RE: [R] ggplot adjust two y-axis

Dear Charles-Edouard

Thanks a lot.
So no way in R to just simply have one ggplot with to axis as in Excel
(attachment)?

Kind regards
Sibylle

-----Original Message-----
From: Charles-?douard Gigu?re <ce.giguere at gmail.com>
Sent: Friday, November 24, 2023 3:14 PM
To: sibylle.stoeckli at gmx.ch; r-help at r-project.org
Subject: RE: [R] ggplot adjust two y-axis

You could also use more simply facet_wrap(~ Studien_Flaeche). 
Charles-?douard

-----Message d'origine-----
De?: Charles-?douard Gigu?re <ce.giguere at gmail.com> Envoy??: 24 novembre
2023 09:11 ??: sibylle.stoeckli at gmx.ch; r-help at r-project.org Objet?: RE: [R]
ggplot adjust two y-axis

Hi Sibylle,
For that kind of data with two different scales, I generally use two graphs
that I name gg1 and gg2 and join them using gridExtra::grid.arrange(gg1,
gg2). This way, the red part of your graph is easier to interpret. 
Have a nice day,
Charles-?douard 

-----Message d'origine-----
De?: R-help <r-help-bounces at r-project.org> De la part de
sibylle.stoeckli at gmx.ch Envoy??: 24 novembre 2023 05:52 ??:
r-help at r-project.org Objet?: [R] ggplot adjust two y-axis

Dear R-users

Is it possible to adjust two y-axis in a ggplot differently?
- First y axis (0-60)
- Second y axis (0-2500)


### Figure 1
ggplot(Fig1,aes(BFF,Wert,fill=Studien_Flaeche))+
  geom_bar(stat="identity",position='dodge')+
  scale_y_continuous(name="First Axis", sec.axis=sec_axis(trans=~.*50,
name="Second Axis"))+
  scale_fill_brewer(palette="Set1")

Thanks a lot
Sibylle




-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot2.pdf
Type: application/pdf
Size: 4386 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20231124/f1a8bab7/attachment.pdf>

From ce@g|guere @end|ng |rom gm@||@com  Fri Nov 24 18:07:33 2023
From: ce@g|guere @end|ng |rom gm@||@com (=?iso-8859-1?Q?Charles-=C9douard_Gigu=E8re?=)
Date: Fri, 24 Nov 2023 12:07:33 -0500
Subject: [R] ggplot adjust two y-axis
In-Reply-To: <03e801da1ef3$17cce0c0$4766a240$@gmx.ch>
References: <033201da1ec4$4c60b340$e52219c0$@gmx.ch>
 <007701da1ee0$062cae30$12860a90$@gmail.com>
 <00b601da1ee0$893b1870$9bb14950$@gmail.com>
 <03c201da1ee2$4e56bb40$eb0431c0$@gmx.ch>
 <00ce01da1ee6$7d6b5b30$78421190$@gmail.com>
 <03e801da1ef3$17cce0c0$4766a240$@gmx.ch>
Message-ID: <012c01da1ef8$b7bb9ea0$2732dbe0$@gmail.com>

Hi, 
Just find a scaling factor that would make the two sets of data comparable.
Here I divided the second row by 5 and did the same for the second axis. 
Charles-?douard
F1 <- as.table(matrix(c(50,11,6,17,16,3,1,2237,611,403,240,280,0,0), 2,7))
barplot(F1, beside = TRUE, col = c("blue", "grey")) axis(2,
at=c(0,10,20,30,40,50,60, labels=c(0,10,20,30,40,50,60))) axis(4, at =
c(0,500,1000,1500,2000,2500), labels =
c(0,500,1000,1500,2000,2500))

-----Message d'origine-----
De?: sibylle.stoeckli at gmx.ch <sibylle.stoeckli at gmx.ch> 
Envoy??: 24 novembre 2023 11:27
??: 'Charles-?douard Gigu?re' <ce.giguere at gmail.com>; r-help at r-project.org
Objet?: RE: [R] ggplot adjust two y-axis

Dear Charles-Edouard

Thanks a lot. Yes indeed barplot sounds excellent.

Unfortunately, the scale of the smaller axis is fixed, even If I am able to
draw to axes. The idea is to expand the scale to the scale to the second
axis for comparison.
F1 <- as.table(matrix(c(50,11,6,17,16,3,1,2237,611,403,240,280,0,0), 2,7))
barplot(F1, beside = TRUE, col = c("blue", "grey")) axis(2,
at=c(0,10,20,30,40,50,60, labels=c(0,10,20,30,40,50,60))) axis(4, at =
c(0,500,1000,1500,2000,2500), labels =
c(0,500,1000,1500,2000,2500))

Kind regards
Sibylle 


-----Original Message-----
From: Charles-?douard Gigu?re <ce.giguere at gmail.com>
Sent: Friday, November 24, 2023 3:57 PM
To: sibylle.stoeckli at gmx.ch; r-help at r-project.org
Subject: RE: [R] ggplot adjust two y-axis

Hi,
 I don't know the axis mecanism well enough in ggplot but using the original
barplot function you can add an axis on the right using the axis function.

Here is an example: 

test <- as.table(matrix(c(2,10,3,11), 2,2)) barplot(test, beside = TRUE, col
= scales::brewer_pal(palette = 1)(2)) axis(4, at = c(0, 5,  10), labels =
c(0,50,100))


-----Message d'origine-----
De?: sibylle.stoeckli at gmx.ch <sibylle.stoeckli at gmx.ch> Envoy??: 24 novembre
2023 09:27 ??: 'Charles-?douard Gigu?re' <ce.giguere at gmail.com>;
r-help at r-project.org Objet?: RE: [R] ggplot adjust two y-axis

Dear Charles-Edouard

Thanks a lot.
So no way in R to just simply have one ggplot with to axis as in Excel
(attachment)?

Kind regards
Sibylle

-----Original Message-----
From: Charles-?douard Gigu?re <ce.giguere at gmail.com>
Sent: Friday, November 24, 2023 3:14 PM
To: sibylle.stoeckli at gmx.ch; r-help at r-project.org
Subject: RE: [R] ggplot adjust two y-axis

You could also use more simply facet_wrap(~ Studien_Flaeche). 
Charles-?douard

-----Message d'origine-----
De?: Charles-?douard Gigu?re <ce.giguere at gmail.com> Envoy??: 24 novembre
2023 09:11 ??: sibylle.stoeckli at gmx.ch; r-help at r-project.org Objet?: RE: [R]
ggplot adjust two y-axis

Hi Sibylle,
For that kind of data with two different scales, I generally use two graphs
that I name gg1 and gg2 and join them using gridExtra::grid.arrange(gg1,
gg2). This way, the red part of your graph is easier to interpret. 
Have a nice day,
Charles-?douard 

-----Message d'origine-----
De?: R-help <r-help-bounces at r-project.org> De la part de
sibylle.stoeckli at gmx.ch Envoy??: 24 novembre 2023 05:52 ??:
r-help at r-project.org Objet?: [R] ggplot adjust two y-axis

Dear R-users

Is it possible to adjust two y-axis in a ggplot differently?
- First y axis (0-60)
- Second y axis (0-2500)


### Figure 1
ggplot(Fig1,aes(BFF,Wert,fill=Studien_Flaeche))+
  geom_bar(stat="identity",position='dodge')+
  scale_y_continuous(name="First Axis", sec.axis=sec_axis(trans=~.*50,
name="Second Axis"))+
  scale_fill_brewer(palette="Set1")

Thanks a lot
Sibylle


From jrkr|de@u @end|ng |rom gm@||@com  Fri Nov 24 19:10:13 2023
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Fri, 24 Nov 2023 13:10:13 -0500
Subject: [R] ggplot adjust two y-axis
In-Reply-To: <012c01da1ef8$b7bb9ea0$2732dbe0$@gmail.com>
References: <033201da1ec4$4c60b340$e52219c0$@gmx.ch>
 <007701da1ee0$062cae30$12860a90$@gmail.com>
 <00b601da1ee0$893b1870$9bb14950$@gmail.com>
 <03c201da1ee2$4e56bb40$eb0431c0$@gmx.ch>
 <00ce01da1ee6$7d6b5b30$78421190$@gmail.com>
 <03e801da1ef3$17cce0c0$4766a240$@gmx.ch>
 <012c01da1ef8$b7bb9ea0$2732dbe0$@gmail.com>
Message-ID: <CAKZQJMDKKHh-ZYiM7rpHHi-xhQpeNbCf5QpUUWZw_qw=DtNF0g@mail.gmail.com>

https://r-graph-gallery.com/line-chart-dual-Y-axis-ggplot2.html

On Fri, 24 Nov 2023 at 12:08, Charles-?douard Gigu?re <ce.giguere at gmail.com>
wrote:

> Hi,
> Just find a scaling factor that would make the two sets of data comparable.
> Here I divided the second row by 5 and did the same for the second axis.
> Charles-?douard
> F1 <- as.table(matrix(c(50,11,6,17,16,3,1,2237,611,403,240,280,0,0), 2,7))
> barplot(F1, beside = TRUE, col = c("blue", "grey")) axis(2,
> at=c(0,10,20,30,40,50,60, labels=c(0,10,20,30,40,50,60))) axis(4, at =
> c(0,500,1000,1500,2000,2500), labels =
> c(0,500,1000,1500,2000,2500))
>
> -----Message d'origine-----
> De : sibylle.stoeckli at gmx.ch <sibylle.stoeckli at gmx.ch>
> Envoy? : 24 novembre 2023 11:27
> ? : 'Charles-?douard Gigu?re' <ce.giguere at gmail.com>; r-help at r-project.org
> Objet : RE: [R] ggplot adjust two y-axis
>
> Dear Charles-Edouard
>
> Thanks a lot. Yes indeed barplot sounds excellent.
>
> Unfortunately, the scale of the smaller axis is fixed, even If I am able to
> draw to axes. The idea is to expand the scale to the scale to the second
> axis for comparison.
> F1 <- as.table(matrix(c(50,11,6,17,16,3,1,2237,611,403,240,280,0,0), 2,7))
> barplot(F1, beside = TRUE, col = c("blue", "grey")) axis(2,
> at=c(0,10,20,30,40,50,60, labels=c(0,10,20,30,40,50,60))) axis(4, at =
> c(0,500,1000,1500,2000,2500), labels =
> c(0,500,1000,1500,2000,2500))
>
> Kind regards
> Sibylle
>
>
> -----Original Message-----
> From: Charles-?douard Gigu?re <ce.giguere at gmail.com>
> Sent: Friday, November 24, 2023 3:57 PM
> To: sibylle.stoeckli at gmx.ch; r-help at r-project.org
> Subject: RE: [R] ggplot adjust two y-axis
>
> Hi,
>  I don't know the axis mecanism well enough in ggplot but using the
> original
> barplot function you can add an axis on the right using the axis function.
>
> Here is an example:
>
> test <- as.table(matrix(c(2,10,3,11), 2,2)) barplot(test, beside = TRUE,
> col
> = scales::brewer_pal(palette = 1)(2)) axis(4, at = c(0, 5,  10), labels =
> c(0,50,100))
>
>
> -----Message d'origine-----
> De : sibylle.stoeckli at gmx.ch <sibylle.stoeckli at gmx.ch> Envoy? : 24
> novembre
> 2023 09:27 ? : 'Charles-?douard Gigu?re' <ce.giguere at gmail.com>;
> r-help at r-project.org Objet : RE: [R] ggplot adjust two y-axis
>
> Dear Charles-Edouard
>
> Thanks a lot.
> So no way in R to just simply have one ggplot with to axis as in Excel
> (attachment)?
>
> Kind regards
> Sibylle
>
> -----Original Message-----
> From: Charles-?douard Gigu?re <ce.giguere at gmail.com>
> Sent: Friday, November 24, 2023 3:14 PM
> To: sibylle.stoeckli at gmx.ch; r-help at r-project.org
> Subject: RE: [R] ggplot adjust two y-axis
>
> You could also use more simply facet_wrap(~ Studien_Flaeche).
> Charles-?douard
>
> -----Message d'origine-----
> De : Charles-?douard Gigu?re <ce.giguere at gmail.com> Envoy? : 24 novembre
> 2023 09:11 ? : sibylle.stoeckli at gmx.ch; r-help at r-project.org Objet : RE:
> [R]
> ggplot adjust two y-axis
>
> Hi Sibylle,
> For that kind of data with two different scales, I generally use two graphs
> that I name gg1 and gg2 and join them using gridExtra::grid.arrange(gg1,
> gg2). This way, the red part of your graph is easier to interpret.
> Have a nice day,
> Charles-?douard
>
> -----Message d'origine-----
> De : R-help <r-help-bounces at r-project.org> De la part de
> sibylle.stoeckli at gmx.ch Envoy? : 24 novembre 2023 05:52 ? :
> r-help at r-project.org Objet : [R] ggplot adjust two y-axis
>
> Dear R-users
>
> Is it possible to adjust two y-axis in a ggplot differently?
> - First y axis (0-60)
> - Second y axis (0-2500)
>
>
> ### Figure 1
> ggplot(Fig1,aes(BFF,Wert,fill=Studien_Flaeche))+
>   geom_bar(stat="identity",position='dodge')+
>   scale_y_continuous(name="First Axis", sec.axis=sec_axis(trans=~.*50,
> name="Second Axis"))+
>   scale_fill_brewer(palette="Set1")
>
> Thanks a lot
> Sibylle
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From sibyiie@stoeckii m@iii@g oii gmx@ch  Fri Nov 24 11:29:50 2023
From: sibyiie@stoeckii m@iii@g oii gmx@ch (sibyiie@stoeckii m@iii@g oii gmx@ch)
Date: Fri, 24 Nov 2023 11:29:50 +0100
Subject: [R] ggplot with two x-axis and two dimensions
Message-ID: <032801da1ec1$28021f00$78065d00$@gmx.ch>

Dear R-user

Does anybody now, if ggplot allows to use two x-axis including two
dimensions (similar to excel plot (picture 1 in the pdf attachmet). If yes,
how should I adapt my code? The parameters are presented in the input file
(attachment: Input).

Fig2b = read.delim("BFF_Fig-2b.txt", na.strings="NA")
names(Fig2b)
head(Fig2b)
summary(Fig2b)
str(Fig2b)
Fig2b$Aspekt<-factor(Fig2b$Aspekt, levels=(c("Voegel", "Kleinsaeuger",
"Schnecken", "Regenwuermer_Asseln", "Pilze")))

### Figure 2b
  ggplot(Fig2b,aes(Aspekt,Wert,fill=Effekt))+
    geom_bar(stat="identity",position='fill')+
    scale_y_continuous(limits=c(0,14), expand=c(0,0))+
    labs(x="", y="Anzahl Studien pro Effekt")

Kind regards
Sibylle


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Picture1.pdf
Type: application/pdf
Size: 161275 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20231124/b94797ef/attachment.pdf>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Input.pdf
Type: application/pdf
Size: 70289 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20231124/b94797ef/attachment-0001.pdf>

From sibyiie@stoeckii m@iii@g oii gmx@ch  Fri Nov 24 15:27:08 2023
From: sibyiie@stoeckii m@iii@g oii gmx@ch (sibyiie@stoeckii m@iii@g oii gmx@ch)
Date: Fri, 24 Nov 2023 15:27:08 +0100
Subject: [R] ggplot adjust two y-axis
In-Reply-To: <00b601da1ee0$893b1870$9bb14950$@gmail.com>
References: <033201da1ec4$4c60b340$e52219c0$@gmx.ch>
 <007701da1ee0$062cae30$12860a90$@gmail.com>
 <00b601da1ee0$893b1870$9bb14950$@gmail.com>
Message-ID: <03c201da1ee2$4e56bb40$eb0431c0$@gmx.ch>

Dear Charles-Edouard

Thanks a lot.
So no way in R to just simply have one ggplot with to axis as in Excel
(attachment)?

Kind regards
Sibylle

-----Original Message-----
From: Charles-?douard Gigu?re <ce.giguere at gmail.com> 
Sent: Friday, November 24, 2023 3:14 PM
To: sibylle.stoeckli at gmx.ch; r-help at r-project.org
Subject: RE: [R] ggplot adjust two y-axis

You could also use more simply facet_wrap(~ Studien_Flaeche). 
Charles-?douard

-----Message d'origine-----
De?: Charles-?douard Gigu?re <ce.giguere at gmail.com> Envoy??: 24 novembre
2023 09:11 ??: sibylle.stoeckli at gmx.ch; r-help at r-project.org Objet?: RE: [R]
ggplot adjust two y-axis

Hi Sibylle,
For that kind of data with two different scales, I generally use two graphs
that I name gg1 and gg2 and join them using gridExtra::grid.arrange(gg1,
gg2). This way, the red part of your graph is easier to interpret. 
Have a nice day,
Charles-?douard 

-----Message d'origine-----
De?: R-help <r-help-bounces at r-project.org> De la part de
sibylle.stoeckli at gmx.ch Envoy??: 24 novembre 2023 05:52 ??:
r-help at r-project.org Objet?: [R] ggplot adjust two y-axis

Dear R-users

Is it possible to adjust two y-axis in a ggplot differently?
- First y axis (0-60)
- Second y axis (0-2500)


### Figure 1
ggplot(Fig1,aes(BFF,Wert,fill=Studien_Flaeche))+
  geom_bar(stat="identity",position='dodge')+
  scale_y_continuous(name="First Axis", sec.axis=sec_axis(trans=~.*50,
name="Second Axis"))+
  scale_fill_brewer(palette="Set1")

Thanks a lot
Sibylle



-------------- next part --------------
A non-text attachment was scrubbed...
Name: Picture1.pdf
Type: application/pdf
Size: 166974 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20231124/e46f62df/attachment.pdf>

From po|c1410 @end|ng |rom gm@||@com  Sat Nov 25 14:22:41 2023
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Sat, 25 Nov 2023 13:22:41 +0000
Subject: [R] ggplot adjust two y-axis
In-Reply-To: <03c201da1ee2$4e56bb40$eb0431c0$@gmx.ch>
References: <033201da1ec4$4c60b340$e52219c0$@gmx.ch>
 <007701da1ee0$062cae30$12860a90$@gmail.com>
 <00b601da1ee0$893b1870$9bb14950$@gmail.com>
 <03c201da1ee2$4e56bb40$eb0431c0$@gmx.ch>
Message-ID: <CA+etgPk_WXkJE0LjaXLBMbkzuWgW8YRG2rO-Myr6x=wf23W7YA@mail.gmail.com>

This is doable. But it's also considered a data visualisation hell! So
Hadley didn't make it easy.

I can provide more details on how to do it later (replying from phone just
now). BUT there is very much a question of should you be plotting like
that. It's probably worth giving it serious thought before figuring out how.


The brief summary of 'how' is to convert the y2 axis values to the y axis
values. Plot it, and add a y2 axis.

So if you were plotting 3 values on y1 with values of 20, 30 and 40. And
the y2 axis should have 150, 350 and 550 for example  then you decide what
150 should be on y1 (is that 20 or perhaps 15??) {This choice changes your
visualisation and hence one of the reasons it can be bad}. If 150 should
appear as 20 you divide all your y2 values by the same proportion (150/20)
and plot them. Then simply add a second y-axis with the scale reversed.





On Sat, 25 Nov 2023, 09:30 , <sibylle.stoeckli at gmx.ch> wrote:

> Dear Charles-Edouard
>
> Thanks a lot.
> So no way in R to just simply have one ggplot with to axis as in Excel
> (attachment)?
>
> Kind regards
> Sibylle
>
> -----Original Message-----
> From: Charles-?douard Gigu?re <ce.giguere at gmail.com>
> Sent: Friday, November 24, 2023 3:14 PM
> To: sibylle.stoeckli at gmx.ch; r-help at r-project.org
> Subject: RE: [R] ggplot adjust two y-axis
>
> You could also use more simply facet_wrap(~ Studien_Flaeche).
> Charles-?douard
>
> -----Message d'origine-----
> De : Charles-?douard Gigu?re <ce.giguere at gmail.com> Envoy? : 24 novembre
> 2023 09:11 ? : sibylle.stoeckli at gmx.ch; r-help at r-project.org Objet : RE:
> [R]
> ggplot adjust two y-axis
>
> Hi Sibylle,
> For that kind of data with two different scales, I generally use two graphs
> that I name gg1 and gg2 and join them using gridExtra::grid.arrange(gg1,
> gg2). This way, the red part of your graph is easier to interpret.
> Have a nice day,
> Charles-?douard
>
> -----Message d'origine-----
> De : R-help <r-help-bounces at r-project.org> De la part de
> sibylle.stoeckli at gmx.ch Envoy? : 24 novembre 2023 05:52 ? :
> r-help at r-project.org Objet : [R] ggplot adjust two y-axis
>
> Dear R-users
>
> Is it possible to adjust two y-axis in a ggplot differently?
> - First y axis (0-60)
> - Second y axis (0-2500)
>
>
> ### Figure 1
> ggplot(Fig1,aes(BFF,Wert,fill=Studien_Flaeche))+
>   geom_bar(stat="identity",position='dodge')+
>   scale_y_continuous(name="First Axis", sec.axis=sec_axis(trans=~.*50,
> name="Second Axis"))+
>   scale_fill_brewer(palette="Set1")
>
> Thanks a lot
> Sibylle
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Nov 25 21:37:37 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 25 Nov 2023 20:37:37 +0000
Subject: [R] ggplot with two x-axis and two dimensions
In-Reply-To: <032801da1ec1$28021f00$78065d00$@gmx.ch>
References: <032801da1ec1$28021f00$78065d00$@gmx.ch>
Message-ID: <db6fe658-58a1-466a-8637-7555f5d50a1e@sapo.pt>

?s 10:29 de 24/11/2023, sibylle.stoeckli at gmx.ch escreveu:
> Dear R-user
> 
> Does anybody now, if ggplot allows to use two x-axis including two
> dimensions (similar to excel plot (picture 1 in the pdf attachmet). If yes,
> how should I adapt my code? The parameters are presented in the input file
> (attachment: Input).
> 
> Fig2b = read.delim("BFF_Fig-2b.txt", na.strings="NA")
> names(Fig2b)
> head(Fig2b)
> summary(Fig2b)
> str(Fig2b)
> Fig2b$Aspekt<-factor(Fig2b$Aspekt, levels=(c("Voegel", "Kleinsaeuger",
> "Schnecken", "Regenwuermer_Asseln", "Pilze")))
> 
> ### Figure 2b
>    ggplot(Fig2b,aes(Aspekt,Wert,fill=Effekt))+
>      geom_bar(stat="identity",position='fill')+
>      scale_y_continuous(limits=c(0,14), expand=c(0,0))+
>      labs(x="", y="Anzahl Studien pro Effekt")
> 
> Kind regards
> Sibylle
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

The first attached file does not match the data in the second file but 
here is an answer to both this question and to your other question [1].

The trick to have a secondary axis is to compute a ratio of axis 
lenghts. The lengths of the main and secondary axis can be computed by 
functions range() and diff(), like in the code below. Then use it to 
scale the secondary axis.



Fig2b <-
   structure(list(
     Aspekt = c("Flora", "Flora", "Flora", "Tagfalter",
                "Tagfalter", "Tagfalter", "Heuschre", "Heuschre", 
"Heuschre",
                "Kaefer_Sp", "Kaefer_Sp", "Kaefer_Sp", "Schwebfli", 
"Schwebfli",
                "Schwebfli", "Bienen_F", "Bienen_F", "Bienen_F", 
"Flora", "Flora",
                "Flora", "Tagfalter", "Tagfalter", "Tagfalter", 
"Heuschre", "Heuschre",
                "Heuschre", "Kaefer_Sp", "Kaefer_Sp", "Kaefer_Sp", 
"Schwebfli",
                "Schwebfli", "Schwebfli", "Bienen_F", "Bienen_F", 
"Bienen_F"),
     BFF = c("BB", "SA", "NE", "BB", "SA", "NE", "BB", "SA", "NE",
             "BB", "SA", "NE", "BB", "SA", "NE", "BB", "SA", "NE", "BB",
             "SA", "NE", "BB", "SA", "NE", "BB", "SA", "NE", "BB", "SA",
             "NE", "BB", "SA", "NE", "BB", "SA", "NE"),
     Effekt = c("Neu",
                "Neu", "Neu", "Neu", "Neu", "Neu", "Neu", "Neu", "Neu", 
"Neu",
                "Neu", "Neu", "Neu", "Neu", "Neu", "Neu", "Neu", "Neu", 
"Pos",
                "Pos", "Pos", "Pos", "Pos", "Pos", "Pos", "Pos", "Pos", 
"Pos",
                "Pos", "Pos", "Pos", "Pos", "Pos", "Pos", "Pos", "Pos"),
     Wert = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 3L, 1L, 1L,
              0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 2L, 1L, 0L, 0L, 1L, 0L,
              9L, 4L, 6L, 0L, 0L, 3L, 0L, 0L, 4L)),
     row.names = c(NA, -36L), class = "data.frame")


library(ggplot2)

# First y axis (0-9)
# Second y axis (0-2500)
# fac <- diff(range( sec axis ))/diff(range( 1st axis ))
fac <- diff(range(0, 2500))/diff(range(0, 9))

ggplot(Fig2b, aes(Aspekt, Wert, fill = Effekt)) +
   geom_col(position = position_dodge()) +
   scale_y_continuous(
     breaks = seq(0, 12, 2L),
     sec.axis = sec_axis(~ . * fac)
   ) +
   labs(x = "", y = "Anzahl Studien pro Effekt")




[1] https://stat.ethz.ch/pipermail/r-help/2023-November/478605.html

Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From r@due@|ng @end|ng |rom uo@@de  Mon Nov 27 13:42:25 2023
From: r@due@|ng @end|ng |rom uo@@de (=?UTF-8?B?RHIuIFJhaW5lciBEw7xzaW5n?=)
Date: Mon, 27 Nov 2023 13:42:25 +0100
Subject: [R] t.test with Welch correction is ambiguous
Message-ID: <CAKW_7ZRsTBk=BeUMXn0-C3ij0LX+=SyCeo2gKemmFHKAu2vY2g@mail.gmail.com>

Dear R Team!



There was an ongoing debate on Research Gate about the ?Welch? option in
your base R t.test command. A user noticed that the correction of the
degrees of freedom labeled as ?Welch Two Sample t-test?, if you choose
var.equal
= TRUE in the R t.test command, differs from the output of the Stata
analysis, which is also labeled as ?Welch's degrees of freedom?.  Confusingly
enough, the R output coincided with the Stata result labeled as
?Satterthwaite's
degrees of freedom?. Unfortunately, the R documentation wasn?t clear
either, since it lacks any specific reference and the formulation is
ambiguous: ?If TRUE then the pooled variance is used to estimate the
variance otherwise the Welch (or Satterthwaite) approximation to the
degrees of freedom is used." It rather sounds as if both options are
available and not that both authors proposed the same correction separately.

After doing some research and looking into the R code, we found a solution
and would like to suggest an update to the R documentation, to make it more
clear (you can find the similar proposal to the Stata list here:
https://www.statalist.org/forums/forum/general-stata-discussion/general/1734987-unequal-vs-welch-options-for-ttest-why-no-mention-of-welch-1938-in-the-documentation
)

What is called ?Welch Two Sample t-test? in the t.test command refers to
two publications (see links below) with the same correction, namely Welch
(1938) and Satterthwaite (1946). Hence, you also find "Welch?Satterthwaite"
correction as a description in the literature for this (which is the
aforementioned ?Satterthwaite's degrees of freedom? correction in Stata).
But there is also another correction proposed by Welch (1947), which has
slightly different denominators (see code below), which is called ?Welch's
degrees of freedom? in Stata. This option is not available in R so far.

Therefore, we suggest a) to cite the appropriate references in the
documentation (at least Welch (1938) and Satterthwaite (1946)), b) adapt
the output to something like ?Welch-Satterthwaite adjusted Two Sample
t-test? and maybe c) to incorporate the third option for the Welch (1947)
adjustment, where the Welch-Satterthwaite correction should be the default
option (Aspin & Welch, 1949). Code proposal below for the df correction.

Best wishes,
Rainer D?sing



   1. ?  https://www.jstor.org/stable/2332010
   <https://www.researchgate.net/deref/https%3A%2F%2Fwww.jstor.org%2Fstable%2F2332010?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InF1ZXN0aW9uIiwicGFnZSI6InF1ZXN0aW9uIiwicG9zaXRpb24iOiJwYWdlQ29udGVudCJ9fQ>
   (Welch, 1938)
   2. ?  https://www.jstor.org/stable/3002019
   <https://www.researchgate.net/deref/https%3A%2F%2Fwww.jstor.org%2Fstable%2F3002019?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InF1ZXN0aW9uIiwicGFnZSI6InF1ZXN0aW9uIiwicG9zaXRpb24iOiJwYWdlQ29udGVudCJ9fQ>
   (Satterthwaite, 1946)
   3. ?  https://www.jstor.org/stable/2332510
   <https://www.researchgate.net/deref/https%3A%2F%2Fwww.jstor.org%2Fstable%2F2332510?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InF1ZXN0aW9uIiwicGFnZSI6InF1ZXN0aW9uIiwicG9zaXRpb24iOiJwYWdlQ29udGVudCJ9fQ>
   (Welch, 1947)
   4. ?  Aspin, Alice A., and B. L. Welch. ?Tables for Use in Comparisons
   Whose Accuracy Involves Two Variances, Separately Estimated.?
   *Biometrika* 36, no. 3/4 (1949): 290?96. https://doi.org/10.2307/2332668
   <https://www.researchgate.net/deref/https%3A%2F%2Fdoi.org%2F10.2307%2F2332668?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InF1ZXN0aW9uIiwicGFnZSI6InF1ZXN0aW9uIiwicG9zaXRpb24iOiJwYWdlQ29udGVudCJ9fQ>.
   [see point 4 in the Appendix by Welch]



var.equal = "yes"

var.equal = "Welch"

var.equal = "W-S"



vx <- var(x)

nx <- length(x)

vy <- var(y)

ny <- length(y)



if (var.equal == "yes") {

  df <- nx + ny - 2

  v <- 0

  if (nx > 1)

    v <- v + (nx - 1) * vx

  if (ny > 1)

    v <- v + (ny - 1) * vy

  v <- v/df

  stderr <- sqrt(v * (1/nx + 1/ny))

} else if (var.equal == "Welch") {

  stderrx <- sqrt(vx/nx)

  stderry <- sqrt(vy/ny)

  stderr <- sqrt(stderrx^2 + stderry^2)

  df <- -2+(stderr^4/(stderrx^4/(nx + 1) + stderry^4/(ny +1)))

} else {

  stderrx <- sqrt(vx/nx)

  stderry <- sqrt(vy/ny)

  stderr <- sqrt(stderrx^2 + stderry^2)

  df <- stderr^4/(stderrx^4/(nx - 1) + stderry^4/(ny -1))

}


-- 
*Dr. rer. nat. Rainer D?sing, Dipl.-Psych. *
Universit?t Osnabr?ck
Institut f?r Psychologie
Fachgebiet Forschungsmethodik, Diagnostik und Evaluation
Lise-Meitner-Str. 3
49076 Osnabr?ck

Raum 75/222
Tel: +49-541 969 7734
Email: raduesing at uos.de <rduesing at uos.de>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Mon Nov 27 16:22:03 2023
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Mon, 27 Nov 2023 15:22:03 +0000
Subject: [R] t.test with Welch correction is ambiguous
In-Reply-To: <CAKW_7ZRsTBk=BeUMXn0-C3ij0LX+=SyCeo2gKemmFHKAu2vY2g@mail.gmail.com>
References: <CAKW_7ZRsTBk=BeUMXn0-C3ij0LX+=SyCeo2gKemmFHKAu2vY2g@mail.gmail.com>
Message-ID: <CH3PR22MB451412C1D50355C6DC3C3A28CFBDA@CH3PR22MB4514.namprd22.prod.outlook.com>

Your solution was educational. Thank you. I have two comments.
1) If you do not provide both options then you are forcing people to conform to your approach. In general I disapprove, but for specific cases I can see advantages.
2) Without reading the relevant papers (and possibly understanding them) is there a simple metric that would enable the correct choice between Welch-Shatterthwaite and Welch (1947)?
3) If there is a broad consensus that Welch (1947) is never the correct option then do not implement it.

As written, it sounds like Welch (1938) proposed a correction. Welch published another correction in 1947, but then retracted his 1947 correction in a 1949 paper. At least that is how I interpret what was written in your option c.

Tim
-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Dr. Rainer D?sing
Sent: Monday, November 27, 2023 7:42 AM
To: r-help at r-project.org
Subject: [R] t.test with Welch correction is ambiguous

[External Email]

Dear R Team!



There was an ongoing debate on Research Gate about the "Welch" option in your base R t.test command. A user noticed that the correction of the degrees of freedom labeled as "Welch Two Sample t-test", if you choose var.equal = TRUE in the R t.test command, differs from the output of the Stata analysis, which is also labeled as "Welch's degrees of freedom".  Confusingly enough, the R output coincided with the Stata result labeled as "Satterthwaite's degrees of freedom". Unfortunately, the R documentation wasn't clear either, since it lacks any specific reference and the formulation is
ambiguous: "If TRUE then the pooled variance is used to estimate the variance otherwise the Welch (or Satterthwaite) approximation to the degrees of freedom is used." It rather sounds as if both options are available and not that both authors proposed the same correction separately.

After doing some research and looking into the R code, we found a solution and would like to suggest an update to the R documentation, to make it more clear (you can find the similar proposal to the Stata list here:
https://www.statalist.org/forums/forum/general-stata-discussion/general/1734987-unequal-vs-welch-options-for-ttest-why-no-mention-of-welch-1938-in-the-documentation
)

What is called "Welch Two Sample t-test" in the t.test command refers to two publications (see links below) with the same correction, namely Welch
(1938) and Satterthwaite (1946). Hence, you also find "Welch-Satterthwaite"
correction as a description in the literature for this (which is the aforementioned "Satterthwaite's degrees of freedom" correction in Stata).
But there is also another correction proposed by Welch (1947), which has slightly different denominators (see code below), which is called "Welch's degrees of freedom" in Stata. This option is not available in R so far.

Therefore, we suggest a) to cite the appropriate references in the documentation (at least Welch (1938) and Satterthwaite (1946)), b) adapt the output to something like "Welch-Satterthwaite adjusted Two Sample t-test" and maybe c) to incorporate the third option for the Welch (1947) adjustment, where the Welch-Satterthwaite correction should be the default option (Aspin & Welch, 1949). Code proposal below for the df correction.

Best wishes,
Rainer D?sing



   1. ?  https://www.jstor.org/stable/2332010
   <https://www.researchgate.net/deref/https%3A%2F%2Fwww.jstor.org%2Fstable%2F2332010?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InF1ZXN0aW9uIiwicGFnZSI6InF1ZXN0aW9uIiwicG9zaXRpb24iOiJwYWdlQ29udGVudCJ9fQ>
   (Welch, 1938)
   2. ?  https://www.jstor.org/stable/3002019
   <https://www.researchgate.net/deref/https%3A%2F%2Fwww.jstor.org%2Fstable%2F3002019?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InF1ZXN0aW9uIiwicGFnZSI6InF1ZXN0aW9uIiwicG9zaXRpb24iOiJwYWdlQ29udGVudCJ9fQ>
   (Satterthwaite, 1946)
   3. ?  https://www.jstor.org/stable/2332510
   <https://www.researchgate.net/deref/https%3A%2F%2Fwww.jstor.org%2Fstable%2F2332510?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InF1ZXN0aW9uIiwicGFnZSI6InF1ZXN0aW9uIiwicG9zaXRpb24iOiJwYWdlQ29udGVudCJ9fQ>
   (Welch, 1947)
   4. ?  Aspin, Alice A., and B. L. Welch. "Tables for Use in Comparisons
   Whose Accuracy Involves Two Variances, Separately Estimated."
   *Biometrika* 36, no. 3/4 (1949): 290-96. https://doi.org/10.2307/2332668
   <https://www.researchgate.net/deref/https%3A%2F%2Fdoi.org%2F10.2307%2F2332668?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InF1ZXN0aW9uIiwicGFnZSI6InF1ZXN0aW9uIiwicG9zaXRpb24iOiJwYWdlQ29udGVudCJ9fQ>.
   [see point 4 in the Appendix by Welch]



var.equal = "yes"

var.equal = "Welch"

var.equal = "W-S"



vx <- var(x)

nx <- length(x)

vy <- var(y)

ny <- length(y)



if (var.equal == "yes") {

  df <- nx + ny - 2

  v <- 0

  if (nx > 1)

    v <- v + (nx - 1) * vx

  if (ny > 1)

    v <- v + (ny - 1) * vy

  v <- v/df

  stderr <- sqrt(v * (1/nx + 1/ny))

} else if (var.equal == "Welch") {

  stderrx <- sqrt(vx/nx)

  stderry <- sqrt(vy/ny)

  stderr <- sqrt(stderrx^2 + stderry^2)

  df <- -2+(stderr^4/(stderrx^4/(nx + 1) + stderry^4/(ny +1)))

} else {

  stderrx <- sqrt(vx/nx)

  stderry <- sqrt(vy/ny)

  stderr <- sqrt(stderrx^2 + stderry^2)

  df <- stderr^4/(stderrx^4/(nx - 1) + stderry^4/(ny -1))

}


--
*Dr. rer. nat. Rainer D?sing, Dipl.-Psych. * Universit?t Osnabr?ck Institut f?r Psychologie Fachgebiet Forschungsmethodik, Diagnostik und Evaluation Lise-Meitner-Str. 3
49076 Osnabr?ck

Raum 75/222
Tel: +49-541 969 7734
Email: raduesing at uos.de <rduesing at uos.de>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Tue Nov 28 02:55:30 2023
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Tue, 28 Nov 2023 14:55:30 +1300
Subject: [R] Problems when trying to visualize clusters
In-Reply-To: <CAMOcQfODCjiR9Ms35pUiqpieo8ru8roWCfBW4C+UUWbp83+wqQ@mail.gmail.com>
References: <CAMOcQfODCjiR9Ms35pUiqpieo8ru8roWCfBW4C+UUWbp83+wqQ@mail.gmail.com>
Message-ID: <09d8c69d-fa38-4de7-8f71-b145fd8e3b0b@stat.auckland.ac.nz>

Hi

Looks like you have misspelled the 'vars'.
Does this work ... ?

plot(kclustalgo, vars = c("Toll","Transits"))

Paul

On 17/11/23 06:10, Paul Bernal wrote:
> install.packages("clustMixType")
> install.packages("factoextra")
> install.packages("NbClust")
> 
> This is my R code:
> #Reading Required Datasets
> df = as.data.frame(read_excel("dataforclustering.xlsx"))
> df2 = df[,-1]
> head(df2)
> scaled_df = scale(df2)
> 
> #This part was to determine the optimal number of clusters
> # Elbow method
> fviz_nbclust(scaled_df, kmeans, method = "wss") +
> geom_vline(xintercept = 4, linetype = 2)+
> labs(subtitle = "Elbow method")
> 
> # Silhouette method
> fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
> labs(subtitle = "Silhouette method")
> 
> # Gap statistic
> # nboot = 50 to keep the function speedy.
> # recommended value: nboot= 500 for your analysis.
> # Use verbose = FALSE to hide computing progression.
> set.seed(123)
> fviz_nbclust(scaled_df, kmeans, nstart = 25, method = "gap_stat", nboot =
> 50)+
> labs(subtitle = "Gap statistic method")
> 
> Based on the elbow method, which suggested k = 4, I then used the following
> code to produce the clusters and try to plot them:
> 
> df$MarketSegment <- as.factor(df$MarketSegment)
> 
> #kproto comes from the clustMixType package
> kclustalgo = kproto(df,4)
> summary(kclustalgo)
> plot(kclustalgo, vars = c("tolls","transits"))
> 
> The problem is that, when using the plot function, it does not generate
> anything, it does not plot anything.
> 
> Below my dataset:
> structure(list(MarketSegment = structure(c(12L, 8L, 4L, 5L, 8L,
> 8L, 9L, 2L, 8L, 11L, 11L, 12L, 5L, 4L, 10L, 10L, 9L, 11L, 5L,
> 10L, 10L, 9L, 9L, 9L, 4L, 11L, 10L, 9L, 11L, 4L, 7L, 1L, 2L,
> 7L, 4L, 6L, 4L, 5L, 4L, 6L, 5L, 11L, 10L, 9L, 8L, 11L, 2L, 4L,
> 5L, 12L, 10L, 5L, 4L, 5L, 10L, 10L, 11L, 2L, 12L, 5L, 10L, 8L,
> 8L, 2L, 8L, 13L, 6L, 7L, 4L, 10L, 8L, 3L, 5L, 2L, 7L, 13L, 5L,
> 5L, 2L, 12L, 4L, 5L, 5L, 12L, 10L, 5L, 11L, 9L, 4L, 2L, 4L, 2L,
> 9L, 5L, 11L, 10L, 4L, 11L, 12L, 9L, 11L, 10L, 4L, 13L, 4L, 2L,
> 4L, 5L, 6L, 13L, 2L, 5L, 10L, 3L, 13L, 8L, 11L, 9L, 8L, 10L,
> 4L, 2L, 11L, 2L, 9L, 4L, 12L, 10L, 8L, 12L, 8L, 10L, 11L, 2L,
> 8L, 4L, 12L, 9L, 8L, 8L, 11L, 11L, 2L, 9L, 10L, 8L, 12L, 2L,
> 11L, 8L, 11L, 4L, 2L, 3L, 3L, 8L, 13L, 5L, 5L, 6L, 6L, 2L, 9L,
> 10L, 2L, 7L, 6L, 2L, 1L, 7L, 6L, 13L, 1L, 2L, 4L, 5L, 12L, 9L,
> 11L, 9L, 8L, 2L, 9L, 9L, 5L, 11L, 2L, 12L, 2L, 8L, 12L, 4L, 5L,
> 4L, 10L, 2L, 9L, 2L, 2L, 2L, 9L, 11L, 2L, 12L, 2L, 10L, 12L,
> 9L, 4L, 12L, 10L, 5L, 12L, 1L, 6L, 5L, 8L, 10L, 9L, 10L, 4L,
> 7L, 8L, 1L, 9L, 3L, 3L, 1L, 4L, 4L, 2L, 4L, 10L, 11L, 8L, 2L,
> 9L, 2L, 5L, 4L, 12L, 4L, 5L, 4L, 9L, 4L, 4L, 12L, 9L, 2L, 8L,
> 12L, 4L, 3L, 7L, 3L, 10L, 7L, 8L, 2L, 6L, 1L, 3L, 6L, 13L, 7L,
> 13L, 9L, 13L, 8L, 3L, 10L, 10L, 5L, 12L, 9L, 8L, 8L, 11L, 10L,
> 8L, 12L, 8L, 5L, 9L, 4L, 12L, 11L, 4L, 8L, 5L, 10L, 11L, 11L,
> 2L, 12L, 5L, 10L, 9L, 13L, 1L, 7L, 9L, 9L, 10L, 3L, 2L, 1L, 8L,
> 8L, 9L, 10L, 2L, 8L, 13L, 6L, 12L, 4L, 8L, 10L, 9L, 10L, 10L,
> 5L, 11L, 8L, 8L, 4L, 12L, 8L, 12L, 10L, 9L, 12L, 5L, 11L, 2L,
> 5L, 5L, 10L, 5L, 5L, 9L, 9L, 5L, 2L, 9L, 1L, 8L, 13L, 7L, 3L,
> 5L, 1L, 1L, 9L, 10L, 7L, 5L, 3L, 1L, 4L), levels = c("Chemical Tankers",
> "Container", "Crude/Product Tankers", "Dry Bulk", "General Cargo",
> "LNG Carrier", "LPG Carrier", "Others", "Passengers", "Refrigerated",
> "Tankers", "Vehicle Carriers", "Vehicle Carriers/RoRo"), class = "factor"),
> Toll = c(45622373.27, 30399013.74, 176306593.66, 18971118.38,
> 25835490.96, 23740969.7, 22570777.11, 144378273.06, 59115267.47,
> 71971071.4, 94431934.17, 14252216.8, 25040195.72, 92607705.13,
> 17595512.81, 22275409.83, 6291531.04, 51104161.27, 25181172.84,
> 34816907.8, 32777647.65, 7099598.51, 27689930.37, 42046359.26,
> 173706597.74, 143220682.62, 59053229.17, 39369534.57, 157970209.29,
> 411908086.08, 30644932.62, 141530616.2, 1086950201, 222938133.49,
> 347883155.9, 160051827.89, 376203394.59, 44232336.52, 410395911.78,
> 218235220.1, 35274869.37, 73258945.88, 37821693.14, 81193.19,
> 25461445.17, 61671172.38, 64984959.44, 166826321.18, 21076499.39,
> 88337589.73, 46904254.95, 20029152.87, 143083949.3, 21959696.81,
> 52382607.59, 3478831.59, 46284549.62, 48579258.24, 47417137.43,
> 25768369.63, 52765742.89, 60329234.95, 52200921.5, 911170775.2,
> 27854758.26, 188077540.25, 170069.18, 46979713.12, 324994117.34,
> 42136353.11, 12495006.27, 93066248.53, 46588988.04, 1203041643,
> 275586213.06, 224722357.56, 38114431.53, 24457874.42, 224106,
> 52935575.5, 145149052.16, 24254689.17, 21355540.17, 77826892.53,
> 37047616.49, 25895846.03, 81595647.93, 18824145.98, 157687486.69,
> 252355857.97, 23554769.2, 42803289.58, 6970409.95, 25223571.18,
> 44521560.29, 23846694.1, 123861794, 62133036.93, 49025354.84,
> 27761074.11, 93221253.37, 67681581.53, 326040777.37, 0, 353324758.38,
> 914308534.52, 375236325.91, 42896733.54, 18760255.6, 198508135.47,
> 1367150804.75, 42296364.22, 32848434.94, 84984870.35, 209972507.43,
> 131115.79, 636385.07, 15683638.27, 27432524.55, 34767287.97,
> 174026078.65, 91872590.71, 77273064.3, 115418664.65, 24248775.39,
> 184598288.14, 55702797.23, 35938942.48, 37876793.27, 67595978.53,
> 37585563.97, 38058681.79, 70479369.62, 181080995.57, 43367438.62,
> 152817300.67, 99222096.54, 29739623.79, 7027238.12, 25482814.45,
> 52706796.25, 44227271.88, 49125255.46, 7273684.04, 31550474.77,
> 45171138.63, 113147627.59, 736129089, 118847881.44, 48827559.85,
> 175552816, 231472438.57, 972466186.8, 20939505.12, 74784961.28,
> 22048526.85, 184182792.62, 50043224.13, 46567864.3, 64096942.63,
> 133561525.43, 1184603445, 27481529.81, 35823758.59, 1241926985.25,
> 336005108, 175196241.59, 1417836913.5, 219080343.22, 447793583.34,
> 142244858.6, 211282556.89, 282402337.27, 73904457.86, 213236.53,
> 23845925.9, 47069774.11, 17091622.26, 77288315.4, 20367261.33,
> 58398395.39, 230933373.58, 26598884.35, 2406557.1, 6480102,
> 13628284.31, 10263514.77, 66291278.83, 45203889.46, 24439458.61,
> 62995994.42, 103545550.11, 23582006.69, 106841255.81, 30920698.81,
> 57152783.67, 6788655.31, 58688264.46, 63623458.42, 381280927.57,
> 26160209.37, 94398586.99, 548546815.6, 94377076.67, 660333530.6,
> 58467965.42, 121250943.68, 39897634.25, 253784215.75, 123264396,
> 58788870.55, 41450428.73, 116407322.67, 37073625.53, 80949.5,
> 46479259.97, 17935104.29, 44743486.45, 50354870.76, 45978813.8,
> 381104737.29, 144588856.56, 13453753.84, 215589051.87, 14640417.36,
> 113367165.56, 100614565.26, 270041980.52, 436045596.44, 399693615.37,
> 80310709.08, 178202292.6, 37426161.19, 84501310.47, 35095993.84,
> 115887420.17, 25320445.08, 131720569.81, 20152178.46, 98738563.37,
> 52761092.05, 126078172.3, 24618706.25, 136326542.07, 11518860.78,
> 156025722.98, 170794953.78, 105383146.32, 33742975.52, 786732496.2,
> 44558463.25, 138272099.98, 332758968.08, 73351527.91, 3711095.76,
> 0, 49843621.55, 22795131.65, 23624194.51, 960690603.6, 0,
> 174697284.22, 75560763.05, 231180, 196673683.99, 190737686.99,
> 213184850.38, 43204339.22, 175208475.3, 14294438.32, 105373950.72,
> 34354378.94, 36201953.3, 152644.76, 4271.52, 21467521.11,
> 24714178.25, 23397907.04, 84318567.96, 41391735.09, 59207931.58,
> 96631125.37, 26119366.87, 24050681.28, 6414468.87, 115073972.91,
> 48806783.58, 53117026.48, 143925878.71, 54427083.34, 29621363.6,
> 67914181.91, 208255468.52, 172563091.58, 783130968, 87885643.22,
> 33623583.6, 49862226.49, 39581084.06, 47338366.37, 0, 0,
> 42059174.7, 55196029.54, 45573526.31, 77542558.18, 948435917.2,
> 184766344.51, 11715869.41, 11465772.13, 58348554.79, 34159529.23,
> 1324615521.7, 14214065.75, 204448377.38, 133199367.48, 48301726.87,
> 171342164.62, 27932981.26, 204453.32, 13799161.85, 36545009.39,
> 40127237.59, 24856336.87, 81983152.36, 27475201.4, 40720204.5,
> 143732024.58, 81736659.41, 54145665.75, 63195468.9, 17990069.83,
> 7063003.98, 53943424.6, 27336061.94, 49141786, 56875952.23,
> 25301093.8, 21993181.36, 52955818.55, 25793889.09, 28102485.94,
> 39856771.5, 45181483.95, 42949296.26, 931539910.4, 34918600.8,
> 134194366.11, 20115045.15, 203545729.19, 68836834.76, 85618322.31,
> 41411914.83, 203629971.2, 200898608.18, 44469248.2, 35518487.49,
> 326654852.92, 38518260.2, 99286360.37, 231011004.03, 368789029.42
> ), Transits = c(557, 2932, 3312, 1015, 3037, 2958, 257, 1797,
> 2812, 1615, 1912, 251, 1836, 2861, 1592, 1908, 149, 1656,
> 1596, 2613, 2409, 159, 205, 235, 2472, 2079, 1631, 202, 1838,
> 3356, 298, 1489, 2493, 1148, 2614, 421, 2758, 651, 2925,
> 519, 453, 2187, 2568, 2799, 2705, 1928, 1187, 3042, 968,
> 789, 2216, 817, 2380, 882, 2371, 324, 1667, 1120, 646, 819,
> 2108, 2737, 2586, 3255, 2210, 796, 4, 440, 2610, 838, 1217,
> 667, 675, 2615, 1349, 886, 556, 1514, 37622, 665, 3431, 1537,
> 1075, 721, 1997, 1333, 2081, 217, 2579, 2534, 703, 992, 226,
> 1771, 1591, 1963, 3306, 1943, 611, 224, 1707, 2151, 3288,
> 2510, 3081, 2892, 3075, 678, 58, 798, 2642, 616, 566, 413,
> 691, 22076, 9415, 300, 2881, 2309, 3613, 1428, 1940, 1691,
> 310, 3549, 561, 2021, 3071, 645, 2641, 2085, 1704, 2126,
> 2668, 2851, 792, 243, 682, 2881, 1810, 1615, 1043, 170, 2140,
> 2615, 833, 3524, 2027, 2497, 2342, 2982, 3326, 181, 596,
> 1986, 787, 878, 813, 181, 340, 2616, 127, 746, 2537, 1526,
> 425, 2843, 1987, 1552, 343, 782, 1850, 1334, 8088, 1431,
> 509, 283, 2216, 228, 2625, 2451, 225, 75, 485, 472, 237,
> 1091, 1069, 2785, 973, 3092, 1597, 3134, 2279, 1093, 155,
> 1131, 1174, 3020, 221, 1744, 3419, 728, 3604, 2199, 765,
> 215, 3033, 632, 1453, 926, 504, 431, 2, 913, 2001, 992, 265,
> 954, 2904, 929, 1696, 2114, 53, 783, 628, 2362, 3004, 2781,
> 1391, 3939, 2031, 2207, 2653, 1597, 299, 1749, 1061, 3019,
> 731, 3206, 1558, 3275, 233, 2598, 2752, 810, 248, 3235, 2455,
> 618, 3220, 647, 51, 3611, 1069, 240, 2086, 3132, 2975, 1799,
> 610, 3, 802, 1027, 844, 170, 650, 1314, 631, 601, 459, 8494,
> 1803, 297, 2909, 2941, 2129, 2172, 2643, 807, 2893, 1767,
> 214, 3109, 676, 1804, 2346, 2692, 856, 1912, 2404, 2264,
> 3094, 448, 900, 1088, 214, 202, 4921, 3567, 229, 249, 968,
> 621, 2824, 1886, 1989, 2034, 265, 590, 2425, 1521, 762, 272,
> 600, 3928, 2811, 5552, 308, 2474, 2442, 1379, 2280, 2897,
> 2794, 2611, 761, 2795, 1110, 1623, 209, 810, 1681, 1642,
> 1092, 1677, 825, 2246, 779, 816, 226, 214, 908, 3010, 204,
> 1503, 1944, 849, 538, 666, 636, 2019, 1994, 196, 665, 1552,
> 559, 569, 2048, 2170)), row.names = c(NA, -362L), class = "data.frame")

-- 
Dr Paul Murrell
Te Kura Tatauranga | Department of Statistics
Waipapa Taumata Rau | The University of Auckland
Private Bag 92019, Auckland 1142, New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
www.stat.auckland.ac.nz/~paul/


From konr@d_kr@emer @end|ng |rom y@hoo@de  Tue Nov 28 11:03:36 2023
From: konr@d_kr@emer @end|ng |rom y@hoo@de (Konrad)
Date: Tue, 28 Nov 2023 11:03:36 +0100
Subject: [R] computer algebra in R
References: <84832852-1840-4ed9-92e9-82cacbb155f6.ref@yahoo.de>
Message-ID: <84832852-1840-4ed9-92e9-82cacbb155f6@yahoo.de>

Dear all,

I'm currently working on converting mathematica code 
(https://github.com/ASDSE/thermosimfit/blob/master/Packages/thermoHD-Comp/thermoCacheHD-1Comp.m) 
to R. The code is related to solve algebraic systems.

> eqthermo = {h0 == h + hd + hga, d0 == d + hd, ga0 == ga + hga, kga ==
> ???? hga / (h * ga), kd == hd / (h * d)};
>
> (* IDA HD*)
> sthdIDAcacheHD[fkd_, fkga_, fh0_, fd0_] :=? sthdIDAcacheHD[fkd, fkga, 
> fh0, fd0] =
> ?? ??? ?? ??? ?Module[{eliHD, solvHD},
> ?? ??? ??? ??? ?eliHD =
> ?? ??? ????? Eliminate[
> ?? ??? ?????? eqthermo /. {d0 -> fd0, h0 -> fh0, kd -> fkd, kga -> 
> fkga}, {h, d, hga, ga}];
> ?? ??? ??? ??? ?solvHD = hd /. NSolve[eliHD, hd];
> ?? ??? ??? ??? ?Return[solvHD];
> ?? ??? ??? ??? ?];

 ?I tried to use the Ryacas package. However, I'm struggling with the 
Elimination step. Within this step a system of equations:

0.3==h+hd+hga,0.4==d+hd,ga0==ga+hga,0.2==hga/(ga h),0.1==hd/(d h) is 
transformed to: -12.+1040. hd+2575. hd^2-250. hd^3==ga0 hd (-200.+500. hd).

My question is whether someone has experience with yacas and can tell me 
how to do this step in R. Beyond that, I would be grateful for every 
hint how to transfer this into R.

All the best,

Konrad


From @orenh @end|ng |rom m@th@@@u@dk  Tue Nov 28 19:37:03 2023
From: @orenh @end|ng |rom m@th@@@u@dk (=?utf-8?B?U8O4cmVuIEjDuGpzZ2FhcmQ=?=)
Date: Tue, 28 Nov 2023 18:37:03 +0000
Subject: [R] computer algebra in R
In-Reply-To: <84832852-1840-4ed9-92e9-82cacbb155f6@yahoo.de>
References: <84832852-1840-4ed9-92e9-82cacbb155f6.ref@yahoo.de>
 <84832852-1840-4ed9-92e9-82cacbb155f6@yahoo.de>
Message-ID: <85691f0cea5e489e793d9cdab7049eae6ee29bf5.camel@math.aau.dk>

Just wanted to mention that the caracas package *may* be better at solving this problem
Best
S?ren

-----Original Message-----
From: Konrad via R-help <r-help at r-project.org>
Reply-To: Konrad <konrad_kraemer at yahoo.de>
To: R-help at r-project.org
Subject: [R] computer algebra in R
Date: Tue, 28 Nov 2023 11:03:36 +0100

Dear all,

I'm currently working on converting mathematica code 
(https://github.com/ASDSE/thermosimfit/blob/master/Packages/thermoHD-Comp/thermoCacheHD-1Comp.m) 
to R. The code is related to solve algebraic systems.

> eqthermo = {h0 == h + hd + hga, d0 == d + hd, ga0 == ga + hga, kga ==
> ???? hga / (h * ga), kd == hd / (h * d)};
> 
> (* IDA HD*)
> sthdIDAcacheHD[fkd_, fkga_, fh0_, fd0_] :=? sthdIDAcacheHD[fkd, fkga, 
> fh0, fd0] =
> ?? ??? ?? ??? ?Module[{eliHD, solvHD},
> ?? ??? ??? ??? ?eliHD =
> ?? ??? ????? Eliminate[
> ?? ??? ?????? eqthermo /. {d0 -> fd0, h0 -> fh0, kd -> fkd, kga -> 
> fkga}, {h, d, hga, ga}];
> ?? ??? ??? ??? ?solvHD = hd /. NSolve[eliHD, hd];
> ?? ??? ??? ??? ?Return[solvHD];
> ?? ??? ??? ??? ?];

??I tried to use the Ryacas package. However, I'm struggling with the 
Elimination step. Within this step a system of equations:

0.3==h+hd+hga,0.4==d+hd,ga0==ga+hga,0.2==hga/(ga h),0.1==hd/(d h) is 
transformed to: -12.+1040. hd+2575. hd^2-250. hd^3==ga0 hd (-200.+500. hd).

My question is whether someone has experience with yacas and can tell me 
how to do this step in R. Beyond that, I would be grateful for every 
hint how to transfer this into R.

All the best,

Konrad

______________________________________________
R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
S?ren H?jsgaard
Head of Department of Mathematical Sciences
Aalborg University, Denmark.
Chair of the Danish Statistical Society


From ||v|ob @end|ng |rom ||ve@com  Wed Nov 29 01:29:49 2023
From: ||v|ob @end|ng |rom ||ve@com (Livio Beqiri)
Date: Wed, 29 Nov 2023 00:29:49 +0000
Subject: [R] Barplot for data frame
Message-ID: <PR3P250MB017749DB9B7C0A2AD207BE04B483A@PR3P250MB0177.EURP250.PROD.OUTLOOK.COM>

I have a dataframe df <-

df <- data.frame (Revenue = c("100", "300", "500"),
                  Brand = c("Apple", "HP", "Lenovo")
                  )


how can i create a vertical barplot that displays brands in x-axis and Revenue in Y-axis



	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Wed Nov 29 10:16:04 2023
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Wed, 29 Nov 2023 11:16:04 +0200
Subject: [R] Barplot for data frame
In-Reply-To: <PR3P250MB017749DB9B7C0A2AD207BE04B483A@PR3P250MB0177.EURP250.PROD.OUTLOOK.COM>
References: <PR3P250MB017749DB9B7C0A2AD207BE04B483A@PR3P250MB0177.EURP250.PROD.OUTLOOK.COM>
Message-ID: <uk6vgk$okp$1@ciao.gmane.io>

Look like homework to me :-)-O

el

On 2023-11-29 02:29 , Livio Beqiri wrote:
> I have a dataframe df <-
> 
> df <- data.frame (Revenue = c("100", "300", "500"),
>                    Brand = c("Apple", "HP", "Lenovo")
>                    )
> 
> 
> how can i create a vertical barplot that displays brands in x-axis and Revenue in Y-axis
> 
> 
> 
> 	[[alternative HTML version deleted]]
>


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Nov 29 10:25:08 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 29 Nov 2023 12:25:08 +0300
Subject: [R] Barplot for data frame
In-Reply-To: <PR3P250MB017749DB9B7C0A2AD207BE04B483A@PR3P250MB0177.EURP250.PROD.OUTLOOK.COM>
References: <PR3P250MB017749DB9B7C0A2AD207BE04B483A@PR3P250MB0177.EURP250.PROD.OUTLOOK.COM>
Message-ID: <20231129122508.546451fc@arachnoid>

? Wed, 29 Nov 2023 00:29:49 +0000
Livio Beqiri <liviob at live.com> ?????:

> how can i create a vertical barplot that displays brands in x-axis
> and Revenue in Y-axis

What have you tried? If you're not currently studying R with an
instructor (who should be contacted with basic questions like this
instead; see the posting guide at [1]), I can recommend a free book by
A. Shipunov [2] to give you the basic R knowledge.

> df <- data.frame (Revenue = c("100", "300", "500"),
>                   Brand = c("Apple", "HP", "Lenovo")
>                   )

My psychic debugging powers tell me that you're getting an error
complaining about the wrong argument type. If that's the case, you
should either avoid quoting your numbers (i.e. say 100 instead of
"100") or transform the character vector into a vector of numbers using
as.numeric().

Either way, it's best to show your work and your error messages because
the psychic debugging powers don't always work properly.

-- 
Best regards,
Ivan

[1]
https://www.r-project.org/posting-guide.html

[2]
https://web.archive.org/web/20230501112111/http://ashipunov.info/shipunov/school/biol_240/en/visual_statistics.pdf


From |eo@m@d@ @end|ng |rom @yon|c@eu  Wed Nov 29 12:53:42 2023
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Wed, 29 Nov 2023 11:53:42 +0000
Subject: [R] computer algebra in R
Message-ID: <AM5P192MB0082552781ABCBC64B9C22CE8483A@AM5P192MB0082.EURP192.PROD.OUTLOOK.COM>

Dear Konrad,

I presume that the system can be written as follows, where h0, d0, ga0, kga and kd are given:

err1 = h + hd + hga - h0;
err2 = d + hd - d0;
err3 = ga + hga - ga0;
err4 = hga - kga*h*ga;
err5 = hd - kd*h*d;

All error terms should be zero.

Do you need (a) the symbolic solution or (b) is a numeric solution fine?

I do not have any experience with yacas or caracas. But see below.

### Case (a)
I did write a (very rudimentary) symbolic solver for systems of polynomial equations in pure R. It should be able to solve this one. Please let me know if this is of interest and I will provide further details.

### Case (b)
Again, it should be possible to solve, see some examples:
https://github.com/discoleo/R/blob/master/Math/Systems.NLE.Tutorial.md
https://github.com/discoleo/R/blob/master/Math/Systems.Lambert.R
I did solve much more complex ones, for a monster see:
https://github.com/discoleo/R/blob/master/Math/Poly.System.S5.Ht.Formulas.Derivation.HS0.R
[and the remaining Poly.System.S5.Ht... scripts]

I presume that only the real roots are required (it's possible to solve systems with complex roots as well). I can provide further details as well.

Sincerely,

Leonard


	[[alternative HTML version deleted]]


From btupper @end|ng |rom b|ge|ow@org  Wed Nov 29 14:44:30 2023
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Wed, 29 Nov 2023 08:44:30 -0500
Subject: [R] Barplot for data frame
In-Reply-To: <20231129122508.546451fc@arachnoid>
References: <PR3P250MB017749DB9B7C0A2AD207BE04B483A@PR3P250MB0177.EURP250.PROD.OUTLOOK.COM>
 <20231129122508.546451fc@arachnoid>
Message-ID: <CALrbzg2CGN8GXWpy28+CSSxs9LtsPyw-=0He+YE63bT3tBTBsg@mail.gmail.com>

Another great resource is RSeek.org  https://rseek.org/?q=barplot

On Wed, Nov 29, 2023 at 4:26?AM Ivan Krylov <krylov.r00t at gmail.com> wrote:

> ? Wed, 29 Nov 2023 00:29:49 +0000
> Livio Beqiri <liviob at live.com> ?????:
>
> > how can i create a vertical barplot that displays brands in x-axis
> > and Revenue in Y-axis
>
> What have you tried? If you're not currently studying R with an
> instructor (who should be contacted with basic questions like this
> instead; see the posting guide at [1]), I can recommend a free book by
> A. Shipunov [2] to give you the basic R knowledge.
>
> > df <- data.frame (Revenue = c("100", "300", "500"),
> >                   Brand = c("Apple", "HP", "Lenovo")
> >                   )
>
> My psychic debugging powers tell me that you're getting an error
> complaining about the wrong argument type. If that's the case, you
> should either avoid quoting your numbers (i.e. say 100 instead of
> "100") or transform the character vector into a vector of numbers using
> as.numeric().
>
> Either way, it's best to show your work and your error messages because
> the psychic debugging powers don't always work properly.
>
> --
> Best regards,
> Ivan
>
> [1]
> https://www.r-project.org/posting-guide.html
>
> [2]
>
> https://web.archive.org/web/20230501112111/http://ashipunov.info/shipunov/school/biol_240/en/visual_statistics.pdf
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Wed Nov 29 16:57:37 2023
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Wed, 29 Nov 2023 21:27:37 +0530
Subject: [R] Code editor for writing R code
Message-ID: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>

Hi,

Currently I use VS-Code to write codes in R. While it is very good, it
does not allow me to write Latex expressions in comments, which I am
willing to have to write corresponding mathematical expressions as
comments in my code files.

Does there exist any Code editor for R, that allows me to write Latex
in comments?

Any information will be appreciated.

Thanks,


From bbo|ker @end|ng |rom gm@||@com  Wed Nov 29 17:14:44 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 29 Nov 2023 11:14:44 -0500
Subject: [R] Code editor for writing R code
In-Reply-To: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>
References: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>
Message-ID: <c8568944-62c8-4dba-a920-93ab9d5d19ce@gmail.com>



   Presumably there's nothing stopping you *writing* LaTeX in comments 
-- do you want a code editor that will render and display the LaTeX as 
you write? (Or am I misunderstanding something?)

   Does anyone do classic literate programming *sensu* Knuth any more? 
https://rpubs.com/bbolker/3153 
https://cran.r-project.org/web/packages/noweb/vignettes/noweb.pdf


On 2023-11-29 10:57 a.m., Christofer Bogaso wrote:
> Hi,
> 
> Currently I use VS-Code to write codes in R. While it is very good, it
> does not allow me to write Latex expressions in comments, which I am
> willing to have to write corresponding mathematical expressions as
> comments in my code files.
> 
> Does there exist any Code editor for R, that allows me to write Latex
> in comments?
> 
> Any information will be appreciated.
> 
> Thanks,
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Wed Nov 29 17:21:01 2023
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 29 Nov 2023 18:21:01 +0200
Subject: [R] Code editor for writing R code
In-Reply-To: <c8568944-62c8-4dba-a920-93ab9d5d19ce@gmail.com>
References: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>
 <c8568944-62c8-4dba-a920-93ab9d5d19ce@gmail.com>
Message-ID: <CAGgJW74mokLGyARkgP96nn7ymKm-RXDrZnj7peqgDD+yguP7wg@mail.gmail.com>

Another direction would be to replace your R script (.R file) with a
Quarto document (.qmd file).
VS-code has good support for Quarto and you could intersperse your
Latex with R chunks.


On Wed, Nov 29, 2023 at 6:15?PM Ben Bolker <bbolker at gmail.com> wrote:
>
>
>
>    Presumably there's nothing stopping you *writing* LaTeX in comments
> -- do you want a code editor that will render and display the LaTeX as
> you write? (Or am I misunderstanding something?)
>
>    Does anyone do classic literate programming *sensu* Knuth any more?
> https://rpubs.com/bbolker/3153
> https://cran.r-project.org/web/packages/noweb/vignettes/noweb.pdf
>
>
> On 2023-11-29 10:57 a.m., Christofer Bogaso wrote:
> > Hi,
> >
> > Currently I use VS-Code to write codes in R. While it is very good, it
> > does not allow me to write Latex expressions in comments, which I am
> > willing to have to write corresponding mathematical expressions as
> > comments in my code files.
> >
> > Does there exist any Code editor for R, that allows me to write Latex
> > in comments?
> >
> > Any information will be appreciated.
> >
> > Thanks,
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 29 17:21:56 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 29 Nov 2023 08:21:56 -0800
Subject: [R] Code editor for writing R code
In-Reply-To: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>
References: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>
Message-ID: <CAGxFJbSghoyqHBfQPQkfvV90W8_pMRKWyo5_2_2bQ4vUDAnOpg@mail.gmail.com>

I believe RMarkdown can use and render latex comments. RStudio/Posix
provides ide extensions (e.g. R Notebooks) that seem to do what you
want, but I have no experience with them. As Ben suggested, there are
likely others, depending on exactly what you want to do.

-- Bert

On Wed, Nov 29, 2023 at 7:58?AM Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
>
> Hi,
>
> Currently I use VS-Code to write codes in R. While it is very good, it
> does not allow me to write Latex expressions in comments, which I am
> willing to have to write corresponding mathematical expressions as
> comments in my code files.
>
> Does there exist any Code editor for R, that allows me to write Latex
> in comments?
>
> Any information will be appreciated.
>
> Thanks,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 29 17:24:44 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 29 Nov 2023 08:24:44 -0800
Subject: [R] Code editor for writing R code
In-Reply-To: <CAGxFJbSghoyqHBfQPQkfvV90W8_pMRKWyo5_2_2bQ4vUDAnOpg@mail.gmail.com>
References: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>
 <CAGxFJbSghoyqHBfQPQkfvV90W8_pMRKWyo5_2_2bQ4vUDAnOpg@mail.gmail.com>
Message-ID: <CAGxFJbRVHtEcfJxSr209z7Ta5PP+sbsQSn7yoMP73fLNf6Zk+g@mail.gmail.com>

This might be of use to you:

https://everyday.codes/tutorials/how-to-use-latex-in-rmarkdown/

-- Bert

On Wed, Nov 29, 2023 at 8:21?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> I believe RMarkdown can use and render latex comments. RStudio/Posix
> provides ide extensions (e.g. R Notebooks) that seem to do what you
> want, but I have no experience with them. As Ben suggested, there are
> likely others, depending on exactly what you want to do.
>
> -- Bert
>
> On Wed, Nov 29, 2023 at 7:58?AM Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
> >
> > Hi,
> >
> > Currently I use VS-Code to write codes in R. While it is very good, it
> > does not allow me to write Latex expressions in comments, which I am
> > willing to have to write corresponding mathematical expressions as
> > comments in my code files.
> >
> > Does there exist any Code editor for R, that allows me to write Latex
> > in comments?
> >
> > Any information will be appreciated.
> >
> > Thanks,
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Wed Nov 29 17:48:36 2023
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Wed, 29 Nov 2023 22:18:36 +0530
Subject: [R] Code editor for writing R code
In-Reply-To: <8ievvg-p66t8t-ahivx4u900hh-1sai45yfknbi-ncyza7-oww5fw-akx7kp-pmvu60hfqa7r-93zurm-oa2dsb-t9rsl6udlczz75a2a1-puwhkqeuofzh-3ogxja-gkobc8-4v4zhbbdjppi-rn25vk-oy96sg.1701273879447@email.android.com>
References: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>
 <8ievvg-p66t8t-ahivx4u900hh-1sai45yfknbi-ncyza7-oww5fw-akx7kp-pmvu60hfqa7r-93zurm-oa2dsb-t9rsl6udlczz75a2a1-puwhkqeuofzh-3ogxja-gkobc8-4v4zhbbdjppi-rn25vk-oy96sg.1701273879447@email.android.com>
Message-ID: <CA+dpOJkC9aAKD99Gy0h+WDEYm-sVtjKw2Oako1DniUbO=gH9pQ@mail.gmail.com>

Hi Sergei,

Where can I find TeX Comments extension in VS Code?

On Wed, Nov 29, 2023 at 9:34?PM Sergei Ko <sggp.sergei at gmail.com> wrote:
>
> TeX Comments extension in VS Code
>
>
>
>
> Sent from my phone
>
>
> -------- Original message --------
> From: Christofer Bogaso <bogaso.christofer at gmail.com>
> Date: Wed, 29 Nov 2023, 15:57
> To: r-help <r-help at r-project.org>
> Subject: [R] Code editor for writing R code
>
> Hi,
>
> Currently I use VS-Code to write codes in R. While it is very good, it
> does not allow me to write Latex expressions in comments, which I am
> willing to have to write corresponding mathematical expressions as
> comments in my code files.
>
> Does there exist any Code editor for R, that allows me to write Latex
> in comments?
>
> Any information will be appreciated.
>
> Thanks,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Wed Nov 29 19:29:03 2023
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 29 Nov 2023 20:29:03 +0200
Subject: [R] Code editor for writing R code
In-Reply-To: <CA+dpOJkC9aAKD99Gy0h+WDEYm-sVtjKw2Oako1DniUbO=gH9pQ@mail.gmail.com>
References: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>
 <8ievvg-p66t8t-ahivx4u900hh-1sai45yfknbi-ncyza7-oww5fw-akx7kp-pmvu60hfqa7r-93zurm-oa2dsb-t9rsl6udlczz75a2a1-puwhkqeuofzh-3ogxja-gkobc8-4v4zhbbdjppi-rn25vk-oy96sg.1701273879447@email.android.com>
 <CA+dpOJkC9aAKD99Gy0h+WDEYm-sVtjKw2Oako1DniUbO=gH9pQ@mail.gmail.com>
Message-ID: <CAGgJW75W+AGQVcof+TS3_1h_W5wenbemsGiFjo2AM9ws99RPzA@mail.gmail.com>

Bert,
Posit (formerly RStudio) has moved from RMarkdown to Quarto. They
still support RMarkdown but major new features will be in Quarto. For
new users a better choice would be Quarto.
See https://quarto.org/docs/faq/rmarkdown.html

Secondly, the OP stated he was using the VS-Code IDE, so there is no
reason to point him to the Posit/RStudio IDE for this functionality
which VS-Code supports very well (as I noted in my response.)

Best,
Eric

On Wed, Nov 29, 2023 at 6:55?PM Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
>
> Hi Sergei,
>
> Where can I find TeX Comments extension in VS Code?
>
> On Wed, Nov 29, 2023 at 9:34?PM Sergei Ko <sggp.sergei at gmail.com> wrote:
> >
> > TeX Comments extension in VS Code
> >
> >
> >
> >
> > Sent from my phone
> >
> >
> > -------- Original message --------
> > From: Christofer Bogaso <bogaso.christofer at gmail.com>
> > Date: Wed, 29 Nov 2023, 15:57
> > To: r-help <r-help at r-project.org>
> > Subject: [R] Code editor for writing R code
> >
> > Hi,
> >
> > Currently I use VS-Code to write codes in R. While it is very good, it
> > does not allow me to write Latex expressions in comments, which I am
> > willing to have to write corresponding mathematical expressions as
> > comments in my code files.
> >
> > Does there exist any Code editor for R, that allows me to write Latex
> > in comments?
> >
> > Any information will be appreciated.
> >
> > Thanks,
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Nov 29 20:01:32 2023
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 29 Nov 2023 11:01:32 -0800
Subject: [R] Code editor for writing R code
In-Reply-To: <CAGgJW75W+AGQVcof+TS3_1h_W5wenbemsGiFjo2AM9ws99RPzA@mail.gmail.com>
References: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>
 <8ievvg-p66t8t-ahivx4u900hh-1sai45yfknbi-ncyza7-oww5fw-akx7kp-pmvu60hfqa7r-93zurm-oa2dsb-t9rsl6udlczz75a2a1-puwhkqeuofzh-3ogxja-gkobc8-4v4zhbbdjppi-rn25vk-oy96sg.1701273879447@email.android.com>
 <CA+dpOJkC9aAKD99Gy0h+WDEYm-sVtjKw2Oako1DniUbO=gH9pQ@mail.gmail.com>
 <CAGgJW75W+AGQVcof+TS3_1h_W5wenbemsGiFjo2AM9ws99RPzA@mail.gmail.com>
Message-ID: <9DB3B145-64DD-45A1-AE7B-2263B585EB6E@dcn.davis.ca.us>

Quarto is built on top of RMarkdown when R is used, so RMarkdown isn't going anywhere soon. Don't spread unnecessary FUD.

Quarto is well-supported in VSCode, though.

And reply to the right branch of the thread... Bert is not in the thread below.

On November 29, 2023 10:29:03 AM PST, Eric Berger <ericjberger at gmail.com> wrote:
>Bert,
>Posit (formerly RStudio) has moved from RMarkdown to Quarto. They
>still support RMarkdown but major new features will be in Quarto. For
>new users a better choice would be Quarto.
>See https://quarto.org/docs/faq/rmarkdown.html
>
>Secondly, the OP stated he was using the VS-Code IDE, so there is no
>reason to point him to the Posit/RStudio IDE for this functionality
>which VS-Code supports very well (as I noted in my response.)
>
>Best,
>Eric
>
>On Wed, Nov 29, 2023 at 6:55?PM Christofer Bogaso
><bogaso.christofer at gmail.com> wrote:
>>
>> Hi Sergei,
>>
>> Where can I find TeX Comments extension in VS Code?
>>
>> On Wed, Nov 29, 2023 at 9:34?PM Sergei Ko <sggp.sergei at gmail.com> wrote:
>> >
>> > TeX Comments extension in VS Code
>> >
>> >
>> >
>> >
>> > Sent from my phone
>> >
>> >
>> > -------- Original message --------
>> > From: Christofer Bogaso <bogaso.christofer at gmail.com>
>> > Date: Wed, 29 Nov 2023, 15:57
>> > To: r-help <r-help at r-project.org>
>> > Subject: [R] Code editor for writing R code
>> >
>> > Hi,
>> >
>> > Currently I use VS-Code to write codes in R. While it is very good, it
>> > does not allow me to write Latex expressions in comments, which I am
>> > willing to have to write corresponding mathematical expressions as
>> > comments in my code files.
>> >
>> > Does there exist any Code editor for R, that allows me to write Latex
>> > in comments?
>> >
>> > Any information will be appreciated.
>> >
>> > Thanks,
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov 29 20:08:06 2023
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 29 Nov 2023 14:08:06 -0500
Subject: [R] Code editor for writing R code
In-Reply-To: <CAGgJW75W+AGQVcof+TS3_1h_W5wenbemsGiFjo2AM9ws99RPzA@mail.gmail.com>
References: <CA+dpOJ=ZC=VUsRiEMRstWRh_PGw3+6WkdVUZO1nnEdhWhhsXyw@mail.gmail.com>
 <8ievvg-p66t8t-ahivx4u900hh-1sai45yfknbi-ncyza7-oww5fw-akx7kp-pmvu60hfqa7r-93zurm-oa2dsb-t9rsl6udlczz75a2a1-puwhkqeuofzh-3ogxja-gkobc8-4v4zhbbdjppi-rn25vk-oy96sg.1701273879447@email.android.com>
 <CA+dpOJkC9aAKD99Gy0h+WDEYm-sVtjKw2Oako1DniUbO=gH9pQ@mail.gmail.com>
 <CAGgJW75W+AGQVcof+TS3_1h_W5wenbemsGiFjo2AM9ws99RPzA@mail.gmail.com>
Message-ID: <7eba91f7-a7d9-4b24-98a8-f56da6c2e234@gmail.com>

On 29/11/2023 1:29 p.m., Eric Berger wrote:
> Bert,
> Posit (formerly RStudio) has moved from RMarkdown to Quarto. They
> still support RMarkdown but major new features will be in Quarto. For
> new users a better choice would be Quarto.
> See https://quarto.org/docs/faq/rmarkdown.html

I'm not sure about that advice.  Quarto has some bad design choices.

For example, these lines: 
https://github.com/quarto-dev/quarto-cli/blob/3c9950947871ceafa54de909b15077cd54e27efe/src/resources/rmd/patch.R#L159-L184 
  have them faking S3 dispatch, but doing it really badly.  They worked 
around an issue I reported last year 
(https://github.com/quarto-dev/quarto-cli/issues/1800), but with a 
design like that, there will be other issues.


> Secondly, the OP stated he was using the VS-Code IDE, so there is no
> reason to point him to the Posit/RStudio IDE for this functionality
> which VS-Code supports very well (as I noted in my response.)

The original question did ask for recommendations for a different editor.

Duncan Murdoch

> 
> Best,
> Eric
> 
> On Wed, Nov 29, 2023 at 6:55?PM Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>>
>> Hi Sergei,
>>
>> Where can I find TeX Comments extension in VS Code?
>>
>> On Wed, Nov 29, 2023 at 9:34?PM Sergei Ko <sggp.sergei at gmail.com> wrote:
>>>
>>> TeX Comments extension in VS Code
>>>
>>>
>>>
>>>
>>> Sent from my phone
>>>
>>>
>>> -------- Original message --------
>>> From: Christofer Bogaso <bogaso.christofer at gmail.com>
>>> Date: Wed, 29 Nov 2023, 15:57
>>> To: r-help <r-help at r-project.org>
>>> Subject: [R] Code editor for writing R code
>>>
>>> Hi,
>>>
>>> Currently I use VS-Code to write codes in R. While it is very good, it
>>> does not allow me to write Latex expressions in comments, which I am
>>> willing to have to write corresponding mathematical expressions as
>>> comments in my code files.
>>>
>>> Does there exist any Code editor for R, that allows me to write Latex
>>> in comments?
>>>
>>> Any information will be appreciated.
>>>
>>> Thanks,
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


